{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert Generate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abasu644/aiops/blob/master/Bert_Generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai0xRngO4xZL",
        "colab_type": "text"
      },
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X8ZS575g5BP",
        "colab_type": "code",
        "outputId": "759fdd69-9636-4faf-f033-3ec513580a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "!pip install torch\n",
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.0+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.3)\n",
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.3.0+cu100)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/60/d9782c56ceefa76033a00e1f84cd8c586c75e6e7fea2cd45ee8b46a386c5/regex-2019.08.19-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.253)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.17.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.253 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.253)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.253->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.253->boto3->pytorch_pretrained_bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.253->boto3->pytorch_pretrained_bert) (1.12.0)\n",
            "Installing collected packages: regex, pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.8.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl_URz9EhMjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForQuestionAnswering, BertForPreTraining ,BertAdam\n",
        "from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertModel, BertConfig,BertOnlyMLMHead"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIAiqnsCqWto",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d857888d-de3d-40eb-bc53-4c9cc69d1792"
      },
      "source": [
        "config=BertConfig.from_dict({'vocab_size':32000,'num_labels':4})\n",
        "print(config)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 4,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YUoKL5yfN8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForSequenceClassification2(BertPreTrainedModel):\n",
        "    r\"\"\"\n",
        "        **labels**: (`optional`) ``torch.LongTensor`` of shape ``(batch_size,)``:\n",
        "            Labels for computing the sequence classification/regression loss.\n",
        "            Indices should be in ``[0, ..., config.num_labels - 1]``.\n",
        "            If ``config.num_labels == 1`` a regression loss is computed (Mean-Square loss),\n",
        "            If ``config.num_labels > 1`` a classification loss is computed (Cross-Entropy).\n",
        "\n",
        "    Outputs: `Tuple` comprising various elements depending on the configuration (config) and inputs:\n",
        "        **loss**: (`optional`, returned when ``labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n",
        "            Classification (or regression if config.num_labels==1) loss.\n",
        "        **logits**: ``torch.FloatTensor`` of shape ``(batch_size, config.num_labels)``\n",
        "            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
        "        **hidden_states**: (`optional`, returned when ``config.output_hidden_states=True``)\n",
        "            list of ``torch.FloatTensor`` (one for the output of each layer + the output of the embeddings)\n",
        "            of shape ``(batch_size, sequence_length, hidden_size)``:\n",
        "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
        "        **attentions**: (`optional`, returned when ``config.output_attentions=True``)\n",
        "            list of ``torch.FloatTensor`` (one for each layer) of shape ``(batch_size, num_heads, sequence_length, sequence_length)``:\n",
        "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
        "\n",
        "    Examples::\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n",
        "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
        "        outputs = model(input_ids, labels=labels)\n",
        "        loss, logits = outputs[:2]\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(BertForSequenceClassification2, self).__init__(config)\n",
        "        config.num_labels = 2\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,\n",
        "                position_ids=None, head_mask=None, labels=None):\n",
        "\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids,\n",
        "                            position_ids=position_ids, \n",
        "                            head_mask=head_mask)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7TMXB_MfQeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelpath = \"bert-base-chinese\"\n",
        "\n",
        "model = BertForSequenceClassification2.from_pretrained(modelpath)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9alyLJZ41kx",
        "colab_type": "text"
      },
      "source": [
        "# Bert Generate One By One"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2-W9XeqYRtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_text = \"[CLS] I go to school by bus [SEP] \"\n",
        "target_text = \"Ami scholey jachi\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdTArBzKhPb2",
        "colab_type": "code",
        "outputId": "67ab04dc-592b-4f2f-98a4-dcf4c731d2ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "modelpath = \"bert-base-chinese\"\n",
        "tokenizer = BertTokenizer.from_pretrained(modelpath)\n",
        "model = BertForMaskedLM2.from_pretrained(modelpath)\n",
        "\n",
        "model.to('cuda')\n",
        "\n",
        "example_pair = dict()\n",
        "\n",
        "for i in range(0,len(target_text)+1):\n",
        "  tokenized_text = tokenizer.tokenize(input_text)\n",
        "  tokenized_text.extend(target_text[:i])\n",
        "  tokenized_text.append('[MASK]')\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "#   for _ in range(512-len(indexed_tokens)):\n",
        "#     indexed_tokens.append(0)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
        "  \n",
        "  loss_ids = [-1] * (len(tokenizer.convert_tokens_to_ids(tokenized_text))-1)\n",
        "  if i == len(target_text):\n",
        "    loss_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[SEP]'))[0])\n",
        "  else:\n",
        "    loss_ids.append(tokenizer.convert_tokens_to_ids(target_text[i])[0])\n",
        "#   for _ in range(512-len(loss_ids)):\n",
        "#     loss_ids.append(-1)\n",
        "  loss_tensors = torch.tensor([loss_ids]).to('cuda')\n",
        "  \n",
        "  example_pair[tokens_tensor] = loss_tensors\n",
        "  print(tokenized_text,loss_ids,loss_ids[-1])\n",
        "  print(len(indexed_tokens),len(loss_tensors))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-bba6bc39b289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodelpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bert-base-chinese\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForMaskedLM2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model config {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# Instantiate model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mweights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialization_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-fe12f35cb1f9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertOnlyMLMHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'bert_model_embedding_weights'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6PRnq8jwb39",
        "colab_type": "code",
        "outputId": "0deedea9-7ae8-44fe-de9e-e669b347c3f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(example_pair)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,   103]],\n",
            "       device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 2769]],\n",
            "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,   103]],\n",
            "       device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 3022]],\n",
            "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
            "           103]], device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 1062]],\n",
            "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
            "          1062,   103]], device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 6722]],\n",
            "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
            "          1062,  6722,   103]], device='cuda:0'): tensor([[ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1, 677]],\n",
            "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
            "          1062,  6722,   677,   103]], device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
            "           -1, 2119]], device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
            "          1062,  6722,   677,  2119,   103]], device='cuda:0'): tensor([[ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
            "         102]], device='cuda:0')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4WdqbT06r44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "b826ecd2-d7ec-4bdf-9a05-dc9445cb1ce3"
      },
      "source": [
        "# Prepare optimizer\n",
        "param_optimizer = list(model.named_parameters())\n",
        "\n",
        "# hack to remove pooler, which is not used\n",
        "# thus it produce None grad that break apex\n",
        "param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ]\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                             lr=5e-5,\n",
        "                             warmup=0.1,\n",
        "                             t_total=300)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7edb9ad9067d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparam_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# hack to remove pooler, which is not used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# thus it produce None grad that break apex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparam_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_optimizer\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'pooler'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmQ3PhWa7I3z",
        "colab_type": "code",
        "outputId": "fdfdbe96-a96b-4e2f-e1f0-2f621b725796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.train()\n",
        "for i in range(0,60):\n",
        "  eveloss = 0\n",
        "  for k,v in example_pair.items():\n",
        "    print(v.shape)\n",
        "    loss = model(k,masked_lm_labels=v)\n",
        "    eveloss += loss.mean().item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  print(\"step \"+ str(i) + \" : \" + str(eveloss))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 0 : 41.22521352767944\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 1 : 26.684499740600586\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 2 : 23.901904106140137\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 3 : 17.304611206054688\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 4 : 28.499771118164062\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 5 : 7.966344833374023\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 6 : 15.410914421081543\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 7 : 39.65335655212402\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 8 : 4.504445552825928\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 9 : 1.9586944580078125\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 10 : 0.06949996948242188\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 11 : 17.85985565185547\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 12 : 0.0017261505126953125\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 13 : 3.814697265625e-06\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 14 : 0.0036678314208984375\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 15 : 0.0002689361572265625\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 16 : 3.814697265625e-06\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 17 : 1.9073486328125e-06\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 18 : 1.9073486328125e-06\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 19 : 4.951913833618164\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 20 : 0.1801738739013672\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 21 : 1.9073486328125e-06\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 22 : 1.9073486328125e-06\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 23 : 0.0001468658447265625\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 24 : 0.0\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 25 : 25.735794067382812\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 26 : 5.7220458984375e-06\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 27 : 0.002979278564453125\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 28 : 0.7532558441162109\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 29 : 2.6702880859375e-05\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 30 : 3.24249267578125e-05\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 31 : 7.62939453125e-06\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 32 : 1.1444091796875e-05\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 33 : 1.1444091796875e-05\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 34 : 3.0517578125e-05\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 35 : 0.000118255615234375\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 36 : 1.52587890625e-05\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 37 : 5.7220458984375e-06\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 38 : 9.72747802734375e-05\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 39 : 9.1552734375e-05\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 40 : 7.62939453125e-06\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n",
            "step 41 : 0.000133514404296875\n",
            "torch.Size([1, 9])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 11])\n",
            "torch.Size([1, 12])\n",
            "torch.Size([1, 13])\n",
            "torch.Size([1, 14])\n",
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 42 : 3.0517578125e-05\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 43 : 2.47955322265625e-05\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 44 : 5.7220458984375e-06\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 45 : 9.918212890625e-05\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 46 : 9.5367431640625e-06\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 47 : 1.1444091796875e-05\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 48 : 9.5367431640625e-06\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 49 : 9.34600830078125e-05\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 50 : 2.47955322265625e-05\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 51 : 2.47955322265625e-05\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 52 : 1.52587890625e-05\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 53 : 0.00025177001953125\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 54 : 3.814697265625e-06\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 55 : 5.7220458984375e-06\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 56 : 7.62939453125e-06\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 57 : 1.9073486328125e-06\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step 58 : 4.00543212890625e-05\n",
            "torch.Size([1, 9])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 13])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 15])\n",
            "step 59 : 3.814697265625e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq4l1GAWRfvm",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epTye3VAZ_5r",
        "colab_type": "code",
        "outputId": "456c52d6-a873-4cd7-c591-0490e9fd93fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "model.eval()\n",
        "for k,v in example_pair.items():\n",
        "    predictions = model(k)\n",
        "    predicted_index = torch.argmax(predictions[0,len(predictions[0])-1]).item()\n",
        "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
        "    if '[SEP]' in predicted_token:\n",
        "      break\n",
        "    print(predicted_token)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['我']\n",
            "['搭']\n",
            "['公']\n",
            "['車']\n",
            "['上']\n",
            "['學']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jJ9Wkaz5AaL",
        "colab_type": "text"
      },
      "source": [
        "# Bert Generate One Time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnIbjZHbYUa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_text = \"[CLS] I go to school by bus [SEP] \"\n",
        "target_text = \"我搭公車上學\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMmvXGZe5mLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "modelpath = \"bert-base-chinese\"\n",
        "tokenizer = BertTokenizer.from_pretrained(modelpath)\n",
        "model = BertForMaskedLM.from_pretrained(modelpath)\n",
        "model.to('cuda')\n",
        "\n",
        "tokenized_text = tokenizer.tokenize(input_text)\n",
        "for i in target_text:\n",
        "  tokenized_text.append('[MASK]')\n",
        "# tokenized_text.append('[SEP]')\n",
        "for _ in range(128-len(tokenized_text)):\n",
        "  tokenized_text.append('[MASK]')\n",
        "# tokenized_text.append('[MASK]')\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
        "\n",
        "loss_ids = []\n",
        "loss_ids = [-1] * (len(tokenizer.tokenize(input_text)))\n",
        "# loss_ids.extend(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_text)))\n",
        "for i in target_text:\n",
        "  loss_ids.append(tokenizer.convert_tokens_to_ids(i)[0])\n",
        "loss_ids.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n",
        "for _ in range(128-len(loss_ids)):\n",
        "  loss_ids.append(-1)\n",
        "loss_tensors = torch.tensor([loss_ids]).to('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxSZyq6D87YX",
        "colab_type": "code",
        "outputId": "9dc17c95-b8c5-4327-b238-e9fa66d196df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "print(tokens_tensor,loss_tensors)\n",
        "print(tokenizer.convert_ids_to_tokens(indexed_tokens))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "           103,   103,   103,   103,   103,   103,   103,   103]],\n",
            "       device='cuda:0') tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 2769, 3022, 1062, 6722,\n",
            "          677, 2119,  102,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
            "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
            "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
            "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
            "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
            "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
            "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
            "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
            "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
            "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1]], device='cuda:0')\n",
            "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtWr0Zs158ZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Prepare optimizer\n",
        "# param_optimizer = list(model.named_parameters())\n",
        "\n",
        "# # hack to remove pooler, which is not used\n",
        "# # thus it produce None grad that break apex\n",
        "# param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
        "\n",
        "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "# optimizer_grouped_parameters = [\n",
        "#         {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.05},\n",
        "#         {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.01}\n",
        "#         ]\n",
        "# optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "#                              lr=5e-5)\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-7)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr = 5e-5, momentum=0.9)\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr = 5e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQfnhXCy5_Ag",
        "colab_type": "code",
        "outputId": "af10ca8a-9a7b-4953-f240-69d3c59b9470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5290
        }
      },
      "source": [
        "model.train()\n",
        "for i in range(0,300):\n",
        "  loss = model(tokens_tensor,masked_lm_labels=loss_tensors)\n",
        "  eveloss = loss.mean().item()\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(\"step \"+ str(i) + \" : \" + str(eveloss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0 : 7.913342475891113\n",
            "step 1 : 7.833029270172119\n",
            "step 2 : 7.197516441345215\n",
            "step 3 : 6.325068473815918\n",
            "step 4 : 5.70965576171875\n",
            "step 5 : 5.5573506355285645\n",
            "step 6 : 4.576362609863281\n",
            "step 7 : 4.289361000061035\n",
            "step 8 : 4.3420515060424805\n",
            "step 9 : 4.592452526092529\n",
            "step 10 : 4.3097662925720215\n",
            "step 11 : 4.651139736175537\n",
            "step 12 : 4.5207648277282715\n",
            "step 13 : 4.477480411529541\n",
            "step 14 : 4.2064900398254395\n",
            "step 15 : 4.258938789367676\n",
            "step 16 : 4.068099498748779\n",
            "step 17 : 3.940248727798462\n",
            "step 18 : 4.226219654083252\n",
            "step 19 : 4.136264801025391\n",
            "step 20 : 4.031257629394531\n",
            "step 21 : 4.052146911621094\n",
            "step 22 : 4.0309343338012695\n",
            "step 23 : 3.9492135047912598\n",
            "step 24 : 3.657867431640625\n",
            "step 25 : 3.862555980682373\n",
            "step 26 : 3.7650206089019775\n",
            "step 27 : 3.5912110805511475\n",
            "step 28 : 3.6331944465637207\n",
            "step 29 : 3.9080066680908203\n",
            "step 30 : 3.6006791591644287\n",
            "step 31 : 3.616935968399048\n",
            "step 32 : 3.6273269653320312\n",
            "step 33 : 3.4186439514160156\n",
            "step 34 : 3.361997365951538\n",
            "step 35 : 3.232696056365967\n",
            "step 36 : 3.52933669090271\n",
            "step 37 : 3.5277061462402344\n",
            "step 38 : 3.4441311359405518\n",
            "step 39 : 3.1852688789367676\n",
            "step 40 : 3.068091630935669\n",
            "step 41 : 3.2665083408355713\n",
            "step 42 : 3.080008029937744\n",
            "step 43 : 3.1224658489227295\n",
            "step 44 : 2.9322803020477295\n",
            "step 45 : 2.863637924194336\n",
            "step 46 : 2.8540420532226562\n",
            "step 47 : 2.8729798793792725\n",
            "step 48 : 2.638160228729248\n",
            "step 49 : 2.4272518157958984\n",
            "step 50 : 2.71510648727417\n",
            "step 51 : 2.541132688522339\n",
            "step 52 : 2.5047762393951416\n",
            "step 53 : 2.6105880737304688\n",
            "step 54 : 1.9781339168548584\n",
            "step 55 : 1.9441291093826294\n",
            "step 56 : 2.1932919025421143\n",
            "step 57 : 2.159261465072632\n",
            "step 58 : 2.2510900497436523\n",
            "step 59 : 2.0489025115966797\n",
            "step 60 : 1.9925830364227295\n",
            "step 61 : 2.0157437324523926\n",
            "step 62 : 1.83278489112854\n",
            "step 63 : 1.6471681594848633\n",
            "step 64 : 1.5999395847320557\n",
            "step 65 : 1.8291329145431519\n",
            "step 66 : 1.865471601486206\n",
            "step 67 : 2.212336778640747\n",
            "step 68 : 1.5861409902572632\n",
            "step 69 : 2.3091835975646973\n",
            "step 70 : 1.996158242225647\n",
            "step 71 : 2.0834097862243652\n",
            "step 72 : 1.6751326322555542\n",
            "step 73 : 2.021115779876709\n",
            "step 74 : 1.7128123044967651\n",
            "step 75 : 1.299766182899475\n",
            "step 76 : 1.3418318033218384\n",
            "step 77 : 1.5672235488891602\n",
            "step 78 : 1.554721474647522\n",
            "step 79 : 1.3490718603134155\n",
            "step 80 : 2.143139362335205\n",
            "step 81 : 1.7476389408111572\n",
            "step 82 : 1.6365439891815186\n",
            "step 83 : 1.2163630723953247\n",
            "step 84 : 2.938359498977661\n",
            "step 85 : 1.0602567195892334\n",
            "step 86 : 1.33014714717865\n",
            "step 87 : 1.7363799810409546\n",
            "step 88 : 1.4378411769866943\n",
            "step 89 : 1.2095121145248413\n",
            "step 90 : 1.2718843221664429\n",
            "step 91 : 1.3220192193984985\n",
            "step 92 : 1.2332451343536377\n",
            "step 93 : 0.9844916462898254\n",
            "step 94 : 1.29464852809906\n",
            "step 95 : 1.306981086730957\n",
            "step 96 : 0.9789025187492371\n",
            "step 97 : 1.3268163204193115\n",
            "step 98 : 1.179093599319458\n",
            "step 99 : 0.8877961039543152\n",
            "step 100 : 1.1054086685180664\n",
            "step 101 : 1.0813977718353271\n",
            "step 102 : 1.0766011476516724\n",
            "step 103 : 0.8238755464553833\n",
            "step 104 : 0.9189795255661011\n",
            "step 105 : 1.1906391382217407\n",
            "step 106 : 0.5976792573928833\n",
            "step 107 : 0.6830437779426575\n",
            "step 108 : 0.7761771082878113\n",
            "step 109 : 0.5914703011512756\n",
            "step 110 : 0.5983243584632874\n",
            "step 111 : 0.9280140995979309\n",
            "step 112 : 1.0083562135696411\n",
            "step 113 : 0.6310529708862305\n",
            "step 114 : 0.39636093378067017\n",
            "step 115 : 0.7182576060295105\n",
            "step 116 : 0.37458691000938416\n",
            "step 117 : 0.7941285371780396\n",
            "step 118 : 0.35499873757362366\n",
            "step 119 : 0.5166822075843811\n",
            "step 120 : 0.14390699565410614\n",
            "step 121 : 0.5186410546302795\n",
            "step 122 : 0.12263625115156174\n",
            "step 123 : 0.3159002661705017\n",
            "step 124 : 0.28471946716308594\n",
            "step 125 : 0.43201854825019836\n",
            "step 126 : 0.3130081593990326\n",
            "step 127 : 0.2788824439048767\n",
            "step 128 : 0.2701137959957123\n",
            "step 129 : 0.40857505798339844\n",
            "step 130 : 0.1467811018228531\n",
            "step 131 : 0.10585485398769379\n",
            "step 132 : 0.16690881550312042\n",
            "step 133 : 0.36910152435302734\n",
            "step 134 : 0.15273775160312653\n",
            "step 135 : 0.23997987806797028\n",
            "step 136 : 0.019033703953027725\n",
            "step 137 : 0.13931791484355927\n",
            "step 138 : 0.20446886122226715\n",
            "step 139 : 0.03363118693232536\n",
            "step 140 : 0.27058520913124084\n",
            "step 141 : 0.42665794491767883\n",
            "step 142 : 0.21620668470859528\n",
            "step 143 : 0.11303602159023285\n",
            "step 144 : 0.4565868377685547\n",
            "step 145 : 0.08169623464345932\n",
            "step 146 : 0.06721986830234528\n",
            "step 147 : 0.029532568529248238\n",
            "step 148 : 0.0182200837880373\n",
            "step 149 : 0.1296495646238327\n",
            "step 150 : 0.01715632900595665\n",
            "step 151 : 0.036151885986328125\n",
            "step 152 : 0.07706451416015625\n",
            "step 153 : 0.2613397240638733\n",
            "step 154 : 0.11421803385019302\n",
            "step 155 : 0.04703821614384651\n",
            "step 156 : 0.9960566759109497\n",
            "step 157 : 0.05726705119013786\n",
            "step 158 : 0.019573483616113663\n",
            "step 159 : 0.24197959899902344\n",
            "step 160 : 0.1230643168091774\n",
            "step 161 : 0.6597734093666077\n",
            "step 162 : 0.009563990868628025\n",
            "step 163 : 3.056791305541992\n",
            "step 164 : 0.04194531962275505\n",
            "step 165 : 0.0481240414083004\n",
            "step 166 : 0.015704018995165825\n",
            "step 167 : 0.0497371144592762\n",
            "step 168 : 0.12608201801776886\n",
            "step 169 : 0.20319557189941406\n",
            "step 170 : 0.0036670139525085688\n",
            "step 171 : 0.00488226767629385\n",
            "step 172 : 0.2012481689453125\n",
            "step 173 : 0.002960477489978075\n",
            "step 174 : 0.008483069017529488\n",
            "step 175 : 0.0181307103484869\n",
            "step 176 : 0.04133524373173714\n",
            "step 177 : 0.00305938720703125\n",
            "step 178 : 0.028586795553565025\n",
            "step 179 : 0.05765097588300705\n",
            "step 180 : 0.019239425659179688\n",
            "step 181 : 0.05654880031943321\n",
            "step 182 : 0.004998070653527975\n",
            "step 183 : 0.03512436896562576\n",
            "step 184 : 0.027407782152295113\n",
            "step 185 : 0.0028348651248961687\n",
            "step 186 : 0.003379549365490675\n",
            "step 187 : 0.03843552619218826\n",
            "step 188 : 0.004937308374792337\n",
            "step 189 : 0.005481175146996975\n",
            "step 190 : 0.0032326835207641125\n",
            "step 191 : 0.0021547588985413313\n",
            "step 192 : 0.0029204231686890125\n",
            "step 193 : 0.017324719578027725\n",
            "step 194 : 0.0134419035166502\n",
            "step 195 : 0.012366430833935738\n",
            "step 196 : 0.01083428505808115\n",
            "step 197 : 0.004296166356652975\n",
            "step 198 : 0.0050577437505126\n",
            "step 199 : 0.0078370226547122\n",
            "step 200 : 0.0013874599244445562\n",
            "step 201 : 0.0017664773622527719\n",
            "step 202 : 0.0051422119140625\n",
            "step 203 : 0.007668631616979837\n",
            "step 204 : 0.0068746292963624\n",
            "step 205 : 0.0018555776914581656\n",
            "step 206 : 0.011963163502514362\n",
            "step 207 : 0.009174891747534275\n",
            "step 208 : 0.0013234274229034781\n",
            "step 209 : 0.026727130636572838\n",
            "step 210 : 0.0005482264677993953\n",
            "step 211 : 0.003975186962634325\n",
            "step 212 : 0.0016316005494445562\n",
            "step 213 : 0.003011158434674144\n",
            "step 214 : 0.0028501239139586687\n",
            "step 215 : 0.0019457681337371469\n",
            "step 216 : 0.0014062608825042844\n",
            "step 217 : 0.0008019038359634578\n",
            "step 218 : 0.0006019047577865422\n",
            "step 219 : 0.0018542153993621469\n",
            "step 220 : 0.0076353889890015125\n",
            "step 221 : 0.0011700221803039312\n",
            "step 222 : 0.0015953609254211187\n",
            "step 223 : 0.0035923549439758062\n",
            "step 224 : 0.0025896343868225813\n",
            "step 225 : 0.0008833748870529234\n",
            "step 226 : 0.0013419559691101313\n",
            "step 227 : 0.0011157989501953125\n",
            "step 228 : 0.0006223405944183469\n",
            "step 229 : 0.00215503154322505\n",
            "step 230 : 0.00067901611328125\n",
            "step 231 : 0.0010730198118835688\n",
            "step 232 : 0.0044615608640015125\n",
            "step 233 : 0.0009392329375259578\n",
            "step 234 : 0.0015615735901519656\n",
            "step 235 : 0.005328587256371975\n",
            "step 236 : 0.0010266985045745969\n",
            "step 237 : 0.0017177036497741938\n",
            "step 238 : 0.0009806497255340219\n",
            "step 239 : 0.0009389604674652219\n",
            "step 240 : 0.0008681160979904234\n",
            "step 241 : 0.0008051735931076109\n",
            "step 242 : 0.0031514849979430437\n",
            "step 243 : 0.0013070787535980344\n",
            "step 244 : 0.0010474069276824594\n",
            "step 245 : 0.00195666728541255\n",
            "step 246 : 0.0013277871767058969\n",
            "step 247 : 0.000514984130859375\n",
            "step 248 : 0.0005694798310287297\n",
            "step 249 : 0.0022256034426391125\n",
            "step 250 : 0.0005479539977386594\n",
            "step 251 : 0.0015024457825347781\n",
            "step 252 : 0.010113035328686237\n",
            "step 253 : 0.0008629389922134578\n",
            "step 254 : 0.0014471326721832156\n",
            "step 255 : 0.0016602107789367437\n",
            "step 256 : 0.0011667524231597781\n",
            "step 257 : 0.031465258449316025\n",
            "step 258 : 0.0021487644407898188\n",
            "step 259 : 0.0006814684020355344\n",
            "step 260 : 0.0015866415342316031\n",
            "step 261 : 0.0014997209655120969\n",
            "step 262 : 0.002365384716540575\n",
            "step 263 : 0.0008760179625824094\n",
            "step 264 : 0.0011264255736023188\n",
            "step 265 : 0.0012008121702820063\n",
            "step 266 : 0.00036076136166229844\n",
            "step 267 : 0.00127410888671875\n",
            "step 268 : 0.0015653882874175906\n",
            "step 269 : 0.005958284717053175\n",
            "step 270 : 0.001996448962017894\n",
            "step 271 : 0.0010487692197784781\n",
            "step 272 : 0.026752471923828125\n",
            "step 273 : 0.0005986350006423891\n",
            "step 274 : 0.002947398694232106\n",
            "step 275 : 0.0009969983948394656\n",
            "step 276 : 0.0013245174195617437\n",
            "step 277 : 0.034785814583301544\n",
            "step 278 : 0.0011144365416839719\n",
            "step 279 : 0.6973615288734436\n",
            "step 280 : 0.0008634839905425906\n",
            "step 281 : 0.0011781965149566531\n",
            "step 282 : 0.0037430354859679937\n",
            "step 283 : 0.0052296775393188\n",
            "step 284 : 0.0008784703095443547\n",
            "step 285 : 0.10502297431230545\n",
            "step 286 : 0.0009389604674652219\n",
            "step 287 : 0.011853626929223537\n",
            "step 288 : 0.002768107922747731\n",
            "step 289 : 0.0039730072021484375\n",
            "step 290 : 0.008652006275951862\n",
            "step 291 : 0.0020108905155211687\n",
            "step 292 : 0.0011286054505035281\n",
            "step 293 : 0.005363191943615675\n",
            "step 294 : 0.0032283237669616938\n",
            "step 295 : 0.003979274071753025\n",
            "step 296 : 0.004879542626440525\n",
            "step 297 : 0.005062648095190525\n",
            "step 298 : 0.0021236964967101812\n",
            "step 299 : 0.007640293799340725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1tz6P9N4e3g",
        "colab_type": "code",
        "outputId": "908553ac-871a-49f8-ba43-862fd167a22d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  predictions = model(tokens_tensor)\n",
        "  start = len(tokenizer.tokenize(input_text))\n",
        "  while start < len(predictions[0]):\n",
        "    predicted_index = torch.argmax(predictions[0,start]).item()\n",
        "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
        "    if '[SEP]' in predicted_token:\n",
        "        break\n",
        "    print(predicted_token)\n",
        "    start+=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['我']\n",
            "['搭']\n",
            "['公']\n",
            "['車']\n",
            "['上']\n",
            "['學']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_Lf5xx8ea9p",
        "colab_type": "text"
      },
      "source": [
        "# Bert Generate LSTM\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgGoh0YfJQKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_text = \"[CLS] I go to school by bus [SEP] \"\n",
        "target_text = \"我搭公車上學\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMM-Kq7aKden",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "modelpath = \"bert-base-chinese\"\n",
        "tokenizer = BertTokenizer.from_pretrained(modelpath)\n",
        "example_pair = dict()\n",
        "\n",
        "for i in range(0,len(target_text)+1):\n",
        "  tokenized_text = tokenizer.tokenize(input_text)\n",
        "  tokenized_text.extend(target_text[:i])\n",
        "  tokenized_text.append('[MASK]')\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "  tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
        "  \n",
        "  loss_ids = [-1] * (len(tokenizer.convert_tokens_to_ids(tokenized_text))-1)\n",
        "  if i == len(target_text):\n",
        "    loss_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[SEP]'))[0])\n",
        "  else:\n",
        "    loss_ids.append(tokenizer.convert_tokens_to_ids(target_text[i])[0])\n",
        "  loss_tensors = torch.tensor([loss_ids]).to('cuda')\n",
        "  \n",
        "  example_pair[tokens_tensor] = loss_tensors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-7whGubegWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        modelpath = \"bert-base-chinese\"\n",
        "        self.bert = BertModel.from_pretrained(modelpath)\n",
        "        self.rnn = nn.LSTM(num_layers=2,dropout=0.2, input_size=768, hidden_size=768//2)\n",
        "        self.fc = nn.Linear(384, self.bert.config.vocab_size)\n",
        "        \n",
        "    def forward(self, x,y=None):\n",
        "        \n",
        "        self.bert.train()\n",
        "        encoded_layers, _ = self.bert(x)\n",
        "        for i in encoded_layers:\n",
        "          enc, _ = self.rnn(i[0,0])\n",
        "        logits = self.fc(enc)\n",
        "        if y is not None:\n",
        "          loss_fct  = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "          loss = loss_fct(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
        "          return loss\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isEDLjTbI3P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertLSTM()\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr = 5e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IimXyW2QJVmA",
        "colab_type": "code",
        "outputId": "6934a341-9e1e-4651-8de8-5a30618a45c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        }
      },
      "source": [
        "model.to('cuda')\n",
        "model.train()\n",
        "for i in range(0,150):\n",
        "  eveloss = 0\n",
        "  for k,v in example_pair.items():\n",
        "    optimizer.zero_grad()\n",
        "    loss = model(k,v)\n",
        "    eveloss += loss.mean().item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(\"step \"+ str(i) + \" : \" + str(eveloss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([768])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-824645e6ef9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexample_pair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0meveloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-139d1fd00ef5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH77VGEAIm5T",
        "colab_type": "code",
        "outputId": "9e3234ec-baf0-4938-b3d2-01f4c8071bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "model.eval()\n",
        "for k,v in example_pair.items():\n",
        "    predictions = model(k)\n",
        "    predicted_index = torch.argmax(predictions[0,-1]).item()\n",
        "    if predicted_index < model.bert.config.vocab_size:\n",
        "      predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
        "    print(predicted_token)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['我']\n",
            "['搭']\n",
            "['公']\n",
            "['車']\n",
            "['上']\n",
            "['學']\n",
            "['[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}