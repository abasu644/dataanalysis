case_id,case_owner,status,case_number,case_record_type,case_comment_created_time,,case_comments,description,subject,,date_time_opened,age,open,account_name,case_comment_0,case_comment_1,case_comment_2,case_comment_3,case_comment_4,case_comment_5,case_comment_6,case_comment_7,case_comment_8,case_comment_9,case_comment_10,case_comment_11,case_comment_12,case_comment_13,case_comment_14,case_comment_15,case_comment_16,case_comment_17,case_comment_18,case_comment_19,case_comment_20,case_comment_21,case_comment_22,case_comment_23,case_comment_24,case_comment_25,case_comment_26,case_comment_27,case_comment_28,case_comment_29,case_comment_30,case_comment_31,case_comment_32,case_comment_33,case_comment_34,case_comment_35,case_comment_36,case_comment_37,case_comment_38,case_comment_39,case_comment_40,case_comment_41,case_comment_42,case_comment_43,case_comment_44,case_comment_45,case_comment_46,case_comment_47,case_comment_48,case_comment_49,case_comment_50,case_comment_51,case_comment_52,case_comment_53,case_comment_54,case_comment_55,case_comment_56,case_comment_57,case_comment_58,case_comment_59,case_comment_60,case_comment_61,case_comment_62,case_comment_63,case_comment_64,case_comment_65,case_comment_66,case_comment_67,case_comment_68,case_comment_69,case_comment_70,case_comment_71,case_comment_72,case_comment_73,case_comment_74,case_comment_75,case_comment_76,case_comment_77,case_comment_78,case_comment_79,case_comment_80,case_comment_81,case_comment_82,case_comment_83,case_comment_84,case_comment_85,case_comment_86,case_comment_87,case_comment_88,case_comment_89,case_comment_90,case_comment_91,case_comment_92,case_comment_93,case_comment_94,case_comment_95,case_comment_96,case_comment_97,case_comment_98,case_comment_99,case_comment_100,case_comment_101,case_comment_102,case_comment_103,case_comment_104,case_comment_105,case_comment_106,case_comment_107,case_comment_108,case_comment_109,case_comment_110,case_comment_111,case_comment_112,case_comment_113,case_comment_114,case_comment_115,case_comment_116,case_comment_117,case_comment_118,case_comment_119,case_comment_120,case_comment_121,case_comment_122,case_comment_123,case_comment_124,case_comment_125,case_comment_126,case_comment_127,case_comment_128,case_comment_129,case_comment_130,case_comment_131,case_comment_132,case_comment_133,case_comment_134,case_comment_135,case_comment_136,response
5000G00001D9qPe,Cloud Engineer Level 1,Closed,1061150,Incident,08-06-2017 03:23,,"Hello Steven,We are going to disabling the maintenance mode. Please let us know if you have any queries.###Hello Steven,Thanks for the information.We have enabled maintenance mode for the resources.","REAN team,We are preforming some preliminary updates to this domain (preview.spendhq.com). Can you put this domain into maintenance mode until 3 pm EDT.Thanks.Steven Ng | Full Stack Developer | SpendHQ(r)O: 770-628-0692 | sng@spendhq.com<mailto:sng@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Maintenance for Preview,,07-06-2017 22:46,5,0,SpendHQ,"Hello Steven,We are going to disabling the maintenance mode. Please let us know if you have any queries.","Hello Steven,Thanks for the information.We have enabled maintenance mode for the resources.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TnB6V,Cloud Engineer Level 1,Closed,1094721,Incident,03-04-2018 18:43,,"Hello Andrew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###We believe this may be from a monitoring service. Please do not block. Thank you.###Hello Team, This is a gentle reminder.Please review the Intrusion Prevention Alert (Packet dropped) details and let us know if you want us to block this IP address from the subnet NACL.###Hello Team,Please review the Intrusion Prevention Alert (Packet dropped) details and let us know if you want us to block this IP address from the subnet NACL###Hello SpendHQ-Team, This is to inform you that we have received an Intrusion Prevention Alert (Packet dropped), we have analyzed the same and below are the findings. Name: Intrusion protection alert Action: drop, Reason: SERVER-ORACLE Oracle WebLogic Server remote command execution attempt, Class: Attempted Administrator Privilege Gain, Source IP Destination IP Port Mapping: 10.59.0.218:16721 ==> 10.59.1.192:80 10.59.1.102:35748 ==> 10.59.1.192:80 Please find the source IP to ELB mapping here which includes non monitoring resources as well. 10.59.0.218 - capfiles-spendhq-xelb - Access Logs not enabled. - Not Under Contract. 10.59.1.102 - preview-spendhq-xelb Access Logs enabled.Please find the associated logs below: 2018:03:31-17:47:58 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.218 dstip=10.59.1.192 proto=6 srcport=16721 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02018:03:31-17:52:18 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.102 dstip=10.59.1.192 proto=6 srcport=35748 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0By analyzing the ELB preview-spendhq-xelb, we were able to track down the requester public IP. Please find the details below. IP Address: 35.168.141.9Country: United StatesRegion: Virginia Please find these details and let us know if we have your approval to block this IP address from the subnet NACL. Feel free to reach us for any queries.","---------- Forwarded message ----------From: Firewall Notification System <manage-spendhq@reancloud.com>Date: Sat, Mar 31, 2018 at 11:17 PMSubject: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped)To: event-5domgd23@dtdg.co, spendhq-support@reancloud.com, ms@reancloud.comIntrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-ORACLE Oracle WebLogic Server remote commandexecution attemptDetails........: https://www.snort.org/search?query=45304Time...........: 2018-03-31 17:47:58Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.0.218Source port: 16721Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)Account Name - SpendHQAccount DL - ms@reancloud.comUTM Hostname - spendhq-utmPrivate IP - 10.59.1.192Public IP - 52.0.17.10Device URL - https://52.0.17.10:4444--System Uptime      : 96 days 10 hours 45 minutesSystem Load        : 0.04System Version     : Sophos UTM 9.506-2Please refer to the manual for detailed instructions.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,31-03-2018 23:20,67,0,SpendHQ,"Hello Andrew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.",We believe this may be from a monitoring service. Please do not block. Thank you.,"Hello Team, This is a gentle reminder.Please review the Intrusion Prevention Alert (Packet dropped) details and let us know if you want us to block this IP address from the subnet NACL.","Hello Team,Please review the Intrusion Prevention Alert (Packet dropped) details and let us know if you want us to block this IP address from the subnet NACL","Hello SpendHQ-Team, This is to inform you that we have received an Intrusion Prevention Alert (Packet dropped), we have analyzed the same and below are the findings. Name: Intrusion protection alert Action: drop, Reason: SERVER-ORACLE Oracle WebLogic Server remote command execution attempt, Class: Attempted Administrator Privilege Gain, Source IP Destination IP Port Mapping: 10.59.0.218:16721 ==> 10.59.1.192:80 10.59.1.102:35748 ==> 10.59.1.192:80 Please find the source IP to ELB mapping here which includes non monitoring resources as well. 10.59.0.218 - capfiles-spendhq-xelb - Access Logs not enabled. - Not Under Contract. 10.59.1.102 - preview-spendhq-xelb Access Logs enabled.Please find the associated logs below: 2018:03:31-17:47:58 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.218 dstip=10.59.1.192 proto=6 srcport=16721 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02018:03:31-17:52:18 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.102 dstip=10.59.1.192 proto=6 srcport=35748 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0By analyzing the ELB preview-spendhq-xelb, we were able to track down the requester public IP. Please find the details below. IP Address: 35.168.141.9Country: United StatesRegion: Virginia Please find these details and let us know if we have your approval to block this IP address from the subnet NACL. Feel free to reach us for any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001C3I78,Cloud Engineer Level 1,Closed,1055027,Incident,20-05-2017 09:37,,"Hello SpendHq-Team, On further analyzing the Preview ELB logs at the time of the alert, We are able to find the IP's 122.107.150.123 and 209.126.136.5. The IP 122.107.150.123 belongs to Victoria region in Australia and the IP 209.126.136.5 belongs to California region in theUnited States. These both IP's was trying to execute the SERVER-APACHE Apache Struts remote code.Please find the logs details below, ELB Logs: 2017-05-20T02:48:47.684839Z preview-spendhq-xelb 122.107.150.123:39932 10.59.1.192:443 0.000042 0.001698 0.000048 403 403 0 209 GET https://52.6.177.194:443/ HTTP/1.1 curl/7.43.0 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.22017-05-20T03:07:13.712521Z preview-spendhq-xelb 209.126.136.5:38122 10.59.1.192:8443 0.000042 0.00169 0.000028 403 403 0 209 GET https://52.4.199.57:8443/ HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Let us know if your team have any further queries regarding this case.###Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-20 02:43:03Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.111Source port: 6586Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http),[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,20-05-2017 08:22,9,0,SpendHQ,"Hello SpendHq-Team, On further analyzing the Preview ELB logs at the time of the alert, We are able to find the IP's 122.107.150.123 and 209.126.136.5. The IP 122.107.150.123 belongs to Victoria region in Australia and the IP 209.126.136.5 belongs to California region in theUnited States. These both IP's was trying to execute the SERVER-APACHE Apache Struts remote code.Please find the logs details below, ELB Logs: 2017-05-20T02:48:47.684839Z preview-spendhq-xelb 122.107.150.123:39932 10.59.1.192:443 0.000042 0.001698 0.000048 403 403 0 209 GET https://52.6.177.194:443/ HTTP/1.1 curl/7.43.0 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.22017-05-20T03:07:13.712521Z preview-spendhq-xelb 209.126.136.5:38122 10.59.1.192:8443 0.000042 0.00169 0.000028 403 403 0 209 GET https://52.4.199.57:8443/ HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Let us know if your team have any further queries regarding this case.","Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001C410j,Cloud Engineer Level 1,Closed,1055635,Incident,24-05-2017 00:57,,"Hello Team,We have verified from the instance level that we are not using the module Struts in our application and this incident will not affect our application. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Hello SpendHQ-Team,On further analysis, we have checked the ELB logs and we could see a number of requests with 403 response code. We got the request from 2 IP's 199.64.6.155 and 24.5.67.101. Both the requests were having 403 error code.ELB Logs:2017-05-23T11:25:43.643527Z Secure-SpendHQ-ELB 199.64.6.155:33455 10.59.1.192:443 0.000051 0.11606 0.000045 403 403 0 0 GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1495449366787 HTTP/1.1 Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko ECDHE-RSA-AES128-SHA256 TLSv1.22017-05-23T11:39:15.424832Z Secure-SpendHQ-ELB 24.5.67.101:50319 10.59.1.192:443 0.000059 0.104268 0.000044 403 403 0 0 GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1495529833951 HTTP/1.1 Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2IP Details for 199.64.6.155:IP: 199.64.6.155Country: United StatesISP: Honeywell International Inc.	IP Details for 24.5.67.101IP: 24.5.67.101Country: United StatesISP: Comcast Cable Communications LLCPlease let us know if you want us to block the IP in NACL level. Let us know if you have any queries regarding this.###Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.123 which belongs to the Secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41819Time...........: 2017-05-23 11:45:32Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.123Source port: 34459Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http),[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,23-05-2017 17:48,7,0,SpendHQ,"Hello Team,We have verified from the instance level that we are not using the module Struts in our application and this incident will not affect our application. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Hello SpendHQ-Team,On further analysis, we have checked the ELB logs and we could see a number of requests with 403 response code. We got the request from 2 IP's 199.64.6.155 and 24.5.67.101. Both the requests were having 403 error code.ELB Logs:2017-05-23T11:25:43.643527Z Secure-SpendHQ-ELB 199.64.6.155:33455 10.59.1.192:443 0.000051 0.11606 0.000045 403 403 0 0 GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1495449366787 HTTP/1.1 Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko ECDHE-RSA-AES128-SHA256 TLSv1.22017-05-23T11:39:15.424832Z Secure-SpendHQ-ELB 24.5.67.101:50319 10.59.1.192:443 0.000059 0.104268 0.000044 403 403 0 0 GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1495529833951 HTTP/1.1 Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2IP Details for 199.64.6.155:IP: 199.64.6.155Country: United StatesISP: Honeywell International Inc.	IP Details for 24.5.67.101IP: 24.5.67.101Country: United StatesISP: Comcast Cable Communications LLCPlease let us know if you want us to block the IP in NACL level. Let us know if you have any queries regarding this.","Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.123 which belongs to the Secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001C4SpF,Cloud Engineer Level 1,Closed,1055913,Incident,24-05-2017 22:05,,"Hello Andrew,We have shut down the Test_Windows_Instance (i-0645988fa5d92b721). Let us know if you have any queries.","Please shut down Test_Windows_Instance (i-0645988fa5d92b721) We do not need this server running at this time. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Group www.spendhq.com | www.insightsourcing.com -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Please shut down Test Windows Instance,,24-05-2017 22:01,0,0,SpendHQ,"Hello Andrew,We have shut down the Test_Windows_Instance (i-0645988fa5d92b721). Let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Cdko2,Cloud Engineer Level 1,Closed,1058275,Incident,01-06-2017 22:32,,"Hello SpendHQ Team,Since the issue is resolved and we are waiting for the reply from Andromeda team, we are closing this case and we will follow up in case id: 01058351###Mail Send to Andromeda====================Hello Andromeda-Team,We had a major outage for SpendHQ which started at 06:40 AM EST and lasted for around 7 hours. During this outage, we received site down alerts for both the URL's https://secure.spendhq.com/login and https://preview.spendhq.com/login. There was a maintenance scheduled by Amazon Web Services on DirectConnect between 04:00 AM EST - 08:00 AM EST on  31st May 2017. We have experienced this outage during the scheduled maintenance period which was not expected as we have a failover connection. During our initial analysis, we came to figure out that the ISCSI devices become inaccessible. Later the issue got resolved automatically and Chris(from Andromeda) informed that this might be due to shifting of connection from 1 Gbps to 10Gbps. REAN Team went ahead, restarted the machines after getting approval from SpendHQ which helped to resolve Read Only mode issue. Later remounted the ISCSI devices and they came back into Read Write mode.Here we need some clarifications regarding the following queries,1, During the shifting of connection, is there any kind of outage expected to happen?2, How did the shifting of connection happen? Automatic or Manually.   If the shifting happened manually, why did the Automatic switch over didn't happened in this case?3, What action can be taken to mitigate these kinds of failover issues in future?Please Advice.###Hello Team,We have successfully binded the /var/www/vhosts/files.spendhq.com/newer_w2/tmp to /var/www/vhosts/secure.spendhq.com/public/app/tmp and have verified that they both have the same data.It turns out that since the NFS shared directory didn't get mounted after the restart, the directory bind also failed.So we had to manually bind the directory again once the NFS shared directory was available.Please verify it from your end and let us know if you have any queries.###Andrew Kim9:54 PM (18 minutes ago)￼￼￼to Rean, spendhq-support￼It appears that one of the mounts is not connected. [akim@ip-10-59-100-94 tmp]$ cat /etc/fstab ## /etc/fstab# Created by anaconda on Wed Oct  7 12:03:19 2015## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=3ef558b6-efb6-42c6-a2c4-246c28e3f389 /                       ext4    defaults        1 1tmpfs                   /dev/shm                tmpfs   defaults        0 0devpts                  /dev/pts                devpts  gid=5,mode=620  0 0sysfs                   /sys                    sysfs   defaults        0 0proc                    /proc                   proc    defaults        0 0 10.59.100.125:/exports /imports/ nfs  sec=sys,noatime  0  010.59.100.125:/exports/files.spendhq.com /var/www/vhosts/files.spendhq.com nfs  sec=sys,noatime  0  0 [akim@ip-10-59-100-94 tmp]$ ls /var/www/vhosts/secure.spendhq.com/public/app/tmplogs[akim@ip-10-59-100-94 tmp]$ ls /var/www/vhosts/files.spendhq.com/newer_w2/tmpandrew20170311  cache  logs  sessions  tmp_old The bottom 2 outputs should match.###Hello Team,As discussed over the call, We have remounted the NFS share volumes on the PROD-SPHQ-WEB-SERVER03 and it was working fine.But still, the site hasn't come up.On further analysis, we found that the issue now is related to the application.Please find the application error logs below: tail -10 /var/www/vhosts/files.spendhq.com/w2/logs/web2-94-http-preview.spendhq.com-error.log[Wed May 31 15:54:11 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:54:25 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:55:57 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:56:17 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:56:21 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:56:22 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:56:23 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 16:00:51 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 16:01:03 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 16:13:13 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575Please let us know if you have any more queries regarding this issue.###Hello Team,We have got the site down again for url: https://preview.spendhq.com/login. We have reached out to Chris and he updated that he had not made any changes from his end. The filesystem mounted on the TEST-SPHQ-WEB-SERVER01 server went to read only mode and in order to resolve this issue, we need to restart the instance as the ISCSI device is mounted on this instance. Please let us know if we can have the approval to restart the instance.###Hello SpendHQ Team,This is to inform you that the site down alert for the url https://preview.spendhq.com/login has recovered and the site is accessible now. Currently we are in call with Andromeda Team. We will let you know the updates shortly.###Hello Team,This is to notify you that we have received a site down alert for preview.spendhq.com.On analysis we could see that the ISCSI device mounted on the DB servers are not accessible.We are analysing more on this issue and have already informed the Andromeda team too.","Wed, 31 May 2017 06:26:18 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30002 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Sydney-C AU, Dallas-B US, California US, Atlanta-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,31-05-2017 15:56,31,0,SpendHQ,"Hello SpendHQ Team,Since the issue is resolved and we are waiting for the reply from Andromeda team, we are closing this case and we will follow up in case id: 01058351","Mail Send to Andromeda====================Hello Andromeda-Team,We had a major outage for SpendHQ which started at 06:40 AM EST and lasted for around 7 hours. During this outage, we received site down alerts for both the URL's https://secure.spendhq.com/login and https://preview.spendhq.com/login. There was a maintenance scheduled by Amazon Web Services on DirectConnect between 04:00 AM EST - 08:00 AM EST on  31st May 2017. We have experienced this outage during the scheduled maintenance period which was not expected as we have a failover connection. During our initial analysis, we came to figure out that the ISCSI devices become inaccessible. Later the issue got resolved automatically and Chris(from Andromeda) informed that this might be due to shifting of connection from 1 Gbps to 10Gbps. REAN Team went ahead, restarted the machines after getting approval from SpendHQ which helped to resolve Read Only mode issue. Later remounted the ISCSI devices and they came back into Read Write mode.Here we need some clarifications regarding the following queries,1, During the shifting of connection, is there any kind of outage expected to happen?2, How did the shifting of connection happen? Automatic or Manually.   If the shifting happened manually, why did the Automatic switch over didn't happened in this case?3, What action can be taken to mitigate these kinds of failover issues in future?Please Advice.","Hello Team,We have successfully binded the /var/www/vhosts/files.spendhq.com/newer_w2/tmp to /var/www/vhosts/secure.spendhq.com/public/app/tmp and have verified that they both have the same data.It turns out that since the NFS shared directory didn't get mounted after the restart, the directory bind also failed.So we had to manually bind the directory again once the NFS shared directory was available.Please verify it from your end and let us know if you have any queries.","Andrew Kim9:54 PM (18 minutes ago)￼￼￼to Rean, spendhq-support￼It appears that one of the mounts is not connected. [akim@ip-10-59-100-94 tmp]$ cat /etc/fstab ## /etc/fstab# Created by anaconda on Wed Oct  7 12:03:19 2015## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#UUID=3ef558b6-efb6-42c6-a2c4-246c28e3f389 /                       ext4    defaults        1 1tmpfs                   /dev/shm                tmpfs   defaults        0 0devpts                  /dev/pts                devpts  gid=5,mode=620  0 0sysfs                   /sys                    sysfs   defaults        0 0proc                    /proc                   proc    defaults        0 0 10.59.100.125:/exports /imports/ nfs  sec=sys,noatime  0  010.59.100.125:/exports/files.spendhq.com /var/www/vhosts/files.spendhq.com nfs  sec=sys,noatime  0  0 [akim@ip-10-59-100-94 tmp]$ ls /var/www/vhosts/secure.spendhq.com/public/app/tmplogs[akim@ip-10-59-100-94 tmp]$ ls /var/www/vhosts/files.spendhq.com/newer_w2/tmpandrew20170311  cache  logs  sessions  tmp_old The bottom 2 outputs should match.","Hello Team,As discussed over the call, We have remounted the NFS share volumes on the PROD-SPHQ-WEB-SERVER03 and it was working fine.But still, the site hasn't come up.On further analysis, we found that the issue now is related to the application.Please find the application error logs below: tail -10 /var/www/vhosts/files.spendhq.com/w2/logs/web2-94-http-preview.spendhq.com-error.log[Wed May 31 15:54:11 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:54:25 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:55:57 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:56:17 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:56:21 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:56:22 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 15:56:23 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 16:00:51 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 16:01:03 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575[Wed May 31 16:13:13 2017] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4575Please let us know if you have any more queries regarding this issue.","Hello Team,We have got the site down again for url: https://preview.spendhq.com/login. We have reached out to Chris and he updated that he had not made any changes from his end. The filesystem mounted on the TEST-SPHQ-WEB-SERVER01 server went to read only mode and in order to resolve this issue, we need to restart the instance as the ISCSI device is mounted on this instance. Please let us know if we can have the approval to restart the instance.","Hello SpendHQ Team,This is to inform you that the site down alert for the url https://preview.spendhq.com/login has recovered and the site is accessible now. Currently we are in call with Andromeda Team. We will let you know the updates shortly.","Hello Team,This is to notify you that we have received a site down alert for preview.spendhq.com.On analysis we could see that the ISCSI device mounted on the DB servers are not accessible.We are analysing more on this issue and have already informed the Andromeda team too.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EqyHh,Cloud Engineer Level 1,Closed,1068561,Incident,18-07-2017 18:06,,"Hello Team,This alert was triggered due to the scheduled start and stop the activity of the instance sphq-web-server03_logi_old - 10.59.100.153.###Hello SpendHQ Team, This is to notify you that we have received a Httpd Process Down alert for TEST-SPHQ-WEB-SERVER03 instance. Later the alert got resolved automatically within a minute. We are investigating the alert and meanwhile let us know if your team is performing any activity from your end.Resources Details: Attached Instances: TEST-SPHQ-WEB-SERVER03_Logi_OldAttached Instances Status: In-Service VPC ID : vpc-76df7212Availability Zone: us-east-1b","[Triggered on {host:10.59.100.153,process:httpd}] [SpendHQ] Httpd Process is down - test-sphq-web-server03_logi_old  - 10.59.100.153 - web  Httpd Process is down     @support@reancloud.comPROCS CRITICAL: 0 processes found for httpdThis alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2014428?group=host%3A10.59.100.153%2Cprocess%3Ahttpd · Edit Monitor: https://app.datadoghq.com/monitors#2014428/edit · Event URL: https://app.datadoghq.com/event/event?id=3961346943292521386 · View 10.59.100.153: https://app.datadoghq.com/infrastructure?hostname=10.59.100.153-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","[Monitor Alert] Triggered: [SpendHQ] Httpd Process is down - test-sphq-web-server03_logi_old - 10.59.100.153 - web on process:httpd,host:10.59.100.153",,18-07-2017 17:02,1,0,SpendHQ,"Hello Team,This alert was triggered due to the scheduled start and stop the activity of the instance sphq-web-server03_logi_old - 10.59.100.153.","Hello SpendHQ Team, This is to notify you that we have received a Httpd Process Down alert for TEST-SPHQ-WEB-SERVER03 instance. Later the alert got resolved automatically within a minute. We are investigating the alert and meanwhile let us know if your team is performing any activity from your end.Resources Details: Attached Instances: TEST-SPHQ-WEB-SERVER03_Logi_OldAttached Instances Status: In-Service VPC ID : vpc-76df7212Availability Zone: us-east-1b",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001GHGOf,Cloud Engineer Level 1,Closed,1073877,Incident,20-08-2017 04:14,,"Hello Matthew,As discussed on the call, we were able to successfully mount iqn.2007-11.com.nimblestorage:prd-db-170819-v777bb21358661922.00000028.2f1dab31 to /mnt/production_19082017.Also as per your request pointed secure ELB to preview internal ELB.Please revert back to us if you have any queries.###Hello Matthew/Chris,Here are the iSCSI volume IQN details of the volume mounted on /mnt/production_10-06-2017 in 10-59-10-135 server.IQN: ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-06-10-17-v777bb21358661922.00000022.2f1dab31-lun-0Let us know if you need any more details on this case.###Matthew WattsChris, do we have everything we need to clone the PRD DB as soon as we are ready? Do we know the volume name###Yes - it is Spend4-06-10-17 Matt...REAN can you verify that this is indeed the mounted production DB volume?The newly created volume (clone) will be called PRD-DB-170819 per the new standard naming convention that Andrew requested- thus REAN can look for this volume to mount once created.Chris###Rean and Chris, Can we please confirm that this schedule works and that we will have everything we will need to commence at 1800 exactly.###Hello Matthew,REAN Team will be available for the release at 1800 hour EST.Regards,Alsa T Alias###Next action : need to check with yogesh###Hello Matthew,We will further discuss and let you know.","Team,We will be planning a release on Saturday 19th July 2017 as you have all been made aware of. I have provided an initial game plan for this release below. Should any of you see any direct issues with this game plan, then please do not hesitate to let me know.1800 EST: Enable Maintenance Mode1805 EST: Shutdown Services1810 EST: Clone Data Directory on 10.59.10.135. Please ensure we know what volume to clone before we start to minimize downtime.1815 EST: Mount Cloned Data Directory to 10.59.10.190 under /mnt/production_19082017.1820 EST: Start Database Services1830 EST: Disable Maintenance Mode.I will solely be responsible for the verification process, so any issues that arise should come directly to me.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Release Schedule,,19-08-2017 04:47,27,0,SpendHQ,"Hello Matthew,As discussed on the call, we were able to successfully mount iqn.2007-11.com.nimblestorage:prd-db-170819-v777bb21358661922.00000028.2f1dab31 to /mnt/production_19082017.Also as per your request pointed secure ELB to preview internal ELB.Please revert back to us if you have any queries.","Hello Matthew/Chris,Here are the iSCSI volume IQN details of the volume mounted on /mnt/production_10-06-2017 in 10-59-10-135 server.IQN: ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-06-10-17-v777bb21358661922.00000022.2f1dab31-lun-0Let us know if you need any more details on this case.","Matthew WattsChris, do we have everything we need to clone the PRD DB as soon as we are ready? Do we know the volume name",Yes - it is Spend4-06-10-17 Matt...REAN can you verify that this is indeed the mounted production DB volume?The newly created volume (clone) will be called PRD-DB-170819 per the new standard naming convention that Andrew requested- thus REAN can look for this volume to mount once created.Chris,"Rean and Chris, Can we please confirm that this schedule works and that we will have everything we will need to commence at 1800 exactly.","Hello Matthew,REAN Team will be available for the release at 1800 hour EST.Regards,Alsa T Alias",Next action : need to check with yogesh,"Hello Matthew,We will further discuss and let you know.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001ivZUx,Cloud Engineer Level 3,Closed,1111450,Incident,04-02-2019 03:24,,"Hello Mattew,Thanks for the quick response. We are marking this case as closed.###Matthew Watts <mwatts@spendhq.com>***************************************************Yes we can close###Hello Matthew,This is a quick follow up. Please confirm whether we are good to close this case. And kindly let us know if you have any queries.###Hello Matthew,Thanks for the update.Please let us know if we are good to close this case or not.###Hello Matt, This issue is not related to the AWS networking and OS Level config issue. This is a known issue in MariaDB. On top of that, we have seen a sudden high Memory Usage on the cluster.###Matthew Watts <mwatts@spendhq.com>Today, 3:23 AMUnderstood. Thank you for the verification. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting###Hello Matthew,We are looking into this issue and will get back you with an update.###Matthew Watts <mwatts@spendhq.com>Today, 3:01 AMRean Support <support@reancloud.com>;spendhq-support@reancloud.comWe are still having issues. See below. This is affecting operations so please treat as a SEV ONE.###When I have checked the error, i could find these issues happen might be when queries are running for long or limit in the MaxOpenFiles. Need to check with Rohit for further details and respond back to the customer with the exact root cause.###Hello Matthew,We will find the reason and will get back to you with further details.###[Matthew Watts updated via email ]Yes, exactly. So can you see any reason why connections are being refused?###Praveen asked one question to Rohit on ops call that, whether this cluster monitored by DD. Please sync up with Rohit and respond to Praveen###Hello Team,We have further checked the details and verified the metrics and could see Network utilization was normal during the time of issue. We couldn't see any networking issue at AWS level. On further checking at the instance level, from the messages logs, we could see below error. We went ahead and checked more about the error and it seems like that it might be an issue with cluster setup. Please validate the details from your end and let us know if you have further queries.Jan 31 17:17:49 ip-10-59-10-210 joblist[87862]: 49.409112 |0|0|0| W 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/joblist/distributedenginecomm.cpp @ 264 Could not connect to PMS3: Connection refused Jan 31 17:17:05 ip-10-59-10-210 joblist[86788]: 05.209840 |0|0|0| C 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/execplan/clientrotator.cpp @ 350 Could not get a ExeMgr connection. Jan 31 17:17:05 ip-10-59-10-210 joblist[86788]: 05.218236 |0|0|0| C 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/execplan/clientrotator.cpp @ 350 Could not get a ExeMgr connection.###Hi Praveen,Customer faced this networking issue before also. They report the networking issue between the cluster.I verified the metrics during the time of customer raised the issue. When they reported us the issue during that hours the network utilization had normal spikes. I do not see this any networking issue at AWS level. It might be an issue with mariadb itself. They need to check at their end. What we can see in the messages logs:Jan 31 17:17:49 ip-10-59-10-210 joblist[87862]: 49.409112 |0|0|0| W 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/joblist/distributedenginecomm.cpp @ 264 Could not connect to PMS3: Connection refusedJan 31 17:17:05 ip-10-59-10-210 joblist[86788]: 05.209840 |0|0|0| C 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/execplan/clientrotator.cpp @ 350 Could not get a ExeMgr connection.Jan 31 17:17:05 ip-10-59-10-210 joblist[86788]: 05.218236 |0|0|0| C 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/execplan/clientrotator.cpp @ 350 Could not get a ExeMgr connection.When I checked on this error, it might be an issue with cluster setup.They usually restart the mariadb when they face this issue.Please guide me if I am wrong on this. case. Thanks !###Hello Robert,From our initial analysis, we could see that there high Spikes in Network IN/OUT metrics on all instances. We have verified the connectivity between all of these instances and everything is working fine. We noticed that there is a high number for time wait connection. Please check the below details for time wait connection.=========================1: [root@ip-10-59-10-26 log]# netstat | grep TIME_WAIT | wc -l25732: [root@ip-10-59-10-210 ~]# netstat | grep TIME_WAIT | wc -l1673: [root@ip-10-59-10-45 ~]# netstat | grep TIME_WAIT | wc -l74: [centos@ip-10-59-10-235 ~]$ netstat | grep TIME_WAIT | wc -l6We will check more on this issue and will provide an update.For quick resolution, we can perform Network service restart. Please review the details and let us if you have any queries related to it.Regards,Gourav Pokhra###Hello Robbert,We will look into this and will get back to you with an update.","REAN,It looks like on our Mariadb production cluster we have had a few networking issues. They keep losing connection between each other. Can you look in to why this is happening so we can try to resolve the issue permanently?These are the db servers we are talking about.10.59.10.210    user1.mariadb.spendhq.net10.59.10.26    performance1.mariadb.spendhq.net10.59.10.45    performance2.mariadb.spendhq.net10.59.10.235    performance3.mariadb.spendhq.netHere are some logs showing the network issues.==> /var/log/mariadb/columnstore/warning.log <==Jan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.010384 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.012987 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.016010 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.048632 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.050879 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.051554 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.063022 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.063910 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.065957 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.067526 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.134056 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.135819 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.137454 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.139423 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.141372 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.159629 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.161379 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.163088 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.165001 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.166883 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.227264 |2147489829|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.229518 |2147489829|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.231442 |2147489829|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.233879 |2147489829|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.235496 |2147489829|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.238084 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.240101 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.242350 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.244231 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.245832 |2147489822|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.262493 |2147489830|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.264185 |2147489830|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.266122 |2147489830|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.268045 |2147489830|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.269641 |2147489830|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.271381 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.273186 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.274880 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.276608 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 joblist[87735]: 25.278265 |2147489824|0|0| C 05 CAL0000: DistributedEngineComm::write: Broken Pipe errorJan 31 17:08:25 ip-10-59-10-210 messagequeue[86788]: 25.619665 |0|0|0| W 31 CAL0000: Client read close socket for InetStreamSocket::readToMagic(): I/O error2.1: err = -1 e = 104: Connection reset by peerJan 31 17:08:25 ip-10-59-10-210 messagequeue[86788]: 25.619639 |0|0|0| W 31 CAL0000: Client read close socket for InetStreamSocket::readToMagic(): I/O error2.1: err = -1 e = 104: Connection reset by peerJan 31 17:08:25 ip-10-59-10-210 messagequeue[86788]: 25.619663 |0|0|0| W 31 CAL0000: Client read close socket for InetStreamSocket::readToMagic: Remote is closedThanks,RobertRobert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.com<mailto:rlittle@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sev 1: Network issues,,31-01-2019 23:12,76,0,SpendHQ,"Hello Mattew,Thanks for the quick response. We are marking this case as closed.",Matthew Watts <mwatts@spendhq.com>***************************************************Yes we can close,"Hello Matthew,This is a quick follow up. Please confirm whether we are good to close this case. And kindly let us know if you have any queries.","Hello Matthew,Thanks for the update.Please let us know if we are good to close this case or not.","Hello Matt, This issue is not related to the AWS networking and OS Level config issue. This is a known issue in MariaDB. On top of that, we have seen a sudden high Memory Usage on the cluster.","Matthew Watts <mwatts@spendhq.com>Today, 3:23 AMUnderstood. Thank you for the verification. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting","Hello Matthew,We are looking into this issue and will get back you with an update.","Matthew Watts <mwatts@spendhq.com>Today, 3:01 AMRean Support <support@reancloud.com>;spendhq-support@reancloud.comWe are still having issues. See below. This is affecting operations so please treat as a SEV ONE.","When I have checked the error, i could find these issues happen might be when queries are running for long or limit in the MaxOpenFiles. Need to check with Rohit for further details and respond back to the customer with the exact root cause.","Hello Matthew,We will find the reason and will get back to you with further details.","[Matthew Watts updated via email ]Yes, exactly. So can you see any reason why connections are being refused?","Praveen asked one question to Rohit on ops call that, whether this cluster monitored by DD. Please sync up with Rohit and respond to Praveen","Hello Team,We have further checked the details and verified the metrics and could see Network utilization was normal during the time of issue. We couldn't see any networking issue at AWS level. On further checking at the instance level, from the messages logs, we could see below error. We went ahead and checked more about the error and it seems like that it might be an issue with cluster setup. Please validate the details from your end and let us know if you have further queries.Jan 31 17:17:49 ip-10-59-10-210 joblist[87862]: 49.409112 |0|0|0| W 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/joblist/distributedenginecomm.cpp @ 264 Could not connect to PMS3: Connection refused Jan 31 17:17:05 ip-10-59-10-210 joblist[86788]: 05.209840 |0|0|0| C 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/execplan/clientrotator.cpp @ 350 Could not get a ExeMgr connection. Jan 31 17:17:05 ip-10-59-10-210 joblist[86788]: 05.218236 |0|0|0| C 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/execplan/clientrotator.cpp @ 350 Could not get a ExeMgr connection.","Hi Praveen,Customer faced this networking issue before also. They report the networking issue between the cluster.I verified the metrics during the time of customer raised the issue. When they reported us the issue during that hours the network utilization had normal spikes. I do not see this any networking issue at AWS level. It might be an issue with mariadb itself. They need to check at their end. What we can see in the messages logs:Jan 31 17:17:49 ip-10-59-10-210 joblist[87862]: 49.409112 |0|0|0| W 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/joblist/distributedenginecomm.cpp @ 264 Could not connect to PMS3: Connection refusedJan 31 17:17:05 ip-10-59-10-210 joblist[86788]: 05.209840 |0|0|0| C 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/execplan/clientrotator.cpp @ 350 Could not get a ExeMgr connection.Jan 31 17:17:05 ip-10-59-10-210 joblist[86788]: 05.218236 |0|0|0| C 05 CAL0000: /data/buildbot/bb-worker/centos7/mariadb-columnstore-engine/dbcon/execplan/clientrotator.cpp @ 350 Could not get a ExeMgr connection.When I checked on this error, it might be an issue with cluster setup.They usually restart the mariadb when they face this issue.Please guide me if I am wrong on this. case. Thanks !","Hello Robert,From our initial analysis, we could see that there high Spikes in Network IN/OUT metrics on all instances. We have verified the connectivity between all of these instances and everything is working fine. We noticed that there is a high number for time wait connection. Please check the below details for time wait connection.=========================1: [root@ip-10-59-10-26 log]# netstat | grep TIME_WAIT | wc -l25732: [root@ip-10-59-10-210 ~]# netstat | grep TIME_WAIT | wc -l1673: [root@ip-10-59-10-45 ~]# netstat | grep TIME_WAIT | wc -l74: [centos@ip-10-59-10-235 ~]$ netstat | grep TIME_WAIT | wc -l6We will check more on this issue and will provide an update.For quick resolution, we can perform Network service restart. Please review the details and let us if you have any queries related to it.Regards,Gourav Pokhra","Hello Robbert,We will look into this and will get back to you with an update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Kpei8,Cloud Engineer Level 1,Closed,1085376,Incident,29-11-2017 23:15,,"Hello Matthew,Thanks for the update.At this time, we are marking this case as resolved.###Matthew Watts10:42 PM (31 minutes ago)￼￼￼to Rean, spendhq-support￼Everything is good. Thank you. At this time the server does not require monitoring.###Hello Matthew, This is a gentle reminderWe have created a new server based on 10.59.10.135 server. Please find the instance details below. Instance ID: i-01883de5eb856abe7 Instance Name: Clone of PRD-DB_v20171127 Instance Type: r3.8xlarge Private IP: 10.59.10.215 Availability zone: us-east-1b Key pair name: Instance Kindly check from your end and let us know if you want us to enable monitoring. Revert back to us if you have any queries.###Hello Matthew, We haven't heard back from you.We have created a new server based on 10.59.10.135 server. Please find the instance details below. Instance ID: i-01883de5eb856abe7 Instance Name: Clone of PRD-DB_v20171127 Instance Type: r3.8xlarge Private IP: 10.59.10.215 Availability zone: us-east-1b Key pair name: Instance Kindly check from your end and let us know if you want us to enable monitoring.###Hello Matthew,We have created a new server based on 10.59.10.135 server. Please find the instance details below.Instance ID: i-01883de5eb856abe7Instance Name: Clone of PRD-DB_v20171127Instance Type: r3.8xlargePrivate IP: 10.59.10.215Availability zone: us-east-1bKey pair name: InstanceKindly check from your end and let us know if you want us to enable monitoring.###Hello Matthew,We will work on this request and will get back to you with details.","REAN,Could we please create a brand new server, based off the 10.59.10.135 server. I need 500GB of space available in the root partition.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Server Creation,,28-11-2017 03:46,43,0,SpendHQ,"Hello Matthew,Thanks for the update.At this time, we are marking this case as resolved.","Matthew Watts10:42 PM (31 minutes ago)￼￼￼to Rean, spendhq-support￼Everything is good. Thank you. At this time the server does not require monitoring.","Hello Matthew, This is a gentle reminderWe have created a new server based on 10.59.10.135 server. Please find the instance details below. Instance ID: i-01883de5eb856abe7 Instance Name: Clone of PRD-DB_v20171127 Instance Type: r3.8xlarge Private IP: 10.59.10.215 Availability zone: us-east-1b Key pair name: Instance Kindly check from your end and let us know if you want us to enable monitoring. Revert back to us if you have any queries.","Hello Matthew, We haven't heard back from you.We have created a new server based on 10.59.10.135 server. Please find the instance details below. Instance ID: i-01883de5eb856abe7 Instance Name: Clone of PRD-DB_v20171127 Instance Type: r3.8xlarge Private IP: 10.59.10.215 Availability zone: us-east-1b Key pair name: Instance Kindly check from your end and let us know if you want us to enable monitoring.","Hello Matthew,We have created a new server based on 10.59.10.135 server. Please find the instance details below.Instance ID: i-01883de5eb856abe7Instance Name: Clone of PRD-DB_v20171127Instance Type: r3.8xlargePrivate IP: 10.59.10.215Availability zone: us-east-1bKey pair name: InstanceKindly check from your end and let us know if you want us to enable monitoring.","Hello Matthew,We will work on this request and will get back to you with details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TB1nO,Cloud Engineer Level 1,Closed,1094009,Incident,30-03-2018 03:40,,"Hello Matthew, We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello Matthew,We haven't heard back from you regarding the case for a while. For continued support regarding the same issue, you can contact us anytime.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.###Hi Matthew,This is a gentle reminder.Please review our previous comments and let us know if you have any issue regarding this case.###Hello Matthew, We haven't heard back from regarding your login issue. We have cross verified the 10.59.10.180 and 10.59.10.82 with the users and their home folder permissions and the authorized keys in 10.59.10.135 and made them identical. Please try to log in again and let us know if you are facing any issues.###Hello Matthew,We haven't heard back from regarding your login issue.We have cross verified the 10.59.10.180 and 10.59.10.82 with the users and their home folder permissions and the authorized keys in 10.59.10.135 and made them identical. Please try to log in again and let us know if you are facing any issues.###Hello Matthew,I have cross verified the 10.59.10.180 and 10.59.10.82 with the users and their home folder permissions and the authorized keys in 10.59.10.135 and made them identical. Please try to log in again and let us know if you are facing any issues.If required, we can get on a call to troubleshoot the issue quickly.Thank You,Safuvan KM###Hello Matthew,We will check on this and will let you know the details.###Matthew Watts9:48 PM (6 minutes ago)to Yogesh, Parvesh, Spendhq The password is ok, but my public key appears not to be on the server.###Hello Matthew,I am able to log in fine. Do you want me to reset your password again?Regards,Yogesh Maloo###Hello Matthew,We acknowledge the delivery of your request. We will check on this and will let you know the updates.","I cannot SSH into this machine - 10.59.10.82. Can you please resolve thisFrom: Parvesh Pothuraju <parvesh.pothuraju@reancloud.com>Date: Tuesday, March 20, 2018 at 4:33 PMTo: Matthew Watts <mwatts@spendhq.com>Subject: Re: Server Password10.59.10.82-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Server Password,,22-03-2018 19:57,176,0,SpendHQ,"Hello Matthew, We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello Matthew,We haven't heard back from you regarding the case for a while. For continued support regarding the same issue, you can contact us anytime.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.","Hi Matthew,This is a gentle reminder.Please review our previous comments and let us know if you have any issue regarding this case.","Hello Matthew, We haven't heard back from regarding your login issue. We have cross verified the 10.59.10.180 and 10.59.10.82 with the users and their home folder permissions and the authorized keys in 10.59.10.135 and made them identical. Please try to log in again and let us know if you are facing any issues.","Hello Matthew,We haven't heard back from regarding your login issue.We have cross verified the 10.59.10.180 and 10.59.10.82 with the users and their home folder permissions and the authorized keys in 10.59.10.135 and made them identical. Please try to log in again and let us know if you are facing any issues.","Hello Matthew,I have cross verified the 10.59.10.180 and 10.59.10.82 with the users and their home folder permissions and the authorized keys in 10.59.10.135 and made them identical. Please try to log in again and let us know if you are facing any issues.If required, we can get on a call to troubleshoot the issue quickly.Thank You,Safuvan KM","Hello Matthew,We will check on this and will let you know the details.","Matthew Watts9:48 PM (6 minutes ago)to Yogesh, Parvesh, Spendhq The password is ok, but my public key appears not to be on the server.","Hello Matthew,I am able to log in fine. Do you want me to reset your password again?Regards,Yogesh Maloo","Hello Matthew,We acknowledge the delivery of your request. We will check on this and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d4EGK,Cloud Engineer Level 1,Closed,1106408,Incident,19-10-2018 23:10,,"Hello Team,We haven't heard back from you regarding this case.At this time we are marking this case as closed and let us know if you have any queries.###Hello Team,This is the quick follow up.Please review the detailed mentioned in the previous comment and let us know if you have any queries related to it.###Hello Team, when we tried to access the site, we found the fatal error. please find the screenshot in the attachment section.We have further checked the details, the Secure-SpendHQ-ELB is pointed to the Sophos Instance and from there, it is pointed to PRD-WW2_6(10.59.101.6) WebServer instance which is attached to the NewPeview-ELB. And the backend DB server is PRD-DB1(10.59.10.190). We have analyzed the WebServer Instance metrics and ELB metrics where it usage looks fine and from WebServer Instance level, we have analyzed the system messages, httpd logs. We could see that the httpd process was killed due to out of memory at the time of the site down. We have shared the memory usage details in the ticket ID: 01106395.Please find the error logs from the WebServer belowOct 17 21:28:45 ip-10-59-101-6 kernel: [14740]    48 14740   103293    10330   0       0             0 httpdOct 17 21:28:45 ip-10-59-101-6 kernel: [14741]    48 14741   534365   441308   0       0             0 httpdOct 17 21:28:45 ip-10-59-101-6 kernel: Out of memory: Kill process 14306 (httpd) score 93 or sacrifice childOct 17 21:28:45 ip-10-59-101-6 kernel: Killed process 14306, UID 48, (httpd) total-vm:3452732kB, anon-rss:3078724kB, file-rss:936kBOct 17 21:29:43 ip-10-59-101-6 clamd[1919]: SelfCheck: Database status OK.Oct 17 21:39:43 ip-10-59-101-6 clamd[1919]: SelfCheck: Database status OK.Oct 17 21:47:18 ip-10-59-101-6 dhclient[1066]: DHCPREQUEST on eth0 to 10.59.101.1 port 67 (xid=0x26f97567)Oct 17 21:47:18 ip-10-59-101-6 dhclient[1066]: DHCPACK from 10.59.101.1 (xid=0x26f97567)Oct 17 21:47:20 ip-10-59-101-6 dhclient[1066]: bound to 10.59.101.6 -- renewal in 1443 seconds.Oct 17 21:49:43 ip-10-59-101-6 clamd[1919]: SelfCheck: Database status OK.Oct 17 21:59:44 ip-10-59-101-6 clamd[1919]: SelfCheck: Database status OK.We couldn't find any suspicious activity from both AWS and instance level for the backend DB server.Kindly review this details and revert back to us in case of any queries.###Hello Team,This is to notify you that we have received an alert regarding Detected Error on SpendHQ Preview URL: https://preview.spendhq.com/login. We could see that the wanted string: SpendHQ was not found in response and the reason for the error.As of the moment, the alert has recovered and the violation lasted for about 6 minutes 59 seconds.We are checking more on this and will let you know the update.","Wed, 17 Oct 2018 17:50:05 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): Frankfurt DE, Dallas-B US, London UK, New Jersey US-- Regards,Kevin M. KariukiJr. Cloud Engineer",Detected Error on SpendHQ Preview,,18-10-2018 03:28,44,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.At this time we are marking this case as closed and let us know if you have any queries.","Hello Team,This is the quick follow up.Please review the detailed mentioned in the previous comment and let us know if you have any queries related to it.","Hello Team, when we tried to access the site, we found the fatal error. please find the screenshot in the attachment section.We have further checked the details, the Secure-SpendHQ-ELB is pointed to the Sophos Instance and from there, it is pointed to PRD-WW2_6(10.59.101.6) WebServer instance which is attached to the NewPeview-ELB. And the backend DB server is PRD-DB1(10.59.10.190). We have analyzed the WebServer Instance metrics and ELB metrics where it usage looks fine and from WebServer Instance level, we have analyzed the system messages, httpd logs. We could see that the httpd process was killed due to out of memory at the time of the site down. We have shared the memory usage details in the ticket ID: 01106395.Please find the error logs from the WebServer belowOct 17 21:28:45 ip-10-59-101-6 kernel: [14740]    48 14740   103293    10330   0       0             0 httpdOct 17 21:28:45 ip-10-59-101-6 kernel: [14741]    48 14741   534365   441308   0       0             0 httpdOct 17 21:28:45 ip-10-59-101-6 kernel: Out of memory: Kill process 14306 (httpd) score 93 or sacrifice childOct 17 21:28:45 ip-10-59-101-6 kernel: Killed process 14306, UID 48, (httpd) total-vm:3452732kB, anon-rss:3078724kB, file-rss:936kBOct 17 21:29:43 ip-10-59-101-6 clamd[1919]: SelfCheck: Database status OK.Oct 17 21:39:43 ip-10-59-101-6 clamd[1919]: SelfCheck: Database status OK.Oct 17 21:47:18 ip-10-59-101-6 dhclient[1066]: DHCPREQUEST on eth0 to 10.59.101.1 port 67 (xid=0x26f97567)Oct 17 21:47:18 ip-10-59-101-6 dhclient[1066]: DHCPACK from 10.59.101.1 (xid=0x26f97567)Oct 17 21:47:20 ip-10-59-101-6 dhclient[1066]: bound to 10.59.101.6 -- renewal in 1443 seconds.Oct 17 21:49:43 ip-10-59-101-6 clamd[1919]: SelfCheck: Database status OK.Oct 17 21:59:44 ip-10-59-101-6 clamd[1919]: SelfCheck: Database status OK.We couldn't find any suspicious activity from both AWS and instance level for the backend DB server.Kindly review this details and revert back to us in case of any queries.","Hello Team,This is to notify you that we have received an alert regarding Detected Error on SpendHQ Preview URL: https://preview.spendhq.com/login. We could see that the wanted string: SpendHQ was not found in response and the reason for the error.As of the moment, the alert has recovered and the violation lasted for about 6 minutes 59 seconds.We are checking more on this and will let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001CdpWL,Cloud Engineer Level 1,Closed,1058351,Incident,07-06-2017 15:15,,"Hello Team,We haven't heard back from Andromeda team regarding this issue. At this time, we're marking this case as Resolved. We will reopen this ticket once we hear back from Andromeda Team regarding the details and let you know the updates.###Chris updated thatthanks for the reminder i will get on it###Hello Chris,This a gentle reminder since we haven't heard back fro you regarding this case.Please let us know if we have any updates on this issue.###Hello Chris,This is a quick follow-up.Please let us know the updates on this case.###Hello Chris,Please let us know the updates on this case?###I will be working the forensics today.Chris Veillette###Mail Send to Andromeda====================Hello Andromeda-Team,We had a major outage for SpendHQ which started at 06:40 AM EST and lasted for around 7 hours. During this outage, we received site down alerts for both the URL's https://secure.spendhq.com/login and https://preview.spendhq.com/login. There was a maintenance scheduled by Amazon Web Services on DirectConnect between 04:00 AM EST - 08:00 AM EST on  31st May 2017. We have experienced this outage during the scheduled maintenance period which was not expected as we have a failover connection. During our initial analysis, we came to figure out that the ISCSI devices become inaccessible. Later the issue got resolved automatically and Chris(from Andromeda) informed that this might be due to shifting of connection from 1 Gbps to 10Gbps. REAN Team went ahead, restarted the machines after getting approval from SpendHQ which helped to resolve Read Only mode issue. Later remounted the ISCSI devices and they came back into Read Write mode.Here we need some clarifications regarding the following queries,1, During the shifting of connection, is there any kind of outage expected to happen?2, How did the shifting of connection happen? Automatic or Manually.   If the shifting happened manually, why did the Automatic switch over didn't happened in this case?3, What action can be taken to mitigate these kinds of failover issues in future?Please Advice.###The issue started during the direct connect maintenance.The ISCSI devices were unreachable.we updated same to Andromeda and spendhq.Later the issue got resolved automatically and Chris updated that this might be due to shifting of connection from 1 Gbps to 10Gbps.After that when we checked the NFS shared directory, We found that it went into read-only mode.Hence we checked the TEST-SPHQ-WEB-SERVER01 where the ISCSI devices are mounted and found that they went into read-only mode.We then take approval from Andrew and restarted the server and after that remounted the ISCSI devices and they came back into rw mode.But the NFS share was not available on PROD-SPHQ-WEB-SERVER03 and hence we restarted that also but the issue didn't get fixed.Later Andrew updated that they are facing the issue on the web server 2 and DB server 2 and since they are production we started working on it.Since the Device mounted on test node is also shared by the prod server we were facing the same issue for NFS share not available.Later after troubleshooting we fixed it since the path of the shared folder was changed by spendhq team recently.We did the same for test website server also.But the preview website was still failing .Later Andrew updated that this is due to the directory binding which was not completed.SO we went ahead and did that and it fixed the issue.Please see the below mentioned thread also:AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED###Hello SpendHQ Team,This is to inform you that we got a site down alert for the url https://secure.spendhq.com/login. The site is up now. As discussed over call, we will discuss this with Andromeda team and prepare the RCA and will share it with you.","Wed, 31 May 2017 11:06:16 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Atlanta-B US, California US, London UK, Sydney-C AU-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,31-05-2017 20:36,163,0,SpendHQ,"Hello Team,We haven't heard back from Andromeda team regarding this issue. At this time, we're marking this case as Resolved. We will reopen this ticket once we hear back from Andromeda Team regarding the details and let you know the updates.",Chris updated thatthanks for the reminder i will get on it,"Hello Chris,This a gentle reminder since we haven't heard back fro you regarding this case.Please let us know if we have any updates on this issue.","Hello Chris,This is a quick follow-up.Please let us know the updates on this case.","Hello Chris,Please let us know the updates on this case?",I will be working the forensics today.Chris Veillette,"Mail Send to Andromeda====================Hello Andromeda-Team,We had a major outage for SpendHQ which started at 06:40 AM EST and lasted for around 7 hours. During this outage, we received site down alerts for both the URL's https://secure.spendhq.com/login and https://preview.spendhq.com/login. There was a maintenance scheduled by Amazon Web Services on DirectConnect between 04:00 AM EST - 08:00 AM EST on  31st May 2017. We have experienced this outage during the scheduled maintenance period which was not expected as we have a failover connection. During our initial analysis, we came to figure out that the ISCSI devices become inaccessible. Later the issue got resolved automatically and Chris(from Andromeda) informed that this might be due to shifting of connection from 1 Gbps to 10Gbps. REAN Team went ahead, restarted the machines after getting approval from SpendHQ which helped to resolve Read Only mode issue. Later remounted the ISCSI devices and they came back into Read Write mode.Here we need some clarifications regarding the following queries,1, During the shifting of connection, is there any kind of outage expected to happen?2, How did the shifting of connection happen? Automatic or Manually.   If the shifting happened manually, why did the Automatic switch over didn't happened in this case?3, What action can be taken to mitigate these kinds of failover issues in future?Please Advice.","The issue started during the direct connect maintenance.The ISCSI devices were unreachable.we updated same to Andromeda and spendhq.Later the issue got resolved automatically and Chris updated that this might be due to shifting of connection from 1 Gbps to 10Gbps.After that when we checked the NFS shared directory, We found that it went into read-only mode.Hence we checked the TEST-SPHQ-WEB-SERVER01 where the ISCSI devices are mounted and found that they went into read-only mode.We then take approval from Andrew and restarted the server and after that remounted the ISCSI devices and they came back into rw mode.But the NFS share was not available on PROD-SPHQ-WEB-SERVER03 and hence we restarted that also but the issue didn't get fixed.Later Andrew updated that they are facing the issue on the web server 2 and DB server 2 and since they are production we started working on it.Since the Device mounted on test node is also shared by the prod server we were facing the same issue for NFS share not available.Later after troubleshooting we fixed it since the path of the shared folder was changed by spendhq team recently.We did the same for test website server also.But the preview website was still failing .Later Andrew updated that this is due to the directory binding which was not completed.SO we went ahead and did that and it fixed the issue.Please see the below mentioned thread also:AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED","Hello SpendHQ Team,This is to inform you that we got a site down alert for the url https://secure.spendhq.com/login. The site is up now. As discussed over call, we will discuss this with Andromeda team and prepare the RCA and will share it with you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DmnJG,Cloud Engineer Level 1,Closed,1064979,Incident,26-06-2017 23:27,,"Hello Team,This is to notify you that alert regarding EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 got resolved and returned to a value of 85.7%.###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of  98%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1     ext4    50G   46G  969M  98% /Files under root directory, 16G tmp 15G usr 12G var 510M home 285M lib 282M opt Files under /tmp folder, 16G     total7.8G    liger_view_acd236eb4cc612e2f94ed2cc23080059.csv1.3G    liger_view_caa16490a6f4c23258e135e31655eacd.csv415M    liger_view_ff9b85102edc1ad4a8437d79aa894e52.csv415M    liger_view_ff88986fe780e75c76da082da8661235.csv415M    liger_view_f4fbdb750931eca9221b550c3bd0d08e.csv415M    liger_view_dcc8ecb85d0a773e151eb8c6e1811fdb.csv415M    liger_view_8a382ae1fa199b034e56139114ce0b84.csv415M    liger_view_2eced08beb365d7f31517668c7fe6054.csv415M    liger_view_249a99d15df0cc5bc8f82aed92c415ca.csv415M    liger_view_107e1e34d1d0624084da210d52467401.csv415M    liger_view_0e7b64dcd53b5ca5e87be5b2f5bf3b44.csv415M    liger_view_02609425a07a3681107111a79f3bc11c.csv323M    liger_view_3db82f98557411ed1cfdf6d673e7a5c0.csv262M    liger_view_6a622ed1ed6dc734c9e7a22684cb6664.csv221M    spark-2.1.0-bin-hadoop2.7192M    spark-2.1.0-bin-hadoop2.7/jars140M    liger_view_ed691f406e09038717dbb7b6d3cebd73.csv140M    liger_view_aed8ff84bedae719a2899ca04128763e.csv140M    liger_view_95ff906dd442a13a69616fb470b50afa.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 90.887This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3929547688500009508 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,26-06-2017 18:32,5,0,SpendHQ,"Hello Team,This is to notify you that alert regarding EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 got resolved and returned to a value of 85.7%.","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of  98%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1     ext4    50G   46G  969M  98% /Files under root directory, 16G tmp 15G usr 12G var 510M home 285M lib 282M opt Files under /tmp folder, 16G     total7.8G    liger_view_acd236eb4cc612e2f94ed2cc23080059.csv1.3G    liger_view_caa16490a6f4c23258e135e31655eacd.csv415M    liger_view_ff9b85102edc1ad4a8437d79aa894e52.csv415M    liger_view_ff88986fe780e75c76da082da8661235.csv415M    liger_view_f4fbdb750931eca9221b550c3bd0d08e.csv415M    liger_view_dcc8ecb85d0a773e151eb8c6e1811fdb.csv415M    liger_view_8a382ae1fa199b034e56139114ce0b84.csv415M    liger_view_2eced08beb365d7f31517668c7fe6054.csv415M    liger_view_249a99d15df0cc5bc8f82aed92c415ca.csv415M    liger_view_107e1e34d1d0624084da210d52467401.csv415M    liger_view_0e7b64dcd53b5ca5e87be5b2f5bf3b44.csv415M    liger_view_02609425a07a3681107111a79f3bc11c.csv323M    liger_view_3db82f98557411ed1cfdf6d673e7a5c0.csv262M    liger_view_6a622ed1ed6dc734c9e7a22684cb6664.csv221M    spark-2.1.0-bin-hadoop2.7192M    spark-2.1.0-bin-hadoop2.7/jars140M    liger_view_ed691f406e09038717dbb7b6d3cebd73.csv140M    liger_view_aed8ff84bedae719a2899ca04128763e.csv140M    liger_view_95ff906dd442a13a69616fb470b50afa.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001GGsvr,Cloud Engineer Level 1,Closed,1073741,Incident,18-08-2017 00:26,,"Hello Matthew,Thanks for your update.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Matthew Watts12:20 AM (4 minutes ago)￼￼￼to Rean, spendhq-support￼This was caused by me. Please disregard, thank you.###Hello SpendHQ-Team,This is to inform you that we have received a site down alert for the URL: http://l.spendhq.com. The issue got resolved within one minute and the site is accessible now.We are analyzing more on this issue and meanwhile let us know if you are performing any activity from your end.","Thu, 17 Aug 2017 14:42:41 -0400Detected Error on SpendHQEstimated Downtime: 59 seconds https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 200, expected 302Sensor parameters:url: http://l.spendhq.comexpect: 302wantedstring: unwantedstring: Reported by node: New Jersey USConfirmed by node(s): London UK, Atlanta-B US, Sydney-C AU, California US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,18-08-2017 00:12,0,0,SpendHQ,"Hello Matthew,Thanks for your update.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Matthew Watts12:20 AM (4 minutes ago)￼￼￼to Rean, spendhq-support￼This was caused by me. Please disregard, thank you.","Hello SpendHQ-Team,This is to inform you that we have received a site down alert for the URL: http://l.spendhq.com. The issue got resolved within one minute and the site is accessible now.We are analyzing more on this issue and meanwhile let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001ivynO,Cloud Engineer Level 1,Closed,1111525,Incident,06-02-2019 14:51,,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved/Closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,###@Team- please check with CC whether we can close this case.###Hello Team, This is to inform you that , as per your request we have cloned the four basic servers and the new server details are as follows. 1. Clone Source: 10.59.10.210 Instance Name: east-readonly-mariadb-copy-44 Instance ID: i-02cd5ec1f379e3fbc Private IP: 10.59.10.206 Instance Type: r4.8xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 2. Clone Source: 10.59.10.26 Instance Name: east-readonly-mariadb-copy-11 Instance ID: i-0e9d5a6280294c1ca Private IP: 10.59.10.176 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 3. Clone Source: 10.59.10.45 Instance Name: east-readonly-mariadb-copy-22 Instance ID: i-0989d9a9a6926b27e Private IP: 10.59.10.72 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 4. Clone Source: 10.59.10.235 Instance Name: east-readonly-mariadb-copy-33 Instance ID:i-01aeb3a0887aa1f8a Private IP: 10.59.10.131 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df72 Subnet ID: subnet-0fdde924 Monitoring: On Please verify the details and let us know if you are facing any issues.###Hello Team, This is to inform you that , as per your request we have cloned the four basic servers and the new server details are as follows. 1. Clone Source: 10.59.10.210 Instance Name: east-readonly-mariadb-copy-44 Instance ID: i-02cd5ec1f379e3fbc Private IP: 10.59.10.206 Instance Type: r4.8xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 2. Clone Source: 10.59.10.26 Instance Name: east-readonly-mariadb-copy-11 Instance ID: i-0e9d5a6280294c1ca Private IP: 10.59.10.176 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 3. Clone Source: 10.59.10.45 Instance Name: east-readonly-mariadb-copy-22 Instance ID: i-0989d9a9a6926b27e Private IP: 10.59.10.72 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 4. Clone Source: 10.59.10.235 Instance Name: east-readonly-mariadb-copy-33 Instance ID:i-01aeb3a0887aa1f8a Private IP: 10.59.10.131 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df72 Subnet ID: subnet-0fdde924 Monitoring: On Please verify the details and let us know if you are facing any issues.###Hello Allen,Sorry for the typo. 1. Clone Source: 10.59.10.210 Instance Name: east-readonly-mariadb-copy-44 Instance ID: i-02cd5ec1f379e3fbc Private IP: 10.59.10.206 Instance Type: r4.8xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 2. Clone Source: 10.59.10.26 Instance Name: east-readonly-mariadb-copy-11 Instance ID: i-0e9d5a6280294c1ca Private IP: 10.59.10.176 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 3. Clone Source: 10.59.10.45 Instance Name: east-readonly-mariadb-copy-22 Instance ID: i-0989d9a9a6926b27e Private IP: 10.59.10.145Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 4. Clone Source: 10.59.10.235 Instance Name: east-readonly-mariadb-copy-33 Instance ID:i-01aeb3a0887aa1f8a Private IP: 10.59.10.131 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df72 Subnet ID: subnet-0fdde924 Monitoring: On Please verify the details.###Question about the 4 latest servers. How can I have two servers with the same ip of 10.59.10.72 ????  I think number 3 in the last email was a bad copy paste????? Allen Herrera | Engineer | SpendHQ®###Hello Team,This is to inform you that , as per your request we have cloned the four basic servers and the new server details are as follows. 1. Clone Source: 10.59.10.210 Instance Name: east-readonly-mariadb-copy-44Instance ID: i-02cd5ec1f379e3fbc Private IP: 10.59.10.206Instance Type: r4.8xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 2. Clone Source: 10.59.10.26 Instance Name: east-readonly-mariadb-copy-11Instance ID: i-0e9d5a6280294c1caPrivate IP: 10.59.10.176 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 3. Clone Source: 10.59.10.45 Instance Name: east-readonly-mariadb-copy-22 Instance ID: i-0989d9a9a6926b27e Private IP: 10.59.10.72 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 4. Clone Source: 10.59.10.235 Instance Name: east-readonly-mariadb-copy-33Instance ID:i-01aeb3a0887aa1f8aPrivate IP: 10.59.10.131 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df72Subnet ID: subnet-0fdde924 Monitoring: On Please verify the details and let us know if you are facing any issues. Thank you.###Hello Allen,We will work on this request and will let you know the updates.Regards,Gourav Pokhra","---------- Forwarded message ---------From: Allen Herrera <aherrera@spendhq.com>Date: Wed, Jan 16, 2019 at 2:24 AMSubject: mariadb clone cluster requestTo: 'Balam Mendoza' via Spendhq Support <spendhq-support@reancloud.com>,Matthew Watts <mwatts@spendhq.com>This is a request of our production mariadb cluster ( 4 servers )*Key**Value**Instance Name **(Name of the instance to identify in the AWS Console)*east-readonly-mariadb-copy*Instance Type**(RAM and CPU)*10.59.10.21010.59.10.2610.59.10.4510.59.10.235*Clone **(Yes/No)*YES*If Yes  **(Machine Details)**Subnet in which it must be Launch **(If this instance need to have networkconnectivity with another instance)*10.59.10.x*Volume Size **(Root)*100g*Secondary Volume**(Not needed/iSCSI Volume/ENS Volume)*none*If it is Cloned iSCSI Volume, then provide the details of volume andprovide Size*No iscsi clone*Security Group Details **(Required ports need to be open for thisinstance)*Same as clone counter part*SSH User Details **(Details of the user who will need to have ssh accessto this instance)*AherreraMwattsdmackay*Need to create new SSH Keys or copy the existing key **(Provide theinstance details from which we need to copy the keys)*Copy existing*Sudo Access **(Details of the user who should have sudo access)*AherreraMwattsdmackay*Operating System*Centos 7*Onboard for REAN Monitoring*yeah*Backup*yes*Environment **(Production/Dev/Test/PoC)*Prod*Requester Email ID **(Email id of the owner of the instance)*aherrera@spendhq.com*Additional Software **(Give details of any specific software need toinstall on an instance or need to configure Public or Internal ELB, domainconfiguration etc.)**Schedule Run Time of Instance **(Does the server need to be turned on allthe time or you want us to apply any scheduled downtime to stop/start)*Up all the time*Allen Herrera* | Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",mariadb clone cluster request,,02-02-2019 00:52,110,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved/Closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,",@Team- please check with CC whether we can close this case.,"Hello Team, This is to inform you that , as per your request we have cloned the four basic servers and the new server details are as follows. 1. Clone Source: 10.59.10.210 Instance Name: east-readonly-mariadb-copy-44 Instance ID: i-02cd5ec1f379e3fbc Private IP: 10.59.10.206 Instance Type: r4.8xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 2. Clone Source: 10.59.10.26 Instance Name: east-readonly-mariadb-copy-11 Instance ID: i-0e9d5a6280294c1ca Private IP: 10.59.10.176 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 3. Clone Source: 10.59.10.45 Instance Name: east-readonly-mariadb-copy-22 Instance ID: i-0989d9a9a6926b27e Private IP: 10.59.10.72 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 4. Clone Source: 10.59.10.235 Instance Name: east-readonly-mariadb-copy-33 Instance ID:i-01aeb3a0887aa1f8a Private IP: 10.59.10.131 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df72 Subnet ID: subnet-0fdde924 Monitoring: On Please verify the details and let us know if you are facing any issues.","Hello Team, This is to inform you that , as per your request we have cloned the four basic servers and the new server details are as follows. 1. Clone Source: 10.59.10.210 Instance Name: east-readonly-mariadb-copy-44 Instance ID: i-02cd5ec1f379e3fbc Private IP: 10.59.10.206 Instance Type: r4.8xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 2. Clone Source: 10.59.10.26 Instance Name: east-readonly-mariadb-copy-11 Instance ID: i-0e9d5a6280294c1ca Private IP: 10.59.10.176 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 3. Clone Source: 10.59.10.45 Instance Name: east-readonly-mariadb-copy-22 Instance ID: i-0989d9a9a6926b27e Private IP: 10.59.10.72 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 4. Clone Source: 10.59.10.235 Instance Name: east-readonly-mariadb-copy-33 Instance ID:i-01aeb3a0887aa1f8a Private IP: 10.59.10.131 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df72 Subnet ID: subnet-0fdde924 Monitoring: On Please verify the details and let us know if you are facing any issues.","Hello Allen,Sorry for the typo. 1. Clone Source: 10.59.10.210 Instance Name: east-readonly-mariadb-copy-44 Instance ID: i-02cd5ec1f379e3fbc Private IP: 10.59.10.206 Instance Type: r4.8xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 2. Clone Source: 10.59.10.26 Instance Name: east-readonly-mariadb-copy-11 Instance ID: i-0e9d5a6280294c1ca Private IP: 10.59.10.176 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 3. Clone Source: 10.59.10.45 Instance Name: east-readonly-mariadb-copy-22 Instance ID: i-0989d9a9a6926b27e Private IP: 10.59.10.145Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 4. Clone Source: 10.59.10.235 Instance Name: east-readonly-mariadb-copy-33 Instance ID:i-01aeb3a0887aa1f8a Private IP: 10.59.10.131 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df72 Subnet ID: subnet-0fdde924 Monitoring: On Please verify the details.",Question about the 4 latest servers. How can I have two servers with the same ip of 10.59.10.72 ????  I think number 3 in the last email was a bad copy paste????? Allen Herrera | Engineer | SpendHQ®,"Hello Team,This is to inform you that , as per your request we have cloned the four basic servers and the new server details are as follows. 1. Clone Source: 10.59.10.210 Instance Name: east-readonly-mariadb-copy-44Instance ID: i-02cd5ec1f379e3fbc Private IP: 10.59.10.206Instance Type: r4.8xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 2. Clone Source: 10.59.10.26 Instance Name: east-readonly-mariadb-copy-11Instance ID: i-0e9d5a6280294c1caPrivate IP: 10.59.10.176 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 3. Clone Source: 10.59.10.45 Instance Name: east-readonly-mariadb-copy-22 Instance ID: i-0989d9a9a6926b27e Private IP: 10.59.10.72 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df7212 Subnet ID: subnet-0fdde924 Monitoring: On 4. Clone Source: 10.59.10.235 Instance Name: east-readonly-mariadb-copy-33Instance ID:i-01aeb3a0887aa1f8aPrivate IP: 10.59.10.131 Instance Type: r5.4xlarge Availability zone: us-east-1b VPC ID: vpc-76df72Subnet ID: subnet-0fdde924 Monitoring: On Please verify the details and let us know if you are facing any issues. Thank you.","Hello Allen,We will work on this request and will let you know the updates.Regards,Gourav Pokhra",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKYk,Cloud Engineer Level 1,Closed,1042226,Incident,14-01-2017 08:48,,We have a change ticket on this. 1042138,"Rean Team are you ready to commence the updates as planned on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Maintenance,,14-01-2017 07:46,1,0,SpendHQ,We have a change ticket on this. 1042138,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FeALB,Cloud Engineer Level 1,Closed,1073263,Incident,15-08-2017 00:03,,"Hello Matthew,We have reset the password and share it in a separate email. Please log in and enable MFA.","I can’t access my account. Please reset my password.From: Anjali Gopinadhan Nair <anjali.gopinadhan@reancloud.com>Date: Monday, August 7, 2017 at 10:35 AMTo: Matthew Watts <mwatts@spendhq.com>Subject: SpendHQ AWS accountHello Matthew,Please find the SpendHQ AWS account credentials below.URL: https://spendhq.signin.aws.amazon.com/consoleUsername: MWattsPassword: Will send via another email.Please enable your MFA once you logged in.Thanks & Regards,Anjali G NairHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>anjali.gopinadhan@reancloud.com<mailto:kriti@reancloud.com> | +91-7702500499 | www.reancloud.com<http://www.reancloudsolutions.com/>[mage removed by sender.][mage removed by sender.]<https://www.reancloud.com/>·         REAN Cloud partners with CloudHealth Technologies<https://www.reancloud.com/news/rean-cloud-partners-cloudhealth-technologies-help-customers-identify-cost-savings-optimize-cloud-deployments/>·         Learn about Continuous Compliance and Auto-Healing<https://www.reancloud.com/cloud-offerings/enterprise-devops-services/>·         Blog: Machine Learning to accelerate DevOps<https://www.reancloud.com/blog/perspective-machine-learning-based-devops/>·         Careers: Join REAN Cloud, our team is growing!<https://www.reancloud.com/careers/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: SpendHQ AWS account,,14-08-2017 23:14,8,0,SpendHQ,"Hello Matthew,We have reset the password and share it in a separate email. Please log in and enable MFA.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001jizJb,Cloud Engineer Level 2,Closed,1111897,Incident,11-02-2019 14:15,,"Hello Team,We have removed this server from monitoring. Going forward you will not witness any data dog alerts for this instance. As this request is completed we are marking this case as resolved and closing this case. Please let us know if you have any further queries.###@Team:Uninstall the datadog agent.Remove the gig_backup tagand Update the monitoring tag value to Off###@TeamCheck with Rohit to remove this server from monitoring###Hello Matthew, Thanks for the update.We will work on this and will let you know the updates RegardsNishad Ali###Please remove this server from monitoringGet Outlook for iOS###Hello TeamOn further analysis, from the httpd error log we could see that the httpd service has been got restarted multiple times at the time of the alert.======================[Sun Feb 10 15:44:10 2019] [notice] caught SIGTERM, shutting down[Sun Feb 10 15:45:43 2019] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Sun Feb 10 15:45:43 2019] [notice] Digest: generating secret for digest authentication ...[Sun Feb 10 15:45:43 2019] [notice] Digest: done[Sun Feb 10 15:45:43 2019] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations[Sun Feb 10 15:52:35 2019] [notice] caught SIGTERM, shutting down[Sun Feb 10 15:52:35 2019] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Sun Feb 10 15:52:35 2019] [notice] Digest: generating secret for digest authentication ...[Sun Feb 10 15:52:35 2019] [notice] Digest: done[Sun Feb 10 15:52:35 2019] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations=======================================when checked with the secure log, we could find that the user mwatts was performing some action on the instance at the time od alert and as a part of that, the httpd service is restarted and the alert has got triggered from the Datatdog./var/log/secure ========================================Feb 10 15:39:08 ip-10-59-100-122 sshd[1981]: Accepted publickey for mwatts from 10.59.1.192 port 52898 ssh2Feb 10 15:39:08 ip-10-59-100-122 sshd[1981]: pam_unix(sshd:session): session opened for user mwatts by (uid=0)Feb 10 15:39:16 ip-10-59-100-122 sudo:   mwatts : TTY=pts/0 ; PWD=/home/mwatts ; USER=root ; COMMAND=/bin/suFeb 10 15:39:16 ip-10-59-100-122 su: pam_unix(su:session): session opened for user root by mwatts(uid=0)Feb 10 15:40:19 ip-10-59-100-122 groupadd[2362]: group added to /etc/group: name=varnish, GID=494Feb 10 15:40:19 ip-10-59-100-122 groupadd[2362]: group added to /etc/gshadow: name=varnishFeb 10 15:40:19 ip-10-59-100-122 groupadd[2362]: new group: name=varnish, GID=494Feb 10 15:40:19 ip-10-59-100-122 useradd[2369]: new user: name=varnish, UID=494, GID=494, home=/var/lib/varnish, shell=/sbin/nologinFeb 10 15:44:10 ip-10-59-100-12===================================[mwatts@ip-10-59-100-137 log]$ w 16:05:57 up 2 days, 11:25,  2 users,  load average: 0.00, 0.00, 0.00USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHATmwatts   pts/0    10.59.1.192      15:39    8:14   0.06s  0.00s sshd: mwatts [priv]centos   pts/1    10.59.1.192      15:53    0.00s  0.03s  0.00s sshd: centos [priv]---------------------Currently,  httpd process is running fine.---------------------[root@ip-10-59-100-137 log]# service httpd statushttpd (pid  8017) is running...[root@ip-10-59-100-137 log]# ----------------------kindly check with the same and let us know the updates to proceed further on this.RegardsNishad Ali C###Hello TeamThis is to inform you that we have received an alert for the httpd process down on the sales_web_server - 10.59.100.137. From instance level, we could see that httpd process was running state and has got restarted.=========================[root@ip-10-59-100-137 centos]# ps -eo pid,lstart,cmd | grep httpd 4464 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4466 Sun Feb 10 15:55:03 2019 /usr/sbin/rotatelogs /var/log/httpd/access_log 86400 4467 Sun Feb 10 15:55:03 2019 /usr/sbin/rotatelogs /var/log/httpd/error_log 86400 4468 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4469 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4470 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4471 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4472 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4473 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4474 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4475 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4582 Sun Feb 10 15:55:47 2019 grep httpd[root@ip-10-59-100-137 centos]# dateSun Feb 10 15:55:51 UTC 2019[root@ip-10-59-100-137 centos]# ============================We are analyzing the issue, Meanwhile, let us know if you are performing any action.RegardsNishad Ali C","Subject: [Monitor Alert] Triggered: [SpendHQ] Httpd Process is down - sales_web_server - 10.59.100.137 - web on process:httpd,host:i-0bdddf52b4cfdff92[Image removed by sender. Datadog][Triggered on {host:i-0bdddf52b4cfdff92,process:httpd}] [SpendHQ] Httpd Process is down - sales_web_server - 10.59.100.137 - webHttpd Process is down    @ms@reancloud.com<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECa4ZPSFheKVV3Kgt6YrvAIS39UJGhw9KZnRJrltVbOTQ-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLyExFwDCR6rxxreUJDZE9-2F5pKuu9HtfDX5VVDoKKcEgPVQtj2ejvblAeroZn-2BoQ925WUIY7aiPg4DahYP0K7pfnJsM6LWSiuu5V7z4Gyfs6GU6kdwnSbadXtVN0in1OHlhIeq3J7maTY91d8gPtaRivenAZF5Mn-2BoQJoFMLdYB6ZLe-2F4V0XVPpCV9v6dcCYVbYEDq3fVVCTdc-2BVc8QewrvP&data=01%7C01%7Cnishad.ali%40hitachivantara.com%7C4282107b12864cebad4608d68f6ee165%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=EsUwzjR6Bpnw87ZhdpZ5Fuoh8LwvaZ7MYPmKdQaI3GA%3D&reserved=0>PROCS CRITICAL: 0 processes found for httpdThe monitor was last triggered at Sun Feb 10 2019 15:46:00 UTC (7 secs ago).________________________________[Monitor Status<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEB5Aa2ChxAC1hSgLnJw3N-2Bpf-2FSro8izCjEwPR8irnBbYnIK7nWuqwyBpQ1qSdlloOYSai-2FA-2B-2BVG7rmrTSArClWVIsCbjgBBp4SycDmNW2IvZQ-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLyExFwDCR6rxxreUJDZE9-2F5FLZGjaBfoqOSdpXJ7BKs0kjKY4ge1XbyJxLLXf-2FzRR0VSD6wmvAYt9gUM7-2FNacPK634F-2B2v201jYE2a1mGVTmpRGcFEtCgcrcFTj4c-2FXOY2GD2Dhylg4gmqt4K-2FUHoeT86ZXl-2BdR0p3DmVZemqJhCNpjvHvyLQ6gzOa0a8f5pULMBsHXv7Day7YWtoIalP4w&data=01%7C01%7Cnishad.ali%40hitachivantara.com%7C4282107b12864cebad4608d68f6ee165%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=%2Ff3PAX2I%2BnW37hOjebZM9xDATdY%2BYH988ZcIQsLF%2FTg%3D&reserved=0>] · [Edit Monitor<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEB5Aa2ChxAC1hSgLnJw3N-2BpkQo3lZrU3a7wg1KElywn8Q-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLyExFwDCR6rxxreUJDZE9-2F56cj-2FLl9T7cOi4WoIzpPk3KbMr0XRc0whFqrwjtXDXh6oQJkKJTdDITaA8norcNZFEJvQQAY-2FbcinccCwoz6xYVsdTCnCOWsoruAzw2Mg6UH9ZlMsdG3t6ZTVICrvtOX3ZUY6WyF1kVe0JqiuoR52E5w-2FUoUP8zzhv7JDcTMbSlTjFBdTV2ztdZPmE2X3i9OJ&data=01%7C01%7Cnishad.ali%40hitachivantara.com%7C4282107b12864cebad4608d68f6ee165%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=vJn%2FMfnjHE60PwpE%2Fc6UvNXZBLZGHJVdNJ7%2B3o3%2F3Us%3D&reserved=0>] · [View i-0bdddf52b4cfdff92<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEDKT1NZt0tnkwEaAxSQZgju0L8vTsgYMVeQcI-2BYzsE96yVBfDWE63dzSRygmS8IEyw-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLyExFwDCR6rxxreUJDZE9-2F52h-2BvS7dubl5WUqLZ8WckuDRVO4RMO4Y0SjDsBi0jN0d4NIzgQMrI5JuuH85lZw2Yqyt-2B2TS4XOjPe4Jc66jBHGoCC9s1YYNSy5jjmDABpm8FdkkNFlyORI-2BgWTAQjlTaTtB95DybC-2FG-2BjrAiqK0vqQcQ-2Fz3-2Bddc6TqDob7mFJX63zHWWLnfGg8-2BbkxI02Uu0&data=01%7C01%7Cnishad.ali%40hitachivantara.com%7C4282107b12864cebad4608d68f6ee165%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=jIjOdV0WXOuq%2FKbedgAP%2BbOGZi4g1r00u9bTUD1MqeA%3D&reserved=0>] · [Show Processes<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQED-2FFPDBbKPsalSo1i1ufo6SoAz0jcd-2B6f345QK7ivt0vnVe6N6mgF22OJiXVhKqRJtAW81GdE-2BYR3sWcuOSQNxHFvu6zTi-2FvBKoYpnFM2Hlp-2FQWgaq2SelnY7M89EVF1Pd2xwRsqQMFLylJ6SBQLfMIBUUZuE-2FytI36-2FMVZteNTPR8wTpra-2F6rZ7LaQO6wk3zk-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLyExFwDCR6rxxreUJDZE9-2F50TWpQzPPd7JjyHilH9FvdEJiDvzNjdq67FwK7FEz1-2FygnZIkNPMlv8H4YMjE178wx5u53qmnTzwJIQSWH2RtqsJF6Ynp5p1ck0Nx0efGZtTSBkCVuAG1rifHJNJgOcPlMnFE0Ds66teBCugapWPuQitTNTGQ6dXTNHtLK39Mz3kaJXD-2FMgH702BORY93QcTM&data=01%7C01%7Cnishad.ali%40hitachivantara.com%7C4282107b12864cebad4608d68f6ee165%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=qaeR9PCx%2FPFgGqjvl1d%2BYLj7ez2fh8R%2FCTqHJbbassg%3D&reserved=0>]This alert was raised by account SpendHQ","[Monitor Alert] Triggered: [SpendHQ] Httpd Process is down - sales_web_server  - 10.59.100.137 - web on process:httpd,host:i-0bdddf52b4cfdff92",,10-02-2019 21:18,17,0,SpendHQ,"Hello Team,We have removed this server from monitoring. Going forward you will not witness any data dog alerts for this instance. As this request is completed we are marking this case as resolved and closing this case. Please let us know if you have any further queries.",@Team:Uninstall the datadog agent.Remove the gig_backup tagand Update the monitoring tag value to Off,@TeamCheck with Rohit to remove this server from monitoring,"Hello Matthew, Thanks for the update.We will work on this and will let you know the updates RegardsNishad Ali",Please remove this server from monitoringGet Outlook for iOS,"Hello TeamOn further analysis, from the httpd error log we could see that the httpd service has been got restarted multiple times at the time of the alert.======================[Sun Feb 10 15:44:10 2019] [notice] caught SIGTERM, shutting down[Sun Feb 10 15:45:43 2019] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Sun Feb 10 15:45:43 2019] [notice] Digest: generating secret for digest authentication ...[Sun Feb 10 15:45:43 2019] [notice] Digest: done[Sun Feb 10 15:45:43 2019] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations[Sun Feb 10 15:52:35 2019] [notice] caught SIGTERM, shutting down[Sun Feb 10 15:52:35 2019] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Sun Feb 10 15:52:35 2019] [notice] Digest: generating secret for digest authentication ...[Sun Feb 10 15:52:35 2019] [notice] Digest: done[Sun Feb 10 15:52:35 2019] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations=======================================when checked with the secure log, we could find that the user mwatts was performing some action on the instance at the time od alert and as a part of that, the httpd service is restarted and the alert has got triggered from the Datatdog./var/log/secure ========================================Feb 10 15:39:08 ip-10-59-100-122 sshd[1981]: Accepted publickey for mwatts from 10.59.1.192 port 52898 ssh2Feb 10 15:39:08 ip-10-59-100-122 sshd[1981]: pam_unix(sshd:session): session opened for user mwatts by (uid=0)Feb 10 15:39:16 ip-10-59-100-122 sudo:   mwatts : TTY=pts/0 ; PWD=/home/mwatts ; USER=root ; COMMAND=/bin/suFeb 10 15:39:16 ip-10-59-100-122 su: pam_unix(su:session): session opened for user root by mwatts(uid=0)Feb 10 15:40:19 ip-10-59-100-122 groupadd[2362]: group added to /etc/group: name=varnish, GID=494Feb 10 15:40:19 ip-10-59-100-122 groupadd[2362]: group added to /etc/gshadow: name=varnishFeb 10 15:40:19 ip-10-59-100-122 groupadd[2362]: new group: name=varnish, GID=494Feb 10 15:40:19 ip-10-59-100-122 useradd[2369]: new user: name=varnish, UID=494, GID=494, home=/var/lib/varnish, shell=/sbin/nologinFeb 10 15:44:10 ip-10-59-100-12===================================[mwatts@ip-10-59-100-137 log]$ w 16:05:57 up 2 days, 11:25,  2 users,  load average: 0.00, 0.00, 0.00USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHATmwatts   pts/0    10.59.1.192      15:39    8:14   0.06s  0.00s sshd: mwatts [priv]centos   pts/1    10.59.1.192      15:53    0.00s  0.03s  0.00s sshd: centos [priv]---------------------Currently,  httpd process is running fine.---------------------[root@ip-10-59-100-137 log]# service httpd statushttpd (pid  8017) is running...[root@ip-10-59-100-137 log]# ----------------------kindly check with the same and let us know the updates to proceed further on this.RegardsNishad Ali C","Hello TeamThis is to inform you that we have received an alert for the httpd process down on the sales_web_server - 10.59.100.137. From instance level, we could see that httpd process was running state and has got restarted.=========================[root@ip-10-59-100-137 centos]# ps -eo pid,lstart,cmd | grep httpd 4464 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4466 Sun Feb 10 15:55:03 2019 /usr/sbin/rotatelogs /var/log/httpd/access_log 86400 4467 Sun Feb 10 15:55:03 2019 /usr/sbin/rotatelogs /var/log/httpd/error_log 86400 4468 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4469 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4470 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4471 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4472 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4473 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4474 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4475 Sun Feb 10 15:55:03 2019 /usr/sbin/httpd 4582 Sun Feb 10 15:55:47 2019 grep httpd[root@ip-10-59-100-137 centos]# dateSun Feb 10 15:55:51 UTC 2019[root@ip-10-59-100-137 centos]# ============================We are analyzing the issue, Meanwhile, let us know if you are performing any action.RegardsNishad Ali C",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001lOqfo,Cloud Engineer Level 1,Closed,1112827,Incident,06-03-2019 10:29,,"@Team:Please close this. This is closed from AWS side and we dint see any impact on the environment.###Hello Team, We received an informational notification from AWS we experienced elevated packet loss that may have impacted AWS Direct Connect connectivity to the US-EAST-1 region. The issue happened between 8:20 PM and 9:20 PM PST. Currently, the issue has been resolved and the service is operating normally. Thanks","Between 8:20PM and 9:20PM PST, we experienced elevated packet loss that may have impacted AWS Direct Connect connectivity to the US-EAST-1 region. The issue has been resolved and the service is operating normally. For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_PACKET_LOSS,,05-03-2019 13:23,21,0,SpendHQ,@Team:Please close this. This is closed from AWS side and we dint see any impact on the environment.,"Hello Team, We received an informational notification from AWS we experienced elevated packet loss that may have impacted AWS Direct Connect connectivity to the US-EAST-1 region. The issue happened between 8:20 PM and 9:20 PM PST. Currently, the issue has been resolved and the service is operating normally. Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Ko4sh,Cloud Engineer Level 1,Closed,1084896,Incident,18-12-2017 10:40,,"Hello SpendHQ,We haven't heard back from youAt this time we are marking this case as resolved. please revert back to us if you have any further queries.###Hi SpendHQ,We are still waiting for a response from your team on this. Please note that any unused EC2 instance in the account will cause the AWS EC2 charges to SpendHQ.We will be closing this ticket by EOD today. Please review 10.59.10.33 server and let us know if we are good to terminate it.###Hello Team,We haven't heard back from you regarding the case for a while.Please review the details and let us know if we are good to decommission this server.###Hello SpendHQ-Team, As per your request, we have set up new CentOS 7 box and stopped the 10.59.10.33 box.we are waiting for an approval from your end to destroy the 10.59.10.33 box. Please let us know if we are good to decommission this server.###In the evening ops call Praveen mentioned need to stop the instance.###Hello SpendHQ-Team,As per your request, we have set up new CentOS 7 box and we are waiting for an approval from your end to destroy the 10.59.10.33 box.Please let us know if we are good to decommission this server.###Hello Team,We haven't heard back from you regarding an approval for Destroying the 10.59.10.33 box. We have completed this request except for step 9. After setting up the new CentOS 7 box, then delete 10.59.10.33 upon our approval and confirmation that the new box is exactly what we needThe server 10.59.10.33 is still running in the account, Which is costing us AWS charges. Please let us know if we are good to decommission this server.###Hello Allen,This ticket as closed due to no response from your side. There were no complaints about this, We hope you are good with the server.But I am re-opening this ticket to get an update on the below step mentioned by you:9. After setting up the new CentOS 7 box, then delete 10.59.10.33 upon our approval and confirmation that the new box is exactly what we need The server 10.59.10.33 is still running in the account, Please let us know if we are good to decommission this server. ThanksYogesh Maloo###I am opening this case as Sumod did not follow up the step 9 mentioned in the email and the server 10.59.10.33 is running till now.###Hello Allen,We haven't heard back from you.We have verified all the SSH keys from 10.59.10.33 and made the necessary permission changes. Kindly try to ssh and let us know if you are still facing the issue.###Hello Allen,We have verified all the SSH keys from 10.59.10.33 and made the necessary permission changes. Kindly try to ssh and let us know if you are still facing the issue.###Matthew Watts8:36 AM (2 minutes ago)￼￼￼to Allen, Rean, spendhq-support￼Rean, Could we follow all instructions please.###Allen Herrera8:35 AM (3 minutes ago)￼￼￼to Matthew, Rean, spendhq-support￼I’m going to message this again because you did not complete step 5 or 10 from the initial request. My SSH keys don’t work on 10.59.10.243. I’m on the VPN at home. VERIFY ALL SSH KEYSIn making this new box with centos 7 make sure the follow requirements are met. The new server should be the same size box as 10.59.10.33 Instead of having CentOS 6.9, we need CentOS 7 on the new boxAll the users from 10.59.10.33  must be present on the new boxAll the permissions for each of these users must also be present on the new box (meaning sudoers too)All ssh keys present on 10.59.10.33, must also be present on the new box so users can ssh without a passwordThe server needs internet connectionThe server should still be behind our Sophos firewall thus requiring our VPN to access the serverDo not monitor or onboard this new server, just like the existing 10.59.10.33After setting up the new CentOS 7 box, then delete 10.59.10.33 upon our approval and confirmation that the new box is exactly what we needAsk us questions if anything is unclear   Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.com###Hello Matthew,We have verified the internet access for this box. Please find the users present in this box below.aherreraakim  centos  dfowler  dmackay  dmiller  mwatts rlittle  sngKindly verify from your end and let us know if we are good to terminate the old instance.###Matthew Watts7:09 AM (1 minute ago)￼￼￼to Rean, spendhq-support￼Can we ensure the networking is configured correctly and the users are present, as per the initial request.###Hello Matthew,This request is completed. Please find the resource details below.Instance details: Name: PRD-New-Centos-7 Id: i-0f1840913cd62bd6c Type: p2.xlarge Key: spendhq-prod-20171101 IP: 10.59.10.243 Please verify from your end and let us know if we are good to terminate the old instance.###This request is completed.Instance details:Name: PRD-New-Centos-7Id: i-0f1840913cd62bd6cType: p2.xlargeKey: spendhq-prod-20171101IP: 10.59.10.243Created all the users in 10.59.10.33 , copied ssh keys, and copied sudoers file.Next action: get this reviewed by Yogesh and update to customer.###Hello Team,We have raised a support ticket with AWS for increasing the instance type and will update you once we get a response from their side. Meanwhile please let us know if you have queries regarding this.###Limit increase request 1Service: EC2 InstancesRegion: US East (Northern Virginia)Primary Instance Type: p2.xlargeLimit name: Instance LimitNew limit value: 2------------Use case description: Hello Team,We have one 'p2.xlarge'. While trying to launch one more instance with the same instance type, we are getting limit reached error. We would like to increase the instance limit from 1 to 2. Please let us know if you need any further details.###Hello Team,While trying to launch a new instance, we are facing instance limit reached error form AWS side. The instance limit for P2.xlarge instance is 1 please let us know whether we can go ahead and request a support ticket for instance limit increase or you need an instance with different instance type.Please find the attached screenshot for more details.###Hello Matthew,Thank You for providing the Approval.@Allen: We will work on this request and will get back to you with the updates soon.Regards,Sumod.K.Bose###APPROVED.Matthew Watts","Hey Rean,We just had 10.59.10.33 created with centos 6.9 but our requirements have changed. We need centos 7.We need this done ASAP as we are behind on this project. Today as soon as possible is necessary.In making this new box with centos 7 make sure the follow requirements are met.  1.  The new server should be the same size box as 10.59.10.33  2.  Instead of having CentOS 6.9, we need CentOS 7 on the new box  3.  All the users from 10.59.10.33  must be present on the new box  4.  All the permissions for each of these users must also be present on the new box (meaning sudoers too)  5.  All ssh keys present on 10.59.10.33, must also be present on the new box so users can ssh without a password  6.  The server needs internet connection  7.  The server should still be behind our Sophos firewall thus requiring our VPN to access the server  8.  Do not monitor or onboard this new server, just like the existing 10.59.10.33  9.  After setting up the new CentOS 7 box, then delete 10.59.10.33 upon our approval and confirmation that the new box is exactly what we need  10. Ask us questions if anything is unclearAllen Herrera | Developer | SpendHQ(r)M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","Destroy 10.59.10.33, Create a new one exactly the same but with centos 7",,21-11-2017 02:06,657,0,SpendHQ,"Hello SpendHQ,We haven't heard back from youAt this time we are marking this case as resolved. please revert back to us if you have any further queries.","Hi SpendHQ,We are still waiting for a response from your team on this. Please note that any unused EC2 instance in the account will cause the AWS EC2 charges to SpendHQ.We will be closing this ticket by EOD today. Please review 10.59.10.33 server and let us know if we are good to terminate it.","Hello Team,We haven't heard back from you regarding the case for a while.Please review the details and let us know if we are good to decommission this server.","Hello SpendHQ-Team, As per your request, we have set up new CentOS 7 box and stopped the 10.59.10.33 box.we are waiting for an approval from your end to destroy the 10.59.10.33 box. Please let us know if we are good to decommission this server.",In the evening ops call Praveen mentioned need to stop the instance.,"Hello SpendHQ-Team,As per your request, we have set up new CentOS 7 box and we are waiting for an approval from your end to destroy the 10.59.10.33 box.Please let us know if we are good to decommission this server.","Hello Team,We haven't heard back from you regarding an approval for Destroying the 10.59.10.33 box. We have completed this request except for step 9. After setting up the new CentOS 7 box, then delete 10.59.10.33 upon our approval and confirmation that the new box is exactly what we needThe server 10.59.10.33 is still running in the account, Which is costing us AWS charges. Please let us know if we are good to decommission this server.","Hello Allen,This ticket as closed due to no response from your side. There were no complaints about this, We hope you are good with the server.But I am re-opening this ticket to get an update on the below step mentioned by you:9. After setting up the new CentOS 7 box, then delete 10.59.10.33 upon our approval and confirmation that the new box is exactly what we need The server 10.59.10.33 is still running in the account, Please let us know if we are good to decommission this server. ThanksYogesh Maloo",I am opening this case as Sumod did not follow up the step 9 mentioned in the email and the server 10.59.10.33 is running till now.,"Hello Allen,We haven't heard back from you.We have verified all the SSH keys from 10.59.10.33 and made the necessary permission changes. Kindly try to ssh and let us know if you are still facing the issue.","Hello Allen,We have verified all the SSH keys from 10.59.10.33 and made the necessary permission changes. Kindly try to ssh and let us know if you are still facing the issue.","Matthew Watts8:36 AM (2 minutes ago)￼￼￼to Allen, Rean, spendhq-support￼Rean, Could we follow all instructions please.","Allen Herrera8:35 AM (3 minutes ago)￼￼￼to Matthew, Rean, spendhq-support￼I’m going to message this again because you did not complete step 5 or 10 from the initial request. My SSH keys don’t work on 10.59.10.243. I’m on the VPN at home. VERIFY ALL SSH KEYSIn making this new box with centos 7 make sure the follow requirements are met. The new server should be the same size box as 10.59.10.33 Instead of having CentOS 6.9, we need CentOS 7 on the new boxAll the users from 10.59.10.33  must be present on the new boxAll the permissions for each of these users must also be present on the new box (meaning sudoers too)All ssh keys present on 10.59.10.33, must also be present on the new box so users can ssh without a passwordThe server needs internet connectionThe server should still be behind our Sophos firewall thus requiring our VPN to access the serverDo not monitor or onboard this new server, just like the existing 10.59.10.33After setting up the new CentOS 7 box, then delete 10.59.10.33 upon our approval and confirmation that the new box is exactly what we needAsk us questions if anything is unclear   Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.com","Hello Matthew,We have verified the internet access for this box. Please find the users present in this box below.aherreraakim  centos  dfowler  dmackay  dmiller  mwatts rlittle  sngKindly verify from your end and let us know if we are good to terminate the old instance.","Matthew Watts7:09 AM (1 minute ago)￼￼￼to Rean, spendhq-support￼Can we ensure the networking is configured correctly and the users are present, as per the initial request.","Hello Matthew,This request is completed. Please find the resource details below.Instance details: Name: PRD-New-Centos-7 Id: i-0f1840913cd62bd6c Type: p2.xlarge Key: spendhq-prod-20171101 IP: 10.59.10.243 Please verify from your end and let us know if we are good to terminate the old instance.","This request is completed.Instance details:Name: PRD-New-Centos-7Id: i-0f1840913cd62bd6cType: p2.xlargeKey: spendhq-prod-20171101IP: 10.59.10.243Created all the users in 10.59.10.33 , copied ssh keys, and copied sudoers file.Next action: get this reviewed by Yogesh and update to customer.","Hello Team,We have raised a support ticket with AWS for increasing the instance type and will update you once we get a response from their side. Meanwhile please let us know if you have queries regarding this.","Limit increase request 1Service: EC2 InstancesRegion: US East (Northern Virginia)Primary Instance Type: p2.xlargeLimit name: Instance LimitNew limit value: 2------------Use case description: Hello Team,We have one 'p2.xlarge'. While trying to launch one more instance with the same instance type, we are getting limit reached error. We would like to increase the instance limit from 1 to 2. Please let us know if you need any further details.","Hello Team,While trying to launch a new instance, we are facing instance limit reached error form AWS side. The instance limit for P2.xlarge instance is 1 please let us know whether we can go ahead and request a support ticket for instance limit increase or you need an instance with different instance type.Please find the attached screenshot for more details.","Hello Matthew,Thank You for providing the Approval.@Allen: We will work on this request and will get back to you with the updates soon.Regards,Sumod.K.Bose",APPROVED.Matthew Watts,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XF5ra,Cloud Engineer Level 1,Closed,1100089,Incident,13-06-2018 16:16,,"Hello SpendHQ-Team,We have further checked the notification and confirmed this is not affecting any of the Direct Connection. Hence we are closing this case.###This is not effecting any of the Direct Connection. We can close this.###Need to review by Rohit.###After checking in the cloudfront I found that below are the affected resources:Directconnect Connection:-10gbps-1gbpsElasticache:-shq-elasticcache-spendhq-redis###Hello SpendHQ Team, Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. During this maintenance window, your AWS Direct Connect services associated with this event may become unavailable. This maintenance is scheduled to avoid disrupting redundant connections at the same time. If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues","Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. During this maintenance window, your AWS Direct Connect services associated with this event may become unavailable.This maintenance is scheduled to avoid disrupting redundant connections at the same time.If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED,,13-06-2018 07:33,9,0,SpendHQ,"Hello SpendHQ-Team,We have further checked the notification and confirmed this is not affecting any of the Direct Connection. Hence we are closing this case.",This is not effecting any of the Direct Connection. We can close this.,Need to review by Rohit.,After checking in the cloudfront I found that below are the affected resources:Directconnect Connection:-10gbps-1gbpsElasticache:-shq-elasticcache-spendhq-redis,"Hello SpendHQ Team, Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. During this maintenance window, your AWS Direct Connect services associated with this event may become unavailable. This maintenance is scheduled to avoid disrupting redundant connections at the same time. If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hQPib,Cloud Engineer Level 3,Closed,1110088,Incident,07-01-2019 12:56,,"Hello Matthew,Thanks for the confirmation.At this time we are marking this case closed and let us know if you have any queries.###Hello Matthew, Kindly disregard the last mails. We will be keeping this case as open until we get an update from you. Its was a mistake from my end that we had got confused with the ISCSI RO mode case which raised as P3. We deeply regret for the mistake happened and beg your apologies for this mistake . Regards###Hello Matthew, Thanks for the confirmation.  As the issue is fixed and we don’t have any pending action from your , So we will be marking this case as closed. Let us know if you have any queries. Thanks###Mathew ReplyPerfect###Hello Matthew, We haven't heard back from you regarding this case. Kindly review the details we shared and let us know if you have any questions or concerns. Thanks###Hello Matthew, We haven't heard back from you regarding this case. Kindly review the details we shared and let us know if you have any questions or concerns. Thanks###Hello Praveen We have analyzed the logs again for the preview load balancer for the last 12 hours and analyzed the logs.we could find that there are many requests at the load balancer level  and could find that most of the GET and. HEAD request to the URL  https://preview.spendhq.com:443/ HTTP/1.1 Got response of 302 and the request processing time for this request is greater than 30 seconds.Most of the 403 responses are written for the POST request and GET request to the URL  http://34.203.134.80:80/yumo.php HTTP/1.1. and POST http://54.236.182.171:80/confg.php HTTP/1.1I also checked with the source IPs of this request and could not find any abusive IP other than that we have blocked.The Site  loading fine for last 3 hours C02XH05GJG5M:spendhq niali$  for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://preview.spendhq.com/ -so /dev/null; doneHTTPCode=302 TotalTime=1.832945HTTPCode=302 TotalTime=1.510947HTTPCode=302 TotalTime=1.682051HTTPCode=302 TotalTime=1.557859HTTPCode=302 TotalTime=1.649216HTTPCode=302 TotalTime=1.685778C02XH05GJG5M:spendhq niali$ Can you please have a look at this to this as we cannot find anything other than the latency issue and request count spike at the time of alert.Thanks###the site is still down and we have muted it.Rohit is checking for the fix. Please check with him once.###Hello Team,We have checked the logs for last 5 hours logs(8:00 am ist to 7:00 am ist). the total 4xx request count was 671. Please find the abusive IP and the request count. We have blocked these IPs from the NACL level as they are abusive.Also, attached the total ELB logs in the attachment for your reference.123.206.210.160Count: 330ISP: Tencent Cloud Computing (Beijing) Co. Ltd.Usage Type: Data Center/Web Hosting/TransitDomain Name: UnknownCountry: ChinaCity: Beijing, Beijing129.204.161.184Count: 328ISP: Tencent Cloud Computing (Beijing) Co. LtdUsage Type: Data Center/Web Hosting/TransitDomain Name: UnknownCountry: ChinaCity: Beijing, Beijing66.240.205.34Count: 5ISP: CARInet Inc.Usage Type: Data Center/Web Hosting/TransitHostname(s): malware-hunter.census.shodan.io Domain Name: UnknownCountry: United StatesCity: San Diego, California122.224.158.196Count: 2ISP: Fuyang Yinhu Gaoqiao Primary schoolUsage Type: University/College/SchoolDomain Name: UnknownCountry: ChinaCity: Gaoqiao, Liaoning60.191.20.210Count: 1ISP: Hangzhou BoKe Information Technology LTDUsage Type: CommercialDomain Name: UnknownCountry: ChinaCity: Hangzhou, ZhejiangPlease review this details and revert back to us in case of any queries.###Hello Matthew,We haven't heard back from you since our last communication on this case.Kindly review the details we shared and let us know if you have any questions or concerns.Thanks###Hello,From what we could gather, CPU and memory utilization on the particular instance was normal at our time of checking. [root@ip-10-59-100-170 logs]# sh cpu.sh Load Average of the System 0.10, 0.03, 0.00 ################################################ Processes with highest CPU usage ################################################ USER PID PPID CMD %CPU root 17441 1 /usr/bin/python /usr/bin/su 0.4 apache 10445 16728 /usr/sbin/httpd 0.1 apache 10728 16728 /usr/sbin/httpd 0.1 apache 11645 16728 /usr/sbin/httpd 0.1 apache 14052 16728 /usr/sbin/httpd 0.1 apache 14992 16728 /usr/sbin/httpd 0.1 [root@ip-10-59-100-170 logs]# sh memory.sh USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND clam 1689 0.0 4.0 774784 617356 ? Ssl 2018 45:40 clamd root 1894 0.0 0.2 1245312 44884 ? Sl 2018 68:58 node logiApplicationService.js --disableSchemaValidation apache 10445 0.1 0.2 404616 42904 ? S 02:02 0:36 /usr/sbin/httpd apache 17692 0.1 0.2 404396 42660 ? S 07:22 0:13 /usr/sbin/httpd apache 16623 0.1 0.2 404336 42608 ? S 06:23 0:15 /usr/sbin/httpd apache 16236 0.1 0.2 404312 42588 ? S 06:01 0:19 /usr/sbin/httpd Looking at the ELB access logs (for both 4xx and 5xx), we have analyzed the logs over multiple timeframes, but could not see any reported for the preview-spendhq-xelb.We also verified the total request processing time and found it to be around 120 seconds:[root@ip-10-59-100-170 httpd]# for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://preview.spendhq.com/login -so /dev/null; done HTTPCode=200 TotalTime=120.685 Client connections [root@ip-10-59-100-170 httpd]# ps aux | grep httpd | wc -l 67Thanks.###Hello Matt,Sure thing. We will be sharing the full details with you shortly.Thanks.###[Via Mail]This is a non-production machine so there is no need to onboard. Can you provide a little more information as to what is going on?Matthew Watts | Manager, Application Development | SpendHQ®###Hello Team,For the past two days we've been receiveing a lot of latency related alerts in regards to this case. Could you be performing some action (copying/deployment) from your end that might be causing this?Also, we can see that the backend instance (10.59.100.170) is not under REAN monitoring. Would you like for us to on-board it for monitoring?Do let us know.Thanks.###Hello Team,We have again reviewed the following metrics to understand the issue.1. CPU utilization2. Memory Utilization3. Apache logs4. ELB access logs 4xx and 5xx1. CPU utilization on the backend instance i-0f36027c388e7a563 : Preview Web[root@ip-10-59-100-170 logs]# sh cpu.shLoad Average of the System0.10, 0.03, 0.00################################################  Processes with highest CPU usage################################################USER       PID  PPID CMD                         %CPUroot     17441     1 /usr/bin/python /usr/bin/su  0.4apache   10445 16728 /usr/sbin/httpd              0.1apache   10728 16728 /usr/sbin/httpd              0.1apache   11645 16728 /usr/sbin/httpd              0.1apache   14052 16728 /usr/sbin/httpd              0.1apache   14992 16728 /usr/sbin/httpd              0.1apache   16236 16728 /usr/sbin/httpd              0.1apache   16621 16728 /usr/sbin/httpd              0.1apache   16622 16728 /usr/sbin/httpd              0.1apache   16623 16728 /usr/sbin/httpd              0.1CPU usage is vey low 2.Memory Utilization on the backend instance i-0f36027c388e7a563 : Preview WebBy using DevOps script==================[root@ip-10-59-100-170 logs]# sh memory.shUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDclam      1689  0.0  4.0 774784 617356 ?       Ssl   2018  45:40 clamdroot      1894  0.0  0.2 1245312 44884 ?       Sl    2018  68:58 node logiApplicationService.js --disableSchemaValidationapache   10445  0.1  0.2 404616 42904 ?        S    02:02   0:36 /usr/sbin/httpdapache   17692  0.1  0.2 404396 42660 ?        S    07:22   0:13 /usr/sbin/httpdapache   16623  0.1  0.2 404336 42608 ?        S    06:23   0:15 /usr/sbin/httpdapache   16236  0.1  0.2 404312 42588 ?        S    06:01   0:19 /usr/sbin/httpdapache   16622  0.1  0.2 404312 42588 ?        S    06:23   0:16 /usr/sbin/httpdapache   17023  0.1  0.2 404028 42308 ?        S    06:46   0:14 /usr/sbin/httpdapache   10728  0.1  0.2 403788 42144 ?        S    02:16   0:34 /usr/sbin/httpdapache   11645  0.1  0.2 403800 42100 ?        S    03:02   0:30 /usr/sbin/httpdThe memory is too low by seeing the above output. But while checking the free -m command we command see that the total 14g is consumed.[root@ip-10-59-100-170 logs]# free -m             total       used       free     shared    buffers     cachedMem:         14938      14345        593          0        210       4134-/+ buffers/cache:      10000       4938Swap:            0          0          0We witnessed this is an issue related to memory.3. Apache logswe checked the /var/www/vhosts/files.spendhq.com/w2/logs/ there is no error logs reported from 31st of Dec.4. ELB access logs 4xx and 5xxWe have checked the logs in multiple time frames from the time of issue till now. We didn't see any 5xx or 4xx logs for the ELB preview-spendhq-xelb.Backend instance and ELB details==========================ELB Details: ----------- Name: preview-spendhq-xelb DNS Name: preview-spendhq-xelb-520312558.us-east-1.elb.amazonaws.com Type: Classic Scheme: internet-facing Availability Zones: subnet-01596c2a - us-east-1b, subnet-acbb09e7 - us-east-1c VPC: vpc-76df7212 Instance ID : i-0f36027c388e7a563Instance Name : Preview WebPrivate Ip : 10.59.100.170Note : This instance is not having monitoring tag and not listing in the datdog,###Hello Team,I have checked with Rohit on this and he mentioned he will check and update the case.###Hello Rohit,We have again verified the total time of the request is 120 seconds please review the details below and earlier comments and recommend a solution to get rid of the latency issue. [root@ip-10-59-100-170 httpd]# for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://preview.spendhq.com/login -so /dev/null; doneHTTPCode=200 TotalTime=120.685Client connections[root@ip-10-59-100-170 httpd]# ps aux | grep httpd | wc -l67###Hello Team,We again received the site down alert for the URL https://preview.spendhq.com/login. The site is not actually down it is loading with high latency. As we have shared the details in the earlier comments please review and let us know if you have any further queries.Meanwhile, we will check internally on this issue and will get back to you with an update.###Hello Rohit,Team has already shared the analysis with the customer. Kindly check and let us know if there is anything pending on this case, otherwise we can move it to confirmation###@TeamThe Total Downtime is 12 hours 1 minute.###Hello Teamon further analysis, from the ELB logs, we could see that the there is a high backend processing time at the time of the alert, The value trigered between  60 and 120 seconds at the time of the alert.======backend_processing_time	response_processing_time	elb_status_code	backend_status_code	received_bytes	sent_bytes	request  60.211326	0.000046	302	302	0	0	HEAD https://preview.spendhq.com:443/ HTTP/1.160.198925	0.000048	302	302	0	0	HEAD https://preview.spendhq.com:443/ HTTP/1.1120.607944	0.000048	200	200	0	8833	GET https://preview.spendhq.com:443/login HTTP/1.160.211694	0.000047	302	302	0	0	HEAD https://preview.spendhq.com:443/ HTTP/1.1120.706341	0.000054	200	200	0	8836	GET https://preview.spendhq.com:443/login HTTP/1.1120.589438	0.000048	200	200	0	8833	GET https://preview.spendhq.com:443/login HTTP/1.1=========We had also checked with the current  response time of the URL and with the response code and we could see that it's working fine and loading within in 2 seconds and getting 200 response code----Testing Website Response Time for :https://preview.spendhq.com/loginLookup Time:		0.132320Connect Time:		0.134056AppCon Time:		1.323512Redirect Time:		0.000000Pre-transfer Time:	1.323595Start-transfer Time:	1.650112Total Time:		1.650146--------Response Code HTTPCode=200 TotalTime=1.914690 HTTPCode=200 TotalTime=1.726068 HTTPCode=200 TotalTime=1.772125 HTTPCode=200 TotalTime=1.766357 HTTPCode=200 TotalTime=1.768367 HTTPCode=200 TotalTime=1.751918-----------Kindly check with the attached logs at the time of alert and Let us know if you have any queries.Thanks###Hello TeamThis is to inform you that the URL https://preview.spendhq.com/login is loading fine without latency. So we have unmuted it and enabled monitoring again.Thanks###Hello Team,This is to inform you that we are currently muted the URL : https://preview.spendhq.com/login from our monitoring as the site takes more time to load and we can only add the Max Timeout to 60s.But we are keeping an Eye on the URL.Adding the high memory Consuming on the instance is  httpd [root@ip-10-59-100-170 centos]# ps aux  | awk '{print $6/1024  MB\\t\\t $11}'  | sort -nr602.758 MB		clamd40.9453 MB		/usr/sbin/httpd40.6992 MB		/usr/sbin/httpd39.7109 MB		/usr/sbin/httpd39.7031 MB		/usr/sbin/httpd39.6836 MB		/usr/sbin/httpd39.4883 MB		/usr/sbin/httpd38.5898 MB		/usr/sbin/httpd38.4414 MB		/usr/sbin/httpdAnd there was a open files  of lsof | grep httpd | wc -l8404and most of the File descriptors are memory mapped to the /usr/sbin/httpdPlease let us know you update.Thank you###I muted the Wormly URL as it taking more time to load the site and we receiving multiple alerts.and increased the timeout 60 for also.please change the value and disable the alert once it is resolved###Matthew Watts1:49 PM (0 minutes ago)to Rean, spendhq-support@reancloud.comI will review, thank you.###Hi Cc, Below are the details I found on checking traceroute preview.spendhq.comtraceroute to preview.spendhq.com (54.236.182.171), 30 hops max, 60 byte packets 1  10.59.1.192 (10.59.1.192)  0.453 ms  0.421 ms  0.429 ms 2  216.182.226.82 (216.182.226.82)  17.027 ms 216.182.226.86 (216.182.226.86)  12.265 ms 216.182.226.82 (216.182.226.82)  17.017 ms 3  * * * 4  * * * 5  * * * 6  * * * 7  * * * 8  * * * 9  * * *10  * * *11  * * *12  * * *13  * * *14  * * *15  * * *16  * * *17  * * *18  * * *19  * * *20  * * *21  * * *22  * * *23  * * *24  * * *25  * * *26  * * *27  * * *28  * * *29  * * *30  * * *------[root@ip-10-59-100-170 log]# for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n http://preview.spendhq.com/ -so /dev/null; doneHTTPCode=301 TotalTime=0.024HTTPCode=301 TotalTime=0.007HTTPCode=301 TotalTime=0.005HTTPCode=301 TotalTime=0.005HTTPCode=301 TotalTime=0.005HTTPCode=301 TotalTime=0.005-------[root@ip-10-59-100-170 log]# curl -Ik  http://preview.spendhq.com/HTTP/1.1 301 Moved PermanentlyContent-Type: text/html; charset=iso-8859-1Date: Tue, 01 Jan 2019 08:00:46 GMTLocation: https://preview.spendhq.com/Server: ApacheConnection: keep-alive-----[root@ip-10-59-100-170 log]# cat httpd/error_log[Sun Dec 30 03:35:08 2018] [notice] Digest: generating secret for digest authentication ...[Sun Dec 30 03:35:08 2018] [notice] Digest: done[Sun Dec 30 03:35:08 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Sun Dec 30 03:35:08 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations[root@ip-10-59-100-170 log]# -----------preview DB [root@ip-10-59-10-135 log]# cat messages Jan  1 02:00:01 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)---Sophos instnces httpd.log 2019:01:01-02:15:55 spendhq httpd: 74.207.230.51 - - [01/Jan/2019:02:15:55 +0000] GET / HTTP/1.1 200 108862019:01:01-02:16:32 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:29 +0000] GET / HTTP/1.1 200 2467252019:01:01-02:16:33 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:33 +0000] GET /core/css/default.css HTTP/1.1 200 6882019:01:01-02:16:34 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:34 +0000] GET /core/css/elements.css HTTP/1.1 200 4032019:01:01-02:16:34 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:34 +0000] GET /core/css/astaro.css HTTP/1.1 200 8342019:01:01-02:16:34 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:34 +0000] GET /core/css/wizard.css HTTP/1.1 200 8632019:01:01-02:16:34 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:34 +0000] GET /core/js/core-9.50.min.js HTTP/1.1 200 1987022019:01:01-02:16:34 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:34 +0000] GET /wfe/asg/js/app-9.50.min.js HTTP/1.1 200 476062019:01:01-02:16:35 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:35 +0000] GET /core/img/blank1x1.gif HTTP/1.1 200 682019:01:01-02:16:35 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:35 +0000] GET /wfe/asg/img/flow_monitor/fm-icon-block.png HTTP/1.1 200 7202019:01:01-02:16:35 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:35 +0000] GET Cloud Watch metrichttps://console.aws.amazon.com/cloudwatch/home?region=us-east-1#metricsV2:graph=~(metrics~(~(~'AWS*2fELB~'Latency~'LoadBalancerName~'preview-spendhq-xelb~(period~300~stat~'Sum))~(~'.~'RequestCount~'.~'.~(stat~'Sum~period~300))~(~'.~'HTTPCode_Backend_4XX~'.~'.~(period~300~stat~'Sum)))~view~'timeSeries~stacked~true~region~'us-east-1~start~'-PT12H~end~'P0D~title~'SHQ-Metric-site-Down);namespace=~'AWS*2fELB;dimensions=~'LoadBalancerName###Hello Team,On further Checking, we can see the Load balancer  preview-spendhq-xelb  has a sudden spike in latency with 2410241.200250626 and high request count of 167 and there was a spike in 2xx Count.Other than we checked the backend instance we couldn't find any error logs. The time wait and established at the connection backend web server is 95 and 25.[centos@ip-10-59-100-170 ~]$ netstat | grep TIME_WAIT | wc -l    25     [centos@ip-10-59-100-170 ~]$ netstat | grep ESTABLISHED | wc -l91the memory of web server   is 937 available [root@ip-10-59-100-170 log]# free -m             total       used       free     shared    buffers     cachedMem:         14938      14000        937          0        210       4457-/+ buffers/cache:       9332       5606Swap:            0          0          0---Also, we checked the backend Database and we couldn't find any error logs other than  Jan  1 02:10:00 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)  The Cpu utilization  on the preview web server and preview DB are normal but there is a spike in N/w in  on preview DB(461381), preview web( 82456858 ) and N/w out on preview web(9788468), preview DB(519445) We are attaching the Screenshot of the Details in the attachment section.Note: Currently also the site is taking more time to load but it is accessible. We are analyzing the ELB Access logs and share with you shorlty.ELB Details: ----------- Name: preview-spendhq-xelb DNS Name: preview-spendhq-xelb-520312558.us-east-1.elb.amazonaws.com Type: Classic Scheme: internet-facing Availability Zones: subnet-01596c2a - us-east-1b, subnet-acbb09e7 - us-east-1c VPC: vpc-76df7212 ----------- Backend Instance Details: ------------------------- Name: Preview DB Instance ID: i-008d43ad00357e47a Availability Zone: us-east-1b Private IP: 10.59.10.135 VPC ID: vpc-76df7212 ------------------------- Name: Preview WEb Instance ID:i-0f36027c388e7a563Availability Zone: us-east-1b Private IP: 10.59.100.170VPC ID: vpc-76df7212 Thanks###Hello Team,The site is still accessible but it taking a long time to load the page.From Wormly, we could see requests timing out after Operation timed out after 9000 milliseconds with 0 bytes being received at the time. And from the preview-spendhq-xelb load balancer, we can see high latency of   2410247.220We are further checking on this and update you.Regards###Hello Team,This is to inform we received a site down alert for URL: https://preview.spendhq.com/login On further Checking, we can the site is accessible at the time but it taking a long time to load the desired page.We are checking further on this and we will let you know the update.Thanks.","Mon, 31 Dec 2018 21:03:02 -0500Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): Dallas-C US, New Jersey US, Frankfurt DE, London UK-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,01-01-2019 07:35,149,0,SpendHQ,"Hello Matthew,Thanks for the confirmation.At this time we are marking this case closed and let us know if you have any queries.","Hello Matthew, Kindly disregard the last mails. We will be keeping this case as open until we get an update from you. Its was a mistake from my end that we had got confused with the ISCSI RO mode case which raised as P3. We deeply regret for the mistake happened and beg your apologies for this mistake . Regards","Hello Matthew, Thanks for the confirmation.  As the issue is fixed and we don’t have any pending action from your , So we will be marking this case as closed. Let us know if you have any queries. Thanks",Mathew ReplyPerfect,"Hello Matthew, We haven't heard back from you regarding this case. Kindly review the details we shared and let us know if you have any questions or concerns. Thanks","Hello Matthew, We haven't heard back from you regarding this case. Kindly review the details we shared and let us know if you have any questions or concerns. Thanks",Hello Praveen We have analyzed the logs again for the preview load balancer for the last 12 hours and analyzed the logs.we could find that there are many requests at the load balancer level  and could find that most of the GET and. HEAD request to the URL  https://preview.spendhq.com:443/ HTTP/1.1 Got response of 302 and the request processing time for this request is greater than 30 seconds.Most of the 403 responses are written for the POST request and GET request to the URL  http://34.203.134.80:80/yumo.php HTTP/1.1. and POST http://54.236.182.171:80/confg.php HTTP/1.1I also checked with the source IPs of this request and could not find any abusive IP other than that we have blocked.The Site  loading fine for last 3 hours C02XH05GJG5M:spendhq niali$  for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\n https://preview.spendhq.com/ -so /dev/null; doneHTTPCode=302 TotalTime=1.832945HTTPCode=302 TotalTime=1.510947HTTPCode=302 TotalTime=1.682051HTTPCode=302 TotalTime=1.557859HTTPCode=302 TotalTime=1.649216HTTPCode=302 TotalTime=1.685778C02XH05GJG5M:spendhq niali$ Can you please have a look at this to this as we cannot find anything other than the latency issue and request count spike at the time of alert.Thanks,the site is still down and we have muted it.Rohit is checking for the fix. Please check with him once.,"Hello Team,We have checked the logs for last 5 hours logs(8:00 am ist to 7:00 am ist). the total 4xx request count was 671. Please find the abusive IP and the request count. We have blocked these IPs from the NACL level as they are abusive.Also, attached the total ELB logs in the attachment for your reference.123.206.210.160Count: 330ISP: Tencent Cloud Computing (Beijing) Co. Ltd.Usage Type: Data Center/Web Hosting/TransitDomain Name: UnknownCountry: ChinaCity: Beijing, Beijing129.204.161.184Count: 328ISP: Tencent Cloud Computing (Beijing) Co. LtdUsage Type: Data Center/Web Hosting/TransitDomain Name: UnknownCountry: ChinaCity: Beijing, Beijing66.240.205.34Count: 5ISP: CARInet Inc.Usage Type: Data Center/Web Hosting/TransitHostname(s): malware-hunter.census.shodan.io Domain Name: UnknownCountry: United StatesCity: San Diego, California122.224.158.196Count: 2ISP: Fuyang Yinhu Gaoqiao Primary schoolUsage Type: University/College/SchoolDomain Name: UnknownCountry: ChinaCity: Gaoqiao, Liaoning60.191.20.210Count: 1ISP: Hangzhou BoKe Information Technology LTDUsage Type: CommercialDomain Name: UnknownCountry: ChinaCity: Hangzhou, ZhejiangPlease review this details and revert back to us in case of any queries.","Hello Matthew,We haven't heard back from you since our last communication on this case.Kindly review the details we shared and let us know if you have any questions or concerns.Thanks","Hello,From what we could gather, CPU and memory utilization on the particular instance was normal at our time of checking. [root@ip-10-59-100-170 logs]# sh cpu.sh Load Average of the System 0.10, 0.03, 0.00",,,,,,,,,,,,,,,,Processes with highest CPU usage,,,,,,,,,,,,,,,,"USER PID PPID CMD %CPU root 17441 1 /usr/bin/python /usr/bin/su 0.4 apache 10445 16728 /usr/sbin/httpd 0.1 apache 10728 16728 /usr/sbin/httpd 0.1 apache 11645 16728 /usr/sbin/httpd 0.1 apache 14052 16728 /usr/sbin/httpd 0.1 apache 14992 16728 /usr/sbin/httpd 0.1 [root@ip-10-59-100-170 logs]# sh memory.sh USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND clam 1689 0.0 4.0 774784 617356 ? Ssl 2018 45:40 clamd root 1894 0.0 0.2 1245312 44884 ? Sl 2018 68:58 node logiApplicationService.js --disableSchemaValidation apache 10445 0.1 0.2 404616 42904 ? S 02:02 0:36 /usr/sbin/httpd apache 17692 0.1 0.2 404396 42660 ? S 07:22 0:13 /usr/sbin/httpd apache 16623 0.1 0.2 404336 42608 ? S 06:23 0:15 /usr/sbin/httpd apache 16236 0.1 0.2 404312 42588 ? S 06:01 0:19 /usr/sbin/httpd Looking at the ELB access logs (for both 4xx and 5xx), we have analyzed the logs over multiple timeframes, but could not see any reported for the preview-spendhq-xelb.We also verified the total request processing time and found it to be around 120 seconds:[root@ip-10-59-100-170 httpd]# for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://preview.spendhq.com/login -so /dev/null; done HTTPCode=200 TotalTime=120.685 Client connections [root@ip-10-59-100-170 httpd]# ps aux | grep httpd | wc -l 67Thanks.","Hello Matt,Sure thing. We will be sharing the full details with you shortly.Thanks.","[Via Mail]This is a non-production machine so there is no need to onboard. Can you provide a little more information as to what is going on?Matthew Watts | Manager, Application Development | SpendHQ®","Hello Team,For the past two days we've been receiveing a lot of latency related alerts in regards to this case. Could you be performing some action (copying/deployment) from your end that might be causing this?Also, we can see that the backend instance (10.59.100.170) is not under REAN monitoring. Would you like for us to on-board it for monitoring?Do let us know.Thanks.","Hello Team,We have again reviewed the following metrics to understand the issue.1. CPU utilization2. Memory Utilization3. Apache logs4. ELB access logs 4xx and 5xx1. CPU utilization on the backend instance i-0f36027c388e7a563 : Preview Web[root@ip-10-59-100-170 logs]# sh cpu.shLoad Average of the System0.10, 0.03, 0.00",,,,,,,,,,,,,,,,Processes with highest CPU usage,,,,,,,,,,,,,,,,"USER       PID  PPID CMD                         %CPUroot     17441     1 /usr/bin/python /usr/bin/su  0.4apache   10445 16728 /usr/sbin/httpd              0.1apache   10728 16728 /usr/sbin/httpd              0.1apache   11645 16728 /usr/sbin/httpd              0.1apache   14052 16728 /usr/sbin/httpd              0.1apache   14992 16728 /usr/sbin/httpd              0.1apache   16236 16728 /usr/sbin/httpd              0.1apache   16621 16728 /usr/sbin/httpd              0.1apache   16622 16728 /usr/sbin/httpd              0.1apache   16623 16728 /usr/sbin/httpd              0.1CPU usage is vey low 2.Memory Utilization on the backend instance i-0f36027c388e7a563 : Preview WebBy using DevOps script==================[root@ip-10-59-100-170 logs]# sh memory.shUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDclam      1689  0.0  4.0 774784 617356 ?       Ssl   2018  45:40 clamdroot      1894  0.0  0.2 1245312 44884 ?       Sl    2018  68:58 node logiApplicationService.js --disableSchemaValidationapache   10445  0.1  0.2 404616 42904 ?        S    02:02   0:36 /usr/sbin/httpdapache   17692  0.1  0.2 404396 42660 ?        S    07:22   0:13 /usr/sbin/httpdapache   16623  0.1  0.2 404336 42608 ?        S    06:23   0:15 /usr/sbin/httpdapache   16236  0.1  0.2 404312 42588 ?        S    06:01   0:19 /usr/sbin/httpdapache   16622  0.1  0.2 404312 42588 ?        S    06:23   0:16 /usr/sbin/httpdapache   17023  0.1  0.2 404028 42308 ?        S    06:46   0:14 /usr/sbin/httpdapache   10728  0.1  0.2 403788 42144 ?        S    02:16   0:34 /usr/sbin/httpdapache   11645  0.1  0.2 403800 42100 ?        S    03:02   0:30 /usr/sbin/httpdThe memory is too low by seeing the above output. But while checking the free -m command we command see that the total 14g is consumed.[root@ip-10-59-100-170 logs]# free -m             total       used       free     shared    buffers     cachedMem:         14938      14345        593          0        210       4134-/+ buffers/cache:      10000       4938Swap:            0          0          0We witnessed this is an issue related to memory.3. Apache logswe checked the /var/www/vhosts/files.spendhq.com/w2/logs/ there is no error logs reported from 31st of Dec.4. ELB access logs 4xx and 5xxWe have checked the logs in multiple time frames from the time of issue till now. We didn't see any 5xx or 4xx logs for the ELB preview-spendhq-xelb.Backend instance and ELB details==========================ELB Details: ----------- Name: preview-spendhq-xelb DNS Name: preview-spendhq-xelb-520312558.us-east-1.elb.amazonaws.com Type: Classic Scheme: internet-facing Availability Zones: subnet-01596c2a - us-east-1b, subnet-acbb09e7 - us-east-1c VPC: vpc-76df7212 Instance ID : i-0f36027c388e7a563Instance Name : Preview WebPrivate Ip : 10.59.100.170Note : This instance is not having monitoring tag and not listing in the datdog,","Hello Team,I have checked with Rohit on this and he mentioned he will check and update the case.","Hello Rohit,We have again verified the total time of the request is 120 seconds please review the details below and earlier comments and recommend a solution to get rid of the latency issue. [root@ip-10-59-100-170 httpd]# for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://preview.spendhq.com/login -so /dev/null; doneHTTPCode=200 TotalTime=120.685Client connections[root@ip-10-59-100-170 httpd]# ps aux | grep httpd | wc -l67","Hello Team,We again received the site down alert for the URL https://preview.spendhq.com/login. The site is not actually down it is loading with high latency. As we have shared the details in the earlier comments please review and let us know if you have any further queries.Meanwhile, we will check internally on this issue and will get back to you with an update.","Hello Rohit,Team has already shared the analysis with the customer. Kindly check and let us know if there is anything pending on this case, otherwise we can move it to confirmation",@TeamThe Total Downtime is 12 hours 1 minute.,"Hello Teamon further analysis, from the ELB logs, we could see that the there is a high backend processing time at the time of the alert, The value trigered between  60 and 120 seconds at the time of the alert.======backend_processing_time	response_processing_time	elb_status_code	backend_status_code	received_bytes	sent_bytes	request  60.211326	0.000046	302	302	0	0	HEAD https://preview.spendhq.com:443/ HTTP/1.160.198925	0.000048	302	302	0	0	HEAD https://preview.spendhq.com:443/ HTTP/1.1120.607944	0.000048	200	200	0	8833	GET https://preview.spendhq.com:443/login HTTP/1.160.211694	0.000047	302	302	0	0	HEAD https://preview.spendhq.com:443/ HTTP/1.1120.706341	0.000054	200	200	0	8836	GET https://preview.spendhq.com:443/login HTTP/1.1120.589438	0.000048	200	200	0	8833	GET https://preview.spendhq.com:443/login HTTP/1.1=========We had also checked with the current  response time of the URL and with the response code and we could see that it's working fine and loading within in 2 seconds and getting 200 response code----Testing Website Response Time for :https://preview.spendhq.com/loginLookup Time:		0.132320Connect Time:		0.134056AppCon Time:		1.323512Redirect Time:		0.000000Pre-transfer Time:	1.323595Start-transfer Time:	1.650112Total Time:		1.650146--------Response Code HTTPCode=200 TotalTime=1.914690 HTTPCode=200 TotalTime=1.726068 HTTPCode=200 TotalTime=1.772125 HTTPCode=200 TotalTime=1.766357 HTTPCode=200 TotalTime=1.768367 HTTPCode=200 TotalTime=1.751918-----------Kindly check with the attached logs at the time of alert and Let us know if you have any queries.Thanks",Hello TeamThis is to inform you that the URL https://preview.spendhq.com/login is loading fine without latency. So we have unmuted it and enabled monitoring again.Thanks,"Hello Team,This is to inform you that we are currently muted the URL : https://preview.spendhq.com/login from our monitoring as the site takes more time to load and we can only add the Max Timeout to 60s.But we are keeping an Eye on the URL.Adding the high memory Consuming on the instance is  httpd [root@ip-10-59-100-170 centos]# ps aux  | awk '{print $6/1024  MB\\t\\t $11}'  | sort -nr602.758 MB		clamd40.9453 MB		/usr/sbin/httpd40.6992 MB		/usr/sbin/httpd39.7109 MB		/usr/sbin/httpd39.7031 MB		/usr/sbin/httpd39.6836 MB		/usr/sbin/httpd39.4883 MB		/usr/sbin/httpd38.5898 MB		/usr/sbin/httpd38.4414 MB		/usr/sbin/httpdAnd there was a open files  of lsof | grep httpd | wc -l8404and most of the File descriptors are memory mapped to the /usr/sbin/httpdPlease let us know you update.Thank you",I muted the Wormly URL as it taking more time to load the site and we receiving multiple alerts.and increased the timeout 60 for also.please change the value and disable the alert once it is resolved,"Matthew Watts1:49 PM (0 minutes ago)to Rean, spendhq-support@reancloud.comI will review, thank you.","Hi Cc, Below are the details I found on checking traceroute preview.spendhq.comtraceroute to preview.spendhq.com (54.236.182.171), 30 hops max, 60 byte packets 1  10.59.1.192 (10.59.1.192)  0.453 ms  0.421 ms  0.429 ms 2  216.182.226.82 (216.182.226.82)  17.027 ms 216.182.226.86 (216.182.226.86)  12.265 ms 216.182.226.82 (216.182.226.82)  17.017 ms 3  * * * 4  * * * 5  * * * 6  * * * 7  * * * 8  * * * 9  * * *10  * * *11  * * *12  * * *13  * * *14  * * *15  * * *16  * * *17  * * *18  * * *19  * * *20  * * *21  * * *22  * * *23  * * *24  * * *25  * * *26  * * *27  * * *28  * * *29  * * *30  * * *------[root@ip-10-59-100-170 log]# for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n http://preview.spendhq.com/ -so /dev/null; doneHTTPCode=301 TotalTime=0.024HTTPCode=301 TotalTime=0.007HTTPCode=301 TotalTime=0.005HTTPCode=301 TotalTime=0.005HTTPCode=301 TotalTime=0.005HTTPCode=301 TotalTime=0.005-------[root@ip-10-59-100-170 log]# curl -Ik  http://preview.spendhq.com/HTTP/1.1 301 Moved PermanentlyContent-Type: text/html; charset=iso-8859-1Date: Tue, 01 Jan 2019 08:00:46 GMTLocation: https://preview.spendhq.com/Server: ApacheConnection: keep-alive-----[root@ip-10-59-100-170 log]# cat httpd/error_log[Sun Dec 30 03:35:08 2018] [notice] Digest: generating secret for digest authentication ...[Sun Dec 30 03:35:08 2018] [notice] Digest: done[Sun Dec 30 03:35:08 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Sun Dec 30 03:35:08 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations[root@ip-10-59-100-170 log]# -----------preview DB [root@ip-10-59-10-135 log]# cat messages Jan  1 02:00:01 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)---Sophos instnces httpd.log 2019:01:01-02:15:55 spendhq httpd: 74.207.230.51 - - [01/Jan/2019:02:15:55 +0000] GET / HTTP/1.1 200 108862019:01:01-02:16:32 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:29 +0000] GET / HTTP/1.1 200 2467252019:01:01-02:16:33 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:33 +0000] GET /core/css/default.css HTTP/1.1 200 6882019:01:01-02:16:34 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:34 +0000] GET /core/css/elements.css HTTP/1.1 200 4032019:01:01-02:16:34 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:34 +0000] GET /core/css/astaro.css HTTP/1.1 200 8342019:01:01-02:16:34 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:34 +0000] GET /core/css/wizard.css HTTP/1.1 200 8632019:01:01-02:16:34 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:34 +0000] GET /core/js/core-9.50.min.js HTTP/1.1 200 1987022019:01:01-02:16:34 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:34 +0000] GET /wfe/asg/js/app-9.50.min.js HTTP/1.1 200 476062019:01:01-02:16:35 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:35 +0000] GET /core/img/blank1x1.gif HTTP/1.1 200 682019:01:01-02:16:35 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:35 +0000] GET /wfe/asg/img/flow_monitor/fm-icon-block.png HTTP/1.1 200 7202019:01:01-02:16:35 spendhq httpd: 10.242.2.3 - - [01/Jan/2019:02:16:35 +0000] GET Cloud Watch metrichttps://console.aws.amazon.com/cloudwatch/home?region=us-east-1#metricsV2:graph=~(metrics~(~(~'AWS*2fELB~'Latency~'LoadBalancerName~'preview-spendhq-xelb~(period~300~stat~'Sum))~(~'.~'RequestCount~'.~'.~(stat~'Sum~period~300))~(~'.~'HTTPCode_Backend_4XX~'.~'.~(period~300~stat~'Sum)))~view~'timeSeries~stacked~true~region~'us-east-1~start~'-PT12H~end~'P0D~title~'SHQ-Metric-site-Down);namespace=~'AWS*2fELB;dimensions=~'LoadBalancerName","Hello Team,On further Checking, we can see the Load balancer  preview-spendhq-xelb  has a sudden spike in latency with 2410241.200250626 and high request count of 167 and there was a spike in 2xx Count.Other than we checked the backend instance we couldn't find any error logs. The time wait and established at the connection backend web server is 95 and 25.[centos@ip-10-59-100-170 ~]$ netstat | grep TIME_WAIT | wc -l    25     [centos@ip-10-59-100-170 ~]$ netstat | grep ESTABLISHED | wc -l91the memory of web server   is 937 available [root@ip-10-59-100-170 log]# free -m             total       used       free     shared    buffers     cachedMem:         14938      14000        937          0        210       4457-/+ buffers/cache:       9332       5606Swap:            0          0          0---Also, we checked the backend Database and we couldn't find any error logs other than  Jan  1 02:10:00 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)  The Cpu utilization  on the preview web server and preview DB are normal but there is a spike in N/w in  on preview DB(461381), preview web( 82456858 ) and N/w out on preview web(9788468), preview DB(519445) We are attaching the Screenshot of the Details in the attachment section.Note: Currently also the site is taking more time to load but it is accessible. We are analyzing the ELB Access logs and share with you shorlty.ELB Details: ----------- Name: preview-spendhq-xelb DNS Name: preview-spendhq-xelb-520312558.us-east-1.elb.amazonaws.com Type: Classic Scheme: internet-facing Availability Zones: subnet-01596c2a - us-east-1b, subnet-acbb09e7 - us-east-1c VPC: vpc-76df7212 ----------- Backend Instance Details: ------------------------- Name: Preview DB Instance ID: i-008d43ad00357e47a Availability Zone: us-east-1b Private IP: 10.59.10.135 VPC ID: vpc-76df7212 ------------------------- Name: Preview WEb Instance ID:i-0f36027c388e7a563Availability Zone: us-east-1b Private IP: 10.59.100.170VPC ID: vpc-76df7212 Thanks","Hello Team,The site is still accessible but it taking a long time to load the page.From Wormly, we could see requests timing out after Operation timed out after 9000 milliseconds with 0 bytes being received at the time. And from the preview-spendhq-xelb load balancer, we can see high latency of   2410247.220We are further checking on this and update you.Regards","Hello Team,This is to inform we received a site down alert for URL: https://preview.spendhq.com/login On further Checking, we can the site is accessible at the time but it taking a long time to load the desired page.We are checking further on this and we will let you know the update.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BYW1K,Cloud Engineer Level 1,Closed,1051375,Incident,03-05-2017 19:53,,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Matthew updated that,We have resolved the issue. We can close the case. The issue was the restrictions on our firewall on this end.###Hello Matthew,Thanks for the update. We will be sharing the bridge details before 11 AM EST on 3rd May 2017.Regards,Safuvan KM###Matthew Watts3:28 AM (4 minutes ago)to Rean, spendhq-support I have availability at 1100 Hours EST tomorrow.###Hello Matthew,I verified it is loading for us with&without VPN. Please refer the attachment section for the screenshot.Please let me know your availability to get on a call to discuss this.Regards,Safuvan KM###Matthew WattsAttachments3:03 AM (7 minutes ago)to Praveen, Rean Here is a screenshot of the result;###Matthew Watts3:01 AM (10 minutes ago)to Praveen, Rean The following link does not resolve anything. Have you verified this inside and outside  the VPN?; http://preview.spendhq.com:8080###Praveen Kumar Muppala2:58 AM (11 minutes ago)to Matthew, Rean Hello Matthew, The 8080 port is working as expected and 8443 is throwing an error called “EMPTY_RESPONSE” and we are sure application is not configured to handle the 8443. Is there something else are you looking here. If needed, we can get on a call to understand the issue better. Regards,-Praveen###Hello Matthew,We are still analyzing the port forwarding issue. Will revert back to you with the updates ASAP.Regards,Safuvan KM###Matthew Watts2:13 AM (4 minutes ago)to Rean Can we have an update to the ticket that was submitted this morning regarding the port access as this still does not appear to be working.###We have checked it from our side and we were able to access preview.spendhq.com:8080. and preview.spendhq.com:8443 was not accessible earlier also but Matthew updated that it was the desired outcome.###Hello Matthew,We will look into this issue and get back to you with the updates.","You had enabled the tomcat port late last week (8080 and 8443) however traffic is no longer being forwarded to this server. Can we please investigate.Matthew Watts | Manager, Application Development | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Port Forwarding,,02-05-2017 19:26,24,0,SpendHQ,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Matthew updated that,We have resolved the issue. We can close the case. The issue was the restrictions on our firewall on this end.","Hello Matthew,Thanks for the update. We will be sharing the bridge details before 11 AM EST on 3rd May 2017.Regards,Safuvan KM","Matthew Watts3:28 AM (4 minutes ago)to Rean, spendhq-support I have availability at 1100 Hours EST tomorrow.","Hello Matthew,I verified it is loading for us with&without VPN. Please refer the attachment section for the screenshot.Please let me know your availability to get on a call to discuss this.Regards,Safuvan KM","Matthew WattsAttachments3:03 AM (7 minutes ago)to Praveen, Rean Here is a screenshot of the result;","Matthew Watts3:01 AM (10 minutes ago)to Praveen, Rean The following link does not resolve anything. Have you verified this inside and outside  the VPN?; http://preview.spendhq.com:8080","Praveen Kumar Muppala2:58 AM (11 minutes ago)to Matthew, Rean Hello Matthew, The 8080 port is working as expected and 8443 is throwing an error called “EMPTY_RESPONSE” and we are sure application is not configured to handle the 8443. Is there something else are you looking here. If needed, we can get on a call to understand the issue better. Regards,-Praveen","Hello Matthew,We are still analyzing the port forwarding issue. Will revert back to you with the updates ASAP.Regards,Safuvan KM",Matthew Watts2:13 AM (4 minutes ago)to Rean Can we have an update to the ticket that was submitted this morning regarding the port access as this still does not appear to be working.,We have checked it from our side and we were able to access preview.spendhq.com:8080. and preview.spendhq.com:8443 was not accessible earlier also but Matthew updated that it was the desired outcome.,"Hello Matthew,We will look into this issue and get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FdepI,Cloud Engineer Level 2,Closed,1073011,Incident,17-08-2017 17:31,,"Hello SpendHQ-Team,Do we have any updates on this case?We have already shared the RCA for the outage happened for Secure on 11th Aug 2017. Kindly validate the RCA and let us know if your team have any further queries regarding this case.As of now, we are marking this case as resolved. Revert back in case of any further queries regarding this case.Regards,Sumod.K.Bose###Next Action: Evening Shift: Send a reminder to the customer to review the RCA.###We haven't heard back from you regarding the case for a while.Please review the RCA document attached with the ticket and let us know if you require the instance type upgrade as mentioned in the RCA as the prevention recommendation.Please revert back to us in the case of further queries.Thank You,Safuvan KM###Hello Team,We have prepared the RCA for SpendHQ outage and it is attached to the attachment section.Kindly validate the details and let us know if you want us to change the instance type. Please revert back to us in case of further queries.###Yogesh will update the RCA with the analysis he performed. Please reach out to Yogesh for further updates.###We had a call with Matthew and updated the secure site down issues. He informed us that he'll review our findings and update the ticket.###Had a call with Yogesh and he updated that he will work on it today.###Hello SpendHQ Team,On initial analysis, we could see that there was a hike in CPU/ Network graphs.We have included the graph in attachment section.Please let us know if you are still performing any activity from your side. Our monitoring tool triggered alert  due to operation timeout due to high latency at ELB level and the site was  accessible for us at the time of alert.Let us know if you have any queries or concerns regarding this.###Hello Team, This is to notify you that we got an alert regarding site down for URL: https://secure.spendhq.com/login . The site was accessible at the time of the alert and got recovered in 2 minutes. We will analyze more on this and let you know the updates. Meanwhile, let us know if you have any queries.###We have prepared the RCA and shared with Yogesh for review. As discussed in Morning ops call Yogesh will check further on this and he will make a call to SpendHQ team. Assigning the ticket with Yogesh.###Please see the RCA link: https://docs.google.com/document/d/1xWaGAj2TmZv3USbBgoTbOrh6_dfk8uiQVIXZuUdtLYE/edit#Please review the RCA with Yogesh. Need to complete the Preventive Actions. for that, we need a confirmation from spend-HQ Team(Andrew) regarding that this is a part of maintenance or not.Previously we have a site down for this same URL on 11th August (01072803). The outage was reported because of the high latency on the application due to the high network traffic on the DB node. And we got a confirmation from Andrew that high network traffic was caused by internal processes and this will be continuing to perform on off-hours.In this case, we have informed all the details and waiting for a reply that if this was a part of their maintenance or not. Because of this, we are not providing the Preventive actions.Based on the reply from the spend-HQ team, We need provide the recommendation.###+++Internal Comment+++We have contacted Yogesh for reviewing the analysis done in this case. He mentioned that he will review it meanwhile start working on the RCA based on the analysis done so far.We have started working on the RCA.RCA Link: https://docs.google.com/document/d/1xWaGAj2TmZv3USbBgoTbOrh6_dfk8uiQVIXZuUdtLYE/edit###Hello SpendHQ-Team,Did you get a chance to review the analysis that has been performed regarding the outage happened on secure.spendhq.com?Kindly validate these details and let us know if your team have any further queries regarding this case. As of now, we are working on the RCA for this outage and will be sharing the report with your team once we are done with it.Regards,Sumod.K.Bose###We have informed Yogesh to review the comments. After that we haven't heard from him. We tried to reach but not reachable.Next action: check with Yogesh in afternoon.###Next Action: Morning Shift: Call the CC and get these analysis reviewed to start the RCA document. To finish the RCA, we would require an update from SpendHQ Andromeda team whether there were any issues from their end with the iSCSI volumes/connection.###As the instance met the maximum resource utilization, it was unable to process the DB connection requests from the web server properly so, we witnessed multiple connections in the TIME_WAIT state. That caused to a high latency over the application. Please let us know if there were any scheduled iSCSI activities in the DB instance that may have lead to this incident. Please have a look at the iSCSI volume activity details during the time and let us know if there were anything suspicious. Please refer these details and feel free to reach out to us if you have any queries. Thank You, Safuvan KM###We are concluding the root cause analysis here. Please find out the complete analysis report below.By analyzing the Secure-SpendHQ-ELB ELB access logs for 30 minutes around the time of the incident, we sorted out 134 requests with 502 response code as well as the Response Processing Time more than 300 seconds. That means the requests were accepted by the application back-end instance but the response processing was taking too much time and then dropped the requests with a 502 response code.HTTP Response Code 502 Bad gateway: Backend server is failing/overloaded.Note: The REAN end point monitoring tool reported the outage because of no response was received within 30 seconds of time and the requests were also dropped with a 502 response code. Please visit the attachment section for the load balancer access logs with 502 response code. Please refer the attached Wormly monitoring tool logs with error response Operation timed out.Analyzed and confirmed the back-end web server PROD-SPHQ-WEB-SERVER03_2nd_August_2017 (10.59.100.170) resource utilization statistics doesn't have any abnormal spikes. By analyzing the back-end DB server PROD-SPHQ-DB-SERVER05 (10.59.10.135) resource utilization statistics, we witnessed a considerable spike in the CPU Utilization, Network IN&OUT Utilization, Memory Utilization, and Disk Utilization statistics.CPU Utilization: Reached 100% during the time of the alert.Network IN: The network inbound traffic was 5068.3 MB/min i.e., 84.5 MB/s.Network Out: The network outbound traffic was 7643.3 MB/min i.e., 127.4 MB/s.Memory Usage: From the DataDog graph, we witnessed a spike in the Memory usage, reached 148.52 GB out of 240 GB.Disk Utilization: From the DataDog graph, we witnessed a spike in the disk utilization for the iSCSI volume /dev/sdb mounted to /mnt/production_10-06-2017 directory.Please refer the attachment section for the graph details for the above-mentioned matrices.Investigated further from the back-end DB instance level using atop and sar tools to find the process details consumed high CPU resource during the time of the incident, we figured out that the ksoftirqd/0 process was consuming high CPU during the time of the alert. ksoftirqd is related to the IRQs (interrupt requests) which is used by the computer to communicate with the devices attached to it. When an interrupt comes from a device, the operating system pauses what it was doing and starts addressing that interrupt.In our case, IRQs was coming very very fast one after the other and the operating system could not finish servicing one before another one arrives. This was because of a very large number of packets received in a short time frame to the network card (It is already visible in the instance's network traffic statistics).Because the operating system cannot handle IRQs as they arrive (because they arrive too fast one after the other), the operating system queues them for later processing using the process ksoftirqd.If ksoftirqd is taking more than a tiny percentage of CPU time, this indicates the machine is under heavy interrupt load.As we witnessed a spike in the disk utilization for the iSCSI volume /dev/sdb which is mounted to /mnt/production_10-06-2017 directory, the network traffic should have been related to the iSCSI and AWS Direct Connect.Note: The iSCSI volume usage increased by 55.3 GB during the time of the alert.In order to confirm the iSCSI data transfer, we have analyzed the AWS Direct Connect resource usage statistics and witnessed there was a considerable spike in the ConnectionBpsEgress, ConnectionBpsIngress, ConnectionPpsEgress, and ConnectionPpsIngress statistics. For more details related to these metrics, please refer the AWS Documentation http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/dx-metricscollected.htmlPlease refer the attachment section for more details.++++++++++TBC+++++++++++###Hello SpendHQ-Team,On further analysis, we were able to figure out that during the time of this alert, the ELB was experiencing high latency caused due to the spike in the CPU Load of the backend database instance. The CPU usage on this instance was at 100% at the time of this issue. Also, we could see that multiple requests were served with 5XX response code during this time.From the instance level, we could see that there were nearly 1015 active connections on which 471 connections were in the TIME_WAIT state. We are currently analyzing more on this issue related to all of these metrics and will revert back to you with the updates once we are done with the investigation.Kindly validate these details and revert back in case of any further queries.Regards,Sumod.K.Bose###Next action - Need to reach out to Yogesh and send a recommendation to the customer and work on RCA.###From the analysis, i could see that 98% of the time this error comes from loading more into memory than what you set up PHP to handle in one process. There are other causes, but these are much less common very rarely it can be a memory leak if we're on PHP 5.3 and above.The prod server is using PHP version 5.6.30 for now.The memory limit is also set to 2041 MB currently.###Hello SpendHQ Team,From our analysis, We could see that there were total 1015 active connections during the time of alert out of which 130 were in the closed wait state,471 in Time wait for state and 298 were in Established state.From We also received an alert for high process count on the server which exceeded a threshold value of 30 with a value of 60.Please find the netstat output mentioned below:[root@ip-10-59-100-170 httpd]# netstat | wc -l1015[root@ip-10-59-100-170 httpd]# netstat | grep CLOSE_WAIT | wc -l130[root@ip-10-59-100-170 httpd]# netstat | grep TIME_WAIT | wc -l471[root@ip-10-59-100-170 httpd]# netstat | grep ESTABLISHED | wc -l298We have also checked the PHP fatal error logs and found the following logs at the time of alert:[Sat Aug 12 02:40:57 2017] [error] [client 10.59.1.192] PHP Fatal error:  Allowed memory size of 2147483648 bytes exhausted (tried to allocate 72 bytes) in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 503, referer: https://secure.spendhq.com/spend-visibility[Sat Aug 12 02:46:20 2017] [error] [client 10.59.1.192] SHQ_Exception: [11]: New Table Mapper version for company_db isg_cushmanw is 32 in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/super_admin_controller.php on line 3345 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/[Sat Aug 12 02:46:20 2017] [error] [client 10.59.1.192] PHP Deprecated:  Non-static method Inflector::slug() should not be called statically, assuming $this from incompatible context in /var/www/vhosts/secure.spendhq.com/public/cake/dispatcher.php on line 530, referer: https://secure.spendhq.com/super_admin/manage_company/We are analysing more on this issue.Please let us know if you have any further queries regarding this.###Hello Matthew,This is to notify you that we got an alert regarding site down for URL: https://secure.spendhq.com/login . The alert got resolved automatically and resolved within 5 minutes. We could see there was high cpu load on the database instance and a high number of process count on web instance.As discussed with you on call, we will perform analysis on the issue and let you know the update.","Fri, 11 Aug 2017 22:52:16 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30002 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Atlanta-B US, Dallas-B US, California US, Sydney-C AU-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,12-08-2017 08:22,129,0,SpendHQ,"Hello SpendHQ-Team,Do we have any updates on this case?We have already shared the RCA for the outage happened for Secure on 11th Aug 2017. Kindly validate the RCA and let us know if your team have any further queries regarding this case.As of now, we are marking this case as resolved. Revert back in case of any further queries regarding this case.Regards,Sumod.K.Bose",Next Action: Evening Shift: Send a reminder to the customer to review the RCA.,"We haven't heard back from you regarding the case for a while.Please review the RCA document attached with the ticket and let us know if you require the instance type upgrade as mentioned in the RCA as the prevention recommendation.Please revert back to us in the case of further queries.Thank You,Safuvan KM","Hello Team,We have prepared the RCA for SpendHQ outage and it is attached to the attachment section.Kindly validate the details and let us know if you want us to change the instance type. Please revert back to us in case of further queries.",Yogesh will update the RCA with the analysis he performed. Please reach out to Yogesh for further updates.,We had a call with Matthew and updated the secure site down issues. He informed us that he'll review our findings and update the ticket.,Had a call with Yogesh and he updated that he will work on it today.,"Hello SpendHQ Team,On initial analysis, we could see that there was a hike in CPU/ Network graphs.We have included the graph in attachment section.Please let us know if you are still performing any activity from your side. Our monitoring tool triggered alert  due to operation timeout due to high latency at ELB level and the site was  accessible for us at the time of alert.Let us know if you have any queries or concerns regarding this.","Hello Team, This is to notify you that we got an alert regarding site down for URL: https://secure.spendhq.com/login . The site was accessible at the time of the alert and got recovered in 2 minutes. We will analyze more on this and let you know the updates. Meanwhile, let us know if you have any queries.",We have prepared the RCA and shared with Yogesh for review. As discussed in Morning ops call Yogesh will check further on this and he will make a call to SpendHQ team. Assigning the ticket with Yogesh.,"Please see the RCA link: https://docs.google.com/document/d/1xWaGAj2TmZv3USbBgoTbOrh6_dfk8uiQVIXZuUdtLYE/edit#Please review the RCA with Yogesh. Need to complete the Preventive Actions. for that, we need a confirmation from spend-HQ Team(Andrew) regarding that this is a part of maintenance or not.Previously we have a site down for this same URL on 11th August (01072803). The outage was reported because of the high latency on the application due to the high network traffic on the DB node. And we got a confirmation from Andrew that high network traffic was caused by internal processes and this will be continuing to perform on off-hours.In this case, we have informed all the details and waiting for a reply that if this was a part of their maintenance or not. Because of this, we are not providing the Preventive actions.Based on the reply from the spend-HQ team, We need provide the recommendation.",+++Internal Comment+++We have contacted Yogesh for reviewing the analysis done in this case. He mentioned that he will review it meanwhile start working on the RCA based on the analysis done so far.We have started working on the RCA.RCA Link: https://docs.google.com/document/d/1xWaGAj2TmZv3USbBgoTbOrh6_dfk8uiQVIXZuUdtLYE/edit,"Hello SpendHQ-Team,Did you get a chance to review the analysis that has been performed regarding the outage happened on secure.spendhq.com?Kindly validate these details and let us know if your team have any further queries regarding this case. As of now, we are working on the RCA for this outage and will be sharing the report with your team once we are done with it.Regards,Sumod.K.Bose",We have informed Yogesh to review the comments. After that we haven't heard from him. We tried to reach but not reachable.Next action: check with Yogesh in afternoon.,"Next Action: Morning Shift: Call the CC and get these analysis reviewed to start the RCA document. To finish the RCA, we would require an update from SpendHQ Andromeda team whether there were any issues from their end with the iSCSI volumes/connection.","As the instance met the maximum resource utilization, it was unable to process the DB connection requests from the web server properly so, we witnessed multiple connections in the TIME_WAIT state. That caused to a high latency over the application. Please let us know if there were any scheduled iSCSI activities in the DB instance that may have lead to this incident. Please have a look at the iSCSI volume activity details during the time and let us know if there were anything suspicious. Please refer these details and feel free to reach out to us if you have any queries. Thank You, Safuvan KM","We are concluding the root cause analysis here. Please find out the complete analysis report below.By analyzing the Secure-SpendHQ-ELB ELB access logs for 30 minutes around the time of the incident, we sorted out 134 requests with 502 response code as well as the Response Processing Time more than 300 seconds. That means the requests were accepted by the application back-end instance but the response processing was taking too much time and then dropped the requests with a 502 response code.HTTP Response Code 502 Bad gateway: Backend server is failing/overloaded.Note: The REAN end point monitoring tool reported the outage because of no response was received within 30 seconds of time and the requests were also dropped with a 502 response code. Please visit the attachment section for the load balancer access logs with 502 response code. Please refer the attached Wormly monitoring tool logs with error response Operation timed out.Analyzed and confirmed the back-end web server PROD-SPHQ-WEB-SERVER03_2nd_August_2017 (10.59.100.170) resource utilization statistics doesn't have any abnormal spikes. By analyzing the back-end DB server PROD-SPHQ-DB-SERVER05 (10.59.10.135) resource utilization statistics, we witnessed a considerable spike in the CPU Utilization, Network IN&OUT Utilization, Memory Utilization, and Disk Utilization statistics.CPU Utilization: Reached 100% during the time of the alert.Network IN: The network inbound traffic was 5068.3 MB/min i.e., 84.5 MB/s.Network Out: The network outbound traffic was 7643.3 MB/min i.e., 127.4 MB/s.Memory Usage: From the DataDog graph, we witnessed a spike in the Memory usage, reached 148.52 GB out of 240 GB.Disk Utilization: From the DataDog graph, we witnessed a spike in the disk utilization for the iSCSI volume /dev/sdb mounted to /mnt/production_10-06-2017 directory.Please refer the attachment section for the graph details for the above-mentioned matrices.Investigated further from the back-end DB instance level using atop and sar tools to find the process details consumed high CPU resource during the time of the incident, we figured out that the ksoftirqd/0 process was consuming high CPU during the time of the alert. ksoftirqd is related to the IRQs (interrupt requests) which is used by the computer to communicate with the devices attached to it. When an interrupt comes from a device, the operating system pauses what it was doing and starts addressing that interrupt.In our case, IRQs was coming very very fast one after the other and the operating system could not finish servicing one before another one arrives. This was because of a very large number of packets received in a short time frame to the network card (It is already visible in the instance's network traffic statistics).Because the operating system cannot handle IRQs as they arrive (because they arrive too fast one after the other), the operating system queues them for later processing using the process ksoftirqd.If ksoftirqd is taking more than a tiny percentage of CPU time, this indicates the machine is under heavy interrupt load.As we witnessed a spike in the disk utilization for the iSCSI volume /dev/sdb which is mounted to /mnt/production_10-06-2017 directory, the network traffic should have been related to the iSCSI and AWS Direct Connect.Note: The iSCSI volume usage increased by 55.3 GB during the time of the alert.In order to confirm the iSCSI data transfer, we have analyzed the AWS Direct Connect resource usage statistics and witnessed there was a considerable spike in the ConnectionBpsEgress, ConnectionBpsIngress, ConnectionPpsEgress, and ConnectionPpsIngress statistics. For more details related to these metrics, please refer the AWS Documentation http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/dx-metricscollected.htmlPlease refer the attachment section for more details.++++++++++TBC+++++++++++","Hello SpendHQ-Team,On further analysis, we were able to figure out that during the time of this alert, the ELB was experiencing high latency caused due to the spike in the CPU Load of the backend database instance. The CPU usage on this instance was at 100% at the time of this issue. Also, we could see that multiple requests were served with 5XX response code during this time.From the instance level, we could see that there were nearly 1015 active connections on which 471 connections were in the TIME_WAIT state. We are currently analyzing more on this issue related to all of these metrics and will revert back to you with the updates once we are done with the investigation.Kindly validate these details and revert back in case of any further queries.Regards,Sumod.K.Bose",Next action - Need to reach out to Yogesh and send a recommendation to the customer and work on RCA.,"From the analysis, i could see that 98% of the time this error comes from loading more into memory than what you set up PHP to handle in one process. There are other causes, but these are much less common very rarely it can be a memory leak if we're on PHP 5.3 and above.The prod server is using PHP version 5.6.30 for now.The memory limit is also set to 2041 MB currently.","Hello SpendHQ Team,From our analysis, We could see that there were total 1015 active connections during the time of alert out of which 130 were in the closed wait state,471 in Time wait for state and 298 were in Established state.From We also received an alert for high process count on the server which exceeded a threshold value of 30 with a value of 60.Please find the netstat output mentioned below:[root@ip-10-59-100-170 httpd]# netstat | wc -l1015[root@ip-10-59-100-170 httpd]# netstat | grep CLOSE_WAIT | wc -l130[root@ip-10-59-100-170 httpd]# netstat | grep TIME_WAIT | wc -l471[root@ip-10-59-100-170 httpd]# netstat | grep ESTABLISHED | wc -l298We have also checked the PHP fatal error logs and found the following logs at the time of alert:[Sat Aug 12 02:40:57 2017] [error] [client 10.59.1.192] PHP Fatal error:  Allowed memory size of 2147483648 bytes exhausted (tried to allocate 72 bytes) in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 503, referer: https://secure.spendhq.com/spend-visibility[Sat Aug 12 02:46:20 2017] [error] [client 10.59.1.192] SHQ_Exception: [11]: New Table Mapper version for company_db isg_cushmanw is 32 in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/super_admin_controller.php on line 3345 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/[Sat Aug 12 02:46:20 2017] [error] [client 10.59.1.192] PHP Deprecated:  Non-static method Inflector::slug() should not be called statically, assuming $this from incompatible context in /var/www/vhosts/secure.spendhq.com/public/cake/dispatcher.php on line 530, referer: https://secure.spendhq.com/super_admin/manage_company/We are analysing more on this issue.Please let us know if you have any further queries regarding this.","Hello Matthew,This is to notify you that we got an alert regarding site down for URL: https://secure.spendhq.com/login . The alert got resolved automatically and resolved within 5 minutes. We could see there was high cpu load on the database instance and a high number of process count on web instance.As discussed with you on call, we will perform analysis on the issue and let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001SVDul,Cloud Engineer Level 1,Closed,1093216,Incident,14-03-2018 01:05,,"Hello Andrew,We have stopped the instance i-0b54f8b6bce5c3fa8. Please let us know if you have any concerns.###Hello Andrew,We will work on this and will let you know the updates.Regards,Kapil B","---------- Forwarded message ----------From: Andrew Kim <Akim@spendhq.com>Date: Wed, Mar 14, 2018 at 12:06 AMSubject: Please stop EC2 instance i-0b54f8b6bce5c3fa8To: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Please stop the EC2 instance i-0b54f8b6bce5c3fa8 (Clone ofPRD-DB_v20171207) with IP 10.59.10.86.Do not terminate this instance at this time.Thank you,*Andrew Kim* | Director of Information Technology & Security | *Spend**HQ®*O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Please stop EC2 instance i-0b54f8b6bce5c3fa8,,14-03-2018 00:09,23,0,SpendHQ,"Hello Andrew,We have stopped the instance i-0b54f8b6bce5c3fa8. Please let us know if you have any concerns.","Hello Andrew,We will work on this and will let you know the updates.Regards,Kapil B",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001U9Y07,Cloud Engineer Level 1,Closed,1094955,Incident,10-04-2018 23:55,,"Hello Team,This is to inform that the regarding the high CPU utilization and CPU Load on prd-ww2_6 - 10.59.101.6 server.The alert got resolved and returned to the normal state.Hence At this time, we are marking this case closed and let us know if you have any queries.###Hello Team,We haven't heard back from you.Please review our previous comment and let us know in case of any queries.###Hello Team,Please review our previous comment and let us know in case of any queries.###Hello SpendHQ Team,This is to inform you that we have received an alert regarding the high CPU utilization and CPU Load on prd-ww2_6 - 10.59.101.6 server. The CPU usage on this instance has exceeded the threshold value of 85% with 87.95%  and the CPU Load has exceeded the threshold value of 2 to 2.42On further checking, we could see that httpd process with PID 14539 is consuming high CPU utilization on the instance.Please find the below current connection to the server.[centos@ip-10-59-101-6 ~]$ netstat | wc -l1565[centos@ip-10-59-101-6 ~]$ netstat | grep TIME_WAIT | wc -l1254[centos@ip-10-59-101-6 ~]$ netstat | grep ESTABLISHED | wc -l118There are 118 established connections and 1254 TIME_WAIT connections in this machinePlease review these details and let us know in case of any query.","[Triggered] [SpendHQ] - High CPU Utilization on the host prd-ww2_6 - 10.59.101.6 - web  High CPU Utilization on the host. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.com`avg(last_5m):avg:system.cpu.stolen{datadog_monitor:on} by {host} + avg:system.cpu.user{datadog_monitor:on} by {host} > 80`Metric value: 90.105This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024189?group=host%3Ai-01ac95c23ac66a40e · Edit Monitor: https://app.datadoghq.com/monitors#2024189/edit · Event URL: https://app.datadoghq.com/event/event?id=4337285231786472365 · View i-01ac95c23ac66a40e: https://app.datadoghq.com/infrastructure?hostname=i-01ac95c23ac66a40e · Show Processes: https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=None&tags=host%3Ai-01ac95c23ac66a40e&from_ts=None&live=false&showSummaryGraphs=true--  <http://go.reancloud.com/public-sector-events>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on the host prd-ww2_6 - 10.59.101.6 - web,,04-04-2018 01:24,167,0,SpendHQ,"Hello Team,This is to inform that the regarding the high CPU utilization and CPU Load on prd-ww2_6 - 10.59.101.6 server.The alert got resolved and returned to the normal state.Hence At this time, we are marking this case closed and let us know if you have any queries.","Hello Team,We haven't heard back from you.Please review our previous comment and let us know in case of any queries.","Hello Team,Please review our previous comment and let us know in case of any queries.","Hello SpendHQ Team,This is to inform you that we have received an alert regarding the high CPU utilization and CPU Load on prd-ww2_6 - 10.59.101.6 server. The CPU usage on this instance has exceeded the threshold value of 85% with 87.95%  and the CPU Load has exceeded the threshold value of 2 to 2.42On further checking, we could see that httpd process with PID 14539 is consuming high CPU utilization on the instance.Please find the below current connection to the server.[centos@ip-10-59-101-6 ~]$ netstat | wc -l1565[centos@ip-10-59-101-6 ~]$ netstat | grep TIME_WAIT | wc -l1254[centos@ip-10-59-101-6 ~]$ netstat | grep ESTABLISHED | wc -l118There are 118 established connections and 1254 TIME_WAIT connections in this machinePlease review these details and let us know in case of any query.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001b1j0q,Cloud Engineer Level 1,Closed,1104107,Incident,06-09-2018 12:33,,"Hello Team,This is to notify you that there is an emergency maintenance that has been scheduled on AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA, this will cause a disruption to your Direct Connect connections associated with this event. The maintenance is for the only test resources that are not affected the production.At this this we are closing this case and let us know if you have any quereis related to it.###Hello Team,This is to notify you that there is an emergency maintenance that has been scheduled on AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA, this will cause a disruption to your Direct Connect connections associated with this event. Also if you have configured your service to use redundant Direct Connect connections, then alternate connections will be available for the duration of the maintenance.Event Dates:Region/AZ: us-east-1Start time: September 6, 2018, at 9:01:00 AM UTCEnd time: September 6, 2018 at 1:01:00 PM UTCAffected Resources:1.Connection name: Test-Connection-10GbpsConnection ID: dxcon-fg8t61olLocation Equinix DC2/DC11, Ashburn, VAType: Regular connectionState: downPort Speed 10Gbps2.Name Test-VI-10GbpsID: dxvif-fh0k2nntAWS device: EqDC2-1q55ih9bd3mk5Virtual Gateway: vgw-ce8867a7VLAN Assigned 100State: available","Emergency maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. This maintenance will cause a disruption to your Direct Connect connections associated with this event.If you have configured your service to use redundant Direct Connect connections, then alternate connections will be available for the duration of the maintenance. For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_EMERGENCY_MAINTENANCE_SCHEDULED,,06-09-2018 04:50,10,0,SpendHQ,"Hello Team,This is to notify you that there is an emergency maintenance that has been scheduled on AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA, this will cause a disruption to your Direct Connect connections associated with this event. The maintenance is for the only test resources that are not affected the production.At this this we are closing this case and let us know if you have any quereis related to it.","Hello Team,This is to notify you that there is an emergency maintenance that has been scheduled on AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA, this will cause a disruption to your Direct Connect connections associated with this event. Also if you have configured your service to use redundant Direct Connect connections, then alternate connections will be available for the duration of the maintenance.Event Dates:Region/AZ: us-east-1Start time: September 6, 2018, at 9:01:00 AM UTCEnd time: September 6, 2018 at 1:01:00 PM UTCAffected Resources:1.Connection name: Test-Connection-10GbpsConnection ID: dxcon-fg8t61olLocation Equinix DC2/DC11, Ashburn, VAType: Regular connectionState: downPort Speed 10Gbps2.Name Test-VI-10GbpsID: dxvif-fh0k2nntAWS device: EqDC2-1q55ih9bd3mk5Virtual Gateway: vgw-ce8867a7VLAN Assigned 100State: available",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001jkRM7,Cloud Engineer Level 1,Closed,1112150,Incident,15-02-2019 05:47,,"Hello DeanThanks for Joining the call,We have shared your new credentials with you over a different mail. As you were able to connect the VPN after Password reset on call itself, we are marking this case as closed.Feel free to reopen this case if you have any further queries.RegardsNishad Ali###Hello DeanCan you please join on the below bridge to look more into this issue.https://hitachivantara.zoom.us/my/safuvankm.RegardsNishad Ali###Hello Dean,Thanks for reaching us. We will check the connectivity issue and will let you know the updates soon.Thanks and RegardsRevathy Kurup","Good afternoon,I am having trouble connecting to the Sophos VPN. I am receiving the following error message, can you please advise?[cid:image001.png@01D4C465.E33131A0]FYI - I have successfully connected to the Sophos VPN before while I was in our office; however, I am remote today.Thanks,DeanDean Thoms | Associate | SpendHQ(r)O: 770.282.8076 | dthoms@spendhq.com<mailto:dthoms@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sophos Connection Issues,,14-02-2019 23:35,6,0,SpendHQ,"Hello DeanThanks for Joining the call,We have shared your new credentials with you over a different mail. As you were able to connect the VPN after Password reset on call itself, we are marking this case as closed.Feel free to reopen this case if you have any further queries.RegardsNishad Ali",Hello DeanCan you please join on the below bridge to look more into this issue.https://hitachivantara.zoom.us/my/safuvankm.RegardsNishad Ali,"Hello Dean,Thanks for reaching us. We will check the connectivity issue and will let you know the updates soon.Thanks and RegardsRevathy Kurup",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKtx,Cloud Engineer Level 1,Closed,1042239,Incident,14-01-2017 09:08,,This alert is due to maintenance.,"Fri, 13 Jan 2017 22:16:00 -0500Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): California US, Sydney-C AU, Atlanta-B US, London UK-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,14-01-2017 08:46,0,0,SpendHQ,This alert is due to maintenance.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TmS5t,Cloud Engineer Level 1,Closed,1094613,Incident,04-04-2018 18:10,,"I apologize, can we unblock this IP address. This is being used by one of our monitoring services.Thank you.###Hello Andrew,Thanks for the update we have blocked the IP from NACL.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Yes, please block 54.153.159.26 and close this ticket. Thank you###Hello Team,This is quick follow up.Please review the previous comment and let us know if we have your approval to block this IP address from the subnet NACL. Feel free to reach us for any queries###Hello Team,Please review the details and let us know if we have your approval to block this IP address from the subnet NACL. Feel free to reach us for any queries.###Hello Team,This is to inform you that we have again received an  Intrusion Prevention Alert from Sophos and the source IP address is 10.59.0.102.Name: Intrusion protection alert Action: drop, Reason: SERVER-ORACLE Oracle WebLogic Server remote command execution attempt, Class: Attempted Administrator Privilege Gain, Please find the Intrusion Prevention Logs: 2018:03:30-23:00:47 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.102 dstip=10.59.1.192 proto=6 srcport=62137 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0By analyzing the ELB Secure-SpendHQ-ELB access logs, we were able to track down the requester public IP. Please find the details below. IP Address: 54.153.159.26Country: AustraliaRegion: New South WalesPlease find these details and let us know if we have your approval to block this IP address from the subnet NACL. Feel free to reach us for any queries.###Hello Team, We have analyzed the alert and below are the details. On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 74.115.21.213 which belongs to the organization - Faction and country United States was trying to execute the Oracle WebLogic Server Remote Code Execution. This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. ELB Log 2018-03-29T23:45:44.329903Z Secure-SpendHQ-ELB 74.115.21.213:21173 10.59.1.192:443 0.000038 0.128574 0.000043 302 302 0 0 GET https://secure.spendhq.com:443/ HTTP/1.1 Monit/5.14 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Chrome/65.0.3325.181 Safari/537.36 - - Please review the details and let us know if you have any queries.###Hello Team,This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.0.193 which belongs to the preview-spendhq ELB.Please find the Intrusion Prevention Logs: 2018:03:29-23:46:23 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.193 dstip=10.59.1.192 proto=6 srcport=3742 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are further analyzing the details and will let you know the updates.","---------- Forwarded message ----------From: Firewall Notification System <manage-spendhq@reancloud.com>Date: Fri, Mar 30, 2018 at 5:16 AMSubject: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped)To: event-5domgd23@dtdg.co, spendhq-support@reancloud.com, ms@reancloud.comIntrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-ORACLE Oracle WebLogic Server remote commandexecution attemptDetails........: https://www.snort.org/search?query=45304Time...........: 2018-03-29 23:46:23Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.0.193Source port: 3742Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 94 days 16 hours 43 minutesSystem Load        : 0.13System Version     : Sophos UTM 9.506-2Please refer to the manual for detailed instructions.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,30-03-2018 06:15,114,0,SpendHQ,"I apologize, can we unblock this IP address. This is being used by one of our monitoring services.Thank you.","Hello Andrew,Thanks for the update we have blocked the IP from NACL.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Yes, please block 54.153.159.26 and close this ticket. Thank you","Hello Team,This is quick follow up.Please review the previous comment and let us know if we have your approval to block this IP address from the subnet NACL. Feel free to reach us for any queries","Hello Team,Please review the details and let us know if we have your approval to block this IP address from the subnet NACL. Feel free to reach us for any queries.","Hello Team,This is to inform you that we have again received an  Intrusion Prevention Alert from Sophos and the source IP address is 10.59.0.102.Name: Intrusion protection alert Action: drop, Reason: SERVER-ORACLE Oracle WebLogic Server remote command execution attempt, Class: Attempted Administrator Privilege Gain, Please find the Intrusion Prevention Logs: 2018:03:30-23:00:47 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.102 dstip=10.59.1.192 proto=6 srcport=62137 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0By analyzing the ELB Secure-SpendHQ-ELB access logs, we were able to track down the requester public IP. Please find the details below. IP Address: 54.153.159.26Country: AustraliaRegion: New South WalesPlease find these details and let us know if we have your approval to block this IP address from the subnet NACL. Feel free to reach us for any queries.","Hello Team, We have analyzed the alert and below are the details. On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 74.115.21.213 which belongs to the organization - Faction and country United States was trying to execute the Oracle WebLogic Server Remote Code Execution. This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. ELB Log 2018-03-29T23:45:44.329903Z Secure-SpendHQ-ELB 74.115.21.213:21173 10.59.1.192:443 0.000038 0.128574 0.000043 302 302 0 0 GET https://secure.spendhq.com:443/ HTTP/1.1 Monit/5.14 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Chrome/65.0.3325.181 Safari/537.36 - - Please review the details and let us know if you have any queries.","Hello Team,This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.0.193 which belongs to the preview-spendhq ELB.Please find the Intrusion Prevention Logs: 2018:03:29-23:46:23 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.193 dstip=10.59.1.192 proto=6 srcport=3742 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are further analyzing the details and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BanUs,Cloud Engineer Level 1,Closed,1052644,Incident,18-05-2017 08:07,,"This is not affecting the SpendHQ environment so we can close this case.###Hello SendHQ-Team,This is to inform you that there is a slight change on the maintenance planned by AWS team on the AWS Direct Connect router.  The maintenance has been postponed to May 31, 2017 which will start on 1:30:00 PM UTC+5:30 and will end at 5:30:00 PM UTC+5:30. The scheduled maintenance is only going to affect one DX connection dxcon-fg50qjyw which is 1GBps connection. We are not using the 1GBps connection and we are only using the 10GBps one. However, we will be monitoring the environment around this maintenance window time. Please let us know if you have any queries regarding this case.Regards,Sumod.K.Bose###Matthew Watts7:27 PM (30 minutes ago)to Rean, spendhq-support Thank you for the update. From: <noreply@salesforce.com> on behalf of Rean Support <support@reancloud.com>Date: Wednesday, May 10, 2017 at 9:54 AMTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Subject: Priority High - P2 | Update on Case # I-01052644###Hello Team,Please ignore the last email.Apologize for the confusion caused.The scheduled maintenance is only going to affect one DX connection dxcon-fg50qjyw which is 1GBps connection. We are not using the 1GBps connection and we are only using the 10GBps one. However we will be monitoring the environment around this maintenance window time. Please let us know if you have any queries regarding this.###[Steven]Thank you REAN team for letting us know. We’ll need to be ready on our end to mitigate the risk of clients thinking that the site is down.[Matthew]Thank you for the notification. I would like to confirm that the disruption will take place from 0300 Hours to 0700 Hours EST on Wednesday 17th May 2017? How soon after this disruption window will services be able to be restored? Is there anything that can be done to prevent the downtime?###Hello Team,This is to notify you that we have received a notification from AWS team that Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6, DC10, Ashburn, VA from Wed, 17 May 2017 08:00:00 GMT to Wed, 17 May 2017 12:00:00 GMT for 4 hours. During this maintenance window, your AWS Direct Connect services listed below may become unavailable.dxvif-fffiuqt9dxcon-fg50qjywAs the maintenance has been scheduled for both the 1 Gbps and 10 Gbps connection we need to schedule a downtime as at the time of maintenance the ISCSI connection from the instance to Nimble storage is going to be disrupted.If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support.","Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6, DC10, Ashburn, VA. During this maintenance window, your AWS Direct Connect services associated with this event may become unavailable.This maintenance is scheduled to avoid disrupting redundant connections at the same time.If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED,,10-05-2017 11:46,191,0,SpendHQ,This is not affecting the SpendHQ environment so we can close this case.,"Hello SendHQ-Team,This is to inform you that there is a slight change on the maintenance planned by AWS team on the AWS Direct Connect router.  The maintenance has been postponed to May 31, 2017 which will start on 1:30:00 PM UTC+5:30 and will end at 5:30:00 PM UTC+5:30. The scheduled maintenance is only going to affect one DX connection dxcon-fg50qjyw which is 1GBps connection. We are not using the 1GBps connection and we are only using the 10GBps one. However, we will be monitoring the environment around this maintenance window time. Please let us know if you have any queries regarding this case.Regards,Sumod.K.Bose","Matthew Watts7:27 PM (30 minutes ago)to Rean, spendhq-support Thank you for the update. From: <noreply@salesforce.com> on behalf of Rean Support <support@reancloud.com>Date: Wednesday, May 10, 2017 at 9:54 AMTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Subject: Priority High - P2 | Update on Case # I-01052644","Hello Team,Please ignore the last email.Apologize for the confusion caused.The scheduled maintenance is only going to affect one DX connection dxcon-fg50qjyw which is 1GBps connection. We are not using the 1GBps connection and we are only using the 10GBps one. However we will be monitoring the environment around this maintenance window time. Please let us know if you have any queries regarding this.",[Steven]Thank you REAN team for letting us know. We’ll need to be ready on our end to mitigate the risk of clients thinking that the site is down.[Matthew]Thank you for the notification. I would like to confirm that the disruption will take place from 0300 Hours to 0700 Hours EST on Wednesday 17th May 2017? How soon after this disruption window will services be able to be restored? Is there anything that can be done to prevent the downtime?,"Hello Team,This is to notify you that we have received a notification from AWS team that Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6, DC10, Ashburn, VA from Wed, 17 May 2017 08:00:00 GMT to Wed, 17 May 2017 12:00:00 GMT for 4 hours. During this maintenance window, your AWS Direct Connect services listed below may become unavailable.dxvif-fffiuqt9dxcon-fg50qjywAs the maintenance has been scheduled for both the 1 Gbps and 10 Gbps connection we need to schedule a downtime as at the time of maintenance the ISCSI connection from the instance to Nimble storage is going to be disrupted.If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C2sKj,Cloud Engineer Level 1,Closed,1054804,Incident,22-05-2017 22:45,,"Hello Matthew,Thanks for the confirmation. We have disabled the maintenance mode for preview.spendhq.com###Hello Andrew,Thanks for the update. We have enabled maintenance mode for the URL preview.spendhq.com and will be reverting back the changes on 23rd May(Tuesday) 2017 at 09 AM EST(06:30 PM IST).Kindly let us know if your team have any further queries.Regards,Sumod.K.Bose###Please put preview.spendhq.com into maintenance until Tuesday at 9am eastern. Thank youAndrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 |akim@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###Hello SpendHQ Team,The url https://preview.spendhq.com/login is still failing. We tried to reach out Andrew and Matthew over phone but didn't able to get them. Please let us know if you are done with the maintenance.###Hello Andrew,We haven't heard back from you. The url https://preview.spendhq.com/login is still failing. Please let us know once you have done with the maintenance.###Hello Andrew,The preview.spendhq.com is still failing. Please let us know once you have done with the maintenance.###Hello Andrew,We are going to disable maintenance mode for preview.spendhq.com. Please let us know if you have any queries regarding this.###Hello Andrew,Thanks for the information. We have enabled maintenance mode for preview.spendhq.com and will disable it at 12pm (noon) eastern.###Andrew replied thatPlease put preview.spendhq.com into maintenance mode until Sunday (5/21) 12pm (noon) eastern.###Got on a call with Andrew and he informed that he will check with his team members and confirm whether they are performing any activity.###The issue is caused by high network traffic generated from distinct I.Ps. Below is the parsed out of all the I.P with request count in recent logs:      4 45.33.115.245      2 45.33.15.197      2 45.33.2.147      1 45.33.96.15      2 45.56.113.167      2 45.56.78.144      2 45.56.90.110      2 45.79.130.157      1 45.79.158.166      2 45.79.169.153      2 45.79.187.152      2 45.79.188.179      2 50.116.36.104     50 52.11.47.12     48 52.19.187.53     45 52.21.231.226     48 52.28.221.96     51 52.64.61.27     48 52.69.241.233     51 52.76.85.66     46 52.8.5.138     48 54.207.79.165      5 54.252.87.165     17 66.246.75.38      6 69.164.195.159      4 74.207.229.76      2 74.207.230.141      4 74.207.230.51      2 74.207.245.56      6 74.82.3.54      1 96.126.125.110      1 104.237.154.108      5 139.162.157.118      4 139.162.203.55      4 173.255.210.63      2 173.255.248.83      1 176.58.114.190      2 176.58.98.203      5 178.79.181.14      1 202.149.218.202      4 212.71.233.175###Escalated to Sushant for further analysis.###Hello SpendHQ Team,From further analysis, we could see that the latency was too high at the time of the alert. The number of connections in CLOSE_WAIT , TIME_WAIT state and  open tcp connections keeps on increasing.Find the logs from attachment section. Please let us know if you are performing any activity.A socket can be in CLOSE_WAIT state indefinitely until the application closes it. This might have caused due to issue in the application.In order to avoid the issue in future, we would recommend you to review the application side.###Hello SpendHQ Team,Since we are again getting the site down alert for the URL https://preview.spendhq.com/login we went ahead and killed the httpd connections which were in the close_wait state. This resolved the issue and now the site is up and running fine.Please let us know if you have any queries.###Hello SpendHQ Team, This is to notify you that we again got site down alert for the url https://preview.spendhq.com/login. From our analysis we are able to find that many of the httpd connections are in the close_wait state. Please let us know whether we can go ahead and kill those connections. Also please let us know whether your team is performing any activity from your end.###Hello SpendHQ Team,This is to inform you that the site down alert for the url https://preview.spendhq.com/login got resolved automatically. The violation has lasted for 10 minutes and now the site is loading fine.While checking the ELB logs, we could see that a number of requests with high latency and 502 as response codes. Please find the attached elb logs from the attachment section.On further investigation, we found that there were 188 open TCP connections in CLOSE_WAIT state and 242 connections in TIME_WAIT state. Please find the attached files. Still we could see that a high number of open TCP connections in TIME_WAIT and CLOSE_WAIT state. Please let us know whether we can reboot the server or kill those connections.###Hello SpendHQ Team,This is to notify you that we again received a site down alert for the url https://preview.spendhq.com/login. We are investigating the alert and meanwhile let us know if you are performing any activity from your end.###Hello Team,Did you get any chance review the previous comments?Please let us know if you have any queries regarding this.###Hello Team,The alert got resolved automatically. The site is up and running fine.On checking the ELB logs we could see a number of requests with 502(Bad gateway) response code. The latency was also high at the time of the alert. Please review the attached log details.On checking the instance level, we could see about 207 connections in CLOSE_WAIT state at the time of the alert. CLOSE_WAIT is the state for the TCP connection after the remote side has requested a shutdown(FIN), and the TCP connection is waiting for the local application to close the socket. There is no timeout for a thread in CLOSE_WAIT state. tcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47828    CLOSE_WAIT  12458/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47766    CLOSE_WAIT  12258/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47773    CLOSE_WAIT  12295/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47855    CLOSE_WAIT  12503/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47866    CLOSE_WAIT  12509/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47811    CLOSE_WAIT  12330/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47865    CLOSE_WAIT  12508/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47849    CLOSE_WAIT  12499/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47812    CLOSE_WAIT  12359/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47768    CLOSE_WAIT  12260/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47861    CLOSE_WAIT  12507/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47851    CLOSE_WAIT  12500/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47852    CLOSE_WAIT  12501/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47765    CLOSE_WAIT  12244/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47749    CLOSE_WAIT  12239/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47840    CLOSE_WAIT  12481/httpdA socket can be in CLOSE_WAIT state indefinitely until the application closes it. This might have caused due to issue in the application. Please review the attachments for more details.Now the CLOSE_WAIT wait connections have reduced to 50 connections. The temporary solution to resolve is either restart the server or kill all connections that are in CLOSE_WAIT state. In order to avoid the issue in future, we would recommend you to review the application side.###Hello Team,This is to notify you that we got alert for site down again for URL: https://preview.spendhq.com/login As an initial analysis, we could see that the Open TCP connections were high with a value of 286 connections. The Network Traffic IN was high with a value of 720KB/s. The latency was high at the time of the alert and while checking the logs we could see many requests with 502(Bad gateway) response code .We could see a lot of connection in CLOSE_WAIT state in the server.We are checking on this and will let you know the updates.###Hello Team,This is to notify you that we got an alert regarding site dwon for URL: https://preview.spendhq.com/login . The alert got resolved automatically and lasted for 5 minutes. The site is accessible now.We are analyzing the issue form our end. Please let us know if you are performing any activity from your end.","Thu, 18 May 2017 17:16:21 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Frankfurt DE, Dallas-B US, Atlanta-B US, California US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,19-05-2017 02:46,92,0,SpendHQ,"Hello Matthew,Thanks for the confirmation. We have disabled the maintenance mode for preview.spendhq.com","Hello Andrew,Thanks for the update. We have enabled maintenance mode for the URL preview.spendhq.com and will be reverting back the changes on 23rd May(Tuesday) 2017 at 09 AM EST(06:30 PM IST).Kindly let us know if your team have any further queries.Regards,Sumod.K.Bose",Please put preview.spendhq.com into maintenance until Tuesday at 9am eastern. Thank youAndrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 |akim@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com,"Hello SpendHQ Team,The url https://preview.spendhq.com/login is still failing. We tried to reach out Andrew and Matthew over phone but didn't able to get them. Please let us know if you are done with the maintenance.","Hello Andrew,We haven't heard back from you. The url https://preview.spendhq.com/login is still failing. Please let us know once you have done with the maintenance.","Hello Andrew,The preview.spendhq.com is still failing. Please let us know once you have done with the maintenance.","Hello Andrew,We are going to disable maintenance mode for preview.spendhq.com. Please let us know if you have any queries regarding this.","Hello Andrew,Thanks for the information. We have enabled maintenance mode for preview.spendhq.com and will disable it at 12pm (noon) eastern.",Andrew replied thatPlease put preview.spendhq.com into maintenance mode until Sunday (5/21) 12pm (noon) eastern.,Got on a call with Andrew and he informed that he will check with his team members and confirm whether they are performing any activity.,The issue is caused by high network traffic generated from distinct I.Ps. Below is the parsed out of all the I.P with request count in recent logs:      4 45.33.115.245      2 45.33.15.197      2 45.33.2.147      1 45.33.96.15      2 45.56.113.167      2 45.56.78.144      2 45.56.90.110      2 45.79.130.157      1 45.79.158.166      2 45.79.169.153      2 45.79.187.152      2 45.79.188.179      2 50.116.36.104     50 52.11.47.12     48 52.19.187.53     45 52.21.231.226     48 52.28.221.96     51 52.64.61.27     48 52.69.241.233     51 52.76.85.66     46 52.8.5.138     48 54.207.79.165      5 54.252.87.165     17 66.246.75.38      6 69.164.195.159      4 74.207.229.76      2 74.207.230.141      4 74.207.230.51      2 74.207.245.56      6 74.82.3.54      1 96.126.125.110      1 104.237.154.108      5 139.162.157.118      4 139.162.203.55      4 173.255.210.63      2 173.255.248.83      1 176.58.114.190      2 176.58.98.203      5 178.79.181.14      1 202.149.218.202      4 212.71.233.175,Escalated to Sushant for further analysis.,"Hello SpendHQ Team,From further analysis, we could see that the latency was too high at the time of the alert. The number of connections in CLOSE_WAIT , TIME_WAIT state and  open tcp connections keeps on increasing.Find the logs from attachment section. Please let us know if you are performing any activity.A socket can be in CLOSE_WAIT state indefinitely until the application closes it. This might have caused due to issue in the application.In order to avoid the issue in future, we would recommend you to review the application side.","Hello SpendHQ Team,Since we are again getting the site down alert for the URL https://preview.spendhq.com/login we went ahead and killed the httpd connections which were in the close_wait state. This resolved the issue and now the site is up and running fine.Please let us know if you have any queries.","Hello SpendHQ Team, This is to notify you that we again got site down alert for the url https://preview.spendhq.com/login. From our analysis we are able to find that many of the httpd connections are in the close_wait state. Please let us know whether we can go ahead and kill those connections. Also please let us know whether your team is performing any activity from your end.","Hello SpendHQ Team,This is to inform you that the site down alert for the url https://preview.spendhq.com/login got resolved automatically. The violation has lasted for 10 minutes and now the site is loading fine.While checking the ELB logs, we could see that a number of requests with high latency and 502 as response codes. Please find the attached elb logs from the attachment section.On further investigation, we found that there were 188 open TCP connections in CLOSE_WAIT state and 242 connections in TIME_WAIT state. Please find the attached files. Still we could see that a high number of open TCP connections in TIME_WAIT and CLOSE_WAIT state. Please let us know whether we can reboot the server or kill those connections.","Hello SpendHQ Team,This is to notify you that we again received a site down alert for the url https://preview.spendhq.com/login. We are investigating the alert and meanwhile let us know if you are performing any activity from your end.","Hello Team,Did you get any chance review the previous comments?Please let us know if you have any queries regarding this.","Hello Team,The alert got resolved automatically. The site is up and running fine.On checking the ELB logs we could see a number of requests with 502(Bad gateway) response code. The latency was also high at the time of the alert. Please review the attached log details.On checking the instance level, we could see about 207 connections in CLOSE_WAIT state at the time of the alert. CLOSE_WAIT is the state for the TCP connection after the remote side has requested a shutdown(FIN), and the TCP connection is waiting for the local application to close the socket. There is no timeout for a thread in CLOSE_WAIT state. tcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47828    CLOSE_WAIT  12458/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47766    CLOSE_WAIT  12258/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47773    CLOSE_WAIT  12295/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47855    CLOSE_WAIT  12503/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47866    CLOSE_WAIT  12509/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47811    CLOSE_WAIT  12330/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47865    CLOSE_WAIT  12508/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47849    CLOSE_WAIT  12499/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47812    CLOSE_WAIT  12359/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47768    CLOSE_WAIT  12260/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47861    CLOSE_WAIT  12507/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47851    CLOSE_WAIT  12500/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47852    CLOSE_WAIT  12501/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47765    CLOSE_WAIT  12244/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47749    CLOSE_WAIT  12239/httpdtcp        1      0 ::ffff:10.59.100.94:443     ::ffff:10.59.1.192:47840    CLOSE_WAIT  12481/httpdA socket can be in CLOSE_WAIT state indefinitely until the application closes it. This might have caused due to issue in the application. Please review the attachments for more details.Now the CLOSE_WAIT wait connections have reduced to 50 connections. The temporary solution to resolve is either restart the server or kill all connections that are in CLOSE_WAIT state. In order to avoid the issue in future, we would recommend you to review the application side.","Hello Team,This is to notify you that we got alert for site down again for URL: https://preview.spendhq.com/login As an initial analysis, we could see that the Open TCP connections were high with a value of 286 connections. The Network Traffic IN was high with a value of 720KB/s. The latency was high at the time of the alert and while checking the logs we could see many requests with 502(Bad gateway) response code .We could see a lot of connection in CLOSE_WAIT state in the server.We are checking on this and will let you know the updates.","Hello Team,This is to notify you that we got an alert regarding site dwon for URL: https://preview.spendhq.com/login . The alert got resolved automatically and lasted for 5 minutes. The site is accessible now.We are analyzing the issue form our end. Please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Dn8vz,Cloud Engineer Level 1,Closed,1065200,Incident,27-06-2017 22:31,,"Hello Team,This is to notify you that the disk usage alert for prod-sphq-db-server05 - 10.59.10.135  got resolved automatically and has returned to a normal value of 88%.###Hello Team,This is to notify you that we got an alert regarding EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135 which has crossed the threshold of 90% and has reached a value of 90%.Please see the usage details below:42G     total18G     usr12G     var11G     tmpPlease remove unwanted files/folders to reduce the volume usage.","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 92.493This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3930969906639540622 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,27-06-2017 18:05,4,0,SpendHQ,"Hello Team,This is to notify you that the disk usage alert for prod-sphq-db-server05 - 10.59.10.135  got resolved automatically and has returned to a normal value of 88%.","Hello Team,This is to notify you that we got an alert regarding EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135 which has crossed the threshold of 90% and has reached a value of 90%.Please see the usage details below:42G     total18G     usr12G     var11G     tmpPlease remove unwanted files/folders to reduce the volume usage.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001blfQO,Cloud Engineer Level 1,Closed,1104938,Incident,19-09-2018 18:46,,I have updated the tags.,"REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environmentby REAN Managed Cloud.The following *AWS::EC2::Instance* resources were affected:------------------------------   - *Violation:* The instance does not adhere the tagging standards set   for your organization.   - *Recommendation:* It is recommended to adhere the tagging standards   set for your organization. Kindly refer internal policy documents.   - *Action taken:* None   - *Resource details:*   Resource ID Instance Name Instance Type Region Missing tags   i-02f014e2b71f64bd8 matt_t2.xlarge t2.xlarge us-east-1 Owner,Monitoring   i-0da6d299396a11567 matt_r3.xlarge r3.xlarge us-east-1 Owner,Monitoring------------------------------Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- Paul MulonziaREĀN Cloud | Reach, Engage, Āctivate, Nurtur--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Managed Cloud: spendhq] EC2 Required tag,,19-09-2018 18:45,0,0,SpendHQ,I have updated the tags.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gbz8N,Cloud Engineer Level 1,Closed,1109535,Incident,16-12-2018 06:33,,"Hello Matthew,We can see that the URL is working fine now. We have unmuted the alert. Now we are marking this case closed.###Hello Matthew,Thank you for the update. We are enabling maintenance on this URL. Please let us know once you are done with the activity.###Please ignore alerts on preview.Matthew###Hello Team,We are continuously receiving the site down alert for URL: https://preview.spendhq.com/login. The alert is recovering in 2 minutes. Please let us know if you are performing any activity.","Thank You, KAPIL BOKDIAJr Cloud Engineer, Cloud Operations, Global ServicesHitachi Vantara m: 730-0421-033e: kapil.bokdia@HitachiVantara.comFollow Hitachi Vantarawww.HitachiVantara.com <https://www.hitachivantara.com/en-us/home.html>|community.HitachiVantara.com <https://community.hitachivantara.com/> <https://community.hitachivantara.com/> <https://twitter.com/HitachiVantara> <https://www.facebook.com/HitachiVantara> <https://www.linkedin.com/company/11257500> <https://www.youtube.com/c/HitachiVantara>  ﻿On 16/12/18, 4:06 AM, ms@reancloud.com <ms@reancloud.com> wrote:    Sat, 15 Dec 2018 17:36:48 -0500        Detected Error on SpendHQ Preview        Estimated Downtime: 1 minute     https://www.wormly.com/edithost/hostid/59890        --------------------    Sensor Failure: HTTP    --------------------    Sensor reported error:    Operation timed out after 30002 milliseconds with 0 bytes received        Sensor parameters:    url: https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fpreview.spendhq.com%2Flogin&amp;data=01%7C01%7Ckapil.bokdia%40hitachivantara.com%7Caf70d3b80af642a118da08d662ddcedd%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=PhRS4anYifn%2FRqrp1mK7yFED6bHuUqbxdWJt4kHakKE%3D&amp;reserved=0    expect: 200    wantedstring: SpendHQ    unwantedstring:                 Reported by node: Atlanta-B US    Confirmed by node(s): Dallas-C US, New Jersey US, London UK, Frankfurt-B DE            -- \\-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: Detected Error on SpendHQ Preview,,16-12-2018 04:09,2,0,SpendHQ,"Hello Matthew,We can see that the URL is working fine now. We have unmuted the alert. Now we are marking this case closed.","Hello Matthew,Thank you for the update. We are enabling maintenance on this URL. Please let us know once you are done with the activity.",Please ignore alerts on preview.Matthew,"Hello Team,We are continuously receiving the site down alert for URL: https://preview.spendhq.com/login. The alert is recovering in 2 minutes. Please let us know if you are performing any activity.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C3e0f,Cloud Engineer Level 1,Closed,1055391,Incident,23-05-2017 13:14,,"Hello SpendHQ-Team,We haven't heard back from you regarding this case. As of now, we are marking this case as resolved. Please let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello Team,On further analysis we found the below details:From the ELB logs we could see requests from IP: 157.55.39.29 having 404 response code.ELB log: 2017-05-22T10:27:09.278460Z Secure-SpendHQ-ELB 157.55.39.29:5867 10.59.1.192:443 0.000046 0.115822 0.000047 404 404 0 6753 GET https://secure.spendhq.com:443/robots.txt HTTP/1.1 Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm) ECDHE-RSA-AES128-SHA256 TLSv1.2IPS log:2017:05:22-10:32:03 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=13592 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0IP Details:IP: 157.55.39.29Country: United StatesISP: Microsoft CorporationPlease let us know if you want us to block the IP in NACL Level.###Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.20 which belongs to the Secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-22 10:32:03Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.20Source port: 13592Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 191 days 2 hours 46 minutesSystem Load        : 0.15,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,22-05-2017 16:05,21,0,SpendHQ,"Hello SpendHQ-Team,We haven't heard back from you regarding this case. As of now, we are marking this case as resolved. Please let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello Team,On further analysis we found the below details:From the ELB logs we could see requests from IP: 157.55.39.29 having 404 response code.ELB log: 2017-05-22T10:27:09.278460Z Secure-SpendHQ-ELB 157.55.39.29:5867 10.59.1.192:443 0.000046 0.115822 0.000047 404 404 0 6753 GET https://secure.spendhq.com:443/robots.txt HTTP/1.1 Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm) ECDHE-RSA-AES128-SHA256 TLSv1.2IPS log:2017:05:22-10:32:03 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=13592 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0IP Details:IP: 157.55.39.29Country: United StatesISP: Microsoft CorporationPlease let us know if you want us to block the IP in NACL Level.","Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.20 which belongs to the Secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001UvtIj,Cloud Engineer Level 1,Closed,1101389,Incident,12-07-2018 08:22,,"Hello Allen,We have disabled maintenance for preview URL. The site is accessible now. Hence, we are closing this case.###Hello Allen,Thanks for the update.We have enabled the maintenance for preview URL. Please let us know once you have done with the testing so that we will resume the monitoring. Also, we have reduced the priority of the ticket to P4.###Allen Herrera10:21 PM (2 minutes ago)to Rean, spendhq-support Please but the preview server 10.59.10.170 in maintenance mode, we are testing new code Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###Hello Team,We are still getting multiple site down alerts for https://preview.spendhq.com/login. We are seeing missing database error while accessing the URL. Error Details:Missing Database TableError: Database table cake_session_salts for model SessionSalt was not found.We have tried to reach out to Andrew/Matthew and Allen over the phone but didn't get any response. Could you please let us know if you are performing any activity on your end.###Hello Team,During the site down period, while accessing the URL we got the below error.Notice (8): Undefined variable: corner [APP/views/errors/missing_table.ctp, line 28] Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28Warning (2): Cannot modify header information - headers already sent [CORE/cake/libs/controller/controller.php, line 742]By analyzing this alert we can confirm that the application was not able to connect to the backend database during the time of the alert. Could you please let us know if you made any changes to the backend database which resulted to this outage.###Hello Team,On analyzing the issue we could see that there were network spikes for CPU utilization, Network In and Out. We have attached the screenshot in the attachment section, please have a look at it.###Hello Team,This is to inform you that the url: https://preview.spendhq.com/login is up and accessible now. We are analyzing the issue and will you know the update.Meanwhile please let us know if in case you have performed any activity from your end.###Hello Team,We received a sitedown for url: https://preview.spendhq.com/login which got recovered and it was violated for 2mins, we are analyzing the issue and will keep you posted.","Wed, 11 Jul 2018 11:36:02 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): New Jersey US, London UK, California US, Frankfurt DE-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Preview,,11-07-2018 21:11,11,0,SpendHQ,"Hello Allen,We have disabled maintenance for preview URL. The site is accessible now. Hence, we are closing this case.","Hello Allen,Thanks for the update.We have enabled the maintenance for preview URL. Please let us know once you have done with the testing so that we will resume the monitoring. Also, we have reduced the priority of the ticket to P4.","Allen Herrera10:21 PM (2 minutes ago)to Rean, spendhq-support Please but the preview server 10.59.10.170 in maintenance mode, we are testing new code Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com","Hello Team,We are still getting multiple site down alerts for https://preview.spendhq.com/login. We are seeing missing database error while accessing the URL. Error Details:Missing Database TableError: Database table cake_session_salts for model SessionSalt was not found.We have tried to reach out to Andrew/Matthew and Allen over the phone but didn't get any response. Could you please let us know if you are performing any activity on your end.","Hello Team,During the site down period, while accessing the URL we got the below error.Notice (8): Undefined variable: corner [APP/views/errors/missing_table.ctp, line 28] Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28Warning (2): Cannot modify header information - headers already sent [CORE/cake/libs/controller/controller.php, line 742]By analyzing this alert we can confirm that the application was not able to connect to the backend database during the time of the alert. Could you please let us know if you made any changes to the backend database which resulted to this outage.","Hello Team,On analyzing the issue we could see that there were network spikes for CPU utilization, Network In and Out. We have attached the screenshot in the attachment section, please have a look at it.","Hello Team,This is to inform you that the url: https://preview.spendhq.com/login is up and accessible now. We are analyzing the issue and will you know the update.Meanwhile please let us know if in case you have performed any activity from your end.","Hello Team,We received a sitedown for url: https://preview.spendhq.com/login which got recovered and it was violated for 2mins, we are analyzing the issue and will keep you posted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XxTDa,Cloud Engineer Level 1,Closed,1100436,Incident,21-06-2018 11:15,,"Hello SpendHQ-Team,We have received AWS notification about IAM Password Last Used Data in your account stating that there was an interruption in processing and collection of password last used data from there end. They use this functionality to provide last sign in date in the IAM console, IAM credential report, and get-user API. Currently, they do not have password last used data from May 3, 2018, 10:50 PM to May 23, 2018, 2:08 PM PDT. Therefore, the password last used date for users does not include password use during this time. This issue was a data collection interruption and there was no impact to access controls during this time. If you are using password last used the information to identify unused credentials for deletion, such as deleting users who did not sign in to AWS in the last 90 days, AWS recommends adjusting evaluation window to include dates after May 23, 2018. Alternatively, if your users use access keys to access AWS programmatically we can refer to access key last used information as it is accurate for all dates. Kindly review this details and revert back to us in case of any queries.###@Team Please followup with CC (Rohit) and get his feedback on whether we need to notify the customer on this or not.","---------- Forwarded message ----------From: SPHQAWS <no-reply@sns.amazonaws.com>Date: Thu, Jun 21, 2018 at 2:17 AMSubject: AWS_IAM_OPERATIONAL_NOTIFICATIONTo: support@reancloud.com*Import message about AWS IAM Password Last Used Data in Your Account*  Weare writing to let you know about an interruption in our processing andcollection of password last used data. We track the last date users sign into AWS with their password, we use this functionality to provide you thelast sign in date in the IAM console[1], IAM credential report[2], andget-user API[3]. We do not have password last used data from May 3, 201810:50 PM to May 23, 2018 2:08 PM PDT. Therefore, the password last useddate for users does not include password use during this time. This issuewas a data collection interruption and there was no impact to accesscontrols during this time.  If you are using password last used informationto identify unused credentials for deletion, such as deleting users who didnot sign in to AWS in the last 90 days, we recommend you adjust yourevaluation window to include dates after May 23, 2018. Alternatively, ifyour users use access keys to access AWS programmatically you can refer toaccess key last used[4] information as it is accurate for all dates. Please contact AWS Support[5] if you have further questions.  [1]https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_finding-unused.html [2] https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html [3]https://docs.aws.amazon.com/IAM/latest/APIReference/API_GetUser.html [4]https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_finding-unused.html#finding-unused-access-keys [5]https://aws.amazon.com/contact-us/ For more details, please seehttps://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018<https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprintto Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018<http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud,securelyJune 11th, 2018<http://go.reancloud.com/moving-to-the-cloud-securely>-- Mr. Stephen Oduor OtienoAWS SysOps-Admin Associate CertifiedDigital Divide Data | 7th Floor, Paramount PlazaGlobe Round About | Nairobi, Kenya______________________________________________________________Mobile: +254 701363300Email: stephen.oduor@reancloud.com | stephen.oduor@digitaldividedata.com |stevenodu@gmail.comDigital Divide Data: Creating a World of Digital PossibilitiesWebsite: Digital Divide Data Kenya Ltd.<https://www.digitaldividedata.com/about/ddd-africa>Phone: (+254) 717552906 / 720420976_________________________________________________________-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>",Fwd: AWS_IAM_OPERATIONAL_NOTIFICATION,,21-06-2018 05:45,6,0,SpendHQ,"Hello SpendHQ-Team,We have received AWS notification about IAM Password Last Used Data in your account stating that there was an interruption in processing and collection of password last used data from there end. They use this functionality to provide last sign in date in the IAM console, IAM credential report, and get-user API. Currently, they do not have password last used data from May 3, 2018, 10:50 PM to May 23, 2018, 2:08 PM PDT. Therefore, the password last used date for users does not include password use during this time. This issue was a data collection interruption and there was no impact to access controls during this time. If you are using password last used the information to identify unused credentials for deletion, such as deleting users who did not sign in to AWS in the last 90 days, AWS recommends adjusting evaluation window to include dates after May 23, 2018. Alternatively, if your users use access keys to access AWS programmatically we can refer to access key last used information as it is accurate for all dates. Kindly review this details and revert back to us in case of any queries.",@Team Please followup with CC (Rohit) and get his feedback on whether we need to notify the customer on this or not.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015XHyp,Cloud Engineer Level 1,Closed,1039946,Incident,20-12-2016 02:00,,We are following this case under the case number 01039936.Hence closing this case for now.,"Perfect. Let’s work with the REAN team to get this mounted. Can we make sure we clone that backup and mount the clone.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Monday, December 19, 2016 11:49 AMTo: Matthew Watts <mwatts@spendhq.com>Subject: Re: Database Volume MountHi Matt,We called the snapshot we took DB-backup-12-16-26I will clone it thus we'll be able to make it available to mount.I can rename if you'd like....I am at my laptop ready to go 😄Chris VeilletteOn Dec 19, 2016, at 11:22 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Absolutely. There is no rush on this.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Monday, December 19, 2016 11:14 AMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>; spendhq-support@reancloud.com<mailto:spendhq-support@reancloud.com>Subject: Re: Database Volume MountHi Matt.... sure - can you give 30 mins to get to my laptop?Chris VeilletteOn Dec 19, 2016, at 10:44 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:A backup was made of our PRD Database last Friday night. Can we please make a copy of this backup and then mount the copy to the DB5 (*.135) machine that was setup. We will need to ensure that we can roll-back to this backup without having to stop the database to create another image.Please advise when this is completed.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Database Volume Mount,,19-12-2016 22:26,4,0,SpendHQ,We are following this case under the case number 01039936.Hence closing this case for now.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Doey6,Cloud Engineer Level 1,Closed,1066271,Incident,02-07-2017 05:04,,"Hello Team,This is to notify you that the alert regarding volume usage for PROD-SPHQ-DB-SERVER05 instance got resolved and the usage has returned to normal with a value of 68.7%. The violation has lasted for 2 hours.###Hello Team, On further analysis, we could see /dev/xvda1 mounted on / is consuming high volume usage on this instance. Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G  209M 100% /Please find the volume usage in / 19G	usr15G	tmp474M home285M libPlease find the below for the detailed volume usage in /tmp. 15G	total1.5G	liger_view_a127c5a2ed0a7a7790327f59706b0b77.csv1.3G	liger_view_d228045958a03c5f4bd03e72de47ae06.csv1012M	liger_view_9cf8f43c36714f6920fd948add6b1fee.csv705M	liger_view_d4f46cf1b5902128917c80caefc9d4f8.csv641M	liger_view_710203d56f02f6070c84e4d8edbbc97b.csv513M	liger_view_c5850033d51a49fe0720d46242bfb169.csv513M	liger_view_3c4bc094d5a902202bb4a37836d0900f.csv496M	liger_view_71b8c01f6e6687590a5d32402dfc974f.csv486M	liger_view_99a95d8f6b4654fef053df706d2cb1b5.csv475M	liger_view_d1df1243cfa31ef858b6f26c04932928.csv449M	liger_view_c830b4887d8ccee9da1dd9f9eb99fa33.csv449M	liger_view_c3845dd854e727b87d3469a15c2ed36c.csv449M	liger_view_c3581932e963b55b0a548c51181e8150.csv449M	liger_view_a93006cfe784ed55cb39b8a2ff6716e3.csv449M	liger_view_6eed87c84d48415b5a924a084aa2e90a.csv449M	liger_view_4a15e36428d1e6176fa0e5c602ab724f.csv449M	liger_view_45a3759449180b2f78163778120f17d5.csv449M	liger_view_154b4d20a2bf676afdc43f87a14902fc.csvPlease delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.###Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 92.973This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3937248685827072300 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,02-07-2017 02:02,3,0,SpendHQ,"Hello Team,This is to notify you that the alert regarding volume usage for PROD-SPHQ-DB-SERVER05 instance got resolved and the usage has returned to normal with a value of 68.7%. The violation has lasted for 2 hours.","Hello Team, On further analysis, we could see /dev/xvda1 mounted on / is consuming high volume usage on this instance. Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G  209M 100% /Please find the volume usage in / 19G	usr15G	tmp474M home285M libPlease find the below for the detailed volume usage in /tmp. 15G	total1.5G	liger_view_a127c5a2ed0a7a7790327f59706b0b77.csv1.3G	liger_view_d228045958a03c5f4bd03e72de47ae06.csv1012M	liger_view_9cf8f43c36714f6920fd948add6b1fee.csv705M	liger_view_d4f46cf1b5902128917c80caefc9d4f8.csv641M	liger_view_710203d56f02f6070c84e4d8edbbc97b.csv513M	liger_view_c5850033d51a49fe0720d46242bfb169.csv513M	liger_view_3c4bc094d5a902202bb4a37836d0900f.csv496M	liger_view_71b8c01f6e6687590a5d32402dfc974f.csv486M	liger_view_99a95d8f6b4654fef053df706d2cb1b5.csv475M	liger_view_d1df1243cfa31ef858b6f26c04932928.csv449M	liger_view_c830b4887d8ccee9da1dd9f9eb99fa33.csv449M	liger_view_c3845dd854e727b87d3469a15c2ed36c.csv449M	liger_view_c3581932e963b55b0a548c51181e8150.csv449M	liger_view_a93006cfe784ed55cb39b8a2ff6716e3.csv449M	liger_view_6eed87c84d48415b5a924a084aa2e90a.csv449M	liger_view_4a15e36428d1e6176fa0e5c602ab724f.csv449M	liger_view_45a3759449180b2f78163778120f17d5.csv449M	liger_view_154b4d20a2bf676afdc43f87a14902fc.csvPlease delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.","Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001azoxA,Cloud Engineer Level 1,Closed,1103387,Incident,31-08-2018 12:53,,"Hello Team,The site down alert for the URL:https://secure.spendhq.com/login and https://preview.spendhq.com/login got resolved and Estimated Downtime was 1 minute. As mentioned in the previous comment we checked all the metrics from AWS and found the sudden spike in ELB Latency.At the alert is resolved we are marking this case as closed and let us know if you have any queries.###Hello Team, The site down alert for the URL:https://secure.spendhq.com/login and https://preview.spendhq.com/login got resolved and Estimated Downtime was 1 minute. As mentioned in the previous comment we checked all the metrics from AWS and found the sudden spike in ELB Latency. From the instance level, there is no suspicious activity during the time of the alert. As this alert was triggered because of latency and the backend server was unable to handle the request within time. And after a minute backend server started working fine and the site got recovered.###Matthew Watts8:42 AM (17 minutes ago)to Rean, spendhq-support@reancloud.comWe are not performing any activity on this end###Hello Team, The site down alert for the URL:https://secure.spendhq.com/login and https://preview.spendhq.com/login got resolved and Estimated Downtime was 1 minute. While checking the backend ELB, Instance, we found the below details. 1. From the NewPreview-ELB load balancer, we could see Latency was around 98590.56 NewPreview-ELB From the Backend Instance PRD-WW1_122 and PRD-WW2_6, we could see all the metrics are looking normal. Please find the ELB latency logs in the attachments section. Kindly validate these details and let us know if you have any queries.###Hello Spendhq-Team, This is to notify you that we received an alert site down on the URL: https://secure.spendhq.com/login and  https://preview.spendhq.com/login.The site down alert got recovered within a minute. we are analyzing more on this issue and will get back to you with updates. Please let us know if you are performing any activity from your end.","Thanks & Regards,Wed, 29 Aug 2018 23:06:08 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30017 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Atlanta-B US, London UK, Frankfurt DE, Dallas-B US--  <https://hubs.ly/H0d8gJ20>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Secure,,30-08-2018 08:36,28,0,SpendHQ,"Hello Team,The site down alert for the URL:https://secure.spendhq.com/login and https://preview.spendhq.com/login got resolved and Estimated Downtime was 1 minute. As mentioned in the previous comment we checked all the metrics from AWS and found the sudden spike in ELB Latency.At the alert is resolved we are marking this case as closed and let us know if you have any queries.","Hello Team, The site down alert for the URL:https://secure.spendhq.com/login and https://preview.spendhq.com/login got resolved and Estimated Downtime was 1 minute. As mentioned in the previous comment we checked all the metrics from AWS and found the sudden spike in ELB Latency. From the instance level, there is no suspicious activity during the time of the alert. As this alert was triggered because of latency and the backend server was unable to handle the request within time. And after a minute backend server started working fine and the site got recovered.","Matthew Watts8:42 AM (17 minutes ago)to Rean, spendhq-support@reancloud.comWe are not performing any activity on this end","Hello Team, The site down alert for the URL:https://secure.spendhq.com/login and https://preview.spendhq.com/login got resolved and Estimated Downtime was 1 minute. While checking the backend ELB, Instance, we found the below details. 1. From the NewPreview-ELB load balancer, we could see Latency was around 98590.56 NewPreview-ELB From the Backend Instance PRD-WW1_122 and PRD-WW2_6, we could see all the metrics are looking normal. Please find the ELB latency logs in the attachments section. Kindly validate these details and let us know if you have any queries.","Hello Spendhq-Team, This is to notify you that we received an alert site down on the URL: https://secure.spendhq.com/login and  https://preview.spendhq.com/login.The site down alert got recovered within a minute. we are analyzing more on this issue and will get back to you with updates. Please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EUIsW,Cloud Engineer Level 2,Closed,1067648,Incident,18-07-2017 23:08,,"Hello Matthew, We haven't heard back from you. spendhq-patch-server public ELB has been created in private subnet(SpendHQ_Web_Private_Subnet_1B) which is causing this unpredictable behavior. There are two solutions. 1. Either move the patch.spendhq.com domain also behind the Sophos VPN 2. Re-create the spendhq-patch-server ELB in the right public subnet and re-map the domain name to the new ELB. Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.###Next Action: Check whether we are getting any reply from customer else send a reminder in afternoon shift.###Hello Matthew,We haven't heard back from you.spendhq-patch-server public ELB has been created in private subnet(SpendHQ_Web_Private_Subnet_1B) which is causing this unpredictable behavior. There are two solutions. 1. Either move the patch.spendhq.com domain also behind the Sophos VPN 2. Re-create the spendhq-patch-server ELB in the right public subnet and re-map the domain name to the new ELB. Please let us know your thought regarding this.###Night shift: Send reminder if no response.###Next action: Evening shift: Check whether we receive any update from Client or else sent a reminder.###Hello Matthew, spendhq-patch-server public ELB has been created in private subnet(SpendHQ_Web_Private_Subnet_1B) which is causing this unpredictable behavior. There are two solutions. Either move the patch.spendhq.com domain also behind the Sophos VPNRe-create the spendhq-patch-server ELB in the right public subnet and re-map the domain name to the new ELB. I see you have already indicated the first solution. Do you still want us to go with the 1st option. Regards,-Praveen###Yogesh updated on OPS that he will call the customer for this issue.But Andrew has replied that he doesn't want the traffic to directly go to the instance.He wants to redirect it to Sophos server like the prod environment.Need to work on it.Also for site slowness issue need to call Yogesh and take updates.###Ok, I’m fairly confident that it’s the ELB, and not our office network. If I run a wget on my local box to http://patch.spendhq.com, every other time it gets stuck. If I run a wget on an outside linux to http://patch.spendhq.com, every other time it gets stuck If I run a wget on REAN DB2 to http://patch.spendhq.com, every other time it gets stuck If I run a wget on REAN DB2 to http://10.59.100.79, it goes through every single time. The other thing I noticed was that the ELB is configured to go direct to the EC2 servers, not to the Sophos. Can we change the ELB for l-spendhq-ELB and spendhq-patch-server to point to the Sophos and have the Sophos redirect?On the Sophosl-spendhq-ELB -> i-01efe7d9363f2a2da -> 10.59.10.107spendhq-patch-server -> i-0590f342fdc9965bb -> 10.59.100.79Thank you,###Hi Mattthew,We have done our analysis on the slowness issue you are facing. We did not notice slowness on patch.spendhq.com and l.spendhq.com.We try to dig further and compared logs on the server but we did not see any new errors coming in on patch.spendHQ web server logs.Please help us on the below items to further analyze the slowness and Sporadic timeout issue you are facing:1. Can you please shed more light on when you are facing this issue and if you are getting any timeout errors?2. Are you facing this issue when connected to VPN?3. We see the tomcat process running on patch.spendhq server, Are we running java application there? We also do not see any redirects pointe=ing to tomcat on patch.spendhq server.We tried to call Dusty Fowler in the EST day timing but the phone was going to voicemail. Could you please help in understanding more about the above questions and help us trying to understand the problem and the application environment.Please let us know if we can schedule a call on this. Thanks###Praveen updated that he will look into this issue in next 30 minutes.Post that go ahead and close other ticket by updating proper comment and follow it in single ticket###Next action: Check with CE3###[Mon Jul 10 18:55:49 2017] [notice] Digest: done[Mon Jul 10 18:55:49 2017] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Mon Jul 10 18:55:49 2017] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations[Wed Jul 12 16:23:12 2017] [notice] caught SIGTERM, shutting down[Wed Jul 12 16:23:12 2017] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Wed Jul 12 16:23:12 2017] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Wed Jul 12 16:23:12 2017] [notice] Digest: generating secret for digest authentication ...[Wed Jul 12 16:23:12 2017] [notice] Digest: done[Wed Jul 12 16:23:12 2017] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Wed Jul 12 16:23:12 2017] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations###[Wed Jul 12 17:58:42 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/errors_controller.php on line 100 fired on host patch.spendhq.com\\n, referer: https://patch.spendhq.com/spend_visibility/navigator[Wed Jul 12 17:58:57 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/errors_controller.php on line 100 fired on host patch.spendhq.com\\n, referer: https://patch.spendhq.com/spend_visibility/navigator[Wed Jul 12 17:59:12 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/errors_controller.php on line 100 fired on host patch.spendhq.com\\n, referer: https://patch.spendhq.com/spend_visibility/navigator[Wed Jul 12 17:59:27 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/errors_controller.php on line 100 fired on host patch.spendhq.com\\n, referer: https://patch.spendhq.com/spend_visibility/navigator[Wed Jul 12 17:59:42 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/errors_controller.php on line 100 fired on host patch.spendhq.com\\n, referer: https://patch.spendhq.com/spend_visibility/navigator[Wed Jul 12 17:59:57 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file###Veena couldn't get time to check on this and assign to Morning on call CE2 Lincy for further checking.###Hello Matthew,We have on board the ELB to REAN MGS contract and enabled the access logs.We have tried from our end and able to access the URL patch.spendhq.com publically. Could you please try it again and let us know if you are still facing the issue meanwhile we will discuss this internally and update you with the status.###We have onboard the ELB and enabled the access logs. We are able to access the URL publicly and sometimes after we tried to refresh the page the site was not responding. Escalated the issue with Veena for further checking on this.###Hello Matthew,Thanks for the update.We will onboard the ELB to REAN MGS contract and enable access logs. Also, we will look into the issue and will let you know the update.###Hello Matthew,The ELB patch.spendhq.com is not under REAN monitoring. Could you please let us know whether we need to onboard the ELB to REAN MGS contract and enable access logs to further look into this.###Hello Matthew,The domain patch.spendhq.com is publically accessible. Could you please try again by clearing your browser cache and let us know if you have any queries.","The domain patch.spendhq.com is not publicly available. Can you resolve this.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Patch.spendhq.com,,12-07-2017 21:58,145,0,SpendHQ,"Hello Matthew, We haven't heard back from you. spendhq-patch-server public ELB has been created in private subnet(SpendHQ_Web_Private_Subnet_1B) which is causing this unpredictable behavior. There are two solutions. 1. Either move the patch.spendhq.com domain also behind the Sophos VPN 2. Re-create the spendhq-patch-server ELB in the right public subnet and re-map the domain name to the new ELB. Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.",Next Action: Check whether we are getting any reply from customer else send a reminder in afternoon shift.,"Hello Matthew,We haven't heard back from you.spendhq-patch-server public ELB has been created in private subnet(SpendHQ_Web_Private_Subnet_1B) which is causing this unpredictable behavior. There are two solutions. 1. Either move the patch.spendhq.com domain also behind the Sophos VPN 2. Re-create the spendhq-patch-server ELB in the right public subnet and re-map the domain name to the new ELB. Please let us know your thought regarding this.",Night shift: Send reminder if no response.,Next action: Evening shift: Check whether we receive any update from Client or else sent a reminder.,"Hello Matthew, spendhq-patch-server public ELB has been created in private subnet(SpendHQ_Web_Private_Subnet_1B) which is causing this unpredictable behavior. There are two solutions. Either move the patch.spendhq.com domain also behind the Sophos VPNRe-create the spendhq-patch-server ELB in the right public subnet and re-map the domain name to the new ELB. I see you have already indicated the first solution. Do you still want us to go with the 1st option. Regards,-Praveen",Yogesh updated on OPS that he will call the customer for this issue.But Andrew has replied that he doesn't want the traffic to directly go to the instance.He wants to redirect it to Sophos server like the prod environment.Need to work on it.Also for site slowness issue need to call Yogesh and take updates.,"Ok, I’m fairly confident that it’s the ELB, and not our office network. If I run a wget on my local box to http://patch.spendhq.com, every other time it gets stuck. If I run a wget on an outside linux to http://patch.spendhq.com, every other time it gets stuck If I run a wget on REAN DB2 to http://patch.spendhq.com, every other time it gets stuck If I run a wget on REAN DB2 to http://10.59.100.79, it goes through every single time. The other thing I noticed was that the ELB is configured to go direct to the EC2 servers, not to the Sophos. Can we change the ELB for l-spendhq-ELB and spendhq-patch-server to point to the Sophos and have the Sophos redirect?On the Sophosl-spendhq-ELB -> i-01efe7d9363f2a2da -> 10.59.10.107spendhq-patch-server -> i-0590f342fdc9965bb -> 10.59.100.79Thank you,","Hi Mattthew,We have done our analysis on the slowness issue you are facing. We did not notice slowness on patch.spendhq.com and l.spendhq.com.We try to dig further and compared logs on the server but we did not see any new errors coming in on patch.spendHQ web server logs.Please help us on the below items to further analyze the slowness and Sporadic timeout issue you are facing:1. Can you please shed more light on when you are facing this issue and if you are getting any timeout errors?2. Are you facing this issue when connected to VPN?3. We see the tomcat process running on patch.spendhq server, Are we running java application there? We also do not see any redirects pointe=ing to tomcat on patch.spendhq server.We tried to call Dusty Fowler in the EST day timing but the phone was going to voicemail. Could you please help in understanding more about the above questions and help us trying to understand the problem and the application environment.Please let us know if we can schedule a call on this. Thanks",Praveen updated that he will look into this issue in next 30 minutes.Post that go ahead and close other ticket by updating proper comment and follow it in single ticket,Next action: Check with CE3,"[Mon Jul 10 18:55:49 2017] [notice] Digest: done[Mon Jul 10 18:55:49 2017] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Mon Jul 10 18:55:49 2017] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations[Wed Jul 12 16:23:12 2017] [notice] caught SIGTERM, shutting down[Wed Jul 12 16:23:12 2017] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Wed Jul 12 16:23:12 2017] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Wed Jul 12 16:23:12 2017] [notice] Digest: generating secret for digest authentication ...[Wed Jul 12 16:23:12 2017] [notice] Digest: done[Wed Jul 12 16:23:12 2017] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Wed Jul 12 16:23:12 2017] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations","[Wed Jul 12 17:58:42 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/errors_controller.php on line 100 fired on host patch.spendhq.com\\n, referer: https://patch.spendhq.com/spend_visibility/navigator[Wed Jul 12 17:58:57 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/errors_controller.php on line 100 fired on host patch.spendhq.com\\n, referer: https://patch.spendhq.com/spend_visibility/navigator[Wed Jul 12 17:59:12 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/errors_controller.php on line 100 fired on host patch.spendhq.com\\n, referer: https://patch.spendhq.com/spend_visibility/navigator[Wed Jul 12 17:59:27 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/errors_controller.php on line 100 fired on host patch.spendhq.com\\n, referer: https://patch.spendhq.com/spend_visibility/navigator[Wed Jul 12 17:59:42 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/errors_controller.php on line 100 fired on host patch.spendhq.com\\n, referer: https://patch.spendhq.com/spend_visibility/navigator[Wed Jul 12 17:59:57 2017] [error] [client 10.59.5.51] SHQ_Exception: [7]: JS Exception Fired while User 1653 and Company 235 were on URL https://patch.spendhq.com/spend_visibility/navigator, other: https://patch.spendhq.com/spend_visibility/navigator: (1) Uncaught SyntaxError: Unexpected token < in JSON at position 0 from Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36. in file",Veena couldn't get time to check on this and assign to Morning on call CE2 Lincy for further checking.,"Hello Matthew,We have on board the ELB to REAN MGS contract and enabled the access logs.We have tried from our end and able to access the URL patch.spendhq.com publically. Could you please try it again and let us know if you are still facing the issue meanwhile we will discuss this internally and update you with the status.",We have onboard the ELB and enabled the access logs. We are able to access the URL publicly and sometimes after we tried to refresh the page the site was not responding. Escalated the issue with Veena for further checking on this.,"Hello Matthew,Thanks for the update.We will onboard the ELB to REAN MGS contract and enable access logs. Also, we will look into the issue and will let you know the update.","Hello Matthew,The ELB patch.spendhq.com is not under REAN monitoring. Could you please let us know whether we need to onboard the ELB to REAN MGS contract and enable access logs to further look into this.","Hello Matthew,The domain patch.spendhq.com is publically accessible. Could you please try again by clearing your browser cache and let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XDkqw,Cloud Engineer Level 3,Closed,1099955,Incident,19-06-2018 23:41,,"As evening ops call Praveen updated that create a jira ticket for Spendhq Architecture diagram and production Cluster monitoring. I have created a Jira ticket for Production cluster monitoring.Jira ticket Link: https://reancloud.atlassian.net/browse/MSI-11313For architecture, Rohit will create a ticket in next sprint.###Hello Matthew,We are following this on Jira ticket.Hence we are closing this case and let us know if you have further queries.###Matthew Watts1:52 AM (0 minutes ago)to praveen.muppala, Allen, spendhq-support shq-elasticcache is a PROD machine.###Thank you Mat. Can you please provide which ones are production clusters and requires monitoring: shq-elasticcachespendhq-redissph-preview Regards,-Praveen###Please monitor as the maintenance scheduled from June 18 to 24###Please rebuild a new cluster in a different center immediately in that case. Send me the address when this is done. Matthew Watts | Manager, Application Development | SpendHQ®###It appears that shq-elasticcache.4ptbnu.ng.0001.use1.cache.amazonaws.com is our PROD instance and will not be effected by these changes. A cluster will not be needed at this time. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a MeetingA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###Hello Matt/Allen, There is no way we can avoid this downtime. This is an AWS Scheduled maintenance window. The only way, we can address is rebuild the nodes on our own scheduled time instead of AWS given time. Here is more detailed information on this maintenance window. See the AWS Scheduled Window for our resources. Fortunately, both the workloads Redis.spendhq-redis / spendhq-redis-001 / Jun 20 2018 08:30 UTCshq-elasticcache / shq-elasticcache-002 / Jun 24 2018 07:00 UTCSpendhq-Redis is a 4 node cluster and the maintenance is scheduled for the primary node(spendhq-redis-001). And all of our clusters are created in single AZ. However, AWS ensures the smooth transition and minimize the downtime as much as possible.shq-elasticcache is a 3 node cluster and the maintenance is scheduled for the replica node(shq-elasticcache-002). So no impact here. We will carefully watch the Spendhq-Redis during the maintenance window which 4:30AM EST on Wednesday. I hope in this time, we will have very minimal traffic. In case, if we see any issues let us know, if you have any steps that we need to follow through to bring the services up and running(may be restarting of Tomcat Services and etc) For better understanding on the components dependencies, we would like to setup a call to build a new architecture diagram that shows all the dependencies. I will ask Rohit to setup a meeting for next week on this topic. Regards,-Praveen###REAN, Please postpone this maintenance window as we cannot go down. These are PROD machines and are under your monitoring. There cannot be any downtime. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting###Can you share the ip addresses for these boxes? Also will these redis elasticcaches be usable during the maintenance timeframe? Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###Hello Team,This is to inform you that we have received notification from AWS regarding ElastiCache maintenance. This will affect your ElastiCache instances in the US-EAST-1 Region.Your following resources will be affected:-Spendhq-redis -Shq-elasticcache The maintenance schedule is:Start time: June 18, 2018 at 3:00:00 AM UTC+3 End time: June 24, 2018 at 4:00:00 AM UTC+3 As these are not under our monitoring and no action required from our side hence we are closing this case. Please reach us out in case of any query.###Hello Team,The maintenance already started. Next Action: As we are not monitoring the elastic cache need to check with him do we keep it open or we can close it.###Hello Team,We haven't heard back from you. Please review our previous comments regarding this case and get back to us if you have any queries.###Hello SpendHQ-Team We haven't heard back from you regarding this case.We have received notification from AWS regarding ElastiCache maintenance. This will affect your ElastiCache instances in the US-EAST-1 Region. Please note that this is a mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s). During the maintenance, your ElastiCache node(s) listed below will be replaced. The maintenance will occur during the time range provided for each node. Replacements generally take few minutes to complete; however, syncing the data from the master node can take additional time. Maintenance window details: Region/AZ: us-east-1 Start time: June 18, 2018 at 3:00:00 AM UTC+3 End time: June 24, 2018 at 4:00:00 AM UTC+3 Affected resources: 1. Name: spendhq-redis Engine version compatibility: 3.2.10 Primary end-point: spendhq-redis.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Availability Zones: us-east-1b Subnet Group: spendhq-redis Node type: cache.r4.large Engine: Redis Multi-AZ: Disabled Maintenance window time range: Jun 20 2018 08:30UTC 2. Name: shq-elasticcache Engine version compatibility: 3.2.4 Primary end-point: shq-elasticcache.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Availability Zones: us-east-1b Subnet Group: spendhq-redis Node type: cache.r3.large Engine: Redis Multi-AZ: Enabled Maintenance window time range: Jun 24 2018 07:00UTC Please take note of the above and let us know if you have any queries.###Need to review by Rohit.###After checking in the cloudfront I found that below are the affected resources: Directconnect Connection: -10gbps -1gbps Elasticache: -shq-elasticcache -spendhq-redis###Hello SpendHQ-Team This is a gentle reminder.We have received notification from AWS regarding ElastiCache maintenance. This will affect your ElastiCache instances in the US-EAST-1 Region. Please note that this is a mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s). During the maintenance, your ElastiCache node(s) listed below will be replaced. The maintenance will occur during the time range provided for each node. Replacements generally take few minutes to complete; however, syncing the data from the master node can take additional time. Maintenance window details: Region/AZ: us-east-1 Start time: June 18, 2018 at 3:00:00 AM UTC+3 End time: June 24, 2018 at 4:00:00 AM UTC+3 Affected resources: 1. Name: spendhq-redis Engine version compatibility: 3.2.10 Primary end-point: spendhq-redis.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Availability Zones: us-east-1b Subnet Group: spendhq-redis Node type: cache.r4.large Engine: Redis Multi-AZ: Disabled Maintenance window time range: Jun 20 2018 08:30UTC 2. Name: shq-elasticcache Engine version compatibility: 3.2.4 Primary end-point: shq-elasticcache.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Availability Zones: us-east-1b Subnet Group: spendhq-redis Node type: cache.r3.large Engine: Redis Multi-AZ: Enabled Maintenance window time range: Jun 24 2018 07:00UTC Please take note of the above and let us know if you have any queries.###Hello SpendHQ-TeamThis is to notify you that we have received notification from AWS regarding ElastiCache maintenance. This will affect your ElastiCache instances in the US-EAST-1 Region.Please note that this is a mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s).During the maintenance, your ElastiCache node(s) listed below will be replaced. The maintenance will occur during the time range provided for each node. Replacements generally take few minutes to complete; however, syncing the data from the master node can take additional time.Maintenance window details:Region/AZ: us-east-1Start time: June 18, 2018 at 3:00:00 AM UTC+3End time: June 24, 2018 at 4:00:00 AM UTC+3Affected resources:1.Name: spendhq-redisEngine version compatibility: 3.2.10Primary end-point: spendhq-redis.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379Availability Zones: us-east-1bSubnet Group: spendhq-redisNode type: cache.r4.largeEngine: RedisMulti-AZ: DisabledMaintenance window time range: Jun 20 2018 08:30UTC2.Name: shq-elasticcacheEngine version compatibility: 3.2.4Primary end-point: shq-elasticcache.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379Availability Zones: us-east-1bSubnet Group: spendhq-redisNode type: cache.r3.largeEngine: RedisMulti-AZ: EnabledMaintenance window time range: Jun 24 2018 07:00UTCPlease take note of the above and let us know if you have any queries.Thanks.","Your Amazon ElastiCache node(s) listed below are scheduled for replacement due to maintenance, which includes mandatory patches to improve security, reliability and operational performance. The maintenance will occur during the time range provided for each node. Please note that this is mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s).  Your ElastiCache instances scheduled for maintenance in the US-EAST-1 Region are located in the 'Affected resources' tab (format: ClusterName / NodeName / Replacement Time).  If we are unable to replace all of the nodes during this maintenance window, we will send you another notification on the remaining nodes’ next scheduled replacement.  Replacements generally take few minutes to complete; however, syncing the data from the master node can take additional time. The nodes will be unavailable to service requests during this period. Refer to the ElastiCache Maintenance FAQs[1].  If you have any questions or concerns, please contact AWS Support[2].   [1] https://aws.amazon.com/elasticache/elasticache-maintenance/ [2] https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_ELASTICACHE_MAINTENANCE_NOTIFICATION,,08-06-2018 07:51,280,0,SpendHQ,"As evening ops call Praveen updated that create a jira ticket for Spendhq Architecture diagram and production Cluster monitoring. I have created a Jira ticket for Production cluster monitoring.Jira ticket Link: https://reancloud.atlassian.net/browse/MSI-11313For architecture, Rohit will create a ticket in next sprint.","Hello Matthew,We are following this on Jira ticket.Hence we are closing this case and let us know if you have further queries.","Matthew Watts1:52 AM (0 minutes ago)to praveen.muppala, Allen, spendhq-support shq-elasticcache is a PROD machine.","Thank you Mat. Can you please provide which ones are production clusters and requires monitoring: shq-elasticcachespendhq-redissph-preview Regards,-Praveen",Please monitor as the maintenance scheduled from June 18 to 24,"Please rebuild a new cluster in a different center immediately in that case. Send me the address when this is done. Matthew Watts | Manager, Application Development | SpendHQ®","It appears that shq-elasticcache.4ptbnu.ng.0001.use1.cache.amazonaws.com is our PROD instance and will not be effected by these changes. A cluster will not be needed at this time. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a MeetingA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com","Hello Matt/Allen, There is no way we can avoid this downtime. This is an AWS Scheduled maintenance window. The only way, we can address is rebuild the nodes on our own scheduled time instead of AWS given time. Here is more detailed information on this maintenance window. See the AWS Scheduled Window for our resources. Fortunately, both the workloads Redis.spendhq-redis / spendhq-redis-001 / Jun 20 2018 08:30 UTCshq-elasticcache / shq-elasticcache-002 / Jun 24 2018 07:00 UTCSpendhq-Redis is a 4 node cluster and the maintenance is scheduled for the primary node(spendhq-redis-001). And all of our clusters are created in single AZ. However, AWS ensures the smooth transition and minimize the downtime as much as possible.shq-elasticcache is a 3 node cluster and the maintenance is scheduled for the replica node(shq-elasticcache-002). So no impact here. We will carefully watch the Spendhq-Redis during the maintenance window which 4:30AM EST on Wednesday. I hope in this time, we will have very minimal traffic. In case, if we see any issues let us know, if you have any steps that we need to follow through to bring the services up and running(may be restarting of Tomcat Services and etc) For better understanding on the components dependencies, we would like to setup a call to build a new architecture diagram that shows all the dependencies. I will ask Rohit to setup a meeting for next week on this topic. Regards,-Praveen","REAN, Please postpone this maintenance window as we cannot go down. These are PROD machines and are under your monitoring. There cannot be any downtime. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting",Can you share the ip addresses for these boxes? Also will these redis elasticcaches be usable during the maintenance timeframe? Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com,"Hello Team,This is to inform you that we have received notification from AWS regarding ElastiCache maintenance. This will affect your ElastiCache instances in the US-EAST-1 Region.Your following resources will be affected:-Spendhq-redis -Shq-elasticcache The maintenance schedule is:Start time: June 18, 2018 at 3:00:00 AM UTC+3 End time: June 24, 2018 at 4:00:00 AM UTC+3 As these are not under our monitoring and no action required from our side hence we are closing this case. Please reach us out in case of any query.","Hello Team,The maintenance already started. Next Action: As we are not monitoring the elastic cache need to check with him do we keep it open or we can close it.","Hello Team,We haven't heard back from you. Please review our previous comments regarding this case and get back to us if you have any queries.","Hello SpendHQ-Team We haven't heard back from you regarding this case.We have received notification from AWS regarding ElastiCache maintenance. This will affect your ElastiCache instances in the US-EAST-1 Region. Please note that this is a mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s). During the maintenance, your ElastiCache node(s) listed below will be replaced. The maintenance will occur during the time range provided for each node. Replacements generally take few minutes to complete; however, syncing the data from the master node can take additional time. Maintenance window details: Region/AZ: us-east-1 Start time: June 18, 2018 at 3:00:00 AM UTC+3 End time: June 24, 2018 at 4:00:00 AM UTC+3 Affected resources: 1. Name: spendhq-redis Engine version compatibility: 3.2.10 Primary end-point: spendhq-redis.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Availability Zones: us-east-1b Subnet Group: spendhq-redis Node type: cache.r4.large Engine: Redis Multi-AZ: Disabled Maintenance window time range: Jun 20 2018 08:30UTC 2. Name: shq-elasticcache Engine version compatibility: 3.2.4 Primary end-point: shq-elasticcache.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Availability Zones: us-east-1b Subnet Group: spendhq-redis Node type: cache.r3.large Engine: Redis Multi-AZ: Enabled Maintenance window time range: Jun 24 2018 07:00UTC Please take note of the above and let us know if you have any queries.",Need to review by Rohit.,After checking in the cloudfront I found that below are the affected resources: Directconnect Connection: -10gbps -1gbps Elasticache: -shq-elasticcache -spendhq-redis,"Hello SpendHQ-Team This is a gentle reminder.We have received notification from AWS regarding ElastiCache maintenance. This will affect your ElastiCache instances in the US-EAST-1 Region. Please note that this is a mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s). During the maintenance, your ElastiCache node(s) listed below will be replaced. The maintenance will occur during the time range provided for each node. Replacements generally take few minutes to complete; however, syncing the data from the master node can take additional time. Maintenance window details: Region/AZ: us-east-1 Start time: June 18, 2018 at 3:00:00 AM UTC+3 End time: June 24, 2018 at 4:00:00 AM UTC+3 Affected resources: 1. Name: spendhq-redis Engine version compatibility: 3.2.10 Primary end-point: spendhq-redis.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Availability Zones: us-east-1b Subnet Group: spendhq-redis Node type: cache.r4.large Engine: Redis Multi-AZ: Disabled Maintenance window time range: Jun 20 2018 08:30UTC 2. Name: shq-elasticcache Engine version compatibility: 3.2.4 Primary end-point: shq-elasticcache.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Availability Zones: us-east-1b Subnet Group: spendhq-redis Node type: cache.r3.large Engine: Redis Multi-AZ: Enabled Maintenance window time range: Jun 24 2018 07:00UTC Please take note of the above and let us know if you have any queries.","Hello SpendHQ-TeamThis is to notify you that we have received notification from AWS regarding ElastiCache maintenance. This will affect your ElastiCache instances in the US-EAST-1 Region.Please note that this is a mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s).During the maintenance, your ElastiCache node(s) listed below will be replaced. The maintenance will occur during the time range provided for each node. Replacements generally take few minutes to complete; however, syncing the data from the master node can take additional time.Maintenance window details:Region/AZ: us-east-1Start time: June 18, 2018 at 3:00:00 AM UTC+3End time: June 24, 2018 at 4:00:00 AM UTC+3Affected resources:1.Name: spendhq-redisEngine version compatibility: 3.2.10Primary end-point: spendhq-redis.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379Availability Zones: us-east-1bSubnet Group: spendhq-redisNode type: cache.r4.largeEngine: RedisMulti-AZ: DisabledMaintenance window time range: Jun 20 2018 08:30UTC2.Name: shq-elasticcacheEngine version compatibility: 3.2.4Primary end-point: shq-elasticcache.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379Availability Zones: us-east-1bSubnet Group: spendhq-redisNode type: cache.r3.largeEngine: RedisMulti-AZ: EnabledMaintenance window time range: Jun 24 2018 07:00UTCPlease take note of the above and let us know if you have any queries.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XxKEN,Cloud Engineer Level 2,Closed,1100406,Incident,22-06-2018 10:25,,"Hello Matthew,The RCA has been attached to the tickets attachments section. At this time we are marking this case as resolved and close and we will work on the preventive actions with the help of customer campaign.###Hello Matthew, Please find the attachment section for the RCA regarding the site down issue. Please review the RCA and let us know if you have any query.###@Team: Please share the RCA with customer as I have reviewed  this with Praveen and added the steps. Thanks!###@Praveen: I have updated the RCA. Please review and let us know if we are good to share this with customer. Thanks !Here is the link for the same:https://docs.google.com/document/d/193nQVS8AEsoPQ4duoll71LloeG-QFaET6V7BwMu2kEE/edit#Regards,Rohit Puri###In morning ops call, Rohit updated that he will work on corrective and preventive actions in RCA.###We have started to create RCA :https://docs.google.com/document/d/193nQVS8AEsoPQ4duoll71LloeG-QFaET6V7BwMu2kEE/edit#heading=h.y27967849eusNeed to complete the preventive action and share it with customer###Hello Matthew,In order to provide a recommendation for issues, we have to analyze the slow query and SQL process details during the time of the alert.  We will analyze all these details internally and will provide a recommendation in the RCA###From Matthew Watts:Please also provide suggestions to mitigate this from happening in the future.###Hello Team,The site down alert for the URL:https://secure.spendhq.com/login got resolved and Estimated Downtime was 18 minutes 59 seconds. While checking the backend ELB, instance and DB servers, we found the below details.1. From the NewPreview-ELB load balancer, we could see Latency was around 20837.0 NewPreview-ELB2. Surge Queue Length count went 300 From the Backend Instance PRD-WW1_122 and PRD-WW2_6, we could see1. CPU utilization and  Network IN/OUT was fine around that time but while checking the established connection was high on both instance at the time of the alert. Please find the details from each instance[root@ip-10-59-100-122 ~]# netstat | grep TIME_WAIT | wc -l42[root@ip-10-59-100-122 ~]# netstat | grep ESTABLISHED | wc -l575--------------------------------------------------------------------------------------------[root@ip-10-59-101-6 centos]# netstat | grep TIME_WAIT | wc -l102[root@ip-10-59-101-6 centos]# netstat | grep ESTABLISHED | wc -l605From the Backend DB server PRD-DB1, we could see 1. Sudden spike CPU usage around 80% on the DB server before the site down2. mysql and postgress process was consuming high CPU usage around that time3. Network IN was 6302.26 megabyte and Network OUT around 8251.10megabyte around the time of the alert.3. 1655 TIME_WAIT connection was established around that timePlease find the attached screenshots for more details.  We will further analyze and will share the RCA for this site down.###Hello Spendhq-Team, This is to notify you that we have received a site down alert on the URL:https://secure.spendhq.com/login. The site is not accessible. We are analysing this issue meanwhile please let us know if you are performing any changes on your end.","---------- Forwarded message ----------From: <ms@reancloud.com>Date: Wed, Jun 20, 2018 at 10:40 PMSubject: Detected Error on SpendHQ SecureTo: ms@reancloud.comWed, 20 Jun 2018 13:10:44 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30010 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, Atlanta-B US, London UK, Dallas-B US-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Secure,,20-06-2018 22:42,36,0,SpendHQ,"Hello Matthew,The RCA has been attached to the tickets attachments section. At this time we are marking this case as resolved and close and we will work on the preventive actions with the help of customer campaign.","Hello Matthew, Please find the attachment section for the RCA regarding the site down issue. Please review the RCA and let us know if you have any query.",@Team: Please share the RCA with customer as I have reviewed  this with Praveen and added the steps. Thanks!,"@Praveen: I have updated the RCA. Please review and let us know if we are good to share this with customer. Thanks !Here is the link for the same:https://docs.google.com/document/d/193nQVS8AEsoPQ4duoll71LloeG-QFaET6V7BwMu2kEE/edit#Regards,Rohit Puri","In morning ops call, Rohit updated that he will work on corrective and preventive actions in RCA.",We have started to create RCA :https://docs.google.com/document/d/193nQVS8AEsoPQ4duoll71LloeG-QFaET6V7BwMu2kEE/edit#heading=h.y27967849eusNeed to complete the preventive action and share it with customer,"Hello Matthew,In order to provide a recommendation for issues, we have to analyze the slow query and SQL process details during the time of the alert.  We will analyze all these details internally and will provide a recommendation in the RCA",From Matthew Watts:Please also provide suggestions to mitigate this from happening in the future.,"Hello Team,The site down alert for the URL:https://secure.spendhq.com/login got resolved and Estimated Downtime was 18 minutes 59 seconds. While checking the backend ELB, instance and DB servers, we found the below details.1. From the NewPreview-ELB load balancer, we could see Latency was around 20837.0 NewPreview-ELB2. Surge Queue Length count went 300 From the Backend Instance PRD-WW1_122 and PRD-WW2_6, we could see1. CPU utilization and  Network IN/OUT was fine around that time but while checking the established connection was high on both instance at the time of the alert. Please find the details from each instance[root@ip-10-59-100-122 ~]# netstat | grep TIME_WAIT | wc -l42[root@ip-10-59-100-122 ~]# netstat | grep ESTABLISHED | wc -l575--------------------------------------------------------------------------------------------[root@ip-10-59-101-6 centos]# netstat | grep TIME_WAIT | wc -l102[root@ip-10-59-101-6 centos]# netstat | grep ESTABLISHED | wc -l605From the Backend DB server PRD-DB1, we could see 1. Sudden spike CPU usage around 80% on the DB server before the site down2. mysql and postgress process was consuming high CPU usage around that time3. Network IN was 6302.26 megabyte and Network OUT around 8251.10megabyte around the time of the alert.3. 1655 TIME_WAIT connection was established around that timePlease find the attached screenshots for more details.  We will further analyze and will share the RCA for this site down.","Hello Spendhq-Team, This is to notify you that we have received a site down alert on the URL:https://secure.spendhq.com/login. The site is not accessible. We are analysing this issue meanwhile please let us know if you are performing any changes on your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001YL4bJ,Cloud Engineer Level 1,Closed,1100774,Incident,03-07-2018 15:59,,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello Team, We haven't heard back from you, Please review the below details and let us know if you any further queries. On further analysis, We could see the spike on latency and request count for the ELB preview-spendhq-xelb. and Network IN and OUT spike on the ELB backend server at the time of the alert. We couldn't find any suspicious activity for the servers Preview DB and Preview Web at AWS level. Please find the attached screenshot for the same. While checking the details at the instance level we could see there is PHP Fatal error and PHP Parse error from the logs /var/www/vhosts/files.spendhq.com/w2/logs/web2-94-https-preview.spendhq.com-error.log. [Wed Jun 27 20:25:58 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:26:06 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:26:07 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:37:18 2018] [error] [client 10.59.1.192] PHP Parse error: syntax error, unexpected ''] );' (T_CONSTANT_ENCAPSED_STRING), expecting ']' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 3788 [Wed Jun 27 20:57:39 2018] [error] [client 10.59.1.192] PHP Fatal error: Allowed memory size of 4294967296 bytes exhausted (tried to allocate 32 bytes) in /var/www/vhosts/secure.spendhq.com/public/cake/libs/configure.php on line 170, referer: https://preview.spendhq.com/files [Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 Also please find the logs from the Preview DB server. It seems here to have successfully, finally, got a DHCPACK after a LONG list of attempts Jun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPREQUEST on eth0 to 10.59.10.1 port 67 (xid=0x27dfc9f9) Jun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPACK from 10.59.10.1 (xid=0x27dfc9f9) Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jun 27 20:22:05 ip-10-59-10-135 dhclient[1664]: bound to 10.59.10.135 -- renewal in 1484 seconds.###Hello Team,We haven't heard back from you regarding the case for a while. Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.###Hello Team,We haven't heard back from you,Please review the below details and let us know if you any further queries.On further analysis, We could see the spike on latency and request count for the ELB preview-spendhq-xelb. and Network IN and OUT spike on the ELB backend server at the time of the alert. We couldn't find any suspicious activity for the servers Preview DB and Preview Web at AWS level. Please find the attached screenshot for the same. While checking the details at the instance level we could see there is PHP Fatal error and PHP Parse error from the logs /var/www/vhosts/files.spendhq.com/w2/logs/web2-94-https-preview.spendhq.com-error.log. [Wed Jun 27 20:25:58 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:26:06 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:26:07 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:37:18 2018] [error] [client 10.59.1.192] PHP Parse error: syntax error, unexpected ''] );' (T_CONSTANT_ENCAPSED_STRING), expecting ']' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 3788 [Wed Jun 27 20:57:39 2018] [error] [client 10.59.1.192] PHP Fatal error: Allowed memory size of 4294967296 bytes exhausted (tried to allocate 32 bytes) in /var/www/vhosts/secure.spendhq.com/public/cake/libs/configure.php on line 170, referer: https://preview.spendhq.com/files [Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 Also please find the logs from the Preview DB server. It seems here to have successfully, finally, got a DHCPACK after a LONG list of attempts Jun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPREQUEST on eth0 to 10.59.10.1 port 67 (xid=0x27dfc9f9) Jun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPACK from 10.59.10.1 (xid=0x27dfc9f9) Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jun 27 20:22:05 ip-10-59-10-135 dhclient[1664]: bound to 10.59.10.135 -- renewal in 1484 seconds.###Hello Team,This is the gentle reminder.Please review the details mentioned in the previous comment and let us know if you have any queries.###Hello Team,On further analysis, We could see the spike on latency and request count for the ELB preview-spendhq-xelb. and Network IN and OUT spike on the ELB backend server at the time of the alert.We couldn't find any suspicious activity for the servers Preview DB and Preview Web at AWS level. Please find the attached screenshot for the same.While checking the details at the instance level we could see there is PHP Fatal error and PHP Parse error from the logs /var/www/vhosts/files.spendhq.com/w2/logs/web2-94-https-preview.spendhq.com-error.log.[Wed Jun 27 20:25:58 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28[Wed Jun 27 20:26:06 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28[Wed Jun 27 20:26:07 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28[Wed Jun 27 20:37:18 2018] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ''] );' (T_CONSTANT_ENCAPSED_STRING), expecting ']' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 3788[Wed Jun 27 20:57:39 2018] [error] [client 10.59.1.192] PHP Fatal error:  Allowed memory size of 4294967296 bytes exhausted (tried to allocate 32 bytes) in /var/www/vhosts/secure.spendhq.com/public/cake/libs/configure.php on line 170, referer: https://preview.spendhq.com/files[Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28[Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28Also please find the logs from the Preview DB server. It seems here to have successfully, finally, got a DHCPACK after a LONG list of attemptsJun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPREQUEST on eth0 to 10.59.10.1 port 67 (xid=0x27dfc9f9)Jun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPACK from 10.59.10.1 (xid=0x27dfc9f9)Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jun 27 20:22:05 ip-10-59-10-135 dhclient[1664]: bound to 10.59.10.135 -- renewal in 1484 seconds.Kindly review this details and please revert back to us in case of any queries.###I tried to connect to Instance but SSH failed. Got Public key denied error.###Hello team,On our initial analysis we identified CPU and Network in and out Spikes at the time of the alert. Please find the screenshots in the document attached below.Checking on the ELB logs, we only identified a few 403 errors, from two IPs 108.189.80.56, 121.231.130.74. Please find the logs attached below. We are further checking on this and we'll get back with more updates.###Hello SpendHQ Team, This is to inform you that we received a site down alert on URL: https://preview.spendhq.com/login. The downtime lasted for 1 minute and eventually got recovered within 1 minute. We are analyzing this and will get back to you with further details on the issue. Thank you.","Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): California US, Frankfurt DE, London UK, Sydney-C AU-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Preview,,28-06-2018 01:56,134,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello Team, We haven't heard back from you, Please review the below details and let us know if you any further queries. On further analysis, We could see the spike on latency and request count for the ELB preview-spendhq-xelb. and Network IN and OUT spike on the ELB backend server at the time of the alert. We couldn't find any suspicious activity for the servers Preview DB and Preview Web at AWS level. Please find the attached screenshot for the same. While checking the details at the instance level we could see there is PHP Fatal error and PHP Parse error from the logs /var/www/vhosts/files.spendhq.com/w2/logs/web2-94-https-preview.spendhq.com-error.log. [Wed Jun 27 20:25:58 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:26:06 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:26:07 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:37:18 2018] [error] [client 10.59.1.192] PHP Parse error: syntax error, unexpected ''] );' (T_CONSTANT_ENCAPSED_STRING), expecting ']' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 3788 [Wed Jun 27 20:57:39 2018] [error] [client 10.59.1.192] PHP Fatal error: Allowed memory size of 4294967296 bytes exhausted (tried to allocate 32 bytes) in /var/www/vhosts/secure.spendhq.com/public/cake/libs/configure.php on line 170, referer: https://preview.spendhq.com/files [Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 Also please find the logs from the Preview DB server. It seems here to have successfully, finally, got a DHCPACK after a LONG list of attempts Jun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPREQUEST on eth0 to 10.59.10.1 port 67 (xid=0x27dfc9f9) Jun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPACK from 10.59.10.1 (xid=0x27dfc9f9) Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jun 27 20:22:05 ip-10-59-10-135 dhclient[1664]: bound to 10.59.10.135 -- renewal in 1484 seconds.","Hello Team,We haven't heard back from you regarding the case for a while. Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.","Hello Team,We haven't heard back from you,Please review the below details and let us know if you any further queries.On further analysis, We could see the spike on latency and request count for the ELB preview-spendhq-xelb. and Network IN and OUT spike on the ELB backend server at the time of the alert. We couldn't find any suspicious activity for the servers Preview DB and Preview Web at AWS level. Please find the attached screenshot for the same. While checking the details at the instance level we could see there is PHP Fatal error and PHP Parse error from the logs /var/www/vhosts/files.spendhq.com/w2/logs/web2-94-https-preview.spendhq.com-error.log. [Wed Jun 27 20:25:58 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:26:06 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:26:07 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 20:37:18 2018] [error] [client 10.59.1.192] PHP Parse error: syntax error, unexpected ''] );' (T_CONSTANT_ENCAPSED_STRING), expecting ']' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 3788 [Wed Jun 27 20:57:39 2018] [error] [client 10.59.1.192] PHP Fatal error: Allowed memory size of 4294967296 bytes exhausted (tried to allocate 32 bytes) in /var/www/vhosts/secure.spendhq.com/public/cake/libs/configure.php on line 170, referer: https://preview.spendhq.com/files [Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 [Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error: Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28 Also please find the logs from the Preview DB server. It seems here to have successfully, finally, got a DHCPACK after a LONG list of attempts Jun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPREQUEST on eth0 to 10.59.10.1 port 67 (xid=0x27dfc9f9) Jun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPACK from 10.59.10.1 (xid=0x27dfc9f9) Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jun 27 20:22:05 ip-10-59-10-135 dhclient[1664]: bound to 10.59.10.135 -- renewal in 1484 seconds.","Hello Team,This is the gentle reminder.Please review the details mentioned in the previous comment and let us know if you have any queries.","Hello Team,On further analysis, We could see the spike on latency and request count for the ELB preview-spendhq-xelb. and Network IN and OUT spike on the ELB backend server at the time of the alert.We couldn't find any suspicious activity for the servers Preview DB and Preview Web at AWS level. Please find the attached screenshot for the same.While checking the details at the instance level we could see there is PHP Fatal error and PHP Parse error from the logs /var/www/vhosts/files.spendhq.com/w2/logs/web2-94-https-preview.spendhq.com-error.log.[Wed Jun 27 20:25:58 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28[Wed Jun 27 20:26:06 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28[Wed Jun 27 20:26:07 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28[Wed Jun 27 20:37:18 2018] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ''] );' (T_CONSTANT_ENCAPSED_STRING), expecting ']' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 3788[Wed Jun 27 20:57:39 2018] [error] [client 10.59.1.192] PHP Fatal error:  Allowed memory size of 4294967296 bytes exhausted (tried to allocate 32 bytes) in /var/www/vhosts/secure.spendhq.com/public/cake/libs/configure.php on line 170, referer: https://preview.spendhq.com/files[Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28[Wed Jun 27 21:32:52 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function makeTopCorners() on null in /var/www/vhosts/secure.spendhq.com/public/app/views/errors/missing_table.ctp on line 28Also please find the logs from the Preview DB server. It seems here to have successfully, finally, got a DHCPACK after a LONG list of attemptsJun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPREQUEST on eth0 to 10.59.10.1 port 67 (xid=0x27dfc9f9)Jun 27 20:22:03 ip-10-59-10-135 dhclient[1664]: DHCPACK from 10.59.10.1 (xid=0x27dfc9f9)Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jun 27 20:22:03 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jun 27 20:22:05 ip-10-59-10-135 dhclient[1664]: bound to 10.59.10.135 -- renewal in 1484 seconds.Kindly review this details and please revert back to us in case of any queries.",I tried to connect to Instance but SSH failed. Got Public key denied error.,"Hello team,On our initial analysis we identified CPU and Network in and out Spikes at the time of the alert. Please find the screenshots in the document attached below.Checking on the ELB logs, we only identified a few 403 errors, from two IPs 108.189.80.56, 121.231.130.74. Please find the logs attached below. We are further checking on this and we'll get back with more updates.","Hello SpendHQ Team, This is to inform you that we received a site down alert on URL: https://preview.spendhq.com/login. The downtime lasted for 1 minute and eventually got recovered within 1 minute. We are analyzing this and will get back to you with further details on the issue. Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hQaGi,Cloud Engineer Level 1,Closed,1110144,Incident,10-01-2019 22:00,,"Hello Team,We are marking this case as closed and tracking it on the latest related issue we had in case 01110533.You can also review the analysis herein and let us know your thoughts on the same by responding to ticket No. 01110533.Thanks.Thanks.###Hello Team,We are downgrading the ticket priority from P1 to P2. Also Please review the latest comments mentioned on the ticket 01110488 and let us know your availability to schedule a call.###Hello SpendHQ,Please review the analysis and recommendations shared by us and get back to us, We are continuously receiving multiple alerts regarding the same URL and the same error.###Hello Team, On further analyzing the logs from the instance level we could see that there was no error reported during the time of the alert. But we noticed that there is no access log reported during the time of the alert. We went ahead and checked the httpd service uptime and it was running from 2018 there is no manual restart happened. [root@ip-10-59-100-122 httpd]# service httpd status httpd (pid 1941) is running... [root@ip-10-59-100-122 httpd]# ps -aux | grep 1941 Warning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.8/FAQ root 1941 0.0 0.0 367436 7800 ? Ss 2018 1:10 /usr/sbin/httpd Based on this we can confirm that there was no issue from the AWS or instance. Please let us know if there any dependency issue from the application side.We would recommend the following things to address the issues. 1. Enable the Datadog Apache integration to review the Apache metrics. 2. Enable the Datadog DB Integration(if the database is PostgreSQL or MySQL compatible, we can enable a plugin) Please let us know if you want to schedule a call to discuss further on this.###Hello TeamKindly check with the detailed analysis shared with you and Let us know if you want to schedule a call to discuss further on this.Thanks###@Afternoo team:Please do follow up with the team if we haven't received any response.###Hello SpendHQ Team,This is quick follow up.Please review the previous comment and let us know if you want to schedule a call to discuss further on this###As updated by Praveen, I have sent the summary note to the customer and requested a call to discuss further.###Hello SpendHQ Team,We have reviewed all the tiers of the application and narrowed down that the issue is with the end Web Application Server where we see it is taking high network in and network out during the outage time.1. The site is not really down, rather it is responding with very high latency.2. The Sophos ELB and Sophos UTM instances are operating normally. There are no suspicious elements in it.3. The Internal ELB is showing high latency which means the Prod Web Server response is very high during the outage time.4. The Prod Web response delay means the backend DB might be taking a long time to respond to the requests.In order to address this, we would recommend the following things.1. Enable the Datadog Apache integration to review the Apache metrics.2. Enable the Datadog DB Integration(if the database is PostgreSQL or MySQL compatible, we can enable a plugin)Please let us know if you want to schedule a call to discuss further on this.Regards,-REAN Team###The RCA is no good and it is not ready to share it with the customer. However, I would like to summarize the issue and share it with the customer,###Hello Matthew,Thank you for your patience as we work on the RCA.We will be sharing the complete document with you soon.Thanks###Team,Please follow up with Praveen for a review on this case.###Hi Praveen can you please review the analysis on Preview n Secure spendhq website down issueas much as Sophos is blocking unwanted traffic and it has to be doing this. And we have already block the ips which were suspiciousfor latency how do we resolve this issue as we will be getting in future too. Please guide on this. Thanks !###Hello Matthew,We are internally checking on this issue and will get back to you with an exact root cause.###Hello Rohit,We have repeated incident for the site down for the URL:https://secure.spendhq.com/login We have checked and found that the issue is related to latency and found some abuse ip from the ELB logs and informed to Client same.We have also checked the Instance level logs but didn't find any suspicious activity.As this issue is the event is occurring multiple times so we have updated the only Sequence of the event for this alert.LInk: https://docs.google.com/document/d/1Jy3FvHFW2ggBbQKsY4TTkiXh4wzY7s1jYKrGxdcF1Y8/editPlease look into this issue and let us know if we have any action item.###Hello Matthew,This is to inform that we have again received a site down alert on URL https://secure.spendhq.com/login and has recovered in 1 minute.From the instance level, there is no suspicious activity during the time of the alert. As this alert was triggered because of latency and the backend server was unable to handle the request within time. And after a minute backend server started working fine and the site got recovered.We are currently working on RCA.Please find the screenshot and ELB latency logs in the attachments section. Kindly validate these details and let us know if you have any queries.###Hello Matthew,We are actively working on RCA. We will get back to you soon.###Hello Matthew,This is to inform you that we have again received a site down alert on the URL https://secure.spendhq.com/login and has recovered in 4 minutes. Just like the previous incidences, the site is not actually down but seems to be having latency issues thus taking to long to load.We will be sharing the RCA on this case soon.Thank you for your patience.###@TeamRohit mentioned that he reviewed the analysis and he Pinged Praveen to look into this.Get in touch with Praveen for the updateThanks###Hello Team,We are actively working on the RCA and we will get back to you with an update shortly.###Hello Team,Based on Ops call discussion yesterday to analyse this case further specifically the elb logs, the case has been updated with additional analysis. We have pinged Praveen to review the case###Hello Matthew and Team, We are still receiving multiple site down alerts on the URL https://secure.spendhq.com/login each time recovering in an average of 2 minutes. This has been the case for the past 24 hoursJust like the previous incidences, the site seems to be having latency issues thus taking to long to load. While we continue with the preparation of the RCA, kindly let us know if there is an ongoing activity from your end. Thanks.###We again received an alert for around 9:17 PM IST and got recovered within 1 min.I checked for the logs at that 30 min around this alert and could find that there are almost 2000 2xx response counts as a total from the below three IP and these IPs are not listed as abusive and they are from US  itself12.69.52.226159.100.161.41192.67.66.5And could also find a high spike in the latency and the almost similar spike in the request count at both the internal and external Load Balancer. Attached the Cloud watch metrics screenshot at the time of the alert.2. From the internal load balancer I could see there are several 4xx response codes reported mainly .ie 403 errors are large in count compared to 404. and the URL which returns the 403 requests arePOST https://secure.spendhq.com:443/errors/report/js HTTP/1.1GET https://secure.spendhq.com:443/css/images/throbber.gif HTTP/1.1POST https://52.73.180.228:443/ HTTP/1.13. further checked for the URL which causing the high Backend processing time from the Internal ELB logs could find the below URLs GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546464502630 HTTP/1.1GET https://secure.spendhq.com:443/login/ HTTP/1.1NB: Attached the Cloud watch metrics for latency and request count at the time we received alert today.Please review this and Let us know the next action on this.Thanks###Hello Praveen As per your recommendation, I had checked the following things1. Fetched the logs for the last 12 hrs of alert and analyzed for the count of the 4xx errors and could find that the there is a large difference in the count of 4xx response at Secure ELB and NewPreview ELB(internal). Even though we can see about 7000 4xx response reported within 12 hours period Further I checked with the URL which caused with the high latency from the Sophos Level and I could find from the WAF logs that the Url which directed to the path  https://secure.spendhq.com/reports/….  and also get reported to have a response time of greater than 30000 milliseconds which actually caused in the alert as in the Wormly the time out is set to 30 seconds==============================2019:01:03-16:59:58 spendhq httpd: id=0299 srcip=10.59.1.217 localip=10.59.1.192 size=454 user=- host=10.59.1.217 method=GET statuscode=200 reason=- extra=- exceptions=- time=675452 url=/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/ server=secure.spendhq.com port=443 query=?_=1546468001943 referer=https://secure.spendhq.com/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup cookie=AWSELB=4D3F4B4B1E321A5E0A81F3C0A74241EE3B892219851142549AC17122CB3D66E70CF358DAC94A2FAD1846A3C637D8FA36A500FA7946EAACFAFF64C7789CDD82C72D672A30CF; __utmc=267748364; CakeCookie[shq_random]=Q2FrZQ%3D%3D.BEGpTF8m%2BawTitj8G5tR7DPPTAUBlhARYOV9YCh3TVfTVZvC; __utmz=267748364.1546528652.37.12.utmcsr=spendhq.com|utmccn=(referral)|utmcmd=referral|utmcct=/; SHQ=%7B%22document_store%22%3A%7B%22email%22%3Afalse%2C%22company%22%3A%22American+Tire+Distributors%22%7D%7D; __utma=267748364.54448570.1526386970.1546467912.1546528652.37; CAKEPHP=5te88vrkal4r6073d536tf2dfl9fsooo3ck9hvrmvombom1ll8m0; __hstc=138704364.3f310df6d52fc2990bb1349b0ae0b212.1526386953585.2019:01:03-16:59:58 spendhq httpd: id=0299 srcip=10.59.1.217 localip=10.59.1.192 size=40165 user=- host=10.59.1.217 method=GET statuscode=200 reason=- extra=- exceptions=- time=639274 url=/login server=secure.spendhq.com port=443 query= referer=- cookie=- set-cookie=CAKEPHP=t1fo48lj8rpg1eh0raktsh93s1l65vfls3m4u6ciqv78jamub450; expires=Thu, 07-Mar-2019 04:59:58 GMT; Max-Age=5400000; path=/; secure; HttpOnly, CakeCookie[shq_random]=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT; Max-Age=0; path=/; httponly, AWSELB=4D3F4B4B1E321A5E0A81F3C0A74241EE3B89221985EAD8EDF10943DDF1247322700E9E23054A2FAD1846A3C637D8FA36A500FA7946EAACFAFF64C7789CDD82C72D672A30CF;PATH=/ uid=XC4-jgo7AcAAAGFACaAAAABx2019:01:03-16:59:59 spendhq httpd: id=0299 srcip=10.59.1.217 localip=10.59.1.192 size=494 user=- host=10.59.1.217 method=GET statuscode=200 reason=- extra=- exceptions=- time=703169 url=/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/ server=secure.spendhq.com port=443 query=?_=1546464512812 referer=https://secure.spendhq.com/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup cookie=__utmz=267748364.1533740242.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); __utmc=267748364; CAKEPHP=ldq1mkolel6g62e64441b83ofg7to3bimkcvkbjvh36g1o9a2971; AWSELB=4D3F4B4B1E321A5E0A81F3C0A74241EE3B892219851142549AC17122CB3D66E70CF358DAC94A2FAD1846A3C637D8FA36A500FA7946EAACFAFF64C7789CDD82C72D672A30CF; __utma=267748364.730845044.1533740242.1546461413.1546529398.37 set-cookie=- uid=XC4-jgo7AcAAAGFACaEAAACL======###Hello Team,This to inform you that we have been receiving multiple site down alerts on the URL https://secure.spendhq.com/login over the last hour that is recovering in an average of 2 minutes.Just like the previous incidences, the site is not actually down but seems to be having latency issues thus taking to long to load.We are analyzing the issue as we work in tandem on the RCA.We will keep you posted in a while.Thanks.###Hello Team,I checked with Rohit he mentioned he is reviewing the RCA.###Hello Team,We have received a site down and we have analyzed and closed the case as the root cause of the site down was same. case id : 01110169###Hello Rohit,Please have a look at the RCA. I have not added Preventive Actions, so check that section if neededhttps://docs.google.com/document/d/1Jy3FvHFW2ggBbQKsY4TTkiXh4wzY7s1jYKrGxdcF1Y8/edit?usp=sharing###Hello Matthew, This is to let you know that the site has now been stable for the past 5 hours. Therefore, we have resumed monitoring on the URL https://secure.spendhq.com/login.As updated earlier, we will be sharing the RCA with you soon,Thanks###Request URL from the abusive IP=================GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498615 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498616 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498612 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498617 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498618 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498619 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498620 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498621 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498622 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498623 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498624 HTTP/1.1###Access logs =========[root@ip-10-59-100-122 production]# tail -1000 10.59.101.6-access.log | grep 02/Jan/201910.59.1.65 - - [02/Jan/2019:00:36:33 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:00:36:33 +0000] GET / HTTP/1.1 302 - http://54.84.128.76:80/ Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:00:36:34 +0000] GET /login HTTP/1.1 301 234 - Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:00:38:40 +0000] GET / HTTP/1.1 302 - - Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:00:38:40 +0000] GET /login HTTP/1.1 301 234 - Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:00:38:40 +0000] GET /login HTTP/1.1 200 34886 http://54.84.128.76/login Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:01:17:13 +0000] GET / HTTP/1.1 301 227 - -10.59.1.65 - - [02/Jan/2019:01:26:27 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.3610.59.1.65 - - [02/Jan/2019:02:10:43 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/601.7.7 (KHTML, like Gecko) Version/9.1.2 Safari/601.7.710.59.1.65 - - [02/Jan/2019:02:23:43 +0000] GET / HTTP/1.1 301 229 - HTTP Banner Detection (https://security.ipip.net)10.59.1.65 - - [02/Jan/2019:02:55:59 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/601.7.7 (KHTML, like Gecko) Version/9.1.2 Safari/601.7.710.59.1.65 - - [02/Jan/2019:03:20:35 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.3610.59.1.65 - - [02/Jan/2019:04:33:14 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.3610.59.1.65 - - [02/Jan/2019:04:48:28 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.3610.59.1.65 - - [02/Jan/2019:04:55:10 +0000] GET / HTTP/1.1 301 227 - Mozilla/5.0(WindowsNT6.1;rv:31.0)Gecko/20100101Firefox/31.010.59.1.65 - - [02/Jan/2019:08:25:14 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.3610.59.1.65 - user [02/Jan/2019:11:11:32 +0000] GET /backupsettings.conf HTTP/1.1 404 28787 - python-requests/2.18.410.59.1.65 - - [02/Jan/2019:11:11:58 +0000] GET /backupsettings.conf HTTP/1.1 301 248 - python-requests/2.18.410.59.1.65 - - [02/Jan/2019:12:25:57 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.3610.59.1.65 - - [02/Jan/2019:14:14:43 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.3610.59.1.65 - - [02/Jan/2019:14:46:53 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.3610.59.1.65 - - [02/Jan/2019:15:36:30 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/601.7.7 (KHTML, like Gecko) Version/9.1.2 Safari/601.7.710.59.1.65 - - [02/Jan/2019:15:36:30 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.3610.59.1.65 - - [02/Jan/2019:15:45:46 +0000] GET / HTTP/1.1 301 229 - -10.59.1.65 - - [02/Jan/2019:16:07:59 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36###@TeamI have further checked with the access logs and Cloud watch metrics and cannot see anything suspicious apart from the latency spike and CPU (CPU spikes to a value around 60% when the alert triggers)Please check further on this and work on RCA.The alert is still in the muted state.###Hello Matthew,We have further checked with Praveen for the recommendation on this as you were not available and to resolve the issue we have blocked the abusive IP at NACL level.we will work on the RCA and will share with you.Thanks###Hello Mathew We have tried to reach out you via phone as the alert is triggering multiple times. As you are not available we have sent a voicemail to with the details. Kindly get back to us on this case as soon as possible.We are still waiting for your approval to further proceed with blocking of the IP which is listed as abusiveThanks###@Team kindly work on the RCA as Matt still needs that from us.###Hello TeamI tried to contact Matthew via phone but he was not available. So dropped a voice mail to him to get approval to mute the abusive IP to resolve the issue. Informed the same to Rohit and as the alert triggers continuously, he mentioned to mute the URL.###Hello TeamWe have further checked with the instance level and could see that there is a high number of connections and httpd process is accessing the high number of files.lsof | grep httpd| wc -l49840[root@ip-10-59-100-122 centos]# netstat | grep http | wc -l420We have further checked with the NETWORK I/O connection again and could see a high spike.[root@ip-10-59-100-122 centos]# netstat -a | grep TIME | wc -l1552[root@ip-10-59-100-122 centos]# netstat -a | grep ESTABLISHED | wc -l510[root@ip-10-59-100-122 centos]# netstat -a | grep CLOSE_WAIT | wc -l0[root@ip-10-59-100-122 centos]# netstat -a | grep LISTEN | wc -l63We could also find a small spike in the CPU at the time of alert and is htppd process is consuming high cpu.[root@ip-10-59-100-122 centos]# free -m             total       used       free     shared    buffers     cachedMem:         61397      37354      24043          0        141       4306-/+ buffers/cache:      32907      28490Swap:            0          0          0[root@ip-10-59-100-122 centos]# top -b -n1 | head -n30top - 16:45:28 up 18 days, 10 min,  1 user,  load average: 1.54, 1.60, 1.94Tasks: 597 total,   3 running, 592 sleeping,   2 stopped,   0 zombieCpu(s):  4.1%us,  0.7%sy,  0.0%ni, 94.8%id,  0.4%wa,  0.0%hi,  0.0%si,  0.0%stMem:  62871452k total, 38109916k used, 24761536k free,   144576k buffersSwap:        0k total,        0k used,        0k free,  4284792k cached  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                                                                             31504 apache    20   0  462m 108m 9980 S 50.9  0.2   2:09.59 httpd                                                                                                                                                               27654 apache    20   0  396m  40m 9144 R 41.1  0.1   0:05.16 httpd                                                                                                                                                               12468 apache    20   0  485m 131m 9564 R 35.2  0.2   2:12.07 httpd                                                                                                                                                                1139 dd-agent  20   0 47724  21m 4188 S 27.4  0.0 189:53.06 process-agent                                                                                                                                                       25201 apache    20   0  407m  52m 9500 S 27.4  0.1   0:12.60 httpd                                                                                                                                                                      Kindly provide us an approval to block the abusive IP listed below that seems which causes for High network I/O to the instance.167.99.97.223 ISP	DigitalOcean LLC Usage Type	Data Center/Web Hosting/Transit Domain Name	Unknown Country	United States City	Santa Clara, California This IP address has been reported a total of 17 times from 14 distinct sources. Confidence of Abuse is 100% 71.6.165.200 ISP	CARInet Inc. Usage Type	Data Center/Web Hosting/Transit Hostname(s)	census12.shodan.io Domain Name	Unknown Country	United States City	San Diego, California This IP address has been reported a total of 2296 times from 412 distinct sources. Confidence of Abuse is 100% 3.IP:	24.3.113.228Decimal:	402878948Hostname:	c-24-3-113-228.hsd1.pa.comcast.netASN:	7922Let us know your update on this.Thanks###Hello Matt,First time the alert got triggered, requests initially timed out after 30001 milliseconds above our monitoring tool's set threshold of 30000 milliseconds. That's a .0001 difference.As earlier on mentioned, the site was only taking long to serve requests, but never actually down.Checking from the AWS ELB dashboard, we did have some spikes in the Average Latency monitor, the highest recored over the period being 79208 milliseconds at around 3:09 PM UTC. Request count on was 1 on average for the last one hour leading up to the the alert.The ELB's backend instance (i-0ace70ce06368e4a7, Private IP: 10.59.100.122) had most of it's metrics operating normally. CPU utiliztion at its peak was at 60% and below that value over most of the alert period. There were also some spikes on the instance's Network In monitor, highest reading recorded over the alert period being 543611665 bytes.[root@ip-10-59-100-122 ~]# netstat | grep TIME_WAIT | wc -l 252 [root@ip-10-59-100-122 ~]# netstat | grep ESTABLISHED | wc -l497 [root@ip-10-59-100-122 ~]# netstat | grep LISTEN | wc -l63From assesing the ELB acces logs, we observed a total of 48, 4xx related errors. Below are the top 5 request URLs with their total count. From 14:00 UTC - 15:00 UTC404 - GET https://secure.spendhq.com:443/css/images/throbber.gif HTTP/1.1 - Total count = 34400 - GET https://secure.spendhq.com:443/vendor_information/get_insights/1540930 HTTP/1.1 - Total count = 3400 - GET https://secure.spendhq.com:443/vendor_information/get_insights/433870 HTTP/1.1 - Total count =2404 - GET https://secure.spendhq.com:443/apple-touch-icon-precomposed.png HTTP/1.1 - Total count =2404 - GET https://secure.spendhq.com:443/apple-touch-icon.png HTTP/1.1 - Total count =2We found these two IPs to be abusive and making these and other requests:167.99.97.223ISP	DigitalOcean LLCUsage Type	Data Center/Web Hosting/TransitDomain Name	UnknownCountry	 United StatesCity	Santa Clara, CaliforniaThis IP address has been reported a total of 17 times from 14 distinct sources.Confidence of Abuse is 100%71.6.165.200ISP	CARInet Inc.Usage Type	Data Center/Web Hosting/TransitHostname(s)	census12.shodan.io Domain Name	UnknownCountry	 United StatesCity	San Diego, CaliforniaThis IP address has been reported a total of 2296 times from 412 distinct sources.Confidence of Abuse is 100%We have attached all the relevant monitor screenshots and ELB logs in the attachment section for your perusal. Kindly go through them all as you await the RCA to be worked on.Instance Details:-----------------Name: PRD-WW1_122Instance ID: i-0ace70ce06368e4a7AZ: us-east-1bInstance Type: r4.2xlargeVPC: ID: vpc-76df7212Private IP: 10.59.100.122-----------------ELB Details:------------Name: Secure-SpendHQ-ELBDNS Name: Secure-SpendHQ-ELB-288546960.us-east-1.elb.amazonaws.com Type: internet-facingScheme: internet-facing------------Thanks.###Hello Matt,The site wasn't down per se, but was rather taking long to load. From our initial analysis, we can see that requests were taking longer than usual to process:C02XH05GJG5M:spendhq niali$ for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://secure.spendhq.com/login -so /dev/null; done;HTTPCode=200 TotalTime=57.308673HTTPCode=200 TotalTime=5.000868HTTPCode=200 TotalTime=2.729599HTTPCode=200 TotalTime=2.056782HTTPCode=200 TotalTime=2.084747HTTPCode=200 TotalTime=2.177897We are working on the RCA as requested and will be sharing it once completed. The alert has since then recovered as well after again re-triggering.Thanks###Informed MGS Leads via mail.###[Via mail]Let’s get an RCA for this please.--Matt###Hello Team,This is to inform you that we received a site down alert for the following URL: https://secure.spendhq.com/login which later on recovered automatically after a minute.We are analyzing this and will be sharing more info.Thanks.","Wed, 02 Jan 2019 09:51:10 -0500Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Dallas-C US, London UK, California US, Frankfurt DE-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,02-01-2019 20:24,194,0,SpendHQ,"Hello Team,We are marking this case as closed and tracking it on the latest related issue we had in case 01110533.You can also review the analysis herein and let us know your thoughts on the same by responding to ticket No. 01110533.Thanks.Thanks.","Hello Team,We are downgrading the ticket priority from P1 to P2. Also Please review the latest comments mentioned on the ticket 01110488 and let us know your availability to schedule a call.","Hello SpendHQ,Please review the analysis and recommendations shared by us and get back to us, We are continuously receiving multiple alerts regarding the same URL and the same error.","Hello Team, On further analyzing the logs from the instance level we could see that there was no error reported during the time of the alert. But we noticed that there is no access log reported during the time of the alert. We went ahead and checked the httpd service uptime and it was running from 2018 there is no manual restart happened. [root@ip-10-59-100-122 httpd]# service httpd status httpd (pid 1941) is running... [root@ip-10-59-100-122 httpd]# ps -aux | grep 1941 Warning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.8/FAQ root 1941 0.0 0.0 367436 7800 ? Ss 2018 1:10 /usr/sbin/httpd Based on this we can confirm that there was no issue from the AWS or instance. Please let us know if there any dependency issue from the application side.We would recommend the following things to address the issues. 1. Enable the Datadog Apache integration to review the Apache metrics. 2. Enable the Datadog DB Integration(if the database is PostgreSQL or MySQL compatible, we can enable a plugin) Please let us know if you want to schedule a call to discuss further on this.",Hello TeamKindly check with the detailed analysis shared with you and Let us know if you want to schedule a call to discuss further on this.Thanks,@Afternoo team:Please do follow up with the team if we haven't received any response.,"Hello SpendHQ Team,This is quick follow up.Please review the previous comment and let us know if you want to schedule a call to discuss further on this","As updated by Praveen, I have sent the summary note to the customer and requested a call to discuss further.","Hello SpendHQ Team,We have reviewed all the tiers of the application and narrowed down that the issue is with the end Web Application Server where we see it is taking high network in and network out during the outage time.1. The site is not really down, rather it is responding with very high latency.2. The Sophos ELB and Sophos UTM instances are operating normally. There are no suspicious elements in it.3. The Internal ELB is showing high latency which means the Prod Web Server response is very high during the outage time.4. The Prod Web response delay means the backend DB might be taking a long time to respond to the requests.In order to address this, we would recommend the following things.1. Enable the Datadog Apache integration to review the Apache metrics.2. Enable the Datadog DB Integration(if the database is PostgreSQL or MySQL compatible, we can enable a plugin)Please let us know if you want to schedule a call to discuss further on this.Regards,-REAN Team","The RCA is no good and it is not ready to share it with the customer. However, I would like to summarize the issue and share it with the customer,","Hello Matthew,Thank you for your patience as we work on the RCA.We will be sharing the complete document with you soon.Thanks","Team,Please follow up with Praveen for a review on this case.",Hi Praveen can you please review the analysis on Preview n Secure spendhq website down issueas much as Sophos is blocking unwanted traffic and it has to be doing this. And we have already block the ips which were suspiciousfor latency how do we resolve this issue as we will be getting in future too. Please guide on this. Thanks !,"Hello Matthew,We are internally checking on this issue and will get back to you with an exact root cause.","Hello Rohit,We have repeated incident for the site down for the URL:https://secure.spendhq.com/login We have checked and found that the issue is related to latency and found some abuse ip from the ELB logs and informed to Client same.We have also checked the Instance level logs but didn't find any suspicious activity.As this issue is the event is occurring multiple times so we have updated the only Sequence of the event for this alert.LInk: https://docs.google.com/document/d/1Jy3FvHFW2ggBbQKsY4TTkiXh4wzY7s1jYKrGxdcF1Y8/editPlease look into this issue and let us know if we have any action item.","Hello Matthew,This is to inform that we have again received a site down alert on URL https://secure.spendhq.com/login and has recovered in 1 minute.From the instance level, there is no suspicious activity during the time of the alert. As this alert was triggered because of latency and the backend server was unable to handle the request within time. And after a minute backend server started working fine and the site got recovered.We are currently working on RCA.Please find the screenshot and ELB latency logs in the attachments section. Kindly validate these details and let us know if you have any queries.","Hello Matthew,We are actively working on RCA. We will get back to you soon.","Hello Matthew,This is to inform you that we have again received a site down alert on the URL https://secure.spendhq.com/login and has recovered in 4 minutes. Just like the previous incidences, the site is not actually down but seems to be having latency issues thus taking to long to load.We will be sharing the RCA on this case soon.Thank you for your patience.",@TeamRohit mentioned that he reviewed the analysis and he Pinged Praveen to look into this.Get in touch with Praveen for the updateThanks,"Hello Team,We are actively working on the RCA and we will get back to you with an update shortly.","Hello Team,Based on Ops call discussion yesterday to analyse this case further specifically the elb logs, the case has been updated with additional analysis. We have pinged Praveen to review the case","Hello Matthew and Team, We are still receiving multiple site down alerts on the URL https://secure.spendhq.com/login each time recovering in an average of 2 minutes. This has been the case for the past 24 hoursJust like the previous incidences, the site seems to be having latency issues thus taking to long to load. While we continue with the preparation of the RCA, kindly let us know if there is an ongoing activity from your end. Thanks.",We again received an alert for around 9:17 PM IST and got recovered within 1 min.I checked for the logs at that 30 min around this alert and could find that there are almost 2000 2xx response counts as a total from the below three IP and these IPs are not listed as abusive and they are from US  itself12.69.52.226159.100.161.41192.67.66.5And could also find a high spike in the latency and the almost similar spike in the request count at both the internal and external Load Balancer. Attached the Cloud watch metrics screenshot at the time of the alert.2. From the internal load balancer I could see there are several 4xx response codes reported mainly .ie 403 errors are large in count compared to 404. and the URL which returns the 403 requests arePOST https://secure.spendhq.com:443/errors/report/js HTTP/1.1GET https://secure.spendhq.com:443/css/images/throbber.gif HTTP/1.1POST https://52.73.180.228:443/ HTTP/1.13. further checked for the URL which causing the high Backend processing time from the Internal ELB logs could find the below URLs GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546464502630 HTTP/1.1GET https://secure.spendhq.com:443/login/ HTTP/1.1NB: Attached the Cloud watch metrics for latency and request count at the time we received alert today.Please review this and Let us know the next action on this.Thanks,"Hello Praveen As per your recommendation, I had checked the following things1. Fetched the logs for the last 12 hrs of alert and analyzed for the count of the 4xx errors and could find that the there is a large difference in the count of 4xx response at Secure ELB and NewPreview ELB(internal). Even though we can see about 7000 4xx response reported within 12 hours period Further I checked with the URL which caused with the high latency from the Sophos Level and I could find from the WAF logs that the Url which directed to the path  https://secure.spendhq.com/reports/….  and also get reported to have a response time of greater than 30000 milliseconds which actually caused in the alert as in the Wormly the time out is set to 30 seconds==============================2019:01:03-16:59:58 spendhq httpd: id=0299 srcip=10.59.1.217 localip=10.59.1.192 size=454 user=- host=10.59.1.217 method=GET statuscode=200 reason=- extra=- exceptions=- time=675452 url=/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/ server=secure.spendhq.com port=443 query=?_=1546468001943 referer=https://secure.spendhq.com/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup cookie=AWSELB=4D3F4B4B1E321A5E0A81F3C0A74241EE3B892219851142549AC17122CB3D66E70CF358DAC94A2FAD1846A3C637D8FA36A500FA7946EAACFAFF64C7789CDD82C72D672A30CF; __utmc=267748364; CakeCookie[shq_random]=Q2FrZQ%3D%3D.BEGpTF8m%2BawTitj8G5tR7DPPTAUBlhARYOV9YCh3TVfTVZvC; __utmz=267748364.1546528652.37.12.utmcsr=spendhq.com|utmccn=(referral)|utmcmd=referral|utmcct=/; SHQ=%7B%22document_store%22%3A%7B%22email%22%3Afalse%2C%22company%22%3A%22American+Tire+Distributors%22%7D%7D; __utma=267748364.54448570.1526386970.1546467912.1546528652.37; CAKEPHP=5te88vrkal4r6073d536tf2dfl9fsooo3ck9hvrmvombom1ll8m0; __hstc=138704364.3f310df6d52fc2990bb1349b0ae0b212.1526386953585.2019:01:03-16:59:58 spendhq httpd: id=0299 srcip=10.59.1.217 localip=10.59.1.192 size=40165 user=- host=10.59.1.217 method=GET statuscode=200 reason=- extra=- exceptions=- time=639274 url=/login server=secure.spendhq.com port=443 query= referer=- cookie=- set-cookie=CAKEPHP=t1fo48lj8rpg1eh0raktsh93s1l65vfls3m4u6ciqv78jamub450; expires=Thu, 07-Mar-2019 04:59:58 GMT; Max-Age=5400000; path=/; secure; HttpOnly, CakeCookie[shq_random]=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT; Max-Age=0; path=/; httponly, AWSELB=4D3F4B4B1E321A5E0A81F3C0A74241EE3B89221985EAD8EDF10943DDF1247322700E9E23054A2FAD1846A3C637D8FA36A500FA7946EAACFAFF64C7789CDD82C72D672A30CF;PATH=/ uid=XC4-jgo7AcAAAGFACaAAAABx2019:01:03-16:59:59 spendhq httpd: id=0299 srcip=10.59.1.217 localip=10.59.1.192 size=494 user=- host=10.59.1.217 method=GET statuscode=200 reason=- extra=- exceptions=- time=703169 url=/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/ server=secure.spendhq.com port=443 query=?_=1546464512812 referer=https://secure.spendhq.com/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup cookie=__utmz=267748364.1533740242.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); __utmc=267748364; CAKEPHP=ldq1mkolel6g62e64441b83ofg7to3bimkcvkbjvh36g1o9a2971; AWSELB=4D3F4B4B1E321A5E0A81F3C0A74241EE3B892219851142549AC17122CB3D66E70CF358DAC94A2FAD1846A3C637D8FA36A500FA7946EAACFAFF64C7789CDD82C72D672A30CF; __utma=267748364.730845044.1533740242.1546461413.1546529398.37 set-cookie=- uid=XC4-jgo7AcAAAGFACaEAAACL======","Hello Team,This to inform you that we have been receiving multiple site down alerts on the URL https://secure.spendhq.com/login over the last hour that is recovering in an average of 2 minutes.Just like the previous incidences, the site is not actually down but seems to be having latency issues thus taking to long to load.We are analyzing the issue as we work in tandem on the RCA.We will keep you posted in a while.Thanks.","Hello Team,I checked with Rohit he mentioned he is reviewing the RCA.","Hello Team,We have received a site down and we have analyzed and closed the case as the root cause of the site down was same. case id : 01110169","Hello Rohit,Please have a look at the RCA. I have not added Preventive Actions, so check that section if neededhttps://docs.google.com/document/d/1Jy3FvHFW2ggBbQKsY4TTkiXh4wzY7s1jYKrGxdcF1Y8/edit?usp=sharing","Hello Matthew, This is to let you know that the site has now been stable for the past 5 hours. Therefore, we have resumed monitoring on the URL https://secure.spendhq.com/login.As updated earlier, we will be sharing the RCA with you soon,Thanks",Request URL from the abusive IP=================GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498615 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498616 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498612 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498617 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498618 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498619 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498620 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498621 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498622 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498623 HTTP/1.1GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1546437498624 HTTP/1.1,"Access logs =========[root@ip-10-59-100-122 production]# tail -1000 10.59.101.6-access.log | grep 02/Jan/201910.59.1.65 - - [02/Jan/2019:00:36:33 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:00:36:33 +0000] GET / HTTP/1.1 302 - http://54.84.128.76:80/ Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:00:36:34 +0000] GET /login HTTP/1.1 301 234 - Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:00:38:40 +0000] GET / HTTP/1.1 302 - - Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:00:38:40 +0000] GET /login HTTP/1.1 301 234 - Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:00:38:40 +0000] GET /login HTTP/1.1 200 34886 http://54.84.128.76/login Mozilla/5.0 zgrab/0.x10.59.1.65 - - [02/Jan/2019:01:17:13 +0000] GET / HTTP/1.1 301 227 - -10.59.1.65 - - [02/Jan/2019:01:26:27 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.3610.59.1.65 - - [02/Jan/2019:02:10:43 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/601.7.7 (KHTML, like Gecko) Version/9.1.2 Safari/601.7.710.59.1.65 - - [02/Jan/2019:02:23:43 +0000] GET / HTTP/1.1 301 229 - HTTP Banner Detection (https://security.ipip.net)10.59.1.65 - - [02/Jan/2019:02:55:59 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/601.7.7 (KHTML, like Gecko) Version/9.1.2 Safari/601.7.710.59.1.65 - - [02/Jan/2019:03:20:35 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.3610.59.1.65 - - [02/Jan/2019:04:33:14 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.3610.59.1.65 - - [02/Jan/2019:04:48:28 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.3610.59.1.65 - - [02/Jan/2019:04:55:10 +0000] GET / HTTP/1.1 301 227 - Mozilla/5.0(WindowsNT6.1;rv:31.0)Gecko/20100101Firefox/31.010.59.1.65 - - [02/Jan/2019:08:25:14 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.3610.59.1.65 - user [02/Jan/2019:11:11:32 +0000] GET /backupsettings.conf HTTP/1.1 404 28787 - python-requests/2.18.410.59.1.65 - - [02/Jan/2019:11:11:58 +0000] GET /backupsettings.conf HTTP/1.1 301 248 - python-requests/2.18.410.59.1.65 - - [02/Jan/2019:12:25:57 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.3610.59.1.65 - - [02/Jan/2019:14:14:43 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.3610.59.1.65 - - [02/Jan/2019:14:46:53 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.3610.59.1.65 - - [02/Jan/2019:15:36:30 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/601.7.7 (KHTML, like Gecko) Version/9.1.2 Safari/601.7.710.59.1.65 - - [02/Jan/2019:15:36:30 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.3610.59.1.65 - - [02/Jan/2019:15:45:46 +0000] GET / HTTP/1.1 301 229 - -10.59.1.65 - - [02/Jan/2019:16:07:59 +0000] GET / HTTP/1.1 301 229 - Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36",@TeamI have further checked with the access logs and Cloud watch metrics and cannot see anything suspicious apart from the latency spike and CPU (CPU spikes to a value around 60% when the alert triggers)Please check further on this and work on RCA.The alert is still in the muted state.,"Hello Matthew,We have further checked with Praveen for the recommendation on this as you were not available and to resolve the issue we have blocked the abusive IP at NACL level.we will work on the RCA and will share with you.Thanks",Hello Mathew We have tried to reach out you via phone as the alert is triggering multiple times. As you are not available we have sent a voicemail to with the details. Kindly get back to us on this case as soon as possible.We are still waiting for your approval to further proceed with blocking of the IP which is listed as abusiveThanks,@Team kindly work on the RCA as Matt still needs that from us.,"Hello TeamI tried to contact Matthew via phone but he was not available. So dropped a voice mail to him to get approval to mute the abusive IP to resolve the issue. Informed the same to Rohit and as the alert triggers continuously, he mentioned to mute the URL.","Hello TeamWe have further checked with the instance level and could see that there is a high number of connections and httpd process is accessing the high number of files.lsof | grep httpd| wc -l49840[root@ip-10-59-100-122 centos]# netstat | grep http | wc -l420We have further checked with the NETWORK I/O connection again and could see a high spike.[root@ip-10-59-100-122 centos]# netstat -a | grep TIME | wc -l1552[root@ip-10-59-100-122 centos]# netstat -a | grep ESTABLISHED | wc -l510[root@ip-10-59-100-122 centos]# netstat -a | grep CLOSE_WAIT | wc -l0[root@ip-10-59-100-122 centos]# netstat -a | grep LISTEN | wc -l63We could also find a small spike in the CPU at the time of alert and is htppd process is consuming high cpu.[root@ip-10-59-100-122 centos]# free -m             total       used       free     shared    buffers     cachedMem:         61397      37354      24043          0        141       4306-/+ buffers/cache:      32907      28490Swap:            0          0          0[root@ip-10-59-100-122 centos]# top -b -n1 | head -n30top - 16:45:28 up 18 days, 10 min,  1 user,  load average: 1.54, 1.60, 1.94Tasks: 597 total,   3 running, 592 sleeping,   2 stopped,   0 zombieCpu(s):  4.1%us,  0.7%sy,  0.0%ni, 94.8%id,  0.4%wa,  0.0%hi,  0.0%si,  0.0%stMem:  62871452k total, 38109916k used, 24761536k free,   144576k buffersSwap:        0k total,        0k used,        0k free,  4284792k cached  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                                                                             31504 apache    20   0  462m 108m 9980 S 50.9  0.2   2:09.59 httpd                                                                                                                                                               27654 apache    20   0  396m  40m 9144 R 41.1  0.1   0:05.16 httpd                                                                                                                                                               12468 apache    20   0  485m 131m 9564 R 35.2  0.2   2:12.07 httpd                                                                                                                                                                1139 dd-agent  20   0 47724  21m 4188 S 27.4  0.0 189:53.06 process-agent                                                                                                                                                       25201 apache    20   0  407m  52m 9500 S 27.4  0.1   0:12.60 httpd                                                                                                                                                                      Kindly provide us an approval to block the abusive IP listed below that seems which causes for High network I/O to the instance.167.99.97.223 ISP	DigitalOcean LLC Usage Type	Data Center/Web Hosting/Transit Domain Name	Unknown Country	United States City	Santa Clara, California This IP address has been reported a total of 17 times from 14 distinct sources. Confidence of Abuse is 100% 71.6.165.200 ISP	CARInet Inc. Usage Type	Data Center/Web Hosting/Transit Hostname(s)	census12.shodan.io Domain Name	Unknown Country	United States City	San Diego, California This IP address has been reported a total of 2296 times from 412 distinct sources. Confidence of Abuse is 100% 3.IP:	24.3.113.228Decimal:	402878948Hostname:	c-24-3-113-228.hsd1.pa.comcast.netASN:	7922Let us know your update on this.Thanks","Hello Matt,First time the alert got triggered, requests initially timed out after 30001 milliseconds above our monitoring tool's set threshold of 30000 milliseconds. That's a .0001 difference.As earlier on mentioned, the site was only taking long to serve requests, but never actually down.Checking from the AWS ELB dashboard, we did have some spikes in the Average Latency monitor, the highest recored over the period being 79208 milliseconds at around 3:09 PM UTC. Request count on was 1 on average for the last one hour leading up to the the alert.The ELB's backend instance (i-0ace70ce06368e4a7, Private IP: 10.59.100.122) had most of it's metrics operating normally. CPU utiliztion at its peak was at 60% and below that value over most of the alert period. There were also some spikes on the instance's Network In monitor, highest reading recorded over the alert period being 543611665 bytes.[root@ip-10-59-100-122 ~]# netstat | grep TIME_WAIT | wc -l 252 [root@ip-10-59-100-122 ~]# netstat | grep ESTABLISHED | wc -l497 [root@ip-10-59-100-122 ~]# netstat | grep LISTEN | wc -l63From assesing the ELB acces logs, we observed a total of 48, 4xx related errors. Below are the top 5 request URLs with their total count. From 14:00 UTC - 15:00 UTC404 - GET https://secure.spendhq.com:443/css/images/throbber.gif HTTP/1.1 - Total count = 34400 - GET https://secure.spendhq.com:443/vendor_information/get_insights/1540930 HTTP/1.1 - Total count = 3400 - GET https://secure.spendhq.com:443/vendor_information/get_insights/433870 HTTP/1.1 - Total count =2404 - GET https://secure.spendhq.com:443/apple-touch-icon-precomposed.png HTTP/1.1 - Total count =2404 - GET https://secure.spendhq.com:443/apple-touch-icon.png HTTP/1.1 - Total count =2We found these two IPs to be abusive and making these and other requests:167.99.97.223ISP	DigitalOcean LLCUsage Type	Data Center/Web Hosting/TransitDomain Name	UnknownCountry	 United StatesCity	Santa Clara, CaliforniaThis IP address has been reported a total of 17 times from 14 distinct sources.Confidence of Abuse is 100%71.6.165.200ISP	CARInet Inc.Usage Type	Data Center/Web Hosting/TransitHostname(s)	census12.shodan.io Domain Name	UnknownCountry	 United StatesCity	San Diego, CaliforniaThis IP address has been reported a total of 2296 times from 412 distinct sources.Confidence of Abuse is 100%We have attached all the relevant monitor screenshots and ELB logs in the attachment section for your perusal. Kindly go through them all as you await the RCA to be worked on.Instance Details:-----------------Name: PRD-WW1_122Instance ID: i-0ace70ce06368e4a7AZ: us-east-1bInstance Type: r4.2xlargeVPC: ID: vpc-76df7212Private IP: 10.59.100.122-----------------ELB Details:------------Name: Secure-SpendHQ-ELBDNS Name: Secure-SpendHQ-ELB-288546960.us-east-1.elb.amazonaws.com Type: internet-facingScheme: internet-facing------------Thanks.","Hello Matt,The site wasn't down per se, but was rather taking long to load. From our initial analysis, we can see that requests were taking longer than usual to process:C02XH05GJG5M:spendhq niali$ for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://secure.spendhq.com/login -so /dev/null; done;HTTPCode=200 TotalTime=57.308673HTTPCode=200 TotalTime=5.000868HTTPCode=200 TotalTime=2.729599HTTPCode=200 TotalTime=2.056782HTTPCode=200 TotalTime=2.084747HTTPCode=200 TotalTime=2.177897We are working on the RCA as requested and will be sharing it once completed. The alert has since then recovered as well after again re-triggering.Thanks",Informed MGS Leads via mail.,[Via mail]Let’s get an RCA for this please.--Matt,"Hello Team,This is to inform you that we received a site down alert for the following URL: https://secure.spendhq.com/login which later on recovered automatically after a minute.We are analyzing this and will be sharing more info.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C3bas,Cloud Engineer Level 1,Closed,1055333,Incident,22-05-2017 10:07,,"Hello SpendHQ-Team, On further analyzing the ELB logs at the time of the alert, We are able to figure out one IP 93.174.95.47 which belongs to Victoria City, English River Region, Seychelles Country was trying to execute the SERVER-APACHE Apache Struts remote code.As a fix, we have blocked the IP at NACL level. Please find the logs details below, Intrusion Prevention logs: 2017:05:22-01:37:29 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=26173 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:22-01:37:29 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=26173 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0ELB Logs:2017-05-22T02:09:06.220507Z Secure-SpendHQ-ELB 93.174.95.47:55808 10.59.1.192:80 0.000039 0.001883 0.000023 403 403 0 250 GET http://52.202.13.253:80/w00tw00t.at.blackhats.romanian.anti-sec:) HTTP/1.1 ZmEu - -2017-05-22T02:09:06.388238Z Secure-SpendHQ-ELB 93.174.95.47:56012 10.59.1.192:80 0.000039 0.001586 0.000021 403 403 0 237 GET http://52.202.13.253:80/phpMyAdmin/scripts/setup.php HTTP/1.1 ZmEu - -Please refer these details and let us know if your team have any further queries regarding this case. Regards, Sumod.K.Bose###Hello SpendHQ-Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.20 which belongs to the secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.Regards,Sumod.K.Bose",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-22 01:37:29Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.20Source port: 26173Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http),[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,22-05-2017 07:22,3,0,SpendHQ,"Hello SpendHQ-Team, On further analyzing the ELB logs at the time of the alert, We are able to figure out one IP 93.174.95.47 which belongs to Victoria City, English River Region, Seychelles Country was trying to execute the SERVER-APACHE Apache Struts remote code.As a fix, we have blocked the IP at NACL level. Please find the logs details below, Intrusion Prevention logs: 2017:05:22-01:37:29 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=26173 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:22-01:37:29 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=26173 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0ELB Logs:2017-05-22T02:09:06.220507Z Secure-SpendHQ-ELB 93.174.95.47:55808 10.59.1.192:80 0.000039 0.001883 0.000023 403 403 0 250 GET http://52.202.13.253:80/w00tw00t.at.blackhats.romanian.anti-sec:) HTTP/1.1 ZmEu - -2017-05-22T02:09:06.388238Z Secure-SpendHQ-ELB 93.174.95.47:56012 10.59.1.192:80 0.000039 0.001586 0.000021 403 403 0 237 GET http://52.202.13.253:80/phpMyAdmin/scripts/setup.php HTTP/1.1 ZmEu - -Please refer these details and let us know if your team have any further queries regarding this case. Regards, Sumod.K.Bose","Hello SpendHQ-Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.20 which belongs to the secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DDh7y,Cloud Engineer Level 1,Closed,1063035,Incident,15-06-2017 22:27,,"Hello Team,This is to inform you that the alert regarding high volume usage for sphq-db-server05 instance /dev/xvda1 volume got resolved and has returned to normal with a value of 49%.###Hello SpendHQ Team, This is to inform you that we got an alert regarding high volume usage for sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90 to 100%. We are investigating the alert and will keep you posted.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Thu, Jun 15, 2017 at 9:50 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjT0PgyAURX-NbDUPFLADgzWaJp07tEuDPPxIVCzC0H9fTO5wcpNzLyp-7S2ZFQMqQVBOBQMucyF5yfKy5reqk13Nad0WbZOVgAHH3DgyKSnEYC0zotKGSm0GQGk5Xi0AQ1n0ZFFTCPuRFXXGuhS97znqoNGN0zdtrGdnjItbSLR7N8yLTRQv8Ibm8_i9nvQeiVfrkY691ZtZXMTTJEGtbpuD839lsjql>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj9tuwyAMhp-GXCIwMZQLLrKueY2JYHKQmpIltNrjz6l2McnyUf78mwL6ITdLAKWdshq1BYVOWoctyLbDj0vv-g51dzO3q2gVVZpkKs0c3OhwSASRSF_Itz7ZDM5kmwYzGBybe5hr3Q5hOgE9W9w2SbFGKtP8zYyVe2t5LLXshwADCoy3Xpi-lq_Ka5-69SzDoPdKKQF22stz4z7l15KyADzJCD3X7_jzoqjP7DqXo77nWkn0kr02yIRxL-t_Nl882c0e1oOf23N8pHt50qmuqeFP3S-XI1OB>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Thu Jun 15 2017 16:20:00 UTC (*56 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtTsuOwyAM_Bo4IjCYwIFDtlv-g-K8pKZkE1rt55dUlUb2jC3NDAX0t4EvAaTqpFWoLEjshO3QgDA9_rjYxR5Vf9XXCzOSKk0iFz4HHK1SN5eTl945HCFTNnnMxjhLhJLfw1zrdjDdM4gNadsEpZqoTPNf81jbbS2PpZb9YKBBgvbWMx2nvTw3pn9peC15YICnA0Js-rP_X5TUyS5zOernr6RAL9pUGvke1qNV3Yf0yPfypDOL1_DNegP-nkZf>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjcsOgyAUBb8GluTyhgUL2uh_IFfURItV-v-lSZOzmmTmYNB-mukWBHALhmtuBGjLjNVKMBX1w412jJrHQQ5PogAbLixXugYPPGc3OeBeopyUM6UY7yChK7bwTPewtnbeREYixr50ngxTS1iX9d0bR2dHfW2tXjcRUoCQ3vgOZ9wavcJx979rTq-81w_-BNrCX_gCCBM2Yg>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVjUsOgzAQQ09DllF-k8AiC9rCPSYkfCQgNAz3bypZlvUk29FDFxLbvBLSCStBWiXAcevAKG56eLWjG3uQ_aCHd2NEpLjwKbPVd2a2s0xSQcKgUGkXnGknhzoYK0Jgu1-JrrvRfaPGKrwuHpEw5mX91o2jsu2cC95Unomekho9rvmmE48aP1Jw6Hh1qYEVf9z1viQ8pz0_8d9n5I98bpTLD5LIO64>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jcEKgzAQRL_GHGU3mzV6yMG25j9iNqhQjdW03197KQwMPJg34rgbk1qcBrTQIGOjgW3dWDa6Nj3fWm99z9gPNNwrA1JkqmNWs0OGLiYjRJSM7phwJGMj6xBRRoPq6eZS9rOivtL-Stj3WkIJkqf5dTnWi6VP2sq_yS9S0YM6pBa0RosNWGgJjDrcel73RwpbfOa3_PaquDVvS8nHF8v1OOI>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjcsOgyAURL9GloTXBV2woI3-B4XrI6lAEf-_mMxicjI5Ey1MHySHFYwbpjlwLRgYqg0oQZWD17iYxQF3s5zfg2KxxY2GTHYbZJR8Ba8N8sAEgBoDYpw4WzVjoMnX7q2Va5BuEEuPL4VG33zM2_7rjvNhIeQ7td5KxRUrpoAXqfa8-ldFn8I33_EZk2bPnI6W6x9gxjaA>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,15-06-2017 22:19,0,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding high volume usage for sphq-db-server05 instance /dev/xvda1 volume got resolved and has returned to normal with a value of 49%.","Hello SpendHQ Team, This is to inform you that we got an alert regarding high volume usage for sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90 to 100%. We are investigating the alert and will keep you posted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hSz5m,Cloud Engineer Level 1,Closed,1110488,Incident,14-01-2019 17:13,,"Hello Team,We are merging this ticket with another ticket 01110690 as both the cases are same. We are now closing this and will do follow up with you on the ticket  01110690.###Hello Matthew,We didn't hear back from you.Please update us regarding your availability to get on a call with us to discuss this issue briefly.###Hello Matthew,As we updated in the last email, we are intermittently receiving site down alerts for URL: https://secure.spendhq.com/loginDuring all the occurrences, the site wasn't actually down but was taking longer to resolve as a result of high latency. Please let us know your availability to get on a call with us to discuss this issue briefly.Thanks###From Matthew:What is the issue?###Hello Matthew, We are yet to hear from you.Kindly let us know your availability so that we get on a call to discuss this issue further.Thanks###Hello Matthew,This is to inform that we have received the site down for the URL https://secure.spendhq.com/login twice. And site came up within 2 minutes. Could you please let us know your available time for discussing the issue happening daily.###Hi Matthew,We are receiving the site down alert for Secure daily. Can we have a call to discuss on this? Please let me know when are you available to discuss the same. Thanks !###Hello Team,This is to inform you that we have again received site down alert for  https://secure.spendhq.com/login and it got resolved in 5 minutes 59 seconds.###Hello Team,We have been receiving multiple site down alerts over the last hour for the url https://secure.spendhq.com/login with the alert recovering in at most 4 minutes. During all the occurrences, the site wasn't actually down but was taking long to resolve as a result of high latency.All instance level logs indicate no errors that would warrant this.In addition to the high latency, during that time the average active connection count has been on steady rise.We have attached the screenshot for these CloudWatch metrics herein for your reference.As communicated earlier, please review the two suggestion below and get back to us:1. Enable the Datadog Apache integration to review the Apache metrics. 2. Enable the Datadog DB Integration(if the database is PostgreSQL or MySQL compatible, we can enable a plugin) Please let us know if you want to schedule a call to discuss further on this.###Hello Team,This is to notify you that we received a site down alert on url  https://secure.spendhq.com/login.The alert is now recovered and in resolved state. The resulting violation lasted 1 minute and 59 seconds.We are analyzing the issue and will get back to you with an update shortly.Thanks.","Wed, 09 Jan 2019 09:57:35 -0500Detected Error on SpendHQ SecureEstimated Downtime: 2 minuteshttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 60002 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): London UK, Dallas-C US, Dallas-B US, Frankfurt-B DE-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,09-01-2019 20:30,117,0,SpendHQ,"Hello Team,We are merging this ticket with another ticket 01110690 as both the cases are same. We are now closing this and will do follow up with you on the ticket  01110690.","Hello Matthew,We didn't hear back from you.Please update us regarding your availability to get on a call with us to discuss this issue briefly.","Hello Matthew,As we updated in the last email, we are intermittently receiving site down alerts for URL: https://secure.spendhq.com/loginDuring all the occurrences, the site wasn't actually down but was taking longer to resolve as a result of high latency. Please let us know your availability to get on a call with us to discuss this issue briefly.Thanks",From Matthew:What is the issue?,"Hello Matthew, We are yet to hear from you.Kindly let us know your availability so that we get on a call to discuss this issue further.Thanks","Hello Matthew,This is to inform that we have received the site down for the URL https://secure.spendhq.com/login twice. And site came up within 2 minutes. Could you please let us know your available time for discussing the issue happening daily.","Hi Matthew,We are receiving the site down alert for Secure daily. Can we have a call to discuss on this? Please let me know when are you available to discuss the same. Thanks !","Hello Team,This is to inform you that we have again received site down alert for  https://secure.spendhq.com/login and it got resolved in 5 minutes 59 seconds.","Hello Team,We have been receiving multiple site down alerts over the last hour for the url https://secure.spendhq.com/login with the alert recovering in at most 4 minutes. During all the occurrences, the site wasn't actually down but was taking long to resolve as a result of high latency.All instance level logs indicate no errors that would warrant this.In addition to the high latency, during that time the average active connection count has been on steady rise.We have attached the screenshot for these CloudWatch metrics herein for your reference.As communicated earlier, please review the two suggestion below and get back to us:1. Enable the Datadog Apache integration to review the Apache metrics. 2. Enable the Datadog DB Integration(if the database is PostgreSQL or MySQL compatible, we can enable a plugin) Please let us know if you want to schedule a call to discuss further on this.","Hello Team,This is to notify you that we received a site down alert on url  https://secure.spendhq.com/login.The alert is now recovered and in resolved state. The resulting violation lasted 1 minute and 59 seconds.We are analyzing the issue and will get back to you with an update shortly.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bmgRC,Cloud Engineer Level 1,Closed,1105047,Incident,22-09-2018 06:13,,"Hello Team,The issue was from the AWS side and it has been resolved and the service is operating normally, hence we are marking this case as resolved and closing this case.Please let us know if you are facing any issues or have any concerns relating to this. Thanks.###Hello Team,Between 8:34 PM and 9:13 PM PDT, AWS experienced elevated packet loss impacting AWS Direct Connect for the US-EAST-1 Region. The issue has been resolved and the service is operating normally.Please let us know if you are facing any issues or have any concerns relating to this.Thanks.###Hello Team, This is to inform you that we received a notification from AWS indicating that at around 7:23 AM PDT they began to experience elevated network latency, impacting AWS Direct Connect connectivity to the US-EAST-1 Region. They are investigating the issue and will be updating us on any new developments. Event data:-----------------------------------------------------------------------Event: DirectConnect connectivity issueStatus: OpenRegion/AZ: us-east-1Start time: September 21, 2018 at 5:23:00 PM UTC+3Event category: Issue------------------------------------------------------------------------Thank you","Starting at 7:23 AM PDT we began to experience elevated network latency,impacting AWS Direct Connect connectivity to the US-EAST-1 Region. We areinvestigating the issue. For more details, please seehttps://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center -Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018<http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center -Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>-- Hosea B. Getusi,*Cloud Engineer,**REĀN Cloud | **Reach, Engage, Āctivate, Nurtur**Mobile*: +254713404220 | *Skype*: hoseagetusi*hosea.getusi@reancloud.com <hosea.getusi@reancloud.com>* |  *www.reancloud.com<http://www.reancloud.com>*--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_CONNECTIVITY_ISSUE,,21-09-2018 21:35,9,0,SpendHQ,"Hello Team,The issue was from the AWS side and it has been resolved and the service is operating normally, hence we are marking this case as resolved and closing this case.Please let us know if you are facing any issues or have any concerns relating to this. Thanks.","Hello Team,Between 8:34 PM and 9:13 PM PDT, AWS experienced elevated packet loss impacting AWS Direct Connect for the US-EAST-1 Region. The issue has been resolved and the service is operating normally.Please let us know if you are facing any issues or have any concerns relating to this.Thanks.","Hello Team, This is to inform you that we received a notification from AWS indicating that at around 7:23 AM PDT they began to experience elevated network latency, impacting AWS Direct Connect connectivity to the US-EAST-1 Region. They are investigating the issue and will be updating us on any new developments. Event data:-----------------------------------------------------------------------Event: DirectConnect connectivity issueStatus: OpenRegion/AZ: us-east-1Start time: September 21, 2018 at 5:23:00 PM UTC+3Event category: Issue------------------------------------------------------------------------Thank you",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKrr,Cloud Engineer Level 1,Closed,1042236,Incident,,,,"ok, done -      volume Spend4 has had a snapshot takenDo you want to turn it into  a clone?Chris VeilletteCTO[1450833261212_7186d8e7bdbb48853119db07d964f770.jpg]www.Andromeda3.com<http://www.Andromeda3.com>cveillette@andromeda3.comMobile: 703.447.4124Office:   571.781.0428________________________________From: Matthew Watts <mwatts@spendhq.com>Sent: Friday, January 13, 2017 10:08 PMTo: Chris Veillette; Mrigank SaxenaCc: REAN SupportSubject: RE: MaintenanceCan you image the Production Machine – Spend4. We just want to create a clone.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Friday, January 13, 2017 10:06 PMTo: Matthew Watts <mwatts@spendhq.com>; Mrigank Saxena <mrigank.saxena@reancloud.com>Cc: REAN Support <support@reancloud.com>Subject: Re: MaintenanceHI Matt -Sorry - didn't know which vol to image - and if you want to clone it ...Can you let me know - I am standing byChris VeilletteCTO[1450833261212_7186d8e7bdbb48853119db07d964f770.jpg]www.Andromeda3.com<http://www.Andromeda3.com>cveillette@andromeda3.com<mailto:cveillette@andromeda3.com>Mobile: 703.447.4124Office:   571.781.0428________________________________From: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Sent: Friday, January 13, 2017 9:52 PMTo: Mrigank Saxena; Chris VeilletteCc: REAN SupportSubject: RE: MaintenanceChris,Did you manage to image the machine?Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]Sent: Friday, January 13, 2017 9:37 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,As mentioned earlier, Andromeda team is going to clone the volume before we proceed with the patching of the instance.Please let us know if that is done so that we can proceed with the security patching.On Sat, Jan 14, 2017 at 8:00 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Please update the 10.59.10.12 machine first and advise when complete.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com<mailto:mrigank.saxena@reancloud.com>]Sent: Friday, January 13, 2017 9:24 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,We are ready for the maintenance. Please let us know once you start making the changes.On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Rean Team are you ready to commence the updates as planned on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Maintenance,,14-01-2017 08:41,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Ce9i0,Cloud Engineer Level 3,Closed,1058697,Incident,13-06-2017 15:46,,"We are closing this case, the issue was related to mysql process monitoring. The instance do not run mysqld instead it runs memsqld. So we have corrected that on server and that issue is resolved.###There is no issue with NFS. The issue was related to mysql process monitoring. The instance do not run mysqld instead it runs memsqld. So we have corrected that on server and that issue is resolved.###This case is escalated to Sanket###Sudheer looked into it and he updated that issue is with newly boarded instances need to check with Yogesh.###raveen Kumar Muppala1:06 AM (2 hours ago)to ms Team, please investigate this. Regards,-Praveen###Hello Team,While checking our monitoring tool Datadog, we found that httpd process was down in the instance PROD-SPHQ-NFS-SERVER01. On investigating, we could see that the end point /var/www/vhosts/files.spendhq.com/logs/web1-https-secure.spendhq.com-error.log was not to able access by httpd process. Please find the snapshot from the attachment section. We have started the httpd process. Please let us know if you have any queries regarding this.","Team,  Please investigate this issue.  Regards,-Praveen-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SpendHQ Datadog NFS Server Process Integration issue,,01-06-2017 17:59,286,0,SpendHQ,"We are closing this case, the issue was related to mysql process monitoring. The instance do not run mysqld instead it runs memsqld. So we have corrected that on server and that issue is resolved.",There is no issue with NFS. The issue was related to mysql process monitoring. The instance do not run mysqld instead it runs memsqld. So we have corrected that on server and that issue is resolved.,This case is escalated to Sanket,Sudheer looked into it and he updated that issue is with newly boarded instances need to check with Yogesh.,"raveen Kumar Muppala1:06 AM (2 hours ago)to ms Team, please investigate this. Regards,-Praveen","Hello Team,While checking our monitoring tool Datadog, we found that httpd process was down in the instance PROD-SPHQ-NFS-SERVER01. On investigating, we could see that the end point /var/www/vhosts/files.spendhq.com/logs/web1-https-secure.spendhq.com-error.log was not to able access by httpd process. Please find the snapshot from the attachment section. We have started the httpd process. Please let us know if you have any queries regarding this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DohR5,Cloud Engineer Level 1,Closed,1066300,Incident,07-07-2017 05:47,,"Hello Team,We haven't heard back from you regarding this case.As of now, we are marking this case as resolved.Please let us know if you have any other queries regarding this case.###Next action: Night shift: Close this case if we haven't heard back from them.###Hello Team,Please let us know if you get a chance to review the RCA shared.Let us know if you have any queries.###Next action: Evening shift: Send a reminder to the customer to review the RCA document shared.###Hello SpendHQ Team, We have prepared the RCA for the outage happened on 2/07/2017. Please find the RCA in the attachment section and let us know if you have any queries.###Folks,I still don't see the right analysis here. I asked about Network In/Out and Disk I/O details. But I don't see them in the report.When I looked into the sar stats during the event time, I clearly see there is a unusual disk IO happened on the system. This could be due to iSCSI Disk IO latency over network.Please add this information to the RCA document and let SpendHQ know saying that, we witnessed only DB high utilization during that time : CPU, Network and Disk hence it is not serving the new queries which leaded the site go down.And ask them that the shown IP Addresses in the report are known sources or can be blocked.###Next Action: Night Shift Team: We have modified the RCA based on Sanket suggestion. We have called him to get the RCA reviewed but he was out of office and mentioned that he will review it once he is back. Please follow up with Sanket during night shift hours and get the RCA reviewed.###We have updated the RCA with details mentioned by Praveen https://docs.google.com/document/d/19QZHnyjGqe9od6BbDiwqUQJl2Nbsw1owS8Dl_OZCSCM/edit#Please review the RCA with Sanket.###Next action: Need to update RCA as per Praveen's suggestion and get it reviewed by Sanket.###Praveen updated that:The dots are not connected well.1. Do you see these requests are coming from Single IP.2. What is the Network I/O3. What is the disk I/O on the DB05 during that time.4. What is the Network I/O on DB05 machine.Please run sar command and see apart from the CPU what else caused the issue during that time in DB machine.###We have prepared the RCA for this case. Refer the link for more details, https://docs.google.com/document/d/19QZHnyjGqe9od6BbDiwqUQJl2Nbsw1owS8Dl_OZCSCM/edit#Resolution part is not added. Need to check this with CE3 and fill the resolution part. Also need to check and confirm if any more details need to be get added on this RCA.###Currently, We are preparing the RCA for this outage and will be sharing it with CE3 for review.###Hello SpendHQ-Team,We are currently working on the RCA for this outage happened and will be sharing the report with your team shortly.Meanwhile please validate all the shared information and let us know incase of any further queries.Regards,Sumod.K.Bose###We have started preparing the RCA and please find the link below: https://docs.google.com/document/d/19QZHnyjGqe9od6BbDiwqUQJl2Nbsw1owS8Dl_OZCSCM/edit#Please check on the resolution part in ops call, update and share with customer###Next action: Morning shift Check whether we are getting any reply from the customer and act accordingly. Check with CC if any analysis is pending or we need to give any recommendations like DB type change.###Next action: Night shift Check whether we are getting any reply from the customer and act accordingly.Check with CC if any analysis is pending or we need to give any recommendations for DB type change.###Hello Team,On further analysis, we found the below details.While analyzing the ELB logs we could see that the latency was high at the time of the alert. We could also observe a high number of 5xx and 4xx alerts. The sum of request was high at that period. Please review the attached ELB logs and graphs for more details.On the Webserver the there was a slight spike in CPU utilization and the Network In was high at that period. The httpd process was running fine in the server.The database instance prod-sphq-db-server05 had a high CPU load at the time of the alert. The load average value has reached a value of 35.54. The CPU utilization was also high which has reached a value of 99%. The memory usage was high and the mysql process was consuming high memory. Please review the attached details.The web server was not able to respond due to high load on the attached application database server which caused this site down issue.Please let us know if your team has performed any activity from your end and reach out to us if you have any further queries.###Hello Team,On initial analysis, we found that the latency was high at the time of the alert. We also observed a spike in the sum of requests and 5xx response code.From the instance metrics, we could see that the CPU was high for the instance. The backend database instance was having high CPU load and memory usage at the time of the alert.We are investigating more on the issue and will let you know the updates.###Hello Team,This is to notify you that we have received a site down alert for the URL https://secure.spendhq.com/login. The alert got recovered after 7 Minutes and the site is up and running now.We will further analyse on this issue and will revert back to you with updates. Meanwhile, please let us know if your team has performed any activity from your end.","Sat, 01 Jul 2017 23:14:18 -0400Detected Error on SpendHQEstimated Downtime: 1 minute 1 second https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30003 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, Atlanta-B US, London UK, Dallas-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,02-07-2017 08:44,117,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.As of now, we are marking this case as resolved.Please let us know if you have any other queries regarding this case.",Next action: Night shift: Close this case if we haven't heard back from them.,"Hello Team,Please let us know if you get a chance to review the RCA shared.Let us know if you have any queries.",Next action: Evening shift: Send a reminder to the customer to review the RCA document shared.,"Hello SpendHQ Team, We have prepared the RCA for the outage happened on 2/07/2017. Please find the RCA in the attachment section and let us know if you have any queries.","Folks,I still don't see the right analysis here. I asked about Network In/Out and Disk I/O details. But I don't see them in the report.When I looked into the sar stats during the event time, I clearly see there is a unusual disk IO happened on the system. This could be due to iSCSI Disk IO latency over network.Please add this information to the RCA document and let SpendHQ know saying that, we witnessed only DB high utilization during that time : CPU, Network and Disk hence it is not serving the new queries which leaded the site go down.And ask them that the shown IP Addresses in the report are known sources or can be blocked.",Next Action: Night Shift Team: We have modified the RCA based on Sanket suggestion. We have called him to get the RCA reviewed but he was out of office and mentioned that he will review it once he is back. Please follow up with Sanket during night shift hours and get the RCA reviewed.,We have updated the RCA with details mentioned by Praveen https://docs.google.com/document/d/19QZHnyjGqe9od6BbDiwqUQJl2Nbsw1owS8Dl_OZCSCM/edit#Please review the RCA with Sanket.,Next action: Need to update RCA as per Praveen's suggestion and get it reviewed by Sanket.,Praveen updated that:The dots are not connected well.1. Do you see these requests are coming from Single IP.2. What is the Network I/O3. What is the disk I/O on the DB05 during that time.4. What is the Network I/O on DB05 machine.Please run sar command and see apart from the CPU what else caused the issue during that time in DB machine.,"We have prepared the RCA for this case. Refer the link for more details, https://docs.google.com/document/d/19QZHnyjGqe9od6BbDiwqUQJl2Nbsw1owS8Dl_OZCSCM/edit#Resolution part is not added. Need to check this with CE3 and fill the resolution part. Also need to check and confirm if any more details need to be get added on this RCA.","Currently, We are preparing the RCA for this outage and will be sharing it with CE3 for review.","Hello SpendHQ-Team,We are currently working on the RCA for this outage happened and will be sharing the report with your team shortly.Meanwhile please validate all the shared information and let us know incase of any further queries.Regards,Sumod.K.Bose","We have started preparing the RCA and please find the link below: https://docs.google.com/document/d/19QZHnyjGqe9od6BbDiwqUQJl2Nbsw1owS8Dl_OZCSCM/edit#Please check on the resolution part in ops call, update and share with customer",Next action: Morning shift Check whether we are getting any reply from the customer and act accordingly. Check with CC if any analysis is pending or we need to give any recommendations like DB type change.,Next action: Night shift Check whether we are getting any reply from the customer and act accordingly.Check with CC if any analysis is pending or we need to give any recommendations for DB type change.,"Hello Team,On further analysis, we found the below details.While analyzing the ELB logs we could see that the latency was high at the time of the alert. We could also observe a high number of 5xx and 4xx alerts. The sum of request was high at that period. Please review the attached ELB logs and graphs for more details.On the Webserver the there was a slight spike in CPU utilization and the Network In was high at that period. The httpd process was running fine in the server.The database instance prod-sphq-db-server05 had a high CPU load at the time of the alert. The load average value has reached a value of 35.54. The CPU utilization was also high which has reached a value of 99%. The memory usage was high and the mysql process was consuming high memory. Please review the attached details.The web server was not able to respond due to high load on the attached application database server which caused this site down issue.Please let us know if your team has performed any activity from your end and reach out to us if you have any further queries.","Hello Team,On initial analysis, we found that the latency was high at the time of the alert. We also observed a spike in the sum of requests and 5xx response code.From the instance metrics, we could see that the CPU was high for the instance. The backend database instance was having high CPU load and memory usage at the time of the alert.We are investigating more on the issue and will let you know the updates.","Hello Team,This is to notify you that we have received a site down alert for the URL https://secure.spendhq.com/login. The alert got recovered after 7 Minutes and the site is up and running now.We will further analyse on this issue and will revert back to you with updates. Meanwhile, please let us know if your team has performed any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001QkREv,Cloud Engineer Level 1,Closed,1091333,Incident,22-02-2018 01:10,,"Hello Steven,Thanks for the confirmationAt this time we are marking this case as resolved. Please revert back to us if you have any queries.###I believe things are ok. This could be caused from the penetration test as I believe that preview.spendhq.com traffic goes through the PROD ELB. Steven Ng | Full Stack LAMP Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.com###Hello SpendHQ-Team,This is a gentle reminder, Please review the details mentioned in the previous comment.please let us know if you have any further queries.###Hello SpendHQ Team,This is to notify you that we received high network in/out alerts for the instances: PRD-DB1,  prd-fs1, prod-sphq-sophos-utm-vpn01,  prd-ww1. The alerts got recovered within 10 minutes on 19-02-2018.Below are the Instance details:Instance name: PRD-DB1Instance id: i-03ccfddd9f02cacb9VPD Id: vpc-76df7212Subnet Id: subnet-0fdde924Instance type: r4.8xlargeInstance name: prd-fs1Instance Id: i-1426f28bVPC Id: vpc-76df7212Subnet Id: subnet-0d093d27Instance type; c4.xlargeInstance name: PROD-SPHQ-SOPHOS-UTM-VPN01Instance Id: i-02d1a63672fb172f4VPC Id: vpc-76df7212Subnet ID: subnet-01596c2aInstance type: m3.xlargeInstance name: PRD-WW1_122Instance id: i-0ace70ce06368e4a7VPC Id: vpc-76df7212Subnet Id: subnet-0d093d27Instance type: c4.2xlargeFrom  AWS level, we could see that there is no abnormal activity expect the spike in  network in/out. Kindly validate these details and let us know if it is an expected behavior and let us know if you have queries.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Tue, Feb 20, 2018 at 5:16 AMSubject: [Monitor Alert] Triggered: [SpendHQ] [DB] - High Network IN onhost - prd-db1 - 10.59.10.190 - dbTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] [DB] - High Network IN on host - prd-db1 -10.59.10.190 - dbHigh Network IN on the instance. Please check the list open TCP Connections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#4090563?to_ts=1519083953000&group=host%3Ai-03ccfddd9f02cacb9&from_ts=1519083653000>*aws.ec2.network_in* over *host:i-03ccfddd9f02cacb9* was *> 5368709120.0*at all times during the *last 5m*.The monitor was last triggered at Mon Feb 19 2018 23:46:03 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#4090563?group=host%3Ai-03ccfddd9f02cacb9>]· [Edit Monitor <https://app.datadoghq.com/monitors#4090563/edit>] · [Viewi-03ccfddd9f02cacb9<https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1519083963000&tags=host%3Ai-03ccfddd9f02cacb9&from_ts=1519083063000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4275188607605955327>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Thanks and Regards,Jamelunissa MohammedHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081jamelunissa.mohammed@reancloud.com  | www.reancloud.com--  <https://www.reancloud.com/news/rean-cloud-awarded-cloud-contract-department-defense-worth-950-million/>--  <https://www.reancloud.com/news/rean-cloud-awarded-cloud-contract-department-defense-worth-950-million/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] [DB] - High Network IN on host - prd-db1 - 10.59.10.190 - db,,20-02-2018 12:05,37,0,SpendHQ,"Hello Steven,Thanks for the confirmationAt this time we are marking this case as resolved. Please revert back to us if you have any queries.",I believe things are ok. This could be caused from the penetration test as I believe that preview.spendhq.com traffic goes through the PROD ELB. Steven Ng | Full Stack LAMP Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.com,"Hello SpendHQ-Team,This is a gentle reminder, Please review the details mentioned in the previous comment.please let us know if you have any further queries.","Hello SpendHQ Team,This is to notify you that we received high network in/out alerts for the instances: PRD-DB1,  prd-fs1, prod-sphq-sophos-utm-vpn01,  prd-ww1. The alerts got recovered within 10 minutes on 19-02-2018.Below are the Instance details:Instance name: PRD-DB1Instance id: i-03ccfddd9f02cacb9VPD Id: vpc-76df7212Subnet Id: subnet-0fdde924Instance type: r4.8xlargeInstance name: prd-fs1Instance Id: i-1426f28bVPC Id: vpc-76df7212Subnet Id: subnet-0d093d27Instance type; c4.xlargeInstance name: PROD-SPHQ-SOPHOS-UTM-VPN01Instance Id: i-02d1a63672fb172f4VPC Id: vpc-76df7212Subnet ID: subnet-01596c2aInstance type: m3.xlargeInstance name: PRD-WW1_122Instance id: i-0ace70ce06368e4a7VPC Id: vpc-76df7212Subnet Id: subnet-0d093d27Instance type: c4.2xlargeFrom  AWS level, we could see that there is no abnormal activity expect the spike in  network in/out. Kindly validate these details and let us know if it is an expected behavior and let us know if you have queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d2Dwu,Cloud Engineer Level 1,Closed,1106207,Incident,18-10-2018 07:14,,"Hi Allen, We haven't heard from you regarding this case for a while.As we have already completed the request, we are proceeding to close the case.For continued support please reach out to us at support@reancloud.com###Hi Allen, This is a gentle reminder, Please confirm that the password is working well and get back to us if you are facing any issue###Hi Allen, This is a gentle reminder, Please confirm that the password is working well and get back to us if you are facing any issue###Nishad Ali8:18 AM (0 minutes ago)to isaac.muteti, aherrera, REAN, spendhq-supportHello Allen,We have done with your request to reset the sudo passwords for the two instances (MariaDB-sandbox-cluster-server-2 and MariaDB-sandbox-cluster-server-1 ) and shared them in a separate email. kindly check with your access and update us back if we are good to close this case.###Isaac Mwania <isaac.muteti@reancloud.com>7:42 PM (19 minutes ago)to REAN, Allen, spendhq-supportHello Allen, We have reset your password and shared the same separately.Please try and let us know if you are facing any issues.###Hello Allen,We acknowledge your request, will work on it and let you know the updates.","For the two servers below, I need my sudo password reset and sent to me.Allen Herrera | Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: <noreply@salesforce.com> on behalf of Rean Support <support@reancloud.com>Date: Thursday, October 4, 2018 at 4:06 AMTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Subject: Update on Case # SR-01105460 | Low - P4 | Fwd: Mariadb sandbox cluster1:Instance ID: i-06437ec373ad1a61aInstance Name: MariaDB-sandbox-cluster-server-1Instance Type: c5.4xlargePrivate IP Address: 10.59.10.117Subnet ID: subnet-0fdde924VPC: vpc-76df72122:Instance ID: i-094c442cda374dd9aInstance Name: MariaDB-sandbox-cluster-server-2Instance Type: r4.8xlargePrivate IP Address: 10.59.10.18Subnet ID: subnet-0fdde924VPC: vpc-76df7212--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Mariadb sandbox cluster,,12-10-2018 21:26,130,0,SpendHQ,"Hi Allen, We haven't heard from you regarding this case for a while.As we have already completed the request, we are proceeding to close the case.For continued support please reach out to us at support@reancloud.com","Hi Allen, This is a gentle reminder, Please confirm that the password is working well and get back to us if you are facing any issue","Hi Allen, This is a gentle reminder, Please confirm that the password is working well and get back to us if you are facing any issue","Nishad Ali8:18 AM (0 minutes ago)to isaac.muteti, aherrera, REAN, spendhq-supportHello Allen,We have done with your request to reset the sudo passwords for the two instances (MariaDB-sandbox-cluster-server-2 and MariaDB-sandbox-cluster-server-1 ) and shared them in a separate email. kindly check with your access and update us back if we are good to close this case.","Isaac Mwania <isaac.muteti@reancloud.com>7:42 PM (19 minutes ago)to REAN, Allen, spendhq-supportHello Allen, We have reset your password and shared the same separately.Please try and let us know if you are facing any issues.","Hello Allen,We acknowledge your request, will work on it and let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001foLW2,Cloud Engineer Level 1,Closed,1108929,Incident,08-12-2018 06:13,,"Hello Team, Your ticket #01108929 is auto closed. We are closing the ticket as no action was performed from your end. If the ticket is closed erroneously, feel free to reopen the ticket. For any escalation, please send an email to reansupportescalation@reancloud.com. We look forward to serve you. Feel free to reach out to us at support@reancloud.com for any additional queries. Rean Cloud Solutions support@reancloud.com###Hello Team,We haven't heard back from you.Please review the previously shared analysis and let us know if you have any questions or concerns.Thanks.###Team,The CPU Utilization maxed out (100%). Network In was also very high at the time (51017669.4 Bytes).We did not receive any alert from DD. I have checked and this instance is not under monitoring.###Hello Team,This is a followup on the analysis shared earlier about the site down alert we received for url: https://preview.spendhq.com/login.We haven't heard back from you regarding this issue.Please review the shared details and let us know if you have any questions.###Hello Team,The alert lasted for a total of 4 minutes before automatically recovering.We've gone ahead and analyzed the issue. From Wormly, we could see requests timing out after 9000 milliseconds with 0 bytes being received at the time.When we assessed the the related ELB, we could see spikes in Average Latency and Requests Count monitors. The highest reading recoreded was 147759.19 milliseconds for average latency and 369 requests for the requests count.Also, CPU utilization had maxed out moments leading up to the time when the site went down. We also noted the below errors from the instance's system logs with one MySQL segmentation fault:----------------------------------------------------------------------------------------------------------------------------------------------[root@ip-10-59-10-135 log]#Dec  6 12:38:34 ip-10-59-10-135 kernel: __ratelimit: 21 callbacks suppressedDec  6 12:38:34 ip-10-59-10-135 kernel: mysqld[36169]: segfault at 28 ip 00000000004ff1f8 sp 00007ffbc9da6d80 error 4 in mysqld[400000+cc1000]Dec  6 12:38:34 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)----------------------------------------------------------------------------------------------------------------------------------------------We have attached the all relevant monitor screenshots for your perusal. Feel free to get in touch if you have any other queries related to this.ELB Details:-----------Name: preview-spendhq-xelbDNS Name: preview-spendhq-xelb-520312558.us-east-1.elb.amazonaws.comType: ClassicScheme: internet-facingAvailability Zones: subnet-01596c2a - us-east-1b, subnet-acbb09e7 - us-east-1cVPC: vpc-76df7212-----------Backend Instance Details:-------------------------Name: Preview DBInstance ID: i-008d43ad00357e47aAvailability Zone: us-east-1bPrivate IP: 10.59.10.135VPC ID: vpc-76df7212-------------------------Thanks.###Hello team,This is to notify that we have received an alert regarding Detected Error on SpendHQ Preview for the url https://preview.spendhq.com/login .Currently we are checking on the issue and keep you posted.","Thu, 06 Dec 2018 07:35:20 -0500Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30002 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): Dallas-C US, Frankfurt-B DE, California US, Dallas-BUS--  <https://www.gartner.com/en/conferences/na/infrastructure-operations-cloud-us>--  <https://www.gartner.com/en/conferences/na/infrastructure-operations-cloud-us>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,06-12-2018 18:06,36,0,SpendHQ,"Hello Team, Your ticket #01108929 is auto closed. We are closing the ticket as no action was performed from your end. If the ticket is closed erroneously, feel free to reopen the ticket. For any escalation, please send an email to reansupportescalation@reancloud.com. We look forward to serve you. Feel free to reach out to us at support@reancloud.com for any additional queries. Rean Cloud Solutions support@reancloud.com","Hello Team,We haven't heard back from you.Please review the previously shared analysis and let us know if you have any questions or concerns.Thanks.","Team,The CPU Utilization maxed out (100%). Network In was also very high at the time (51017669.4 Bytes).We did not receive any alert from DD. I have checked and this instance is not under monitoring.","Hello Team,This is a followup on the analysis shared earlier about the site down alert we received for url: https://preview.spendhq.com/login.We haven't heard back from you regarding this issue.Please review the shared details and let us know if you have any questions.","Hello Team,The alert lasted for a total of 4 minutes before automatically recovering.We've gone ahead and analyzed the issue. From Wormly, we could see requests timing out after 9000 milliseconds with 0 bytes being received at the time.When we assessed the the related ELB, we could see spikes in Average Latency and Requests Count monitors. The highest reading recoreded was 147759.19 milliseconds for average latency and 369 requests for the requests count.Also, CPU utilization had maxed out moments leading up to the time when the site went down. We also noted the below errors from the instance's system logs with one MySQL segmentation fault:----------------------------------------------------------------------------------------------------------------------------------------------[root@ip-10-59-10-135 log]#Dec  6 12:38:34 ip-10-59-10-135 kernel: __ratelimit: 21 callbacks suppressedDec  6 12:38:34 ip-10-59-10-135 kernel: mysqld[36169]: segfault at 28 ip 00000000004ff1f8 sp 00007ffbc9da6d80 error 4 in mysqld[400000+cc1000]Dec  6 12:38:34 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)----------------------------------------------------------------------------------------------------------------------------------------------We have attached the all relevant monitor screenshots for your perusal. Feel free to get in touch if you have any other queries related to this.ELB Details:-----------Name: preview-spendhq-xelbDNS Name: preview-spendhq-xelb-520312558.us-east-1.elb.amazonaws.comType: ClassicScheme: internet-facingAvailability Zones: subnet-01596c2a - us-east-1b, subnet-acbb09e7 - us-east-1cVPC: vpc-76df7212-----------Backend Instance Details:-------------------------Name: Preview DBInstance ID: i-008d43ad00357e47aAvailability Zone: us-east-1bPrivate IP: 10.59.10.135VPC ID: vpc-76df7212-------------------------Thanks.","Hello team,This is to notify that we have received an alert regarding Detected Error on SpendHQ Preview for the url https://preview.spendhq.com/login .Currently we are checking on the issue and keep you posted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EUGD7,Cloud Engineer Level 1,Closed,1067632,Incident,12-07-2017 21:03,,"Hello Dusty,Thanks for the update. We have changed the Expected HTTP Response code from 200 to 302 in our URL monitoring tool. Please check and confirm that the URL is behaving in an expected manner so that we can close this case from our end.###That is the expected behavior.  It is for security purposes.  Users will not be allowed to access that page without a valid securekey from our parent application. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com###Hello SpendHQ-Team,This is to notify you that we have received a site down alert for the URL http://l.spendhq.com. The page is not loading fine. we are getting an error while loading the page. Please find the attached snapshots and detailed error message from the attachment section.We are investigating the alert and meanwhile let us know if your team is performing any activity from your end.","Wed, 12 Jul 2017 10:57:45 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 302, expected 200Sensor parameters:url: http://l.spendhq.comexpect: 200wantedstring: unwantedstring: Reported by node: New Jersey USConfirmed by node(s): London UK, Frankfurt DE, California US, Atlanta-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,12-07-2017 20:27,1,0,SpendHQ,"Hello Dusty,Thanks for the update. We have changed the Expected HTTP Response code from 200 to 302 in our URL monitoring tool. Please check and confirm that the URL is behaving in an expected manner so that we can close this case from our end.",That is the expected behavior.  It is for security purposes.  Users will not be allowed to access that page without a valid securekey from our parent application. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com,"Hello SpendHQ-Team,This is to notify you that we have received a site down alert for the URL http://l.spendhq.com. The page is not loading fine. we are getting an error while loading the page. Please find the attached snapshots and detailed error message from the attachment section.We are investigating the alert and meanwhile let us know if your team is performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EUaIE,Cloud Engineer Level 2,Closed,1067808,Incident,14-07-2017 12:09,,"We are closing this case and will follow up on ticket 01067648.###Hello Team,We have escalated this issue to our senior engineering team and will keep you posted on the progress.We are having 3 tickets for this one case. So we are closing these two cases 01067808 and 01067796 and will follow up on main ticket 01067648.###Hello Team, We will look into this issue and get back to you with the updates.","Rean,Can we please look into and resolve this slowness;[cid:image001.png@01D2FBC2.B23BDAE0]-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",PATCH SPENDHQ Speed,,13-07-2017 19:58,16,0,SpendHQ,We are closing this case and will follow up on ticket 01067648.,"Hello Team,We have escalated this issue to our senior engineering team and will keep you posted on the progress.We are having 3 tickets for this one case. So we are closing these two cases 01067808 and 01067796 and will follow up on main ticket 01067648.","Hello Team, We will look into this issue and get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001PdEZT,Cloud Engineer Level 1,Closed,1089900,Incident,06-04-2018 16:44,,"since It is a warning alert and the alert got resolved , we are closing this case","[Warn] [SpendHQ] - High Network IN  on host - prd-db1 - 10.59.10.190 - db Status  @support@reancloud.comaws.ec2.network_in over datadog_monitor:on,host:i-03ccfddd9f02cacb9 was > 1610000000.0 at all times during the last 15m.Metric value: 2123808384.0This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024210?group=host%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2024210/edit · Event URL: https://app.datadoghq.com/event/event?id=4247231625908723166 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9 · Show Processes: https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=None&tags=host%3Ai-03ccfddd9f02cacb9&from_ts=None&live=false&showSummaryGraphs=true-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Warn: [SpendHQ] - High Network IN  on host - prd-db1 - 10.59.10.190 - db Status,,31-01-2018 22:23,1554,0,SpendHQ,"since It is a warning alert and the alert got resolved , we are closing this case",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ayh2E,Cloud Engineer Level 2,Closed,1103219,Incident,29-08-2018 00:01,,"Hello Chris,Please discard our previous email.As discussed with Allen, we don't need to mount nimble storage volume on this server and we are good with the ticket for now.  @Allen, as you confirmed we are marking this case as resolved. Please revert back to us if you have any concerns###Hello Chris,We haven't heard back from you.We are trying to mount the iSCSI Volume iqn.2007-11.com.nimblestorage:prd-db-171120-180601-clone-v777bb21358661922.00000046.2f1dab31 in the machine 10.59.10.180 but we are not able to login to the target.Please re-share the volume again with this machine 10.59.10.180.###Hello Rohit As discussed on the call I have checked all the instances in spend HQ account. All the instance are not having fstab entries with ISCSI volumes and the instance which are having ISCSI entries which are commented on previously.As mentioned by Rohit I have used SSM to get these detailsSSM Command ID : 164285e1-8036-44ac-bf91-6e157d62b0adAnd the output also pushed to S3 Bucket name: reancloud28082018Next Actin for the L1 team: Kindly review these details with Rohit and check is there any pending action for us.###Please check with Rohit, whether the customer was asking for the zadara storage. If not please do follow up with Chris to get new volume backup###Please check with Rohit, whether we need to check any other details###Hello Allen,Previously we thought this was nimple/Jetstor volume on the server 10.59.10.180. Now we are able to see that zadaractorage /dev/sdm mounted on /usr/local/mariadb. Please let us know if you want us mount any other iscsi volumes on the server###Hey Rean, What did you guys run to get the zadara mounts up on 10.59.10.68. All I see in history are  952  iscsiadm --mode discovery --type sendtargets --portal 172.23.104.77:3260  953  iscsiadm --mode discovery --type sendtargets --portal 172.24.5.3:3260  Allen Herrera | Associate Engineer | SpendHQ®###Hi Allen,We have made the changes to the fstab entry for the machine 10.59.10.180 and mounted back the iSCSI Volume on the folder /usr/local/mariadb. For the iSCSI Volume which needs to be mounted on the folder /mnt/production_may_23_2018, we are facing issue while trying to logging into the target. We have raised our concern with Chris. Once Chris re-share the volume again with this machine. We will mount the volume and update you. Thanks !Regards,Rohit Puri###Hi Chris,We are trying to mount the iSCSI Volume iqn.2007-11.com.nimblestorage:prd-db-171120-180601-clone-v777bb21358661922.00000046.2f1dab31 in the machine 10.59.10.180 but we are not able to login to the target. It fails with the below error:×Please re-share the volume again with this machine 10.59.10.180. Its an priority. Thanks !Regards,Rohit Puri###I have detached the volume and attached to the test instance and commented teh fstab entry. Reattached the volume to old machine and facing issue to find teh iscsi volume that mounted earlier.Rohit is working on it.###Hello TeamAllen requested that we apply the fix to this server 10.59.10.180 as well since it is still offline###Hello Allen We will work on it and keep you posted on the developments.Regards###Hello Matthew,We have already prepared the RCA. Please find the document from the attachment section and let us know if you have any queries.###REAN, Can you please advise when we can expect an RCA for the occurrences that happened over the weekend? It is critical that we get these sooner rather than later. Matthew Watts | Manager, Application Development | SpendHQ®###Hello Team,We have created the RCA document which will describe the outage which was happened yesterday and Preventive action which we need to take to get rid of this kind of issues in future.Please find the RCA document in the attachments section and let us know if you have any further concerns/queries.###@Team:We are good to share the RCA with SpendHQ Team###Created the RCA, preventive actions are pending. Please reach out to Rohit for the further action item on this casehttps://docs.google.com/document/d/1xxCj-uwVtdevZVdzrWgWN06fE8vmj37EczeqMZazXuw/edit?usp=sharing###Rohit Puri10:43 PM (5 hours ago)to Matthew, REAN Hi Mathew,We have mounted the iSCSI volume on /usr/local/mariadb in the instance 10.59.10.68Please verify the data and let us know if you face any issue. Thanks !Regards,Rohit Puri###Need to create an RCA. As discussed with Rohit please go through the following point that has to cover on the RCA. Get it review by him tomorrow morning.Why it does not come up:1. The fstab entry has the entry for iSCSI Volume which created issue.2. iscsi volumes name changes whenever server reboots3. The fstab entry look for the disk name which is added in the fstab entry4. We dettached the root volume and attached the volume to other instance5. Commented the fstqab entry then we attached the volume again6. This let the instance to start this time there is no bad entry nowso bad fstab entry created the issueGo through the AWS summary in the previous comment to get more details.###Sent an email to MGSleads@reancloud.com###[AWS Team reponse]=================Hello Thenmozhy, Thank you for your time on Chat today. Below you can find a short summary of our chat session for future reference.You have contacted AWS Premium Support as the EC2 instance i-073f764282507b8a8 was failing it's Instance Level Status checks.During our chat session, I reviewed the instance and it's Underlying hardware and I can confirm the underlying hardware hosting the instance was healthy and passing it's status checks [1]. However, the instance was failing it's Instance level status checks [2].Therefore, I reviewed the Console output from the EC2 instance and noticed the instance was booting into emergency mode with the following error messages:         [1;33mDEPEND [0m] Dependency failed for /usr/local/mariadb.        [ [1;33mDEPEND [0m] Dependency failed for Local File Systems.        [ [1;33mDEPEND [0m] Dependency failed for Relabel all filesystems, if necessary.        [ [1;33mDEPEND [0m] Dependency failed for Mark the need to relabel after reboot.        [ [1;33mDEPEND [0m] Dependency failed for Migrate local... structure to the new structure.        [ [1;31m TIME  [0m] Timed out waiting for device dev-sdae.device.        [ [1;33mDEPEND [0m] Dependency failed for /mnt/preview_csv_transfer_07_18_18.I suspected the issue to be a bad entry in the fstab file that is causing the instance to fail it's boot.Later, we setup a screen share session and launched the test instance i-048d057832851caa6 in the same Availability zone us-east-1b. Following this step, we detached the EBS Volume vol-0ddc8a2cde5121025 from the EC2 instance i-073f764282507b8a8 and attached it to the EC2 instance i-048d057832851caa6 as it's Secondary Volume /dev/sdf.Following this, we SSH'ed into the test instance and mounted the secondary voloume at /mnt by running: sudo mount /dev/xvdf1 /mnt.Later, we noticed some entries in fstab file that could be an issue. We commented out these entries, unmounted the volume, stopped the test instance, Detached the Volume vol-0ddc8a2cde5121025 and attached it back to the Original instance i-073f764282507b8a8.Following this, we started the original instance i-073f764282507b8a8 back up and confirmed you were able to SSH into it and the instance was passing it's status checks. Later, we added the nofail option to the fstab file and then ran the mount -a command to confirm an entry (ISCSI mount) for /dev/sdae was failing. These entries were not mounting an EBS/instance Store volume and you later confirmed that these were ISCSI mounts. We later confirmed there was no file system by running lsblk -f and hence this mount was failing.It was a pleasure assisting you today. Meanwhile, Please Feel free to contact us if you have any further questions or concerns, we will be happy to assist.Best regards,Mohit M.Amazon Web Services###Hello Matthew,Thanks for the update.We are currently working with AWS support team to resolve the issue and will get back to you.###Matthew Watts9:34 PM (34 minutes ago)to me, REAN Perfect. We need an RCA as to why that happened###Hello Matthew,The issue got fixed now.We will provide an RCA regarding this issue. Please revert back to us in case of any queries.###Hello Matthew,We have joined the call. Please, can you please join the call again.https://reancloud.zoom.us/my/mgse1###We have postponed the release and will touch base with next steps tomorrow. Matthew Watts###Hello Matthew,We have performed stop and start and again the server is going to stopped state. We are raising AWS support case to schedule a call to resolve this issue and will share the bridge details with you.###I was on the call but no-one was there. Matthew Watts###Hello Matthew,Can you please join on the below bridge.https://reancloud.zoom.us/my/mgse1###Can you guys create a bridge as this is preventing us from moving forwards Matthew Watts###Please do  Matthew Watts###Hello Matthew,The instance status check got failed. We are going to perform stop and start activity. Please find the screenshot for the same.","REAN,We are unable to reboot server 10.59.10.68. Can we please setup a bridge asap to resolve.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SEV ONE,,26-08-2018 19:34,52,0,SpendHQ,"Hello Chris,Please discard our previous email.As discussed with Allen, we don't need to mount nimble storage volume on this server and we are good with the ticket for now.  @Allen, as you confirmed we are marking this case as resolved. Please revert back to us if you have any concerns","Hello Chris,We haven't heard back from you.We are trying to mount the iSCSI Volume iqn.2007-11.com.nimblestorage:prd-db-171120-180601-clone-v777bb21358661922.00000046.2f1dab31 in the machine 10.59.10.180 but we are not able to login to the target.Please re-share the volume again with this machine 10.59.10.180.",Hello Rohit As discussed on the call I have checked all the instances in spend HQ account. All the instance are not having fstab entries with ISCSI volumes and the instance which are having ISCSI entries which are commented on previously.As mentioned by Rohit I have used SSM to get these detailsSSM Command ID : 164285e1-8036-44ac-bf91-6e157d62b0adAnd the output also pushed to S3 Bucket name: reancloud28082018Next Actin for the L1 team: Kindly review these details with Rohit and check is there any pending action for us.,"Please check with Rohit, whether the customer was asking for the zadara storage. If not please do follow up with Chris to get new volume backup","Please check with Rohit, whether we need to check any other details","Hello Allen,Previously we thought this was nimple/Jetstor volume on the server 10.59.10.180. Now we are able to see that zadaractorage /dev/sdm mounted on /usr/local/mariadb. Please let us know if you want us mount any other iscsi volumes on the server","Hey Rean, What did you guys run to get the zadara mounts up on 10.59.10.68. All I see in history are  952  iscsiadm --mode discovery --type sendtargets --portal 172.23.104.77:3260  953  iscsiadm --mode discovery --type sendtargets --portal 172.24.5.3:3260  Allen Herrera | Associate Engineer | SpendHQ®","Hi Allen,We have made the changes to the fstab entry for the machine 10.59.10.180 and mounted back the iSCSI Volume on the folder /usr/local/mariadb. For the iSCSI Volume which needs to be mounted on the folder /mnt/production_may_23_2018, we are facing issue while trying to logging into the target. We have raised our concern with Chris. Once Chris re-share the volume again with this machine. We will mount the volume and update you. Thanks !Regards,Rohit Puri","Hi Chris,We are trying to mount the iSCSI Volume iqn.2007-11.com.nimblestorage:prd-db-171120-180601-clone-v777bb21358661922.00000046.2f1dab31 in the machine 10.59.10.180 but we are not able to login to the target. It fails with the below error:×Please re-share the volume again with this machine 10.59.10.180. Its an priority. Thanks !Regards,Rohit Puri",I have detached the volume and attached to the test instance and commented teh fstab entry. Reattached the volume to old machine and facing issue to find teh iscsi volume that mounted earlier.Rohit is working on it.,Hello TeamAllen requested that we apply the fix to this server 10.59.10.180 as well since it is still offline,Hello Allen We will work on it and keep you posted on the developments.Regards,"Hello Matthew,We have already prepared the RCA. Please find the document from the attachment section and let us know if you have any queries.","REAN, Can you please advise when we can expect an RCA for the occurrences that happened over the weekend? It is critical that we get these sooner rather than later. Matthew Watts | Manager, Application Development | SpendHQ®","Hello Team,We have created the RCA document which will describe the outage which was happened yesterday and Preventive action which we need to take to get rid of this kind of issues in future.Please find the RCA document in the attachments section and let us know if you have any further concerns/queries.",@Team:We are good to share the RCA with SpendHQ Team,"Created the RCA, preventive actions are pending. Please reach out to Rohit for the further action item on this casehttps://docs.google.com/document/d/1xxCj-uwVtdevZVdzrWgWN06fE8vmj37EczeqMZazXuw/edit?usp=sharing","Rohit Puri10:43 PM (5 hours ago)to Matthew, REAN Hi Mathew,We have mounted the iSCSI volume on /usr/local/mariadb in the instance 10.59.10.68Please verify the data and let us know if you face any issue. Thanks !Regards,Rohit Puri",Need to create an RCA. As discussed with Rohit please go through the following point that has to cover on the RCA. Get it review by him tomorrow morning.Why it does not come up:1. The fstab entry has the entry for iSCSI Volume which created issue.2. iscsi volumes name changes whenever server reboots3. The fstab entry look for the disk name which is added in the fstab entry4. We dettached the root volume and attached the volume to other instance5. Commented the fstqab entry then we attached the volume again6. This let the instance to start this time there is no bad entry nowso bad fstab entry created the issueGo through the AWS summary in the previous comment to get more details.,Sent an email to MGSleads@reancloud.com,"[AWS Team reponse]=================Hello Thenmozhy, Thank you for your time on Chat today. Below you can find a short summary of our chat session for future reference.You have contacted AWS Premium Support as the EC2 instance i-073f764282507b8a8 was failing it's Instance Level Status checks.During our chat session, I reviewed the instance and it's Underlying hardware and I can confirm the underlying hardware hosting the instance was healthy and passing it's status checks [1]. However, the instance was failing it's Instance level status checks [2].Therefore, I reviewed the Console output from the EC2 instance and noticed the instance was booting into emergency mode with the following error messages:         [1;33mDEPEND [0m] Dependency failed for /usr/local/mariadb.        [ [1;33mDEPEND [0m] Dependency failed for Local File Systems.        [ [1;33mDEPEND [0m] Dependency failed for Relabel all filesystems, if necessary.        [ [1;33mDEPEND [0m] Dependency failed for Mark the need to relabel after reboot.        [ [1;33mDEPEND [0m] Dependency failed for Migrate local... structure to the new structure.        [ [1;31m TIME  [0m] Timed out waiting for device dev-sdae.device.        [ [1;33mDEPEND [0m] Dependency failed for /mnt/preview_csv_transfer_07_18_18.I suspected the issue to be a bad entry in the fstab file that is causing the instance to fail it's boot.Later, we setup a screen share session and launched the test instance i-048d057832851caa6 in the same Availability zone us-east-1b. Following this step, we detached the EBS Volume vol-0ddc8a2cde5121025 from the EC2 instance i-073f764282507b8a8 and attached it to the EC2 instance i-048d057832851caa6 as it's Secondary Volume /dev/sdf.Following this, we SSH'ed into the test instance and mounted the secondary voloume at /mnt by running: sudo mount /dev/xvdf1 /mnt.Later, we noticed some entries in fstab file that could be an issue. We commented out these entries, unmounted the volume, stopped the test instance, Detached the Volume vol-0ddc8a2cde5121025 and attached it back to the Original instance i-073f764282507b8a8.Following this, we started the original instance i-073f764282507b8a8 back up and confirmed you were able to SSH into it and the instance was passing it's status checks. Later, we added the nofail option to the fstab file and then ran the mount -a command to confirm an entry (ISCSI mount) for /dev/sdae was failing. These entries were not mounting an EBS/instance Store volume and you later confirmed that these were ISCSI mounts. We later confirmed there was no file system by running lsblk -f and hence this mount was failing.It was a pleasure assisting you today. Meanwhile, Please Feel free to contact us if you have any further questions or concerns, we will be happy to assist.Best regards,Mohit M.Amazon Web Services","Hello Matthew,Thanks for the update.We are currently working with AWS support team to resolve the issue and will get back to you.","Matthew Watts9:34 PM (34 minutes ago)to me, REAN Perfect. We need an RCA as to why that happened","Hello Matthew,The issue got fixed now.We will provide an RCA regarding this issue. Please revert back to us in case of any queries.","Hello Matthew,We have joined the call. Please, can you please join the call again.https://reancloud.zoom.us/my/mgse1",We have postponed the release and will touch base with next steps tomorrow. Matthew Watts,"Hello Matthew,We have performed stop and start and again the server is going to stopped state. We are raising AWS support case to schedule a call to resolve this issue and will share the bridge details with you.",I was on the call but no-one was there. Matthew Watts,"Hello Matthew,Can you please join on the below bridge.https://reancloud.zoom.us/my/mgse1",Can you guys create a bridge as this is preventing us from moving forwards Matthew Watts,Please do  Matthew Watts,"Hello Matthew,The instance status check got failed. We are going to perform stop and start activity. Please find the screenshot for the same.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000017QL1r,Cloud Engineer Level 1,Closed,1042796,Incident,06-02-2017 04:22,,"Hi Steven,Thanks for your update.Please update us once you schedule the downtime so we could include the iscsi service restart on the same window. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Steven updated that,We do not have a scheduled downtime in mind. This will happen in the next few months. Steven Ng | Full Stack Developer | SpendHQ®###Hello Steven,We haven't heard back from you. Please mention the planned downtime of the PROD-SPHQ-DB-SERVER03 server. So that we can restart the iscsi and iscsid services.###Hello Steven,Thanks for the update.We will hold the service restart till then. Please specify the time frame for the planned downtime so we could include the service restart on the same window.Thanks & Regards,Safuvan KM###Steven Ng:I do not want to go forward with doing that since it is a live PROD server currently. I may want to do the restart next week when we have a planned downtime for that server. Steven Ng | Full Stack Developer | SpendHQ®O: 770-628-0692 | sng@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group###Hello Steven,Do we have any updates on this?Please let us know if we can perform an iscsi and iscsid service restart in 10.59.10.91 to resolve the initiator errors.###Hello Steven,Thanks for the update. We will hold the restart for now and please let us know once you have ready with the restart of ISCSI service.###Delay restarting 10.59.10.91 until I have communicated this with the team.###Hello Steven,There will be a downtime of below 5 minutes for ISCSI service.Best Regards, Safuvan KM###Would restarting cause any downtime for 10.59.10.91?###My mistake, please DO NOT restart 10.59.10.91. It is currently being used in a live PROD environment.###Please coordinate with whoever is handling the current case on the 10.59.10.91 machine.That case number is: I-01042803###Hello Matthew,We have restarted the service from 10.59.10.148 but the error messages in 10.59.10.91 still happening. Usually, this error will pop up due to the initiator name replication but this is an exception. Need to look into it further. Please let us know if we can restart the ISCSI service in 10.59.10.91 also.Best Regards, Safuvan KM###I restarted the iscsi and iscsid in 10.59.10.148 but the errors in 10.59.10.91 is still repeating.From 10.59.10.91, there is one target in iscsi status in which the server is failed to login. the target details are here.iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000015.2f1dab31 (non-flash)        Current Portal: 172.23.104.77:3260,2460        Persistent Portal: 172.23.104.77:3260,2460###Matthew WattsLet’s do it now please Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com###Hello Steven,From the messages logs, we could see the login rejected errors due to initiator error are mentioning to the PROD-SPHQ-DB-SERVER03.Feb  2 21:01:25 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:28 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:31 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:34 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:36 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:39 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:42 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:45 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:47 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:50 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)From the PROD-SPHQ-DB-SERVER03, we could see the initiator names are different in the ISCSI status and in the initiator configuration file.[root@ip-10-59-10-148 ~]# /etc/init.d/iscsi status | grep Iface Initiatorname                Iface Initiatorname: iqn.1994-05.com.redhat:64d02cf6d2ce[root@ip-10-59-10-148 ~]# cat /etc/iscsi/initiatorname.iscsiInitiatorName=iqn.1994-05.com.redhat:201701140148This can be resolved by an ISCSI service restart. Please let us know the window to perform this action on PROD-SPHQ-DB-SERVER03 that will resolve the issue.Best Regards, Safuvan KM###Hello Steven,We are looking into this and will get back to you with updates.",I keep getting this message on /var/log/messages for the machine at 10.59.10.91 Feb  2 17:48:36 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Can someone take a look into this? Thank you.,10.59.10.91 iscsi initiator error,,02-02-2017 23:22,77,0,SpendHQ,"Hi Steven,Thanks for your update.Please update us once you schedule the downtime so we could include the iscsi service restart on the same window. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Steven updated that,We do not have a scheduled downtime in mind. This will happen in the next few months. Steven Ng | Full Stack Developer | SpendHQ®","Hello Steven,We haven't heard back from you. Please mention the planned downtime of the PROD-SPHQ-DB-SERVER03 server. So that we can restart the iscsi and iscsid services.","Hello Steven,Thanks for the update.We will hold the service restart till then. Please specify the time frame for the planned downtime so we could include the service restart on the same window.Thanks & Regards,Safuvan KM",Steven Ng:I do not want to go forward with doing that since it is a live PROD server currently. I may want to do the restart next week when we have a planned downtime for that server. Steven Ng | Full Stack Developer | SpendHQ®O: 770-628-0692 | sng@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group,"Hello Steven,Do we have any updates on this?Please let us know if we can perform an iscsi and iscsid service restart in 10.59.10.91 to resolve the initiator errors.","Hello Steven,Thanks for the update. We will hold the restart for now and please let us know once you have ready with the restart of ISCSI service.",Delay restarting 10.59.10.91 until I have communicated this with the team.,"Hello Steven,There will be a downtime of below 5 minutes for ISCSI service.Best Regards, Safuvan KM",Would restarting cause any downtime for 10.59.10.91?,"My mistake, please DO NOT restart 10.59.10.91. It is currently being used in a live PROD environment.",Please coordinate with whoever is handling the current case on the 10.59.10.91 machine.That case number is: I-01042803,"Hello Matthew,We have restarted the service from 10.59.10.148 but the error messages in 10.59.10.91 still happening. Usually, this error will pop up due to the initiator name replication but this is an exception. Need to look into it further. Please let us know if we can restart the ISCSI service in 10.59.10.91 also.Best Regards, Safuvan KM","I restarted the iscsi and iscsid in 10.59.10.148 but the errors in 10.59.10.91 is still repeating.From 10.59.10.91, there is one target in iscsi status in which the server is failed to login. the target details are here.iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000015.2f1dab31 (non-flash)        Current Portal: 172.23.104.77:3260,2460        Persistent Portal: 172.23.104.77:3260,2460","Matthew WattsLet’s do it now please Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com","Hello Steven,From the messages logs, we could see the login rejected errors due to initiator error are mentioning to the PROD-SPHQ-DB-SERVER03.Feb  2 21:01:25 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:28 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:31 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:34 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:36 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:39 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:42 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:45 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:47 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Feb  2 21:01:50 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)From the PROD-SPHQ-DB-SERVER03, we could see the initiator names are different in the ISCSI status and in the initiator configuration file.[root@ip-10-59-10-148 ~]# /etc/init.d/iscsi status | grep Iface Initiatorname                Iface Initiatorname: iqn.1994-05.com.redhat:64d02cf6d2ce[root@ip-10-59-10-148 ~]# cat /etc/iscsi/initiatorname.iscsiInitiatorName=iqn.1994-05.com.redhat:201701140148This can be resolved by an ISCSI service restart. Please let us know the window to perform this action on PROD-SPHQ-DB-SERVER03 that will resolve the issue.Best Regards, Safuvan KM","Hello Steven,We are looking into this and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001HXRe1,Cloud Engineer Level 1,Closed,1080399,Incident,28-09-2017 18:19,,"Hello Dusty,Thanks for the update. As of now, we are marking this case as resolved. Kindly revert back incase of any further queries.Regards,Sumod.K.Bose###[Dusty updated the case via Email]That is the expected result when going to that domain.  From my testing everything is working correctly.Dusty Fowler | Developer | SpendHQ® O: 770.628.0026 | dfowler@spendhq.com A SaaS Spend Visibility solution from Insight Sourcing Group www.spendhq.com | www.insightsourcing.com###Hello Dusty,Thanks for the update. While we try to access the URL https://l.spendhq.com/, we could see the below mentioned error.==================================================================Logi Debugger Trace ReportThere was an error while processing your request.The error was:Unable to authenticate the user. Missing rdSecureKey parameter.Click here for more detailed information.==================================================================Also, we have attached the screenshot of the same along with this CMP Ticket. Kindly validate it from your end and let us know if you have any further queries regarding the same.Regards,Sumod.K.Bose###[Dusty updated the case via Email]Further update, all application errors have been corrected and things appear to be working as normal.  Thanks again. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###[Dusty updated the case via Email]Thanks for upping the size.  I am looking into the application error. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com###Next action: Follow up with Matthew in evening shift.###Hello Matthew, Thank you for your time over the call, in the call we tried to fix the Name or Service not known error (Attached the screenshot) and you have fixed the issue and confirmed the web page is loading fine for you. While checking from our side, we are getting a Navigator error (attached the screenshot). As discussed you will be fixing this issue once you are back available. Until the time, we are keeping this ticket on hold. @Dusty: We have successfully increased the root volume size to 160 GB, please verify from your side and let us know if you have any queries. Please find the details below. [root@ip-10-59-10-107 centos]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 ext4 158G 6.9G 145G 5% / tmpfs tmpfs 7.3G 0 7.3G 0% /dev/shm###Hello Dusty, In order to perform this action, we have performed a restart on this machine. Post restart we can see that the tomcat service didn't come up automatically. We have performed a manual restart and after that, we can see the below error message while loading the page. Please see the attachment section for error details It seems like an application error. Can you please have a look into this. Meanwhile, we will raise a support ticket with AWS to identify the issue with resizing the partition.###Dusty Fowler12:30 AM (6 hours ago)to Rean, spendhq-support Let’s keep the RAM as it is then.  However, I think we are good resizing the EBS volume if you want to take the volume offline.  This is a development machine, so there should be no client impact.  Can we schedule to have this done ASAP? Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com###Hello Dusty,The current size of the 10.59.10.107 instance is C4.2xlarge which has a memory of 15GB.If you want us to increase the memory to 30 GB then we have to resize the instance to C4.4xlarge.Please note that to resize the instance we need to perform a stop and start which will cause a downtime of 5-10 minutes.Also, For resizing the root volume, There are 2 ways:1.Launch a new instance from the AMI of the current instance.2.Resize the current root EBS volume which will cause a downtime of 10-15 mins.Since, As updated above, We need to stop the instance for changing its type, We can schedule these both activities together in order to make the downtime minimal.Kindly review our findings and let us know your thoughts on this.","Currently the 10.59.10.107 machine has total space size of 8G (located at /dev/xvda1).[dusty@10 home]$ df -hFilesystem      Size  Used Avail Use% Mounted on/dev/xvda1      7.8G  6.8G  569M  93% /tmpfs           7.3G     0  7.3G   0% /dev/shmCan we get this increased to 160G?Also, if I am reading correct it has 15G of RAM[dusty@10 home]$ free             total       used       free     shared    buffers     cachedMem:      15297464    6299700    8997764        236     214808    2216040-/+ buffers/cache:    3868852   11428612Swap:            0          0          0Can we have that doubled if that is the case?Thanks!Dusty Fowler | Developer | SpendHQ(r)O: 770.628.0026 | dfowler@spendhq.com<mailto:dfowler@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- <https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Up drive size,,27-09-2017 21:04,21,0,SpendHQ,"Hello Dusty,Thanks for the update. As of now, we are marking this case as resolved. Kindly revert back incase of any further queries.Regards,Sumod.K.Bose",[Dusty updated the case via Email]That is the expected result when going to that domain.  From my testing everything is working correctly.Dusty Fowler | Developer | SpendHQ® O: 770.628.0026 | dfowler@spendhq.com A SaaS Spend Visibility solution from Insight Sourcing Group www.spendhq.com | www.insightsourcing.com,"Hello Dusty,Thanks for the update. While we try to access the URL https://l.spendhq.com/, we could see the below mentioned error.==================================================================Logi Debugger Trace ReportThere was an error while processing your request.The error was:Unable to authenticate the user. Missing rdSecureKey parameter.Click here for more detailed information.==================================================================Also, we have attached the screenshot of the same along with this CMP Ticket. Kindly validate it from your end and let us know if you have any further queries regarding the same.Regards,Sumod.K.Bose","[Dusty updated the case via Email]Further update, all application errors have been corrected and things appear to be working as normal.  Thanks again. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com",[Dusty updated the case via Email]Thanks for upping the size.  I am looking into the application error. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com,Next action: Follow up with Matthew in evening shift.,"Hello Matthew, Thank you for your time over the call, in the call we tried to fix the Name or Service not known error (Attached the screenshot) and you have fixed the issue and confirmed the web page is loading fine for you. While checking from our side, we are getting a Navigator error (attached the screenshot). As discussed you will be fixing this issue once you are back available. Until the time, we are keeping this ticket on hold. @Dusty: We have successfully increased the root volume size to 160 GB, please verify from your side and let us know if you have any queries. Please find the details below. [root@ip-10-59-10-107 centos]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 ext4 158G 6.9G 145G 5% / tmpfs tmpfs 7.3G 0 7.3G 0% /dev/shm","Hello Dusty, In order to perform this action, we have performed a restart on this machine. Post restart we can see that the tomcat service didn't come up automatically. We have performed a manual restart and after that, we can see the below error message while loading the page. Please see the attachment section for error details It seems like an application error. Can you please have a look into this. Meanwhile, we will raise a support ticket with AWS to identify the issue with resizing the partition.","Dusty Fowler12:30 AM (6 hours ago)to Rean, spendhq-support Let’s keep the RAM as it is then.  However, I think we are good resizing the EBS volume if you want to take the volume offline.  This is a development machine, so there should be no client impact.  Can we schedule to have this done ASAP? Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com","Hello Dusty,The current size of the 10.59.10.107 instance is C4.2xlarge which has a memory of 15GB.If you want us to increase the memory to 30 GB then we have to resize the instance to C4.4xlarge.Please note that to resize the instance we need to perform a stop and start which will cause a downtime of 5-10 minutes.Also, For resizing the root volume, There are 2 ways:1.Launch a new instance from the AMI of the current instance.2.Resize the current root EBS volume which will cause a downtime of 10-15 mins.Since, As updated above, We need to stop the instance for changing its type, We can schedule these both activities together in order to make the downtime minimal.Kindly review our findings and let us know your thoughts on this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001IHYpI,Cloud Engineer Level 1,Closed,1082013,Incident,17-10-2017 07:02,,"Hello Team,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.###Hello Team, We haven't heard back from you. Please review the details and let us know if you have any further queries on this case.###Next action: Do follow up with the customer during evening shift hours.###Hello Teaam,We haven't heard back from you.Please review the details and let us know if you have any further queries on this case.###Hello SpendHQ-Team,We did the further investigation on this issue and come up with and conclusion that the site was not actually down. The application was witnessing a high traffic at the time of the alert and that was visible as a spike in the ELB sum request count statistics. Because of the high load in the web server, the request were taking long time than normal to get processed and we were witnessing a large spike in the ELB latency i.e., the latency reached a maximum value of 297 seconds. Our monitoring tool is configured to report the application outage if the there is no response was received for the access request in a period of 30 seconds. From the end point monitoring tool(wormly) logs, we were able to find the time out errors stating the same. Please find the logs below:HTTP Request    23:09:17    Operation timed out after 9000 milliseconds with 0 bytes received        Sydney-C AUHTTP Request    23:09:17    Operation timed out after 9002 milliseconds with 0 bytes received        Dallas-B USHTTP Request    23:09:17    Operation timed out after 9001 milliseconds with 0 bytes received        Frankfurt DEHTTP Request    23:09:17    Operation timed out after 9010 milliseconds with 0 bytes received        California USWe have pulled the ELB access logs and that has the complete list of logs with high latency including the wormly test requests. Please find the attachment section for more details.Since the site was not actually down, we are reducing the priority to P3. Kindly validate the details and let us know if you have any queries.###Hello SpendHQ-Team, This is to inform you that we received an alert regarding site down for the URL https://secure.spendhq.com/login. The overall downtime was about 4 minutes & 1 second. Currently, the URL is up and serving well. We are performing further investigation regarding this outage and will get back to you with further updates. Meanwhile, please let us know if your team has performed any kind of activity which lead to this outage. Revert back in case of any further queries.","Fri, 13 Oct 2017 13:36:56 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Dallas-B US, California US, Sydney-C AU, Atlanta-B US--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,13-10-2017 23:07,80,0,SpendHQ,"Hello Team,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.","Hello Team, We haven't heard back from you. Please review the details and let us know if you have any further queries on this case.",Next action: Do follow up with the customer during evening shift hours.,"Hello Teaam,We haven't heard back from you.Please review the details and let us know if you have any further queries on this case.","Hello SpendHQ-Team,We did the further investigation on this issue and come up with and conclusion that the site was not actually down. The application was witnessing a high traffic at the time of the alert and that was visible as a spike in the ELB sum request count statistics. Because of the high load in the web server, the request were taking long time than normal to get processed and we were witnessing a large spike in the ELB latency i.e., the latency reached a maximum value of 297 seconds. Our monitoring tool is configured to report the application outage if the there is no response was received for the access request in a period of 30 seconds. From the end point monitoring tool(wormly) logs, we were able to find the time out errors stating the same. Please find the logs below:HTTP Request    23:09:17    Operation timed out after 9000 milliseconds with 0 bytes received        Sydney-C AUHTTP Request    23:09:17    Operation timed out after 9002 milliseconds with 0 bytes received        Dallas-B USHTTP Request    23:09:17    Operation timed out after 9001 milliseconds with 0 bytes received        Frankfurt DEHTTP Request    23:09:17    Operation timed out after 9010 milliseconds with 0 bytes received        California USWe have pulled the ELB access logs and that has the complete list of logs with high latency including the wormly test requests. Please find the attachment section for more details.Since the site was not actually down, we are reducing the priority to P3. Kindly validate the details and let us know if you have any queries.","Hello SpendHQ-Team, This is to inform you that we received an alert regarding site down for the URL https://secure.spendhq.com/login. The overall downtime was about 4 minutes & 1 second. Currently, the URL is up and serving well. We are performing further investigation regarding this outage and will get back to you with further updates. Meanwhile, please let us know if your team has performed any kind of activity which lead to this outage. Revert back in case of any further queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Lu4V8,Cloud Engineer Level 3,Closed,1086356,Incident,21-12-2017 11:08,,"Hi Matthew,As discussed on the Bi-Weekly call we are closing this ticket. Please let us know if you have any questions. Thanks###Hi Andrew, Matthew,We have not received a response from you on this.Please note that the site was not actually down at the time of the alert but the Wormly alert triggered due to the high latency on the website. We can see there was high traffic at the time of alert and that caused high load on the production database.To optimize these further please review the attached ELB logs to optimize the long-running database queries.Please let us know if you have any questions or we are good to close this case.###On evening ops call Sanket mentioned to Yogesh to review the SpendHQ environmentNeed to check with Yogesh for updates on this case###Hello Team,We haven't heard back from youPlease review the details in the previous comment and revert back to us if you have further queries.###Hello Team,We haven't heard back from you.The site was not actually down and it was due to the latency where our monitoring tool was trying to ping the site but didn't get any response within the specified time period (30 seconds). Hence it has thrown the site down alert.All of the requests within the timeframe of this issue has been served with 200 response code. We are looking for a solution to avoid this kind of issues and will reach out to you with the updates.###Send a reminder to the customer on the evening shift.###As per the discussion on today's evening call, this ticket has assigned to Praveen for review.###Evening OPS call Sanket updated that he will review this ticket and provide us with an update.###Based on morning Ops call discussion, on shift team suggested that autoscalling & HA is only solution to solve this problem in this environment. Need further discussion.Regards/Chirodeep###Hello Team,On further analysis, we were able to figure out that the URL https://secure.spendhq.com/login was not down at the time of this alert. The violation has lasted for 7 minutes and 1 seconds.We have verified the logs and we could see a sudden spike in the ELB latency graph where ELB was not able to respond to our monitoring request within the timeout period set in the monitoring tool (which is 30 seconds). Hence it has thrown the Site down alert. From the instance level, we could see a high number of connections in TIME_WAIT state. There are 754  connections which are in TIME_WAIT state condition. netstat -a | grep -i TIME | wc -l   754    All of the requests within the timeframe of this issue has been served with 200 response code. As the URL https://secure.spendhq.com/login was not down, we are reducing the priority of this case from P1 to P2. We have attached the ELB access logs and latency graph during the time of this issue along with this ticket for reference. Kindly validate it for more details.###Hello Team, This is to inform you that we received a site down alert for the URL https://secure.spendhq.com/login.The site is taking too much time for accessible. We will analyze the issue from our end and meanwhile please let us know if your team has performed any activity from your end.","Tue, 12 Dec 2017 12:21:17 -0500Detected Error on SpendHQ SecureEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Dallas-B US, California US, Frankfurt DE, Atlanta-B US-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,12-12-2017 22:51,204,0,SpendHQ,"Hi Matthew,As discussed on the Bi-Weekly call we are closing this ticket. Please let us know if you have any questions. Thanks","Hi Andrew, Matthew,We have not received a response from you on this.Please note that the site was not actually down at the time of the alert but the Wormly alert triggered due to the high latency on the website. We can see there was high traffic at the time of alert and that caused high load on the production database.To optimize these further please review the attached ELB logs to optimize the long-running database queries.Please let us know if you have any questions or we are good to close this case.",On evening ops call Sanket mentioned to Yogesh to review the SpendHQ environmentNeed to check with Yogesh for updates on this case,"Hello Team,We haven't heard back from youPlease review the details in the previous comment and revert back to us if you have further queries.","Hello Team,We haven't heard back from you.The site was not actually down and it was due to the latency where our monitoring tool was trying to ping the site but didn't get any response within the specified time period (30 seconds). Hence it has thrown the site down alert.All of the requests within the timeframe of this issue has been served with 200 response code. We are looking for a solution to avoid this kind of issues and will reach out to you with the updates.",Send a reminder to the customer on the evening shift.,"As per the discussion on today's evening call, this ticket has assigned to Praveen for review.",Evening OPS call Sanket updated that he will review this ticket and provide us with an update.,"Based on morning Ops call discussion, on shift team suggested that autoscalling & HA is only solution to solve this problem in this environment. Need further discussion.Regards/Chirodeep","Hello Team,On further analysis, we were able to figure out that the URL https://secure.spendhq.com/login was not down at the time of this alert. The violation has lasted for 7 minutes and 1 seconds.We have verified the logs and we could see a sudden spike in the ELB latency graph where ELB was not able to respond to our monitoring request within the timeout period set in the monitoring tool (which is 30 seconds). Hence it has thrown the Site down alert. From the instance level, we could see a high number of connections in TIME_WAIT state. There are 754  connections which are in TIME_WAIT state condition. netstat -a | grep -i TIME | wc -l   754    All of the requests within the timeframe of this issue has been served with 200 response code. As the URL https://secure.spendhq.com/login was not down, we are reducing the priority of this case from P1 to P2. We have attached the ELB access logs and latency graph during the time of this issue along with this ticket for reference. Kindly validate it for more details.","Hello Team, This is to inform you that we received a site down alert for the URL https://secure.spendhq.com/login.The site is taking too much time for accessible. We will analyze the issue from our end and meanwhile please let us know if your team has performed any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013vv8S,Cloud Engineer Level 1,Closed,1030980,Incident,12-11-2016 14:17,,"Team,It's a duplicate ticket.","Can we please request that the secure.spendhq.com ELB points to 10.58.100.118 and the preview.spendhq.com ELB points to 10.59.100.125.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",ELB Changes,,12-11-2016 14:10,0,0,SpendHQ,"Team,It's a duplicate ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DdBZt,Cloud Engineer Level 1,Closed,1063195,Incident,16-06-2017 21:45,,"Hello SpendHQ-Team,This is to notify you that the alert regarding volume usage for  prod-sphq-db-server05 instance /dev/xvda1 volume got resolved and has returned to normal with a value of 55%. The violation lasted for 1 hour 6 minutes.###Hello Team,This is to notify you that the alert regarding volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume is still in an open state with the value of 100%. Please review breakup details provided in the ticket and delete/zip the files which are consuming high volume.###Hello SpendHQ Team, This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% to 100%.Please see the usage details below.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G   17M 100% /Usage under / is given below:47G     total24G     tmp12G     var11G     usr510M    home285M    lib282M    optUsage under /tmp is given below:24G     total7.8G    liger_view_41abb8e65f688db087e5e76d16c36ac6.csv1.9G    liger_view_598fa1779fbcfaeb2e97a27a92b4620f.csv1.8G    liger_view_ac8ba9aafd515aa75070861eb9d50845.csv1.1G    liger_view_282e607c5298b17b54fbe7e18cbde94e.csv920M    liger_view_f38241d8921e7f8d589f1c7c22231fd9.csv920M    liger_view_b2d8803657fa33071ef7357660d8258a.csv920M    liger_view_6c7004dd91b42b13c86293fa1bd45d92.csv920M    liger_view_37a0bcd251b3f36e2cde754fad299a64.csv879M    liger_view_d4cc48300d4b1db91b71c8d706e62af1.csvPlease remove or zip files to reduce the current volume usage.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Fri, Jun 16, 2017 at 8:35 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjTsPgyAYRX-NbDUfIA8HBvswTTp3aJcGAR-JClUY-u-LyR1ObnLutYrVnUOTIoAFcMwxA0ZlySkmuMTQyPp8q6S48rZlUFRgox1K49GoHDBBesIJp53g2HaaVLWUjpsOBHU9mtUYY9gL2hSkzdEhlFZHbf0wfvPGcnTG-LTGTGHz_TS7TOkEb7h8Hr_XE98T2tSy5-PN6dXMPtnDRFEtfp2i3_7pETm3>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj02OgzAMhU8TlpHt_IAXWbTTco1RmqSAVBoG0qrHn4BmMZIl28_yp_eiM3xLzeQIsAWLFg0Y1UmrkFAinDo-X3XXXmzfGxAaYomDDLkZnQ_6FtM9eR2IAnhrMYWOg8XWM2tqHm4sZdmEOgnqa_llkdEXH_Mw_lTGXLU5P6eS102QIiDFloXqS_4u9e2CmltLRjMDgCA7rPm1VD2m9xSSILOTDfV1P_rnHT3u09eYt3LcEaThmkOiMpVwX_P8n63pYDerm7cabk3-GR75FXd3TXF_7n4BZQdTQg>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Fri Jun 16 2017 15:05:00 UTC (*37 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtjsGOwyAMRL8GjsiYmoQDh3a7_AdglERqSjah1X7-kmolS_aMpXnDnlwqcvEIegCrrSYgMyprNGql4Tq62_dlHO42BAJxAW48qVzl7DNydhYcuczJIsSUKDFlxAgDDEU-_NzadghzFRj6xG1THFvkOs0_PWPt3lqfS6v7IdAgoHHWCROmvb42Ye5c3ksuAulMIAxdf_bvm6M-r6-5Hu3z16DI9b5KG5K7X49edS_xmR_1xSdLNv_P-gPqMEZF>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjUkOwjAQBF9jH6MZ73PwAQT5h8k4i5TEITH_x0hIfSqpqjlaemW5RAXowaFDC1aHzmlU2CHcAt2fJviH63sLwgBXnrqhyDlmUn4M5LXDEcAjGGeY2GSySVs0co1zrccl9E2ovi0dR8epJi7T_G6NrbGt7Est5yWUVqA0OWow81LlGber_Z057cNaPvwTZI1_4QuLzDVC>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVjksOwyAQQ08DS8QwgZAFi1Zp7sEnPykJKUzuXyp5YVl6tpPTQ5j57pSEXhowoKVGKwyCAgHyZYf3p7P9aKZJS9bJRGkVMfPN9QZCb21QBpPCYKJSaGGYtdG4QJT8cBvRXRm-mJqa_H2L5MmnvG7f1nG2bL-W4iuVJ9JTZobTlitd_mx2BCn00D4IQM2LO2ubL7O_4pGf9Oc5uTNfO-XyAwVGOpo>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jcsKgzAURL8mWYZ78zJ3kYXF-h8xiQ9QYzXt99duCgMDB-ZM8oaGzBcvARuwaNGAUU5YhRIFQuvo8dSu6WzfG2AaUk2TiIXPfowuIzocZcyEKcqgcbBWh4GCswh89XOtx8VUy2R_JxyHSKGGVKb5dTu2m-VP3uu_Vb8kpjpFaLAxpIkAyAFq5Kffrvv-zGGPa3mn355Xv5V9qeX8AgPdOV8>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjcsOgyAURL9GloTLS1ywaNP6HzwuaqJCEf-_mMxicjI5E62aPJLNcgYj06BBMSUM1QI4UGAvM72_0owfPc-KDZLFFhcaMlktlxIgjcp4nhBjEjh58BK9M9o4RLLbtbVyDeI18LnHlUKjay7mZf11x_GwEPJ9tt5KxYQVz4AXqfa4-ldFd4Y93_EZk2aPfG4t1z-flDdN>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,16-06-2017 20:49,1,0,SpendHQ,"Hello SpendHQ-Team,This is to notify you that the alert regarding volume usage for  prod-sphq-db-server05 instance /dev/xvda1 volume got resolved and has returned to normal with a value of 55%. The violation lasted for 1 hour 6 minutes.","Hello Team,This is to notify you that the alert regarding volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume is still in an open state with the value of 100%. Please review breakup details provided in the ticket and delete/zip the files which are consuming high volume.","Hello SpendHQ Team, This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% to 100%.Please see the usage details below.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G   17M 100% /Usage under / is given below:47G     total24G     tmp12G     var11G     usr510M    home285M    lib282M    optUsage under /tmp is given below:24G     total7.8G    liger_view_41abb8e65f688db087e5e76d16c36ac6.csv1.9G    liger_view_598fa1779fbcfaeb2e97a27a92b4620f.csv1.8G    liger_view_ac8ba9aafd515aa75070861eb9d50845.csv1.1G    liger_view_282e607c5298b17b54fbe7e18cbde94e.csv920M    liger_view_f38241d8921e7f8d589f1c7c22231fd9.csv920M    liger_view_b2d8803657fa33071ef7357660d8258a.csv920M    liger_view_6c7004dd91b42b13c86293fa1bd45d92.csv920M    liger_view_37a0bcd251b3f36e2cde754fad299a64.csv879M    liger_view_d4cc48300d4b1db91b71c8d706e62af1.csvPlease remove or zip files to reduce the current volume usage.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DB06U,Cloud Engineer Level 1,Closed,1061714,Incident,10-06-2017 01:05,,"I did the initial analysis and there were 4 alerts with the message SERVER-APACHE Apache Struts remote code execution attempt. As we are not using Apache strut and as per the previous conclusion to not to inform these false positives before the Sophos firmware update, we are closing this case.Thank You,Safuvan KM###This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.Regards,Safuvan KM",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-06-09 18:36:50Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 54943Destination IP address: 10.59.1.192 (spendhq)Destination port: 8080 (http-alt)--System Uptime      : 209 days 10 hours 51 minutesSystem Load        : 0.16System Version     : Sophos UTM 9.408-4Please refer to the manual for detailed instructions.,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,10-06-2017 00:15,1,0,SpendHQ,"I did the initial analysis and there were 4 alerts with the message SERVER-APACHE Apache Struts remote code execution attempt. As we are not using Apache strut and as per the previous conclusion to not to inform these false positives before the Sophos firmware update, we are closing this case.Thank You,Safuvan KM","This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.Regards,Safuvan KM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DBJA2,Cloud Engineer Level 3,Closed,1061939,Incident,14-06-2017 17:37,,"Hello Team,We are creating a deployment plan for enabling piped logging program to rotate apache logs.As of now we are closing this ticket and will open a change ticket to share the deployment plan.Please let us know if you have any queries regarding this.###Sivasankar updated to check the apache log levels that Apache recognizes. emerg: Emergency situations where the system is in an unusable state.alert: Severe situation where action is needed promptly.crit: Important problems that need to be addressed.error: An Error has occurred. Something was unsuccessful.warn: Something out of the ordinary happened, but not a cause for concern.notice: Something normal, but worth noting has happened.info: An informational message that might be nice to know.debug: Debugging information that can be useful to pinpoint where a problem is occurring.trace[1-8]: Tracing information of various levels of verbosity that produces a large amount of information.When you specify a log level, you are not choosing to log the messages labeled in that category, you are choosing the least important level that you wish to log.This means that any levels above the selected level are also logged. For example, if you choose the warn log level, messages tagged with warn, error, crit, alert, and emerg will all be logged.We specify the level of logging desired with the LogLevel directive. We can see the default log level in the default configuration file.I am verifying the details and based on that will update the deployment plan and test it.###I had a discussion with Siva and he will review the deployment plan. please check with him for the status.###Yogesh: We were successful with the test in REAN LAB test instance for piped logging program to rotate apache logs. Please review the deployment plan https://docs.google.com/spreadsheets/d/14LHtkimJOpoYQ3N3AL0eI1MZFocujAwi2jKLO7Fk1yE/edit#gid=11467729 and let me know if we can share it with the customer by asking for a maintenance window to apply this?###We have launched a test instance in reanlab account and checked the deployment plan. After changing the CustomLog in httpd.conf to CustomLog |/usr/local/apache/bin/rotatelogs /var/log/access_log 60480 commonCustomLog |/usr/local/apache/bin/rotatelogs /var/log/error_log 60480 commonand tried to restart the httpd service, it fails. While checking the httpd error logs, we could see the below entries*****************unable to start piped log program '/usr/local/apache/bin/rotatelogs /var/log/access_log 60480': No such file or directoryUnable to open logsunable to start piped log program '/usr/local/apache/bin/rotatelogs /var/log/access_log 60480': No such file or directoryUnable to open logs*****************So we have changed the CustomLog entries to CustomLog |usr/sbin/rotatelogs /var/log/access_log 60 commonCustomLog |usr/sbin/rotatelogs /var/log/error_log 60 commonand now we were able to restart the httpd service and we could see that both /var/log/access_log and /var/log/error_log logs are getting rotated.###We need to test this in lab account and everything is working fine review it with CE2 and update with customer.###Please find the deployment plan link to Enable piped logging program to rotate apache logshttps://docs.google.com/spreadsheets/d/14LHtkimJOpoYQ3N3AL0eI1MZFocujAwi2jKLO7Fk1yE/edit#gid=11467729###8) Logging in /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log			[root@ip-10-59-100-94 logs]# ls -ltrh			total 4.9G			-rwxrwxrwx 1 nfsnobody nfsnobody    0 Sep 20  2016 web2-http-secure.spendhq.com-error.log			-rwxrwxrwx 1 nfsnobody nfsnobody    0 Sep 20  2016 web2-http-preview.spendhq.com-error.log			-rwxrwxrwx 1 nfsnobody nfsnobody 4.8M Nov 11  2016 web2-https-preview.spendhq.com-error.log			-rw-r--r-- 1 nfsnobody nfsnobody    0 Apr 26 16:08 web2-http-api.spendhq.com-error.log			-rw-r--r-- 1 nfsnobody nfsnobody  67K May  8 19:43 web2-http-api.spendhq.com-access.log			-rwxrwxrwx 1 nfsnobody nfsnobody 370M May 15 15:53 web2-https-preview.spendhq.com-access.log			-rw-rw-r-- 1 rlittle   rlittle   2.0M May 25 15:01 ana.log			-rw-rw-r-- 1 rlittle   rlittle   184M May 25 20:51 ana2.log			-rw-rw-r-- 1 rlittle   rlittle   171M May 25 21:08 ana3.log			-rw-r--r-- 1 nfsnobody nfsnobody  99K Jun  5 17:25 web2-94-http-preview.spendhq.com-error.log			-rwxrwxrwx 1 nfsnobody nfsnobody 4.6M Jun  9 19:29 web2-http-preview.spendhq.com-access.log			-rw-r--r-- 1 nfsnobody nfsnobody 5.9M Jun 10 15:04 web2-94-https-preview.spendhq.com-error.log			-rw-r--r-- 1 nfsnobody nfsnobody  13M Jun 11 22:24 web2-94-http-preview.spendhq.com-access.log			-rw-r--r-- 1 nfsnobody nfsnobody 621K Jun 12 02:20 web2-https-api.spendhq.com-error.log			-rw-r--r-- 1 nfsnobody nfsnobody  16M Jun 12 02:20 web2-https-api.spendhq.com-access.log			-rwxrwxrwx 1 nfsnobody nfsnobody  16M Jun 12 02:20 web2-https-secure.spendhq.com-error.log			-rwxrwxrwx 1 nfsnobody nfsnobody 9.2M Jun 12 06:39 web2-http-secure.spendhq.com-access.log			-rwxrwxrwx 1 nfsnobody nfsnobody 3.9G Jun 12 07:36 web2-https-secure.spendhq.com-access.log			-rw-r--r-- 1 nfsnobody nfsnobody 300M Jun 12 07:36 web2-94-https-preview.spendhq.com-access.log			[root@ip-10-59-100-94 logs]# head web2-http-secure.spendhq.com-access.log			10.59.1.241 - - [12/Nov/2016:08:56:29 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 10.0; WOW64; rv:49.0) Gecko/20100101 Firefox/49.0			10.59.5.204 - - [12/Nov/2016:08:57:45 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (iPhone; CPU iPhone OS 10_1_1 like Mac OS X) AppleWebKit/602.2.14 (KHTML, like Gecko) Version/10.0 Mobile/14B100 Safari/602.1			10.59.5.204 - - [12/Nov/2016:09:05:17 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 5.1; rv:6.0.2) Gecko/20100101 Firefox/6.0.2			10.59.5.204 - - [12/Nov/2016:11:05:29 +0000] GET /robots.txt HTTP/1.1 301 245 - Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)			10.59.5.204 - - [12/Nov/2016:11:05:59 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 5.1; rv:6.0.2) Gecko/20100101 Firefox/6.0.2			10.59.5.204 - - [12/Nov/2016:11:08:32 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Linux; Android 6.0.1; Nexus 5X Build/MMB29P) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.96 Mobile Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)			10.59.5.204 - - [12/Nov/2016:12:05:19 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 5.1; rv:6.0.2) Gecko/20100101 Firefox/6.0.2			10.59.5.204 - - [12/Nov/2016:13:37:01 +0000] GET /wp-login.php HTTP/1.1 301 247 - Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1			10.59.5.204 - - [12/Nov/2016:13:37:06 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1			10.59.5.204 - - [12/Nov/2016:14:05:32 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 5.1; rv:6.0.2) Gecko/20100101 Firefox/6.0.2###5) Process holding access log			[root@ip-10-59-100-94 log]# lsof httpd/access_log			COMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME			httpd    2061 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    2949 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    3755 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    3943 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    3977 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    5860 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    6749 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   11992 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   17948 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   23112 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   23568 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   24410 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   29651   root   15w   REG  202,1        0 3774 httpd/access_log		67) We can see that there were a kernel module update and PHP version upgrade performed on June 1st we started seeing issues with the log rotation after that the first issue occurred on 3rd June.					Jun 01 19:53:55 Updated: nss-3.28.4-3.el6_9.x86_64			Jun 01 19:53:55 Updated: nss-sysinit-3.28.4-3.el6_9.x86_64			Jun 01 19:53:56 Updated: initscripts-9.03.58-1.el6.centos.1.x86_64			Jun 01 19:53:56 Updated: libtirpc-0.2.1-13.el6_9.x86_64			Jun 01 19:53:59 Updated: kernel-firmware-2.6.32-696.3.1.el6.noarch			Jun 01 19:54:03 Installed: kernel-2.6.32-696.3.1.el6.x86_64			Jun 01 19:54:03 Updated: rpcbind-0.2.0-13.el6_9.x86_64			Jun 01 19:54:03 Updated: nss-tools-3.28.4-3.el6_9.x86_64			Jun 01 19:54:04 Updated: kernel-headers-2.6.32-696.3.1.el6.x86_64			Jun 01 19:54:04 Updated: sudo-1.8.6p3-28.el6_9.x86_64			Jun 01 20:18:33 Installed: php-5.6.30-1.el6.remi.x86_647) Apache log configuration[root@ip-10-59-100-94 httpd]# cat conf/httpd.conf | grep -v ^# | grep logLoadModule log_config_module modules/mod_log_config.soLoadModule logio_module modules/mod_logio.soErrorLog logs/error_logCustomLog logs/access_log combined[Continution in next comment ]###Hi Team,From my analysis, I could find that we started seeing issue Sat, 03 Jun 2017. We did not make any log rotation configuration change recently also and the log rotation also worked properly before the Jun 3rd. The only change that we can see which could have impacted the log rotation activity is kernel module and PHP version upgrade performed on Jun 1st.Also during this analysis, we could see that the actual logs are not getting populated in default access log location(/var/log/httpd/access_log) instead of that we could see the access log populating in /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log which currently not getting rotated(size: 3.9G). They also use log_config_module module in apache for logging.We need to add log rotation configuration to  /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.logPlease find the analysis done below:	Event time	----------		Sat, 10 Jun 2017 23:46:46 -0400		Sat, 03 Jun 2017 23:17:59 -0400	Resource Involved in the Event	------------------------------			1. EC2 instance		Resource details EC2	--------------------		1. Name:	PROD-SPHQ-WEB-SERVER03 : 10.59.100.94		Analysis	--------		1) Linux distribution details :Linux ip-10-59-100-94.ec2.internal 2.6.32-696.1.1.el6.x86_64 #1 SMP Tue Apr 11 17:13:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux				2) Cron Job details :Present for root						## Run the file monitor script every day at 8:00am (server time is UTC)			*/5  *  *  *  * /usr/bin/php /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/monitor_directories.php >> /var/tmp/shq-logs/crons/file-monitor.log 2>&1						## Run load validation every minute.			*/1  *  *  *  * /bin/bash /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/load.sh >> /var/tmp/shq-logs/crons/load.log 2>&1								3) Up time :  06:35:59 up 11 days, 16:59,  1 user,  load average: 0.42, 0.22, 0.13				4) Users longlined at time of issue   			dmiller  pts/1        10.59.1.192      Mon Jun  5 15:26 - 17:44  (02:17)    			mwatts   pts/2        10.59.1.192      Mon Jun  5 15:09 - 17:43  (02:34)    			dmiller  pts/1        10.59.1.192      Mon Jun  5 14:52 - 15:19  (00:26)    			centos   pts/1        10.59.1.192      Mon Jun  5 13:18 - 13:23  (00:05)    			centos   pts/1        10.59.1.192      Fri Jun  2 22:09 - 02:22  (04:12)    			dmiller  pts/1        10.59.1.192      Fri Jun  2 14:49 - 15:02  (00:13)    			dfowler  pts/4        10.59.1.192      Thu Jun  1 19:48 - 21:06  (01:18)    			mwatts   pts/4        10.59.1.192      Thu Jun  1 19:37 - 19:40  (00:02)    			mwatts   pts/4        10.59.1.192      Thu Jun  1 18:42 - 19:32  (00:49)    			dfowler  pts/3        10.59.1.192      Thu Jun  1 18:36 - 20:44  (02:08)    			dmiller  pts/3        10.59.1.192      Thu Jun  1 18:32 - 18:35  (00:03)    			sng      pts/2        10.59.1.192      Thu Jun  1 14:50 - 22:07  (07:16)    			sng      pts/1        10.59.1.192      Thu Jun  1 14:43 - 22:07  (07:24)    			mwatts   pts/0        10.59.1.192      Thu Jun  1 14:34 - 18:29  (03:55)    			dfowler  pts/1        10.59.1.192      Thu Jun  1 00:46 - 01:40  (00:53) [Continution in next comment ]###Praveen updated to Create a JIRA ticket and come up with a deployment to perform the log rotation at apache level and not using the system level log rotation. Link for reference : https://httpd.apache.org/docs/2.4/programs/rotatelogs.html###Hello Team,On further analysis we found below details:The httpd process went down in the server and it caused after the logrotation which contains a apache reload.  Please review the below apache error log.[Sun Jun 11 03:45:37 2017] [notice] SIGHUP received.  Attempting to restart*** glibc detected *** /usr/sbin/httpd: free(): invalid pointer: 0x00007f55fb108038 ***======= Backtrace: =========/lib64/libc.so.6(+0x75dee)[0x7f55f9744dee]/lib64/libc.so.6(+0x78c3d)[0x7f55f9747c3d]/etc/httpd/modules/mod_ldap.so(+0x6630)[0x7f55f7491630]/usr/lib64/libapr-1.so.0(apr_pool_destroy+0x7e)[0x7f55f9c9899e]/usr/lib64/libapr-1.so.0(apr_pool_clear+0x45)[0x7f55f9c98be5]/usr/sbin/httpd(main+0xa25)[0x7f55fb1ae935]/lib64/libc.so.6(__libc_start_main+0xfd)[0x7f55f96edd1d]/usr/sbin/httpd(+0x16a09)[0x7f55fb1ada09]======= Memory map: ========7f55e0000000-7f55e0021000 rw-p 00000000 00:00 07f55e0021000-7f55e4000000 ---p 00000000 00:00 07f55e4fc0000-7f55e4fd6000 r-xp 00000000 ca:01 297459                     /lib64/libgcc_s-4.4.7-20120601.so.17f55e4fd6000-7f55e51d5000 ---p 00016000 ca:01 297459                     /lib64/libgcc_s-4.4.7-20120601.so.17f55e51d5000-7f55e51d6000 rw-p 00015000 ca:01 297459                     /lib64/libgcc_s-4.4.7-20120601.so.17f55e51d6000-7f55e5254000 rw-s 00000000 00:04 20100429                   /dev/zero (deleted)7f55e5254000-7f55e52c2000 r-xp 00000000 ca:01 264987                     /usr/lib64/php/modules/redis.so7f55e52c2000-7f55e54c2000 ---p 0006e000 ca:01 264987                     /usr/lib64/php/modules/redis.so7f55e54c2000-7f55e54c7000 rw-p 0006e000 ca:01 264987                     /usr/lib64/php/modules/redis.so......[Sun Jun 11 03:45:37 2017] [notice] seg fault or similar nasty error detected in the parent processWe observed below kernel log entries.httpd[13344]: segfault at ffffffffffffff50 ip 00007f55faf8243c sp 00007ffd56797f20 error 4 in ld-2.12.so[7f55faf74000+20000]httpd[9466]: segfault at ffffffffffffff50 ip 00007f55faf8243c sp 00007ffd56797f20 error 4 in ld-2.12.so[7f55faf74000+20000]The apache version is Apache/2.2.15. The error glibc detected *** /usr/sbin/httpd: free(): invalid pointer observed from the httpd error log tells that the httpd process kept a pointer to a block of memory around even though the memory had already been freed for other use. So it can be the issue with the dynamic memory allocation. The segmentation fault is an indication of a program bug. It occurs when a program tries to access memory it's not allowed to access. The segmentation fault is caused by PHP. We recommend upgrading the apache and PHP to latest versions. We will further investigate the issue and let you know the updates.###Hello Team,This is to inform you that the site down alert got resolved.We have verified that both the sites https://preview.spendhq.com/login and https://secure.spendhq.com/login are running fine.On initial analysis, we could see that the httpd process went down on prod-sphq-web-server03 and we have started the service which resolved the issue.We are analyzing more on this and will keep you posted regarding the updates.###Hello Team, This is to inform you that we received a site down alert for URLs https://preview.spendhq.com/login and https://secure.spendhq.com/login. We are analyzing the issue and will let you know the update. Please let us know if you are performing any activity from your end.","Sat, 10 Jun 2017 23:46:46 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: --------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Dallas-B US, Sydney-C AU, London UK, Frankfurt DE-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,11-06-2017 09:16,80,0,SpendHQ,"Hello Team,We are creating a deployment plan for enabling piped logging program to rotate apache logs.As of now we are closing this ticket and will open a change ticket to share the deployment plan.Please let us know if you have any queries regarding this.","Sivasankar updated to check the apache log levels that Apache recognizes. emerg: Emergency situations where the system is in an unusable state.alert: Severe situation where action is needed promptly.crit: Important problems that need to be addressed.error: An Error has occurred. Something was unsuccessful.warn: Something out of the ordinary happened, but not a cause for concern.notice: Something normal, but worth noting has happened.info: An informational message that might be nice to know.debug: Debugging information that can be useful to pinpoint where a problem is occurring.trace[1-8]: Tracing information of various levels of verbosity that produces a large amount of information.When you specify a log level, you are not choosing to log the messages labeled in that category, you are choosing the least important level that you wish to log.This means that any levels above the selected level are also logged. For example, if you choose the warn log level, messages tagged with warn, error, crit, alert, and emerg will all be logged.We specify the level of logging desired with the LogLevel directive. We can see the default log level in the default configuration file.I am verifying the details and based on that will update the deployment plan and test it.",I had a discussion with Siva and he will review the deployment plan. please check with him for the status.,Yogesh: We were successful with the test in REAN LAB test instance for piped logging program to rotate apache logs. Please review the deployment plan https://docs.google.com/spreadsheets/d/14LHtkimJOpoYQ3N3AL0eI1MZFocujAwi2jKLO7Fk1yE/edit#gid=11467729 and let me know if we can share it with the customer by asking for a maintenance window to apply this?,"We have launched a test instance in reanlab account and checked the deployment plan. After changing the CustomLog in httpd.conf to CustomLog |/usr/local/apache/bin/rotatelogs /var/log/access_log 60480 commonCustomLog |/usr/local/apache/bin/rotatelogs /var/log/error_log 60480 commonand tried to restart the httpd service, it fails. While checking the httpd error logs, we could see the below entries*****************unable to start piped log program '/usr/local/apache/bin/rotatelogs /var/log/access_log 60480': No such file or directoryUnable to open logsunable to start piped log program '/usr/local/apache/bin/rotatelogs /var/log/access_log 60480': No such file or directoryUnable to open logs*****************So we have changed the CustomLog entries to CustomLog |usr/sbin/rotatelogs /var/log/access_log 60 commonCustomLog |usr/sbin/rotatelogs /var/log/error_log 60 commonand now we were able to restart the httpd service and we could see that both /var/log/access_log and /var/log/error_log logs are getting rotated.",We need to test this in lab account and everything is working fine review it with CE2 and update with customer.,Please find the deployment plan link to Enable piped logging program to rotate apache logshttps://docs.google.com/spreadsheets/d/14LHtkimJOpoYQ3N3AL0eI1MZFocujAwi2jKLO7Fk1yE/edit#gid=11467729,"8) Logging in /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log			[root@ip-10-59-100-94 logs]# ls -ltrh			total 4.9G			-rwxrwxrwx 1 nfsnobody nfsnobody    0 Sep 20  2016 web2-http-secure.spendhq.com-error.log			-rwxrwxrwx 1 nfsnobody nfsnobody    0 Sep 20  2016 web2-http-preview.spendhq.com-error.log			-rwxrwxrwx 1 nfsnobody nfsnobody 4.8M Nov 11  2016 web2-https-preview.spendhq.com-error.log			-rw-r--r-- 1 nfsnobody nfsnobody    0 Apr 26 16:08 web2-http-api.spendhq.com-error.log			-rw-r--r-- 1 nfsnobody nfsnobody  67K May  8 19:43 web2-http-api.spendhq.com-access.log			-rwxrwxrwx 1 nfsnobody nfsnobody 370M May 15 15:53 web2-https-preview.spendhq.com-access.log			-rw-rw-r-- 1 rlittle   rlittle   2.0M May 25 15:01 ana.log			-rw-rw-r-- 1 rlittle   rlittle   184M May 25 20:51 ana2.log			-rw-rw-r-- 1 rlittle   rlittle   171M May 25 21:08 ana3.log			-rw-r--r-- 1 nfsnobody nfsnobody  99K Jun  5 17:25 web2-94-http-preview.spendhq.com-error.log			-rwxrwxrwx 1 nfsnobody nfsnobody 4.6M Jun  9 19:29 web2-http-preview.spendhq.com-access.log			-rw-r--r-- 1 nfsnobody nfsnobody 5.9M Jun 10 15:04 web2-94-https-preview.spendhq.com-error.log			-rw-r--r-- 1 nfsnobody nfsnobody  13M Jun 11 22:24 web2-94-http-preview.spendhq.com-access.log			-rw-r--r-- 1 nfsnobody nfsnobody 621K Jun 12 02:20 web2-https-api.spendhq.com-error.log			-rw-r--r-- 1 nfsnobody nfsnobody  16M Jun 12 02:20 web2-https-api.spendhq.com-access.log			-rwxrwxrwx 1 nfsnobody nfsnobody  16M Jun 12 02:20 web2-https-secure.spendhq.com-error.log			-rwxrwxrwx 1 nfsnobody nfsnobody 9.2M Jun 12 06:39 web2-http-secure.spendhq.com-access.log			-rwxrwxrwx 1 nfsnobody nfsnobody 3.9G Jun 12 07:36 web2-https-secure.spendhq.com-access.log			-rw-r--r-- 1 nfsnobody nfsnobody 300M Jun 12 07:36 web2-94-https-preview.spendhq.com-access.log			[root@ip-10-59-100-94 logs]# head web2-http-secure.spendhq.com-access.log			10.59.1.241 - - [12/Nov/2016:08:56:29 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 10.0; WOW64; rv:49.0) Gecko/20100101 Firefox/49.0			10.59.5.204 - - [12/Nov/2016:08:57:45 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (iPhone; CPU iPhone OS 10_1_1 like Mac OS X) AppleWebKit/602.2.14 (KHTML, like Gecko) Version/10.0 Mobile/14B100 Safari/602.1			10.59.5.204 - - [12/Nov/2016:09:05:17 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 5.1; rv:6.0.2) Gecko/20100101 Firefox/6.0.2			10.59.5.204 - - [12/Nov/2016:11:05:29 +0000] GET /robots.txt HTTP/1.1 301 245 - Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)			10.59.5.204 - - [12/Nov/2016:11:05:59 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 5.1; rv:6.0.2) Gecko/20100101 Firefox/6.0.2			10.59.5.204 - - [12/Nov/2016:11:08:32 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Linux; Android 6.0.1; Nexus 5X Build/MMB29P) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.96 Mobile Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)			10.59.5.204 - - [12/Nov/2016:12:05:19 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 5.1; rv:6.0.2) Gecko/20100101 Firefox/6.0.2			10.59.5.204 - - [12/Nov/2016:13:37:01 +0000] GET /wp-login.php HTTP/1.1 301 247 - Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1			10.59.5.204 - - [12/Nov/2016:13:37:06 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1			10.59.5.204 - - [12/Nov/2016:14:05:32 +0000] GET / HTTP/1.1 301 235 - Mozilla/5.0 (Windows NT 5.1; rv:6.0.2) Gecko/20100101 Firefox/6.0.2","5) Process holding access log			[root@ip-10-59-100-94 log]# lsof httpd/access_log			COMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME			httpd    2061 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    2949 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    3755 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    3943 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    3977 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    5860 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd    6749 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   11992 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   17948 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   23112 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   23568 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   24410 apache   15w   REG  202,1        0 3774 httpd/access_log			httpd   29651   root   15w   REG  202,1        0 3774 httpd/access_log		67) We can see that there were a kernel module update and PHP version upgrade performed on June 1st we started seeing issues with the log rotation after that the first issue occurred on 3rd June.					Jun 01 19:53:55 Updated: nss-3.28.4-3.el6_9.x86_64			Jun 01 19:53:55 Updated: nss-sysinit-3.28.4-3.el6_9.x86_64			Jun 01 19:53:56 Updated: initscripts-9.03.58-1.el6.centos.1.x86_64			Jun 01 19:53:56 Updated: libtirpc-0.2.1-13.el6_9.x86_64			Jun 01 19:53:59 Updated: kernel-firmware-2.6.32-696.3.1.el6.noarch			Jun 01 19:54:03 Installed: kernel-2.6.32-696.3.1.el6.x86_64			Jun 01 19:54:03 Updated: rpcbind-0.2.0-13.el6_9.x86_64			Jun 01 19:54:03 Updated: nss-tools-3.28.4-3.el6_9.x86_64			Jun 01 19:54:04 Updated: kernel-headers-2.6.32-696.3.1.el6.x86_64			Jun 01 19:54:04 Updated: sudo-1.8.6p3-28.el6_9.x86_64			Jun 01 20:18:33 Installed: php-5.6.30-1.el6.remi.x86_647) Apache log configuration[root@ip-10-59-100-94 httpd]# cat conf/httpd.conf | grep -v ^# | grep logLoadModule log_config_module modules/mod_log_config.soLoadModule logio_module modules/mod_logio.soErrorLog logs/error_logCustomLog logs/access_log combined[Continution in next comment ]","Hi Team,From my analysis, I could find that we started seeing issue Sat, 03 Jun 2017. We did not make any log rotation configuration change recently also and the log rotation also worked properly before the Jun 3rd. The only change that we can see which could have impacted the log rotation activity is kernel module and PHP version upgrade performed on Jun 1st.Also during this analysis, we could see that the actual logs are not getting populated in default access log location(/var/log/httpd/access_log) instead of that we could see the access log populating in /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log which currently not getting rotated(size: 3.9G). They also use log_config_module module in apache for logging.We need to add log rotation configuration to  /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.logPlease find the analysis done below:	Event time	----------		Sat, 10 Jun 2017 23:46:46 -0400		Sat, 03 Jun 2017 23:17:59 -0400	Resource Involved in the Event	------------------------------			1. EC2 instance		Resource details EC2	--------------------		1. Name:	PROD-SPHQ-WEB-SERVER03 : 10.59.100.94		Analysis	--------		1) Linux distribution details :Linux ip-10-59-100-94.ec2.internal 2.6.32-696.1.1.el6.x86_64 #1 SMP Tue Apr 11 17:13:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux				2) Cron Job details :Present for root						## Run the file monitor script every day at 8:00am (server time is UTC)			*/5  *  *  *  * /usr/bin/php /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/monitor_directories.php >> /var/tmp/shq-logs/crons/file-monitor.log 2>&1						## Run load validation every minute.			*/1  *  *  *  * /bin/bash /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/load.sh >> /var/tmp/shq-logs/crons/load.log 2>&1								3) Up time :  06:35:59 up 11 days, 16:59,  1 user,  load average: 0.42, 0.22, 0.13				4) Users longlined at time of issue   			dmiller  pts/1        10.59.1.192      Mon Jun  5 15:26 - 17:44  (02:17)    			mwatts   pts/2        10.59.1.192      Mon Jun  5 15:09 - 17:43  (02:34)    			dmiller  pts/1        10.59.1.192      Mon Jun  5 14:52 - 15:19  (00:26)    			centos   pts/1        10.59.1.192      Mon Jun  5 13:18 - 13:23  (00:05)    			centos   pts/1        10.59.1.192      Fri Jun  2 22:09 - 02:22  (04:12)    			dmiller  pts/1        10.59.1.192      Fri Jun  2 14:49 - 15:02  (00:13)    			dfowler  pts/4        10.59.1.192      Thu Jun  1 19:48 - 21:06  (01:18)    			mwatts   pts/4        10.59.1.192      Thu Jun  1 19:37 - 19:40  (00:02)    			mwatts   pts/4        10.59.1.192      Thu Jun  1 18:42 - 19:32  (00:49)    			dfowler  pts/3        10.59.1.192      Thu Jun  1 18:36 - 20:44  (02:08)    			dmiller  pts/3        10.59.1.192      Thu Jun  1 18:32 - 18:35  (00:03)    			sng      pts/2        10.59.1.192      Thu Jun  1 14:50 - 22:07  (07:16)    			sng      pts/1        10.59.1.192      Thu Jun  1 14:43 - 22:07  (07:24)    			mwatts   pts/0        10.59.1.192      Thu Jun  1 14:34 - 18:29  (03:55)    			dfowler  pts/1        10.59.1.192      Thu Jun  1 00:46 - 01:40  (00:53) [Continution in next comment ]",Praveen updated to Create a JIRA ticket and come up with a deployment to perform the log rotation at apache level and not using the system level log rotation. Link for reference : https://httpd.apache.org/docs/2.4/programs/rotatelogs.html,"Hello Team,On further analysis we found below details:The httpd process went down in the server and it caused after the logrotation which contains a apache reload.  Please review the below apache error log.[Sun Jun 11 03:45:37 2017] [notice] SIGHUP received.  Attempting to restart*** glibc detected *** /usr/sbin/httpd: free(): invalid pointer: 0x00007f55fb108038 ***======= Backtrace: =========/lib64/libc.so.6(+0x75dee)[0x7f55f9744dee]/lib64/libc.so.6(+0x78c3d)[0x7f55f9747c3d]/etc/httpd/modules/mod_ldap.so(+0x6630)[0x7f55f7491630]/usr/lib64/libapr-1.so.0(apr_pool_destroy+0x7e)[0x7f55f9c9899e]/usr/lib64/libapr-1.so.0(apr_pool_clear+0x45)[0x7f55f9c98be5]/usr/sbin/httpd(main+0xa25)[0x7f55fb1ae935]/lib64/libc.so.6(__libc_start_main+0xfd)[0x7f55f96edd1d]/usr/sbin/httpd(+0x16a09)[0x7f55fb1ada09]======= Memory map: ========7f55e0000000-7f55e0021000 rw-p 00000000 00:00 07f55e0021000-7f55e4000000 ---p 00000000 00:00 07f55e4fc0000-7f55e4fd6000 r-xp 00000000 ca:01 297459                     /lib64/libgcc_s-4.4.7-20120601.so.17f55e4fd6000-7f55e51d5000 ---p 00016000 ca:01 297459                     /lib64/libgcc_s-4.4.7-20120601.so.17f55e51d5000-7f55e51d6000 rw-p 00015000 ca:01 297459                     /lib64/libgcc_s-4.4.7-20120601.so.17f55e51d6000-7f55e5254000 rw-s 00000000 00:04 20100429                   /dev/zero (deleted)7f55e5254000-7f55e52c2000 r-xp 00000000 ca:01 264987                     /usr/lib64/php/modules/redis.so7f55e52c2000-7f55e54c2000 ---p 0006e000 ca:01 264987                     /usr/lib64/php/modules/redis.so7f55e54c2000-7f55e54c7000 rw-p 0006e000 ca:01 264987                     /usr/lib64/php/modules/redis.so......[Sun Jun 11 03:45:37 2017] [notice] seg fault or similar nasty error detected in the parent processWe observed below kernel log entries.httpd[13344]: segfault at ffffffffffffff50 ip 00007f55faf8243c sp 00007ffd56797f20 error 4 in ld-2.12.so[7f55faf74000+20000]httpd[9466]: segfault at ffffffffffffff50 ip 00007f55faf8243c sp 00007ffd56797f20 error 4 in ld-2.12.so[7f55faf74000+20000]The apache version is Apache/2.2.15. The error glibc detected *** /usr/sbin/httpd: free(): invalid pointer observed from the httpd error log tells that the httpd process kept a pointer to a block of memory around even though the memory had already been freed for other use. So it can be the issue with the dynamic memory allocation. The segmentation fault is an indication of a program bug. It occurs when a program tries to access memory it's not allowed to access. The segmentation fault is caused by PHP. We recommend upgrading the apache and PHP to latest versions. We will further investigate the issue and let you know the updates.","Hello Team,This is to inform you that the site down alert got resolved.We have verified that both the sites https://preview.spendhq.com/login and https://secure.spendhq.com/login are running fine.On initial analysis, we could see that the httpd process went down on prod-sphq-web-server03 and we have started the service which resolved the issue.We are analyzing more on this and will keep you posted regarding the updates.","Hello Team, This is to inform you that we received a site down alert for URLs https://preview.spendhq.com/login and https://secure.spendhq.com/login. We are analyzing the issue and will let you know the update. Please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bja1f,Cloud Engineer Level 1,Closed,1104421,Incident,20-09-2018 15:26,,"Hello Team,We are marking this case as close as we are tracking this ticket in case id: 01104660.###Hello Team,We haven't heard back from you. Please check and advise on whether we are good with cleaning them following EBS volumes.Resource ID vol-08525b5a8797e3935 Volume Name A3-DX-Failover-Test-Fix Type General Purpose SSD Owner Region us-east-1 Creation Date 2018-05-10 Size 500 GiB Age 125 days Resource ID vol-060c6db8b26f5244f Volume Name Type General Purpose SSD Owner spendhq-support@reancloud.com Region us-east-1 Creation Date 2018-06-07 Size 8 GiB Age 97 days Resource ID vol-78e4f4c5 Volume Name CloudEndure Volume u978v Type Standard Owner Region us-west-1 Creation Date 2016-05-25 Size 10 GiB Age 839 days###Hello Team,We haven't heard back from you, the following EBS volumes are neither attached to any running nor stopped instance. or notResource ID vol-08525b5a8797e3935 Volume Name A3-DX-Failover-Test-Fix Type General Purpose SSD Owner Region us-east-1 Creation Date 2018-05-10 Size 500 GiB Age 125 days Resource ID vol-060c6db8b26f5244f Volume Name Type General Purpose SSD Owner spendhq-support@reancloud.com Region us-east-1 Creation Date 2018-06-07 Size 8 GiB Age 97 days Resource ID vol-78e4f4c5 Volume Name CloudEndure Volume u978v Type Standard Owner Region us-west-1 Creation Date 2016-05-25 Size 10 GiB Age 839 days Please advise on whether we are good with cleaning them up. Thank you.###Hello Team,The following EBS volumes are neither to attached to running nor stopped instance.Resource ID vol-08525b5a8797e3935 Volume Name A3-DX-Failover-Test-Fix Type General Purpose SSD Owner Region us-east-1 Creation Date 2018-05-10 Size 500 GiB Age 125 days Resource ID vol-060c6db8b26f5244f Volume Name Type General Purpose SSD Owner spendhq-support@reancloud.com Region us-east-1 Creation Date 2018-06-07 Size 8 GiB Age 97 days Resource ID vol-78e4f4c5 Volume Name CloudEndure Volume u978v Type Standard Owner Region us-west-1 Creation Date 2016-05-25 Size 10 GiB Age 839 daysPlease advise on whether we are good with cleaning them up or not.Thank you.###Hello Team,We haven't heard back from you regarding the previously shared list of unused EBS volumes.Please review them and provide approval to clean them up. Thanks.###Hello SpendHQThe following EBS volumes are neither to attached to running nor stopped instance please review and get back to usResource ID vol-08525b5a8797e3935Volume Name A3-DX-Failover-Test-Fix Type General Purpose SSD Owner Region us-east-1 Creation Date 2018-05-10Size 500 GiBAge 125 days Resource ID vol-060c6db8b26f5244f Volume Name Type General Purpose SSDOwner spendhq-support@reancloud.com Region us-east-1Creation Date 2018-06-07Size 8 GiBAge 97 days Resource ID vol-78e4f4c5Volume Name CloudEndure Volume u978vType StandardOwner Region us-west-1Creation Date  2016-05-25Size 10 GiBAge 839 days","Stephen KimaniJunior Cloud Engineerreancloud.com---------- Forwarded message ----------From: <ms@reancloud.com>Date: Wed, Sep 12, 2018 at 5:04 PMSubject: [Managed Cloud: spendhq] Ununsed Ebs Volume checkTo: spendhq-support@reancloud.comREAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environmentby REAN Managed Cloud.The following *AWS::EC2::Volume* resources were affected:------------------------------   - *Violation:* EBS volume is not attached any stopped or running EC2   instance.   - *Recommendation:* Review the use of the unattached EBS volume.   Unattached EBS volume are chargeable.   - *Action taken:* None   - *Resource details:*   Resource ID Volume Name Type Owner Region Creation Date Size Age   vol-08525b5a8797e3935 A3-DX-Failover-Test-Fix General Purpose SSD   us-east-1 2018-05-10 500 GiB 125 days   vol-060c6db8b26f5244f General Purpose SSD spendhq-support@reancloud.com   us-east-1 2018-06-07 8 GiB 97 days   vol-78e4f4c5 CloudEndure Volume u978v Standard us-west-1 2016-05-25 10   GiB 839 days------------------------------Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Managed Cloud: spendhq] Ununsed Ebs Volume check,,12-09-2018 20:41,187,0,SpendHQ,"Hello Team,We are marking this case as close as we are tracking this ticket in case id: 01104660.","Hello Team,We haven't heard back from you. Please check and advise on whether we are good with cleaning them following EBS volumes.Resource ID vol-08525b5a8797e3935 Volume Name A3-DX-Failover-Test-Fix Type General Purpose SSD Owner Region us-east-1 Creation Date 2018-05-10 Size 500 GiB Age 125 days Resource ID vol-060c6db8b26f5244f Volume Name Type General Purpose SSD Owner spendhq-support@reancloud.com Region us-east-1 Creation Date 2018-06-07 Size 8 GiB Age 97 days Resource ID vol-78e4f4c5 Volume Name CloudEndure Volume u978v Type Standard Owner Region us-west-1 Creation Date 2016-05-25 Size 10 GiB Age 839 days","Hello Team,We haven't heard back from you, the following EBS volumes are neither attached to any running nor stopped instance. or notResource ID vol-08525b5a8797e3935 Volume Name A3-DX-Failover-Test-Fix Type General Purpose SSD Owner Region us-east-1 Creation Date 2018-05-10 Size 500 GiB Age 125 days Resource ID vol-060c6db8b26f5244f Volume Name Type General Purpose SSD Owner spendhq-support@reancloud.com Region us-east-1 Creation Date 2018-06-07 Size 8 GiB Age 97 days Resource ID vol-78e4f4c5 Volume Name CloudEndure Volume u978v Type Standard Owner Region us-west-1 Creation Date 2016-05-25 Size 10 GiB Age 839 days Please advise on whether we are good with cleaning them up. Thank you.","Hello Team,The following EBS volumes are neither to attached to running nor stopped instance.Resource ID vol-08525b5a8797e3935 Volume Name A3-DX-Failover-Test-Fix Type General Purpose SSD Owner Region us-east-1 Creation Date 2018-05-10 Size 500 GiB Age 125 days Resource ID vol-060c6db8b26f5244f Volume Name Type General Purpose SSD Owner spendhq-support@reancloud.com Region us-east-1 Creation Date 2018-06-07 Size 8 GiB Age 97 days Resource ID vol-78e4f4c5 Volume Name CloudEndure Volume u978v Type Standard Owner Region us-west-1 Creation Date 2016-05-25 Size 10 GiB Age 839 daysPlease advise on whether we are good with cleaning them up or not.Thank you.","Hello Team,We haven't heard back from you regarding the previously shared list of unused EBS volumes.Please review them and provide approval to clean them up. Thanks.",Hello SpendHQThe following EBS volumes are neither to attached to running nor stopped instance please review and get back to usResource ID vol-08525b5a8797e3935Volume Name A3-DX-Failover-Test-Fix Type General Purpose SSD Owner Region us-east-1 Creation Date 2018-05-10Size 500 GiBAge 125 days Resource ID vol-060c6db8b26f5244f Volume Name Type General Purpose SSDOwner spendhq-support@reancloud.com Region us-east-1Creation Date 2018-06-07Size 8 GiBAge 97 days Resource ID vol-78e4f4c5Volume Name CloudEndure Volume u978vType StandardOwner Region us-west-1Creation Date  2016-05-25Size 10 GiBAge 839 days,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001cJZ0t,Cloud Engineer Level 1,Closed,1105522,Incident,04-10-2018 22:32,,Another case exists for this hence we are closing this case.,"Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. During this maintenance window, your AWS Direct Connect services associated with this event may become unavailable.This maintenance is scheduled to avoid disrupting redundant connections at the same time.If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED,,04-10-2018 07:40,15,0,SpendHQ,Another case exists for this hence we are closing this case.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DBAe3,Cloud Engineer Level 1,Closed,1061866,Incident,10-06-2017 17:47,,"Hello Team,This is to inform you that the site down alert for the UR's https://preview.spendhq.com/login and https://secure.spendhq.com/login has recovered. The site is accessible now and serving well. The total downtime was 10 minutes 58 seconds. As discussed with Steven, we confirmed that it was part of maintenance. So we are marking this case as resolved.###Hello Team,This is to inform you that we received a site down alert for URLs https://preview.spendhq.com/login and https://secure.spendhq.com/login. We are analyzing the issue and will let you know the update. Please let us know if you are performing any activity from your end.","Sat, 10 Jun 2017 07:55:05 -0400Detected Error on SpendHQEstimated Downtime: 59 seconds https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: --------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Frankfurt DE, Sydney-C AU, Dallas-B US, California US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,10-06-2017 17:25,0,0,SpendHQ,"Hello Team,This is to inform you that the site down alert for the UR's https://preview.spendhq.com/login and https://secure.spendhq.com/login has recovered. The site is accessible now and serving well. The total downtime was 10 minutes 58 seconds. As discussed with Steven, we confirmed that it was part of maintenance. So we are marking this case as resolved.","Hello Team,This is to inform you that we received a site down alert for URLs https://preview.spendhq.com/login and https://secure.spendhq.com/login. We are analyzing the issue and will let you know the update. Please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001UnUQi,Cloud Engineer Level 1,Closed,1096410,Incident,17-04-2018 01:46,,"Hello David,Thanks for the update.At this time we are marking this case as resolved. Please revert back to us if you have any queries.###David Miller1:02 AM (41 minutes ago)to Manideep, REAN, Matthew Thank you, can my password be reset?###David MillerThank you, everything is working!###Hello David,We have granted the sudo access to your user dmiller. Please check from your end and let us know if you have any further queries.###Hello David,We have reset the password for your user on this server and shared the credentials with you. Please verify and let us know if you are facing any issues.Thanks & Regards,Anu Pappachan###ApprovedMatthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Group###Hello Matthew,Thanks for the Approval,We will work on this and will get back to you with updates.###Hello David,In order to work on this request could you please get an approval from Andrew/Matthew.###Hello David,We will work on this request and will get back to you with updates.","Rean,Please give my user (dmiller) sudo access to the following server:10.59.10.190Thank YouDavid MillerDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sudo Access,,16-04-2018 19:14,7,0,SpendHQ,"Hello David,Thanks for the update.At this time we are marking this case as resolved. Please revert back to us if you have any queries.","David Miller1:02 AM (41 minutes ago)to Manideep, REAN, Matthew Thank you, can my password be reset?","David MillerThank you, everything is working!","Hello David,We have granted the sudo access to your user dmiller. Please check from your end and let us know if you have any further queries.","Hello David,We have reset the password for your user on this server and shared the credentials with you. Please verify and let us know if you are facing any issues.Thanks & Regards,Anu Pappachan","ApprovedMatthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Group","Hello Matthew,Thanks for the Approval,We will work on this and will get back to you with updates.","Hello David,In order to work on this request could you please get an approval from Andrew/Matthew.","Hello David,We will work on this request and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001jlxo8,Cloud Engineer Level 1,Closed,1112336,Incident,22-02-2019 22:59,,"Hello Team,We haven't heard back from you.At this time we are marking the case as closed.Let us know if you have any queries.###Hello Team,This is a quick follow up.Please review the previous comment and let us know if you have any queries.###Hello Team,We have verified the ELB logs as well as the backend instance (PRD-WW1_122) logs. All the requests are coming from genuine IPs. We have verified the production server logs but did not find anything suspicious.We have attached the ELB logs for your reference. Please review and let us know if you have any question.###Hello Team, This is to inform you that at the time when we received site down alert, the site was loading fine from our end. We analyzed the issue and found the following on the external load balancer Secure-SpendHQ-ELB  : 1. Spike in latency graph with a maximum value of 72329.49 ms 2. We can see a sudden spike in Request Count and value has been reached to 255 3. We also found a sudden spike in active connection count and value was 346 On internal load balancer NewPreview-ELB also we noticed the same patterns of graphs, here are the details : 1. Sudden Spike in latency during the same time of site down alert 2. Spike in request count with a value of 255 requests We have also verified the CPU, Network IN/OUT metrics of the backend instances for the time and all looks normal. We further checked the website response time. Please See the below output.C02XH055JG5M:keys kbokdia$ for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://secure.spendhq.com/login -so /dev/null; done; HTTPCode=200 TotalTime=109.324724HTTPCode=200 TotalTime=18.737947HTTPCode=200 TotalTime=1.757676HTTPCode=200 TotalTime=1.757497HTTPCode=200 TotalTime=1.847585HTTPCode=200 TotalTime=1.672807The site actually not goes down and it taking much time to load. Due to high latency, our monitor tool timed out the ping and it triggers the site down alert. Please find the Cloudwatch Metrics graph in the attachment section for the reference. We are checking the logs from the instance level and will update you.###Hello Spendhq-Team,We are receiving multiple sites down alerts for URL: https://secure.spendhq.com/login. The alerts were resolved in 3 minutes and 4 minutes. The site is accessible now. We are checking from our end and will let you know the update.###Hello Team, This is to inform you that we received a site down alert for the following URL: https://secure.spendhq.com/login which later on recovered automatically after a minute. We are analyzing this and will be sharing more info. Thanks.","On 20/02/19, 11:35 AM, rean_ms@hitachivantara.com <rean_ms@hitachivantara.com> wrote:    Wed, 20 Feb 2019 01:05:39 -0500        Detected Error on SpendHQ Secure        Estimated Downtime: 2 minutes     https://www.wormly.com/edithost/hostid/50743        --------------------    Sensor Failure: HTTP    --------------------    Sensor reported error:    Operation timed out after 60001 milliseconds with 0 bytes received        Sensor parameters:    url: https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsecure.spendhq.com%2Flogin&amp;data=01%7C01%7Ckapil.bokdia%40hitachivantara.com%7C9e3055f7b34e422deb0808d696f97154%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=4iZ7X33OCNpSyE5zVL7%2FqbTw3FY1alnkGoKkF7R%2FQyo%3D&amp;reserved=0    expect: 200    wantedstring: All Rights Reserved    unwantedstring: Forbidden                Reported by node: New Jersey US    Confirmed by node(s): Dallas-C US, Sydney-C AU, Frankfurt DE, London UK",Detected Error on SpendHQ Secure,,20-02-2019 11:36,59,0,SpendHQ,"Hello Team,We haven't heard back from you.At this time we are marking the case as closed.Let us know if you have any queries.","Hello Team,This is a quick follow up.Please review the previous comment and let us know if you have any queries.","Hello Team,We have verified the ELB logs as well as the backend instance (PRD-WW1_122) logs. All the requests are coming from genuine IPs. We have verified the production server logs but did not find anything suspicious.We have attached the ELB logs for your reference. Please review and let us know if you have any question.","Hello Team, This is to inform you that at the time when we received site down alert, the site was loading fine from our end. We analyzed the issue and found the following on the external load balancer Secure-SpendHQ-ELB  : 1. Spike in latency graph with a maximum value of 72329.49 ms 2. We can see a sudden spike in Request Count and value has been reached to 255 3. We also found a sudden spike in active connection count and value was 346 On internal load balancer NewPreview-ELB also we noticed the same patterns of graphs, here are the details : 1. Sudden Spike in latency during the same time of site down alert 2. Spike in request count with a value of 255 requests We have also verified the CPU, Network IN/OUT metrics of the backend instances for the time and all looks normal. We further checked the website response time. Please See the below output.C02XH055JG5M:keys kbokdia$ for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://secure.spendhq.com/login -so /dev/null; done; HTTPCode=200 TotalTime=109.324724HTTPCode=200 TotalTime=18.737947HTTPCode=200 TotalTime=1.757676HTTPCode=200 TotalTime=1.757497HTTPCode=200 TotalTime=1.847585HTTPCode=200 TotalTime=1.672807The site actually not goes down and it taking much time to load. Due to high latency, our monitor tool timed out the ping and it triggers the site down alert. Please find the Cloudwatch Metrics graph in the attachment section for the reference. We are checking the logs from the instance level and will update you.","Hello Spendhq-Team,We are receiving multiple sites down alerts for URL: https://secure.spendhq.com/login. The alerts were resolved in 3 minutes and 4 minutes. The site is accessible now. We are checking from our end and will let you know the update.","Hello Team, This is to inform you that we received a site down alert for the following URL: https://secure.spendhq.com/login which later on recovered automatically after a minute. We are analyzing this and will be sharing more info. Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014m2aR,Cloud Engineer Level 1,Closed,1034255,Incident,28-11-2016 03:13,,"There is a sshrc script under /etc/ssh/ which will be executed whenever the user logs into the server and posts a message in slack(Internal message app).###Hi Matthew, Thanks for the update.At this time, we're marking this case as resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###We just have a bash script in an sshrc that is executed on login.If you need more information, then let me know.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>###Hello Mathew, This is to confirm that these authentications are being performed by REAN team.We have found two important vulnerabilities for wget and ntpd packages and hence we have executed an automated script which will get the version of these packages installed. If the version we are using is vulnerable we can plan for a patch update. We are in the process of generating the report, once the report is ready we will get back to you with more details. Please go through the below links for more details of the vulnerability.https://legalhackers.com/advisories/Wget-Exploit-ACL-bypass-RaceCond-CVE-2016-7098.htmlhttp://thehackernews.com/2016/11/ntp-server-vulnerability.html?m=1Can you please let us know how you are monitoring the SSH logins so that we will also monitor closely. Let us know if you have any queries.###Hello Matthew,We will look into this and will get back to you with updates.","We received notification that a user called reanro authenticated into our infrastructure boxes on AWS over 250 times in a very short space of time. Can you confirm this was REAN performing these authentications?Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Suspicious Login Attempts,,27-11-2016 22:27,5,0,SpendHQ,There is a sshrc script under /etc/ssh/ which will be executed whenever the user logs into the server and posts a message in slack(Internal message app).,"Hi Matthew, Thanks for the update.At this time, we're marking this case as resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","We just have a bash script in an sshrc that is executed on login.If you need more information, then let me know.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>","Hello Mathew, This is to confirm that these authentications are being performed by REAN team.We have found two important vulnerabilities for wget and ntpd packages and hence we have executed an automated script which will get the version of these packages installed. If the version we are using is vulnerable we can plan for a patch update. We are in the process of generating the report, once the report is ready we will get back to you with more details. Please go through the below links for more details of the vulnerability.https://legalhackers.com/advisories/Wget-Exploit-ACL-bypass-RaceCond-CVE-2016-7098.htmlhttp://thehackernews.com/2016/11/ntp-server-vulnerability.html?m=1Can you please let us know how you are monitoring the SSH logins so that we will also monitor closely. Let us know if you have any queries.","Hello Matthew,We will look into this and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Uuvad,Cloud Engineer Level 1,Closed,1101201,Incident,13-07-2018 10:51,,"Hello Andrew,We have increased the threshold value to 95%.The alert got resolved and returned to normal state. At this time we are marking this case closed and let us know if you have any queries.###Hello, can we increase the alert threshold on this server? Either 90% or 95%? One of the services is designed for high memory usage and is expected. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®###Hello Team, This is to inform you that the memory Utilization is still past the threshold value. The current value is 89.8%.Please review this and let us know in case of any queries.###Hello Team,We haven't heard back from you.Please review our previous comment, please let us know your thoughts regarding this and revert back to us in case of any queries.###Current disk usage is 89.8%###Hello Team,This is a gentle reminder.We have analyzed this alert and we could see that the memsql process consuming more memory in both servers. Please find the details memory usage details for both servers below. 1. spendhq-memsql-server3-2018-04-01( i-093eff6fae479397c) ------------------------------------------------------------------------------------- USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND memsql 14438 10.8 44.2 128918716 111248144 ? Sl May29 6222:07 /mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/data/memsqld.pid --user=memsql memsql 14443 10.7 44.1 128981756 111030352 ? Sl May29 6148:55 /mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/data/memsqld.pid --user=memsql memsql 96540 15.1 0.1 12877900 337472 ? Sl May07 13475:48 /var/lib/memsql-ops/lib/memsql-ops start --port 9000 root 587 0.0 0.0 131132 65232 ? Ss Apr01 0:58 /usr/lib/systemd/systemd-journald dd-agent 66834 0.2 0.0 5366184 53380 ? Ssl Jun22 56:22 /opt/datadog-agent/bin/agent/agent start -p /opt/datadog-agent/run/agent.pid memsql 14448 0.0 0.0 247236 46904 ? Ssl May29 0:00 /mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/data/memsqld.pid --user=memsql memsql 14447 0.0 0.0 247216 46900 ? Ssl May29 0:00 /mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/data/memsqld.pid --user=memsql 2. SpendHQ-memsql-server2-2018-04-01(i-0382b753fdc5a21bd) ------------------------------------------------------------------------------------------- USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND memsql 14045 10.8 44.2 129102548 111288004 ? Sl May29 6242:11 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsql memsql 14050 11.0 44.2 129251172 111204600 ? Sl May29 6322:52 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/data/memsqld.pid --user=memsql memsql 96752 15.0 0.1 12885828 333592 ? Sl May07 13400:13 /var/lib/memsql-ops/lib/memsql-ops start --port 9000 root 593 0.0 0.0 130956 66360 ? Ss Apr01 0:59 /usr/lib/systemd/systemd-journald dd-agent 66299 0.2 0.0 5349792 53948 ? Ssl Jun22 56:13 /opt/datadog-agent/bin/agent/agent start -p /opt/datadog-agent/run/agent.pid memsql 14055 0.0 0.0 247236 46904 ? Ssl May29 0:00 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsql memsql 14054 0.0 0.0 247232 46900 ? Ssl May29 0:00 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/data Kindly review this details and please let us know your thoughts regarding this and revert back to us in case of any queries.###Hello Team,This is a gentle reminder.Please review our previous comment and revert us back in case of any query.###Hello Team,We have analyzed this alert and we could see that the memsql process consuming more memory in both servers. Please find the details memory usage details for both servers below.1. spendhq-memsql-server3-2018-04-01( i-093eff6fae479397c)-------------------------------------------------------------------------------------USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDmemsql    14438 10.8 44.2 128918716 111248144 ? Sl   May29 6222:07 /mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/data/memsqld.pid --user=memsqlmemsql    14443 10.7 44.1 128981756 111030352 ? Sl   May29 6148:55 /mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/data/memsqld.pid --user=memsqlmemsql    96540 15.1  0.1 12877900 337472 ?     Sl   May07 13475:48 /var/lib/memsql-ops/lib/memsql-ops start --port 9000root        587  0.0  0.0 131132 65232 ?        Ss   Apr01   0:58 /usr/lib/systemd/systemd-journalddd-agent  66834  0.2  0.0 5366184 53380 ?       Ssl  Jun22  56:22 /opt/datadog-agent/bin/agent/agent start -p /opt/datadog-agent/run/agent.pidmemsql    14448  0.0  0.0 247236 46904 ?        Ssl  May29   0:00 /mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/data/memsqld.pid --user=memsqlmemsql    14447  0.0  0.0 247216 46900 ?        Ssl  May29   0:00 /mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/data/memsqld.pid --user=memsql2. SpendHQ-memsql-server2-2018-04-01(i-0382b753fdc5a21bd)-------------------------------------------------------------------------------------------USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDmemsql    14045 10.8 44.2 129102548 111288004 ? Sl   May29 6242:11 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsqlmemsql    14050 11.0 44.2 129251172 111204600 ? Sl   May29 6322:52 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/data/memsqld.pid --user=memsqlmemsql    96752 15.0  0.1 12885828 333592 ?     Sl   May07 13400:13 /var/lib/memsql-ops/lib/memsql-ops start --port 9000root        593  0.0  0.0 130956 66360 ?        Ss   Apr01   0:59 /usr/lib/systemd/systemd-journalddd-agent  66299  0.2  0.0 5349792 53948 ?       Ssl  Jun22  56:13 /opt/datadog-agent/bin/agent/agent start -p /opt/datadog-agent/run/agent.pidmemsql    14055  0.0  0.0 247236 46904 ?        Ssl  May29   0:00 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsqlmemsql    14054  0.0  0.0 247232 46900 ?        Ssl  May29   0:00 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/dataKindly review this details and please let us know your thoughts regarding this and revert back to us in case of any queries.###Hello Team, This is to inform you that we have received an alert regarding high memory Utilization on spendhq-memsql-server3-2018-04-01 and spendhq-memsql-server2-2018-04-01 has exceeded the threshold value of 85 to 89.8 and 85% to 89.87%.Resource Details:- 1)Instance ID: i-093eff6fae479397cInstance Name: spendhq-memsql-server3-2018-04-01Private IP: 10.59.100.2302)Instance ID: i-0382b753fdc5a21bdInstance Name: SpendHQ-memsql-server2-2018-04-01Private IP: 10.59.100.171We are analyzing the alerts from our end and will get back to you with the updates.","--------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Fri, Jun 22, 2018 at 2:36 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Memory UtilizationAlert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 -To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host -spendhq-memsql-server3-2018-04-01 - 10.59.100.230 -Detected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1529658407000&group=host%3Ai-093eff6fae479397c&from_ts=1529654807000>avg(last_5m):( avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 85The monitor was last triggered at Fri Jun 22 2018 09:06:57 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-093eff6fae479397c>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-093eff6fae479397c<https://app.datadoghq.com/infrastructure?filter=i-093eff6fae479397c>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1529658417000&tags=host%3Ai-093eff6fae479397c&from_ts=1529657517000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4452598521678690756>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 - and spendhq-memsql-server2-2018-04-01,,08-07-2018 15:28,115,0,SpendHQ,"Hello Andrew,We have increased the threshold value to 95%.The alert got resolved and returned to normal state. At this time we are marking this case closed and let us know if you have any queries.","Hello, can we increase the alert threshold on this server? Either 90% or 95%? One of the services is designed for high memory usage and is expected. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®","Hello Team, This is to inform you that the memory Utilization is still past the threshold value. The current value is 89.8%.Please review this and let us know in case of any queries.","Hello Team,We haven't heard back from you.Please review our previous comment, please let us know your thoughts regarding this and revert back to us in case of any queries.",Current disk usage is 89.8%,"Hello Team,This is a gentle reminder.We have analyzed this alert and we could see that the memsql process consuming more memory in both servers. Please find the details memory usage details for both servers below. 1. spendhq-memsql-server3-2018-04-01( i-093eff6fae479397c) ------------------------------------------------------------------------------------- USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND memsql 14438 10.8 44.2 128918716 111248144 ? Sl May29 6222:07 /mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/data/memsqld.pid --user=memsql memsql 14443 10.7 44.1 128981756 111030352 ? Sl May29 6148:55 /mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/data/memsqld.pid --user=memsql memsql 96540 15.1 0.1 12877900 337472 ? Sl May07 13475:48 /var/lib/memsql-ops/lib/memsql-ops start --port 9000 root 587 0.0 0.0 131132 65232 ? Ss Apr01 0:58 /usr/lib/systemd/systemd-journald dd-agent 66834 0.2 0.0 5366184 53380 ? Ssl Jun22 56:22 /opt/datadog-agent/bin/agent/agent start -p /opt/datadog-agent/run/agent.pid memsql 14448 0.0 0.0 247236 46904 ? Ssl May29 0:00 /mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/data/memsqld.pid --user=memsql memsql 14447 0.0 0.0 247216 46900 ? Ssl May29 0:00 /mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/data/memsqld.pid --user=memsql 2. SpendHQ-memsql-server2-2018-04-01(i-0382b753fdc5a21bd) ------------------------------------------------------------------------------------------- USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND memsql 14045 10.8 44.2 129102548 111288004 ? Sl May29 6242:11 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsql memsql 14050 11.0 44.2 129251172 111204600 ? Sl May29 6322:52 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/data/memsqld.pid --user=memsql memsql 96752 15.0 0.1 12885828 333592 ? Sl May07 13400:13 /var/lib/memsql-ops/lib/memsql-ops start --port 9000 root 593 0.0 0.0 130956 66360 ? Ss Apr01 0:59 /usr/lib/systemd/systemd-journald dd-agent 66299 0.2 0.0 5349792 53948 ? Ssl Jun22 56:13 /opt/datadog-agent/bin/agent/agent start -p /opt/datadog-agent/run/agent.pid memsql 14055 0.0 0.0 247236 46904 ? Ssl May29 0:00 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsql memsql 14054 0.0 0.0 247232 46900 ? Ssl May29 0:00 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/data Kindly review this details and please let us know your thoughts regarding this and revert back to us in case of any queries.","Hello Team,This is a gentle reminder.Please review our previous comment and revert us back in case of any query.","Hello Team,We have analyzed this alert and we could see that the memsql process consuming more memory in both servers. Please find the details memory usage details for both servers below.1. spendhq-memsql-server3-2018-04-01( i-093eff6fae479397c)-------------------------------------------------------------------------------------USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDmemsql    14438 10.8 44.2 128918716 111248144 ? Sl   May29 6222:07 /mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/data/memsqld.pid --user=memsqlmemsql    14443 10.7 44.1 128981756 111030352 ? Sl   May29 6148:55 /mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/data/memsqld.pid --user=memsqlmemsql    96540 15.1  0.1 12877900 337472 ?     Sl   May07 13475:48 /var/lib/memsql-ops/lib/memsql-ops start --port 9000root        587  0.0  0.0 131132 65232 ?        Ss   Apr01   0:58 /usr/lib/systemd/systemd-journalddd-agent  66834  0.2  0.0 5366184 53380 ?       Ssl  Jun22  56:22 /opt/datadog-agent/bin/agent/agent start -p /opt/datadog-agent/run/agent.pidmemsql    14448  0.0  0.0 247236 46904 ?        Ssl  May29   0:00 /mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3307-MI15998ea9/data/memsqld.pid --user=memsqlmemsql    14447  0.0  0.0 247216 46900 ?        Ssl  May29   0:00 /mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI70ae2297/data/memsqld.pid --user=memsql2. SpendHQ-memsql-server2-2018-04-01(i-0382b753fdc5a21bd)-------------------------------------------------------------------------------------------USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDmemsql    14045 10.8 44.2 129102548 111288004 ? Sl   May29 6242:11 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsqlmemsql    14050 11.0 44.2 129251172 111204600 ? Sl   May29 6322:52 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/data/memsqld.pid --user=memsqlmemsql    96752 15.0  0.1 12885828 333592 ?     Sl   May07 13400:13 /var/lib/memsql-ops/lib/memsql-ops start --port 9000root        593  0.0  0.0 130956 66360 ?        Ss   Apr01   0:59 /usr/lib/systemd/systemd-journalddd-agent  66299  0.2  0.0 5349792 53948 ?       Ssl  Jun22  56:13 /opt/datadog-agent/bin/agent/agent start -p /opt/datadog-agent/run/agent.pidmemsql    14055  0.0  0.0 247236 46904 ?        Ssl  May29   0:00 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsqlmemsql    14054  0.0  0.0 247232 46900 ?        Ssl  May29   0:00 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/dataKindly review this details and please let us know your thoughts regarding this and revert back to us in case of any queries.","Hello Team, This is to inform you that we have received an alert regarding high memory Utilization on spendhq-memsql-server3-2018-04-01 and spendhq-memsql-server2-2018-04-01 has exceeded the threshold value of 85 to 89.8 and 85% to 89.87%.Resource Details:- 1)Instance ID: i-093eff6fae479397cInstance Name: spendhq-memsql-server3-2018-04-01Private IP: 10.59.100.2302)Instance ID: i-0382b753fdc5a21bdInstance Name: SpendHQ-memsql-server2-2018-04-01Private IP: 10.59.100.171We are analyzing the alerts from our end and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Dlx6o,Cloud Engineer Level 1,Closed,1064333,Incident,23-06-2017 01:42,,"Hi Steven,Thanks for the update,  we will keep monitoring the alert.At this time we are marking this case as resolved, please let us know if you have any further queries.###Steven Updated that.We are writing files into /tmp for a production related feature. There is a cron job that is supposed to clean up after a certain time. That partition can fill up until we make a code change. We are in the process of validating that code change. Do keep monitoring of it if the server does come offline because of low disk space.###Hello Team,We are getting multiple alerts regarding high disk usage for  prod-sphq-db-server05 - 10.59.10.135. We have created a report for the alerts we received for past 2 weeks. By analyzing the details we could see /tmp directory is filling fast and which is the reason behind this repeating disk usage alerts. To resolve the issue we can create a separate partition for /tmp or set up any automated clean up of files when the disk size reaches 90%. Please review the sheet attached to the attachment section and let us know your thought regarding this.",We are getting multiple disk usage alert for root volume in prod-sphq-db-server05 - 10.59.10.135.,SpendHQ Disk_Usage for root volume in prod-sphq-db-server05 - 10.59.10.135,,22-06-2017 23:59,2,0,SpendHQ,"Hi Steven,Thanks for the update,  we will keep monitoring the alert.At this time we are marking this case as resolved, please let us know if you have any further queries.",Steven Updated that.We are writing files into /tmp for a production related feature. There is a cron job that is supposed to clean up after a certain time. That partition can fill up until we make a code change. We are in the process of validating that code change. Do keep monitoring of it if the server does come offline because of low disk space.,"Hello Team,We are getting multiple alerts regarding high disk usage for  prod-sphq-db-server05 - 10.59.10.135. We have created a report for the alerts we received for past 2 weeks. By analyzing the details we could see /tmp directory is filling fast and which is the reason behind this repeating disk usage alerts. To resolve the issue we can create a separate partition for /tmp or set up any automated clean up of files when the disk size reaches 90%. Please review the sheet attached to the attachment section and let us know your thought regarding this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hQIO5,Cloud Engineer Level 1,Closed,1110080,Incident,03-01-2019 07:53,,"Hello Team,This is to inform you that we are closing this case from our end since the alert got recovered. If you feel this is still in trouble, Please don't hesitate to contact back. Thank you.###Hello Team,This is a quick follow up.Please review our shared analysis and let us know if you have any question on the same.Thanks,###Hello Team,This is to inform you that the alert regarding high Network OUT on host - sphq-db4-20180830 has recovered and it lased for about 4 hours.Please have a look at our shared analysis and let us know your thoughts on the same.Thanks,###Hello Team,We have received an alert regarding high Network OUT on host - sphq-db4-20180830 which has yet recovered.Currently the alert has crossed the set threshold of 1.1Gb/min and is currently at a value of 2.45 Gb/min. Please see below the connections summary at the time of checking:  1 established)     97 ESTABLISHED      1 Foreign     18 LISTEN     93 TIME_WAITBelow are TIME_WAIT connection summary:tcp        0      0 10.59.10.210:32992      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33116      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33100      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33136      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33104      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33272      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33122      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33216      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:32956      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33018      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33066      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:42568      10.59.10.26:8603        TIME_WAIT   -   Resource Details:-----------------------Instance ID:	i-082d412700b276f44	Instance Name: SPHQ-DB4-20180830	Instance Type: r4.8xlarge	Account: SpendHQ	Availability Zone:	us-east-1b	Region:	us-east-1 Subnet:	subnet-0fdde924	VPC: vpc-76df7212 Private IP Address: 10.59.10.210Please review these details and let us know if you have any questions.Thanks","[image: Datadog][Triggered] [SpendHQ] - High Network OUT on host - sphq-db4-20180830 -10.59.10.210 -High Network OUT on the instance. Please check the list open TCPConnections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024199?to_ts=1546276649000&group=host%3Ai-082d412700b276f44&from_ts=1546269449000>*aws.ec2.network_out* over *datadog_monitor:on,host:i-082d412700b276f44*was *> 1100000000.0* at all times during the *last 30m*.The monitor was last triggered at Mon Dec 31 2018 17:17:39 UTC (*4 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024199?group=host%3Ai-082d412700b276f44>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024199/edit>] · [Viewi-082d412700b276f44<https://app.datadoghq.com/infrastructure?filter=i-082d412700b276f44>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1546276779000&tags=host%3Ai-082d412700b276f44&from_ts=1546275759000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4731406403425086008>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - sphq-db4-20180830 - 10.59.10.210 -,,31-12-2018 23:07,57,0,SpendHQ,"Hello Team,This is to inform you that we are closing this case from our end since the alert got recovered. If you feel this is still in trouble, Please don't hesitate to contact back. Thank you.","Hello Team,This is a quick follow up.Please review our shared analysis and let us know if you have any question on the same.Thanks,","Hello Team,This is to inform you that the alert regarding high Network OUT on host - sphq-db4-20180830 has recovered and it lased for about 4 hours.Please have a look at our shared analysis and let us know your thoughts on the same.Thanks,","Hello Team,We have received an alert regarding high Network OUT on host - sphq-db4-20180830 which has yet recovered.Currently the alert has crossed the set threshold of 1.1Gb/min and is currently at a value of 2.45 Gb/min. Please see below the connections summary at the time of checking:  1 established)     97 ESTABLISHED      1 Foreign     18 LISTEN     93 TIME_WAITBelow are TIME_WAIT connection summary:tcp        0      0 10.59.10.210:32992      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33116      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33100      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33136      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33104      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33272      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33122      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33216      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:32956      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33018      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:33066      10.59.10.210:8601       TIME_WAIT   -                   tcp        0      0 10.59.10.210:42568      10.59.10.26:8603        TIME_WAIT   -   Resource Details:-----------------------Instance ID:	i-082d412700b276f44	Instance Name: SPHQ-DB4-20180830	Instance Type: r4.8xlarge	Account: SpendHQ	Availability Zone:	us-east-1b	Region:	us-east-1 Subnet:	subnet-0fdde924	VPC: vpc-76df7212 Private IP Address: 10.59.10.210Please review these details and let us know if you have any questions.Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015VfzZ,Cloud Engineer Level 1,Closed,1038895,Incident,20-12-2016 09:48,,"Andrew has replied to close the case###Hello Andrew,Thank you for your response. We are closing this ticket.###Hi Team,This is a gentle reminder since we haven't heard back from you regarding this case. Please review and let us know if you have any queries.###Hello Team,Please find the RCA report for the issue in the attachments.Also, Do let us know if you have any more queries regarding this.###We have edited the RCA based on Sanket suggestions and assigned it to Sanket for final review.###Hi Andrew,For our recent outage, we have received a response back from AWS where they confirm about network connectivity issues at their end at the time of the issue.This resulted into the outage. Our team is working on adding this information to RCA document. We will send you RCA soon.Thanks,Sanket DangiBegin Forwarded Message:From: 'no-reply-aws@amazon.com' via REAN Managed Services <ms@reancloud.com>Subject: RE: [Case 1993328101] Call: iSCSI dismounted for sdaDate: 17 December 2016 16:26To: spendhq@reancloudsolutions.com <spendhq@reancloudsolutions.com>Cc: ms@reancloud.com <ms@reancloud.com>Hello,At the mentioned time we faced a network event that severed the network connectivity momentarily, and I could see a packet loss increase between the affected instance (i-1426f28b) and the Direct Connect. So, as I said before the Direct Connect it self was healthy and ok.Once connectivity was restored, the instance connectivity to the direct connect recovered since it was not directly impacted. Unfortunately, due to the sensitive nature of our infrastructure this is the most information I can provide at this point.As you are aware, hardware failures are very hard to predict as electronics have a life-cycle, but as we have reliable and fault-tolerant systems, you always have the flexibility of switching the underlying host if any issue arises. In most cases, stop-starting the instance will move the instance to new and healthy hardware.AWS works hard to minimize failures, but our infrastructure is not immune and unfortunately sometimes failures do occur.We will continue to monitor this closely, but please, let me know if you have any more issues and I will escalate this as a priority. If this issue happen again, could I ask you to provide a traceroute to the endpoint where the connection is failing if that is the case.Hope I answered your question. If you have any other question regarding this issue, please let me know.Best regards,George F.Amazon Web ServicesCheck out the AWS Support Knowledge Center, a knowledge base of articles and videos that answer customer questions about AWS services: https://aws.amazon.com/premiumsupport/knowledge-center/?icmpid=support_email_categoryWe value your feedback. Please rate my response using the link below.===================================================To contact us again about this case, please return to the AWS Support Center using the following URL:https://console.aws.amazon.com/support/home#/case/?displayId=1993328101&language=en(If you are connecting by federation, log in before following the link.)*Please note: this e-mail was sent from an address that cannot accept incoming e-mail. Please use the link above if you need to contact us again about this same issue.====================================================================Learn to work with the AWS Cloud. Get started with free online videos and self-paced labs athttp://aws.amazon.com/training/====================================================================Amazon Web Services, Inc. is an affiliate of Amazon.com, Inc. Amazon.com is a registered trademark of Amazon.com, Inc. or its affiliates.###Hello Andrew,On further analysis on this issue, we could see that instance lost connection to ISCSI. In order to find the reason behind it, we have raised a support ticket with AWS.AWS team confirmed that it was not direct connect issue and also there was no problem with the underlying hardware.Support then opened a ticket with their networking team to check if there were anything abnormal at that time.So we are waiting for a reply from them.As soon as we hear back from AWS support we will get back to you with the root cause.###We  tried to get on a call with AWS support and at that time we received an email from AWS support team that they reached the network operations team, and they are still investigating to give us an answer. They are  following the evolution of the troubleshooting, soon as we have an answer they  will update us.We asked support to provide an update ASAP.###We got on a call with AWS to check on network outage issue. AWS support team told that they will reach out to us after performing the analysis.###We have created the RCA and shared with internally for Review.###Hi Andrew,Thanks for the detailed note. We will share the RCA with details of iscsi connection failure.###Below is a summary of events along with next step itemsOn Wednesday, December 14th 2016, a SpendHQ client submitted a support email regarding difficulty exporting data from SpendHQ. Upon investigation, the SpendHQ team identified an error message on 10.59.100.125 in /var/log/messages indicating the following:Kernel reported iSCSI connection 1:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)At 10:49am eastern, the SpendHQ team submitted a ticket to REAN requesting assistance (case 01038895).At 11:15am eastern, the SpendHQ team escalated internally. Upon internal diagnostics, it was found that data could not be written to 10.59.100.125:/var/www/vhosts/files.spendhq.com (directory mounted to the Nimble at /dev/sda) and determined that the root cause was related to the iscsi connection to the Nimble device.An attempt to unmount and remount /dev/sda was performed, but failed due to the device being busy. At this time, /dev/sda is still mounted.At 11:26am, SpendHQ reached out to Andromeda3 (A3) for assistance and at 11:38am, was in contact with Chris Veillette from A3. A3 was able to confirm that traffic between the server and Nimble was being observed. The SpendHQ team then requested A3 to clone the SHQ1Files01 volume and name SHQFiles01a. The SHQFiles01a volume was then mounted from /dev/sdb to /var/www/vhosts/files1.spendhq.com. Testing was performed to ensure that data could be written to this new mount point. Next, the SpendHQ team began to remap the NFS share. Due to troubleshooting and testing, the new NFS share export is located at /export_new/files.spendhq.comAt 12:30pm, REAN escalated the issues to a P1 and began assisting. Once the mount point and NFS share point were working, it was determined that the NFS client on 10.59.100.118 needed to be changed. Unfortunately, the mount point was “busy” and could not be changed. At 12:55pm, SpendHQ requested that REAN create a snapshot of 10.59.100.118 and a restart of the server be performed. After the server rebooted, SpendHQ changed /etc/fstab from to 10.59.100.125:/exports/files.spendhq.com /var/www/vhosts/files.spendhq.com 10.59.100.125:/exports_new/files.spendhq.com /var/www/vhosts/files.spendhq.com and a mount -a was performed. After the mount point was corrected, apache was restarted and regression tests were performed to confirm the application was working. At 1:06pm, SpendHQ confirmed the application was working.The following is an overview of the problem path•	Client attempts to generate an excel export on web server (10.59.100.118)•	Export is written to a temporary file – file path is read only and cannot be written to•	Temporary path is an NFS share located on File1 server (10.59.100.125)•	Folder shared is a mount pointing to the Nimble•	Server lost connection to the iscsi according to the logsNext steps•	Root cause is needed on why iscsi connection failed – REAN investigate•	Monitoring is needed to proactively identify before clients raise issue – REAN provide recommendations•	Architecture should be re-evaluated and failure points should be identified – SHQ team•	Fault tolerance and/or rapid failover needs to be implemented - TBD###[Internal]Sanket had a call with spendHQ team and the issue was they cloned one of their nimble storage and added a new one. Post that, the original one got into read-only mode. This volume which got into read-only mode is shared as NFS volume on another instance. So, everything got into read-only mode.They picked up the new volume and made that as the production volume. Modified NFS configuration to the new volume and everything came back to normal. Andrew will send a note on this and based on that we will further discuss on how and why this happened at the first place.###Hi Team,We will look into the issue and let you know the update.","Hello REAN, We noticed that the iSCSI connection was disconnected around 12/14/2016 6:18 AM EST. Here is what /var/log/messages said in the attached text file. /dev/sda on /var/www/vhosts/files.spendhq.com type ext4 (rw) Can you take a look as to why this happened? Also is there a way to get alerts for incidents like this? Because the mount was disconnected, it interrupted our application logging, file uploads and report generation since the sda device was our dedicated file server.",iSCSI dismounted for sda,,14-12-2016 21:30,132,0,SpendHQ,Andrew has replied to close the case,"Hello Andrew,Thank you for your response. We are closing this ticket.","Hi Team,This is a gentle reminder since we haven't heard back from you regarding this case. Please review and let us know if you have any queries.","Hello Team,Please find the RCA report for the issue in the attachments.Also, Do let us know if you have any more queries regarding this.",We have edited the RCA based on Sanket suggestions and assigned it to Sanket for final review.,"Hi Andrew,For our recent outage, we have received a response back from AWS where they confirm about network connectivity issues at their end at the time of the issue.This resulted into the outage. Our team is working on adding this information to RCA document. We will send you RCA soon.Thanks,Sanket DangiBegin Forwarded Message:From: 'no-reply-aws@amazon.com' via REAN Managed Services <ms@reancloud.com>Subject: RE: [Case 1993328101] Call: iSCSI dismounted for sdaDate: 17 December 2016 16:26To: spendhq@reancloudsolutions.com <spendhq@reancloudsolutions.com>Cc: ms@reancloud.com <ms@reancloud.com>Hello,At the mentioned time we faced a network event that severed the network connectivity momentarily, and I could see a packet loss increase between the affected instance (i-1426f28b) and the Direct Connect. So, as I said before the Direct Connect it self was healthy and ok.Once connectivity was restored, the instance connectivity to the direct connect recovered since it was not directly impacted. Unfortunately, due to the sensitive nature of our infrastructure this is the most information I can provide at this point.As you are aware, hardware failures are very hard to predict as electronics have a life-cycle, but as we have reliable and fault-tolerant systems, you always have the flexibility of switching the underlying host if any issue arises. In most cases, stop-starting the instance will move the instance to new and healthy hardware.AWS works hard to minimize failures, but our infrastructure is not immune and unfortunately sometimes failures do occur.We will continue to monitor this closely, but please, let me know if you have any more issues and I will escalate this as a priority. If this issue happen again, could I ask you to provide a traceroute to the endpoint where the connection is failing if that is the case.Hope I answered your question. If you have any other question regarding this issue, please let me know.Best regards,George F.Amazon Web ServicesCheck out the AWS Support Knowledge Center, a knowledge base of articles and videos that answer customer questions about AWS services: https://aws.amazon.com/premiumsupport/knowledge-center/?icmpid=support_email_categoryWe value your feedback. Please rate my response using the link below.===================================================To contact us again about this case, please return to the AWS Support Center using the following URL:https://console.aws.amazon.com/support/home#/case/?displayId=1993328101&language=en(If you are connecting by federation, log in before following the link.)*Please note: this e-mail was sent from an address that cannot accept incoming e-mail. Please use the link above if you need to contact us again about this same issue.====================================================================Learn to work with the AWS Cloud. Get started with free online videos and self-paced labs athttp://aws.amazon.com/training/====================================================================Amazon Web Services, Inc. is an affiliate of Amazon.com, Inc. Amazon.com is a registered trademark of Amazon.com, Inc. or its affiliates.","Hello Andrew,On further analysis on this issue, we could see that instance lost connection to ISCSI. In order to find the reason behind it, we have raised a support ticket with AWS.AWS team confirmed that it was not direct connect issue and also there was no problem with the underlying hardware.Support then opened a ticket with their networking team to check if there were anything abnormal at that time.So we are waiting for a reply from them.As soon as we hear back from AWS support we will get back to you with the root cause.","We  tried to get on a call with AWS support and at that time we received an email from AWS support team that they reached the network operations team, and they are still investigating to give us an answer. They are  following the evolution of the troubleshooting, soon as we have an answer they  will update us.We asked support to provide an update ASAP.",We got on a call with AWS to check on network outage issue. AWS support team told that they will reach out to us after performing the analysis.,We have created the RCA and shared with internally for Review.,"Hi Andrew,Thanks for the detailed note. We will share the RCA with details of iscsi connection failure.","Below is a summary of events along with next step itemsOn Wednesday, December 14th 2016, a SpendHQ client submitted a support email regarding difficulty exporting data from SpendHQ. Upon investigation, the SpendHQ team identified an error message on 10.59.100.125 in /var/log/messages indicating the following:Kernel reported iSCSI connection 1:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)At 10:49am eastern, the SpendHQ team submitted a ticket to REAN requesting assistance (case 01038895).At 11:15am eastern, the SpendHQ team escalated internally. Upon internal diagnostics, it was found that data could not be written to 10.59.100.125:/var/www/vhosts/files.spendhq.com (directory mounted to the Nimble at /dev/sda) and determined that the root cause was related to the iscsi connection to the Nimble device.An attempt to unmount and remount /dev/sda was performed, but failed due to the device being busy. At this time, /dev/sda is still mounted.At 11:26am, SpendHQ reached out to Andromeda3 (A3) for assistance and at 11:38am, was in contact with Chris Veillette from A3. A3 was able to confirm that traffic between the server and Nimble was being observed. The SpendHQ team then requested A3 to clone the SHQ1Files01 volume and name SHQFiles01a. The SHQFiles01a volume was then mounted from /dev/sdb to /var/www/vhosts/files1.spendhq.com. Testing was performed to ensure that data could be written to this new mount point. Next, the SpendHQ team began to remap the NFS share. Due to troubleshooting and testing, the new NFS share export is located at /export_new/files.spendhq.comAt 12:30pm, REAN escalated the issues to a P1 and began assisting. Once the mount point and NFS share point were working, it was determined that the NFS client on 10.59.100.118 needed to be changed. Unfortunately, the mount point was “busy” and could not be changed. At 12:55pm, SpendHQ requested that REAN create a snapshot of 10.59.100.118 and a restart of the server be performed. After the server rebooted, SpendHQ changed /etc/fstab from to 10.59.100.125:/exports/files.spendhq.com /var/www/vhosts/files.spendhq.com 10.59.100.125:/exports_new/files.spendhq.com /var/www/vhosts/files.spendhq.com and a mount -a was performed. After the mount point was corrected, apache was restarted and regression tests were performed to confirm the application was working. At 1:06pm, SpendHQ confirmed the application was working.The following is an overview of the problem path•	Client attempts to generate an excel export on web server (10.59.100.118)•	Export is written to a temporary file – file path is read only and cannot be written to•	Temporary path is an NFS share located on File1 server (10.59.100.125)•	Folder shared is a mount pointing to the Nimble•	Server lost connection to the iscsi according to the logsNext steps•	Root cause is needed on why iscsi connection failed – REAN investigate•	Monitoring is needed to proactively identify before clients raise issue – REAN provide recommendations•	Architecture should be re-evaluated and failure points should be identified – SHQ team•	Fault tolerance and/or rapid failover needs to be implemented - TBD","[Internal]Sanket had a call with spendHQ team and the issue was they cloned one of their nimble storage and added a new one. Post that, the original one got into read-only mode. This volume which got into read-only mode is shared as NFS volume on another instance. So, everything got into read-only mode.They picked up the new volume and made that as the production volume. Modified NFS configuration to the new volume and everything came back to normal. Andrew will send a note on this and based on that we will further discuss on how and why this happened at the first place.","Hi Team,We will look into the issue and let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001Fm4vG,Cloud Engineer Level 1,Closed,1078135,Incident,09-09-2017 15:46,,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you've any queries, we want to hear from you! Please re-open this case for continued support.###Hello Team,This is to inform you that we got a MySQL process down alert for the machine PRD-DB. The alert got resolved and we have confirmed that the process is up and running now.The violation lasted for 4 minutes.Resource Details:Instance Name: PRD-DBPrivate IP: 10.59.10.135 Instance type: r3.8xlargeOn further analysis at the instance level, we could see that the sng was logged in the machine at the time of the alert. And the bash history seems like the user is doing some activity related to this process. Please find the details below.sudo crontab -eps aux | grep postgressudo /etc/init.d/,ysql-ib startsudo /etc/init.d/mysql-ib startsudo /etc/init.d/mysqld-ib startsudo /etc/init.d/infobright-iee-postgres statussudo /etc/init.d/infobright-iee-postgres startWe tried to reach Steven Ng over a phone call but he was not available, Please let us know if you are doing any activity from your side.","[Triggered on {host:10.59.10.135,process:mysql}] [SpendHQ] MySQL Process is down - prd-db  - 10.59.10.135 - db  MySQL Process is down @support@reancloud.com     @support@reancloud.comPROCS CRITICAL: 0 processes found for mysqlThis alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2014430?group=host%3A10.59.10.135%2Cprocess%3Amysql · Edit Monitor: https://app.datadoghq.com/monitors#2014430/edit · Event URL: https://app.datadoghq.com/event/event?id=4037054141048496380 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","[Monitor Alert] Triggered: [SpendHQ] MySQL Process is down - prd-db - 10.59.10.135 - db on process:mysql,host:10.59.10.135",,08-09-2017 22:30,17,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you've any queries, we want to hear from you! Please re-open this case for continued support.","Hello Team,This is to inform you that we got a MySQL process down alert for the machine PRD-DB. The alert got resolved and we have confirmed that the process is up and running now.The violation lasted for 4 minutes.Resource Details:Instance Name: PRD-DBPrivate IP: 10.59.10.135 Instance type: r3.8xlargeOn further analysis at the instance level, we could see that the sng was logged in the machine at the time of the alert. And the bash history seems like the user is doing some activity related to this process. Please find the details below.sudo crontab -eps aux | grep postgressudo /etc/init.d/,ysql-ib startsudo /etc/init.d/mysql-ib startsudo /etc/init.d/mysqld-ib startsudo /etc/init.d/infobright-iee-postgres statussudo /etc/init.d/infobright-iee-postgres startWe tried to reach Steven Ng over a phone call but he was not available, Please let us know if you are doing any activity from your side.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001cI255,Cloud Engineer Level 1,Closed,1105327,Incident,03-10-2018 04:56,,"Hello Team, We are closing the ticket as no action was performed from your end. However, if the ticket is closed erroneously, feel free to reopen the ticket. You can always to reach out to us at support@reancloud.com for any additional queries.###Hello Matthew,This is just a quick follow up.Did you get a chance to go through the analysis we shared?Please let us know your thoughts on the same.###Matthew Watts5:33 AM (1 hour ago)to Rean, spendhq-support@reancloud.comThank you for the notification. We will review and let you know if we have any questions###Hello Team, This is a gentle reminder. Please have a look at our analysis shared with you and let us know if you have any questions as we look further into this.###Hello Team, This is a gentle reminder. Please have a look at our analysis shared with you and let us know if you have any questions as we look further into this.###Hello Team,We have analyzed the server details during the time of the alert and could note that the website was actually not down but the page was taking too long to load i.e there was high latency at the time.We have checked the error logs and noted a couple of errors. On the HTTPD level, there was a MaxClients error a while before the alert got triggered.[Thu Sep 27 15:21:12 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Thu Sep 27 15:21:12 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations[Fri Sep 28 16:39:12 2018] [error] server reached MaxClients setting, consider raising the MaxClients settingFrom the configuration we can see MaxClients settings limit as below.<IfModule prefork.c>StartServers       8MinSpareServers    5MaxSpareServers   20ServerLimit      256MaxClients       256MaxRequestsPerChild  4000</IfModule><IfModule worker.c>StartServers         4MaxClients         300MinSpareThreads     25MaxSpareThreads     75ThreadsPerChild     25MaxRequestsPerChild  0</IfModule>We also noted that several requests were in TIME_WAIT and CLOSE_WAIT state.[root@ip-10-59-100-170 centos]# netstat -a | grep https | wc -l189[root@ip-10-59-100-170 centos]#[root@ip-10-59-100-170 centos]# netstat -a | grep TIME_WAIT | wc -l218[root@ip-10-59-100-170 centos]# netstat -a | grep TIME_WAIT | wc -l190[root@ip-10-59-100-170 centos]# netstat -a | grep httpd | wc -l0[root@ip-10-59-100-170 centos]# netstat -a | grep ESTABILISHED | wc -l0[root@ip-10-59-100-170 centos]# netstat -a | grep CLOSE_WAIT | wc -l177[root@ip-10-59-100-170 centos]# netstat -a | grep https | wc -l189We have checked all other relevant CloudWatch logs on the server and couldn't see any anomaly. However on the ALB level we can see no requests were being served at this time evidenced by broken graph. We have attached the same below.This alert triggered twice in a span of 10 minutes. Please review these details and let us know if you have any questions as we look further into this.Thanks.###Hello Team,This is to inform you that the site down alert got recovered and violation lasts for 5 minutes.We analyzing from our end get back to you with an update.than you.###Hello Team,This is to inform you that we received a site down alert for URL: https://preview.spendhq.com/loginwe analyzing the issue and get back with an update. meanwhile please let us know if you are performing any activity from your end.","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Fri, Sep 28, 2018 at 11:32 PMSubject: Detected Error on SpendHQ PreviewTo: <ms@reancloud.com>Fri, 28 Sep 2018 14:02:30 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): Sydney-C AU, London UK, California US, Frankfurt DE-- *Thank You,**        Rafi R*--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Preview,,28-09-2018 23:34,101,0,SpendHQ,"Hello Team, We are closing the ticket as no action was performed from your end. However, if the ticket is closed erroneously, feel free to reopen the ticket. You can always to reach out to us at support@reancloud.com for any additional queries.","Hello Matthew,This is just a quick follow up.Did you get a chance to go through the analysis we shared?Please let us know your thoughts on the same.","Matthew Watts5:33 AM (1 hour ago)to Rean, spendhq-support@reancloud.comThank you for the notification. We will review and let you know if we have any questions","Hello Team, This is a gentle reminder. Please have a look at our analysis shared with you and let us know if you have any questions as we look further into this.","Hello Team, This is a gentle reminder. Please have a look at our analysis shared with you and let us know if you have any questions as we look further into this.","Hello Team,We have analyzed the server details during the time of the alert and could note that the website was actually not down but the page was taking too long to load i.e there was high latency at the time.We have checked the error logs and noted a couple of errors. On the HTTPD level, there was a MaxClients error a while before the alert got triggered.[Thu Sep 27 15:21:12 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Thu Sep 27 15:21:12 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations[Fri Sep 28 16:39:12 2018] [error] server reached MaxClients setting, consider raising the MaxClients settingFrom the configuration we can see MaxClients settings limit as below.<IfModule prefork.c>StartServers       8MinSpareServers    5MaxSpareServers   20ServerLimit      256MaxClients       256MaxRequestsPerChild  4000</IfModule><IfModule worker.c>StartServers         4MaxClients         300MinSpareThreads     25MaxSpareThreads     75ThreadsPerChild     25MaxRequestsPerChild  0</IfModule>We also noted that several requests were in TIME_WAIT and CLOSE_WAIT state.[root@ip-10-59-100-170 centos]# netstat -a | grep https | wc -l189[root@ip-10-59-100-170 centos]#[root@ip-10-59-100-170 centos]# netstat -a | grep TIME_WAIT | wc -l218[root@ip-10-59-100-170 centos]# netstat -a | grep TIME_WAIT | wc -l190[root@ip-10-59-100-170 centos]# netstat -a | grep httpd | wc -l0[root@ip-10-59-100-170 centos]# netstat -a | grep ESTABILISHED | wc -l0[root@ip-10-59-100-170 centos]# netstat -a | grep CLOSE_WAIT | wc -l177[root@ip-10-59-100-170 centos]# netstat -a | grep https | wc -l189We have checked all other relevant CloudWatch logs on the server and couldn't see any anomaly. However on the ALB level we can see no requests were being served at this time evidenced by broken graph. We have attached the same below.This alert triggered twice in a span of 10 minutes. Please review these details and let us know if you have any questions as we look further into this.Thanks.","Hello Team,This is to inform you that the site down alert got recovered and violation lasts for 5 minutes.We analyzing from our end get back to you with an update.than you.","Hello Team,This is to inform you that we received a site down alert for URL: https://preview.spendhq.com/loginwe analyzing the issue and get back with an update. meanwhile please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DHt9C,Cloud Engineer Level 1,Closed,1063883,Incident,20-06-2017 22:55,,"Hello Team, The  alert regarding volume usage alert for prod-sphq-db-server05 got resolved and returned to a normal value of 57%.###Hello Team, This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% and reached to a value of 99%. We are analyzing the disk usage details and will share it with you shortly.","[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjbEKwyAYhJ8mbpVfjRoHh6YQCp07tEsxGpNAElOjQ9--Bo7jOPjunOaqH9CsKRAJorjgwBpMgKqGYcVbBrLjpBFtKwhUNbjkRmwDmgpiJbPECGok740l1hNOFa2d88wIjxY9pbQfFbtWtCsy-46dScaFcfqWjfXsrA15SyXtMfh5GUrKF3jD7fP4vZ7knlHU61GO42A2u4TsThIlvYZtTiH-ATHdOjs>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj8tuhDAMRb8mLCPbeeFFFqUVv1G5hAGkYUIhM-rnN6AuKll-XMtH1yk6_hqbJRJgAF-zd2BajUDcGs2uMxB6h63vOo-gLKSSJj3kZo42SXAgzoZBWrE8CJFF4nBDQXGhuce5lO1Q5k1RX0O2TScpkvI0f1fGWrU1P5aS90ORISDDnpXpS_4s9ewDLQcOwTADgCI_7fm5VT2Nr2UYFbmT7Kiv81V_Xknw7N7nfJRrj6Ad13c0GlcJtz2v_9keL3azx_Woz-2jPIZ7fqbTXVPin7tfy1xSmA>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Tue Jun 20 2017 16:50:00 UTC (*37 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtTssOwjAM-5r2WKVJn4ceGGj_0a17SYyOrSA-nw4hRY6dSLZT0L4b-BIQpAVT0WggJySgdyS8bghsq6UzTWMkMAWppEn0mc_BU6dIG-Wcss5Ii711GJW3OMaxcyO_h7mU7WB0YdjWidsmUiwx5Wl-Vo-13tb8WEreD4aEgOSNZ9ROe35tjG5peC_9wFCfDhrbqn_7805Rnuw656P8_hKE9rW2kKT5HtajVt2H-Ojv-ZXOLF7CP-sLUIZFXg>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjTsOwyAQRE8DJVrAy6egiAvfA1j8kWzj2OT-IVKk0RRPejMU0KfCt6BAWjC9DYJ2QoLyTguPowY7oXRmHI0ENgA1WkSufA3Szj5DUgOiwRTBebIFBio4Z5lN4ntYW7sepl9MTT3xugTFFqku67tvHJ0d9dxavR-mtAKlvfEdFtoav8Px9L-7xDPv9UM_gbfwF74JoTZg>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVTssKgzAQ_BpzDJusieaQQ6X4H2seKlRj4_r_TWEYhoF5RG_cksTuNagBbGNrAEepQLsRpTMTwjAbNdppsgq6HiLHVYYiNp_QYD8sg9OJAExOebRkUw5IqHMg8fEb83V3-Or03EDXJSMxxbJu39ZxNG8_c6Wb6xP4qanDeSs3n3Q0-VYgjWtXpEIjqj_uNl8TneFTnvjPC_ZHOXcu9QexaDv1>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jUsOwyAQQ08DSzQw_GbBolGVe5BAPlIS0oT2_KWbSpYtPcl2CoaGzNegQDqwza0B9EKCIo-CTIfgeiO97TorgWlINc1iLHwJ4DIO0lL0mrKeECdwEBGmDJSiVnwLS63nzfDBVN8Uz1OkWGMq8_JqG3tj-ZOP-k_s18TwiaQkOPJaK2ecQS0tv8J-t_srx2Pcyjv9-ryGvRxrLdcX4NY5Eg>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVTUkOhCAQfI0cSQOyHTiMB_-BdI-aKDiI_x9MKpVKpRYM2i_E9iBBWDCdjQbluADpneJeTwrsrIUz02QEDCNgw5WnwraAyafRqwTkF4uLMagdKWd7U5KImh1ha-26B_UZ5NwRr4tjbBHLuv36xvl6KZUnt66uSl-qlBPdrIbz7l-VYk5HefANsxbOkvdW6h93jjar>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,20-06-2017 22:43,0,0,SpendHQ,"Hello Team, The  alert regarding volume usage alert for prod-sphq-db-server05 got resolved and returned to a normal value of 57%.","Hello Team, This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% and reached to a value of 99%. We are analyzing the disk usage details and will share it with you shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FdGtl,Cloud Engineer Level 1,Closed,1072803,Incident,11-08-2017 04:45,,"Andrew Kim4:14 AM (30 minutes ago)to Rean, spendhq-support We will be continuing to perform our off-hours batch processes, but expect the impact to be minimal. Please keep monitoring turned on, as we still occasionally have clients accessing during off-hours and want to be notified if clients cannot access the system. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®###Sure, Andrew, We are monitoring the resources as well as the application and will be notifying you if we witness anything unusual.Thank You,REAN Support###Hello Andrew, Thanks for the confirmation, meanwhile we have verified that the outage was reported by our end point monitoring tool because of the high latency on the application due to the high network traffic on the DB node. Now, we have verified that the application is loading and serving well. Could you please let us know if you are still performing the action on the node that can cause to the network traffic so that we can enable the maintenance for the resources. At this time, we are marking this case as resolved as well as reducing the case priority to P3 as this was something related to the actions performed by SpendHQ on the DB server. Please feel free to reach out to us if you have any queries related to this.Thank You,REAN Support###Safuvan Kotakuthmatayil <safuvan.kotakuthmatayil@reancloud.com>3:59 AM (0 minutes ago)to Andrew, Steven, Daniel, spendhq-support Hello Andrew,Thanks for the confirmation, meanwhile we have verified that the outage was reported by our end point monitoring tool because of the high latency on the application due to the high network traffic on the DB node. Now, we have verified that the application is loading and serving well. Could you please let us know if you are still performing the action on the node that can cause to the network traffic so that we can enable the maintenance for the resources.At this time, we are marking this case as resolved as well as reducing the case priority to P3 as this was something related to the actions performed by SpendHQ on the DB server. Please feel free to reach out to us if you have any queries related to this.--Thanks & Regards,Safuvan KM###Andrew Kim3:51 AM (0 minutes ago)to me, Steven, Daniel, akim, spendhq-support I confirmed with the team. This network traffic was caused by internal processes. You can close this ticket. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®###Safuvan Kotakuthmatayil <safuvan.kotakuthmatayil@reancloud.com>3:49 AM (0 minutes ago)to Steven, Daniel, akim, spendhq-support Adding Steven and Daniel.Please respond to the below email.--Thanks & Regards,Safuvan KM###On analyzing further, we could see that the backend DB instance PROD-SPHQ-DB-SERVER05(10.59.10.135) is going through a high network in bound and out bound traffic. From the DB instance level, we could see that Steven NG and Daniel Mackay from your team is already on the DB server.Could you please confirm if you are performing any changes from your end that can lead to the unexpected network traffic as well as to the Secure website outage? We are looking into the instance level logs to investigate this further.Thank You,REAN Support###Hello SpendHq Team, This is to inform you that we received a site down alert for the URL https://secure.spendhq.com/login. The alert got recovered within 2 minutes and the site is well accessible now. We will analyze the issue from our end and meanwhile please let us know if your team has performed any activity from your end.","Thu, 10 Aug 2017 17:46:41 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, Dallas-B US, London UK, Atlanta-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,11-08-2017 03:16,1,0,SpendHQ,"Andrew Kim4:14 AM (30 minutes ago)to Rean, spendhq-support We will be continuing to perform our off-hours batch processes, but expect the impact to be minimal. Please keep monitoring turned on, as we still occasionally have clients accessing during off-hours and want to be notified if clients cannot access the system. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®","Sure, Andrew, We are monitoring the resources as well as the application and will be notifying you if we witness anything unusual.Thank You,REAN Support","Hello Andrew, Thanks for the confirmation, meanwhile we have verified that the outage was reported by our end point monitoring tool because of the high latency on the application due to the high network traffic on the DB node. Now, we have verified that the application is loading and serving well. Could you please let us know if you are still performing the action on the node that can cause to the network traffic so that we can enable the maintenance for the resources. At this time, we are marking this case as resolved as well as reducing the case priority to P3 as this was something related to the actions performed by SpendHQ on the DB server. Please feel free to reach out to us if you have any queries related to this.Thank You,REAN Support","Safuvan Kotakuthmatayil <safuvan.kotakuthmatayil@reancloud.com>3:59 AM (0 minutes ago)to Andrew, Steven, Daniel, spendhq-support Hello Andrew,Thanks for the confirmation, meanwhile we have verified that the outage was reported by our end point monitoring tool because of the high latency on the application due to the high network traffic on the DB node. Now, we have verified that the application is loading and serving well. Could you please let us know if you are still performing the action on the node that can cause to the network traffic so that we can enable the maintenance for the resources.At this time, we are marking this case as resolved as well as reducing the case priority to P3 as this was something related to the actions performed by SpendHQ on the DB server. Please feel free to reach out to us if you have any queries related to this.--Thanks & Regards,Safuvan KM","Andrew Kim3:51 AM (0 minutes ago)to me, Steven, Daniel, akim, spendhq-support I confirmed with the team. This network traffic was caused by internal processes. You can close this ticket. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®","Safuvan Kotakuthmatayil <safuvan.kotakuthmatayil@reancloud.com>3:49 AM (0 minutes ago)to Steven, Daniel, akim, spendhq-support Adding Steven and Daniel.Please respond to the below email.--Thanks & Regards,Safuvan KM","On analyzing further, we could see that the backend DB instance PROD-SPHQ-DB-SERVER05(10.59.10.135) is going through a high network in bound and out bound traffic. From the DB instance level, we could see that Steven NG and Daniel Mackay from your team is already on the DB server.Could you please confirm if you are performing any changes from your end that can lead to the unexpected network traffic as well as to the Secure website outage? We are looking into the instance level logs to investigate this further.Thank You,REAN Support","Hello SpendHq Team, This is to inform you that we received a site down alert for the URL https://secure.spendhq.com/login. The alert got recovered within 2 minutes and the site is well accessible now. We will analyze the issue from our end and meanwhile please let us know if your team has performed any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015VZck,Cloud Engineer Level 1,Closed,1038786,Incident,14-12-2016 14:23,,"Hi Team,We are closing this ticket as the limit got increased to 10.###Hi SpendHQ Team,We have raised support ticket with AWS to increase the  r3.8xlarge instance limit  from  5 t0 10 as the usage is currently at 4.",Raise support ticket with AWS to increase EC2 limit.,AWS limit checker ALERT for spendhq,,14-12-2016 12:29,2,0,SpendHQ,"Hi Team,We are closing this ticket as the limit got increased to 10.","Hi SpendHQ Team,We have raised support ticket with AWS to increase the  r3.8xlarge instance limit  from  5 t0 10 as the usage is currently at 4.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000017QP4g,Cloud Engineer Level 1,Closed,1042803,Incident,03-02-2017 22:27,,"Hello Matthew,Thank you for your confirmation.###Matthew replied that Thank you. This is resolved. You may close the ticket.###Hi Matthew, We have remounted the file system in read-write mode. Please verify from your end and let us know if you have any queries.###Hi Matthew,While unmounting the file system it has shown as busy. As we have not tried unmounting using command #umount -l ,  the option to perform a lazy unmount. Let us know if we can go ahead with this operation before going with the option to restart the instance.###Hello Matthew,We have tried to unmount the file system but the device is showing busy so we are not able to unmount it.Could you please let us know whether we have your approval to restart the instance to resolve the issue.###Hello Matthew,We have analysed the issue and found the file system /dev/sda mounted on /var/infobright went read-only mode.Please see the details below:[root@ip-10-59-10-148 infobright]# touch f1touch: cannot touch `f1': Read-only file systemWhen checking the mounted file systems on the server we could see the device has read-write permission[root@ip-10-59-10-148 infobright]# mount | grep sda/dev/sda on /var/infobright type ext4 (rw)But when checking the mounts under cat /proc/mounts file, we are getting following output which means the file system is currently under read-only mode.[root@ip-10-59-10-148 infobright]# cat /proc/mounts | grep sda/dev/sda /var/infobright ext4 ro,relatime,barrier=1,data=ordered 0 0So, in order to resolve the issue, we have two options1. unmount the filesystem and remount it with rw permission2. If the above solution doesn't work we need to restart the server.Please let us know your thought regarding this.###Hello Matthew,We are looking into this and will get back you with the updates.","We are having issues with the drive that's mounted on /var/infobright which has caused the database to crash. Please resolve asap.[mwatts@ip-10-59-10-148 ~]$ ll /var/infobright/ls: reading directory /var/infobright/: Input/output errorMatthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",DB3 Issues | 10.59.10.148,,03-02-2017 02:09,20,0,SpendHQ,"Hello Matthew,Thank you for your confirmation.",Matthew replied that Thank you. This is resolved. You may close the ticket.,"Hi Matthew, We have remounted the file system in read-write mode. Please verify from your end and let us know if you have any queries.","Hi Matthew,While unmounting the file system it has shown as busy. As we have not tried unmounting using command #umount -l ,  the option to perform a lazy unmount. Let us know if we can go ahead with this operation before going with the option to restart the instance.","Hello Matthew,We have tried to unmount the file system but the device is showing busy so we are not able to unmount it.Could you please let us know whether we have your approval to restart the instance to resolve the issue.","Hello Matthew,We have analysed the issue and found the file system /dev/sda mounted on /var/infobright went read-only mode.Please see the details below:[root@ip-10-59-10-148 infobright]# touch f1touch: cannot touch `f1': Read-only file systemWhen checking the mounted file systems on the server we could see the device has read-write permission[root@ip-10-59-10-148 infobright]# mount | grep sda/dev/sda on /var/infobright type ext4 (rw)But when checking the mounts under cat /proc/mounts file, we are getting following output which means the file system is currently under read-only mode.[root@ip-10-59-10-148 infobright]# cat /proc/mounts | grep sda/dev/sda /var/infobright ext4 ro,relatime,barrier=1,data=ordered 0 0So, in order to resolve the issue, we have two options1. unmount the filesystem and remount it with rw permission2. If the above solution doesn't work we need to restart the server.Please let us know your thought regarding this.","Hello Matthew,We are looking into this and will get back you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001IFCBm,Cloud Engineer Level 1,Closed,1081034,Incident,04-10-2017 21:12,,"Hello Team,This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 3.08. The mysql process was consuming the usage.The alert got resolved automatically and has reduced to a value of 2.69. Let us know if you have any further queries.Resource Details:Name:prd-db1Instance-type:r4.8xlargeRegion:us-east-1","[Triggered] [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over datadog_monitor:on,host:i-03ccfddd9f02cacb9 was > 3.0 on average during the last 5m.Metric value: 3.019This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=4074653512864928091 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Migrate 5 applications at the cost of 4 for just $100k    <https://www.reancloud.com/migration-campaign/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db,,04-10-2017 21:02,0,0,SpendHQ,"Hello Team,This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 3.08. The mysql process was consuming the usage.The alert got resolved automatically and has reduced to a value of 2.69. Let us know if you have any further queries.Resource Details:Name:prd-db1Instance-type:r4.8xlargeRegion:us-east-1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hRS9l,Cloud Engineer Level 1,Closed,1110258,Incident,05-01-2019 02:30,,"Hello Team,We have updated the missing tags for the below instances.  Since we don't have any other pending action we are marking this case as resolved and closing the case.ID: i-084133fa44eecea55Name: matt_m5.large_02Tags updated: Monitoring,OwnerID: i-08ba7660add5681aeName: matt_m5.large_03Tags updated: Monitoring,OwnerID: i-0bd7e6960b41a03e6Name: WebTest01Tag updated: MonitoringPlease reach out to us in case of any query or concern.Thanks,###Please fix it. Praveen Muppala Cloud Architect / Tech Lead, Managed Services","REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::EC2::Instance resources were affected:________________________________  *   Violation: Resource does not adhere to the tagging standards set for your organization.  *   Recommendation: It is recommended to adhere the tagging standards set for your organization. Kindly refer internal policy documents to avoid resource termination.  *   Action taken: None  *   Resource details:Resource IDInstance NameInstance TypeOwnerRegionMissing tagsi-084133fa44eecea55matt_m5.large_02m5.largeus-east-1Monitoring,Owneri-08ba7660add5681aematt_m5.large_03m5.largeus-east-1Monitoring,Owneri-0bd7e6960b41a03e6WebTest01c4.2xlargespendhq-support@reancloud.com<mailto:spendhq-support@reancloud.com>us-east-1Monitoring________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Managed Cloud: spendhq] Tag Validator Alert,,04-01-2019 21:36,5,0,SpendHQ,"Hello Team,We have updated the missing tags for the below instances.  Since we don't have any other pending action we are marking this case as resolved and closing the case.ID: i-084133fa44eecea55Name: matt_m5.large_02Tags updated: Monitoring,OwnerID: i-08ba7660add5681aeName: matt_m5.large_03Tags updated: Monitoring,OwnerID: i-0bd7e6960b41a03e6Name: WebTest01Tag updated: MonitoringPlease reach out to us in case of any query or concern.Thanks,","Please fix it. Praveen Muppala Cloud Architect / Tech Lead, Managed Services",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Fk2mk,Cloud Engineer Level 1,Closed,1077329,Incident,05-09-2017 21:18,,"Hello SpendHQ-Team,The alert regarding high Disk Usage on the instance prd-lg1 - 10.59.10.107 got resolved and returned to a normal state with a value of 76%. The violation lasted for 6 days.As the alert is in the resolved state, we are marking this case as closed. Kindly validate the details and revert back in case of any further queries.Regards,Sumod.K.Bose###Next Action: Get on a call with customer if the alert is not resolved###Hello Team,This is a gentle reminderThis is to inform you that the alert regarding the high volume usage on the instance PRD-LG1(10.59.10.107) is still open and the current usage is 94%. The device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. once your team finishes testing, Please remove the file and folders to reduce the volume usage on this instance and let us know if you have further queries on this.Please###The current usage is at 93.2%.Next action: Send reminder in the evening shift.###The current usage is at 92.7%. Keep monitoring the volume usage status and keep the customer updated about any increase from the 92.4%. Next reminder should be sent in the evening shift.###We haven't heard back from you regarding this case for a while.The volume used for the instance PRD-LG1(10.59.10.107)'s root volume has increased again to 92.4%. I can understand that Dusty was performing some testing on the node and that led to this incident. This ticket has been kept on hold for the last couple of days to get an update from you as it is an expected behaviour due to the testing. Please provide an update once the testing is done so we could take back the ticket from hold and pull out the volume usage details for analysis.Thank You,Safuvan KM###92.4%###Hello SpendHQ-Team, This is to inform you that the alert regarding the high volume usage on the instance PRD-LG1(10.59.10.107) is still open and the current usage is 90.3%. The device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance.Once your team finishes testing, Please remove the file and folders to reduce the volume usage on this instance and let us know if you have further queries on this.###Current usage 90%.###Just to update, we are doing some testing on this machine and have launched some temporary applications that are taking up some space.  Once we finish testing we will be removing the files and that should free up space. Dusty###We have contacted Matthew via phone and he asked to send the details to Dusty Fowler. So we are informing him via email.###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PRD-LG1(10.59.10.107). The volume usage on this instance is above the threshold value of 90% with a value of 97%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. Filesystem Type Size Used Avail Use% Mounted on/dev/xvda1 ext4 7.8G 7.2G 255M 97% /Files under root directory, 7.1G    total4.9G    opt1.1G    usr483M    home286M    lib268M    var44M     boot32M     root30M     etc Delete/zip unwanted files or folders to reduce the current volume usage state on this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : 	i-01efe7d9363f2a2daInstance type :c4.2xlarge Availability zone : us-east-1b Private IPs : 10.59.10.107","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-lg1 - 10.59.10.107  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 90.079This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.107 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=4025357190254528278 · View 10.59.10.107: https://app.datadoghq.com/infrastructure?hostname=10.59.10.107-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-lg1 - 10.59.10.107,,31-08-2017 20:51,120,0,SpendHQ,"Hello SpendHQ-Team,The alert regarding high Disk Usage on the instance prd-lg1 - 10.59.10.107 got resolved and returned to a normal state with a value of 76%. The violation lasted for 6 days.As the alert is in the resolved state, we are marking this case as closed. Kindly validate the details and revert back in case of any further queries.Regards,Sumod.K.Bose",Next Action: Get on a call with customer if the alert is not resolved,"Hello Team,This is a gentle reminderThis is to inform you that the alert regarding the high volume usage on the instance PRD-LG1(10.59.10.107) is still open and the current usage is 94%. The device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. once your team finishes testing, Please remove the file and folders to reduce the volume usage on this instance and let us know if you have further queries on this.Please",The current usage is at 93.2%.Next action: Send reminder in the evening shift.,The current usage is at 92.7%. Keep monitoring the volume usage status and keep the customer updated about any increase from the 92.4%. Next reminder should be sent in the evening shift.,"We haven't heard back from you regarding this case for a while.The volume used for the instance PRD-LG1(10.59.10.107)'s root volume has increased again to 92.4%. I can understand that Dusty was performing some testing on the node and that led to this incident. This ticket has been kept on hold for the last couple of days to get an update from you as it is an expected behaviour due to the testing. Please provide an update once the testing is done so we could take back the ticket from hold and pull out the volume usage details for analysis.Thank You,Safuvan KM",92.40%,"Hello SpendHQ-Team, This is to inform you that the alert regarding the high volume usage on the instance PRD-LG1(10.59.10.107) is still open and the current usage is 90.3%. The device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance.Once your team finishes testing, Please remove the file and folders to reduce the volume usage on this instance and let us know if you have further queries on this.",Current usage 90%.,"Just to update, we are doing some testing on this machine and have launched some temporary applications that are taking up some space.  Once we finish testing we will be removing the files and that should free up space. Dusty",We have contacted Matthew via phone and he asked to send the details to Dusty Fowler. So we are informing him via email.,"Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PRD-LG1(10.59.10.107). The volume usage on this instance is above the threshold value of 90% with a value of 97%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. Filesystem Type Size Used Avail Use% Mounted on/dev/xvda1 ext4 7.8G 7.2G 255M 97% /Files under root directory, 7.1G    total4.9G    opt1.1G    usr483M    home286M    lib268M    var44M     boot32M     root30M     etc Delete/zip unwanted files or folders to reduce the current volume usage state on this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : 	i-01efe7d9363f2a2daInstance type :c4.2xlarge Availability zone : us-east-1b Private IPs : 10.59.10.107",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001KrHRv,Cloud Engineer Level 1,Closed,1085833,Incident,05-12-2017 04:41,,"Hello Team,We got backup failed alert regarding following instances. While checking further on it I could see that Yogesh changed the backup policy of these instances from 3d1w1m to 3d2w1m. So 1 weekly back up check got failed. Due to which alert got triggered.PRD-API-WW1PRD-API-WW2PROD-SPHQ-SOPHOS-VPN01PRD-WW2_6PRD-WW1_122PRD-SV1PRD-LG1PRD-FS1PRD-DB1","Regards,Alsa T AliasREĀN Cloud India Pvt Ltd | Reach, Engage, Āctivate, Nurturealsa.thuruthel@reancloud.com---------- Forwarded message ----------From: Rean Support <notifications@reancloud.com>Date: Tue, Dec 5, 2017 at 4:15 AMSubject: Backup for instance i-0ace70ce06368e4a7 (AWS Account: SpendHQ)failedTo: ms@reancloud.com <ms@reancloud.com>, k.lichkina@cloudaware.com <k.lichkina@cloudaware.com>Backup for the EC2 instance PRD-WW1_122, ID  i-0ace70ce06368e4a7 (AWSAccount: SpendHQ) failed.New value - 80%Prior value - 100%Region - us-east-1Instance link: https://reancloud.cloudforce.com/a0X0G00000C0OSjCMDB link: https://reancloud--ca10.na43.visual.force.com/apex/CaCmdb?sfdc.tabName=01rF0000000mKDl--  <https://www.reancloud.com/aws-reinvent/>--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Backup for instance i-0ace70ce06368e4a7 (AWS Account: SpendHQ) failed,,05-12-2017 04:32,1,0,SpendHQ,"Hello Team,We got backup failed alert regarding following instances. While checking further on it I could see that Yogesh changed the backup policy of these instances from 3d1w1m to 3d2w1m. So 1 weekly back up check got failed. Due to which alert got triggered.PRD-API-WW1PRD-API-WW2PROD-SPHQ-SOPHOS-VPN01PRD-WW2_6PRD-WW1_122PRD-SV1PRD-LG1PRD-FS1PRD-DB1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001S693k,Cloud Engineer Level 1,Closed,1092853,Incident,10-03-2018 01:01,,"Andrew Kim12:59 AM (1 minute ago)to Rean, spendhq-support Thank you. We may have already deleted his account. This case can be closed. Andrew Kim | Director of Information Technology & Security | SpendHQ®###Hello Andrew,We didn't find the user Darren in the Sophos user.Please let us know the if you have any further queries.Please refer the screenshot.###Hello Andrew,We will work on this and will let you know the updates.","Thanks & Regards,Gourav PokhraREĀN Cloud Solutions | Reach, Engage, Activate, Nurture4th Floor, 26, Tulsi Complex,100 Feet Road, New BhupalpuraUdaipur, Rajasthan 313001Gourav.pokhra@reancloud.com |+918696096500| www.reancloud.com<http://www.reancloudsolutions.com/>Toll-Free Number: +12015828406---------- Forwarded message ----------From: Andrew Kim <Akim@spendhq.com>Date: Fri, Mar 9, 2018 at 11:06 PMSubject: Sophos User Access - darrenTo: Spendhq Support <spendhq-support@reancloud.com>Please confirm that the Darren user in Sophos is disabled and includescreenshot.Thank you,*Andrew Kim* | Director of Information Technology & Security | *Spend**HQ®*O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Sophos User Access - darren,,09-03-2018 23:10,3,0,SpendHQ,"Andrew Kim12:59 AM (1 minute ago)to Rean, spendhq-support Thank you. We may have already deleted his account. This case can be closed. Andrew Kim | Director of Information Technology & Security | SpendHQ®","Hello Andrew,We didn't find the user Darren in the Sophos user.Please let us know the if you have any further queries.Please refer the screenshot.","Hello Andrew,We will work on this and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Xzq15,Cloud Engineer Level 1,Closed,1100709,Incident,27-06-2018 13:58,,"Hello Team,This is to inform you that the alert regarding EBS High Disk Usage ( /dev/xvda1 ) on prd-fs1 got recovered and back to its normal state with the value of 79.9%.###Hello SpendHQ team, On further analysis, we could see that Root volume is consuming high disk usage on this instance. Refer the below volume breakdown details. 1.7T    total913G    var820G    exports_production1.3G    usr285M    lib209M    opt44M     boot30M     etc24M     home19M     lib6414M     tmp14M     sbin6.2M    bin5.5M    root152K    dev16K     lost+found8.0K    run4.0K    srv4.0K    selinux4.0K    mntThe top disk consuming files in /var are listed below==>>du: cannot access `/proc/2649/task/2649/fdinfo/5': No such file or directorydu: cannot access `/proc/2649/fdinfo/5': No such file or directory26G     /var/www/vhosts/secure.spendhq.com/public/app/tmp/spend_visibility.MYI.gz26G     /var/www/vhosts/files.spendhq.com/tmp/spend_visibility.MYI.gz26G     /exports_production/files.spendhq.com/tmp/spend_visibility.MYI.gz17G     /var/www/vhosts/files.spendhq.com/etl_test_uploads_2.27.18/gpc_rollup_201510_201803_dm.out17G     /var/www/vhosts/files.spendhq.com/etl_test_uploads_2.27.18/gpc_201510_201803_dm.out17G     /exports_production/files.spendhq.com/etl_test_uploads_2.27.18/gpc_rollup_201510_201803_dm.out17G     /exports_production/files.spendhq.com/etl_test_uploads_2.27.18/gpc_201510_201803_dm.out9.9G    /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log9.9G    /exports_production/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log9.8G    /var/www/vhosts/files.spendhq.com/etl_test_uploads_2.27.18/jll_201306_201805_dm.outKindly validate the details and zip/clean the unwanted files and please revert back to us in case of any queries.###Hello SpendHQ team, This is to notify you that we have received an alert regarding EBS High Disk Usage ( /dev/xvda1 ) on prd-fs1 and it reached the threshold value of 80 %.  We will analyze more on this. Please find the resource details below. Name:prd-fs1 Instance Id: i-1426f28b Private Ip: 10.59.100.125 instance-type:c4.xlarge availability-zone:us-east-1b","[image: Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-fs1 -10.59.100.125High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1530063939000&group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-1426f28b&from_ts=1530060339000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 80The monitor was last triggered at Wed Jun 27 2018 01:45:49 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-1426f28b>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [Viewi-1426f28b <https://app.datadoghq.com/infrastructure?filter=i-1426f28b>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1530063949000&tags=host%3Ai-1426f28b&from_ts=1530063049000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4459402211181884916>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-fs1 - 10.59.100.125,,27-06-2018 07:18,15,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding EBS High Disk Usage ( /dev/xvda1 ) on prd-fs1 got recovered and back to its normal state with the value of 79.9%.","Hello SpendHQ team, On further analysis, we could see that Root volume is consuming high disk usage on this instance. Refer the below volume breakdown details. 1.7T    total913G    var820G    exports_production1.3G    usr285M    lib209M    opt44M     boot30M     etc24M     home19M     lib6414M     tmp14M     sbin6.2M    bin5.5M    root152K    dev16K     lost+found8.0K    run4.0K    srv4.0K    selinux4.0K    mntThe top disk consuming files in /var are listed below==>>du: cannot access `/proc/2649/task/2649/fdinfo/5': No such file or directorydu: cannot access `/proc/2649/fdinfo/5': No such file or directory26G     /var/www/vhosts/secure.spendhq.com/public/app/tmp/spend_visibility.MYI.gz26G     /var/www/vhosts/files.spendhq.com/tmp/spend_visibility.MYI.gz26G     /exports_production/files.spendhq.com/tmp/spend_visibility.MYI.gz17G     /var/www/vhosts/files.spendhq.com/etl_test_uploads_2.27.18/gpc_rollup_201510_201803_dm.out17G     /var/www/vhosts/files.spendhq.com/etl_test_uploads_2.27.18/gpc_201510_201803_dm.out17G     /exports_production/files.spendhq.com/etl_test_uploads_2.27.18/gpc_rollup_201510_201803_dm.out17G     /exports_production/files.spendhq.com/etl_test_uploads_2.27.18/gpc_201510_201803_dm.out9.9G    /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log9.9G    /exports_production/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log9.8G    /var/www/vhosts/files.spendhq.com/etl_test_uploads_2.27.18/jll_201306_201805_dm.outKindly validate the details and zip/clean the unwanted files and please revert back to us in case of any queries.","Hello SpendHQ team, This is to notify you that we have received an alert regarding EBS High Disk Usage ( /dev/xvda1 ) on prd-fs1 and it reached the threshold value of 80 %.  We will analyze more on this. Please find the resource details below. Name:prd-fs1 Instance Id: i-1426f28b Private Ip: 10.59.100.125 instance-type:c4.xlarge availability-zone:us-east-1b",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001kngr1,Cloud Engineer Level 1,Closed,1112565,Incident,02-03-2019 04:36,,"Hello Matthew,The current value of Disk usage is 87.5% and the alert is recovered. Please do some more clean up also.As the alert is resolved. Currently, we are marking this case as closed. We will inform you when the alert gets triggered again.Please let us know if you any queries.Regards,-Rafi###Matthew Watts <mwatts@spendhq.com>Fri 03/01/19 04:26 AMThank you for the alert. Please confirm if this is resolved.Matthew Watts | Manager, Application Development | SpendHQ®###Hello Matthew,Yes, the alert is recovered as per the threshold level we set it up on monitoring tool. but its still 87% utilizing the space.Please do some more clean upRegards,Rafi Ramesh###Hello Team,This is to remind you that the alert regarding EBS disk usage for the instance SPHQ-DB2-20180830 is still in an open state.The current usage is 92.3%.File System: /dev/sdaType:ext4Total Size:8.0TUsed Size:7.0TAvailable Size:595Guse%: 93% Mounted On: /usr/local/mariadbDetailed usage details:Disk usage as per Directories in /usr/local/mariadb/columnstore==>>7.0T    data21.3G    dataUsage under the /usr/local/mariadb/columnstore/data directory==>>1.3G    bulkUsage under the /usr/local/mariadb/columnstore/data2 directory==>>7.0T    000.dir5.1G    versionbuffer.cdfKindly zip or delete the unwanted files. Please revert back to us in case of any queries.###Current utilization is 91.6%###Hello Team,We haven't heard back from you.The alert still in the open state with the value of 91.6%. Please find the disk usage below. Kindly zip or delete the unwanted files. Please revert back to us in case of any queries.Resource details : Instance name : SPHQ-DB2-20180830 Instance ID : i-0105d8ab19d508dd6 private IP : 10.59.10.45 The following is the disk usage details : 6.8T	/usr/local/mariadb/columnstore 16K	/usr/local/mariadb/lost+found Thanks.###Current utilization is 90.8%###Hello Team This is to notify you that we have received an EBS high Disk usage alert with a current value of 90.2%. While checking we could see that the folder is consuming 6.8TB of space and having 760 GB free space.Resource details : Instance name : SPHQ-DB2-20180830Instance ID : i-0105d8ab19d508dd6private IP : 10.59.10.45The following is the disk usage details : 6.8T	/usr/local/mariadb/columnstore16K	/usr/local/mariadb/lost+foundPlease check the details from your end and let us know if you have any further queries. Regards Athira","[Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db2-20180830 - 10.59.10.45High Disk Usage detected on the device /dev/sda   @rean_ms@hitachivantara.com[Metric Graph]<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUoq3Jm7VhQX6XRi2GSjpultm0wJsamjtBUmZ-2BU9fd-2FCuA-2F9SDp28X93MXaP4HCJ57r-2FXIeLGQOQfzlRx0IE7OFiEWU-2FVKxagitwUY012v2bBRcsG4oI1tzUIJtxrMMwzwC-2Bpi4oeU4HgCGsKbdxYhpiQ-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33P4QQGBbYDzujRxKidrdY2JwalI8K1bShb0298aszneqKmQZo7GgR1XKds7rKi0KCbOulHwHPVIz-2BaVEbhgsQDgr6wCjuYZnPs1lzOn5dnnJdY7xwPQcLxUmylbbSlvmS1bT7rY-2FERYOXNz7ampQJAg0rnVGN05BusmJe5UQpQENY14H2DvJqkGlKxpuKntBTO1bk7-2BTrMG8kHTx31rAdn&data=01%7C01%7Cathira.pk%40hitachivantara.com%7C3060fa2adcf94882d5b008d69bfa160b%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=JDGlWMhe1pjUspoA0pA0hWvyqtm6fhBUph412OemNqk%3D&reserved=0>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 90The monitor was last triggered at Tue Feb 26 2019 14:52:49 UTC (3 secs ago).________________________________[Monitor Status<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUoKvcGnAzkyStJKdzb6NVcA5t2M-2BrFxoMN2TmHLeZCbSYfp82eDhSdg741ilgwakJA2sRnb5OtKBGKtkhY-2BP1lUA-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33P4QQGBbYDzujRxKidrdY2JwalI8K1bShb0298aszneli7ag3gikaJ0u-2BFbzSYM1hpH41BXKCCEiuZ9LoacrkaHIt-2Bg1u77BgAj0Z7EF9igRcl-2BellannsVbAWfc1MAGhdTMSbiXdl4aH0DJ4C1bIzROw-2FYtY4hhjB04IqDhLlklaop4bACZQCP9bFjVJ3-2BMMqdGLwbqTeknBZPQLaNZFn&data=01%7C01%7Cathira.pk%40hitachivantara.com%7C3060fa2adcf94882d5b008d69bfa160b%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=8XGTwzakkkXg1zUaCcfWmBAHjwxpXDtYoLXgy4U%2BRRQ%3D&reserved=0>] · [Edit Monitor<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUo3IM-2FbEP-2FJM89epazZbNBUA-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33P4QQGBbYDzujRxKidrdY2JwalI8K1bShb0298aszneramfRVcp80MlDDYPElRjhFumjZywxBK8Gzjf6D0-2Bat0uQ1vjdsvaW420-2FwPbNPaegEkQHKOqToyiLL2LDo8nR01gVUnrdPFplUhb5EbgKmMPzDQf3dlSHtp5TvwzsKxgVYD1TmZ3zrpBU7H7PHMZQ-2BXBZUZ6PdJcWLprf2gKZsz&data=01%7C01%7Cathira.pk%40hitachivantara.com%7C3060fa2adcf94882d5b008d69bfa160b%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=8IfP1YwZMygj8iV%2FDV8wHAamVSE%2BxRnbIwT75oOzkvE%3D&reserved=0>] · [View i-0105d8ab19d508dd6<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEDKT1NZt0tnkwEaAxSQZgjulmG8eAXgJiEQQ1IARF6DGABH4uVqjj5aQfIiB59UCaQ-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33P4QQGBbYDzujRxKidrdY2JwalI8K1bShb0298aszneqrYko9cy7-2FOqYPHap-2BAicb-2Ff9xpHwIs5mnfOD5uUMgRJKgfeVy2UyKbUxqyspp56fmhBLYgAMkmvN2dEjUT1gd7mSqgRHg-2BFSYi6UqcMJN0vV4MB20nU2GBdtcxteJrQvZjVfZPBpEACc3zNz8er-2Fh4Xws6VkdXnnNhR2kwy9db&data=01%7C01%7Cathira.pk%40hitachivantara.com%7C3060fa2adcf94882d5b008d69bfa160b%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=h7Lm3pRhX6Y7tbSNWSHo%2FocpmxjYc0qN1ESoKpPEols%3D&reserved=0>] · [Show Processes<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQED-2FFPDBbKPsalSo1i1ufo6S-2FX4pKstbDP3BrKs5ghv71-2FKTmDfY5JbsRHo-2BCPF4E-2BK4tsSCLHrXYLGueT0q2PfKVGJH2k-2Bps2ec0APVKfynmv2XGbY2HWQk8kCB8nk8H0wpJ1TwlFddhPewpmfxdasMnNH-2FRBPXTXSnGI-2BW0Dg79KiP-2F1iVusfK6MyCkIAl2tA-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33P4QQGBbYDzujRxKidrdY2JwalI8K1bShb0298asznehUY7sSKVTKALKn3yOqnH5TDwWcD0kmf-2BQUP1JJsw3uWYNi-2F5THx67-2FbFB4sj-2Fx3NF4F5FAVvbGQQOxYFuRBViNIBiT-2BrNRFUd6pSlQcRVa7mik0-2BMpA1bEFXSzSngFzQe-2FVxkSJevEINByq-2BTn4lw-2F-2BMV7Q1qmoIplqMHQwvNBe&data=01%7C01%7Cathira.pk%40hitachivantara.com%7C3060fa2adcf94882d5b008d69bfa160b%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=ORzhpWr7iiJKQBZBYKctK6nBVnIpfNdYhGxfy3t3GyA%3D&reserved=0>]This alert was raised by account SpendHQComment in Datadog<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAYJwPp8omKJuncXDFvQtomqfPumIJClQ3dfAqmZTLUngurkmbQMO4dMW8Ydesk5RY-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33P4QQGBbYDzujRxKidrdY2JwalI8K1bShb0298asznetH4-2FYWVg0ZBaddhs841HPr41dl-2BZxJ1Soqdp2ZZgruS2vCDtuZGZx5Gq3eovev0kA4QbWS-2FSUPDP3VYspXieW8ECfIcJEg6zkfPx7NPm0ykDncWEIiOduwgWFrx9CR2OTeaHbvkZiseqvl85rgzSR7A16ZOmSnq8FD79ujkaUTb&data=01%7C01%7Cathira.pk%40hitachivantara.com%7C3060fa2adcf94882d5b008d69bfa160b%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=UjzpYlXCQv035n8yyZ9SyD5mTaKn0QWb5U4FuBfu1yw%3D&reserved=0>To manage your Datadog subscriptions, click here<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECkg7AnUPKGn51plZlHct1NB9fwJzgmRoiq4UZtJ-2F9d6Q-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33P4QQGBbYDzujRxKidrdY2JwalI8K1bShb0298aszneuNk-2BnJX6TZKC0na4UuWHsQcdVH3BPQTW-2BKWORshNKSi-2FMqtudxbd1BBbT8Ewey8g2cOCb7kpS9t2HhYRWBaDjnwAweI0mDVhAn6FwTgSa1xvJthWqIZ2Q-2FWdh494thdTAvAkg5A-2FUCU7AXY3NOHVV0VAb-2FooHnSAUbiU0vAmVdl&data=01%7C01%7Cathira.pk%40hitachivantara.com%7C3060fa2adcf94882d5b008d69bfa160b%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=zREZulm8%2BkiumrRbANETrCFpzbYe3sVoEh%2BOjGDdR6k%3D&reserved=0>.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db2-20180830 - 10.59.10.45,,26-02-2019 20:24,80,0,SpendHQ,"Hello Matthew,The current value of Disk usage is 87.5% and the alert is recovered. Please do some more clean up also.As the alert is resolved. Currently, we are marking this case as closed. We will inform you when the alert gets triggered again.Please let us know if you any queries.Regards,-Rafi","Matthew Watts <mwatts@spendhq.com>Fri 03/01/19 04:26 AMThank you for the alert. Please confirm if this is resolved.Matthew Watts | Manager, Application Development | SpendHQ®","Hello Matthew,Yes, the alert is recovered as per the threshold level we set it up on monitoring tool. but its still 87% utilizing the space.Please do some more clean upRegards,Rafi Ramesh","Hello Team,This is to remind you that the alert regarding EBS disk usage for the instance SPHQ-DB2-20180830 is still in an open state.The current usage is 92.3%.File System: /dev/sdaType:ext4Total Size:8.0TUsed Size:7.0TAvailable Size:595Guse%: 93% Mounted On: /usr/local/mariadbDetailed usage details:Disk usage as per Directories in /usr/local/mariadb/columnstore==>>7.0T    data21.3G    dataUsage under the /usr/local/mariadb/columnstore/data directory==>>1.3G    bulkUsage under the /usr/local/mariadb/columnstore/data2 directory==>>7.0T    000.dir5.1G    versionbuffer.cdfKindly zip or delete the unwanted files. Please revert back to us in case of any queries.",Current utilization is 91.6%,"Hello Team,We haven't heard back from you.The alert still in the open state with the value of 91.6%. Please find the disk usage below. Kindly zip or delete the unwanted files. Please revert back to us in case of any queries.Resource details : Instance name : SPHQ-DB2-20180830 Instance ID : i-0105d8ab19d508dd6 private IP : 10.59.10.45 The following is the disk usage details : 6.8T	/usr/local/mariadb/columnstore 16K	/usr/local/mariadb/lost+found Thanks.",Current utilization is 90.8%,"Hello Team This is to notify you that we have received an EBS high Disk usage alert with a current value of 90.2%. While checking we could see that the folder is consuming 6.8TB of space and having 760 GB free space.Resource details : Instance name : SPHQ-DB2-20180830Instance ID : i-0105d8ab19d508dd6private IP : 10.59.10.45The following is the disk usage details : 6.8T	/usr/local/mariadb/columnstore16K	/usr/local/mariadb/lost+foundPlease check the details from your end and let us know if you have any further queries. Regards Athira",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ESiYs,Cloud Engineer Level 1,Closed,1067037,Incident,07-07-2017 09:28,,"Hello Matthew, Thanks for your confirmation. At this time, we're marking this case as Resolved. Please revert back to us if you have any queries.###Matthew WattsThank you###Hi Matthew,We have reset the MFA for your user account matthew. Now you will be able to login the user portal with Username and password for generating a new barcode.Please let us know if you are facing any issue.","I am unable to login to Sophos to generate my barcode for the authenticatopr app.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sophos,,07-07-2017 08:54,1,0,SpendHQ,"Hello Matthew, Thanks for your confirmation. At this time, we're marking this case as Resolved. Please revert back to us if you have any queries.",Matthew WattsThank you,"Hi Matthew,We have reset the MFA for your user account matthew. Now you will be able to login the user portal with Username and password for generating a new barcode.Please let us know if you are facing any issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001WYHVw,Cloud Engineer Level 1,Closed,1099508,Incident,29-05-2018 19:20,,"Hello Allen,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Allen Herrera7:16 PM (2 minutes ago)to Matthew, spendhq-support Looks good team! Thank you !###Afternoon team please check if you got any notification from there side if not please do a follow up###Matthew Watts7:37 AM (7 hours ago)to Rean, spendhq-support We will verify on Tuesday as it is a holiday here in the USA.###Hi Mathew/Allen,We haven't heard back from you. Please review the previous comments and let us know if you are facing any challenges.###Hi Mathew/Allen,Please try to access the folder /usr/local/mariadb now. As we tested from our end we are able to touch a file in the same folder now. Please let us know if the issue is still persist for you. Thanks !###Matthew Watts10:29 AM (29 minutes ago)to Rean, spendhq-support Why can you not mount the volume into the server?###Hello Team,We have unmounted the volume but not able to mount back the volume so we need to restart the server.Please provide your approval for the reboot.###/usr/local/mariadb went to read-only mount. We performed the lazy mount and unmounted the volume but able to mount back the volume. Please check with Rohit to further on this case.###Hello Matthew,We are working on this issue and will get back to you soon.###Matthew Watts4:35 AM (1 hour ago)to me, Allen, REAN No, instead please run lsof on the cli, grep the location and kill that process. Then mount the drive. Please let Allen know what the process is so he can restart it if need be.###Hello Matthew,We are checking this issue and will let you know the update.###Matthew Watts2:29 AM (39 minutes ago)to Allen, Rean, spendhq-support Please resolve this immediately.###Hello Allen,When we are trying to unmount the volume it is showing busy with following error umount: /usr/local/mariadb: target is busy.Please find the screenshot in the attachments section with all running process under this disk. Please approve us to kill the processes. So that will do unmount and remount the disk.###Hello Allen,We are checking on this and will get back to you with updates.","---------- Forwarded message ----------From: Manideep Gunda <manideep.gunda@reancloud.com>Date: Fri, May 25, 2018 at 7:27 PMSubject: Re: MOUNTS READ ONLYTo: Allen Herrera <aherrera@spendhq.com>Cc: REAN Managed Services <ms@reancloud.com>Hello Allen,We are checking on this and will get back to you with updates.On Fri, May 25, 2018 at 7:17 PM, Allen Herrera <aherrera@spendhq.com> wrote:> /usr/local/mariadb.  @ 10.59.10.180  is in read only and is blocking my> work for the day. I need this fixed now>>>> *Allen Herrera* | Associate Engineer | *Spend**HQ®*>> C: 360.888.3938 | aherrera@spendhq.com>> *A SaaS Spend Visibility solution from Insight Sourcing Group*>> www.spendhq.com | www.insightsourcing.com>>>-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <http://go.reancloud.com/secure-your-cloud>--  <http://go.reancloud.com/secure-your-cloud>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: MOUNTS READ ONLY,,25-05-2018 19:58,95,0,SpendHQ,"Hello Allen,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Allen Herrera7:16 PM (2 minutes ago)to Matthew, spendhq-support Looks good team! Thank you !",Afternoon team please check if you got any notification from there side if not please do a follow up,"Matthew Watts7:37 AM (7 hours ago)to Rean, spendhq-support We will verify on Tuesday as it is a holiday here in the USA.","Hi Mathew/Allen,We haven't heard back from you. Please review the previous comments and let us know if you are facing any challenges.","Hi Mathew/Allen,Please try to access the folder /usr/local/mariadb now. As we tested from our end we are able to touch a file in the same folder now. Please let us know if the issue is still persist for you. Thanks !","Matthew Watts10:29 AM (29 minutes ago)to Rean, spendhq-support Why can you not mount the volume into the server?","Hello Team,We have unmounted the volume but not able to mount back the volume so we need to restart the server.Please provide your approval for the reboot.",/usr/local/mariadb went to read-only mount. We performed the lazy mount and unmounted the volume but able to mount back the volume. Please check with Rohit to further on this case.,"Hello Matthew,We are working on this issue and will get back to you soon.","Matthew Watts4:35 AM (1 hour ago)to me, Allen, REAN No, instead please run lsof on the cli, grep the location and kill that process. Then mount the drive. Please let Allen know what the process is so he can restart it if need be.","Hello Matthew,We are checking this issue and will let you know the update.","Matthew Watts2:29 AM (39 minutes ago)to Allen, Rean, spendhq-support Please resolve this immediately.","Hello Allen,When we are trying to unmount the volume it is showing busy with following error umount: /usr/local/mariadb: target is busy.Please find the screenshot in the attachments section with all running process under this disk. Please approve us to kill the processes. So that will do unmount and remount the disk.","Hello Allen,We are checking on this and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKsf,Cloud Engineer Level 1,Closed,1042237,Incident,,,,"also - we by default are taking a snapshot every hour of Spend4 - the last occurred a 2200 hrs.Chris VeilletteCTO[1450833261212_7186d8e7bdbb48853119db07d964f770.jpg]www.Andromeda3.com<http://www.Andromeda3.com>cveillette@andromeda3.comMobile: 703.447.4124Office:   571.781.0428________________________________From: Matthew Watts <mwatts@spendhq.com>Sent: Friday, January 13, 2017 10:08 PMTo: Chris Veillette; Mrigank SaxenaCc: REAN SupportSubject: RE: MaintenanceCan you image the Production Machine – Spend4. We just want to create a clone.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Friday, January 13, 2017 10:06 PMTo: Matthew Watts <mwatts@spendhq.com>; Mrigank Saxena <mrigank.saxena@reancloud.com>Cc: REAN Support <support@reancloud.com>Subject: Re: MaintenanceHI Matt -Sorry - didn't know which vol to image - and if you want to clone it ...Can you let me know - I am standing byChris VeilletteCTO[1450833261212_7186d8e7bdbb48853119db07d964f770.jpg]www.Andromeda3.com<http://www.Andromeda3.com>cveillette@andromeda3.com<mailto:cveillette@andromeda3.com>Mobile: 703.447.4124Office:   571.781.0428________________________________From: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Sent: Friday, January 13, 2017 9:52 PMTo: Mrigank Saxena; Chris VeilletteCc: REAN SupportSubject: RE: MaintenanceChris,Did you manage to image the machine?Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]Sent: Friday, January 13, 2017 9:37 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,As mentioned earlier, Andromeda team is going to clone the volume before we proceed with the patching of the instance.Please let us know if that is done so that we can proceed with the security patching.On Sat, Jan 14, 2017 at 8:00 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Please update the 10.59.10.12 machine first and advise when complete.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com<mailto:mrigank.saxena@reancloud.com>]Sent: Friday, January 13, 2017 9:24 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,We are ready for the maintenance. Please let us know once you start making the changes.On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Rean Team are you ready to commence the updates as planned on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Maintenance,,14-01-2017 08:42,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001GJPph,Cloud Engineer Level 1,Closed,1076523,Incident,29-08-2017 03:04,,"Hello SpendHQ Team,This Alarm is related to AWS Direct Connect.It is regarding the packet rate for inbound data to the AWS side of the connection.We have checked and verified that the alarm is resolved and is in OK state now.Please let us know if you have any other queries regarding this.","What is this rean? On 8/28/17, 3:49 PM, SPHQ-DXMon <no-reply@sns.amazonaws.com> wrote:    You are receiving this email because your Amazon CloudWatch Alarm DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb in the US East (N. Virginia) region has entered the ALARM state, because Threshold Crossed: 1 datapoint [121332.1 (28/08/17 19:44:00)] was greater than or equal to the threshold (120000.0). at Monday 28 August, 2017 19:49:02 UTC.        View this alarm in the AWS Management Console:    https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#s=Alarms&alarm=DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb        Alarm Details:    - Name:                       DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb    - Description:                The packet rate for inbound data to the AWS side of the connection.    - State Change:               OK -> ALARM    - Reason for State Change:    Threshold Crossed: 1 datapoint [121332.1 (28/08/17 19:44:00)] was greater than or equal to the threshold (120000.0).    - Timestamp:                  Monday 28 August, 2017 19:49:02 UTC    - AWS Account:                261234435984        Threshold:    - The alarm is in the ALARM state when the metric is GreaterThanOrEqualToThreshold 120000.0 for 300 seconds.         Monitored Metric:    - MetricNamespace:                     AWS/DX    - MetricName:                          ConnectionPpsIngress    - Dimensions:                          [ConnectionId = dxcon-ffpmy711]    - Period:                              300 seconds    - Statistic:                           Average    - Unit:                                not specified                State Change Actions:    - OK:     - ALARM: [arn:aws:sns:us-east-1:261234435984:SpendHQ-DirectConnect-Cloudwatch-Monitoring]    - INSUFFICIENT_DATA:             --    If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:    https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQ-DirectConnect-Cloudwatch-Monitoring:24ff3fa5-5763-4bc5-b430-6ec72c0bae22&Endpoint=spendhq-support@reancloud.com        Please do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support    -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: ALARM: DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb in US East (N. Virginia),,29-08-2017 01:35,5,0,SpendHQ,"Hello SpendHQ Team,This Alarm is related to AWS Direct Connect.It is regarding the packet rate for inbound data to the AWS side of the connection.We have checked and verified that the alarm is resolved and is in OK state now.Please let us know if you have any other queries regarding this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001lRaWa,Cloud Engineer Level 1,Closed,1113094,Incident,13-03-2019 22:14,,"Hello Balam,Hope they are able to access the instance & use sudo for doing the pentest. As there is no action pending on this. we are marking this case as closed. Although you can re-open this case at any timeFeel free to reach us if you need any helpRegards, -Rafi###Hello Team,This is a quick follow up. We have provided sudo access for the users jbell and gingers on the server Ubuntu_pentest. Please validate the access and please let us know whether we are good to close this case.###Hello balm,We have provided passwordless access to the users. Could you please check again and let you know if you still facing issues while logging.Thanks and Regards Revathy Kurup###Hi Revathy,They have tried but it is asking for password, since they are authenticating with SSH keys I would suggest a passwordless sudo, if not possible, then please provide the password to the users.Best,Balam Mendoza###Hello Balam,We have provided sudo access for the users jbell and gingers on the server Ubuntu_pentest. Please validate the access and please let us know if you are facing any issues.Thanks and Regards###Hello Matthew/Balam,We are working for providing the sudo access for below-mentioned users and will let you know the updates soon. jbell  gingers Thanks and RegardsRevathy Kurup###Approved. Matthew Watts###Hello Matthew,Could you please provide approval to give sudo access for below-mentioned users on Ubuntu_pentest Instance.   jbell  gingers Thanks and RegardsRevathy Kurup","Hi,We need the users jbell and gingers on the pentest instance to have sudo enabled. Can you help us with this?Best,Balam MendozaCISO OfficeSpendHQ-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Pentest Instance - Sudoers,,11-03-2019 21:00,49,0,SpendHQ,"Hello Balam,Hope they are able to access the instance & use sudo for doing the pentest. As there is no action pending on this. we are marking this case as closed. Although you can re-open this case at any timeFeel free to reach us if you need any helpRegards, -Rafi","Hello Team,This is a quick follow up. We have provided sudo access for the users jbell and gingers on the server Ubuntu_pentest. Please validate the access and please let us know whether we are good to close this case.","Hello balm,We have provided passwordless access to the users. Could you please check again and let you know if you still facing issues while logging.Thanks and Regards Revathy Kurup","Hi Revathy,They have tried but it is asking for password, since they are authenticating with SSH keys I would suggest a passwordless sudo, if not possible, then please provide the password to the users.Best,Balam Mendoza","Hello Balam,We have provided sudo access for the users jbell and gingers on the server Ubuntu_pentest. Please validate the access and please let us know if you are facing any issues.Thanks and Regards","Hello Matthew/Balam,We are working for providing the sudo access for below-mentioned users and will let you know the updates soon. jbell  gingers Thanks and RegardsRevathy Kurup",Approved. Matthew Watts,"Hello Matthew,Could you please provide approval to give sudo access for below-mentioned users on Ubuntu_pentest Instance.   jbell  gingers Thanks and RegardsRevathy Kurup",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013uxOo,Cloud Engineer Level 1,Closed,1030236,Incident,10-11-2016 04:01,,"Hello Team, Please ignore this alert because one of our Rean Team member was trying to login.","Failed WebAdmin login attempt from 10.242.2.4 at 2016-11-09 22:27:03 with username admin.        -- System Uptime      : 165 days 16 hours 54 minutesSystem Load        : 0.07System Version     : Sophos UTM 9.403-4Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][WARN-005] Failed WebAdmin login,,10-11-2016 03:57,0,0,SpendHQ,"Hello Team, Please ignore this alert because one of our Rean Team member was trying to login.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001J2p8l,Cloud Engineer Level 1,Closed,1082439,Incident,18-10-2017 21:19,,"Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 3.036. The alert got resolved automatically and has reduced to a value of 2.901. Let us know if you have any further queries. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1","[Triggered] [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over datadog_monitor:on,host:i-03ccfddd9f02cacb9 was > 3.0 on average during the last 5m.Metric value: 3.036This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=4094905007450710639 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db,,18-10-2017 20:20,1,0,SpendHQ,"Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 3.036. The alert got resolved automatically and has reduced to a value of 2.901. Let us know if you have any further queries. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VMiql,Cloud Engineer Level 1,Closed,1097369,Incident,30-04-2018 13:59,,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello Matthew, We haven't heard back from you on this case. We have stopped the mentioned instance. Please verify and let us know if you have any queries.###Hello Matthew, We haven't heard back from you on this case.We have stopped the mentioned instance. Please verify and let us know if you have any queries.###Hello Matthew,We have stopped the mentioned instance. Please verify and let us know if you have any queries.###Hello Matthew,Before performing stop activity on this instances, we would like to let you know that by checking from instance level we found that among 4 instances following 3 instances are having icsci volume mounted on them but the below instances are not having fstab entries. Please find the screenshots below:For instance:  10.59.10.171 - SpendHQ-Server1-2018-03-16For instance: 10.59.10.122 - SpendHQ-Server2-2018-03-16Kindly validate these details and let us know whether we can go ahead and perform stop activity.","REAN,Can we stop and not terminate the servers outlines below. Please advise once this has been done.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Andrew Kim <Akim@spendhq.com>Date: Wednesday, April 25, 2018 at 3:39 PMTo: Matthew Watts <mwatts@spendhq.com>Subject: REAN AWS Servers - Please InvestigateMatthew – can you look into the following servers?10.59.10.171 - SpendHQ-Server1-2018-03-1610.59.10.122 - SpendHQ-Server2-2018-03-1610.59.10.89 - PRD-DB-Clone-2018-03-1610.59.10.215 - Clone of PRD-DB_v20171127Thanks,Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com<mailto:akim@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: REAN AWS Servers - Please Investigate,,26-04-2018 02:54,107,0,SpendHQ,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello Matthew, We haven't heard back from you on this case. We have stopped the mentioned instance. Please verify and let us know if you have any queries.","Hello Matthew, We haven't heard back from you on this case.We have stopped the mentioned instance. Please verify and let us know if you have any queries.","Hello Matthew,We have stopped the mentioned instance. Please verify and let us know if you have any queries.","Hello Matthew,Before performing stop activity on this instances, we would like to let you know that by checking from instance level we found that among 4 instances following 3 instances are having icsci volume mounted on them but the below instances are not having fstab entries. Please find the screenshots below:For instance:  10.59.10.171 - SpendHQ-Server1-2018-03-16For instance: 10.59.10.122 - SpendHQ-Server2-2018-03-16Kindly validate these details and let us know whether we can go ahead and perform stop activity.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001jlyLH,Cloud Engineer Level 1,Closed,1112343,Incident,26-02-2019 06:45,,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved/Closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,-Rafi###Hello Jason,This is a quick followup We haven't heard back from you please let us know if you are facing any issue. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved/Closed, although you can re-open the case anytime by sending an email back to us.ThanksRegards,Rafi Ramesh###Hello Team,This is a quick followup We haven't heard back from you please let us know if you have any issue.Thanks###Hi Jason, We have sent the same response via the ticketing system.The issue is resolved now. Earlier the ALB was configured to access the application on port 80. The required changes has been made on the ALB side. Please let us know if you have any issue. Regards,Manideep.G###Rean,Can I get an update on when this will be completed?Thanks,Jason###Hi Matthew,The issue is resolved now. Earlier the ALB was configured to access the application on port 80. The required changes has been made on the ALB side. Please let us know if you have any issue. Thanks###Hello Matthew,We will look into this and will get back to you with an update.","Rean,It appears that the sales.spendhq.com load balancer isn’t making it to the 10.59.100.137 box. Can you review and let me know once it’s resolved? Can we make sure this is forwarding to 443.[cid:image001.png@01D4C90A.36621300][cid:image002.png@01D4C90A.36621300]Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sales Load Balancer,,20-02-2019 16:21,134,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved/Closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,-Rafi","Hello Jason,This is a quick followup We haven't heard back from you please let us know if you are facing any issue. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved/Closed, although you can re-open the case anytime by sending an email back to us.ThanksRegards,Rafi Ramesh","Hello Team,This is a quick followup We haven't heard back from you please let us know if you have any issue.Thanks","Hi Jason, We have sent the same response via the ticketing system.The issue is resolved now. Earlier the ALB was configured to access the application on port 80. The required changes has been made on the ALB side. Please let us know if you have any issue. Regards,Manideep.G","Rean,Can I get an update on when this will be completed?Thanks,Jason","Hi Matthew,The issue is resolved now. Earlier the ALB was configured to access the application on port 80. The required changes has been made on the ALB side. Please let us know if you have any issue. Thanks","Hello Matthew,We will look into this and will get back to you with an update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014ICsM,Cloud Engineer Level 1,Closed,1031852,Incident,17-11-2016 02:50,,"Hello Steven,Thanks for the update.###We were performing some tests and caused the issue. You can mark this closed now.###Hello SpendHQ-Team,We didn't hear back from you. Please let us know if your team performed any activity from your end.###Hello SpendHQ-Team,We would like to notify you that the alert regarding detected error on SpendHQ got recovered now.  On further analysis we could see the error messages in Apache log files at the time of the alert. Please see the attached text file for the error reports.Also please let us know if you have performed any activity from your end.###Hello Team,We would like to inform you that we got site down alert for the URL https://preview.spendhq.com/login.While accessing the URL we got the following error message.Warning (512): Cache not configured properly. Please check Cache::config(); in APP/config/core.php [CORE/cake/libs/configure.php, line 408]Notice (8): Undefined index: prefix [CORE/cake/libs/configure.php, line 416] Fatal error: Call to a member function get() on null in /var/www/vhosts/secure.spendhq.com/public/cake/libs/cache/redis.php on line 135We also see that sng user is logged in to the system Please let us know if you are performing any activity from your end.","Tue, 15 Nov 2016 18:22:34 -0500Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Frankfurt DE, London UK, Sydney-C AU, Dallas-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,16-11-2016 04:52,22,0,SpendHQ,"Hello Steven,Thanks for the update.",We were performing some tests and caused the issue. You can mark this closed now.,"Hello SpendHQ-Team,We didn't hear back from you. Please let us know if your team performed any activity from your end.","Hello SpendHQ-Team,We would like to notify you that the alert regarding detected error on SpendHQ got recovered now.  On further analysis we could see the error messages in Apache log files at the time of the alert. Please see the attached text file for the error reports.Also please let us know if you have performed any activity from your end.","Hello Team,We would like to inform you that we got site down alert for the URL https://preview.spendhq.com/login.While accessing the URL we got the following error message.Warning (512): Cache not configured properly. Please check Cache::config(); in APP/config/core.php [CORE/cake/libs/configure.php, line 408]Notice (8): Undefined index: prefix [CORE/cake/libs/configure.php, line 416] Fatal error: Call to a member function get() on null in /var/www/vhosts/secure.spendhq.com/public/cake/libs/cache/redis.php on line 135We also see that sng user is logged in to the system Please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000018I9Fq,Cloud Engineer Level 1,Closed,1043229,Incident,16-02-2017 11:58,,We are following this on 1043214,"Thu, 16 Feb 2017 00:36:43 -0500Detected Error on SpendHQEstimated Downtime: 1 minute 59 seconds https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: --------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, California US, London UK, Dallas-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,16-02-2017 11:06,1,0,SpendHQ,We are following this on 1043214,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C4Mox,Cloud Engineer Level 1,Closed,1055865,Incident,24-05-2017 18:52,,"Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.123 which belongs to the Secure ELB. On further analysing the ELB logs at the time of the alert, We are able to figure out one IP 138.128.9.140 which belongs to the organisation B2 Net Solutions and country United States was trying to execute the SERVER-APACHE Apache Struts remote code. Please find the ELB logs details below, 2017-05-24T10:42:49.456517Z Secure-SpendHQ-ELB 138.128.9.140:61328 10.59.1.192:443 0.000059 0.133744 0.00004 404 404 0 6755 GET https://secure.spendhq.com:443/wp-login.php?action=login HTTP/1.1 Opera/9.80 (Windows NT 6.2; Win64; x64) Presto/2.12.388 Version/12.17 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Please let us know whether we need to block this IP in the NACL level and let us know if you have any queries.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41819Time...........: 2017-05-24 10:48:10Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.111Source port: 1386 (checksum)Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 193 days 3 hours 2 minutesSystem Load        : 0.10,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,24-05-2017 17:50,1,0,SpendHQ,"Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.123 which belongs to the Secure ELB. On further analysing the ELB logs at the time of the alert, We are able to figure out one IP 138.128.9.140 which belongs to the organisation B2 Net Solutions and country United States was trying to execute the SERVER-APACHE Apache Struts remote code. Please find the ELB logs details below, 2017-05-24T10:42:49.456517Z Secure-SpendHQ-ELB 138.128.9.140:61328 10.59.1.192:443 0.000059 0.133744 0.00004 404 404 0 6755 GET https://secure.spendhq.com:443/wp-login.php?action=login HTTP/1.1 Opera/9.80 (Windows NT 6.2; Win64; x64) Presto/2.12.388 Version/12.17 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Please let us know whether we need to block this IP in the NACL level and let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DnWSM,Cloud Engineer Level 1,Closed,1065471,Incident,28-06-2017 21:56,,"Hi Team,This is to inform you that  volume usage alert for PROD-SPHQ-DB-SERVER05 instance got resolved and returned to a normal value of 79% and violation lasted for 2hours 30 minutes.###Hi Team,On further analysis, we were able to figure out that the device /dev/xvda1 volume mounted on root is consuming high volume usage on this instance. Please find the disk usage details./ usage:47G     total18G     usr17G     tmp12G     varusage on /tmp :9.6G    liger_view_b00af241d15276550e8f8e7d48365f9d.csv1.8G    liger_view_943ef6f4f72be240b2622fcfa122d988.csv1.8G    liger_view_74a8f737e4372ace3c2bb5b206c7ab49.csv681M    liger_view_88bc10275df0e433204152a39b33d224.csv637M    liger_view_5cd48d190da1ed1cb97af2d7fb909a47.csvusage on /usr :16G     local882M    share813M    lib130M    lib64Delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.###Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 91.31This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3932473971135485553 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,28-06-2017 18:59,3,0,SpendHQ,"Hi Team,This is to inform you that  volume usage alert for PROD-SPHQ-DB-SERVER05 instance got resolved and returned to a normal value of 79% and violation lasted for 2hours 30 minutes.","Hi Team,On further analysis, we were able to figure out that the device /dev/xvda1 volume mounted on root is consuming high volume usage on this instance. Please find the disk usage details./ usage:47G     total18G     usr17G     tmp12G     varusage on /tmp :9.6G    liger_view_b00af241d15276550e8f8e7d48365f9d.csv1.8G    liger_view_943ef6f4f72be240b2622fcfa122d988.csv1.8G    liger_view_74a8f737e4372ace3c2bb5b206c7ab49.csv681M    liger_view_88bc10275df0e433204152a39b33d224.csv637M    liger_view_5cd48d190da1ed1cb97af2d7fb909a47.csvusage on /usr :16G     local882M    share813M    lib130M    lib64Delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.","Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TAmrf,Cloud Engineer Level 1,Closed,1093956,Incident,22-03-2018 06:52,,"Hello Team,The alert regarding network in/out alerts for the instances prod-sphq-sophos-utm-vpn01 got recovered. At this time we are marking this case as resolved.###Hello SpendHQ Team, This is to notify you that we are receiving multiple high network in/out alerts for the instances prod-sphq-sophos-utm-vpn01.Please find the attachment for network details.Below are the Instance details: Instance name: PROD-SPHQ-SOPHOS-UTM-VPN01 Instance Id: i-02d1a63672fb172f4 VPC Id: vpc-76df7212 Subnet ID: subnet-01596c2a Instance type: m3.xlarge From AWS level, we could see that there is no abnormal activity. Kindly validate these details and let us know if it is an expected behavior and let us know if you have queries.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Thu, Mar 22, 2018 at 3:17 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host -prod-sphq-sophos-utm-vpn01 - - firewallTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Network OUT on host -prod-sphq-sophos-utm-vpn01 - - firewallHigh Network OUT on the instance. Please check the list open TCPConnections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024199?to_ts=1521668849000&group=host%3Ai-02d1a63672fb172f4&from_ts=1521668249000>*aws.ec2.network_out* over *datadog_monitor:on,host:i-02d1a63672fb172f4*was *> 536870912.0* at all times during the *last 10m*.The monitor was last triggered at Wed Mar 21 2018 21:47:39 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024199?group=host%3Ai-02d1a63672fb172f4>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024199/edit>] · [Viewi-02d1a63672fb172f4<https://app.datadoghq.com/infrastructure?hostname=i-02d1a63672fb172f4>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1521668859000&tags=host%3Ai-02d1a63672fb172f4&from_ts=1521667959000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4318555971855290598>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - prod-sphq-sophos-utm-vpn01 - - firewall,,22-03-2018 03:37,4,0,SpendHQ,"Hello Team,The alert regarding network in/out alerts for the instances prod-sphq-sophos-utm-vpn01 got recovered. At this time we are marking this case as resolved.","Hello SpendHQ Team, This is to notify you that we are receiving multiple high network in/out alerts for the instances prod-sphq-sophos-utm-vpn01.Please find the attachment for network details.Below are the Instance details: Instance name: PROD-SPHQ-SOPHOS-UTM-VPN01 Instance Id: i-02d1a63672fb172f4 VPC Id: vpc-76df7212 Subnet ID: subnet-01596c2a Instance type: m3.xlarge From AWS level, we could see that there is no abnormal activity. Kindly validate these details and let us know if it is an expected behavior and let us know if you have queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eMSVG,IT Management,Closed,1107103,Incident,19-11-2018 06:35,,"Hello Chris, We haven't heard back from you regarding the case. For continued support regarding the same issue, you can contact us any time. At this time we are marking this case closed and let us know if you have any queries related to it.###Hello Team,This is a quick follow up.We have done with your request and sent you a reset password link from REANCLOUD/SALESFORCE website. Could you please check and confirm whether we are good to close this case.###Hello Team,This is a gentle reminder.We have completed your request and sent you a reset password link from REANCLOUD/SALESFORCE website. Please check and let us know if are facing any issues. And please confirm that whether we are good to close this case.###Hi Chris, This is a gentle reminder.We have sent you a reset password link from REANCLOUD/SALESFORCE wesite. Kindly check if it allows you to set up a new password. If you are still facing the issue, will go on a call to resolve it.###Hi Chris,We have sent you a reset password link from REANCLOUD/SALESFORCE wesite. Kindly check if it allows you to set up a new password. If you are still facing issue, will go on a call to resolve it.Regards/Chirodeep###@TeamCheck with Chirodeep to reset the password###Thenmozhy D6:49 PM (0 minutes ago)to Chris, spendhq-supportHello Chris,Thanks for the confirmation.We will reset your password for the ticketing system and will get back to you.###Hello Chris,Can you please confirm that are you facing the issue with our ticketing system?Thanks & Regards,Thenmozhy D","---------- Forwarded message ---------From: Chris Veillette <cveillette@andromeda3.com>Date: Fri, Nov 2, 2018 at 6:33 PMSubject: case : I-01106916.To: spendhq-support@reancloud.com <spendhq-support@reancloud.com>my password expired -I try and reset it - i get a reset email, click on it,then it  dumps back to the same page -meaning it sends me *another* emailwhich then sends me another email to reset my password.......an endlessloop...!!*Chris Veillette**CIO*[image: 1450833261212_7186d8e7bdbb48853119db07d964f770.jpg]www.Andromeda3.comcveillette@andromeda3.com*Mobile:* 703.447.4124*Office: *  571.781.0428--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",case : I-01106916.,,02-11-2018 18:38,396,0,SpendHQ,"Hello Chris, We haven't heard back from you regarding the case. For continued support regarding the same issue, you can contact us any time. At this time we are marking this case closed and let us know if you have any queries related to it.","Hello Team,This is a quick follow up.We have done with your request and sent you a reset password link from REANCLOUD/SALESFORCE website. Could you please check and confirm whether we are good to close this case.","Hello Team,This is a gentle reminder.We have completed your request and sent you a reset password link from REANCLOUD/SALESFORCE website. Please check and let us know if are facing any issues. And please confirm that whether we are good to close this case.","Hi Chris, This is a gentle reminder.We have sent you a reset password link from REANCLOUD/SALESFORCE wesite. Kindly check if it allows you to set up a new password. If you are still facing the issue, will go on a call to resolve it.","Hi Chris,We have sent you a reset password link from REANCLOUD/SALESFORCE wesite. Kindly check if it allows you to set up a new password. If you are still facing issue, will go on a call to resolve it.Regards/Chirodeep",@TeamCheck with Chirodeep to reset the password,"Thenmozhy D6:49 PM (0 minutes ago)to Chris, spendhq-supportHello Chris,Thanks for the confirmation.We will reset your password for the ticketing system and will get back to you.","Hello Chris,Can you please confirm that are you facing the issue with our ticketing system?Thanks & Regards,Thenmozhy D",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DljKM,Cloud Engineer Level 1,Closed,1064169,Incident,22-06-2017 06:23,,"Hello SpendHQ-Team, The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and volume usage reached to a value of 87%.###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 ext4 50G 47G 55M 100% / Files under root directory, 20G tmp 15G usr 12G var 510M home 285M lib 282M opt Files under /tmp folder, 20G     total1.5G    liger_view_63f979ff50c2b7909d597a89a4ee2536.csv1.2G    liger_view_f8a3db67f3503695f4fc1cf3789e7b47.csv1.2G    liger_view_a2f823a28d38fd880b2e20c6cf9b69af.csv920M    liger_view_96af673b981d7e58e2bbc166ffa285c5.csv920M    liger_view_1f298ca7f2a6e8fc53bfaceff1ca9c41.csv897M    liger_view_fca31c82ac2f94e1a93a38746b82c36e.csv897M    liger_view_5962b3cce6ee9f7f40a2e401d09496c0.csv896M    liger_view_467282af40dbe9dbef2d619d1141ae7d.csv833M    liger_view_9529ca526803fd4cf952152781f289be.csv833M    liger_view_54451efdd16ebf36c7f3494814da20cf.csv833M    liger_view_09edb01c859c06ddecb1cc659a6702ea.csv800M    liger_view_f57149c9c33e8266e1b1f59b939a5827.csv769M    liger_view_f47058d94522e5ab35555eb90fdea140.csv769M    liger_view_7b8963516c4ba91b6a3d37945258b76b.csv705M    liger_view_d7803b83619071bcf4ccea035ecdf216.csv705M    liger_view_403fce72f22c39e8f6b136dc2f7ab00c.csv577M    liger_view_f1f0eae3a73193f88af4c2a7f436b44c.csv500M    liger_view_54b8fa674525c1f696db9a309fa28272.csv491M    liger_view_6a622ed1ed6dc734c9e7a22684cb6664.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Thu, Jun 22, 2017 at 4:13 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjbsOgkAQRb-G7SQzszyk2MKAxMTaQhsz7gNIgEVYCv_eJbnFyU3OvUbl1ceKQRFgCQUhUSapSksEpBTbWtbXHJomgzavqiQDE0yXai96hWykY6eRC3cmdhYIz8Amt5HKshCj6kNYtkReEmpjeFlSw4GN7_pv3JiOTmu_zyHSsno3jDbSfoIX1O_77_nA2y5WNW3xeLU869Hv5jBFUJOfh-DXP0lpOmc>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj8uOwyAMRb8GlsiYV1iwGCXDb1Q0kIfUlAyhVT9_SDSLkSw_ruWj6-iUvSe6OgRuQCNHlAItMxw4Mu570X8rGAYJXllLJMQaZzZmujiuA8jurgJKk2SQyUSYJhhT0FOSkOjDLbXuBxFfBH2LsO8shhpinpefxtiatuXnWnM5CAoEFFZbInzNt9rOBi5tB520xgIAQT2X_NqbHtN7HRNBdZIV-jZf9fOOgZ9dv-SjXnsOTFnWMheqEaaSt_9sYS42LW472nMlhef4yK94uqPV_bn7BVCpU0U>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Wed Jun 21 2017 22:43:00 UTC (*28 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtTsuOgzAM_JrkGNnOg_qQwwqW_whJFpBKQyGt9vM3VCuN7BlbmpnkLU9Zrp4AO3CEREYTqw4BSeHY6_7bwjAYGC2zMJBqmlUscvGTC5xjBKIbunwzE9ifDplTimSInbz7pdb9FPpL0NgQ9l2lUEMq8_JsHlu7beWx1nKcgjQBaXYs9Dgf5bULPaT8XmMWZC8HS2PTn_37TgEv1i_lrJ8_grKs2kRt5eG3s1U9cnjEe3mlK0tW_5_1B6IqRdE>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjUEOgyAQRU8DSzMMA5YFi0brPYChaqLFKr1_adLkr17y3mdvXMxy9QiqB4sKkTS6rlegsFPToIeHgXEkmIxzgoArz10qcvGgYr4lgMj9kykmtpmyIW2jpUwqyc0vtR6X0HeBU1s4jo5DDVzm5d0ae2N7ea21nJdAjYDaWddg5rXK0-9X-ztzeKWtfPgnyOr_whcpQjas>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVjUsOgzAQQ09DltF8CDSLLCoo9xgIFKRCaBju31SyLOtJtmNwfpzNFgiwhYaQqGbytkVAsjh03L0c9H0Ng_O-qiFqfNspmTUgt41_iIv8EI408eibcYRldkJAiOYTVtXzqvhZ0VAk52mjqMT0Xr9lYy9sO5Ysl-Z70jvPFQ9ruvSQvcQewTpviyM7k8N-lfs8yzF90h3_faNhT8emKf8ARp07Hw>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jcEOgyAQRL9GjmbZBWEPHBot_0FdWk2qWKX9_tpLJ5NM8pKZkWD5ltUcELSDDjWiIeTWadDY6thTf7UwDAaiZW4MSJVHOxY1BWTOQskJ-C4nfe8M_GRGcbcRvFfPMNW6HQ1dGoyn07a1kmqS8phe58ZysvzJa_0nxVkaGogRvTeWUVtwHohJ7WE5zvs9p3V8lrf8-qqGpaxzLfsX1Rw5Bw>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjUsOhCAQRE8jS9I0MsiCxUTHe_BpP8kIDuL9B5NaVF4qr6JVxhPbLYLQ8EKB2Es0XAsQyMU8yvGjYJp6mJUxXQ-xxpWHzDbbEw3egFtkBC3jghgGT16BEV6RRva1W63n1cl3h3OLO08eXXUxr9uvOY6HhZDvVFs7Cy1UKAW6WLHH1b4KuRS--Y7PmFV75LTXXP6FMjbq>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,22-06-2017 04:44,2,0,SpendHQ,"Hello SpendHQ-Team, The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and volume usage reached to a value of 87%.","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 ext4 50G 47G 55M 100% / Files under root directory, 20G tmp 15G usr 12G var 510M home 285M lib 282M opt Files under /tmp folder, 20G     total1.5G    liger_view_63f979ff50c2b7909d597a89a4ee2536.csv1.2G    liger_view_f8a3db67f3503695f4fc1cf3789e7b47.csv1.2G    liger_view_a2f823a28d38fd880b2e20c6cf9b69af.csv920M    liger_view_96af673b981d7e58e2bbc166ffa285c5.csv920M    liger_view_1f298ca7f2a6e8fc53bfaceff1ca9c41.csv897M    liger_view_fca31c82ac2f94e1a93a38746b82c36e.csv897M    liger_view_5962b3cce6ee9f7f40a2e401d09496c0.csv896M    liger_view_467282af40dbe9dbef2d619d1141ae7d.csv833M    liger_view_9529ca526803fd4cf952152781f289be.csv833M    liger_view_54451efdd16ebf36c7f3494814da20cf.csv833M    liger_view_09edb01c859c06ddecb1cc659a6702ea.csv800M    liger_view_f57149c9c33e8266e1b1f59b939a5827.csv769M    liger_view_f47058d94522e5ab35555eb90fdea140.csv769M    liger_view_7b8963516c4ba91b6a3d37945258b76b.csv705M    liger_view_d7803b83619071bcf4ccea035ecdf216.csv705M    liger_view_403fce72f22c39e8f6b136dc2f7ab00c.csv577M    liger_view_f1f0eae3a73193f88af4c2a7f436b44c.csv500M    liger_view_54b8fa674525c1f696db9a309fa28272.csv491M    liger_view_6a622ed1ed6dc734c9e7a22684cb6664.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Fcy4d,Cloud Engineer Level 1,Closed,1072602,Incident,10-08-2017 23:58,,"Hello SpendHQ-Team,Please find the attached RCA and let us know if you have any further queries regarding this.###Hello Andrew,Thanks for the response.We are currently preparing the RCA and we will be sharing it with you shortly.###Thank you. You may close this ticket###Hello Team,Please review the findings provided and let us know if you have any further queries.###Yogesh informed he will review.Next action:Please check with yogesh for any next actions###Hello Team,On further analysis, we found the below details:From the ELB level, there was high latency observed at the time of the alert. The request count was also high. The backend processing time has reached to value of 300s. Please review the graphs attached for more details.From the instance level, we could see a number of connections in TIME_WAIT state. There was 868 connections were in TIME_WAIT state at the time of the alert. The connections made to the DB went to this TIME_WAIT state. Please see the connection details below:[root@ip-10-59-100-170 httpd]# netstat -tunlpa | grep TIME_WAIT | wc -l868Please review a snippet of TIME_WAIT connections observed in webserver.[root@ip-10-59-100-170 httpd]# netstat -tunlpa | grep TIME_WAITtcp        0      0 10.59.100.170:33672         10.59.10.12:6379            TIME_WAIT   -tcp        0      0 10.59.100.170:52848         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:52344         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:43154         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:52912         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:43448         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:43642         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:42872         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:42176         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:53984         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:60892         10.59.10.12:6379            TIME_WAIT   -tcp        0      0 10.59.100.170:43738         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:43690         169.254.169.254:80          TIME_WAIT   -tcp        0      0 10.59.100.170:53418         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:52502         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:43700         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:53734         10.59.10.135:5030           TIME_WAIT   -----The backend database instance experienced a high CPU load. The CPU load has reached a value of 23.18. Please review the graphs attached for CPU load. The Network IN/OUT went high for the database instance.We recommend enabling the fast recycling by setting TCP_TW_RECYCLE and also reuse of connections TCP_TW_REUSE kernel parameters to “1”. We request your developers to look into database connections and ensure they are closed properly.###Hello Team,On initial analysis, we could see that there was high latency at the time of the alert.  The request count was also high at the ELB level.  The metrics of the web server was normal. The backend instance experienced a high CPU load at the time of the alert .The site is up and running fine.We are still analyzing more on this and will provide you the updates.###Hello Team, This is to inform you that we received a site down alert for the URL https://secure.spendhq.com/login. The alert got recovered within 3 minutes and the site is well accessible now. We will analyze the issue from our end and meanwhile please let us know if your team has performed any activity from your end.","Wed, 09 Aug 2017 21:12:26 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): California US, Frankfurt DE, Sydney-C AU, London UK-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,10-08-2017 06:42,18,0,SpendHQ,"Hello SpendHQ-Team,Please find the attached RCA and let us know if you have any further queries regarding this.","Hello Andrew,Thanks for the response.We are currently preparing the RCA and we will be sharing it with you shortly.",Thank you. You may close this ticket,"Hello Team,Please review the findings provided and let us know if you have any further queries.",Yogesh informed he will review.Next action:Please check with yogesh for any next actions,"Hello Team,On further analysis, we found the below details:From the ELB level, there was high latency observed at the time of the alert. The request count was also high. The backend processing time has reached to value of 300s. Please review the graphs attached for more details.From the instance level, we could see a number of connections in TIME_WAIT state. There was 868 connections were in TIME_WAIT state at the time of the alert. The connections made to the DB went to this TIME_WAIT state. Please see the connection details below:[root@ip-10-59-100-170 httpd]# netstat -tunlpa | grep TIME_WAIT | wc -l868Please review a snippet of TIME_WAIT connections observed in webserver.[root@ip-10-59-100-170 httpd]# netstat -tunlpa | grep TIME_WAITtcp        0      0 10.59.100.170:33672         10.59.10.12:6379            TIME_WAIT   -tcp        0      0 10.59.100.170:52848         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:52344         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:43154         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:52912         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:43448         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:43642         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:42872         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:42176         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:53984         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:60892         10.59.10.12:6379            TIME_WAIT   -tcp        0      0 10.59.100.170:43738         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:43690         169.254.169.254:80          TIME_WAIT   -tcp        0      0 10.59.100.170:53418         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:52502         10.59.10.135:5030           TIME_WAIT   -tcp        0      0 10.59.100.170:43700         10.59.10.135:5029           TIME_WAIT   -tcp        0      0 10.59.100.170:53734         10.59.10.135:5030           TIME_WAIT   -----The backend database instance experienced a high CPU load. The CPU load has reached a value of 23.18. Please review the graphs attached for CPU load. The Network IN/OUT went high for the database instance.We recommend enabling the fast recycling by setting TCP_TW_RECYCLE and also reuse of connections TCP_TW_REUSE kernel parameters to “1”. We request your developers to look into database connections and ensure they are closed properly.","Hello Team,On initial analysis, we could see that there was high latency at the time of the alert.  The request count was also high at the ELB level.  The metrics of the web server was normal. The backend instance experienced a high CPU load at the time of the alert .The site is up and running fine.We are still analyzing more on this and will provide you the updates.","Hello Team, This is to inform you that we received a site down alert for the URL https://secure.spendhq.com/login. The alert got recovered within 3 minutes and the site is well accessible now. We will analyze the issue from our end and meanwhile please let us know if your team has performed any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001NPsDT,Cloud Engineer Level 1,Closed,1088039,Incident,10-01-2018 03:07,,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM###Send closure email at the end of night shift hours(9th Jan 2018) in case of no response from the customer.###Hello Matthew, This is a gentle reminder. We haven't heard back from you regarding this case.We have verified that the EBS volume is still mounted on the 10.59.10.17 server. | => df -Th /dev/xvdf ext4 493G 171M 467G 1% /mnt/test2 Please verify the above details and let us know if you have any queries.###Hello Matthew, This is a gentle reminder.We haven't heard back from you regarding this case.Please verify the below details and let us know if you have any queries.###Hello Matthew, We haven't heard back from you! We have verified the case created on November 20th and we could see the volume we created for 10.59.10.17 server on that day was an EBS volume and not an ISCSI. Refer the case id: 01084907. We have verified that the EBS volume is still mounted on the 10.59.10.17 server. | => df -Th /dev/xvdf ext4 493G 171M 467G 1% /mnt/test2 Please verify the above details and let us know if you have any queries.###Hello Matthew,We have verified the case created on November 20th and we could see the volume we created for 10.59.10.17 server on that day was an EBS volume and not an ISCSI. Refer the case id: 01084907.We have verified that the EBS volume is still mounted on the 10.59.10.17 server.| => df -Th/dev/xvdf      ext4   493G  171M  467G   1% /mnt/test2Please verify the above details and let us know if you have any queries.###Hello Matthew,We are looking into it and will get back to you with an update.","REAN,A request was placed on the 20th November 2017 to create a ISCSI volume for the 10.59.10.17 server, however this could not be located. Whilst on the call with REAN and A3 we were unable to recover this volume after a restart.We need this volume as it contains data that is critical to operations. Please retrieve the data and mount it to /mnt/17_latest when you have done so.If you have any questions, then please do not hesitate to let me know.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://www.reancloud.com/news/rean-cloud-named-partner-newly-launched-aws-alexa-business/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SEV ONE: Data Loss,,06-01-2018 09:35,90,0,SpendHQ,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM",Send closure email at the end of night shift hours(9th Jan 2018) in case of no response from the customer.,"Hello Matthew, This is a gentle reminder. We haven't heard back from you regarding this case.We have verified that the EBS volume is still mounted on the 10.59.10.17 server. | => df -Th /dev/xvdf ext4 493G 171M 467G 1% /mnt/test2 Please verify the above details and let us know if you have any queries.","Hello Matthew, This is a gentle reminder.We haven't heard back from you regarding this case.Please verify the below details and let us know if you have any queries.","Hello Matthew, We haven't heard back from you! We have verified the case created on November 20th and we could see the volume we created for 10.59.10.17 server on that day was an EBS volume and not an ISCSI. Refer the case id: 01084907. We have verified that the EBS volume is still mounted on the 10.59.10.17 server. | => df -Th /dev/xvdf ext4 493G 171M 467G 1% /mnt/test2 Please verify the above details and let us know if you have any queries.","Hello Matthew,We have verified the case created on November 20th and we could see the volume we created for 10.59.10.17 server on that day was an EBS volume and not an ISCSI. Refer the case id: 01084907.We have verified that the EBS volume is still mounted on the 10.59.10.17 server.| => df -Th/dev/xvdf      ext4   493G  171M  467G   1% /mnt/test2Please verify the above details and let us know if you have any queries.","Hello Matthew,We are looking into it and will get back to you with an update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001YMCLU,Cloud Engineer Level 1,Closed,1100933,Incident,11-07-2018 06:39,,"Hello Team,We still haven't heard back from you.As this is already resolved we are closing the case.Please note that you can always get in touch with us for any clarifications.Thanks###Hello Team, We haven't heard back from you. From the logs there are 3 kinds of errors Identified: 1. Not allowed because not listed in AllowUsers/input_userauth_request: invalid user centos For this case its not clear why this error was being raised because when checking contents of /etc/ssh/sshd_config we could see AllowUsers mwatts centos dmackay. In our case we were using centos as the user which should have worked perfectly. 2. No supported authentication methods available This may have been caused due incorrect permissions to the private key being used when logging in. 3. Postponed publickey. May have been caused by User trying to access the server via SSH, but before the public key was accepted it tried with other methods of authentication (publickey,gssapi-with-mic,password)###Hello Team,This is a gentle reminder.Please review our previous comment and let us know if in case you have any query.###Hello Team, We haven't heard back from you. From the logs there are 3 kinds of errors Identified: 1. Not allowed because not listed in AllowUsers/input_userauth_request: invalid user centos For this case its not clear why this error was being raised because when checking contents of /etc/ssh/sshd_config we could see AllowUsers mwatts centos dmackay. In our case we were using centos as the user which should have worked perfectly. 2. No supported authentication methods available This may have been caused due incorrect permissions to the private key being used when logging in. 3. Postponed publickey. May have been caused by User trying to access the server via SSH, but before the public key was accepted it tried with other methods of authentication (publickey,gssapi-with-mic,password)###Hello Team,We haven't heard back from you.Please review our previous comments and let us know if you have any queries.###From the logs there are 3 kinds of errors Identified:1. Not allowed because not listed in AllowUsers/input_userauth_request: invalid user centosFor this case its not clear why this error was being raised because when checking contents of /etc/ssh/sshd_config we could see AllowUsers mwatts centos dmackay. In our case we were using centos as the user which should have worked perfectly.2. No supported authentication methods availableThis may have been caused due incorrect permissions to the private key being used when logging in.3. Postponed publickey.May have been caused  by User trying to access the server via SSH, but before the public key was accepted it tried with other methods of authentication (publickey,gssapi-with-mic,password)###Find the logs to the failed SSH logins in the attachment section.###Hello Matthew,We are now able to log in to the instance. The alert is also recovered with a current value of 13.###Hello Matthew,The username is Centos and keypair name: Instance.pem. We are still not able to login into the instance. Can you please check from your end.###@Team:Provide the info to Mathew that we tried to ssh to this instance using keypair and username Centos. Do follow up.###I have pinged rohit for this please ask him if there is any action required.###Jamelunissa Mohammed <jamelunissa.mohammed@reancloud.com>9:36 PM (3 hours ago)to REAN, Matthew, Andrew, David, Dusty, Allen Hello Matthew,The username is centos.###From Matthew Watts REAN, What username do you login as REAN?###Andrew Kim6:42 PM (2 minutes ago)to Rean, spendhq-support Please do NOT reboot this server at this time. We are investigating. Thank you,###Team, analyze why we are not able to login to this server.###Hello Team,We have received the alert regarding high CPU Utilization on the host prd-sv1(10.59.100.193). We are not able to login to the server to further analysis on this issue.Please provide an approval to perform the reboot on this instance.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Fri, Jun 29, 2018 at 2:58 PMSubject: [Monitor Alert] No data: [SpendHQ] - High CPU Utilization on thehost prd-sv1 - 10.59.100.193 -To: REANCloud Support <ms@reancloud.com>[image: Datadog][No data] [SpendHQ] - High CPU Utilization on the host prd-sv1 -10.59.100.193 -@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>*host:i-048e66836110e8d7b* has been missing data for the *last 10m*The monitor was last triggered at Fri Jun 29 2018 09:28:29 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024189?group=host%3Ai-048e66836110e8d7b>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024189/edit>] · [Viewi-048e66836110e8d7b<https://app.datadoghq.com/infrastructure?filter=i-048e66836110e8d7b>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1530264509000&tags=host%3Ai-048e66836110e8d7b&from_ts=1530263609000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4462767042007699511>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] No data: [SpendHQ] - High CPU Utilization on the host prd-sv1 - 10.59.100.193 -,,02-07-2018 16:13,206,0,SpendHQ,"Hello Team,We still haven't heard back from you.As this is already resolved we are closing the case.Please note that you can always get in touch with us for any clarifications.Thanks","Hello Team, We haven't heard back from you. From the logs there are 3 kinds of errors Identified: 1. Not allowed because not listed in AllowUsers/input_userauth_request: invalid user centos For this case its not clear why this error was being raised because when checking contents of /etc/ssh/sshd_config we could see AllowUsers mwatts centos dmackay. In our case we were using centos as the user which should have worked perfectly. 2. No supported authentication methods available This may have been caused due incorrect permissions to the private key being used when logging in. 3. Postponed publickey. May have been caused by User trying to access the server via SSH, but before the public key was accepted it tried with other methods of authentication (publickey,gssapi-with-mic,password)","Hello Team,This is a gentle reminder.Please review our previous comment and let us know if in case you have any query.","Hello Team, We haven't heard back from you. From the logs there are 3 kinds of errors Identified: 1. Not allowed because not listed in AllowUsers/input_userauth_request: invalid user centos For this case its not clear why this error was being raised because when checking contents of /etc/ssh/sshd_config we could see AllowUsers mwatts centos dmackay. In our case we were using centos as the user which should have worked perfectly. 2. No supported authentication methods available This may have been caused due incorrect permissions to the private key being used when logging in. 3. Postponed publickey. May have been caused by User trying to access the server via SSH, but before the public key was accepted it tried with other methods of authentication (publickey,gssapi-with-mic,password)","Hello Team,We haven't heard back from you.Please review our previous comments and let us know if you have any queries.","From the logs there are 3 kinds of errors Identified:1. Not allowed because not listed in AllowUsers/input_userauth_request: invalid user centosFor this case its not clear why this error was being raised because when checking contents of /etc/ssh/sshd_config we could see AllowUsers mwatts centos dmackay. In our case we were using centos as the user which should have worked perfectly.2. No supported authentication methods availableThis may have been caused due incorrect permissions to the private key being used when logging in.3. Postponed publickey.May have been caused  by User trying to access the server via SSH, but before the public key was accepted it tried with other methods of authentication (publickey,gssapi-with-mic,password)",Find the logs to the failed SSH logins in the attachment section.,"Hello Matthew,We are now able to log in to the instance. The alert is also recovered with a current value of 13.","Hello Matthew,The username is Centos and keypair name: Instance.pem. We are still not able to login into the instance. Can you please check from your end.",@Team:Provide the info to Mathew that we tried to ssh to this instance using keypair and username Centos. Do follow up.,I have pinged rohit for this please ask him if there is any action required.,"Jamelunissa Mohammed <jamelunissa.mohammed@reancloud.com>9:36 PM (3 hours ago)to REAN, Matthew, Andrew, David, Dusty, Allen Hello Matthew,The username is centos.","From Matthew Watts REAN, What username do you login as REAN?","Andrew Kim6:42 PM (2 minutes ago)to Rean, spendhq-support Please do NOT reboot this server at this time. We are investigating. Thank you,","Team, analyze why we are not able to login to this server.","Hello Team,We have received the alert regarding high CPU Utilization on the host prd-sv1(10.59.100.193). We are not able to login to the server to further analysis on this issue.Please provide an approval to perform the reboot on this instance.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ZiGfW,Cloud Engineer Level 1,Closed,1102271,Incident,03-08-2018 01:49,,"Hello Team,This is to inform you that the alert regarding the High CPU Load for the following instance got recovered and the violation lasted for 1 hour.spendhq-memsql-server3-2018-04-01 - 10.59.100.230spendhq-memsql-server2-2018-04-01 - 10.59.100.171spendhq-memsql-server1-2018-04-01 - 10.59.100.191As the alert in recovered state, we are marking this case as resolved hence closing this case. Kindly revert back to us in case of any queries.###Hello TeamWe are receiving multiple alerts on High CPU Load on host spendhq-memsql-server1-2018-04-01 - 10.59.100.191  for 2 servers.spendhq-memsql-server3-2018-04-01 - 10.59.100.230 spendhq-memsql-server2-2018-04-01 - 10.59.100.171spendhq-memsql-server1-2018-04-01 - 10.59.100.191The alerts are been recovered within a few minutes. We are analyzing and wil get back to you with updates, However, kindly let us know if you are performing any action. However we analyzing","Stephen KimaniJunior Cloud Engineerreancloud.com---------- Forwarded message ----------From: Datadog Alerting <alert@dtdg.co>Date: Thu, Aug 2, 2018 at 6:51 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on hostspendhq-memsql-server1-2018-04-01 - 10.59.100.191 -To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High CPU Load on host spendhq-memsql-server1-2018-04-01- 10.59.100.191 -Detected High CPU load. Log in to the machine and verify which process isconsuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023975?to_ts=1533225105000&group=host%3Ai-073579ff33c73d3cd&from_ts=1533217905000>*system.load.15* over *datadog_monitor:on,host:i-073579ff33c73d3cd* was *>4.0* on average during the *last 30m*.The monitor was last triggered at Thu Aug 02 2018 15:51:55 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023975?group=host%3Ai-073579ff33c73d3cd>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023975/edit>] · [Viewi-073579ff33c73d3cd<https://app.datadoghq.com/infrastructure?filter=i-073579ff33c73d3cd>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1533225115000&tags=host%3Ai-073579ff33c73d3cd&from_ts=1533224215000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4512437769181290172>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on host spendhq-memsql-server1-2018-04-01 - 10.59.100.191 -,,02-08-2018 21:30,4,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding the High CPU Load for the following instance got recovered and the violation lasted for 1 hour.spendhq-memsql-server3-2018-04-01 - 10.59.100.230spendhq-memsql-server2-2018-04-01 - 10.59.100.171spendhq-memsql-server1-2018-04-01 - 10.59.100.191As the alert in recovered state, we are marking this case as resolved hence closing this case. Kindly revert back to us in case of any queries.","Hello TeamWe are receiving multiple alerts on High CPU Load on host spendhq-memsql-server1-2018-04-01 - 10.59.100.191  for 2 servers.spendhq-memsql-server3-2018-04-01 - 10.59.100.230 spendhq-memsql-server2-2018-04-01 - 10.59.100.171spendhq-memsql-server1-2018-04-01 - 10.59.100.191The alerts are been recovered within a few minutes. We are analyzing and wil get back to you with updates, However, kindly let us know if you are performing any action. However we analyzing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DBsK8,Cloud Engineer Level 1,Closed,1062384,Incident,14-06-2017 20:31,,"We had a call with Matthew and he updated that we need to contact him directly if we witness volume usage on root hitting at 100%. Also, he informed that REAN does not want to clear any logs from this instance if we witness high volume usage. The only thing we want to do is to inform them regarding the issue.###Hello SpendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 53%. The violation lasted for 24 minutes.We could see a sudden decrease in the size of /tmp folder. We are closely monitoring on it and will keep you updated. As of now, we are marking this case as resolved. Kindly revert back incase of any queries.Regards,Sumod.K.Bose###Hello Matthew,We could still see that the volume usage on this instance is still increasing gradually. The volume usage on this instance is at 98% and the available space on this instance is about 1.3GB.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   46G  1.3G  98% /Volume usage details on this instance,25G     tmp12G     var8.0G    usr510M    home285M    lib282M    opt/tmp folder is consuming high volume usage on this instance.25G     total7.8G    liger_view_acd236eb4cc612e2f94ed2cc23080059.csv1.5G    liger_view_0df3b11227ab3ea894a0574d4bbbb025.csv1.3G    Client217SpendDataAggregate_upload.sql.gz1.1G    liger_view_d0be0bb41be7c5130fbcf5c112e427f6.csv1.1G    liger_view_b08f7bf907b545c3acfb7866eef4eed5.csvKindly validate these details and delete/zip unwanted files or folders to reduce the current volume usage state in this instance. Revert back incase of any queries.Regards,Sumod.K.Bose###This is perfect. Please always advise us of issues like this on PRD machines. Thnak you.Regards,Matthew Watts###Hello Matthew,Thanks for joining the call. As per the discussion happened, you have moved some files to a different location for resolving 100% usage on the root volume for PROD-SPHQ-DB-SERVER05(10.59.10.135). As of now, the root volume usage on this instance is at 93%.[root@ip-10-59-10-135 /]# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   44G  3.5G  93% /As we discussed, REAN Team will contact you directly if we came to figure out that the root volume is again hitting at 100%.As it is a recurring issue, please let us know what all steps can REAN take to overcome the volume usage on this instance. ie, Moving/Deleting any particular log files. From the last few days, we can see /tmp folder is consuming high volume usage on this instance.Kindly validate these details and let us know the updates. Revert back incase of any queries.Regards,Sumod.K.Bose###Hello Team,This is to inform you that the volume usage on /dev/xvda1  mounted on root for PROD-SPHQ-DB-SERVER05 instance is reached  100%. Please Zip/delete the unwanted file and folders to resolve this issue.###Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage /dev/xvda1 mounted on root for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 94%. Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1  ext4    50G   44G  3.2G  94% /44G     total21G     tmp15G     var8.0G    usr510M    home285M    lib282M    opt44M     boot30M     etc19M     lib64tmp folder usage details21G     total7.8G    liger_view_acd236eb4cc612e2f94ed2cc23080059.csv2.0G    tiger_view_e242dfa28bace2b415078b4f7307f1d3.csv.gz1.5G    liger_view_0df3b11227ab3ea894a0574d4bbbb025.csv1.3G    liger_view_caa16490a6f4c23258e135e31655eacd.csv1.3G    liger_view_63f979ff50c2b7909d597a89a4ee2536.csv1.3G    Client217SpendDataAggregate_upload.sql.gz1.1G    liger_view_d0be0bb41be7c5130fbcf5c112e427f6.csv872M    liger_view_3f9c1ad163c573e5d9b02ee4a3e0fab3.csv764M    eighty_million_view_test.csv.gz436M    liger_view_d67305ba397f263124ab78863092aa75.csv436M    liger_view_d0e49e45cf34c76c39bcb470d4f61b47.csv367M    liger_view_2d32b3c178972699268d8997969dc77b.csv353M    att_test.sql221M    spark-2.1.0-bin-hadoop2.7181M    liger_view_e8097497adfa77f3f4802d7d0cc525c7.csv121M    liger_view_261089bca64386602af8d70c65d5464e.csv103M    tyler_att.csv86M     Client424SpendData.sql.gz78M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm/var filder usage deatils15G    total9.8G    tmp2.2G    www2.1G    lib228M    log129M    cachePlease let us know if we have your approval to perform unnecessary files and folders from the SpendHQ nodes in the case of volume usage alerts if it is going high. If we have your approval, please mention the folders and files from which we can compress data in order to resolve the volume usage. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924###The answer to Sanket's query: [How the volume usage resolved]: From the instance level, it seems like the volume usage change is for the tmp directory(tmp usage was decreased from 24G to 5G). I suspect this was due to the temporary files for resolved automatically by the system.###This is to inform you that the disk utilization alert for the SpendHQ Prod node 10.59.10.135 has resolved automatically and returned to a normal value of 61% consumption. The violation lasted for 12 hours. Please refer the attachment section for the Volume usage graph from the DataDog console for the last 24 hours. The root volume usage was touching 100% consumption and it is a high priority case. Please let us know if we have your approval to perform unnecessary files and folders from the SpendHQ nodes in the case of volume usage alerts if it is going high. If we have your approval, please mention the folders and files from which we can compress data in order to resolve the volume usage. We will wait for your input before closing the case. Thank You, Safuvan KM###Hello Team,Please review the usage details and remove/zip unwanted files to reduce the current usage.[root@ip-10-59-10-135 ~]# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   46G  1.1G  98% /47G     total47G     /24G     /tmp15G     /var9.8G    /var/tmp7.7G    /usr7.1G    /var/tmp/robert_uploads5.9G    /usr/local5.8G    /usr/local/infobright-products/iee/postgres/5.0.45.8G    /usr/local/infobright-products/iee/postgres5.8G    /usr/local/infobright-products/iee5.8G    /usr/local/infobright-products5.5G    /usr/local/infobright-products/iee/postgres/5.0.4/ib_data5.2G    /usr/local/infobright-products/iee/postgres/5.0.4/ib_data/dusty/public5.2G    /usr/local/infobright-products/iee/postgres/5.0.4/ib_data/dusty2.2G    /var/www/vhosts/secure.spendhq.com2.2G    /var/www/vhosts2.2G    /var/www2.1G    /var/lib1.6G    /var/lib/memsql-ops[root@ip-10-59-10-135 tmp]# du -sch * | sort -hr | head24G     total6.0G    liger_view_b00af241d15276550e8f8e7d48365f9d.csv2.0G    tiger_view_e242dfa28bace2b415078b4f7307f1d3.csv.gz1.8G    liger_view_3e86ddd800bc8ce8ba4147f616e260cf.csv1.3G    liger_view_897aed78457b53cc02eeefbb5699955b.csv1.3G    Client217SpendDataAggregate_upload.sql.gz1.2G    liger_view_acd236eb4cc612e2f94ed2cc23080059.csv899M    liger_view_752f752b3c4db4dc52b99d38a019f6e0.csv819M    liger_view_557e26d1f2379b1da6078a97227e6078.csv764M    eighty_million_view_test.csv.gz[root@ip-10-59-10-135 tmp]# du -sch * | sort -hr | head -2023G     total6.0G    liger_view_b00af241d15276550e8f8e7d48365f9d.csv2.0G    tiger_view_e242dfa28bace2b415078b4f7307f1d3.csv.gz1.8G    liger_view_3e86ddd800bc8ce8ba4147f616e260cf.csv1.3G    Client217SpendDataAggregate_upload.sql.gz1.2G    liger_view_acd236eb4cc612e2f94ed2cc23080059.csv899M    liger_view_752f752b3c4db4dc52b99d38a019f6e0.csv819M    liger_view_557e26d1f2379b1da6078a97227e6078.csv764M    eighty_million_view_test.csv.gz436M    liger_view_34814ed89b0f3b1a8706be1d990db29d.csv430M    liger_view_1c5245e09a28f2a7e20778d27d62a3fa.csv391M    liger_view_6e222ff4464cd6f85fa0cdb9bcf2b12c.csv382M    liger_view_61718af5d827c7d99d8d51ddf727b29b.csv353M    att_test.sql323M    liger_view_3db82f98557411ed1cfdf6d673e7a5c0.csv278M    liger_view_3997fbabcbb8090be130a1ec92b108eb.csv257M    liger_view_88b4b56406dd443108ece0c07f89d241.csv257M    liger_view_6abeb0962e1d21264aded02c63eb312d.csv257M    liger_view_0b01fffb4e01c572db65264a9bff109a.csv257M    liger_view_03f28057c6f44627c27fb0651d067d5c.csv[root@ip-10-59-10-135 var]# du -sch tmp/* | sort -hr | head -209.8G    total7.1G    tmp/robert_uploads2.2G    tmp/Client287SpendData_Reporting.sql.gz269M    tmp/Client217SpendDataAggregate.sql.gz171M    tmp/yum-mwatts-ylg2M9Please let us know if you have any queries regarding this.###Hello Team,This is to notify you that the alert regarding volume usage for PROD-SPHQ-DB-SERVER05 instance has reached to 100%. Please delete/zip unwanted files to resolve the issue.###Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage /dev/xvda1 mounted on root for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 93%. Please find the disk usage details below and please find the folders consuming more space from attachment section.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   44G  3.5G  93% /Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924Please delete or zip unwanted files and let us know if you have any queries.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Tue, Jun 13, 2017 at 11:48 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjT0LwyAYhH9N3CqvGhMdHEJIKXTu0C7Fr3xAEq0xQ_99LdzBcXDPOcWl8WhRFEgLDWHFohaYgJSUYSkGzvp2YB0fgJCmqsFlN2Eb0KyosaYFCXJ0hnmpBSWCOcFHo0VheLSqOed4VKyr6LVIx4idztqFaf4UxvbvrA3nnkuKKYzL6ks6L_CC_n3_Ph_kdqKktqMcJ693u4bT_Zcoqy3sSw7pB0MqOkk>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj02OwyAMhU9DlsjYQMKCRdVJrjEiOH9SU9KEVnP8IdEsRrJl-1n-9MzeuH6oFo-garCKSja6kQqcQ5KuaQ3d65ZupgWlrNDAmScZUzV7dEw6EMZeYd_XOoLFyLYPhmMcR64efs55OwTdBHYlwrZJDjlwmuZXYaxFW9NzyWk_BBICkrNOUJfTdy5nX0q7mkjb2gGAQDvt6b0VnYfPEgeB5iQb7Mp81Z8PB3V29zkd-dorkMaVd6QiUwjjntb_bNIXu9r9epTn9iE84yO9-XRXZf_n7hfAG1Oz>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Tue Jun 13 2017 06:18:00 UTC (*47 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtTkGOwyAMfA0cEbYDxAcOVTf5BwE2idSUbEKrff6SaiWPPGNLM5O84SnL1aMGpy1QQ9_1CjQzkuJ-MHR3A93MoAGs6HSqaVaxyMVPkR2YHrL5dtpZRgcYY7axC25il-XDL7Xup6CbwLFN2HeVQg2pzMtP89jabSvPtZbjFEiokdiyoHE-ymsX9JXye41ZoLkcDI5Nf_bvOwW42H0pZ_38QSvDrbYCMvLw29mqHjk846O80pUlq__P-gPFZEX->]· [Edit Monitor<http://email.dtdg.co/c/eJwtjUkOwyAQBF8DRzTDYpgDhyhy_sHmRbKNY5P_h0iRui8lVXf2hmLhq5eAFgZUvU47gUAklSA3GvW0o3qYERAHpiG3PItU-eIj2VAcpYkiTBNASRglYXA6GGs08c0vrZ03Uw8mXz3hPEUOLeQ6L---sXe212Nt9bqZVBKkooE6LHlt_PL73f-uEo601U_-Cbz5v_AFLTk2hQ>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVTssOgyAQ_Bo5EmBF4cDBtPofK0vVRMXi-v-lyUwymWQeFKyfk9iCUbpXnYZK1zqplfcGpHejhVc_wmBHpXXXtIqYFhmzWINDQ5gioqaE0TgFprOzIegV-Oit2MPKfN0NDI2ZKvC6JCEj5WX91o6jetv5KXhzeSI_JTUwrfnmE48q31pJ6-sVqcGKEo67zpeEZ9zzQ_-84HDkc-NcfrfyO9A>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jc0OgyAQhJ9GjmRh-dsDh6bV90CgaqJilfb5Sy9NZjLJJN9M8prGzBYvQVgwApudclwAkUROrtd4tz3edA9CmE5BqmnisbDZO2eMdNYApKei3GCVKUatjNNRj4Ktfq71uDq8dXJoCsfBU6ghlWl-tY2tdfmT9_pPHJbU4QNJgCRDBpwFEoiK2Om3q92fOexxLe_041n1W9mXWs4vt6M4uw>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjUkKxCAURE8Tl6LxOy1chCZ9D4efAZJoG3P_NlAFxaOoSk7agGR3I-OaKS66DRjKmbWjoNbMUnz0LCY5M87VACy1tNKYyea8ZABggkWBUYPyEK0xYklBLgp0IIfbWiv3IKZh_Hb5Umjyzae8br--cb4sxvxcradSccGKV8SbVHfe_auiv-KRn_SWSXNnvvaW6x977zbC>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,13-06-2017 11:50,33,0,SpendHQ,"We had a call with Matthew and he updated that we need to contact him directly if we witness volume usage on root hitting at 100%. Also, he informed that REAN does not want to clear any logs from this instance if we witness high volume usage. The only thing we want to do is to inform them regarding the issue.","Hello SpendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 53%. The violation lasted for 24 minutes.We could see a sudden decrease in the size of /tmp folder. We are closely monitoring on it and will keep you updated. As of now, we are marking this case as resolved. Kindly revert back incase of any queries.Regards,Sumod.K.Bose","Hello Matthew,We could still see that the volume usage on this instance is still increasing gradually. The volume usage on this instance is at 98% and the available space on this instance is about 1.3GB.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   46G  1.3G  98% /Volume usage details on this instance,25G     tmp12G     var8.0G    usr510M    home285M    lib282M    opt/tmp folder is consuming high volume usage on this instance.25G     total7.8G    liger_view_acd236eb4cc612e2f94ed2cc23080059.csv1.5G    liger_view_0df3b11227ab3ea894a0574d4bbbb025.csv1.3G    Client217SpendDataAggregate_upload.sql.gz1.1G    liger_view_d0be0bb41be7c5130fbcf5c112e427f6.csv1.1G    liger_view_b08f7bf907b545c3acfb7866eef4eed5.csvKindly validate these details and delete/zip unwanted files or folders to reduce the current volume usage state in this instance. Revert back incase of any queries.Regards,Sumod.K.Bose","This is perfect. Please always advise us of issues like this on PRD machines. Thnak you.Regards,Matthew Watts","Hello Matthew,Thanks for joining the call. As per the discussion happened, you have moved some files to a different location for resolving 100% usage on the root volume for PROD-SPHQ-DB-SERVER05(10.59.10.135). As of now, the root volume usage on this instance is at 93%.[root@ip-10-59-10-135 /]# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   44G  3.5G  93% /As we discussed, REAN Team will contact you directly if we came to figure out that the root volume is again hitting at 100%.As it is a recurring issue, please let us know what all steps can REAN take to overcome the volume usage on this instance. ie, Moving/Deleting any particular log files. From the last few days, we can see /tmp folder is consuming high volume usage on this instance.Kindly validate these details and let us know the updates. Revert back incase of any queries.Regards,Sumod.K.Bose","Hello Team,This is to inform you that the volume usage on /dev/xvda1  mounted on root for PROD-SPHQ-DB-SERVER05 instance is reached  100%. Please Zip/delete the unwanted file and folders to resolve this issue.","Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage /dev/xvda1 mounted on root for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 94%. Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1  ext4    50G   44G  3.2G  94% /44G     total21G     tmp15G     var8.0G    usr510M    home285M    lib282M    opt44M     boot30M     etc19M     lib64tmp folder usage details21G     total7.8G    liger_view_acd236eb4cc612e2f94ed2cc23080059.csv2.0G    tiger_view_e242dfa28bace2b415078b4f7307f1d3.csv.gz1.5G    liger_view_0df3b11227ab3ea894a0574d4bbbb025.csv1.3G    liger_view_caa16490a6f4c23258e135e31655eacd.csv1.3G    liger_view_63f979ff50c2b7909d597a89a4ee2536.csv1.3G    Client217SpendDataAggregate_upload.sql.gz1.1G    liger_view_d0be0bb41be7c5130fbcf5c112e427f6.csv872M    liger_view_3f9c1ad163c573e5d9b02ee4a3e0fab3.csv764M    eighty_million_view_test.csv.gz436M    liger_view_d67305ba397f263124ab78863092aa75.csv436M    liger_view_d0e49e45cf34c76c39bcb470d4f61b47.csv367M    liger_view_2d32b3c178972699268d8997969dc77b.csv353M    att_test.sql221M    spark-2.1.0-bin-hadoop2.7181M    liger_view_e8097497adfa77f3f4802d7d0cc525c7.csv121M    liger_view_261089bca64386602af8d70c65d5464e.csv103M    tyler_att.csv86M     Client424SpendData.sql.gz78M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm/var filder usage deatils15G    total9.8G    tmp2.2G    www2.1G    lib228M    log129M    cachePlease let us know if we have your approval to perform unnecessary files and folders from the SpendHQ nodes in the case of volume usage alerts if it is going high. If we have your approval, please mention the folders and files from which we can compress data in order to resolve the volume usage. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924","The answer to Sanket's query: [How the volume usage resolved]: From the instance level, it seems like the volume usage change is for the tmp directory(tmp usage was decreased from 24G to 5G). I suspect this was due to the temporary files for resolved automatically by the system.","This is to inform you that the disk utilization alert for the SpendHQ Prod node 10.59.10.135 has resolved automatically and returned to a normal value of 61% consumption. The violation lasted for 12 hours. Please refer the attachment section for the Volume usage graph from the DataDog console for the last 24 hours. The root volume usage was touching 100% consumption and it is a high priority case. Please let us know if we have your approval to perform unnecessary files and folders from the SpendHQ nodes in the case of volume usage alerts if it is going high. If we have your approval, please mention the folders and files from which we can compress data in order to resolve the volume usage. We will wait for your input before closing the case. Thank You, Safuvan KM","Hello Team,Please review the usage details and remove/zip unwanted files to reduce the current usage.[root@ip-10-59-10-135 ~]# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   46G  1.1G  98% /47G     total47G     /24G     /tmp15G     /var9.8G    /var/tmp7.7G    /usr7.1G    /var/tmp/robert_uploads5.9G    /usr/local5.8G    /usr/local/infobright-products/iee/postgres/5.0.45.8G    /usr/local/infobright-products/iee/postgres5.8G    /usr/local/infobright-products/iee5.8G    /usr/local/infobright-products5.5G    /usr/local/infobright-products/iee/postgres/5.0.4/ib_data5.2G    /usr/local/infobright-products/iee/postgres/5.0.4/ib_data/dusty/public5.2G    /usr/local/infobright-products/iee/postgres/5.0.4/ib_data/dusty2.2G    /var/www/vhosts/secure.spendhq.com2.2G    /var/www/vhosts2.2G    /var/www2.1G    /var/lib1.6G    /var/lib/memsql-ops[root@ip-10-59-10-135 tmp]# du -sch * | sort -hr | head24G     total6.0G    liger_view_b00af241d15276550e8f8e7d48365f9d.csv2.0G    tiger_view_e242dfa28bace2b415078b4f7307f1d3.csv.gz1.8G    liger_view_3e86ddd800bc8ce8ba4147f616e260cf.csv1.3G    liger_view_897aed78457b53cc02eeefbb5699955b.csv1.3G    Client217SpendDataAggregate_upload.sql.gz1.2G    liger_view_acd236eb4cc612e2f94ed2cc23080059.csv899M    liger_view_752f752b3c4db4dc52b99d38a019f6e0.csv819M    liger_view_557e26d1f2379b1da6078a97227e6078.csv764M    eighty_million_view_test.csv.gz[root@ip-10-59-10-135 tmp]# du -sch * | sort -hr | head -2023G     total6.0G    liger_view_b00af241d15276550e8f8e7d48365f9d.csv2.0G    tiger_view_e242dfa28bace2b415078b4f7307f1d3.csv.gz1.8G    liger_view_3e86ddd800bc8ce8ba4147f616e260cf.csv1.3G    Client217SpendDataAggregate_upload.sql.gz1.2G    liger_view_acd236eb4cc612e2f94ed2cc23080059.csv899M    liger_view_752f752b3c4db4dc52b99d38a019f6e0.csv819M    liger_view_557e26d1f2379b1da6078a97227e6078.csv764M    eighty_million_view_test.csv.gz436M    liger_view_34814ed89b0f3b1a8706be1d990db29d.csv430M    liger_view_1c5245e09a28f2a7e20778d27d62a3fa.csv391M    liger_view_6e222ff4464cd6f85fa0cdb9bcf2b12c.csv382M    liger_view_61718af5d827c7d99d8d51ddf727b29b.csv353M    att_test.sql323M    liger_view_3db82f98557411ed1cfdf6d673e7a5c0.csv278M    liger_view_3997fbabcbb8090be130a1ec92b108eb.csv257M    liger_view_88b4b56406dd443108ece0c07f89d241.csv257M    liger_view_6abeb0962e1d21264aded02c63eb312d.csv257M    liger_view_0b01fffb4e01c572db65264a9bff109a.csv257M    liger_view_03f28057c6f44627c27fb0651d067d5c.csv[root@ip-10-59-10-135 var]# du -sch tmp/* | sort -hr | head -209.8G    total7.1G    tmp/robert_uploads2.2G    tmp/Client287SpendData_Reporting.sql.gz269M    tmp/Client217SpendDataAggregate.sql.gz171M    tmp/yum-mwatts-ylg2M9Please let us know if you have any queries regarding this.","Hello Team,This is to notify you that the alert regarding volume usage for PROD-SPHQ-DB-SERVER05 instance has reached to 100%. Please delete/zip unwanted files to resolve the issue.","Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage /dev/xvda1 mounted on root for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 93%. Please find the disk usage details below and please find the folders consuming more space from attachment section.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   44G  3.5G  93% /Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924Please delete or zip unwanted files and let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Dnoq5,Cloud Engineer Level 1,Closed,1065616,Incident,04-07-2017 21:00,,"Hello David,We haven't heard back from you regarding this case. At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Regards,Sumod.K.Bose###Next action: Evening shift: check whether we got a reply from David else send a reminder.###Safuvan Kotakuthmatayil <safuvan.kotakuthmatayil@reancloud.com>8:06 AM (0 minutes ago)to David, Spendhq Hello David,We haven't heard back from you.Please provide us the VPN client logs for further troubleshooting this issue.--Thanks & Regards,Safuvan KM###Next action: Night shift Team: check whether we got a reply from David else send a reminder.###Next action: Evening shift Team: check whether we got a reply from David else send a reminder.###Next action: Morning shift Team: check whether we got a reply from David else send a reminder.###Hello David,We haven't heard back from you.Please provide us the VPN client logs for further troubleshooting this issue.###Next action: Evening shift Team: check whether we got a reply from David else send a reminder.###Next action:  Morning shift Team: check whether we got a reply from David else send a reminder.###Hello David,The VPN Client logs are located in /Library/Application Support/Tunnelblick/Logs. Or use the below steps to get the logsClick on the Tunnelblick icon at the top of the screen;Click VPN Details;Select the Configurations pane at the top;Select the configuration in the list on the left;To copy the log to the Clipboard, click the Copy Log to Clipboard button.or check this link: https://strongvpn.com/logs-tunnelblick.htmlPlease provide us the logs for further troubleshooting this issue.###We had a call with David.1) He was able to connect the Vpn successfully but after some time it is getting automatically disconnected.Next Steps: We need to analyze the sophos logs, Need to provide steps for fetching VPN client logs from MAC machine so that david will share the client log with us.###Hi David, Apologize for the late reply, we will be available in the below bridge for next 15 minutes. If this won't works for you please let us know your convenient time so that we can reschedule accordingly.www.uberconference.com/akhilkurumathNote: Going forward please forward the emails to support@reancloud.com so that you will get a quick response from one of our team members.###Hi David,Please let us know your available time for a screen share session to resolve this issue quickly","Hi David,Please let us know your available time for a screen share session toresolve this issue quickly?On Thu, Jun 29, 2017 at 2:00 AM, David Miller <dmiller@spendhq.com> wrote:> My vpn on my mac keeps asking me to enter my password about every 30> minutes, is there any way to avoid this?  Seems extremely excessive>>>> *From: *Akhil Kurumath <akhil.kurumath@reancloud.com>> *Date: *Tuesday, January 3, 2017 at 9:10 AM> *To: *David Miller <dmiller@spendhq.com>> *Subject: *Re: VPN Access>>>> Hi David,>>>> We have created VPN user for you, use the below credentials for login.>>>>>> Please find the attached document for more details.>>>> On Tue, Jan 3, 2017 at 6:57 PM, Matthew Watts <mwatts@spendhq.com> wrote:>> Please could you create VPN access for David Miller – dmiller@spendhq.com>>>> *Matthew Watts* | Manager, Data Intelligence Systems | *Spend**HQ®*>> O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com>> *A SaaS Spend Visibility solution from Insight Sourcing Group*>> *www.spendhq.com <http://www.spendhq.com/>* | *www.insightsourcing.com> <http://www.insightsourcing.com/>*>>>>>>>> -->> Regards,>> Akhil K M>> REĀN Cloud Solutions | Reach, Engage, Āctivate, Nurture>> 2201 Cooperative Way #250, Herndon, Va 20171>> akhil.kurumath@reancloud.com | www.reancloud.com> <http://www.reancloudsolutions.com/>>> [image: mage removed by sender.]>>>> [image: mage removed by sender.]> <https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>>>    - REAN Cloud Achieves AWS Financial Services Competency>    <https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>>    - REAN Cloud is Premier Consulting Partner 2017>    <https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>>    - REAN Cloud receives 8 AWS Service Designations>    <https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>>    - Accelerate the Application Life Cycle with REAN DevOpsNow>    <https://www.reancloud.com/devopsnow/>>>>-- Regards,Akhil K MREĀN Cloud Solutions | Reach, Engage, Āctivate, Nurture2201 Cooperative Way #250, Herndon, Va 20171akhil.kurumath@reancloud.com | www.reancloud.com<http://www.reancloudsolutions.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: VPN Access,,29-06-2017 08:27,133,0,SpendHQ,"Hello David,We haven't heard back from you regarding this case. At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Regards,Sumod.K.Bose",Next action: Evening shift: check whether we got a reply from David else send a reminder.,"Safuvan Kotakuthmatayil <safuvan.kotakuthmatayil@reancloud.com>8:06 AM (0 minutes ago)to David, Spendhq Hello David,We haven't heard back from you.Please provide us the VPN client logs for further troubleshooting this issue.--Thanks & Regards,Safuvan KM",Next action: Night shift Team: check whether we got a reply from David else send a reminder.,Next action: Evening shift Team: check whether we got a reply from David else send a reminder.,Next action: Morning shift Team: check whether we got a reply from David else send a reminder.,"Hello David,We haven't heard back from you.Please provide us the VPN client logs for further troubleshooting this issue.",Next action: Evening shift Team: check whether we got a reply from David else send a reminder.,Next action:  Morning shift Team: check whether we got a reply from David else send a reminder.,"Hello David,The VPN Client logs are located in /Library/Application Support/Tunnelblick/Logs. Or use the below steps to get the logsClick on the Tunnelblick icon at the top of the screen;Click VPN Details;Select the Configurations pane at the top;Select the configuration in the list on the left;To copy the log to the Clipboard, click the Copy Log to Clipboard button.or check this link: https://strongvpn.com/logs-tunnelblick.htmlPlease provide us the logs for further troubleshooting this issue.","We had a call with David.1) He was able to connect the Vpn successfully but after some time it is getting automatically disconnected.Next Steps: We need to analyze the sophos logs, Need to provide steps for fetching VPN client logs from MAC machine so that david will share the client log with us.","Hi David, Apologize for the late reply, we will be available in the below bridge for next 15 minutes. If this won't works for you please let us know your convenient time so that we can reschedule accordingly.www.uberconference.com/akhilkurumathNote: Going forward please forward the emails to support@reancloud.com so that you will get a quick response from one of our team members.","Hi David,Please let us know your available time for a screen share session to resolve this issue quickly",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XDxAg,Cloud Engineer Level 1,Closed,1099986,Incident,09-06-2018 04:47,,"Hello team, The alert regarding high CPU utilization on host i-0ace70ce06368e4a7 (prd-ww1_122 ) got recovered and returned to a current value of 0.86.The alert is in resolved state therefore we are closing this case. Please get back to us in case of any queries.Thanks.###Hello Spendhq-Team, This is to inform you that we have received an alert regarding high CPU Utilization on prd-ww1_122 (10.59.100.122) has exceeded the threshold value of 80 to 88.92. Please find the resources details below. Resource Details:- Instance ID: i-0ace70ce06368e4a7 Instance Name: prd-ww1_122 Private IP: 10.59.100.122 Please find CPU utilization details below. ################################################   Processes with highest CPU usage################################################ USER       PID  PPID CMD                         %CPUapache   28487  1838 /usr/sbin/httpd             51.1apache    4803  1838 /usr/sbin/httpd             14.0apache    5517  1838 /usr/sbin/httpd             13.5apache    1332  1838 /usr/sbin/httpd              9.5apache   26964  1838 /usr/sbin/httpd              8.9apache   18196  1838 /usr/sbin/httpd              8.2apache    9726  1838 /usr/sbin/httpd              1.8apache    9221  1838 /usr/sbin/httpd              1.7apache   28188  1838 /usr/sbin/httpd              1.6apache    9220  1838 /usr/sbin/httpd              1.3We could see that the process httpd with PID 28487 is consuming most of the CPU. Kindly check these details and let us know if you have any query.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Sat, Jun 9, 2018 at 12:13 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on thehost prd-ww1_122 - 10.59.100.122 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High CPU Utilization on the host prd-ww1_122 -10.59.100.122 - webHigh CPU Utilization on the host. Log in to the machine and verify whichprocess is consuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024189?to_ts=1528483399000&group=host%3Ai-0ace70ce06368e4a7&from_ts=1528479799000>avg(last_5m):avg:system.cpu.stolen{datadog_monitor:on} by {host} +avg:system.cpu.user{datadog_monitor:on} by {host} > 80The monitor was last triggered at Fri Jun 08 2018 18:43:29 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024189?group=host%3Ai-0ace70ce06368e4a7>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024189/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?filter=i-0ace70ce06368e4a7>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1528483409000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1528482509000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4432885160756763069>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Thanks & Regards,Kapil BokdiaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture4th Floor, 26, Tulsi Complex,100 Feet Road, New BhupalpuraUdaipur, Rajasthan 313001kapil.bokdia@reancloud.com |+917300421033| www.reancloud.com<http://www.reancloudsolutions.com/>Toll-Free Number: +12015828406-- Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on the host prd-ww1_122 - 10.59.100.122 - web,,09-06-2018 00:19,5,0,SpendHQ,"Hello team, The alert regarding high CPU utilization on host i-0ace70ce06368e4a7 (prd-ww1_122 ) got recovered and returned to a current value of 0.86.The alert is in resolved state therefore we are closing this case. Please get back to us in case of any queries.Thanks.","Hello Spendhq-Team, This is to inform you that we have received an alert regarding high CPU Utilization on prd-ww1_122 (10.59.100.122) has exceeded the threshold value of 80 to 88.92. Please find the resources details below. Resource Details:- Instance ID: i-0ace70ce06368e4a7 Instance Name: prd-ww1_122 Private IP: 10.59.100.122 Please find CPU utilization details below.",,,,,,,,,,,,,,,,Processes with highest CPU usage,,,,,,,,,,,,,,,,USER       PID  PPID CMD                         %CPUapache   28487  1838 /usr/sbin/httpd             51.1apache    4803  1838 /usr/sbin/httpd             14.0apache    5517  1838 /usr/sbin/httpd             13.5apache    1332  1838 /usr/sbin/httpd              9.5apache   26964  1838 /usr/sbin/httpd              8.9apache   18196  1838 /usr/sbin/httpd              8.2apache    9726  1838 /usr/sbin/httpd              1.8apache    9221  1838 /usr/sbin/httpd              1.7apache   28188  1838 /usr/sbin/httpd              1.6apache    9220  1838 /usr/sbin/httpd              1.3We could see that the process httpd with PID 28487 is consuming most of the CPU. Kindly check these details and let us know if you have any query.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001dgNW5,Cloud Engineer Level 1,Closed,1107069,Incident,02-11-2018 02:22,,"Hello Matthew,Thanks for the update. As the alert is triggered due to known action we are marking this case as closed.###Matthew Watts <mwatts@spendhq.com>2:14 AM (6 minutes ago)to Rean, spendhq-support@reancloud.comWe have resolved this.###Hello TeamWe have received a site down alert for the URL: https://secure.spendhq.com/login.We are checking on the issue. Please update us back if you are performing any action from your end.","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Fri, Nov 2, 2018 at 2:03 AMSubject: Detected Error on SpendHQ SecureTo: <ms@reancloud.com>Thu, 01 Nov 2018 16:33:04 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Atlanta-B US, Dallas-B US, London UK, Frankfurt DE--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Secure,,02-11-2018 02:04,0,0,SpendHQ,"Hello Matthew,Thanks for the update. As the alert is triggered due to known action we are marking this case as closed.","Matthew Watts <mwatts@spendhq.com>2:14 AM (6 minutes ago)to Rean, spendhq-support@reancloud.comWe have resolved this.",Hello TeamWe have received a site down alert for the URL: https://secure.spendhq.com/login.We are checking on the issue. Please update us back if you are performing any action from your end.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VrX7b,Cloud Engineer Level 2,Closed,1098240,Incident,16-05-2018 03:43,,"Hello Team,We are closing this ticket as the maintenance was completed on May 15th###Hello SpendHQ-Team,This is to inform you that we received a notification from AWS stating that planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. The affected resource is the virtual interface (insightsourcing_zadara).Virtual interface details:Name: insightsourcing_zadara Connection: dxcon-1sdrrjhmzo7uu Virtual Gateway: vgw-ce8867a7The affected resource was not related to either  SpendHQ-Equinix-10Gb (10 Gbps) or SpendHQ (1Gbps) connections. Please review these details and let us know if you have any queries.###By checking we found that the affected resource is the virtual interface (insightsourcing_zadara).Please find the virtual interface details below:Name: insightsourcing_zadaraConnection: dxcon-1sdrrjhmzo7uuVirtual Gateway: vgw-ce8867a7.Please check with rohit and inform the customer.###We have checked at our end and unable to find the associated affected resource.Next Action: Need to check with Rohit","Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. During this maintenance window, your AWS Direct Connect services associated with this event may become unavailable.This maintenance is scheduled to avoid disrupting redundant connections at the same time.If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED,,08-05-2018 07:38,188,0,SpendHQ,"Hello Team,We are closing this ticket as the maintenance was completed on May 15th","Hello SpendHQ-Team,This is to inform you that we received a notification from AWS stating that planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. The affected resource is the virtual interface (insightsourcing_zadara).Virtual interface details:Name: insightsourcing_zadara Connection: dxcon-1sdrrjhmzo7uu Virtual Gateway: vgw-ce8867a7The affected resource was not related to either  SpendHQ-Equinix-10Gb (10 Gbps) or SpendHQ (1Gbps) connections. Please review these details and let us know if you have any queries.",By checking we found that the affected resource is the virtual interface (insightsourcing_zadara).Please find the virtual interface details below:Name: insightsourcing_zadaraConnection: dxcon-1sdrrjhmzo7uuVirtual Gateway: vgw-ce8867a7.Please check with rohit and inform the customer.,We have checked at our end and unable to find the associated affected resource.Next Action: Need to check with Rohit,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ZCDZT,Cloud Engineer Level 1,Closed,1101938,Incident,27-07-2018 07:50,,"Hello Allen,Thank you for the update. Now we are marking this case as resolved and closing this case. Kindly let us know if you have any query/concern related to it.###Allen Herrera11:15 PM (0 minutes ago)to Rean, spendhq-support Looks good thank you!###Hello Allen,We have mounted the iscsi volume PRD-DB-170819-Clone-180725 on /mnt/production_07_25_2018 in the instance 10.59.10.135. Please check from your end and let us know if you are facing any issues.###Hello Allen,We will attach the volume and get back to you once this is completed.###Great!Rean can we attach that volume to 10.59.10.135 under /mnt following the naming of production_month_day_yearExample: /mnt/production_07_24_2018Allen Herrera###Chris Veillette <cveillette@andromeda3.com>3:11 PM (6 minutes ago)to Allen, spendhq-support, Matthew, Andrew, David, Praveen Ok here is the production db clone:PRD-DB-170819-Clone-180725it is online and ready to goChris Veillette###OkChris Veillette On Jul 24, 2018, at 9:41 PM, Allen Herrera <aherrera@spendhq.com> wrote:###lrwxrwxrwx 1 root root   9 Jul 11 21:44 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-170819-v777bb21358661922.00000028.2f1dab31-lun-0 -> ../../sdn  yeah go with that one I guess PRD-DB-170919 Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###Hi REAN & Everyone -According to my spreadsheet, there are three volumes labeled as production connected to 10.59.10.190They are :05-05-test-dbPRD-DB-170919 ( i think this is might be it...)spend4-db-backup-07-20-17Please let me know which one to clone - I need to do this evening as I will be on travel tmrw - 25 JUL..Thanks!Chris Veillette###Hello Allen,We acknowledge your request, we will work on it and get back to you with updates","---------- Forwarded message ----------From: Allen Herrera <aherrera@spendhq.com>Date: Tue, Jul 24, 2018 at 11:42 PMSubject: preview data refreshTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Hey Rean,We need a clone of our production data volume/dev/sdn        4.0T  2.0T  1.9T  52% /mnt/production_19082017From 10.59.10.190And attach that cloned drive to10.59.10.135 under /mnt following the naming of production_month_day_yearExample: /mnt/production_07_24_2018*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- Raleigh Convention Center25th July, 2018 <http://go.reancloud.com/raleigh-email-sign>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>-- Raleigh Convention Center25th July, 2018 <http://go.reancloud.com/raleigh-email-sign>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: preview data refresh,,25-07-2018 02:15,54,0,SpendHQ,"Hello Allen,Thank you for the update. Now we are marking this case as resolved and closing this case. Kindly let us know if you have any query/concern related to it.","Allen Herrera11:15 PM (0 minutes ago)to Rean, spendhq-support Looks good thank you!","Hello Allen,We have mounted the iscsi volume PRD-DB-170819-Clone-180725 on /mnt/production_07_25_2018 in the instance 10.59.10.135. Please check from your end and let us know if you are facing any issues.","Hello Allen,We will attach the volume and get back to you once this is completed.",Great!Rean can we attach that volume to 10.59.10.135 under /mnt following the naming of production_month_day_yearExample: /mnt/production_07_24_2018Allen Herrera,"Chris Veillette <cveillette@andromeda3.com>3:11 PM (6 minutes ago)to Allen, spendhq-support, Matthew, Andrew, David, Praveen Ok here is the production db clone:PRD-DB-170819-Clone-180725it is online and ready to goChris Veillette","OkChris Veillette On Jul 24, 2018, at 9:41 PM, Allen Herrera <aherrera@spendhq.com> wrote:",lrwxrwxrwx 1 root root   9 Jul 11 21:44 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-170819-v777bb21358661922.00000028.2f1dab31-lun-0 -> ../../sdn  yeah go with that one I guess PRD-DB-170919 Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com,"Hi REAN & Everyone -According to my spreadsheet, there are three volumes labeled as production connected to 10.59.10.190They are :05-05-test-dbPRD-DB-170919 ( i think this is might be it...)spend4-db-backup-07-20-17Please let me know which one to clone - I need to do this evening as I will be on travel tmrw - 25 JUL..Thanks!Chris Veillette","Hello Allen,We acknowledge your request, we will work on it and get back to you with updates",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gbgeZ,Cloud Engineer Level 1,Closed,1109506,Incident,17-12-2018 07:49,,"Hello Team,This is to inform you that the alert regarding High Network OUT on host - sphq-db4-20180830 got recovered.As the alert in the recovered state, we are marking this case as closed. Kindly revert back to us in case of any queries.###Hello Team, We checked on this alert and we could see that from the AWS console we could see that during the time of the alert there was a spike in network packets in and network in.Please find the screenshot attached on the attachment section and let us know your thoughts on the same.Thanks,###Hello Team,This is to inform you that we have received an alert regarding High Network OUT on host - sphq-db4-20180830 which has surpassed the set threshold of 2.44G and is at 4.97G.We are analyzing more on this and will get back you with more details.Resource Details:Instance ID: i-082d412700b276f44	Instance Name or ID: SPHQ-DB4-20180830	Instance Type:	r4.8xlarge	Region: us-east-1	Private IP Address: 10.59.10.210","[image: Datadog][Triggered] [SpendHQ] - High Network OUT on host - sphq-db4-20180830 - -High Network OUT on the instance. Please check the list open TCPConnections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024199?to_ts=1544811509000&group=host%3Ai-082d412700b276f44&from_ts=1544804309000>*aws.ec2.network_out* over *datadog_monitor:on,host:i-082d412700b276f44*was *> 1100000000.0* at all times during the *last 30m*.The monitor was last triggered at Fri Dec 14 2018 18:18:39 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024199?group=host%3Ai-082d412700b276f44>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024199/edit>] · [Viewi-082d412700b276f44<https://app.datadoghq.com/infrastructure?filter=i-082d412700b276f44>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1544811639000&tags=host%3Ai-082d412700b276f44&from_ts=1544810619000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4706825414500759028>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- \\-- \\-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - sphq-db4-20180830 - -,,15-12-2018 00:04,64,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding High Network OUT on host - sphq-db4-20180830 got recovered.As the alert in the recovered state, we are marking this case as closed. Kindly revert back to us in case of any queries.","Hello Team, We checked on this alert and we could see that from the AWS console we could see that during the time of the alert there was a spike in network packets in and network in.Please find the screenshot attached on the attachment section and let us know your thoughts on the same.Thanks,","Hello Team,This is to inform you that we have received an alert regarding High Network OUT on host - sphq-db4-20180830 which has surpassed the set threshold of 2.44G and is at 4.97G.We are analyzing more on this and will get back you with more details.Resource Details:Instance ID: i-082d412700b276f44	Instance Name or ID: SPHQ-DB4-20180830	Instance Type:	r4.8xlarge	Region: us-east-1	Private IP Address: 10.59.10.210",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014KkQs,Cloud Engineer Level 1,Closed,1033066,Incident,22-11-2016 14:39,,Please ignore this alert as one of our Team member was trying to login.,"Too many failed logins from 52.220.215.91 for facility portal.Further logins will be blocked for 600 seconds.        -- System Uptime      : 10 days 1 hour 8 minutesSystem Load        : 0.07System Version     : Sophos UTM 9.408-4Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][WARN-070] Too many failed logins,,22-11-2016 14:24,0,0,SpendHQ,Please ignore this alert as one of our Team member was trying to login.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EVV72,Cloud Engineer Level 1,Closed,1068282,Incident,16-07-2017 21:15,,"Hello Team, This is to notify you that we have received an alert that High Disk Usage ( /dev/sdb ) - prod-sphq-db-server05 has exceeded a threshold value of 90%. The alert got resolved automatically and return to normal state with the value of 89.76%###Hello Team, This is to notify you that we have received an alert that  High Disk Usage ( /dev/sdb ) - prod-sphq-db-server05 has exceeded a threshold value of 90 on average with the value of 91%. We are analyzing further on this issue and will get back to you with the updates.","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sdb ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/sdb     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 90.16This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fsdb%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3958582322556084374 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sdb ) - prod-sphq-db-server05 - 10.59.10.135,,16-07-2017 19:16,2,0,SpendHQ,"Hello Team, This is to notify you that we have received an alert that High Disk Usage ( /dev/sdb ) - prod-sphq-db-server05 has exceeded a threshold value of 90%. The alert got resolved automatically and return to normal state with the value of 89.76%","Hello Team, This is to notify you that we have received an alert that  High Disk Usage ( /dev/sdb ) - prod-sphq-db-server05 has exceeded a threshold value of 90 on average with the value of 91%. We are analyzing further on this issue and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DmCyq,Cloud Engineer Level 1,Closed,1064530,Incident,23-06-2017 21:34,,"Hi SpendHq-Team, This is to inform you that the high volume usage alert on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal value of 80%.###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance.We are still working on this and will get back to you with updates","From: Datadog Alerting <alert@datadoghq.com> Date: Fri, Jun 23, 2017 at 8:19 PM Subject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135 To: REANCloud Support <ms@reancloud.com> [image: Datadog] [Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135 High Disk Usage detected on the device /dev/xvda1 @ms@reancloud.com <http://email.dtdg.co/c/eJwVjbsKgzAARb_GbJW8Y4YM2iKFzh3apcQ8VFBjYzL07xvhDocL516rmBwcmBWGSECOMYaMElQzRBmreyQ7BlvZUclvXLQVhTbZsTYBTGow3GtPOTWESYEbQRAUzJnGem-RcGBRU0r7UZG2wn2J3vfa6qRtGKdv2VjPzpiQt1Roj8HPiyuUL_ANr5_H7_VE9wyiWo9yHJ3ezBKyPU2Q1Bq2OYX4Bx4hOiA> [image: Metric Graph] <http://email.dtdg.co/c/eJxNj8uOwyAMRb-GLBE2mMQLFulU-Y2KBvKQmpImtJrPL4lmMZLlx7V8dB0c8T1Ws0MFtbKIqMhokASGSHbAF1ItXwzbq61bYVTIYZR9qiYHgyEYNPeG7qx1HWuvuEHfRKpND7Z6uCnndRe6FdiV8Osqg88-pHF6FcZStCU955y2XaBGhZotC93ldMvl7AqGG7Cm0ayUEmjHLb3Xoof4mfsokA4yYVfms_5-goej-5nSns89KEksSwZNhTBsafnP1vZkV5tb9vLcFv2zf6R3ONxV2f25-wJsqFIq> avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90 The monitor was last triggered at Thu Jun 22 2017 20:54:00 UTC (*29 secs ago*). ------------------------------",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,23-06-2017 21:03,1,0,SpendHQ,"Hi SpendHq-Team, This is to inform you that the high volume usage alert on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal value of 80%.","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance.We are still working on this and will get back to you with updates",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001K0lPQ,Cloud Engineer Level 1,Closed,1084118,Incident,10-11-2017 00:01,,"Hello Allen,In order to prevent this from happening in future. We have allowed all the traffic from complete 10.59.0.0/16 VPC on the Sophos UTM. There will be no further requirement to open traffic from any new servers. Please revert back to us in case of further queries.###In order to prevent this from happening in future. We have allowed all the traffic from complete 10.59.0.0/16 VPC on the Sophos UTM. There will be no further requirement to open traffic from any new servers.###Check with CC whether we need to provide any update to customer other than below one###Hello Allen,Going forward we will ensure that this will not happen and will make sure to avoid the mistake for any changes again.###Confirmed. Internet is enabled on both boxes. How can we prevent this from happening in the future?This is the second time its happened. This  cost us valuable time today. Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group###I have opened the traffic from this instance at Sophos level which fixed the issue.###Hello Allen,This is fixed. We can confirm that both Larvel servers 10.59.101.78 and 10.59.100.78 are having internet access now. Please check it on your end and let us know if you have any concerns.###Hello Team,We will look into this issue and will let you know the updates.","Why don't both our new Laravel servers on 10.59.101.78 and 10.59.100.78 have internet access??examplecurl -l 'http://google.com'curl: (7) Failed to connect to 2607:f8b0:4004:806::200e: Network is unreachableI need someone to fix this asap. I need to be able to fetch and update the code base. This requires internet!How can I make my setup instructions clearer for this issue not to happen again because its effecting our release timeline.(this happened too during the setup of our test Laravel server 10.59.100.210)Allen Herrera | Developer | SpendHQ(r)M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",No internet on new laravel servers,,09-11-2017 02:07,23,0,SpendHQ,"Hello Allen,In order to prevent this from happening in future. We have allowed all the traffic from complete 10.59.0.0/16 VPC on the Sophos UTM. There will be no further requirement to open traffic from any new servers. Please revert back to us in case of further queries.",In order to prevent this from happening in future. We have allowed all the traffic from complete 10.59.0.0/16 VPC on the Sophos UTM. There will be no further requirement to open traffic from any new servers.,Check with CC whether we need to provide any update to customer other than below one,"Hello Allen,Going forward we will ensure that this will not happen and will make sure to avoid the mistake for any changes again.",Confirmed. Internet is enabled on both boxes. How can we prevent this from happening in the future?This is the second time its happened. This  cost us valuable time today. Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group,I have opened the traffic from this instance at Sophos level which fixed the issue.,"Hello Allen,This is fixed. We can confirm that both Larvel servers 10.59.101.78 and 10.59.100.78 are having internet access now. Please check it on your end and let us know if you have any concerns.","Hello Team,We will look into this issue and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001KpRTP,Cloud Engineer Level 1,Closed,1085315,Incident,27-11-2017 21:22,,"Hello Matthew,This request has been completed.We have created a VPN user for schulz@pythian.com and have shared the credentials with the user in a separate email.Kindly validate it from your end and let us know if you have any further queries regarding this case.Regards,Sumod.K.Bose###Hello Matthew,We will work on this and will let you know the updates.","REAN,Could we please add the following user to the VPN:schulz@pythian.com<mailto:schulz@pythian.com>Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",VPN User,,27-11-2017 19:46,26,0,SpendHQ,"Hello Matthew,This request has been completed.We have created a VPN user for schulz@pythian.com and have shared the credentials with the user in a separate email.Kindly validate it from your end and let us know if you have any further queries regarding this case.Regards,Sumod.K.Bose","Hello Matthew,We will work on this and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TACBK,Cloud Engineer Level 1,Closed,1093753,Incident,23-03-2018 09:22,,"Hello Team,We haven't heard back from you,At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Thank You,Manideep###Hello Team,We haven't heard back from you,Please review the Analysis in the Previous comment. The site was not actually down We have checked the ELB monitoring and found that the Latency and request count was hight at the time of the alert. The 4XX and 5XX was normal at the time of the alert. Please find the attached ELB graphs and Logs. Kindly validate these details and let us know if we are good to close this case.###Hello Team, We further analyzed the issue and the url https://preview.spendhq.com/login pointed to preview-spendhq-xelb load balancer which is then redirected to internal load balancer Preview-api-spendhq-com through Sophos WAF. We have checked the ELB monitoring and found that the Latency and request count was hight at the time of the alert. The 4XX and 5XX was normal at the time of the alert. Please find the attached ELB graphs and Logs. we could see the sum requests went high during this time period. From the attached ELB logs it is clear that there were many requests with high backend processing time. As this was not usual traffic please let us know if you were performing any activity from your end at the time of the alert. Also, let us know if you have any questions or we are good to close this case.###@Manideep: Please investigate the root cause and inform the customer.###Hello Team,This is to notify that site-down alert for URL:- https://preview.spendhq.com/login got resolved violation last for 12 minutes.At this time we downgrading the priority to p2 and We are analyzing the issue and will get back to you with updates.###Hello Team,This is to notify that we have received a site down for URL:-https://preview.spendhq.com/login.We are analyzing the issue, Meanwhile please let us know if there is any activity is performing on your end","Tue, 20 Mar 2018 15:46:33 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30002 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: Atlanta-B USConfirmed by node(s): Sydney-C AU, New Jersey US, Dallas-B US, California US-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,21-03-2018 01:16,56,0,SpendHQ,"Hello Team,We haven't heard back from you,At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Thank You,Manideep","Hello Team,We haven't heard back from you,Please review the Analysis in the Previous comment. The site was not actually down We have checked the ELB monitoring and found that the Latency and request count was hight at the time of the alert. The 4XX and 5XX was normal at the time of the alert. Please find the attached ELB graphs and Logs. Kindly validate these details and let us know if we are good to close this case.","Hello Team, We further analyzed the issue and the url https://preview.spendhq.com/login pointed to preview-spendhq-xelb load balancer which is then redirected to internal load balancer Preview-api-spendhq-com through Sophos WAF. We have checked the ELB monitoring and found that the Latency and request count was hight at the time of the alert. The 4XX and 5XX was normal at the time of the alert. Please find the attached ELB graphs and Logs. we could see the sum requests went high during this time period. From the attached ELB logs it is clear that there were many requests with high backend processing time. As this was not usual traffic please let us know if you were performing any activity from your end at the time of the alert. Also, let us know if you have any questions or we are good to close this case.",@Manideep: Please investigate the root cause and inform the customer.,"Hello Team,This is to notify that site-down alert for URL:- https://preview.spendhq.com/login got resolved violation last for 12 minutes.At this time we downgrading the priority to p2 and We are analyzing the issue and will get back to you with updates.","Hello Team,This is to notify that we have received a site down for URL:-https://preview.spendhq.com/login.We are analyzing the issue, Meanwhile please let us know if there is any activity is performing on your end",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eOnkD,Cloud Engineer Level 1,Closed,1107366,Incident,09-11-2018 06:20,,"Hello Team,This is to inform you that the alert later on got recovered and the violation lasted for about two hours. Please go through our previously shared analysis in regards to this alert and let us know if yo have any queries.Thanks.###Hello Team,This is to notify you that we have received a high memory utilization alert on the host PRD-WW2_6 in us-east-1 region which has crossed the set threshold of 95% memory utilization and is at 96.44% utilization:                    total       used       free     shared    buffers     cachedMem:           31G        29G       1.8G       876K        29M       310M-/+ buffers/cache:        29G       2.2GSwap:           0B         0B         0BOn Checking we could see that the httpd process is consuming high memory on the instance.PID %MEM COMMAND9485 3.0 /usr/sbin/httpd18821 2.8 /usr/sbin/httpd18836 2.3 /usr/sbin/httpd20003 2.3 /usr/sbin/httpd3061 2.1 /usr/sbin/httpd28218 1.8 /usr/sbin/httpd17854 1.7 /usr/sbin/httpd25191 1.7 /usr/sbin/httpd25195 1.7 /usr/sbin/httpd25330 1.7 /usr/sbin/httpd25335 1.7 /usr/sbin/httpd7727 1.7 /usr/sbin/httpd17856 1.6 /usr/sbin/httpd17857 1.6 /usr/sbin/httpd18338 1.6 /usr/sbin/httpd25328 1.6 /usr/sbin/httpd30365 1.6 /usr/sbin/httpd7717 1.6 /usr/sbin/httpd18281 1.5 /usr/sbin/httpd23759 1.5 /usr/sbin/httpd25321 1.5 /usr/sbin/httpd25325 1.5 /usr/sbin/httpd26524 1.5 /usr/sbin/httpd30988 1.5 /usr/sbin/httpd3335 1.5 /usr/sbin/httpd4838 1.5 /usr/sbin/httpd8688 1.5 /usr/sbin/httpd9519 1.5 /usr/sbin/httpd23121 1.4 /usr/sbin/httpd26497 1.4 /usr/sbin/httpd27667 1.4 /usr/sbin/httpd4835 1.4 /usr/sbin/httpd7726 1.4 /usr/sbin/httpd13366 1.3 /usr/sbin/httpd18277 1.3 /usr/sbin/httpd7357 1.3 /usr/sbin/httpd7719 1.3 /usr/sbin/httpd18820 1.2 /usr/sbin/httpd22313 1.2 /usr/sbin/httpd25329 1.2 /usr/sbin/httpd25333 1.2 /usr/sbin/httpd3213 1.2 /usr/sbin/httpd13446 1.1 /usr/sbin/httpd26496 1.1 /usr/sbin/httpd3186 1.1 /usr/sbin/httpd23814 1.0 /usr/sbin/httpd28229 1.0 /usr/sbin/httpd19740 0.9 /usr/sbin/httpd25320 0.9 /usr/sbin/httpd4176 0.9 /usr/sbin/httpdPlease check on this and let us know if you have any queries or concerns.Thanks.Resource Details:Instance ID:	i-01ac95c23ac66a40e	Instance Name:	PRD-WW2_6	Instance Type: 	m4.2xlarge	Availability Zone:	us-east-1c	Region:	us-east-1Subnet: 	subnet-29b09361	VPC:	vpc-76df7212Private IP Address: 	10.59.101.6","[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 -10.59.101.6 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1541711327000&group=host%3Ai-01ac95c23ac66a40e&from_ts=1541704127000>avg(last_30m):(avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by {host}- avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by{host} ) /avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by{host} * 100 > 95The monitor was last triggered at Thu Nov 08 2018 21:08:57 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-01ac95c23ac66a40e>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-01ac95c23ac66a40e<https://app.datadoghq.com/infrastructure?filter=i-01ac95c23ac66a40e>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1541711457000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1541710437000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4654812984183991373>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Paul MulonziaREĀN Cloud | Reach, Engage, Āctivate, Nurtur--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 - 10.59.101.6 - web,,09-11-2018 03:29,3,0,SpendHQ,"Hello Team,This is to inform you that the alert later on got recovered and the violation lasted for about two hours. Please go through our previously shared analysis in regards to this alert and let us know if yo have any queries.Thanks.","Hello Team,This is to notify you that we have received a high memory utilization alert on the host PRD-WW2_6 in us-east-1 region which has crossed the set threshold of 95% memory utilization and is at 96.44% utilization:                    total       used       free     shared    buffers     cachedMem:           31G        29G       1.8G       876K        29M       310M-/+ buffers/cache:        29G       2.2GSwap:           0B         0B         0BOn Checking we could see that the httpd process is consuming high memory on the instance.PID %MEM COMMAND9485 3.0 /usr/sbin/httpd18821 2.8 /usr/sbin/httpd18836 2.3 /usr/sbin/httpd20003 2.3 /usr/sbin/httpd3061 2.1 /usr/sbin/httpd28218 1.8 /usr/sbin/httpd17854 1.7 /usr/sbin/httpd25191 1.7 /usr/sbin/httpd25195 1.7 /usr/sbin/httpd25330 1.7 /usr/sbin/httpd25335 1.7 /usr/sbin/httpd7727 1.7 /usr/sbin/httpd17856 1.6 /usr/sbin/httpd17857 1.6 /usr/sbin/httpd18338 1.6 /usr/sbin/httpd25328 1.6 /usr/sbin/httpd30365 1.6 /usr/sbin/httpd7717 1.6 /usr/sbin/httpd18281 1.5 /usr/sbin/httpd23759 1.5 /usr/sbin/httpd25321 1.5 /usr/sbin/httpd25325 1.5 /usr/sbin/httpd26524 1.5 /usr/sbin/httpd30988 1.5 /usr/sbin/httpd3335 1.5 /usr/sbin/httpd4838 1.5 /usr/sbin/httpd8688 1.5 /usr/sbin/httpd9519 1.5 /usr/sbin/httpd23121 1.4 /usr/sbin/httpd26497 1.4 /usr/sbin/httpd27667 1.4 /usr/sbin/httpd4835 1.4 /usr/sbin/httpd7726 1.4 /usr/sbin/httpd13366 1.3 /usr/sbin/httpd18277 1.3 /usr/sbin/httpd7357 1.3 /usr/sbin/httpd7719 1.3 /usr/sbin/httpd18820 1.2 /usr/sbin/httpd22313 1.2 /usr/sbin/httpd25329 1.2 /usr/sbin/httpd25333 1.2 /usr/sbin/httpd3213 1.2 /usr/sbin/httpd13446 1.1 /usr/sbin/httpd26496 1.1 /usr/sbin/httpd3186 1.1 /usr/sbin/httpd23814 1.0 /usr/sbin/httpd28229 1.0 /usr/sbin/httpd19740 0.9 /usr/sbin/httpd25320 0.9 /usr/sbin/httpd4176 0.9 /usr/sbin/httpdPlease check on this and let us know if you have any queries or concerns.Thanks.Resource Details:Instance ID:	i-01ac95c23ac66a40e	Instance Name:	PRD-WW2_6	Instance Type: 	m4.2xlarge	Availability Zone:	us-east-1c	Region:	us-east-1Subnet: 	subnet-29b09361	VPC:	vpc-76df7212Private IP Address: 	10.59.101.6",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G0000157Ea7,Cloud Engineer Level 1,Closed,1037258,Incident,08-12-2016 06:10,,"Hello Matthew,Thanks for your confirmation.At this time, we are marking this case as resolved.###We can confirm that we have access to the box.###Hello Matthew,We haven't heard back from you regarding this case. As per your request, we have launched a new instance from the image of the instance 10.59.100.118.Please verify it from your end and let us know if you are facing any issues while trying to access the new instance.###Hello Matthew,As per your request, we have launched one new instance from an image taken from 10.59.100.118. Please find the below details.Resource Details:Instance ID : i-6f4d8478Instance state : runningInstance type : c4.2xlargeAvailability zone : us-east-1bPrivate IPs : 10.59.100.94Security groups : SpendHQ_Private_Webserver_Security_GroupVPC ID : vpc-76df7212AMI ID : PROD-SPHQ-WEB-SERVER02_AMI_7-Dec-2016 (ami-6cd8df7b)Subnet ID : subnet-0d093d27Please let us know if we need to add this instance under our monitoring list.And let us know if you have any further queries regarding this request also refer the attachments for more details.###Hi Matthew,We will work on this request and get back to you once we are done.","Can we please request a new instance (c4.2xlarge) to be deployed, from an image taken from 10.59.100.118.Thank you.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",New Instance,,06-12-2016 22:55,31,0,SpendHQ,"Hello Matthew,Thanks for your confirmation.At this time, we are marking this case as resolved.",We can confirm that we have access to the box.,"Hello Matthew,We haven't heard back from you regarding this case. As per your request, we have launched a new instance from the image of the instance 10.59.100.118.Please verify it from your end and let us know if you are facing any issues while trying to access the new instance.","Hello Matthew,As per your request, we have launched one new instance from an image taken from 10.59.100.118. Please find the below details.Resource Details:Instance ID : i-6f4d8478Instance state : runningInstance type : c4.2xlargeAvailability zone : us-east-1bPrivate IPs : 10.59.100.94Security groups : SpendHQ_Private_Webserver_Security_GroupVPC ID : vpc-76df7212AMI ID : PROD-SPHQ-WEB-SERVER02_AMI_7-Dec-2016 (ami-6cd8df7b)Subnet ID : subnet-0d093d27Please let us know if we need to add this instance under our monitoring list.And let us know if you have any further queries regarding this request also refer the attachments for more details.","Hi Matthew,We will work on this request and get back to you once we are done.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C15Sx,Cloud Engineer Level 1,Closed,1053222,Incident,15-05-2017 10:22,,"We have verified from the instance level that we are not using the JAVA module Struts in our application and this incident will not affect our application.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries. Best Regards, Safuvan KM###Hello SpendHQ-Team, We have again received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.123 which belongs to the secure ELB.On the further analysis on the ELB logs, we could see the IP 40.77.167.108 having 404 response code. The IP 40.77.167.108 is belongs to Microsoft bingbot. We have checked IP address details and verified that this is not a blacklisted IP.Let us know if you have any further queries on this.###Hello Team,We have received another Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.20 which belongs to the secure ELB.On the further analysis on the ELB logs, we could see the IP 108.21.114.104 having 403 response code.The IP 108.21.114.104 which belongs to MCI Communications Services, Inc. d/b/a Verizon Business from New York is tried to execute Apache Struts remote code.We have checked IP address details and verified that this is not a blacklisted IP.  Please let us know whether we can block this IP and let us know if you have any further queries on this.###Hello SpendHQ-Team, On further analyzing the ELB logs at the time of the alert we could see the IP 137.226.113.7 having 403 response code.The IP 137.226.113.7 which belongs to RIPE Network Coordination Centre (RIPE) in Amsterdam is trying to execute Apache Struts remote code.As per https://www.abuseipdb.com, this IP address has been reported a total of 73 times for web app attack and port scan. We have blocked the IP address at NACL level.  Please let us know if you have any queries regarding this.###Hello Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167   which belongs to the preview ELB. Please find the IPS logs below. 2017:05:13-13:02:51 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=35818 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:13-13:02:51 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=35818 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are analyzing the ELB logs and will let you know the further updates.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-13 13:02:51Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167 Source port: 35818Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http),[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,13-05-2017 18:46,40,0,SpendHQ,"We have verified from the instance level that we are not using the JAVA module Struts in our application and this incident will not affect our application.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries. Best Regards, Safuvan KM","Hello SpendHQ-Team, We have again received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.123 which belongs to the secure ELB.On the further analysis on the ELB logs, we could see the IP 40.77.167.108 having 404 response code. The IP 40.77.167.108 is belongs to Microsoft bingbot. We have checked IP address details and verified that this is not a blacklisted IP.Let us know if you have any further queries on this.","Hello Team,We have received another Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.20 which belongs to the secure ELB.On the further analysis on the ELB logs, we could see the IP 108.21.114.104 having 403 response code.The IP 108.21.114.104 which belongs to MCI Communications Services, Inc. d/b/a Verizon Business from New York is tried to execute Apache Struts remote code.We have checked IP address details and verified that this is not a blacklisted IP.  Please let us know whether we can block this IP and let us know if you have any further queries on this.","Hello SpendHQ-Team, On further analyzing the ELB logs at the time of the alert we could see the IP 137.226.113.7 having 403 response code.The IP 137.226.113.7 which belongs to RIPE Network Coordination Centre (RIPE) in Amsterdam is trying to execute Apache Struts remote code.As per https://www.abuseipdb.com, this IP address has been reported a total of 73 times for web app attack and port scan. We have blocked the IP address at NACL level.  Please let us know if you have any queries regarding this.","Hello Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167   which belongs to the preview ELB. Please find the IPS logs below. 2017:05:13-13:02:51 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=35818 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:13-13:02:51 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=35818 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are analyzing the ELB logs and will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DpGuU,Cloud Engineer Level 1,Closed,1066750,Incident,05-07-2017 18:27,,"Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 3.02.Later the alert got resolved automatically and return to a normal state with the value of 2.985.","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.02This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3942569134177953231 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,05-07-2017 18:08,0,0,SpendHQ,"Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 3.02.Later the alert got resolved automatically and return to a normal state with the value of 2.985.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Vr9k7,Cloud Engineer Level 3,Closed,1098144,Incident,08-06-2018 01:40,,"We have created JIRA ticket for the case and assign the ticket to Rohit.MSI-11020 and closing this case.###I am closing this ticket. Because I unselected all the alert settings since we are dropping the packets which are attacks.Raise a Sophos request and ask them how to whitelist a VPC CIDR range in IPS and not to alert if the IP matches.Regards,-Praveen###As mentioned in the Ops call, Praveen is working on this and will provide an update.###As mentioned in the Ops call, Praveen is working on this and will provide an update.###Hello Team,We checked with Praveen during night shift since he was busy with some other priority works. He didn't respond.Please check with Praveen for the update on this case.###Evening OPS call Praveen updated that he will provide an update on this case.@Night Team: Please check with Praveen for the further update.###Hello Andrew, We are currently checking on this case and will let you know the updates.###During ops call, we asked Praveen for an update on this case. But we didn't hear back from him.  Next Action: Please check with Praveen for update on this###@afternoon team: Please check with Praveen for the further updates.###Hello Andrew,We are currently checking on this case and will let you know the updates.###Hello Praveen,Please provide an update on this.@afternoon team: Please check with Praveen for the further updates.###This should be resulted into Change ticket along with deployment plan and customer approval###ELB should be configured to support proxy protocol (External ELB) and listeners must be tcp not httpThen configure sophos to support proxy protocolTest it first and understand what all need to be configured to make it work and it requires downtime for applicationTestconfigure xELB -> Sophos -> internalELB -> webserver and make this work without proxy supportreconfigure xELB to support proxy protocol, change listener to TCP (I don't know whether they started supporting proxyprotocol with http listener), enable proxyprotocol support in UTM, internal elb / app remains same, hit the external elb and watch sophos logs to see if you are able to see source ip addresses###Praveen will look into this and update us.###I had a discussion with Praveen on this yesterday. We have to enable the Proxy Protocol so that we can have the real IP of source instead of ELB ip whenever we get this alert. For now we ave diabled the Intrusion Prevention Alert notification as when we analysed the logs we found that the traffic is coming from SOPHOS to SOPHOS. Need to get more details on Proxy Protocol enabling. Discussion internally with the team. I will update the case later today.###During morning ops call Rohit mentioned he will check once he get time.###Hello Andrew,Thanks for the update.We will check further on this and will get back to you with details.###No, we do not have another Sophos WAF###Hi Team,We analysed the logs for the high number of Intrusion Prevention Alerts. We found that high number of request were coming from the Sophos to Sophos only. As this is because, the sites are setup in the WAF of SOPHOS. When we analysed the logs of ELB we found the request were coming from SOPHOS. Therefore, we want to ask you is site do send request to another site which is configured under WAF of SOPHOS ?###Rohit mentioned that he will add the details on this ticket###Yesterday Evening OPS Call Rohit updated that he will look and update,Next action: Need to check with Rohit for further update.###Need to get the update from Rohit.###Hello Team, This is to inform you that we are receiving multiple Intrusion Prevention Alert from Sophos, the source IPs and corresponding ELB below. 10.59.1.169 and 10.59.0.71 ==> api-spendhq-com 10.59.1.97 and 10.59.0.57 ==> SpendHQ-CAT-MapD-xELB 10.59.0.251 and 10.59.1.118 ==> Preview-api-spendhq-com 10.59.1.234 and 10.59.0.219 ==> preview-spendhq-xelb 10.59.0.218 and 10.59.1.102==> capfiles-spendhq-xelb Name: Intrusion protection alert Action: drop, Reason: SERVER-WEBAPP Drupal 8 remote code execution attempt detected , SERVER-WEBAPP D-Link getcfg.php credential disclosure attempt Class: Attempted Administrator Privilege Gain ,Attempted Information Leak Please find the source/destination details and intrusion prevention logs and ELB logs from the attachment section.###Please find the attached elb logs. From the logs we could see all the request are from different IP's and for the preview-spendhq-xelb we could see the request are trying to access the index.php pages. Please analyse the logs and inform all the details customer###Hello Team,This is to inform you that we are receiving  multiple  Intrusion Prevention Alert from Sophos, the source IPs and corresponding ELB below.10.59.1.169 and 10.59.0.71 ==>  api-spendhq-com10.59.1.97 and 10.59.0.57 ==>  SpendHQ-CAT-MapD-xELB10.59.0.251 and 10.59.1.118  ==> Preview-api-spendhq-com10.59.1.234   and 10.59.0.219 ==> preview-spendhq-xelb10.59.0.218  and 10.59.1.102==>  capfiles-spendhq-xelbName: Intrusion protection alert Action: drop, Reason: SERVER-WEBAPP Drupal 8 remote code execution attempt detected , SERVER-WEBAPP D-Link getcfg.php credential disclosure attemptClass: Attempted Administrator Privilege Gain ,Attempted Information LeakPlease find the source/destination details and intrusion prevention logs from the attachment section.","---------- Forwarded message ----------From: <ms@reancloud.com>Date: Mon, May 7, 2018 at 4:38 AMSubject: [SpendHQ] [10.59.1.192] [CRIT-852] Intrusion Prevention Alert(Packet dropped)To: ms@reancloud.comIntrusion Count: 130Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-WEBAPP Drupal 8 remote code execution attemptdetectedDetails........: https://www.snort.org/search?query=46316Time...........: 2018-05-06 23:08:16Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.118Source port: 46355Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)Account Name - SpendHQAccount DL - ms@reancloud.comUTM Hostname - spendhq-utmPrivate IP - 10.59.1.192Public IP - 52.0.17.10Device URL - https://52.0.17.10:4444-- System Uptime      : 132 days 16 hours 5 minutesSystem Load        : 0.17System Version     : Sophos UTM 9.506-2Please refer to the manual for detailed instructions.--  <http://go.reancloud.com/gartner-magic-quadrant>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [SpendHQ] [10.59.1.192] [CRIT-852] Intrusion Prevention Alert (Packet dropped),,07-05-2018 04:42,765,0,SpendHQ,We have created JIRA ticket for the case and assign the ticket to Rohit.MSI-11020 and closing this case.,"I am closing this ticket. Because I unselected all the alert settings since we are dropping the packets which are attacks.Raise a Sophos request and ask them how to whitelist a VPC CIDR range in IPS and not to alert if the IP matches.Regards,-Praveen","As mentioned in the Ops call, Praveen is working on this and will provide an update.","As mentioned in the Ops call, Praveen is working on this and will provide an update.","Hello Team,We checked with Praveen during night shift since he was busy with some other priority works. He didn't respond.Please check with Praveen for the update on this case.",Evening OPS call Praveen updated that he will provide an update on this case.@Night Team: Please check with Praveen for the further update.,"Hello Andrew, We are currently checking on this case and will let you know the updates.","During ops call, we asked Praveen for an update on this case. But we didn't hear back from him.  Next Action: Please check with Praveen for update on this",@afternoon team: Please check with Praveen for the further updates.,"Hello Andrew,We are currently checking on this case and will let you know the updates.","Hello Praveen,Please provide an update on this.@afternoon team: Please check with Praveen for the further updates.",This should be resulted into Change ticket along with deployment plan and customer approval,"ELB should be configured to support proxy protocol (External ELB) and listeners must be tcp not httpThen configure sophos to support proxy protocolTest it first and understand what all need to be configured to make it work and it requires downtime for applicationTestconfigure xELB -> Sophos -> internalELB -> webserver and make this work without proxy supportreconfigure xELB to support proxy protocol, change listener to TCP (I don't know whether they started supporting proxyprotocol with http listener), enable proxyprotocol support in UTM, internal elb / app remains same, hit the external elb and watch sophos logs to see if you are able to see source ip addresses",Praveen will look into this and update us.,I had a discussion with Praveen on this yesterday. We have to enable the Proxy Protocol so that we can have the real IP of source instead of ELB ip whenever we get this alert. For now we ave diabled the Intrusion Prevention Alert notification as when we analysed the logs we found that the traffic is coming from SOPHOS to SOPHOS. Need to get more details on Proxy Protocol enabling. Discussion internally with the team. I will update the case later today.,During morning ops call Rohit mentioned he will check once he get time.,"Hello Andrew,Thanks for the update.We will check further on this and will get back to you with details.","No, we do not have another Sophos WAF","Hi Team,We analysed the logs for the high number of Intrusion Prevention Alerts. We found that high number of request were coming from the Sophos to Sophos only. As this is because, the sites are setup in the WAF of SOPHOS. When we analysed the logs of ELB we found the request were coming from SOPHOS. Therefore, we want to ask you is site do send request to another site which is configured under WAF of SOPHOS ?",Rohit mentioned that he will add the details on this ticket,"Yesterday Evening OPS Call Rohit updated that he will look and update,Next action: Need to check with Rohit for further update.",Need to get the update from Rohit.,"Hello Team, This is to inform you that we are receiving multiple Intrusion Prevention Alert from Sophos, the source IPs and corresponding ELB below. 10.59.1.169 and 10.59.0.71 ==> api-spendhq-com 10.59.1.97 and 10.59.0.57 ==> SpendHQ-CAT-MapD-xELB 10.59.0.251 and 10.59.1.118 ==> Preview-api-spendhq-com 10.59.1.234 and 10.59.0.219 ==> preview-spendhq-xelb 10.59.0.218 and 10.59.1.102==> capfiles-spendhq-xelb Name: Intrusion protection alert Action: drop, Reason: SERVER-WEBAPP Drupal 8 remote code execution attempt detected , SERVER-WEBAPP D-Link getcfg.php credential disclosure attempt Class: Attempted Administrator Privilege Gain ,Attempted Information Leak Please find the source/destination details and intrusion prevention logs and ELB logs from the attachment section.",Please find the attached elb logs. From the logs we could see all the request are from different IP's and for the preview-spendhq-xelb we could see the request are trying to access the index.php pages. Please analyse the logs and inform all the details customer,"Hello Team,This is to inform you that we are receiving  multiple  Intrusion Prevention Alert from Sophos, the source IPs and corresponding ELB below.10.59.1.169 and 10.59.0.71 ==>  api-spendhq-com10.59.1.97 and 10.59.0.57 ==>  SpendHQ-CAT-MapD-xELB10.59.0.251 and 10.59.1.118  ==> Preview-api-spendhq-com10.59.1.234   and 10.59.0.219 ==> preview-spendhq-xelb10.59.0.218  and 10.59.1.102==>  capfiles-spendhq-xelbName: Intrusion protection alert Action: drop, Reason: SERVER-WEBAPP Drupal 8 remote code execution attempt detected , SERVER-WEBAPP D-Link getcfg.php credential disclosure attemptClass: Attempted Administrator Privilege Gain ,Attempted Information LeakPlease find the source/destination details and intrusion prevention logs from the attachment section.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bma5j,Cloud Engineer Level 1,Closed,1105025,Incident,22-09-2018 04:21,,"Hello Team,This is to inform you that the EC2 i3.8xlarge limit in the US East (Northern Virginia) region has been increased to 10.Since the limit got increased we are marking the case as closed.###Hello there,Diego here, from AWS Billing & Accounts.I’m happy to inform you that we've approved and processed your EC2 i3.8xlarge limit increase request for the US East (Northern Virginia) region, and your new limit is 10. Please keep in mind that it can sometimes take up to 15 minutes for the new limit to take effect and become available for use. Thanks for your patience while we worked on your limit increase request.I hope this helps, and let us know if you have any other questions.Have a great one!!Best regards,Diego MAmazon Web Services###Limit increase request 1Service: EC2 InstancesRegion: US East (Northern Virginia)Primary Instance Type: i3.8xlargeLimit name: Instance LimitNew limit value: 10------------Use case description: Hello AWS Team,We are requesting you to increase the number of the on-demand instance with instance type  i3.8xlarge from 5 to 10.Thank you. =======================================Limit increase request 1Service: SES Sending LimitsRegion: US East (Northern Virginia)Limit name: Desired Daily Sending QuotaNew limit value: 150000------------Use case description: Hello Team,This is a high priority request. Please increase our SES daily sending quota limit to 150000 ASAP.Mail Type: OtherWebsite URL: spendhq.comMy email-sending complies with the AWS Service Terms and AUP: YesI only send to recipients who have specifically requested my mail: YesI have a process to handle bounces and complaints: Yes =======================================###Hello Team,This is to inform you that,  We have received an AWS limit checker ALERT for  Resources EC2 and SES.REGION      |       RESOURCE |    LIMIT       |      USAGE       |         SERVICE                                                                                             us-east-1     |     EC2                |      5             |        4               |         On-Demand instances - i3.8xlarge                                                                                                  us-east-1     |      SES               |      126700   |        102246     |            Daily sending quota                                                                                                               Amazon SES Sending LimitsBelow are the latest statistics and metrics related to your Amazon SES Usage.Sending Quota:         	send 126700 emails per 24 hour periodQuota Used:	               81% as of 2018-09-21 17:08 UTC+5:30Max Send Rate:	      32 emails/secondLast updated:	              2018-09-21 17:08 UTC+5:30Ec2 Instances using i3.8xlargeInstances: i-0382b753fdc5a21bd (SpendHQ-memsql-server2-2018-04-01), i-05b27d1c4fdea7552 (SpendHQ-memsql-server4-2018-09-20), i-073579ff33c73d3cd (SpendHQ-memsql-server1-2018-04-01), i-093eff6fae479397c (SpendHQ-memsql-server3-2018-04-01)Currently, we are working with AWS team to increase the limit for EC2 and SES as below For Ec2 Increasing limit from 5 to 10For SES increasing 120k to 150k Please let us know if you have any concerns","---------- Forwarded message ---------From: AWS-Limit <no-reply@sns.amazonaws.com>Date: Fri, Sep 21, 2018 at 3:00 PMSubject: REAN CLOUD AWS limit checker ALERT for spendhq - WARNINGTo: <ms@reancloud.com>Below are resource details that cross limitsREGION       RESOURCE   LIMIT          USAGE          SERVICEus-east-1       EC2               5               4               On-Demandinstances - i3.8xlargeus-east-1       SES               126700          102246          Dailysending quota--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-west-2.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-west-2:210278571640:AWS-Limit:1217fddf-d8e0-4042-af10-1de467aaca07&Endpoint=ms@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support-- *Thank You,**        Rafi R*--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: REAN CLOUD AWS limit checker ALERT for spendhq - WARNING,,21-09-2018 15:17,13,0,SpendHQ,"Hello Team,This is to inform you that the EC2 i3.8xlarge limit in the US East (Northern Virginia) region has been increased to 10.Since the limit got increased we are marking the case as closed.","Hello there,Diego here, from AWS Billing & Accounts.I’m happy to inform you that we've approved and processed your EC2 i3.8xlarge limit increase request for the US East (Northern Virginia) region, and your new limit is 10. Please keep in mind that it can sometimes take up to 15 minutes for the new limit to take effect and become available for use. Thanks for your patience while we worked on your limit increase request.I hope this helps, and let us know if you have any other questions.Have a great one!!Best regards,Diego MAmazon Web Services","Limit increase request 1Service: EC2 InstancesRegion: US East (Northern Virginia)Primary Instance Type: i3.8xlargeLimit name: Instance LimitNew limit value: 10------------Use case description: Hello AWS Team,We are requesting you to increase the number of the on-demand instance with instance type  i3.8xlarge from 5 to 10.Thank you. =======================================Limit increase request 1Service: SES Sending LimitsRegion: US East (Northern Virginia)Limit name: Desired Daily Sending QuotaNew limit value: 150000------------Use case description: Hello Team,This is a high priority request. Please increase our SES daily sending quota limit to 150000 ASAP.Mail Type: OtherWebsite URL: spendhq.comMy email-sending complies with the AWS Service Terms and AUP: YesI only send to recipients who have specifically requested my mail: YesI have a process to handle bounces and complaints: Yes =======================================","Hello Team,This is to inform you that,  We have received an AWS limit checker ALERT for  Resources EC2 and SES.REGION      |       RESOURCE |    LIMIT       |      USAGE       |         SERVICE                                                                                             us-east-1     |     EC2                |      5             |        4               |         On-Demand instances - i3.8xlarge                                                                                                  us-east-1     |      SES               |      126700   |        102246     |            Daily sending quota                                                                                                               Amazon SES Sending LimitsBelow are the latest statistics and metrics related to your Amazon SES Usage.Sending Quota:         	send 126700 emails per 24 hour periodQuota Used:	               81% as of 2018-09-21 17:08 UTC+5:30Max Send Rate:	      32 emails/secondLast updated:	              2018-09-21 17:08 UTC+5:30Ec2 Instances using i3.8xlargeInstances: i-0382b753fdc5a21bd (SpendHQ-memsql-server2-2018-04-01), i-05b27d1c4fdea7552 (SpendHQ-memsql-server4-2018-09-20), i-073579ff33c73d3cd (SpendHQ-memsql-server1-2018-04-01), i-093eff6fae479397c (SpendHQ-memsql-server3-2018-04-01)Currently, we are working with AWS team to increase the limit for EC2 and SES as below For Ec2 Increasing limit from 5 to 10For SES increasing 120k to 150k Please let us know if you have any concerns",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FawdL,Cloud Engineer Level 1,Closed,1071371,Incident,03-08-2017 06:31,,"Hello Matthew,We haven't heard back from you regarding this case.We have checked and confirmed that the preview.spendhq.com URL is loading fine and hence we have disabled the maintenance enabled on this URL. Kindly validate these details and revert back in case of any further queries.At this time, we are marking this case as closed.Regards,Sumod.K.Bose###Hello Matthew,Could you please let us know if the maintenance on preview.spendhq.com has been completed? If so, we can disable the maintenance mode enabled on this URL.As of now, we can see that this web page is loading fine. Validate these details and revert back incase of any queries.Regards,Sumod.K.Bose###I have reduced the priority to P4 since it is a maintenance doing from the customer.###Hello Matthew,Thanks for your confirmation.We have enabled maintenance mode for preview.spendhq.com/login. Please let us know once you are done with the maintenance so that we can disable the maintenance back again.Regards,Sumod.K.Bose###We are working on this code base and will advise once this is complete.Regards,Matthew Watts###Hello SpendHQ-Team,This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. The site is still down and we are unable to access the website.We are currently analyzing this issue and will get back to you with further updates. Meanwhile please let us know if your team is performing any activity from your end which has caused this outage.Regards,Sumod.K.Bose","Wed, 02 Aug 2017 14:15:38 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Frankfurt DE, Sydney-C AU, Dallas-B US, London UK-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,02-08-2017 23:45,7,0,SpendHQ,"Hello Matthew,We haven't heard back from you regarding this case.We have checked and confirmed that the preview.spendhq.com URL is loading fine and hence we have disabled the maintenance enabled on this URL. Kindly validate these details and revert back in case of any further queries.At this time, we are marking this case as closed.Regards,Sumod.K.Bose","Hello Matthew,Could you please let us know if the maintenance on preview.spendhq.com has been completed? If so, we can disable the maintenance mode enabled on this URL.As of now, we can see that this web page is loading fine. Validate these details and revert back incase of any queries.Regards,Sumod.K.Bose",I have reduced the priority to P4 since it is a maintenance doing from the customer.,"Hello Matthew,Thanks for your confirmation.We have enabled maintenance mode for preview.spendhq.com/login. Please let us know once you are done with the maintenance so that we can disable the maintenance back again.Regards,Sumod.K.Bose","We are working on this code base and will advise once this is complete.Regards,Matthew Watts","Hello SpendHQ-Team,This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. The site is still down and we are unable to access the website.We are currently analyzing this issue and will get back to you with further updates. Meanwhile please let us know if your team is performing any activity from your end which has caused this outage.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ZkjMa,Cloud Engineer Level 1,Closed,1102592,Incident,11-08-2018 06:25,,"Hello Team,As the alert in the recovered state, we are marking this case as resolved hence closing. Kindly revert back to us in case of any queries.###Hello SpendHQ Team,This is to notify you that we have received multiple alerts regarding High CPU Load on host spendhq-memsql-server3-2018-04-01 - 10.59.100.230.The alerts are getting recovered within 1 hour. From the instance level we can see that the process memsqld is consuming much CPU and memory which is causing the issue. PID     USER   PR  NI  VIRT RES  SHR S  %CPU %MEM   TIME+ COMMAND14443 memsql  20  0 0.125t 0.109t  36812 S  1306 46.5  11736:50 memsqldPlease see the attachment section for the detailed processes consumption and let us know if you have any queries.Resource details:Instance Name: SpendHQ-memsql-server3-2018-04-01Instance ID: i-093eff6fae479397cInstance type: i3.8xlargevailability zone: us-east-1bPrivate IPs: 10.59.100.230","---------- Forwarded message ----------From: Datadog Alerting <alert@dtdg.co>Date: Fri, Aug 10, 2018 at 7:20 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on hostspendhq-memsql-server3-2018-04-01 - 10.59.100.230 -To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High CPU Load on host spendhq-memsql-server3-2018-04-01- 10.59.100.230 -Detected High CPU load. Log in to the machine and verify which process isconsuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023975?to_ts=1533918045000&group=host%3Ai-093eff6fae479397c&from_ts=1533910845000>*system.load.15* over *datadog_monitor:on,host:i-093eff6fae479397c* was *>4.0* on average during the *last 1h*.The monitor was last triggered at Fri Aug 10 2018 16:20:55 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023975?group=host%3Ai-093eff6fae479397c>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023975/edit>] · [Viewi-093eff6fae479397c<https://app.datadoghq.com/infrastructure?filter=i-093eff6fae479397c>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1533918175000&tags=host%3Ai-093eff6fae479397c&from_ts=1533917155000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4524063375853573514>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- *Mr. Stephen Oduor Otieno**Junior Cloud Engineer**REĀN Cloud. **stephen.oduor@reancloud.com <stephen.oduor@reancloud.com> |www.reancloud.com <http://www.reancloud.com>**AWS SysOps-Admin Associate Certified*--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on host spendhq-memsql-server3-2018-04-01 - 10.59.100.230 -,,10-08-2018 21:53,9,0,SpendHQ,"Hello Team,As the alert in the recovered state, we are marking this case as resolved hence closing. Kindly revert back to us in case of any queries.","Hello SpendHQ Team,This is to notify you that we have received multiple alerts regarding High CPU Load on host spendhq-memsql-server3-2018-04-01 - 10.59.100.230.The alerts are getting recovered within 1 hour. From the instance level we can see that the process memsqld is consuming much CPU and memory which is causing the issue. PID     USER   PR  NI  VIRT RES  SHR S  %CPU %MEM   TIME+ COMMAND14443 memsql  20  0 0.125t 0.109t  36812 S  1306 46.5  11736:50 memsqldPlease see the attachment section for the detailed processes consumption and let us know if you have any queries.Resource details:Instance Name: SpendHQ-memsql-server3-2018-04-01Instance ID: i-093eff6fae479397cInstance type: i3.8xlargevailability zone: us-east-1bPrivate IPs: 10.59.100.230",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gcwmQ,Cloud Engineer Level 1,Closed,1109665,Incident,22-12-2018 07:51,,"Thanks for your confirmation. We are marking this case as closed.###Matthew Watts7:48 AM (0 minutes ago)to Rean, spendhq-support@reancloud.comWe can close this case now.###Hello Kristen,This is quick follow up.Please let us know if you have any update on this case.###Thanks Kristen!Please do keep us posted.Regards.Stephen Oduor###Kristen Stretch12:40 AM (0 minutes ago)to meOk , may be something on my end. I will poke around and get back to you.###Hi Kristen,We haven't made any Port 22 (SSH) security group changes related to the matt_t2.xlarge SG.Please provide us with the details of the access issue you are facing so we can help.Thanks.Stephen Oduor###Hi Stephen,Everything seems to work however I can no longer get into the matt_t2.xlarge box. Could this be related to the config change?-Kristen###Hello Kristen & SpendHQ Team,We have made the changes to the respective SGs as per discussions on call in order to leverage the security loop that was there before.Below are the changes made:1. On Jenkins Master SG: We have allowed ssh from VPC CIDR Block 10.59.0.0/16 2. On matt_t2.xlarge SG: We have restricted Port 25 to VPC CIDR 10.59.0.0/16Please verify if everything is working fine and let us know if you are facing any issues.Thanks.​Stephen Oduor###stephen.oduor [10:46 PM]Hello Praveen,According to Matthew's approval on the above case, is it okay if I make these changes on the respective SGs?.1. On Jenkins Master SG: Allow ssh from VPC CIDR Block 10.59.0.0/162. On matt_t2.xlarge SG: restrict Port 25 to VPC CIDR 10.59.0.0/16 (This port is currently open to the world. I have doubts on this because the SG is associated to Prod Servers.)Praveen Kumar Muppala [10:54 PM]Go aheadBoth looks good.stephen.oduor [10:55 PM]Sure. Thanks.###Hello Kristen,We had a call with Matthew on the issue and will be working on the recommendations.We will keep you posted on the progress of the case.Thanks.Stephen Oduor###Kristen Stretch5:56 PM (3 hours ago)to meHi Stephen, Any update?###Hello Matthew,Thanks for the approval.We will work on it and will get back to you with an update.###Please lock down 22 for just VPN connections and lock SMTP. Matthew Watts | Manager, Application Development | SpendHQ®###Hi Matthew,As discussed on the call, here are changes you need to take care:1. On instance JENKINS_MASTER (10.59.100.188) Port 22 is open for 0.0.0.0/0 For security reason, we recommend either give us approval to restrict it to be ssh after VPN is connected or please restrict from you end.2. On instance matt_t2.xlarge(10.59.10.19) Port 25 is open for 0.0.0.0/0We recommend you to restrict or remove the SMTP (Port 25) if it is not required.Please let us know if you have any question. Thanks.###@Praveen:Please find the details below:1. The tags are not properly reflecting whether the (matt_t2.xlarge is slave or what type of machine it is) ---> I will work along with Matthew on this as Customer has created this instance.2. The SG name for the Jenkins Master instance is not following the standard naming convention(REAN Team find out who created this instance from CloudTrail) ---> Chnadrapratap completed this request for the below request:https://reancloud.cloudforce.com/5000G00001d1fwG?srPos=3&srKp=00a3. The Jenkins SG's many ports are opened to the public which is a security issue though it is running privately. This needs to be reviewed and limit it to your VPC CIDR network.----> I will work along with SpendHQ team to get it resolve in todays call. 4. matt_t2.xlarge instance is using the Prod Web Security group if it is a slave Jenkins it should having it's own SG. ----> I will work along with SpendHQ team to get it resolve in todays call.5. In SpendHQ_Private_Webserver_Security_Group Inbound rule with 25 port opened to the public which is a security issue. ---> This will also be taken care.###[email  update from Matthew]We can discuss on tomorrow’s call. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting###Hello SpendHQ Team,There are many fundamental mistakes in this server setup.1. The tags are not properly reflecting whether the (matt_t2.xlarge is slave or what type of machine it is)2. The SG name for the Jenkins Master instance is not following the standard naming convention(REAN Team find out who created this instance from CloudTrail)3. The Jenkins SG's many ports are opened to the public which is a security issue though it is running privately. This needs to be reviewed and limit it to your VPC CIDR network.4. matt_t2.xlarge instance is using the Prod Web Security group if it is a slave Jenkins it should having it's own SG.5. In SpendHQ_Private_Webserver_Security_Group Inbound rule with 25 port opened to the public which is a security issue.All these items need to be addressed ASAP. @rohit, please take a lead on this.Regards,-Praveen###Hi Kristen,Thanks for the prompt response.We will work on your request and get back to you with an update.Thanks.###Hi Stephen, I am unsure how to implement this change, but I also have only limited access myself. If you could assist me in making the changes that would be great. -Kristen###Hello Kristen.Sorry for the late reply.We have reviewed these two instances and we can see they are both in the same VPC (VPC ID: vpc-76df7212) but different subnets.To enable secure communication between these two instances, all you have to do is allow traffic from the CIDR block of this VPC or subnets on the respective security groups of the servers.The CIDR block are as below:VPC ID: vpc-76df7212CIDR: 10.59.0.0/16 Jenkins Master:Subnet: subnet-0d093d27Subnet CIDR: 10.59.100.0/24Security Group: launch-wizard-1matt_t2.xlarge:Subnet: subnet-0fdde924Subnet CIDR: 10.59.10.0/24Security Group in use: SpendHQ_Private_Webserver_Security_GroupFor example, to allow ssh to Jenkins Master from matt_t2.xlarge, allow traffic on Port 22 from CIDR 10.59.10.0/24 on the launch-wizard-1 security group and vice versa.Please let us know if you need our assistance on implementing this changes and we will be glad to help.Thanks.Stephen Oduor###Kristen Stretch9:33 PM (57 minutes ago)to support@reancloud.comChecking for an update on the below, as I have not heard anything yet.###Hi Kristen,We acknowledge your request.We will look into it and will get back to you with more details.Thanks,","Hi, I need to make sure this port is secure. I am using this instance to communicate with the Jenkins slave node machine ( matt_t2.xlarge, Instance ID: i-02f014e2b71f64bd8, Private IP: 10.59.10.19). What needs to be done to secure this while still allowing for communication between the machines?-KristenFrom: Matthew WattsSent: Saturday, December 15, 2018 5:35 PMTo: Kristen Stretch <kstretch@spendhq.com>Subject: Re: [Managed Cloud: spendhq] EC2 Exposed Instance AlertMaybe they opened to the world instead? Worth checking and locking to that sole IPV4Get Outlook for iOS<https://aka.ms/o0ukef>________________________________From: Kristen Stretch <kstretch@spendhq.com<mailto:kstretch@spendhq.com>>Sent: Saturday, December 15, 2018 5:34 pmTo: Matthew WattsSubject: Re: [Managed Cloud: spendhq] EC2 Exposed Instance AlertPotentially, trying to determine if that's the port used to communicate with the slave node. I believe I requested it be open to Jenkins node.________________________________From: Matthew WattsSent: Saturday, December 15, 2018 10:15:47 AMTo: Kristen StretchSubject: Fwd: [Managed Cloud: spendhq] EC2 Exposed Instance AlertWhat is this all about? Can we lock it down?Get Outlook for iOS<https://aka.ms/o0ukef>________________________________From: notifications@mnc-notify.com<mailto:notifications@mnc-notify.com>Sent: Saturday, December 15, 2018 10:05 amTo: Matthew WattsSubject: [Managed Cloud: spendhq] EC2 Exposed Instance AlertREAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::EC2::Instance resources were affected:________________________________  *   Violation: A forbidden port is exposed to the internet.  *   Recommendation: Please ensure you have followed the correct procedure to open this rule.  *   Action taken: None  *   Resource details:Resource IDInstance NameRegionExposed IPExposed Porti-079130613ab17ad30JENKINS_MASTERus-east-10.0.0.0/022________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Managed Cloud: spendhq] EC2 Exposed Instance Alert,,19-12-2018 21:01,59,0,SpendHQ,Thanks for your confirmation. We are marking this case as closed.,"Matthew Watts7:48 AM (0 minutes ago)to Rean, spendhq-support@reancloud.comWe can close this case now.","Hello Kristen,This is quick follow up.Please let us know if you have any update on this case.",Thanks Kristen!Please do keep us posted.Regards.Stephen Oduor,"Kristen Stretch12:40 AM (0 minutes ago)to meOk , may be something on my end. I will poke around and get back to you.","Hi Kristen,We haven't made any Port 22 (SSH) security group changes related to the matt_t2.xlarge SG.Please provide us with the details of the access issue you are facing so we can help.Thanks.Stephen Oduor","Hi Stephen,Everything seems to work however I can no longer get into the matt_t2.xlarge box. Could this be related to the config change?-Kristen","Hello Kristen & SpendHQ Team,We have made the changes to the respective SGs as per discussions on call in order to leverage the security loop that was there before.Below are the changes made:1. On Jenkins Master SG: We have allowed ssh from VPC CIDR Block 10.59.0.0/16 2. On matt_t2.xlarge SG: We have restricted Port 25 to VPC CIDR 10.59.0.0/16Please verify if everything is working fine and let us know if you are facing any issues.Thanks.​Stephen Oduor","stephen.oduor [10:46 PM]Hello Praveen,According to Matthew's approval on the above case, is it okay if I make these changes on the respective SGs?.1. On Jenkins Master SG: Allow ssh from VPC CIDR Block 10.59.0.0/162. On matt_t2.xlarge SG: restrict Port 25 to VPC CIDR 10.59.0.0/16 (This port is currently open to the world. I have doubts on this because the SG is associated to Prod Servers.)Praveen Kumar Muppala [10:54 PM]Go aheadBoth looks good.stephen.oduor [10:55 PM]Sure. Thanks.","Hello Kristen,We had a call with Matthew on the issue and will be working on the recommendations.We will keep you posted on the progress of the case.Thanks.Stephen Oduor","Kristen Stretch5:56 PM (3 hours ago)to meHi Stephen, Any update?","Hello Matthew,Thanks for the approval.We will work on it and will get back to you with an update.","Please lock down 22 for just VPN connections and lock SMTP. Matthew Watts | Manager, Application Development | SpendHQ®","Hi Matthew,As discussed on the call, here are changes you need to take care:1. On instance JENKINS_MASTER (10.59.100.188) Port 22 is open for 0.0.0.0/0 For security reason, we recommend either give us approval to restrict it to be ssh after VPN is connected or please restrict from you end.2. On instance matt_t2.xlarge(10.59.10.19) Port 25 is open for 0.0.0.0/0We recommend you to restrict or remove the SMTP (Port 25) if it is not required.Please let us know if you have any question. Thanks.",@Praveen:Please find the details below:1. The tags are not properly reflecting whether the (matt_t2.xlarge is slave or what type of machine it is) ---> I will work along with Matthew on this as Customer has created this instance.2. The SG name for the Jenkins Master instance is not following the standard naming convention(REAN Team find out who created this instance from CloudTrail) ---> Chnadrapratap completed this request for the below request:https://reancloud.cloudforce.com/5000G00001d1fwG?srPos=3&srKp=00a3. The Jenkins SG's many ports are opened to the public which is a security issue though it is running privately. This needs to be reviewed and limit it to your VPC CIDR network.----> I will work along with SpendHQ team to get it resolve in todays call. 4. matt_t2.xlarge instance is using the Prod Web Security group if it is a slave Jenkins it should having it's own SG. ----> I will work along with SpendHQ team to get it resolve in todays call.5. In SpendHQ_Private_Webserver_Security_Group Inbound rule with 25 port opened to the public which is a security issue. ---> This will also be taken care.,"[email  update from Matthew]We can discuss on tomorrow’s call. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting","Hello SpendHQ Team,There are many fundamental mistakes in this server setup.1. The tags are not properly reflecting whether the (matt_t2.xlarge is slave or what type of machine it is)2. The SG name for the Jenkins Master instance is not following the standard naming convention(REAN Team find out who created this instance from CloudTrail)3. The Jenkins SG's many ports are opened to the public which is a security issue though it is running privately. This needs to be reviewed and limit it to your VPC CIDR network.4. matt_t2.xlarge instance is using the Prod Web Security group if it is a slave Jenkins it should having it's own SG.5. In SpendHQ_Private_Webserver_Security_Group Inbound rule with 25 port opened to the public which is a security issue.All these items need to be addressed ASAP. @rohit, please take a lead on this.Regards,-Praveen","Hi Kristen,Thanks for the prompt response.We will work on your request and get back to you with an update.Thanks.","Hi Stephen, I am unsure how to implement this change, but I also have only limited access myself. If you could assist me in making the changes that would be great. -Kristen","Hello Kristen.Sorry for the late reply.We have reviewed these two instances and we can see they are both in the same VPC (VPC ID: vpc-76df7212) but different subnets.To enable secure communication between these two instances, all you have to do is allow traffic from the CIDR block of this VPC or subnets on the respective security groups of the servers.The CIDR block are as below:VPC ID: vpc-76df7212CIDR: 10.59.0.0/16 Jenkins Master:Subnet: subnet-0d093d27Subnet CIDR: 10.59.100.0/24Security Group: launch-wizard-1matt_t2.xlarge:Subnet: subnet-0fdde924Subnet CIDR: 10.59.10.0/24Security Group in use: SpendHQ_Private_Webserver_Security_GroupFor example, to allow ssh to Jenkins Master from matt_t2.xlarge, allow traffic on Port 22 from CIDR 10.59.10.0/24 on the launch-wizard-1 security group and vice versa.Please let us know if you need our assistance on implementing this changes and we will be glad to help.Thanks.Stephen Oduor","Kristen Stretch9:33 PM (57 minutes ago)to support@reancloud.comChecking for an update on the below, as I have not heard anything yet.","Hi Kristen,We acknowledge your request.We will look into it and will get back to you with more details.Thanks,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015WutO,Cloud Engineer Level 1,Closed,1039564,Incident,23-12-2016 13:55,,"We are following this ticket with andromeda team over email. email subject Issue facing with nimble storage.###Hello SpendHQ-Team, We are marking this case as resolved for now. Please let us know if you have any more queries regarding this.###Sent an Email to chris.Hi Chris,We received an alert for site down for URL https://preview.spendhq.com/login on 12/18/2016 9:34 AM IST. In our analysis, we found that we are facing an issue where the nimble volumes /dev/sda and /dev/sdb got into read-only mode this causes the apache service down and resulted in the outage. So we tried to remount the volume but it shows busy so we restarted the machine and remounted the volume with proper permission which resolves the issue.We raised a support ticket with AWS to confirm whether there was any network issue from AWS side and they confirmed that it is not an issue from their side.Earlier also we faced the same issue on 12/14/2016 9:33 PM IST at that time there was a Network outage at AWS level so closed that ticket.Please let us know the why the volume got into read-only mode and help us to find a proper solution so that we can avoid it in future.###We tried to reach out Andromeda team in a call, but they are not picking up the phone call.###Hello SpendHQ-Team,Sorry for the delay.Please find the attached RCA prepared regarding the site down issue for the URL https://preview.spendhq.com/login. AWS team updated that there was no issue from their end during the time period of this issue.We are following up with Andromeda team for more updates on this issue.Meanwhile, please validate the RCA and let us know if your team have any further queries regarding this issue.Thanks,Sumod.K.Bose###Hello Team,We are still waiting for a reply from AWS team regarding this issue.We are still following up with them and will get back to you with updates.###Hi Team,We raised a support ticket with AWS to confirm whether there was any network issue from AWS side.We provided the traceroute to the endpoint as mentioned by AWS and waiting for a response from AWS side, will get back to you with updates ASAP.###AWS team informed that.Hello,Thank you for providing us with the information requested by my colleague George. I have reached out to him and we will continue troubleshooting on this issue further.Be rest assured that we will reach out to you as soon as we have an update on this issue.Highly appreciate your patience in this regard.Best regards,###We have provided the traceroute to the endpoint as mentioned by AWS and waiting for their response.###AWS ReplyHello, Sorry for the late response.To help the networking team troubleshooting this issue, could I ask you to provide a traceroute to the endpoint where the connection is failing if that is the case. For this last issue, a traceroute from the instance to the iSCSI server, will help to see the path that the package is following and check if there were any issue. However looking into the last logs you sent, this issue now seems to be different from what you were facing before. I did not see any networking error on the last log. These filesystems sda and sdb were checked with fsck, this is probably why they were mounted in read-only.I'm looking forward for the traceroute output, so we can provide information about what is happening.Best regards,George F.Amazon Web Services###We have prepared the RCA and waiting for the reply from AWS team regarding this issue. As soon as we heard back from them, we will update the RCA and will share it with the client.###readonlyerrors_spendHQ.txt is the log file attached to this ticket. Thanks###Hi Matthew,We reviewed the /var/log/messages and /var/log/httpd/error log file after the alert and see logs about filesystem being read only and few filesystem errors. Due to which httpd service was also not able to open files under /var/www/vhosts/files.spendhq.com/logs/ for writing logs which resulted in httpd service got stopped. (I have attached the log file for reference)We tried to umount the filesystem to mount it back but it was failing saying device is busy. So instead of doing force umount we restarted the server considering the fact the preview site was already down and should bring back asap.I apologize for not asking for prior consent and not in sync about the fact that the same mounts are also being used on the secure site.We understand the risk and will make sure we directly call you or get a consent before performing such operations on the environment.Please let us know if you have further queries regarding this. Thanks###I have personally resolved the issue described here, however please in the future do not restart the box unless you receive prior consent from to mitigate data loss.###Thank you for the fast response. My initial findings are that no mount points /exports_new are working on .125 which is making the file system unavailable on .118.###Hello Matthew,We acknowledge the delivery of your email. We have considered this as a P1 issue and will get back to you with the updates soon.Thanks,Sumod K Bose###Mail from Matthew WattsWhat made you restart that box in the first place? What indication did you get that the mount because read only? Due to the fact that the box (.125) was restarted, the file system mounts are now unavailable on our PRD (.118) server. Please work on making  this available immediately as this renders the PRD environment useless. I am available on 904.868.8848 if you need to talk. This is A SEV ONE!###Hello SpendHQ Team,In our analysis, we have found that we are facing the same issue again where the devices  /dev/sda and /dev/sdb got into read-only mode.To resolve the issue we tried to unmount the devices but we were not able to unmount it as the device were busy.So we went ahead and restarted the instance and again mounted the devices /dev/sda on /var/www/vhosts/files.spendhq.com and /dev/sdb on /var/www/vhosts/files1.spendhq.com which resolved the issue.Please find the logs messaged in the attachments.We are performing detailed analysis and will submit the RCA shortly.Andromeda Team, Please look into this issue and let us know why this device is got into read-only mode .###Hello SpendHQ Team, Please Ignore the previous notification. This is to notify you that we have received an alert for site down for URL https://preview.spendhq.com/login . We have checked and verified that the URL is not accessible. We are investigating more on this and will keep you posted.###Hello SpendHQ Team,This is to notify you that we have received an alert for site down for URL https://preview.spendhq.com/login . We have checked and verified that the URL accessible. We are investigating more on this and will keep you updated.","Sat, 17 Dec 2016 22:46:16 -0500Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 403, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): California US, London UK, Sydney-C AU, Frankfurt DE-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,18-12-2016 09:16,125,0,SpendHQ,We are following this ticket with andromeda team over email. email subject Issue facing with nimble storage.,"Hello SpendHQ-Team, We are marking this case as resolved for now. Please let us know if you have any more queries regarding this.","Sent an Email to chris.Hi Chris,We received an alert for site down for URL https://preview.spendhq.com/login on 12/18/2016 9:34 AM IST. In our analysis, we found that we are facing an issue where the nimble volumes /dev/sda and /dev/sdb got into read-only mode this causes the apache service down and resulted in the outage. So we tried to remount the volume but it shows busy so we restarted the machine and remounted the volume with proper permission which resolves the issue.We raised a support ticket with AWS to confirm whether there was any network issue from AWS side and they confirmed that it is not an issue from their side.Earlier also we faced the same issue on 12/14/2016 9:33 PM IST at that time there was a Network outage at AWS level so closed that ticket.Please let us know the why the volume got into read-only mode and help us to find a proper solution so that we can avoid it in future.","We tried to reach out Andromeda team in a call, but they are not picking up the phone call.","Hello SpendHQ-Team,Sorry for the delay.Please find the attached RCA prepared regarding the site down issue for the URL https://preview.spendhq.com/login. AWS team updated that there was no issue from their end during the time period of this issue.We are following up with Andromeda team for more updates on this issue.Meanwhile, please validate the RCA and let us know if your team have any further queries regarding this issue.Thanks,Sumod.K.Bose","Hello Team,We are still waiting for a reply from AWS team regarding this issue.We are still following up with them and will get back to you with updates.","Hi Team,We raised a support ticket with AWS to confirm whether there was any network issue from AWS side.We provided the traceroute to the endpoint as mentioned by AWS and waiting for a response from AWS side, will get back to you with updates ASAP.","AWS team informed that.Hello,Thank you for providing us with the information requested by my colleague George. I have reached out to him and we will continue troubleshooting on this issue further.Be rest assured that we will reach out to you as soon as we have an update on this issue.Highly appreciate your patience in this regard.Best regards,",We have provided the traceroute to the endpoint as mentioned by AWS and waiting for their response.,"AWS ReplyHello, Sorry for the late response.To help the networking team troubleshooting this issue, could I ask you to provide a traceroute to the endpoint where the connection is failing if that is the case. For this last issue, a traceroute from the instance to the iSCSI server, will help to see the path that the package is following and check if there were any issue. However looking into the last logs you sent, this issue now seems to be different from what you were facing before. I did not see any networking error on the last log. These filesystems sda and sdb were checked with fsck, this is probably why they were mounted in read-only.I'm looking forward for the traceroute output, so we can provide information about what is happening.Best regards,George F.Amazon Web Services","We have prepared the RCA and waiting for the reply from AWS team regarding this issue. As soon as we heard back from them, we will update the RCA and will share it with the client.",readonlyerrors_spendHQ.txt is the log file attached to this ticket. Thanks,"Hi Matthew,We reviewed the /var/log/messages and /var/log/httpd/error log file after the alert and see logs about filesystem being read only and few filesystem errors. Due to which httpd service was also not able to open files under /var/www/vhosts/files.spendhq.com/logs/ for writing logs which resulted in httpd service got stopped. (I have attached the log file for reference)We tried to umount the filesystem to mount it back but it was failing saying device is busy. So instead of doing force umount we restarted the server considering the fact the preview site was already down and should bring back asap.I apologize for not asking for prior consent and not in sync about the fact that the same mounts are also being used on the secure site.We understand the risk and will make sure we directly call you or get a consent before performing such operations on the environment.Please let us know if you have further queries regarding this. Thanks","I have personally resolved the issue described here, however please in the future do not restart the box unless you receive prior consent from to mitigate data loss.",Thank you for the fast response. My initial findings are that no mount points /exports_new are working on .125 which is making the file system unavailable on .118.,"Hello Matthew,We acknowledge the delivery of your email. We have considered this as a P1 issue and will get back to you with the updates soon.Thanks,Sumod K Bose","Mail from Matthew WattsWhat made you restart that box in the first place? What indication did you get that the mount because read only? Due to the fact that the box (.125) was restarted, the file system mounts are now unavailable on our PRD (.118) server. Please work on making  this available immediately as this renders the PRD environment useless. I am available on 904.868.8848 if you need to talk. This is A SEV ONE!","Hello SpendHQ Team,In our analysis, we have found that we are facing the same issue again where the devices  /dev/sda and /dev/sdb got into read-only mode.To resolve the issue we tried to unmount the devices but we were not able to unmount it as the device were busy.So we went ahead and restarted the instance and again mounted the devices /dev/sda on /var/www/vhosts/files.spendhq.com and /dev/sdb on /var/www/vhosts/files1.spendhq.com which resolved the issue.Please find the logs messaged in the attachments.We are performing detailed analysis and will submit the RCA shortly.Andromeda Team, Please look into this issue and let us know why this device is got into read-only mode .","Hello SpendHQ Team, Please Ignore the previous notification. This is to notify you that we have received an alert for site down for URL https://preview.spendhq.com/login . We have checked and verified that the URL is not accessible. We are investigating more on this and will keep you posted.","Hello SpendHQ Team,This is to notify you that we have received an alert for site down for URL https://preview.spendhq.com/login . We have checked and verified that the URL accessible. We are investigating more on this and will keep you updated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001OYVC1,Cloud Engineer Level 1,Closed,1088868,Incident,19-01-2018 00:07,,"Hi David, As we worked on the call and added your correct ssh keys to the server, And you were able to access the 10.59.10.190 server. Hence, We are closing this case on our side. Please let us know if you see any issue further.###Hello David,This request has been completed.Kindly check and let us know if you are able to access the server 10.59.10.190 using your own credentials. Also revert back incase of any further queries.Regards,Sumod.K.Bose###Please work on it and update customer###Hello David,Thanks for the update,As the issue got fixed, we are reducing the priority of this case.We will get back to you once we are done with copying your ssh key.###David Miller5:28 AM (0 minutes ago)￼￼￼to me￼Looks like we fixed the db issue, let’s look at copying my ssh key up there so next time I can deal with it directly, thank you###Hello David,We are looking into this and will get back to you shortly.","Rean,Our database has too many connection and we need to restart msyql infobright.  I also do not have an account on the box to do it myself.  Can you copy my key from another server to 10.59.10.190?Thank YouDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sev 1,,18-01-2018 05:21,19,0,SpendHQ,"Hi David, As we worked on the call and added your correct ssh keys to the server, And you were able to access the 10.59.10.190 server. Hence, We are closing this case on our side. Please let us know if you see any issue further.","Hello David,This request has been completed.Kindly check and let us know if you are able to access the server 10.59.10.190 using your own credentials. Also revert back incase of any further queries.Regards,Sumod.K.Bose",Please work on it and update customer,"Hello David,Thanks for the update,As the issue got fixed, we are reducing the priority of this case.We will get back to you once we are done with copying your ssh key.","David Miller5:28 AM (0 minutes ago)￼￼￼to me￼Looks like we fixed the db issue, let’s look at copying my ssh key up there so next time I can deal with it directly, thank you","Hello David,We are looking into this and will get back to you shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gd2kB,Cloud Engineer Level 1,Closed,1109678,Incident,20-12-2018 00:39,,We are following on this case: 01109665Hence closing this duplicate case.,"Checking for an update on the below, as I have not heard anything yet.Hi, I need to make sure this port is secure. I am using this instance to communicate with the Jenkins slave node machine ( matt_t2.xlarge, Instance ID: i-02f014e2b71f64bd8, Private IP: 10.59.10.19). What needs to be done to secure this while still allowing for communication between the machines?-KristenFrom: Matthew WattsSent: Saturday, December 15, 2018 5:35 PMTo: Kristen Stretch <kstretch@spendhq.com<mailto:kstretch@spendhq.com>>Subject: Re: [Managed Cloud: spendhq] EC2 Exposed Instance AlertMaybe they opened to the world instead? Worth checking and locking to that sole IPV4Get Outlook for iOS<https://aka.ms/o0ukef>________________________________From: Kristen Stretch <kstretch@spendhq.com<mailto:kstretch@spendhq.com>>Sent: Saturday, December 15, 2018 5:34 pmTo: Matthew WattsSubject: Re: [Managed Cloud: spendhq] EC2 Exposed Instance AlertPotentially, trying to determine if that's the port used to communicate with the slave node. I believe I requested it be open to Jenkins node.________________________________From: Matthew WattsSent: Saturday, December 15, 2018 10:15:47 AMTo: Kristen StretchSubject: Fwd: [Managed Cloud: spendhq] EC2 Exposed Instance AlertWhat is this all about? Can we lock it down?Get Outlook for iOS<https://aka.ms/o0ukef>________________________________From: notifications@mnc-notify.com<mailto:notifications@mnc-notify.com>Sent: Saturday, December 15, 2018 10:05 amTo: Matthew WattsSubject: [Managed Cloud: spendhq] EC2 Exposed Instance AlertREAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::EC2::Instance resources were affected:________________________________  *   Violation: A forbidden port is exposed to the internet.  *   Recommendation: Please ensure you have followed the correct procedure to open this rule.  *   Action taken: None  *   Resource details:Resource IDInstance NameRegionExposed IPExposed Porti-079130613ab17ad30JENKINS_MASTERus-east-10.0.0.0/022________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: [Managed Cloud: spendhq] EC2 Exposed Instance Alert,,20-12-2018 00:03,1,0,SpendHQ,We are following on this case: 01109665Hence closing this duplicate case.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gdELI,Cloud Engineer Level 1,Closed,1109710,Incident,25-12-2018 22:12,,"Hello Matthew,Thank you for the confirmation.We are now closing this case. Merry Christmas to you too!Thanks###Matthew Watts7:10 PM (29 minutes ago)to Rean, spendhq-support@reancloud.comLet’s close this. Thanks. Merry Christmas!###Hello Team, This is a gentle reminder.We have resolved the RO mode issue on the below all the 3 instances. SpendHQ-memsql-server3-2018-04-01 SpendHQ-memsql-server2-2018-04-01SpendHQ-memsql-server4-2018-09-20We have provided you access to the following instances. SpendHQ-memsql-server3-2018-04-01 SpendHQ-memsql-server2-2018-04-01Please verify the same and kindly let us know whether we are good to close the ticket.###Hello Team,We have resolved the RO mode issue on the below all the 3 instances.SpendHQ-memsql-server3-2018-04-01 -10.59.100.230 SpendHQ-memsql-server2-2018-04-01 -10.59.100.171 SpendHQ-memsql-server4-2018-09-20 -10.59.100.46 We have provided you access to the following instances. 10.59.100.230 10.59.100.171 Please verify the same and kindly let us know whether we are good to close the ticket.###Rohit mentioned to do follow up with the customer and get confirmation.###@Rohit, I have verified all the alerts that we received from the jenkins jobs yesterday are only for SpendHQ-memsql-server1.There is no alert triggered for the instances IPs you mentioned (SpendHQ-memsql-server2,3,4) Please let us know if we have any further action on this.###Hello Team,As this issue seems to be resolved, we are downgrading the priority of this ticket.Please verify from your end and let us know if you are facing any issues.###@Team:Whenever any volume goes into RO modewe get a mail with this subject line: ISCSI Device Details which are in RO modeAs the jenkins job is scheduled on the basis of tag namely: iscsi_volume:yesyesterday on few instances the volume went into RO mode Customer has reported that volume went into RO mode for the below instances too: 10.59.100.23010.59.100.17110.59.100.46will you please check if we get the notification or not for the above instances?Please verify the above information  and let me update here itself. THanks !###@Team:Move the priority to P4 as the main request has been resolved.###Hello Daniel,This is a quick followup.We have provided access to the instances.Please verify that you can access them and let us know if you are facing any issues.Thanks.###Hello Daniel,We have provided you access to the following instances.10.59.100.230 10.59.100.171 Please verify and let us know if you are facing any issues.###Hi Daniel, We have resolved the RO mode issue on the below all the 3 instances. We are working on resolving the access issue for you on the two instances. We will update you in a while on this. Thanks !###That particular server looks to be fine – but the rest of the cluster looks to be in read-only. I need that fixed. Note: I do not have access on two of these servers. Can you please give me access (otherwise I will not be able to check locally on these servers – although I can probably verify when trying to start MemSQL). Public Key: ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAQEAkOMc6b5R8Nnn9XZJHKQKUyUMDbrXam0TWA3iYtVA1fQqExYpMYPLX1vpp0/sUdQuNlW+qPlB4iocHgM9rnUimPxcrDk4dFkz4L+0YfdMKOYnYL2XG5Fpc5mDpX+D7lPnHWuZf0FlCU56h7eizQ2S7jGcMITawtK1Pt0DjU0V5D7XMbmc5Jp25G40rCI0gWkGr/YdsdI9kI2nRlJp07GhK+k5jIZnxjCKMrk/eqjSmU6GNzRTlgE3aLCLQX08IR/WUUCnsIn00vWyGs7sw+G2hyKSDRQy3VMieVzDAxz7cHS7hTSpD7X2jSDYi9UZ3dxKOdBVat2O8lC386JKcApPnw== rsa-key-20180626 The others servers are:10.59.100.230 – I do not have access10.59.100.171 – I do not have access10.59.100.46 – I have access  Best Regards, Dan Mackay | Spend Solutions DBA | SpendHQ###Hello Daniel,We have killed the process and remounted the ISCSI volume successfully. We have verified that we are able to touch a file in the /mnt/memsql_storage folder. Please check from your end and let us know if you have any queries.###Please get the iscsi volume back to a normal operating mode.  Best Regards, Dan Mackay | Spend Solutions DBA | SpendHQ###Please call my cell if you need anything else regarding this: 404-988-3100  Best Regards, Dan Mackay | Spend Solutions DBA | SpendHQ###Hello Matthew/Daniel,We are trying to reach you through a phone call in order to get an approval to kill the process as the iscsi volume went to read-only mode and not able to unmount it. As we haven't got any response to the call, we left a voice message. We will be waiting for your approval to kill the process. Request you to reply ASAP. Please find the process details below: bash 41193 dmackay cwd DIR 8,16 4096 4194305 /mnt/memsql_storage/reports Thanks!###Hello Daniel,We have tried to reach you through a phone call in order to get an approval to kill the process as the iscsi volume went to read-only mode and not able to unmount it. As we haven't got any response to the call, we left a voice message. We will be waiting for your approval to kill the process. Request you to reply ASAP.Please find the process details below:bash 41193 dmackay cwd DIR 8,16 4096 4194305 /mnt/memsql_storage/reports Thanks!###Hello Spendhq-Team,We are still unable to unmount the volume and could see the below process running.bash       41193         dmackay  cwd       DIR               8,16      4096    4194305 /mnt/memsql_storage/reportsWe tried to reach you on call to get confirmation but haven't got any response from your end. Request you to kill the process so that we can fix the read-only mode on the volume.###Hello Spendhq-Team,We are not able to unmount the volume because of the below processes:bash       41193         dmackay  cwd       DIR               8,16      4096    4194305 /mnt/memsql_storage/reportsbash       79729            root  cwd       DIR               8,16      4096          2 /mnt/memsql_storagelsof       85427            root  cwd       DIR               8,16      4096          2 /mnt/memsql_storagegrep       85428            root  cwd       DIR               8,16      4096          2 /mnt/memsql_storagelsof       85429            root  cwd       DIR               8,16      4096          2 /mnt/memsql_storageKindly request you to kill the processes so that we can unmount and remount the volume.###Hello  Spendhq-Team,This is to inform you that we received a notification stating that ISCSI volume ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server1-2018-04-01:dev10.ctr1-lun-0 went into read-only mode on the instance SpendHQ-memsql-server1-2018-04-01 (Instance ID: i-073579ff33c73d3cd). We are checking from our end and will let you know the update.","The daily report of ISCSI devices which are in RO modeInstance_ID     Instance_Name   ISCSI_Name      Machine_Level_Disk_Name Mount_Directory Mount_Propertiesi-073579ff33c73d3cd     SpendHQ-memsql-server1-2018-04-01       ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server1-2018-04-01:dev10.ctr1-lun-0    sdb     /mnt/memsql_storage     ro-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",ISCSI Device Details which are in RO mode,,20-12-2018 14:38,128,0,SpendHQ,"Hello Matthew,Thank you for the confirmation.We are now closing this case. Merry Christmas to you too!Thanks","Matthew Watts7:10 PM (29 minutes ago)to Rean, spendhq-support@reancloud.comLet’s close this. Thanks. Merry Christmas!","Hello Team, This is a gentle reminder.We have resolved the RO mode issue on the below all the 3 instances. SpendHQ-memsql-server3-2018-04-01 SpendHQ-memsql-server2-2018-04-01SpendHQ-memsql-server4-2018-09-20We have provided you access to the following instances. SpendHQ-memsql-server3-2018-04-01 SpendHQ-memsql-server2-2018-04-01Please verify the same and kindly let us know whether we are good to close the ticket.","Hello Team,We have resolved the RO mode issue on the below all the 3 instances.SpendHQ-memsql-server3-2018-04-01 -10.59.100.230 SpendHQ-memsql-server2-2018-04-01 -10.59.100.171 SpendHQ-memsql-server4-2018-09-20 -10.59.100.46 We have provided you access to the following instances. 10.59.100.230 10.59.100.171 Please verify the same and kindly let us know whether we are good to close the ticket.",Rohit mentioned to do follow up with the customer and get confirmation.,"@Rohit, I have verified all the alerts that we received from the jenkins jobs yesterday are only for SpendHQ-memsql-server1.There is no alert triggered for the instances IPs you mentioned (SpendHQ-memsql-server2,3,4) Please let us know if we have any further action on this.","Hello Team,As this issue seems to be resolved, we are downgrading the priority of this ticket.Please verify from your end and let us know if you are facing any issues.",@Team:Whenever any volume goes into RO modewe get a mail with this subject line: ISCSI Device Details which are in RO modeAs the jenkins job is scheduled on the basis of tag namely: iscsi_volume:yesyesterday on few instances the volume went into RO mode Customer has reported that volume went into RO mode for the below instances too: 10.59.100.23010.59.100.17110.59.100.46will you please check if we get the notification or not for the above instances?Please verify the above information  and let me update here itself. THanks !,@Team:Move the priority to P4 as the main request has been resolved.,"Hello Daniel,This is a quick followup.We have provided access to the instances.Please verify that you can access them and let us know if you are facing any issues.Thanks.","Hello Daniel,We have provided you access to the following instances.10.59.100.230 10.59.100.171 Please verify and let us know if you are facing any issues.","Hi Daniel, We have resolved the RO mode issue on the below all the 3 instances. We are working on resolving the access issue for you on the two instances. We will update you in a while on this. Thanks !","That particular server looks to be fine – but the rest of the cluster looks to be in read-only. I need that fixed. Note: I do not have access on two of these servers. Can you please give me access (otherwise I will not be able to check locally on these servers – although I can probably verify when trying to start MemSQL). Public Key: ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAQEAkOMc6b5R8Nnn9XZJHKQKUyUMDbrXam0TWA3iYtVA1fQqExYpMYPLX1vpp0/sUdQuNlW+qPlB4iocHgM9rnUimPxcrDk4dFkz4L+0YfdMKOYnYL2XG5Fpc5mDpX+D7lPnHWuZf0FlCU56h7eizQ2S7jGcMITawtK1Pt0DjU0V5D7XMbmc5Jp25G40rCI0gWkGr/YdsdI9kI2nRlJp07GhK+k5jIZnxjCKMrk/eqjSmU6GNzRTlgE3aLCLQX08IR/WUUCnsIn00vWyGs7sw+G2hyKSDRQy3VMieVzDAxz7cHS7hTSpD7X2jSDYi9UZ3dxKOdBVat2O8lC386JKcApPnw== rsa-key-20180626 The others servers are:10.59.100.230 – I do not have access10.59.100.171 – I do not have access10.59.100.46 – I have access  Best Regards, Dan Mackay | Spend Solutions DBA | SpendHQ","Hello Daniel,We have killed the process and remounted the ISCSI volume successfully. We have verified that we are able to touch a file in the /mnt/memsql_storage folder. Please check from your end and let us know if you have any queries.","Please get the iscsi volume back to a normal operating mode.  Best Regards, Dan Mackay | Spend Solutions DBA | SpendHQ","Please call my cell if you need anything else regarding this: 404-988-3100  Best Regards, Dan Mackay | Spend Solutions DBA | SpendHQ","Hello Matthew/Daniel,We are trying to reach you through a phone call in order to get an approval to kill the process as the iscsi volume went to read-only mode and not able to unmount it. As we haven't got any response to the call, we left a voice message. We will be waiting for your approval to kill the process. Request you to reply ASAP. Please find the process details below: bash 41193 dmackay cwd DIR 8,16 4096 4194305 /mnt/memsql_storage/reports Thanks!","Hello Daniel,We have tried to reach you through a phone call in order to get an approval to kill the process as the iscsi volume went to read-only mode and not able to unmount it. As we haven't got any response to the call, we left a voice message. We will be waiting for your approval to kill the process. Request you to reply ASAP.Please find the process details below:bash 41193 dmackay cwd DIR 8,16 4096 4194305 /mnt/memsql_storage/reports Thanks!","Hello Spendhq-Team,We are still unable to unmount the volume and could see the below process running.bash       41193         dmackay  cwd       DIR               8,16      4096    4194305 /mnt/memsql_storage/reportsWe tried to reach you on call to get confirmation but haven't got any response from your end. Request you to kill the process so that we can fix the read-only mode on the volume.","Hello Spendhq-Team,We are not able to unmount the volume because of the below processes:bash       41193         dmackay  cwd       DIR               8,16      4096    4194305 /mnt/memsql_storage/reportsbash       79729            root  cwd       DIR               8,16      4096          2 /mnt/memsql_storagelsof       85427            root  cwd       DIR               8,16      4096          2 /mnt/memsql_storagegrep       85428            root  cwd       DIR               8,16      4096          2 /mnt/memsql_storagelsof       85429            root  cwd       DIR               8,16      4096          2 /mnt/memsql_storageKindly request you to kill the processes so that we can unmount and remount the volume.","Hello  Spendhq-Team,This is to inform you that we received a notification stating that ISCSI volume ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server1-2018-04-01:dev10.ctr1-lun-0 went into read-only mode on the instance SpendHQ-memsql-server1-2018-04-01 (Instance ID: i-073579ff33c73d3cd). We are checking from our end and will let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001iuSgj,Cloud Engineer Level 1,Closed,1111269,Incident,28-01-2019 22:24,,"Thanks for the confirmation Robert.On that note we are marking this case as closed.Feel free to keep in touch for continued support.Thanks.Stephen Oduor###Robert Little7:52 PM (0 minutes ago)to me, David, REANCloud, MatthewI have verified my access thanks.###Hello Robert,We have completed your request.Please try accessing the server with the credentials shared with you separately and let us know if you are facing any issues.Thanks.Stephen Oduor###Sure Matt !We are on it.###[Via Email]This needs to be expedited too please.Matthew Watts###Hello Matthew,Thanks for the approval.We acknowledge receipt of the request. We will work on it and update the user on the progress.Regards.Stephen Oduor","ApprovedGet Outlook for iOS<https://aka.ms/o0ukef>________________________________From: Robert LittleSent: Monday, January 28, 2019 10:21:07 AMTo: Rean SupportCc: Matthew Watts; David MillerSubject: Robert Database server accessHello REAN,Please grant the user rlittle sudo access and ssh access to the following servers as I am the on call database engineer. Please use the below public key for the user. Please let me know if you need any more information.10.59.10.210    user1.mariadb.spendhq.net10.59.10.26    performance1.mariadb.spendhq.net10.59.10.45    performance2.mariadb.spendhq.net10.59.10.235    performance3.mariadb.spendhq.netssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDIwP1I/BQqusrO4KRuIJqS6zDplxkoTlwMs6+CkPP+5LJ0scy2eCRII/2W6ty3V27vq2M+hqzcBFpqW8SkhCEvW4yq2V4ZxPZTT2WYrPZFpKc7eSYWaUg1dkaST+UC8MoGFZEgXGcCeHh0JCjLWI6jVYo7jKb9xggwOa2teFIZLaqJ/R1+KGa1RNm4M6mxNUOBFYtaGAlBXAucU1Pew4NUKiLKxRzOmM7yyGSX/ep3jmw62hRJLNjXC7I+r5y/z2BEYtt+P2UH1dn8gtISpEyQZLDZT6ENOOOsEQ5BBvthyqi0anMPbopHWywcofAg90zElI5JMD3t2XTBZsBfUBtd rlittle@lbryant03.isg.localThanks,Robert-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Robert Database server access,,28-01-2019 20:52,2,0,SpendHQ,Thanks for the confirmation Robert.On that note we are marking this case as closed.Feel free to keep in touch for continued support.Thanks.Stephen Oduor,"Robert Little7:52 PM (0 minutes ago)to me, David, REANCloud, MatthewI have verified my access thanks.","Hello Robert,We have completed your request.Please try accessing the server with the credentials shared with you separately and let us know if you are facing any issues.Thanks.Stephen Oduor",Sure Matt !We are on it.,[Via Email]This needs to be expedited too please.Matthew Watts,"Hello Matthew,Thanks for the approval.We acknowledge receipt of the request. We will work on it and update the user on the progress.Regards.Stephen Oduor",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G000015Wy7G,Cloud Engineer Level 1,Closed,1039591,Incident,18-12-2016 17:41,,We are tracking this case under Case Number 01039564. Hence closing the case for now.,"What made you restart that box in the first place? What indication did you get that the mount because read only?Due to the fact that the box (.125) was restarted, the file system mounts are now unavailable on our PRD (.118) server. Please work on making  this available immediately as this renders the PRD environment useless.I am available on 904.868.8848 if you need to talk. This is A SEV ONE!Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: noreply@salesforce.com [mailto:noreply@salesforce.com] On Behalf Of Mrigank SaxenaSent: Sunday, December 18, 2016 12:56 AMTo: spendhq-support@reancloud.comSubject: Priority Critical - P1 | Update on Case # I-01039564Hello SpendHQ,Below comment added in reference to the case : I-01039564.Hello SpendHQ Team,In our analysis, we have found that we are facing the same issue again where the devices /dev/sda and /dev/sdb got into read-only mode.To resolve the issue we tried to unmount the devices but we were not able to unmount it as the device were busy.So we went ahead and restarted the instance and again mounted the devices /dev/sda on /var/www/vhosts/files.spendhq.com and /dev/sdb on /var/www/vhosts/files1.spendhq.com which resolved the issue.Please find the logs messaged in the attachments.We are performing detailed analysis and will submit the RCA shortly.Andromeda Team, Please look into this issue and let us know why this device is got into read-only mode .Case link: https://reancloud.force.com/customers/5000G000015WutOYou can click on the above link to add your comments or to review the progress. Thank you for your support and patience.Please do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at your respective REAN distribution email address.REAN Cloud-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Priority Critical - P1 | Update on Case # I-01039564,,18-12-2016 16:51,1,0,SpendHQ,We are tracking this case under Case Number 01039564. Hence closing the case for now.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Lt84P,Cloud Engineer Level 1,Closed,1086131,Incident,08-12-2017 12:38,,"Hello Team,This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.18. The alert got resolved and return to normal state.###Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.18. The MySQL process was consuming the usage. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1 We are analyzing more on this and get back to you with details.","[Triggered] [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over datadog_monitor:on,host:i-03ccfddd9f02cacb9 was > 3.0 on average during the last 5m.Metric value: 3.006This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=4168292537644164162 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db,,08-12-2017 11:24,1,0,SpendHQ,"Hello Team,This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.18. The alert got resolved and return to normal state.","Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.18. The MySQL process was consuming the usage. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1 We are analyzing more on this and get back to you with details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VsQPq,Cloud Engineer Level 1,Closed,1098551,Incident,11-05-2018 00:21,,"Hello Allen,Thanks for the update.This was the activity performed by your end only. Now we are marking this case as closed.###Thank you Rean, I resolved the issue by running composer install. This was my fault, I switched the branches and didn’t realize it required a new package. I’ve resolved the issue. Allen Herrera | Associate Engineer | SpendHQ®###Hello Team,From our initial analysis, we could see 500 response code while trying to access the URL. While checking the details at the instance level we could see there is PHP fatal error from the logs/var/www/vhosts/files.spendhq.com/w2/logs/web2-94-https-preview.spendhq.com-error.log.Please review the details/logs with the application team and fix the issue. Let us know if you have any queries. [Thu May 10 00:46:58 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 01:05:21 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 17:45:28 2018] [error] [client 10.59.1.192] PHP Fatal error:  Class 'GuzzleHttp\\Client' not found in /var/www/vhosts/secure.spendhq.com/public/app/vendors/shq_service/shq_service.php on line 26[Thu May 10 17:46:08 2018] [error] [client 10.59.1.192] PHP Fatal error:  Class 'GuzzleHttp\\Client' not found in /var/www/vhosts/secure.spendhq.com/public/app/vendors/shq_service/shq_service.php on line 26[Thu May 10 17:46:41 2018] [error] [client 10.59.1.192] PHP Fatal error:  Class 'GuzzleHttp\\Client' not found in /var/www/vhosts/secure.spendhq.com/public/app/vendors/shq_service/shq_service.php on line 26###Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.","Thu, 10 May 2018 13:41:19 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: Atlanta-B USConfirmed by node(s): Dallas-B US, California US, Frankfurt DE, New Jersey US--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,10-05-2018 23:11,1,0,SpendHQ,"Hello Allen,Thanks for the update.This was the activity performed by your end only. Now we are marking this case as closed.","Thank you Rean, I resolved the issue by running composer install. This was my fault, I switched the branches and didn’t realize it required a new package. I’ve resolved the issue. Allen Herrera | Associate Engineer | SpendHQ®","Hello Team,From our initial analysis, we could see 500 response code while trying to access the URL. While checking the details at the instance level we could see there is PHP fatal error from the logs/var/www/vhosts/files.spendhq.com/w2/logs/web2-94-https-preview.spendhq.com-error.log.Please review the details/logs with the application team and fix the issue. Let us know if you have any queries. [Thu May 10 00:46:58 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 01:05:21 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 17:45:28 2018] [error] [client 10.59.1.192] PHP Fatal error:  Class 'GuzzleHttp\\Client' not found in /var/www/vhosts/secure.spendhq.com/public/app/vendors/shq_service/shq_service.php on line 26[Thu May 10 17:46:08 2018] [error] [client 10.59.1.192] PHP Fatal error:  Class 'GuzzleHttp\\Client' not found in /var/www/vhosts/secure.spendhq.com/public/app/vendors/shq_service/shq_service.php on line 26[Thu May 10 17:46:41 2018] [error] [client 10.59.1.192] PHP Fatal error:  Class 'GuzzleHttp\\Client' not found in /var/www/vhosts/secure.spendhq.com/public/app/vendors/shq_service/shq_service.php on line 26","Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013UAzZ,Cloud Engineer Level 1,Closed,1025387,Incident,27-10-2016 22:56,,"Hello SpendHQ,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.###Hi Team,Gentle reminder,Did you get a chance to look into this issue, please let us know whether the specified Ip is a valid one or not.###Hello Team,As this issue was a critical one, we have blocked the IP 195.62.53.168 in NACL. Please let us know whether this IP was a valid one or not.###Hi Team, Since this is a critical issue and we got it multiple times we have blocked the IP 195.62.53.168  in NACL. Please inform us if it is a valid one and let us know if you have any queries on this.###Hi SpendHQ Team, We want to inform you that we have received threat notification from Sophos in your environment. The source IP/host 10.59.1.167 was found to communicate with a potentially malicious site outside your company. We are looking into it and will update you with details shortly.",Advanced Threat ProtectionA threat has been detected in your networkThe source IP/host listed below was found to communicate with a potentially malicious site outside your company.Details about the alert:Threat name....: C2/Generic-ADetails........: http://www.sophos.com/en-us/threat-center/threat-analyses/viruses-and-spyware/C2~Generic-A.aspxTime...........: 2016-10-26 06:27:04Traffic blocked: noSource IP address or host: 10.59.1.167,[spendhq][CRIT-861] Advanced Threat Protection Alert,,26-10-2016 12:06,48,0,SpendHQ,"Hello SpendHQ,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.","Hi Team,Gentle reminder,Did you get a chance to look into this issue, please let us know whether the specified Ip is a valid one or not.","Hello Team,As this issue was a critical one, we have blocked the IP 195.62.53.168 in NACL. Please let us know whether this IP was a valid one or not.","Hi Team, Since this is a critical issue and we got it multiple times we have blocked the IP 195.62.53.168  in NACL. Please inform us if it is a valid one and let us know if you have any queries on this.","Hi SpendHQ Team, We want to inform you that we have received threat notification from Sophos in your environment. The source IP/host 10.59.1.167 was found to communicate with a potentially malicious site outside your company. We are looking into it and will update you with details shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013XkFz,Cloud Engineer Level 1,Closed,1028648,Incident,04-11-2016 20:58,,"[Internal]Hello team,We have followed up on this case through its original case number 01025297.So we are closing this here.","Where can we download the Sophos Software for the new VPN user that you created;shq_systemMatthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sophos Download,,04-11-2016 20:21,1,0,SpendHQ,"[Internal]Hello team,We have followed up on this case through its original case number 01025297.So we are closing this here.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Dm1No,Cloud Engineer Level 1,Closed,1064378,Incident,23-06-2017 06:19,,"Hi SpendHq-Team,This is to inform you that the high volume usage alert on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal value of 80% and violation lasted for 2 hours.###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G  331M 100% /Files under root directory, 20G tmp 15G usr 12G var 510M home 285M lib 282M opt Files under /tmp folder, 18G     total7.8G    liger_view_c830b4887d8ccee9da1dd9f9eb99fa33.csv1.8G    liger_view_86d81e37583dfca66a0f56c30940cc5b.csv1.8G    liger_view_1a1784cff20ed80ad102e4266bbd6feb.csv1.5G    liger_view_13d30ba55882068447838be94439078f.csv758M    liger_view_cbea22ef8a74d565eb9f8d4749332dc6.csv743M    liger_view_7b367e82195e9f7fc5b97629ad06fd9d.csv631M    liger_view_88bc10275df0e433204152a39b33d224.csv631M    liger_view_685a41cba13291fdd6d6b6238fa8793f.csv368M    liger_view_6bcb1f4a39dbb9320ea2ea952f74ca1c.csv354M    liger_view_a54144ed50626138b74aa224e74e6c67.csv292M    liger_view_403fce72f22c39e8f6b136dc2f7ab00c.csv282M    liger_view_82b57cf9e789003160d312b2a2750b4f.csv221M    spark-2.1.0-bin-hadoop2.7192M    spark-2.1.0-bin-hadoop2.7/jars121M    liger_view_261089bca64386602af8d70c65d5464e.csv84M     liger_view_df1770e6f32ac8858805de839a465950.csv78M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm71M     liger_view_7ad894f970b3ef797c10a5ed0e97934f.csv64M     liger_view_575a9727b7d04bde4655f0a79ab3aa4b.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Fri, Jun 23, 2017 at 2:24 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjbsKgzAARb_GbJW8Y4YM2iKFzh3apcQ8VFBjYzL07xvhDocL516rmBwcmBWGSECOMYaMElQzRBmreyQ7BlvZUclvXLQVhTbZsTYBTGow3GtPOTWESYEbQRAUzJnGem-RcGBRU0r7UZG2wn2J3vfa6qRtGKdv2VjPzpiQt1Roj8HPiyuUL_ANr5_H7_VE9wyiWo9yHJ3ezBKyPU2Q1Bq2OYX4Bx4hOiA>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj8uOwyAMRb-GLBE2mMQLFulU-Y2KBvKQmpImtJrPL4lmMZLlx7V8dB0c8T1Ws0MFtbKIqMhokASGSHbAF1ItXwzbq61bYVTIYZR9qiYHgyEYNPeG7qx1HWuvuEHfRKpND7Z6uCnndRe6FdiV8Osqg88-pHF6FcZStCU955y2XaBGhZotC93ldMvl7AqGG7Cm0ayUEmjHLb3Xoof4mfsokA4yYVfms_5-goej-5nSns89KEksSwZNhTBsafnP1vZkV5tb9vLcFv2zf6R3ONxV2f25-wJsqFIq>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Thu Jun 22 2017 20:54:00 UTC (*29 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtTtEKwyAM_Bp9lCQaiw8-dBv9D6vSFtbZtW7s82fHIFySC3eX5NmNWS6eADuwRARsNCpGw6wGdBeG3l2Mszfb9cJAqmlSscjZ46iBMyLF1IRoRwMmW-viGCgG6OTdz7Vuh9C9oKFV2DaVQg2pTPOzeayNW8tjqWU_BGkC0s46oYdpL69N6FvK7yVmQXw6MA1t__XPOwU8p-tcjvq7Iyh2qiFqlrtfj_bqnsMj3ssrnVmy-n_WF3aDRaA>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjUsOhCAQBU8DS9I0P1mw0Ey8B9L4SVQcZe4_TDLJW1VS9SgYP2W-BQTpwCIiGK2kMFIbI0bpBwO9H7S3L-t6poEqLSIVvgawspuIXIyzltSh7ZzMQJAdqWlOie9hrfV6mOoZjm3xugTFGqks67s1jsaOcm613A9DhYDKW99gpq3yOxxP-7tzPNNePvQTeA1_4Qsd5zap>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVjc0OhCAQg59GjoQBRp0DB43xPRDwJ1nFxfH9l02apvmSttEhLUkcTivoVKu1VmgNSASLKGegEdVAo6V2aruhsSpy3GTIYncpdlaRWXQILYFe-15Tb02_EiaAlMTH7cz305ih0XOVv28ZPfuYt_1bN87Kjmst_uHyBn5Lasy854cvf9Y4gZJIsjoYFMWdT70vyV_hk9_47wt2Z74OzuUHPZc7DQ>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9js0KgzAQhJ8mOYZkd2PMIQdFfI_8VYVqrKZ9_qaXwsDAwDczyWkbMt8cSGVkBwBSEyqhFWktZmVHLQc7ku2mzgyMZKppEbHw1cUHQJ9UjMEEE5G0NAAGc1AYMxrNn26t9bwZDgzmJn-eIvnqU1nWV-vYW5Y_-ah_x3lLDCe0QABEaC2Z3rZrPb_cfrf5K_sjPss7_Xhe3V6OrZbrC-sMOTE>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjUEOgyAURE8jSwII_LJgoWm8x5dP1aQCRbx_MZnF5GXyhrxxa2SHV0KCsEopYfQouZHaGL5INxsxuVk7-7YwDVpQo42HzHaPL1oVaAXkpDCohACiMQA4iQYssq_fWyvXME6DWnqwFE7YkPK2_7rjfFgI-U6tt1LjJ9aYQrxY9efVv2rEFL75pmfMmj9zOlqufy2KNh8>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,23-06-2017 02:33,4,0,SpendHQ,"Hi SpendHq-Team,This is to inform you that the high volume usage alert on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal value of 80% and violation lasted for 2 hours.","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G  331M 100% /Files under root directory, 20G tmp 15G usr 12G var 510M home 285M lib 282M opt Files under /tmp folder, 18G     total7.8G    liger_view_c830b4887d8ccee9da1dd9f9eb99fa33.csv1.8G    liger_view_86d81e37583dfca66a0f56c30940cc5b.csv1.8G    liger_view_1a1784cff20ed80ad102e4266bbd6feb.csv1.5G    liger_view_13d30ba55882068447838be94439078f.csv758M    liger_view_cbea22ef8a74d565eb9f8d4749332dc6.csv743M    liger_view_7b367e82195e9f7fc5b97629ad06fd9d.csv631M    liger_view_88bc10275df0e433204152a39b33d224.csv631M    liger_view_685a41cba13291fdd6d6b6238fa8793f.csv368M    liger_view_6bcb1f4a39dbb9320ea2ea952f74ca1c.csv354M    liger_view_a54144ed50626138b74aa224e74e6c67.csv292M    liger_view_403fce72f22c39e8f6b136dc2f7ab00c.csv282M    liger_view_82b57cf9e789003160d312b2a2750b4f.csv221M    spark-2.1.0-bin-hadoop2.7192M    spark-2.1.0-bin-hadoop2.7/jars121M    liger_view_261089bca64386602af8d70c65d5464e.csv84M     liger_view_df1770e6f32ac8858805de839a465950.csv78M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm71M     liger_view_7ad894f970b3ef797c10a5ed0e97934f.csv64M     liger_view_575a9727b7d04bde4655f0a79ab3aa4b.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Dmwju,Cloud Engineer Level 1,Closed,1065038,Incident,27-06-2017 04:16,,"Hello SpendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 80%. The violation lasted for 4 hours.We are monitoring on it and will keep your team updated if we still witness any spikes in the volume usage on this instance. As the alert got resolved, we are marking this case as resolved. Kindly revert back incases of any queries.Regards,Sumod.K.Bose###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 92%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -hTFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   43G  4.1G  92% /Files under root directory,43G     total18G     usr13G     tmp12G     var523M    home285M    lib282M    opt /tmp directory Details13G     total1.8G    liger_view_eb8f0f375d4bda7b2cf81f7f272d0284.csv1.8G    liger_view_c8253bcc6b2f20e76375db2c9bdf4615.csv1.2G    liger_view_9df74dbd891c1326f0a2fd12f2f9ceb0.csv1.2G    liger_view_74d3df4c0435a74ba0a26f9a824556e2.csv1.2G    liger_view_58ff8ac2fd855ec9ee0ea3d71b5b2de2.csv1.2G    liger_view_1aabb3fa1280144bf946da37d00c05f1.csv922M    liger_view_252054d3336b71092e429c0d065425b7.csv474M    liger_view_6912792f76d9d5b828cf67f2107a3aeb.csv358M    liger_view_f74fa6e69ffcbeab6cc82a4acd5dc5e9.csv358M    liger_view_9081cfea7ad8629e341f85c78efe8eb4.csv328M    liger_view_63f979ff50c2b7909d597a89a4ee2536.csv280M    liger_view_4c4fc602e3cd76a5f154b087fb911683.csv262M    liger_view_09edb01c859c06ddecb1cc659a6702ea.csv224M    liger_view_a47e1eac55bc31e0d6e0aa358abaea36.csv221M    spark-2.1.0-bin-hadoop2.7161M    liger_view_71adb86bb9608f861e0d8ac2159ee0aa.csv147M    liger_view_cbea22ef8a74d565eb9f8d4749332dc6.csv101M    liger_view_aed8ff84bedae719a2899ca04128763e.csv101M    liger_view_04954fc27e11f857cc6e718533d43845.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 90.034This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3929883909831004551 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,27-06-2017 00:06,4,0,SpendHQ,"Hello SpendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 80%. The violation lasted for 4 hours.We are monitoring on it and will keep your team updated if we still witness any spikes in the volume usage on this instance. As the alert got resolved, we are marking this case as resolved. Kindly revert back incases of any queries.Regards,Sumod.K.Bose","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 92%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -hTFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   43G  4.1G  92% /Files under root directory,43G     total18G     usr13G     tmp12G     var523M    home285M    lib282M    opt /tmp directory Details13G     total1.8G    liger_view_eb8f0f375d4bda7b2cf81f7f272d0284.csv1.8G    liger_view_c8253bcc6b2f20e76375db2c9bdf4615.csv1.2G    liger_view_9df74dbd891c1326f0a2fd12f2f9ceb0.csv1.2G    liger_view_74d3df4c0435a74ba0a26f9a824556e2.csv1.2G    liger_view_58ff8ac2fd855ec9ee0ea3d71b5b2de2.csv1.2G    liger_view_1aabb3fa1280144bf946da37d00c05f1.csv922M    liger_view_252054d3336b71092e429c0d065425b7.csv474M    liger_view_6912792f76d9d5b828cf67f2107a3aeb.csv358M    liger_view_f74fa6e69ffcbeab6cc82a4acd5dc5e9.csv358M    liger_view_9081cfea7ad8629e341f85c78efe8eb4.csv328M    liger_view_63f979ff50c2b7909d597a89a4ee2536.csv280M    liger_view_4c4fc602e3cd76a5f154b087fb911683.csv262M    liger_view_09edb01c859c06ddecb1cc659a6702ea.csv224M    liger_view_a47e1eac55bc31e0d6e0aa358abaea36.csv221M    spark-2.1.0-bin-hadoop2.7161M    liger_view_71adb86bb9608f861e0d8ac2159ee0aa.csv147M    liger_view_cbea22ef8a74d565eb9f8d4749332dc6.csv101M    liger_view_aed8ff84bedae719a2899ca04128763e.csv101M    liger_view_04954fc27e11f857cc6e718533d43845.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001deKS0,Cloud Engineer Level 1,Closed,1106770,Incident,29-10-2018 13:26,,"Hi Team,We received an alert regarding Httpd Process is down for prd-ww1_122 Ip address-10.59.100.12.We have checked from the instance level and we could see that httpd process got killed at the time of the alert before restarting. [Thu Oct 25 18:13:02 2018] [notice] caught SIGTERM, shutting down [Thu Oct 25 18:14:43 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec) [Thu Oct 25 18:14:43 2018] [notice] Digest: generating secret for digest authentication ... [Thu Oct 25 18:14:43 2018] [notice] Digest: done [Thu Oct 25 18:14:43 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations Except for Network IN spikes at the time of the alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors. We got status checked for the instance prd-ww1_122 .Case details:01106769Please let us know if you have any further questions regarding the same. As of now, we are marking this case as closed.###Hello Team,We received an alert of  Httpd Process is down -on prd-ww1_122 - 10.59.100.122, On analyzing this issue, from the httpd error logs, we could see the httpd process got killed at the time of the alert before restarting. [Thu Oct 25 18:13:02 2018] [notice] caught SIGTERM, shutting down [Thu Oct 25 18:14:43 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec) [Thu Oct 25 18:14:43 2018] [notice] Digest: generating secret for digest authentication ... [Thu Oct 25 18:14:43 2018] [notice] Digest: done [Thu Oct 25 18:14:43 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations Except for Network IN spikes at the time of the alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors. You can also refer to the related Status Check Failed case 01106769 for additional info. Please review these details and let us know if you have any questions. Thanks###Hello Team,We have analyzed this issue and from the httpd error logs we could see the httpd process got killed at the time of the alert before restarting.[Thu Oct 25 18:13:02 2018] [notice] caught SIGTERM, shutting down[Thu Oct 25 18:14:43 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Thu Oct 25 18:14:43 2018] [notice] Digest: generating secret for digest authentication ...[Thu Oct 25 18:14:43 2018] [notice] Digest: done[Thu Oct 25 18:14:43 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operationsExcept for Network IN spikes at the time of alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors.You can also refer to the related Status Check Failed case 01106769 for additional info.Please review these details and let us know if you have any questions.Thanks.###Hello Team, This is to notify you that we received an alert regarding Httpd Process is down - prd-ww1_122 - 10.59.100.122. The alert is recovered and in OK state. The violation lasted 2 minutes.We are looking into this issue and will get back to you with the updates. Resource Details: ------------------------------------------------------------------------------------------- Instance Name: PRD-WW1_122 Instance ID: i-0ace70ce06368e4a7 Instance Type: r4.2xlarge Private IP: 10.59.100.122 VPC ID: vpc-76df7212 Subnet ID: subnet-0d093d27 Availability Zone: us-east-1b -------------------------------------------------------------------------------------------- Thanks.","[Triggered on {host:i-0ace70ce06368e4a7,process:httpd}] [SpendHQ] HttpdProcess is down - prd-ww1_122 - 10.59.100.122 - webHttpd Process is down @ms@reancloud.com<https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>PROCS CRITICAL: 0 processes found for httpdThe monitor was last triggered at Thu Oct 25 2018 18:16:00 UTC (*6 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2014428?group=host%3Ai-0ace70ce06368e4a7%2Cprocess%3Ahttpd>]· [Edit Monitor <https://app.datadoghq.com/monitors#2014428/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?filter=i-0ace70ce06368e4a7>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CASC&to_ts=1540491480000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1540490460000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4634345215041773731>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <http://htchivantara.is/2RAornF>","[Monitor Alert] Triggered: [SpendHQ] Httpd Process is down - prd-ww1_122 - 10.59.100.122 - web on host:i-0ace70ce06368e4a7,process:httpd",,25-10-2018 23:59,85,0,SpendHQ,"Hi Team,We received an alert regarding Httpd Process is down for prd-ww1_122 Ip address-10.59.100.12.We have checked from the instance level and we could see that httpd process got killed at the time of the alert before restarting. [Thu Oct 25 18:13:02 2018] [notice] caught SIGTERM, shutting down [Thu Oct 25 18:14:43 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec) [Thu Oct 25 18:14:43 2018] [notice] Digest: generating secret for digest authentication ... [Thu Oct 25 18:14:43 2018] [notice] Digest: done [Thu Oct 25 18:14:43 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations Except for Network IN spikes at the time of the alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors. We got status checked for the instance prd-ww1_122 .Case details:01106769Please let us know if you have any further questions regarding the same. As of now, we are marking this case as closed.","Hello Team,We received an alert of  Httpd Process is down -on prd-ww1_122 - 10.59.100.122, On analyzing this issue, from the httpd error logs, we could see the httpd process got killed at the time of the alert before restarting. [Thu Oct 25 18:13:02 2018] [notice] caught SIGTERM, shutting down [Thu Oct 25 18:14:43 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec) [Thu Oct 25 18:14:43 2018] [notice] Digest: generating secret for digest authentication ... [Thu Oct 25 18:14:43 2018] [notice] Digest: done [Thu Oct 25 18:14:43 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations Except for Network IN spikes at the time of the alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors. You can also refer to the related Status Check Failed case 01106769 for additional info. Please review these details and let us know if you have any questions. Thanks","Hello Team,We have analyzed this issue and from the httpd error logs we could see the httpd process got killed at the time of the alert before restarting.[Thu Oct 25 18:13:02 2018] [notice] caught SIGTERM, shutting down[Thu Oct 25 18:14:43 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Thu Oct 25 18:14:43 2018] [notice] Digest: generating secret for digest authentication ...[Thu Oct 25 18:14:43 2018] [notice] Digest: done[Thu Oct 25 18:14:43 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operationsExcept for Network IN spikes at the time of alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors.You can also refer to the related Status Check Failed case 01106769 for additional info.Please review these details and let us know if you have any questions.Thanks.","Hello Team, This is to notify you that we received an alert regarding Httpd Process is down - prd-ww1_122 - 10.59.100.122. The alert is recovered and in OK state. The violation lasted 2 minutes.We are looking into this issue and will get back to you with the updates. Resource Details: ------------------------------------------------------------------------------------------- Instance Name: PRD-WW1_122 Instance ID: i-0ace70ce06368e4a7 Instance Type: r4.2xlarge Private IP: 10.59.100.122 VPC ID: vpc-76df7212 Subnet ID: subnet-0d093d27 Availability Zone: us-east-1b -------------------------------------------------------------------------------------------- Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EV6kU,Cloud Engineer Level 1,Closed,1067965,Incident,14-07-2017 21:09,,"Andrew replied:Yes, this was me. You can ignore and close this case.Thank you,###Hello Andrew,This is to inform you that we received multiple login failure alerts for your IAM user akim for the SpendHQ AWS account. After 4 failed attempts, we could see that you have logged in successfully. Could you please confirm this was from your side and please let us know if you are facing any log in the issue so that we can assist you with.Regards,Safuvan KM###{    eventVersion: 1.05,    userIdentity: {        type: IAMUser,        principalId: AIDAIU5MRGFMPG7HO2UIM,        accountId: 261234435984,        accessKeyId: ,        userName: akim    },    eventTime: 2017-07-14T14:34:03Z,    eventSource: signin.amazonaws.com,    eventName: ConsoleLogin,    awsRegion: us-east-1,    sourceIPAddress: 74.115.22.44,    userAgent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:54.0) Gecko/20100101 Firefox/54.0,    errorMessage: Failed authentication,    requestParameters: null,    responseElements: {        ConsoleLogin: Failure    },    additionalEventData: {        LoginTo: https://console.aws.amazon.com/console/home?state=hashArgs%23&isauthcode=true,        MobileVersion: No,        MFAUsed: Yes    },    eventID: ddc93b6c-ad4a-4155-8089-b0884ed839f9,    eventType: AwsConsoleSignIn,    recipientAccountId: 261234435984}","[Triggered] [SpendHQ] [CloudTrail] -  AWS Console Signin Failure Notification -  - 3955744564966809604 - A user failed to log in the AWS console  @support@reancloud.com4 events triggered this monitor, here is the last one.- - -#### A user failed to log in the AWS console- - -Number of events matching sources:cloudtrail priority:all user failed to log in the AWS console was >= 1 during the last 15mThis alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023861? · Edit Monitor: https://app.datadoghq.com/monitors#2023861/edit · Event URL: https://app.datadoghq.com/event/event?id=3955744831893450465-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] [CloudTrail] - AWS Console Signin Failure Notification - - 3955744564966809604 - A user failed to log in the AWS console,,14-07-2017 20:17,1,0,SpendHQ,"Andrew replied:Yes, this was me. You can ignore and close this case.Thank you,","Hello Andrew,This is to inform you that we received multiple login failure alerts for your IAM user akim for the SpendHQ AWS account. After 4 failed attempts, we could see that you have logged in successfully. Could you please confirm this was from your side and please let us know if you are facing any log in the issue so that we can assist you with.Regards,Safuvan KM","{    eventVersion: 1.05,    userIdentity: {        type: IAMUser,        principalId: AIDAIU5MRGFMPG7HO2UIM,        accountId: 261234435984,        accessKeyId: ,        userName: akim    },    eventTime: 2017-07-14T14:34:03Z,    eventSource: signin.amazonaws.com,    eventName: ConsoleLogin,    awsRegion: us-east-1,    sourceIPAddress: 74.115.22.44,    userAgent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:54.0) Gecko/20100101 Firefox/54.0,    errorMessage: Failed authentication,    requestParameters: null,    responseElements: {        ConsoleLogin: Failure    },    additionalEventData: {        LoginTo: https://console.aws.amazon.com/console/home?state=hashArgs%23&isauthcode=true,        MobileVersion: No,        MFAUsed: Yes    },    eventID: ddc93b6c-ad4a-4155-8089-b0884ed839f9,    eventType: AwsConsoleSignIn,    recipientAccountId: 261234435984}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001iuJPS,Cloud Engineer Level 1,Closed,1111241,Incident,28-01-2019 05:30,,"Hello Team,This is to notify you that the alert got resolved and back to its normal state with the value of 196.31M hence we are marking this case as closed.###Hello Team, We have received an alert regarding High Network OUT on sphq-db4-20180830 as we can see that it has crossed the threshold and reached the value of 4.58G. Resource Details: ID: i-082d412700b276f44 IP: 10.59.10.210 [root@ip-10-59-10-210 ~]# netstat | wc -l263[root@ip-10-59-10-210 ~]# netstat | grep TIME_WAIT | wc -l34[root@ip-10-59-10-210 ~]# netstat | grep ESTABLISHED | wc -l134","________________________________From: Datadog Alerting <alert@dtdg.co>Sent: Sunday, January 27, 2019 8:57 PMTo: REANCloud SupportSubject: [Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - sphq-db4-20180830 - 10.59.10.210 -[Datadog][Triggered] [SpendHQ] - High Network OUT on host - sphq-db4-20180830 - 10.59.10.210 -High Network OUT on the instance. Please check the list open TCP Connections@ms@reancloud.com<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Faccount%2Fprofile%2Fu-0Z0C_KyYU1Hu&data=01%7C01%7Cmanideep.gunda%40hitachivantara.com%7C3d1332de61314937aaec08d6846bfb9e%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=tHClr78gIJnjgM5mGbAoah9Lm8ld7NXZVtvivfHAR5U%3D&reserved=0>[Metric Graph]<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Fmonitors%232024199%3Fto_ts%3D1548602909000%26group%3Dhost%253Ai-082d412700b276f44%26from_ts%3D1548595649000&data=01%7C01%7Cmanideep.gunda%40hitachivantara.com%7C3d1332de61314937aaec08d6846bfb9e%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=z5cI5Ogs%2FKYavO9NV1NDq%2Fil%2FE%2B6r454e2APfh%2FYkrQ%3D&reserved=0>aws.ec2.network_out over datadog_monitor:on,host:i-082d412700b276f44 was > 1100000000.0 at all times during the last 30m.The monitor was last triggered at Sun Jan 27 2019 15:27:39 UTC (1 sec ago).________________________________[Monitor Status<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Fmonitors%232024199%3Fgroup%3Dhost%253Ai-082d412700b276f44&data=01%7C01%7Cmanideep.gunda%40hitachivantara.com%7C3d1332de61314937aaec08d6846bfb9e%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=bjjD0Y1BNJhZ38t7W7SHDbzyE5sMcUmNLvqrYD7dJhk%3D&reserved=0>] · [Edit Monitor<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Fmonitors%232024199%2Fedit&data=01%7C01%7Cmanideep.gunda%40hitachivantara.com%7C3d1332de61314937aaec08d6846bfb9e%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=EngtaqZur6C6Hi7E6VpzP2WMp5t71fi5h%2FaGmc1UR9o%3D&reserved=0>] · [View i-082d412700b276f44<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Finfrastructure%3Ffilter%3Di-082d412700b276f44&data=01%7C01%7Cmanideep.gunda%40hitachivantara.com%7C3d1332de61314937aaec08d6846bfb9e%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=qMsn83COw2FDh7iWlGvVQ4sFUJS0fZPOeBTK2HneUho%3D&reserved=0>] · [Show Processes<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Fprocess%3Fsort%3Dmemory%252CDESC%26to_ts%3D1548602979000%26tags%3Dhost%253Ai-082d412700b276f44%26from_ts%3D1548601959000%26live%3Dfalse%26showSummaryGraphs%3Dtrue&data=01%7C01%7Cmanideep.gunda%40hitachivantara.com%7C3d1332de61314937aaec08d6846bfb9e%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=iOOiSvE13ZO2kTnsG0SW5ipQkMPM%2BQVezInOu6m%2BdNw%3D&reserved=0>]This alert was raised by account SpendHQComment in Datadog<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Fevent%2Fevent%3Fid%3D4770433501122577291&data=01%7C01%7Cmanideep.gunda%40hitachivantara.com%7C3d1332de61314937aaec08d6846bfb9e%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=XFLZy0dTDWwCCNV11kpl%2FPmFd3mgzCKECavqRAbuE7Q%3D&reserved=0>To manage your Datadog subscriptions, click here<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Faccount%2Fpreferences&data=01%7C01%7Cmanideep.gunda%40hitachivantara.com%7C3d1332de61314937aaec08d6846bfb9e%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=5Wf0MLH5FZsH3fPOBwzccA6xktHQ692QywCWSAMuFJY%3D&reserved=0>.-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fw: [Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - sphq-db4-20180830 - 10.59.10.210 -,,27-01-2019 21:27,8,0,SpendHQ,"Hello Team,This is to notify you that the alert got resolved and back to its normal state with the value of 196.31M hence we are marking this case as closed.","Hello Team, We have received an alert regarding High Network OUT on sphq-db4-20180830 as we can see that it has crossed the threshold and reached the value of 4.58G. Resource Details: ID: i-082d412700b276f44 IP: 10.59.10.210 [root@ip-10-59-10-210 ~]# netstat | wc -l263[root@ip-10-59-10-210 ~]# netstat | grep TIME_WAIT | wc -l34[root@ip-10-59-10-210 ~]# netstat | grep ESTABLISHED | wc -l134",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001i7CMK,Cloud Engineer Level 1,Closed,1110828,Incident,18-01-2019 06:17,,"Hello Team,This is to inform you that the alert regarding High Network OUT on host - sphq-db4-20180830 got recovered and back to its normal state hence we are marking this case as closed, please feel free to reach us out in case of any query.###Hello Team,This is to notify that the alert is recovered with a value of 1.07G. Please find our analysis below and let us know if you have any queries on the same.###Hello Team,We have received an alert regarding High Network OUT on sphq-db4-20180830  as we can see that it has crossed the threshold and reached the value of 2.38G.Resource Details:  ID: i-082d412700b276f44IP: 10.59.10.210On analyzing the issue we could see that the following are the connection details:[centos@ip-10-59-10-210 ~]$ netstat | wc -l554[centos@ip-10-59-10-210 ~]$ netstat | grep TIME_WAIT | wc -l346[centos@ip-10-59-10-210 ~]$ netstat | grep ESTABLISHED | wc -l143","[image: Datadog][Triggered] [SpendHQ] - High Network OUT on host - sphq-db4-20180830 -10.59.10.210 -High Network OUT on the instance. Please check the list open TCPConnections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024199?to_ts=1547666249000&group=host%3Ai-082d412700b276f44&from_ts=1547659049000>*aws.ec2.network_out* over *datadog_monitor:on,host:i-082d412700b276f44*was *> 1100000000.0* at all times during the *last 30m*.The monitor was last triggered at Wed Jan 16 2019 19:17:39 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024199?group=host%3Ai-082d412700b276f44>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024199/edit>] · [Viewi-082d412700b276f44<https://app.datadoghq.com/infrastructure?filter=i-082d412700b276f44>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1547666379000&tags=host%3Ai-082d412700b276f44&from_ts=1547665359000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4754719976907657074>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - sphq-db4-20180830 - 10.59.10.210 -,,17-01-2019 01:00,29,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding High Network OUT on host - sphq-db4-20180830 got recovered and back to its normal state hence we are marking this case as closed, please feel free to reach us out in case of any query.","Hello Team,This is to notify that the alert is recovered with a value of 1.07G. Please find our analysis below and let us know if you have any queries on the same.","Hello Team,We have received an alert regarding High Network OUT on sphq-db4-20180830  as we can see that it has crossed the threshold and reached the value of 2.38G.Resource Details:  ID: i-082d412700b276f44IP: 10.59.10.210On analyzing the issue we could see that the following are the connection details:[centos@ip-10-59-10-210 ~]$ netstat | wc -l554[centos@ip-10-59-10-210 ~]$ netstat | grep TIME_WAIT | wc -l346[centos@ip-10-59-10-210 ~]$ netstat | grep ESTABLISHED | wc -l143",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015XIfa,Cloud Engineer Level 1,Closed,1039947,Incident,20-12-2016 02:01,,We are following this case under the case number 01039936.Hence closing this case for now.,"Perfect. REAN Team can we work on getting this mounted please.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Monday, December 19, 2016 12:08 PMTo: Matthew Watts <mwatts@spendhq.com>Subject: Re: Database Volume MountDone  !! Ready to mount.Chris VeilletteOn Dec 19, 2016, at 12:05 PM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:The naming convention is good, but the clone of that backup could be appended with “clone”.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Monday, December 19, 2016 12:04 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Subject: Re: Database Volume MountOk - did you want to change the name?Chris VeilletteOn Dec 19, 2016, at 11:56 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Perfect. Let’s work with the REAN team to get this mounted. Can we make sure we clone that backup and mount the clone.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Monday, December 19, 2016 11:49 AMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Subject: Re: Database Volume MountHi Matt,We called the snapshot we took DB-backup-12-16-26I will clone it thus we'll be able to make it available to mount.I can rename if you'd like....I am at my laptop ready to go 😄Chris VeilletteOn Dec 19, 2016, at 11:22 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Absolutely. There is no rush on this.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Monday, December 19, 2016 11:14 AMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>; spendhq-support@reancloud.com<mailto:spendhq-support@reancloud.com>Subject: Re: Database Volume MountHi Matt.... sure - can you give 30 mins to get to my laptop?Chris VeilletteOn Dec 19, 2016, at 10:44 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:A backup was made of our PRD Database last Friday night. Can we please make a copy of this backup and then mount the copy to the DB5 (*.135) machine that was setup. We will need to ensure that we can roll-back to this backup without having to stop the database to create another image.Please advise when this is completed.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Database Volume Mount,,19-12-2016 22:53,3,0,SpendHQ,We are following this case under the case number 01039936.Hence closing this case for now.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016ofyb,Cloud Engineer Level 2,Closed,1042305,Incident,18-01-2017 23:10,,"Sudheer had a call with Andrew and he mentioned that this issue need to be discussed with Matthew and he will get back to us within next 24 hours.###Hello Matthew,From the logs, we were able to figure out that few logs are indicating the MySQL shut down as below.170106 20:16:16 [ERROR] /usr/local/infobright-4.9.0-x86_64/bin/mysqld: Incorrect key file for table '/tmp/#sql_17e47_0.MYI'; try to repair it170111 17:14:30 [ERROR] /usr/local/infobright-4.9.0-x86_64/bin/mysqld: Server shutdown in progressThere are two main reasons for this error message to show:1) The MySQL query that we are trying to execute takes too long and the MySQL server times out.The solution for this issue is to optimize your database for the queries which fail.2) You have a crashed table in your database.The solution in this case is to repair and optimize your database.We have already created the monitoring policies for the MySQL service and we will closely monitor the MySQL and will inform you in case of any issues in future.For now, we are marking this case as resolved.Please let us know if you would like to know any further information from our end.###I see the errors in the iee-mysql.err log file  [Warning] IPaddress '10.59.100.125' could not be resolved: no reverse address mapping.  [Warning] IP address '10.59.10.12' could not be resolved: no reverse address mapping. 170116 16:27:11 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht' MySQL has to do a reverse lookup on every IP address connecting to it to determine whether they are part of the domain.We need to check the DNS lookups for the Ip's and most of these IPs are from USA###I have tried to figure out the issue from the logs, but could not pin point the exact issue that cause to the outage. Escalating the ticeket to Sriram.###From my analysis, I understood that the server is configured with mysql infobright solution.________________________________________________________________________________| ~ @ ip-10-59-10-12 (root)| => /etc/init.d/mysqld-ib status SUCCESS! MySQL running (5988)________________________________________________________________________________| ~ @ ip-10-59-10-12 (root)| => service mysqld-ib status SUCCESS! MySQL running (5988)________________________________________________________________________________________________________________________________________________________________Verified that we are able to connect to mysql-ib server.| ~ @ ip-10-59-10-12 (root)| => mysql-ib -u rlittle -picangetinWelcome to the MySQL monitor.  Commands end with ; or \\g.Your MySQL connection id is 294230Server version: 5.1.40 build number (revision)=IEE_4.9.0_r38009_38040(iee - commercial) (shared)Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql> ________________________________________________________________________________The mysql-ib data is stored in separate volume ________________________________________________________________________________| ~ @ ip-10-59-10-12 (root)| => df -hFilesystem      Size  Used Avail Use% Mounted on/dev/xvda1       99G   77G   17G  83% /tmpfs           121G     0  121G   0% /dev/shm/dev/sdc        4.0T  1.6T  2.2T  43% /var/infobright________________________________________________________________________________Also verified the mysql-ib error logs are available.________________________________________________________________________________| /var/infobright/data @ ip-10-59-10-12 (root)| => ls -R | grep mysqliee-mysql.erriee-mysql.err-oldmysqlexcel_mysql_date_conversion.frmexcel_mysql_date_conversion.MYDexcel_mysql_date_conversion.MYI./mysql:________________________________________________________________________________________________________________________________________________________________| /var/infobright/data @ ip-10-59-10-12 (root)| => tail iee-mysql.err170116 16:22:31 [Warning] IP address '10.59.100.125' could not be resolved: no reverse address mapping.170116 16:27:10 [Warning] IP address '10.59.10.12' could not be resolved: no reverse address mapping.170116 16:27:11 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 16:30:35 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 16:31:12 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 19:58:16 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 20:48:04 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 22:02:06 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 22:02:09 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170117  3:58:31 [Warning] IP address '10.59.1.192' could not be resolved: no reverse address mapping.________________________________________________________________________________Need to analyze the error logs and figure out what went wrong.###Hi Team,When we checked we found that the location for mysql logs as below:[mysqld]basedir = /usr/local/infobright-4.9.0-x86_64#datadir = /usr/local/infobright-4.9.0-x86_64/datadatadir = /var/infobright/datalog-error = /var/infobright/data/iee-mysql.errlog-output = FILEWhen we checked the status of mysql service we are receiving the following error.[root@ip-10-59-10-12 data]# service mysqld statusmysqld: unrecognized serviceChecked and found that mysql is installedInstalled PackagesName        : mysqlArch        : x86_64Version     : 5.1.73Release     : 5.el6_6Size        : 2.4 MRepo        : installedFrom repo   : baseNeed to analyze more why the service is shown unrecognized.[root@ip-10-59-10-12 data]# mysqlERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)From below you can see mysqld is active[root@ip-10-59-10-12 data]# ps uxa | grep mysqldroot       5852  0.0  0.0 145000  1556 ?        S    Jan16   0:00 su mysql -s /bin/bash -c /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-12.ec2.internal.pid >/dev/null 2>&1mysql      5855  0.0  0.0 106060  1308 ?        Ss   Jan16   0:00 bash -c /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-12.ec2.internal.pid >/dev/null 2>&1mysql      5856  0.0  0.0 106064  1496 ?        S    Jan16   0:00 /bin/sh /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-12.ec2.internal.pidmysql      5988 35.7 32.1 191247176 81083232 ?  Sl   Jan16 358:30 /usr/local/infobright-4.9.0-x86_64/bin/mysqld --defaults-file=/etc/my-ib.cnf --basedir=/usr/local/infobright-4.9.0-x86_64 --datadir=/var/infobright/data --log-error=/var/infobright/data/iee-mysql.err --pid-file=/var/infobright/data/ip-10-59-10-12.ec2.internal.pid --socket=/tmp/mysql-ib.sock --port=5029###Hi Matthew,On checking, we found that the start time for MySQL process is at 16:22 UTC on 16th Jan and we found some MySQL-related errors from system logs.We are still investigating this issue and will get back to you with details.###On checking, we found the below points.1.) Last start time for MySQL process is 16:22 UTC on Jan16. Please find the below details.[root@ip-10-59-10-12 infobright-4.9.0-x86_64]# netstat -tlpnActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program nametcp        0      0 :::5029                     :::*                        LISTEN      5988/mysqld[root@ip-10-59-10-12 infobright-4.9.0-x86_64]# ps -eo pid,ppid,cmd,stime | grep '598.'  5852      1 su mysql -s /bin/bash -c /u 16:22  5855   5852 bash -c /usr/local/infobrig 16:22  5856   5855 /bin/sh /usr/local/infobrig 16:22  5988   5856 /usr/local/infobright-4.9.0 16:22[root@ip-10-59-10-12 log]# dateMon Jan 16 23:21:32 UTC 20172.) On checking the system logs we found the below error messages.Jan 15 23:20:14 ip-10-59-10-12 collectd[45880]: apache: curl_easy_perform failed: Failed to connect to local-stackdriver-agent.stackdriver.com port 80: Connection refusedJan 15 23:20:14 ip-10-59-10-12 collectd[45880]: mysql plugin: Failed to connect to database <none> at server localhost: Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)Jan 15 23:20:14 ip-10-59-10-12 collectd[45880]: read-function of plugin `apache//localhost' failed. Will suspend it for 86400.000 seconds.Jan 15 23:20:14 ip-10-59-10-12 collectd[45880]: read-function of plugin `mysql-sys_infobright' failed. Will suspend it for 86400.000 seconds.Jan 15 23:20:14 ip-10-59-10-12 collectd[45880]: mysql plugin: Failed to connect to database <none> at server localhost: Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)Jan 15 23:20:14 ip-10-59-10-12 collectd[45880]: read-function of plugin `mysql-rean_stackdriver' failed. Will suspend it for 86400.000 seconds.Jan 16 02:52:40 ip-10-59-10-12 kernel: connection5:0: detected conn error (1011)Jan 16 02:52:41 ip-10-59-10-12 iscsid: Kernel reported iSCSI connection 5:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)The MySQL process is installed in a custom location, we couldn't find MySQL related logs.Analyze further to find the root cause behind this issue, check with Sudheer/ Sanket for the log file location.###Hi Matthew,Earlier we don't any policy to monitor MySQL process status. We have created a new policy to monitor MySQL process for all the DB servers.We are analyzing more on this issue and will get back to you with details.###It was my understanding that you also monitor the database service, which came down today. Can you confirm that you are monitoring this service?###Hi Matthew,The last outage which our monitoring tool identified on 14/12/2017 at 3:26 AM UTC. During that time there was a maintenance going on to perform updates on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos. We have also successfully changed the ISCSI initiator name for PROD-SPHQ-DB-SERVER03 and TEST-SPHQ-WEB-SERVER01 during the maintenance.This requires a downtime since we need to restart the ISCSI initiator service. We already informed these details with you before the maintenance. Please let us know if you are asking about this outage. Meanwhile, we will perform more analysis from our side.###Hi Matthew,Monitoring is enabled for this instance but we are not monitoring the ISCSI volume mounted.Please let us know what kind of outage you are facing on this instance. We didn't get alerts related to this instance from any our monitoring tool.","Rean Team, We recently had an outage on our PRD Database (10.59.10.12), yet we received no communication from yourselves about this outage. Can you please advise if you are monitoring this box and if this is the case why no communication was relayed about the outage.",PRD Database,,16-01-2017 22:47,42,0,SpendHQ,Sudheer had a call with Andrew and he mentioned that this issue need to be discussed with Matthew and he will get back to us within next 24 hours.,"Hello Matthew,From the logs, we were able to figure out that few logs are indicating the MySQL shut down as below.170106 20:16:16 [ERROR] /usr/local/infobright-4.9.0-x86_64/bin/mysqld: Incorrect key file for table '/tmp/#sql_17e47_0.MYI'; try to repair it170111 17:14:30 [ERROR] /usr/local/infobright-4.9.0-x86_64/bin/mysqld: Server shutdown in progressThere are two main reasons for this error message to show:1) The MySQL query that we are trying to execute takes too long and the MySQL server times out.The solution for this issue is to optimize your database for the queries which fail.2) You have a crashed table in your database.The solution in this case is to repair and optimize your database.We have already created the monitoring policies for the MySQL service and we will closely monitor the MySQL and will inform you in case of any issues in future.For now, we are marking this case as resolved.Please let us know if you would like to know any further information from our end.",I see the errors in the iee-mysql.err log file  [Warning] IPaddress '10.59.100.125' could not be resolved: no reverse address mapping.  [Warning] IP address '10.59.10.12' could not be resolved: no reverse address mapping. 170116 16:27:11 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht' MySQL has to do a reverse lookup on every IP address connecting to it to determine whether they are part of the domain.We need to check the DNS lookups for the Ip's and most of these IPs are from USA,"I have tried to figure out the issue from the logs, but could not pin point the exact issue that cause to the outage. Escalating the ticeket to Sriram.","From my analysis, I understood that the server is configured with mysql infobright solution.________________________________________________________________________________| ~ @ ip-10-59-10-12 (root)| => /etc/init.d/mysqld-ib status SUCCESS! MySQL running (5988)________________________________________________________________________________| ~ @ ip-10-59-10-12 (root)| => service mysqld-ib status SUCCESS! MySQL running (5988)________________________________________________________________________________________________________________________________________________________________Verified that we are able to connect to mysql-ib server.| ~ @ ip-10-59-10-12 (root)| => mysql-ib -u rlittle -picangetinWelcome to the MySQL monitor.  Commands end with ; or \\g.Your MySQL connection id is 294230Server version: 5.1.40 build number (revision)=IEE_4.9.0_r38009_38040(iee - commercial) (shared)Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql> ________________________________________________________________________________The mysql-ib data is stored in separate volume ________________________________________________________________________________| ~ @ ip-10-59-10-12 (root)| => df -hFilesystem      Size  Used Avail Use% Mounted on/dev/xvda1       99G   77G   17G  83% /tmpfs           121G     0  121G   0% /dev/shm/dev/sdc        4.0T  1.6T  2.2T  43% /var/infobright________________________________________________________________________________Also verified the mysql-ib error logs are available.________________________________________________________________________________| /var/infobright/data @ ip-10-59-10-12 (root)| => ls -R | grep mysqliee-mysql.erriee-mysql.err-oldmysqlexcel_mysql_date_conversion.frmexcel_mysql_date_conversion.MYDexcel_mysql_date_conversion.MYI./mysql:________________________________________________________________________________________________________________________________________________________________| /var/infobright/data @ ip-10-59-10-12 (root)| => tail iee-mysql.err170116 16:22:31 [Warning] IP address '10.59.100.125' could not be resolved: no reverse address mapping.170116 16:27:10 [Warning] IP address '10.59.10.12' could not be resolved: no reverse address mapping.170116 16:27:11 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 16:30:35 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 16:31:12 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 19:58:16 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 20:48:04 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 22:02:06 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170116 22:02:09 [ERROR] Invalid (old?) table or database name 'spend_visibility_custom_values2.bht'170117  3:58:31 [Warning] IP address '10.59.1.192' could not be resolved: no reverse address mapping.________________________________________________________________________________Need to analyze the error logs and figure out what went wrong.","Hi Team,When we checked we found that the location for mysql logs as below:[mysqld]basedir = /usr/local/infobright-4.9.0-x86_64#datadir = /usr/local/infobright-4.9.0-x86_64/datadatadir = /var/infobright/datalog-error = /var/infobright/data/iee-mysql.errlog-output = FILEWhen we checked the status of mysql service we are receiving the following error.[root@ip-10-59-10-12 data]# service mysqld statusmysqld: unrecognized serviceChecked and found that mysql is installedInstalled PackagesName        : mysqlArch        : x86_64Version     : 5.1.73Release     : 5.el6_6Size        : 2.4 MRepo        : installedFrom repo   : baseNeed to analyze more why the service is shown unrecognized.[root@ip-10-59-10-12 data]# mysqlERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)From below you can see mysqld is active[root@ip-10-59-10-12 data]# ps uxa | grep mysqldroot       5852  0.0  0.0 145000  1556 ?        S    Jan16   0:00 su mysql -s /bin/bash -c /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-12.ec2.internal.pid >/dev/null 2>&1mysql      5855  0.0  0.0 106060  1308 ?        Ss   Jan16   0:00 bash -c /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-12.ec2.internal.pid >/dev/null 2>&1mysql      5856  0.0  0.0 106064  1496 ?        S    Jan16   0:00 /bin/sh /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-12.ec2.internal.pidmysql      5988 35.7 32.1 191247176 81083232 ?  Sl   Jan16 358:30 /usr/local/infobright-4.9.0-x86_64/bin/mysqld --defaults-file=/etc/my-ib.cnf --basedir=/usr/local/infobright-4.9.0-x86_64 --datadir=/var/infobright/data --log-error=/var/infobright/data/iee-mysql.err --pid-file=/var/infobright/data/ip-10-59-10-12.ec2.internal.pid --socket=/tmp/mysql-ib.sock --port=5029","Hi Matthew,On checking, we found that the start time for MySQL process is at 16:22 UTC on 16th Jan and we found some MySQL-related errors from system logs.We are still investigating this issue and will get back to you with details.","On checking, we found the below points.1.) Last start time for MySQL process is 16:22 UTC on Jan16. Please find the below details.[root@ip-10-59-10-12 infobright-4.9.0-x86_64]# netstat -tlpnActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program nametcp        0      0 :::5029                     :::*                        LISTEN      5988/mysqld[root@ip-10-59-10-12 infobright-4.9.0-x86_64]# ps -eo pid,ppid,cmd,stime | grep '598.'  5852      1 su mysql -s /bin/bash -c /u 16:22  5855   5852 bash -c /usr/local/infobrig 16:22  5856   5855 /bin/sh /usr/local/infobrig 16:22  5988   5856 /usr/local/infobright-4.9.0 16:22[root@ip-10-59-10-12 log]# dateMon Jan 16 23:21:32 UTC 20172.) On checking the system logs we found the below error messages.Jan 15 23:20:14 ip-10-59-10-12 collectd[45880]: apache: curl_easy_perform failed: Failed to connect to local-stackdriver-agent.stackdriver.com port 80: Connection refusedJan 15 23:20:14 ip-10-59-10-12 collectd[45880]: mysql plugin: Failed to connect to database <none> at server localhost: Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)Jan 15 23:20:14 ip-10-59-10-12 collectd[45880]: read-function of plugin `apache//localhost' failed. Will suspend it for 86400.000 seconds.Jan 15 23:20:14 ip-10-59-10-12 collectd[45880]: read-function of plugin `mysql-sys_infobright' failed. Will suspend it for 86400.000 seconds.Jan 15 23:20:14 ip-10-59-10-12 collectd[45880]: mysql plugin: Failed to connect to database <none> at server localhost: Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)Jan 15 23:20:14 ip-10-59-10-12 collectd[45880]: read-function of plugin `mysql-rean_stackdriver' failed. Will suspend it for 86400.000 seconds.Jan 16 02:52:40 ip-10-59-10-12 kernel: connection5:0: detected conn error (1011)Jan 16 02:52:41 ip-10-59-10-12 iscsid: Kernel reported iSCSI connection 5:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)The MySQL process is installed in a custom location, we couldn't find MySQL related logs.Analyze further to find the root cause behind this issue, check with Sudheer/ Sanket for the log file location.","Hi Matthew,Earlier we don't any policy to monitor MySQL process status. We have created a new policy to monitor MySQL process for all the DB servers.We are analyzing more on this issue and will get back to you with details.","It was my understanding that you also monitor the database service, which came down today. Can you confirm that you are monitoring this service?","Hi Matthew,The last outage which our monitoring tool identified on 14/12/2017 at 3:26 AM UTC. During that time there was a maintenance going on to perform updates on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos. We have also successfully changed the ISCSI initiator name for PROD-SPHQ-DB-SERVER03 and TEST-SPHQ-WEB-SERVER01 during the maintenance.This requires a downtime since we need to restart the ISCSI initiator service. We already informed these details with you before the maintenance. Please let us know if you are asking about this outage. Meanwhile, we will perform more analysis from our side.","Hi Matthew,Monitoring is enabled for this instance but we are not monitoring the ISCSI volume mounted.Please let us know what kind of outage you are facing on this instance. We didn't get alerts related to this instance from any our monitoring tool.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001J3uqI,Cloud Engineer Level 1,Closed,1082806,Incident,26-10-2017 23:44,,"Hello Allen,Thanks for teh confirmation.At this time we are marking this case as resolved. Revert back to us in case of further queries.###Thank you ! I just visited the 4 sites, all of them resolve. Good work !Allen###Hi Allen,This is fixed. Please try all the URLs below and let us know if you see any issue:To resolve the issue with apl.spendhq.com we created separate virtualhost files, updated the /etc/hosts file and also changed the HTTPS 443 listners on ELB to TCP 443:http://api.spendhq.com/https://api.spendhq.com/We needed to change the name from preview.api to preview-api in order to resolve the HTTPS warning on the below site.http://preview-api.spendhq.com/https://preview-api.spendhq.com/Please try all the URLs above and let us know if you see any issue.Else let us know if you are good with the changes done and if we can close this case.###Starting a Troubleshooting session with Allen Now,###Yogesh will be having a call with customerNext Action: Check with Yogesh for updates.###We have fixed the preview.api.spendhq.com site on the Sophos side and now http://preview.api.spendhq.com/ and http://api.spendhq.com/ are serving well now.We see a certificate warning for https://preview.api.spendhq.com/ and that seems to require a custom SSL certificate for preview.api.spendhq.com, Or else we can change the name to previewapi.spendhq.com which should not give these warnings.While accessing https://api.spendhq.com/, We are getting an empty response from the server. This seems to be a configuration issue. Refer details below :[2017-10-26 06:07.15]  ~[Yogesh.YKM-RC] ➤ curl -I api.spendhq.com:443curl: (52) Empty reply from server                                                                                                                                        ✘─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────[2017-10-26 06:09.36]  ~[Yogesh.YKM-RC] ➤ curl -I api.spendhq.comHTTP/1.1 200 OKContent-Type: text/html; charset=UTF-8Date: Thu, 26 Oct 2017 00:39:46 GMTSecurity: SHQ 2.1Server: ApacheConnection: keep-alive###Hi Allen,I couldn't SSH to 10.59.100.210. Instance.pem key pair is rejected. Please let me know if you have reconfigured the SSH credentials, and then kindly provide me the access to it to investigate this.Thank You,Safuvan KM###Allen Herrera6:31 PM (1 hour ago)to Rean, spendhq-support Same thing still:http://api-spendhq-com-43120098.us-east-1.elb.amazonaws.com/         does work (http)https://api-spendhq-com-43120098.us-east-1.elb.amazonaws.com/         does NOT work (https) Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group From: noreply@salesforce.com [mailto:noreply@salesforce.com] On Behalf Of Rean SupportSent: Tuesday, October 24, 2017 10:42 PMTo: spendhq-support@reancloud.comSubject: Update on Case # I-01082806 | Low - P4 | Fwd: Check preview.api.spendhq.com configuration###Hello Allen,We are able to access the page for api-spendhq-com-43120098.us-east-1.elb.amazonaws.com.Please see the attached screenshot.  Kindly let us know whether do you want secure connection through a specific port.###Hello Allen,Please confirm if api-spendhq-com-43120098.us-east-1.elb.amazonaws.com is pointed to the EC2 preview.api.spendhq.com. We don't find any entry for this in sophos.On checking we could see the Preview-api-spendhq-com-1361113177.us-east-1.elb.amazonaws.com ELB is pointed to the  EC2 preview.api.spendhq.com and we have the necessary entries for this. Regarding the firewall rules we will check on this and will update you.###Hey rean , do we have any special firewall rules on preview-api-spendhq-com-1361113177.us-east-1.elb.amazonaws.comorapi-spendhq-com-43120098.us-east-1.elb.amazonaws.com that would effect https requests? Specifically for api-spendhq-com-43120098.us-east-1.elb.amazonaws.com we get timeout errors hitting https://api-spendhq-com-43120098.us-east-1.elb.amazonaws.com   Allen Herrera | Developer | SpendHQ®###Hello Team,We have verified the entries for Virtual and real webservers in sophos and it is configured correctly. We can confirm that preview-api ELB pointing to the Sophos is forwarding to the EC2 preview.api.spendhq.com.Let us know if you have any further queries.###Please work on this in night shift.###Hello Andrew,We will check on this and will let you know the updates.","---------- Forwarded message ----------From: Andrew Kim <Akim@spendhq.com>Date: Mon, Oct 23, 2017 at 8:05 PMSubject: Check preview.api.spendhq.com configurationTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Hello – we are testing one of our servers, but the configuration does notappear to work correctly. Please adviseWe’ve done the following   - Created a DNS entry for api.spendhq.com -> api-spendhq-com-43120098.us-   east-1.elb.amazonaws.com      - This appears to be resolving to EC2 preview.api.spendhq.com   - Created a DNS entry for preview.api.spendhq.com ->   Preview-api-spendhq-com-1361113177.us-east-1.elb.amazonaws.com   <http://Preview-api-spendhq-com-1361113177.us-east-1.elb.amazonaws.com>      - This does NOT resolve to EC2 preview.api.spendhq.com – we’re not      sure where this is being point toPlease confirm that the preview-api ELB pointing to the Sophos isforwarding to the EC2 preview.api.spendhq.comThank you,*Andrew Kim* | Director of Information Technology & Security | *Spend**HQ®*O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Check preview.api.spendhq.com configuration,,23-10-2017 20:13,76,0,SpendHQ,"Hello Allen,Thanks for teh confirmation.At this time we are marking this case as resolved. Revert back to us in case of further queries.","Thank you ! I just visited the 4 sites, all of them resolve. Good work !Allen","Hi Allen,This is fixed. Please try all the URLs below and let us know if you see any issue:To resolve the issue with apl.spendhq.com we created separate virtualhost files, updated the /etc/hosts file and also changed the HTTPS 443 listners on ELB to TCP 443:http://api.spendhq.com/https://api.spendhq.com/We needed to change the name from preview.api to preview-api in order to resolve the HTTPS warning on the below site.http://preview-api.spendhq.com/https://preview-api.spendhq.com/Please try all the URLs above and let us know if you see any issue.Else let us know if you are good with the changes done and if we can close this case.","Starting a Troubleshooting session with Allen Now,",Yogesh will be having a call with customerNext Action: Check with Yogesh for updates.,"We have fixed the preview.api.spendhq.com site on the Sophos side and now http://preview.api.spendhq.com/ and http://api.spendhq.com/ are serving well now.We see a certificate warning for https://preview.api.spendhq.com/ and that seems to require a custom SSL certificate for preview.api.spendhq.com, Or else we can change the name to previewapi.spendhq.com which should not give these warnings.While accessing https://api.spendhq.com/, We are getting an empty response from the server. This seems to be a configuration issue. Refer details below :[2017-10-26 06:07.15]  ~[Yogesh.YKM-RC] ➤ curl -I api.spendhq.com:443curl: (52) Empty reply from server                                                                                                                                        ✘─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────[2017-10-26 06:09.36]  ~[Yogesh.YKM-RC] ➤ curl -I api.spendhq.comHTTP/1.1 200 OKContent-Type: text/html; charset=UTF-8Date: Thu, 26 Oct 2017 00:39:46 GMTSecurity: SHQ 2.1Server: ApacheConnection: keep-alive","Hi Allen,I couldn't SSH to 10.59.100.210. Instance.pem key pair is rejected. Please let me know if you have reconfigured the SSH credentials, and then kindly provide me the access to it to investigate this.Thank You,Safuvan KM","Allen Herrera6:31 PM (1 hour ago)to Rean, spendhq-support Same thing still:http://api-spendhq-com-43120098.us-east-1.elb.amazonaws.com/         does work (http)https://api-spendhq-com-43120098.us-east-1.elb.amazonaws.com/         does NOT work (https) Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group From: noreply@salesforce.com [mailto:noreply@salesforce.com] On Behalf Of Rean SupportSent: Tuesday, October 24, 2017 10:42 PMTo: spendhq-support@reancloud.comSubject: Update on Case # I-01082806 | Low - P4 | Fwd: Check preview.api.spendhq.com configuration","Hello Allen,We are able to access the page for api-spendhq-com-43120098.us-east-1.elb.amazonaws.com.Please see the attached screenshot.  Kindly let us know whether do you want secure connection through a specific port.","Hello Allen,Please confirm if api-spendhq-com-43120098.us-east-1.elb.amazonaws.com is pointed to the EC2 preview.api.spendhq.com. We don't find any entry for this in sophos.On checking we could see the Preview-api-spendhq-com-1361113177.us-east-1.elb.amazonaws.com ELB is pointed to the  EC2 preview.api.spendhq.com and we have the necessary entries for this. Regarding the firewall rules we will check on this and will update you.","Hey rean , do we have any special firewall rules on preview-api-spendhq-com-1361113177.us-east-1.elb.amazonaws.comorapi-spendhq-com-43120098.us-east-1.elb.amazonaws.com that would effect https requests? Specifically for api-spendhq-com-43120098.us-east-1.elb.amazonaws.com we get timeout errors hitting https://api-spendhq-com-43120098.us-east-1.elb.amazonaws.com   Allen Herrera | Developer | SpendHQ®","Hello Team,We have verified the entries for Virtual and real webservers in sophos and it is configured correctly. We can confirm that preview-api ELB pointing to the Sophos is forwarding to the EC2 preview.api.spendhq.com.Let us know if you have any further queries.",Please work on this in night shift.,"Hello Andrew,We will check on this and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001RSMkD,Cloud Engineer Level 1,Closed,1091917,Incident,28-02-2018 20:29,,"Hello Dusty,Thanks for the updateWe have modified the endpoint monitoring from http://preview-api.spendhq.com to https://preview-api.spendhq.com/api/. At this time we are marking this case as resolved. Please revert back to us if you have any further concerns.###I think the true monitor will be on - https://preview-api.spendhq.com/api/ and that should be the 301.  The base domain “should” never serve any pages. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com###Hello Dusty, We haven't heard back from you. Please review the case comments and let us know your response.For now, we have modified the endpoint monitoring and disabled the maintenance for preview-api.spendhq.com by changing Expected HTTP Response from 200 OK to 301 Moved Permanently to pass the monitor. Please find the changes below.Previous Monitor Configuration:~~~~~~~~~~~~~~~~~~~~~~~URL: https://preview-api.spendhq.comTimeout (s): 30Expected HTTP Response: 200 OKVerify SSL certificate?: YesMin. SSL cert. validity (days): 30Allow insecure TLS/SSL ciphers: NoMatch content in headers: NoCurrent Monitor Configuration:~~~~~~~~~~~~~~~~~~~~~~URL: http://preview-api.spendhq.comTimeout (s): 30Expected HTTP Response: 301 Moved PermanentlyVerify SSL certificate?: YesMin. SSL cert. validity (days): 30Allow insecure TLS/SSL ciphers: NoMatch content in headers: NoPlease review these details and let us know if we are good with this or else we can modify it as per needed.Thank You,Safuvan KM###Hello Dusty,Thank you for the update.Previously,  the URL https://preview-api.spendhq.com was publically accessible and hence our endpoint URL monitoring tool was able to perform health checks for this URL.Due to the recent changes, our monitoring tool was unable to reach out https://preview-api.spendhq.com. As of now, we have enabled maintenance mode on this URL.As this outage was caused due to a known activity, we are decreasing the priority of this case from P2 to P3. Kindly validate these details and let us know your thoughts regarding the same.Regards,Sumod.K.Bose###The domain is not down.  This is an api specific endpoint, so we do not want web browsers to hit it.  It will only serve successful responses if being hit by an api protocal.   I hope that makes sense. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com###Have sent out an email regarding the same on SpendHQ DL. Waiting for their response.###Hello SpendHQ-Team,The website is still down for the https://preview-api.spendhq.com and the alert is open for the last 1 hour.If this issue is not caused due to any planned activity, we can get on a quick call for further discussion on this case. Kindly let us know your thoughts regarding the same.Regards,Sumod.K.Bose###Hello SpendHQ-Team,The alert regarding site down for the URL https://preview-api.spendhq.com is still open and the website is down for the last 40 minutes. We have tried to reach out to Allen, Matthew and Andrew to check and confirm if there were any maintenance activity performed but the call was left unanswered.We could see that the user aherrera is currently logged into this instance.We have checked form the instance level and it seems that the services are running as expected. Kindly let us know if any change has been performed from your end which has caused this outage. If not, we can get on a quick call to discuss further on this issue. Let us know your thoughts regarding the same.Regards,Sumod.K.Bose###Hello SpendHQ-team,We have received another site down alert for the URL: https://preview-api.spendhq.com.The site is still down. We will further investigate the alert and will let you know the updates.###Hello SpendHQ-team, This is to notify you that we have received a site down alert for the URL:https://preview-api.spendhq.com. Later the alert got resolved and the site is accessible now. The violation lasted for 2 minutes 59 seconds. We are investigating the alert and meanwhile let us know if you are performing any activity from your end.","Mon, 26 Feb 2018 10:28:12 -0500Detected Error on SpendHQ PreviewEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Sensor parameters:url: https://preview-api.spendhq.comexpect: 200wantedstring: unwantedstring: Reported by node: Atlanta-B USConfirmed by node(s): Frankfurt DE, Dallas-B US, California US, Sydney-C AU--  <https://www.reancloud.com/news/rean-cloud-awarded-cloud-contract-department-defense-worth-950-million/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,26-02-2018 20:58,48,0,SpendHQ,"Hello Dusty,Thanks for the updateWe have modified the endpoint monitoring from http://preview-api.spendhq.com to https://preview-api.spendhq.com/api/. At this time we are marking this case as resolved. Please revert back to us if you have any further concerns.",I think the true monitor will be on - https://preview-api.spendhq.com/api/ and that should be the 301.  The base domain “should” never serve any pages. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com,"Hello Dusty, We haven't heard back from you. Please review the case comments and let us know your response.For now, we have modified the endpoint monitoring and disabled the maintenance for preview-api.spendhq.com by changing Expected HTTP Response from 200 OK to 301 Moved Permanently to pass the monitor. Please find the changes below.Previous Monitor Configuration:~~~~~~~~~~~~~~~~~~~~~~~URL: https://preview-api.spendhq.comTimeout (s): 30Expected HTTP Response: 200 OKVerify SSL certificate?: YesMin. SSL cert. validity (days): 30Allow insecure TLS/SSL ciphers: NoMatch content in headers: NoCurrent Monitor Configuration:~~~~~~~~~~~~~~~~~~~~~~URL: http://preview-api.spendhq.comTimeout (s): 30Expected HTTP Response: 301 Moved PermanentlyVerify SSL certificate?: YesMin. SSL cert. validity (days): 30Allow insecure TLS/SSL ciphers: NoMatch content in headers: NoPlease review these details and let us know if we are good with this or else we can modify it as per needed.Thank You,Safuvan KM","Hello Dusty,Thank you for the update.Previously,  the URL https://preview-api.spendhq.com was publically accessible and hence our endpoint URL monitoring tool was able to perform health checks for this URL.Due to the recent changes, our monitoring tool was unable to reach out https://preview-api.spendhq.com. As of now, we have enabled maintenance mode on this URL.As this outage was caused due to a known activity, we are decreasing the priority of this case from P2 to P3. Kindly validate these details and let us know your thoughts regarding the same.Regards,Sumod.K.Bose","The domain is not down.  This is an api specific endpoint, so we do not want web browsers to hit it.  It will only serve successful responses if being hit by an api protocal.   I hope that makes sense. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com",Have sent out an email regarding the same on SpendHQ DL. Waiting for their response.,"Hello SpendHQ-Team,The website is still down for the https://preview-api.spendhq.com and the alert is open for the last 1 hour.If this issue is not caused due to any planned activity, we can get on a quick call for further discussion on this case. Kindly let us know your thoughts regarding the same.Regards,Sumod.K.Bose","Hello SpendHQ-Team,The alert regarding site down for the URL https://preview-api.spendhq.com is still open and the website is down for the last 40 minutes. We have tried to reach out to Allen, Matthew and Andrew to check and confirm if there were any maintenance activity performed but the call was left unanswered.We could see that the user aherrera is currently logged into this instance.We have checked form the instance level and it seems that the services are running as expected. Kindly let us know if any change has been performed from your end which has caused this outage. If not, we can get on a quick call to discuss further on this issue. Let us know your thoughts regarding the same.Regards,Sumod.K.Bose","Hello SpendHQ-team,We have received another site down alert for the URL: https://preview-api.spendhq.com.The site is still down. We will further investigate the alert and will let you know the updates.","Hello SpendHQ-team, This is to notify you that we have received a site down alert for the URL:https://preview-api.spendhq.com. Later the alert got resolved and the site is accessible now. The violation lasted for 2 minutes 59 seconds. We are investigating the alert and meanwhile let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001RT1r0,Cloud Engineer Level 1,Closed,1092034,Incident,28-02-2018 06:39,,"Hello Team, This is to inform you that we received alerts regarding the high memory utilization for instance prd-ww2_6. The memory utilization has exceeded the threshold value of 80% to a value of 81%. We could see that httpd process was consuming more memory.Also, the alerts were getting resolved within 10 minutes. Please let us know whether you are having any concerns regarding this. As currently the alert is resolved state we are closing this case.Refer the below resource details, Instance ID: i-01ac95c23ac66a40e Instance type: c4.2xlarge Availability zone: us-east-1c Private IP: 10.59.101.6 VPC ID: vpc-76df7212 Subnet ID: subnet-29b09361","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Wed, Feb 28, 2018 at 4:15 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Memory UtilizationAlert on host - prd-ww2_6 - 10.59.101.6 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 -10.59.101.6 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1519771547000&group=host%3Ai-01ac95c23ac66a40e&from_ts=1519771247000>avg(last_5m):( avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 80The monitor was last triggered at Tue Feb 27 2018 22:45:57 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-01ac95c23ac66a40e>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-01ac95c23ac66a40e<https://app.datadoghq.com/infrastructure?hostname=i-01ac95c23ac66a40e>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1519771557000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1519770657000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4286724526736470176>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 - 10.59.101.6 - web,,28-02-2018 04:43,2,0,SpendHQ,"Hello Team, This is to inform you that we received alerts regarding the high memory utilization for instance prd-ww2_6. The memory utilization has exceeded the threshold value of 80% to a value of 81%. We could see that httpd process was consuming more memory.Also, the alerts were getting resolved within 10 minutes. Please let us know whether you are having any concerns regarding this. As currently the alert is resolved state we are closing this case.Refer the below resource details, Instance ID: i-01ac95c23ac66a40e Instance type: c4.2xlarge Availability zone: us-east-1c Private IP: 10.59.101.6 VPC ID: vpc-76df7212 Subnet ID: subnet-29b09361",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001kqdpq,Cloud Engineer Level 1,Closed,1112756,Incident,03-03-2019 21:23,,"Hello Team,This is to notify you that we are marking this case as closed as we already have a ticket regarding this with case id: 01112674.###Hello Team,We have received an notification regarding unused eni below are the details for the same:1) eni-0010b7c49c8b771b3  Event time: 2019-02-22, 04:25:18 AM User name: AWSElasticsearch2) eni-0018935d73581d9c2  Event time: 2019-02-22, 04:25:17 AM  User name: AWSElasticsearch3) eni-03e3adfbd7b0c0137   Event time: 2019-02-14, 06:34:52 PM   User name: AWSElasticsearch4) eni-05149ab6beb147c9f   Event time: 2019-02-14, 06:34:53 PM    User name: AWSElasticsearch5) eni-05eaf737f37376958   Event time: 2019-02-22, 04:25:18 AM   User name: AWSElasticsearch6) eni-06567c965aef39f31   Event time: 2019-02-22, 04:25:16 AM   User name: AWSElasticsearch7) eni-06641298f0767f55a   Event time: 2019-02-14, 06:34:53 PM   User name: AWSElasticsearch8)eni-0846d5522e3ed4f00    Event time: 2019-02-14, 05:16:15 PM    User name: AWSElasticsearch9) eni-0970cc9281bcfeef3   Event time: 2019-02-14, 05:16:17 PM   User name: AWSElasticsearchPlease have a look at the details and let us know if we can clean them up.Thanks","From: notifications@mnc-notify.com <notifications@mnc-notify.com>Reply-To: notifications@mnc-notify.com <notifications@mnc-notify.com>Date: Sunday, 3 March 2019 at 6:11 PMTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Subject: [Managed Cloud: spendhq] Unused ENIs Check***** EXTERNAL EMAIL *****REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::EC2::NetworkInterface resources were affected:________________________________  *   Violation: This ENI is not being used by any instance  *   Recommendation: Since the ENI is not being used by any instance, associate it with any instance or it will get deleted.  *   Action taken: None  *   Resource details:Resource IDRegioneni-05149ab6beb147c9fus-east-1eni-06567c965aef39f31us-east-1eni-03e3adfbd7b0c0137us-east-1eni-0018935d73581d9c2us-east-1eni-0010b7c49c8b771b3us-east-1eni-05eaf737f37376958us-east-1eni-0846d5522e3ed4f00us-east-1eni-0970cc9281bcfeef3us-east-1eni-06641298f0767f55aus-east-1________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.",[Managed Cloud: spendhq] Unused ENIs Check,,03-03-2019 18:32,3,0,SpendHQ,"Hello Team,This is to notify you that we are marking this case as closed as we already have a ticket regarding this with case id: 01112674.","Hello Team,We have received an notification regarding unused eni below are the details for the same:1) eni-0010b7c49c8b771b3  Event time: 2019-02-22, 04:25:18 AM User name: AWSElasticsearch2) eni-0018935d73581d9c2  Event time: 2019-02-22, 04:25:17 AM  User name: AWSElasticsearch3) eni-03e3adfbd7b0c0137   Event time: 2019-02-14, 06:34:52 PM   User name: AWSElasticsearch4) eni-05149ab6beb147c9f   Event time: 2019-02-14, 06:34:53 PM    User name: AWSElasticsearch5) eni-05eaf737f37376958   Event time: 2019-02-22, 04:25:18 AM   User name: AWSElasticsearch6) eni-06567c965aef39f31   Event time: 2019-02-22, 04:25:16 AM   User name: AWSElasticsearch7) eni-06641298f0767f55a   Event time: 2019-02-14, 06:34:53 PM   User name: AWSElasticsearch8)eni-0846d5522e3ed4f00    Event time: 2019-02-14, 05:16:15 PM    User name: AWSElasticsearch9) eni-0970cc9281bcfeef3   Event time: 2019-02-14, 05:16:17 PM   User name: AWSElasticsearchPlease have a look at the details and let us know if we can clean them up.Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001i7rph,Cloud Engineer Level 1,Closed,1110923,Incident,19-01-2019 04:19,,"[Via Email]I am now able to access and run sudo commands on all 6 servers. Thank you Stephen.Thanks,Chris Min###Hi Chris,Thank you for joining the call and for the confirmation that the issue is sorted out.As the issue is resolved, we are marking this case as closed.Please feel free to keep in touch for continued support.Thanks.Stephen Oduor###Hi Chris,Please join the bridge below for a troubleshooting session.https://reancloud.zoom.us/my/mgse1Thanks.Stephen Oduor###Stephen, I still cannot access the server. ThanksChris Min###Hi Chris,Can you please try accessing server 10.59.100.193 once more and let us know the updates.In case the issue persists then we might have to go on call to resolve it there.Let us know if it's a success.Thanks & Regards.Stephen Oduor###Sorry for the inconvenience caused by inability to access 10.59.100.193.Let's have look at it once more and get back to you.Thanks.###Stephen,I do have sudo access on 10.59.100.125 now and I can sudo su without typing in other 4 servers and 10.59.100.125.However, I still cannot access 10.59.100.193.Thanks,Chris Min |###Hi Chris,We have addressed the issues you raised. You now have sudo access for server 10.59.100.125.On top of that, we have also removed the need to enter your password to run sudo commands. Remember however that you will still need the password to connect to the servers.Please verify these access once more, especially for server 10.59.100.193, and let us know if there are any more bottlenecks.Thanks. Regards.Stephen Oduor###Hi Chris,This is noted. We are looking into the issues you've raised and will get back to you as soon as possible.Thanks. Regards.Stephen Oduor###Hi Stephen,I was able to access all but 1 server. I cannot access 10.59.100.193. Could you take a look?Also, I do not have sudo access on 10.59.100.125 and I was told that I need to be a sudo-er on that server.Lastly, could you allow me to omit my sudo password on these 6 servers?Thanks,Chris Min###Hello Chris,We have completed your request and shared the credentials with you separately.Please verify access to all the six servers (10.59.100.125, 10.59.10.210, 10.59.10.26, 10.59.10.45, 10.59.10.235 and 10.59.100.193) and let us know if you are facing any issues.Thanks. Regards.Stephen Oduor###Hi David,We are currently working on this. It should be done in a few minutes.We will keep you updated.Thanks.Stephen Oduor###[Via Email] This needs to be done by the end of the day pleaseDavid Miller###[Via Email]This request is approved also.  Thank youDavid Miller###Hello Chris,We acknowledge  your request.We will look into it and will get back to you with more details.Thanks,","Hi REAN,I need to be able to access the following servers for on call purpose:  *   10.59.100.125  *   10.59.10.210  *   10.59.10.26  *   10.59.10.45  *   10.59.10.235  *   10.59.100.193My username is cmin and my public key is attached in this email. I believe I need the same level of permission as dmiller, dfowler, or aherrera.Thank you,Chris Min | Senior Data Engineer | SpendHQ®O: 470.204.0862 | C: 770.688.5695 | cmin@spendhq.com<mailto:cmin@spenhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com> | www.insightsourcing.com<http://www.insightsourcing.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Server access for cmin,,18-01-2019 23:58,4,0,SpendHQ,"[Via Email]I am now able to access and run sudo commands on all 6 servers. Thank you Stephen.Thanks,Chris Min","Hi Chris,Thank you for joining the call and for the confirmation that the issue is sorted out.As the issue is resolved, we are marking this case as closed.Please feel free to keep in touch for continued support.Thanks.Stephen Oduor","Hi Chris,Please join the bridge below for a troubleshooting session.https://reancloud.zoom.us/my/mgse1Thanks.Stephen Oduor","Stephen, I still cannot access the server. ThanksChris Min","Hi Chris,Can you please try accessing server 10.59.100.193 once more and let us know the updates.In case the issue persists then we might have to go on call to resolve it there.Let us know if it's a success.Thanks & Regards.Stephen Oduor",Sorry for the inconvenience caused by inability to access 10.59.100.193.Let's have look at it once more and get back to you.Thanks.,"Stephen,I do have sudo access on 10.59.100.125 now and I can sudo su without typing in other 4 servers and 10.59.100.125.However, I still cannot access 10.59.100.193.Thanks,Chris Min |","Hi Chris,We have addressed the issues you raised. You now have sudo access for server 10.59.100.125.On top of that, we have also removed the need to enter your password to run sudo commands. Remember however that you will still need the password to connect to the servers.Please verify these access once more, especially for server 10.59.100.193, and let us know if there are any more bottlenecks.Thanks. Regards.Stephen Oduor","Hi Chris,This is noted. We are looking into the issues you've raised and will get back to you as soon as possible.Thanks. Regards.Stephen Oduor","Hi Stephen,I was able to access all but 1 server. I cannot access 10.59.100.193. Could you take a look?Also, I do not have sudo access on 10.59.100.125 and I was told that I need to be a sudo-er on that server.Lastly, could you allow me to omit my sudo password on these 6 servers?Thanks,Chris Min","Hello Chris,We have completed your request and shared the credentials with you separately.Please verify access to all the six servers (10.59.100.125, 10.59.10.210, 10.59.10.26, 10.59.10.45, 10.59.10.235 and 10.59.100.193) and let us know if you are facing any issues.Thanks. Regards.Stephen Oduor","Hi David,We are currently working on this. It should be done in a few minutes.We will keep you updated.Thanks.Stephen Oduor",[Via Email] This needs to be done by the end of the day pleaseDavid Miller,[Via Email]This request is approved also.  Thank youDavid Miller,"Hello Chris,We acknowledge  your request.We will look into it and will get back to you with more details.Thanks,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001jiNkZ,Cloud Engineer Level 1,Closed,1111831,Incident,11-02-2019 14:45,,"Hello Matthew,We haven't heard back from you regarding this case & Apologize for the for the inconvenience caused by our side.At this time, we're marking this case as Resolved/Closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,###Hello Matthew,Please review our analysis and please let us know if you have any queries.###Hi Matthew,Thanks for being patient while we sort this out. After an in-depth discussion with in our team, we've realized that we're responsible for this service down issue. As a part of working on ticket : 01111820 ; while creating the clone of the server 10.59.100.122 the instance got rebooted, which resulted this alert. The alert got recovered with in one minute.We are deeply sorry for the inconvenience caused. Should you want any further details, feel free to contact us anytime.Thank you.###From Matthew,=============Any status on this.###@Team:This went down because of Our Team were working on one of the cmp ticket and creating ami of the production instance 10.59.100.122And Team has forgot to select the no reboot option which lead to the reboot of the machine.###Hello Cc,On Checking the logs below are the findings I found SIGTERM(signal 15)  kill the process.also killed the rpcbind and restarted the service.---------eb  8 04:08:08 ip-10-59-100-122 init: serial (ttyS0) main process (2039) killed by TERM signalFeb  8 04:08:08 ip-10-59-100-122 init: tty (/dev/tty1) main process (2040) killed by TERM signalFeb  8 04:08:09 ip-10-59-100-122 init: newrelic-infra main process (799) killed by TERM signalFeb  8 04:08:10 ip-10-59-100-122 init: datadog-agent main process (1116) killed by TERM signalFeb  8 04:08:10 ip-10-59-100-122 init: datadog-agent-process main process (1127) killed by TERM signalFeb  8 04:08:10 ip-10-59-100-122 init: datadog-agent-trace main process (1128) killed by TERM signalFeb  8 04:08:12 ip-10-59-100-122 clamd[1749]: Pid file removed.Feb  8 04:08:12 ip-10-59-100-122 clamd[1749]: --- Stopped at Fri Feb  8 04:08:12 2019Feb  8 04:08:12 ip-10-59-100-122 clamd[1749]: Socket file removed.Feb  8 04:08:12 ip-10-59-100-122 kernel: nfsd: last server has exited, flushing export cacheFeb  8 04:08:12 ip-10-59-100-122 rpc.mountd[1424]: Caught signal 15, un-registering and exiting.Feb  8 04:08:13 ip-10-59-100-122 acpid: exitingFeb  8 04:08:13 ip-10-59-100-122 ntpd[1666]: ntpd exiting on signal 15Feb  8 04:08:17 ip-10-59-100-122 rpcbind: rpcbind terminating on signal. Restart with rpcbind -wFeb  8 04:08:17 ip-10-59-100-122 auditd[1135]: The audit daemon is exiting.Feb  8 04:08:17 ip-10-59-100-122 kernel: type=1305 audit(1549598897.136:625357): audit_pid=0 old=1135 auid=4294967295 ses=4294967295 res=1Feb  8 04:08:17 ip-10-59-100-122 kernel: type=1305 audit(1549598897.242:625358): audit_enabled=0 old=1 auid=4294967295 ses=4294967295 res=1-----------## Normally it happens when the kernel doesn't have enough resources to continue while the memory is used for all process when some high load occurs.Feb  8 04:06:01 ip-10-59-100-122 CROND[17459]: (root) CMD (/bin/bash /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/load.sh >> /var/tmp/shq-logs/crons/load.log 2>&1)Feb  8 04:07:01 ip-10-59-100-122 CROND[17589]: (root) CMD (/bin/bash /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/load.sh >> /var/tmp/shq-logs/crons/load.log 2>&1)Feb  8 04:08:01 ip-10-59-100-122 CROND[17724]: (root) CMD (/bin/bash /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/load.sh >> /var/tmp/shq-logs/crons/load.log 2>&1)Feb  8 04:08:12 ip-10-59-100-122 crond[1998]: (CRON) INFO (Shutting down)Feb  8 04:09:10 ip-10-59-100-122 crond[1992]: (CRON) STARTUP (1.4.4)Feb  8 04:09:10 ip-10-59-100-122 crond[1992]: (CRON) INFO (RANDOM_DELAY will be scaled with factor 58% if used.)Feb  8 04:09:10 ip-10-59-100-122 crond[1992]: (CRON) INFO (running with inotify support)Feb  8 04:10:01 ip-10-59-100-122 CROND[2250]: (root) CMD (/usr/bin/php /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/monitor_directories.php >> /var/tmp/shq-logs/crons/file-monitor.log 2>&1)Feb  8 04:10:01 ip-10-59-100-122 CROND[2251]: (root) CMD (/bin/bash /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/load.sh >> /var/tmp/shq-logs/crons/load.log 2>&1)Feb  8 04:10:01 ip-10-59-100-122 CROND[2254]: (root) CMD (/usr/lib64/sa/sa1 1 1)----------## from the above, we can observe the cron job is shutting down to execute the script and starting. Hope which caused the high load and SIGTERM happened.[ Continue comment ]###[ continue ]from httpd.errror also it showing of the SIGTERMsh: name: command not foundsh: Company: command not foundsh: name: command not foundPHP Fatal error:  Cannot call overloaded function for non-object in /var/www/vhosts/secure.spendhq.com/public/cake/libs/configure.php on line 140PHP Fatal error:  Cannot call overloaded function for non-object in /var/www/vhosts/secure.spendhq.com/public/app/vendors/htmlpurifier_lite/library/HTMLPurifier/Bootstrap.php on line 40[Fri Feb 08 04:08:10 2019] [notice] caught SIGTERM, shutting down[Fri Feb 08 04:09:10 2019] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Fri Feb 08 04:09:10 2019] [notice] Digest: generating secret for digest authentication ...[Fri Feb 08 04:09:10 2019] [notice] Digest: done[Fri Feb 08 04:09:11 2019] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operationsPlease review this & let me know i can convey the same to SHQ Team.Thanks###Hello Team,This is to inform you we received an alert regarding httpd &  Postfix service are down and both processes were recovered within one minute.We also verified by login the server.[root@ip-10-59-100-122 ~]# service httpd statushttpd (pid  1935) is running...[root@ip-10-59-100-122 ~]# service postfix statusmaster (pid  1890) is running...We are checking the logs why the process is down. Meanwhile please let us know if you have performed any activity from your side & which cause this alert we received.RegardsRafi R","[Datadog][Triggered on {host:i-0ace70ce06368e4a7,process:httpd}] [SpendHQ] Httpd Process is down - prd-ww1_122 - 10.59.100.122 - webHttpd Process is down    @ms@reancloud.com<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECa4ZPSFheKVV3Kgt6YrvAIS39UJGhw9KZnRJrltVbOTQ-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLxjfI0wlUwROBoUGWg4lCbtrQ7WfciXPoPHuA5jdjrZBBhFURdeeWZE8krCr5x82ez4r1wGZT0KLgz5pq1aGm5zkiZe65Qdy6etHV96bADmT-2BeEAUZM1BcytRiJNdYlPq05WkIpys8QL1bwT32Finnud38i6SXO4rAfIPHeaumypB6JMgTxJ0pH1R0CNcZJ1CivquSPndrNacbA3O4XgbaR&data=01%7C01%7Crafi.ramesh%40hitachivantara.com%7C9c6dbda6346541c5f10308d68d7b7a86%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=ODUs0n7rrxoZXQjGNEHINMkn8vfpU4uOCIbPP8fCtOo%3D&reserved=0>PROCS CRITICAL: 0 processes found for httpdThe monitor was last triggered at Fri Feb 08 2019 04:11:00 UTC (14 secs ago).________________________________[Monitor Status<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEB5Aa2ChxAC1hSgLnJw3N-2Bpf-2FSro8izCjEwPR8irnBbYr0HUolcXoP8iGQdOecKUw7VIXGqLqIeAkTulPiy1lyulqEecOfSAW1287GPmkZFTA-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLxjfI0wlUwROBoUGWg4lCbtwDZMqaq3aoPTcUq6gg1is-2FfzbKPqcAek5uimdzaZZm9sOdeaRZ6kYH-2Fl5BZQSKSsuEAuk8BCTCYcUVfql9MAx5jq7YwiB2RSZVJwBevkbk6WR62Q42rJPCViHZV9Pfm87NI1fcWVL3cTF0ldANJHASIdRF-2ByP-2FiPJWZSpbXgoKdNNRKOH4z0-2BgGwKwXCI-2BHM&data=01%7C01%7Crafi.ramesh%40hitachivantara.com%7C9c6dbda6346541c5f10308d68d7b7a86%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=ZlURqTJVhsylxsBM3yiC5NLpNyCZ9%2Bij8SA5VMSmYWE%3D&reserved=0>] · [Edit Monitor<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEB5Aa2ChxAC1hSgLnJw3N-2BpkQo3lZrU3a7wg1KElywn8Q-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLxjfI0wlUwROBoUGWg4lCbt-2FQr1j2llBzTUBnxK4T-2BEd4QnlyeZaNFRbJp0J1BsHg0fgWJGvIgtSuK5KabOEFv6-2F1GXUJY4xwJrhJY7LocQbtgqH6jeW36Ot3jjP9KQfq-2BOMi3RgxEcWuSE13utJ6FmNdr-2BFCliQ1avYjTpwy612CjjTyvCkuQmsrtdkKOs5y5bV0kpfuXjuc-2BFbFpRBxWs&data=01%7C01%7Crafi.ramesh%40hitachivantara.com%7C9c6dbda6346541c5f10308d68d7b7a86%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=rYphSFc%2BEZf21uLx%2FxJ9xSW0jDkdrAbQ90XHOM4FEYA%3D&reserved=0>] · [View i-0ace70ce06368e4a7<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEDKT1NZt0tnkwEaAxSQZgjumtEz3bx7Kvv4ratZWlij2hgYT60tN-2FFpPB5Ct4FBDnM-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLxjfI0wlUwROBoUGWg4lCbtoBqDoRO334qnISZJ-2BaH-2FC1S5EG1b2oOT8K-2F1nc-2FUDDSH8cCOks2CcjHTAxujxdG3iymjQCQrTQncaCoWpWeYpW2v2M89NlAXFldj1qBPmyCY8pejvo370S0GTrthUr7vzlRupls7xN4PsOfBEwYBMmlySV9svftjthPIYCxl19pgbl0F1NxjqmnrjUp-2FSepa&data=01%7C01%7Crafi.ramesh%40hitachivantara.com%7C9c6dbda6346541c5f10308d68d7b7a86%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=YZ0go8NQvshOnKjxf7nX3U8wi47qHaRCkCF8TnVxcak%3D&reserved=0>] · [Show Processes<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQED-2FFPDBbKPsalSo1i1ufo6SoAz0jcd-2B6f345QK7ivt0viZ-2B6qH14iDNp9QIk8jSlyNy8tDH3lUqB3M9fCZZ3XfFwlK1MVuzpBU-2F77BfHzydgSJPowOlVwV2ORONNEpiq56PltBAfgQiRdrFJM09tONl57xlN5PJv-2FaysC3Rb8t-2BoAJqJq-2FY02v7HcKPWLSOGt0-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLxjfI0wlUwROBoUGWg4lCbtLXurSMw46AubLpAK1ttuOMpo-2FT5wuUGyBsKvp5519vVyT9P1RBw9ET3c7fziGGNU6ZpGpVrZ83VYG68d0le4-2FtkyDhqc8Y-2FjwHfo6hvEjWR2lwLNW-2FbDa4UlYXyRQi3IVtwSWio4XqMG-2B9jOFOj1hd4GH4yw83u-2FEAujtlb5B7aNAVcPEH-2FG-2B-2FAUYGSxNBiL&data=01%7C01%7Crafi.ramesh%40hitachivantara.com%7C9c6dbda6346541c5f10308d68d7b7a86%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=uBfd5YYr6DnR8P9AFJTJ9xZgFrZjvbl1BfC6bu6jiQw%3D&reserved=0>]This alert was raised by account SpendHQComment in Datadog<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAYJwPp8omKJuncXDFvQtom9gJpvhAWNcvkCKGu50EBGdj2LmPB2fNPzhih3rvPlxM-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLxjfI0wlUwROBoUGWg4lCbtcPVuLGnK0QsyoreXFs5hmpw61ANFRmp1-2FooqAjcrUT9QLg-2BcWSjBCGQ-2BAxEbV-2FW-2FVNmWbNk5Rv7StRhVry7PijarVx5WvkgTyhM4UPN3-2BuaFjHvvMKk7rH8Pdv9nfnlL8DNPeIvn9Ccrrs4rd4cYaLYngdWOKSN7-2B133A9cXHO4W2hsJiD2RBHSLZvin49Fc&data=01%7C01%7Crafi.ramesh%40hitachivantara.com%7C9c6dbda6346541c5f10308d68d7b7a86%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=%2BL%2FAbcYs0AW5%2Fs9%2BfFvVJCgDsgqcF4Mkyyu2E80dtXA%3D&reserved=0>To manage your Datadog subscriptions, click here<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECkg7AnUPKGn51plZlHct1NB9fwJzgmRoiq4UZtJ-2F9d6Q-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLxjfI0wlUwROBoUGWg4lCbt64joGfHEUmjT6Wap1cSaK-2FyasPSg-2FiNN6s-2F62a-2BBHGi4v1nTgVaCKp7y2-2Fw2o6v4GtkDYMCITSFK8lIvanRzx-2FUAsgNoS4-2BZM3HgTlq5OkRdz8gae8BuDeColEceFwFcCs98HW9fvDjt54ZCxKfFHZNjXK-2BEMj-2BmDvtGMk5X1bh6X8uohbuZhXUiSHjlbxbi&data=01%7C01%7Crafi.ramesh%40hitachivantara.com%7C9c6dbda6346541c5f10308d68d7b7a86%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=fOC9gFJjNkp4QRBGx%2FHqaCGybqBq2ZQ9gJmiz0dhoBI%3D&reserved=0>.","[Monitor Alert] Triggered: [SpendHQ] Httpd Process is down - prd-ww1_122  - 10.59.100.122 - web on host:i-0ace70ce06368e4a7,process:httpd",,08-02-2019 09:52,77,0,SpendHQ,"Hello Matthew,We haven't heard back from you regarding this case & Apologize for the for the inconvenience caused by our side.At this time, we're marking this case as Resolved/Closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,","Hello Matthew,Please review our analysis and please let us know if you have any queries.","Hi Matthew,Thanks for being patient while we sort this out. After an in-depth discussion with in our team, we've realized that we're responsible for this service down issue. As a part of working on ticket : 01111820 ; while creating the clone of the server 10.59.100.122 the instance got rebooted, which resulted this alert. The alert got recovered with in one minute.We are deeply sorry for the inconvenience caused. Should you want any further details, feel free to contact us anytime.Thank you.","From Matthew,=============Any status on this.",@Team:This went down because of Our Team were working on one of the cmp ticket and creating ami of the production instance 10.59.100.122And Team has forgot to select the no reboot option which lead to the reboot of the machine.,"Hello Cc,On Checking the logs below are the findings I found SIGTERM(signal 15)  kill the process.also killed the rpcbind and restarted the service.---------eb  8 04:08:08 ip-10-59-100-122 init: serial (ttyS0) main process (2039) killed by TERM signalFeb  8 04:08:08 ip-10-59-100-122 init: tty (/dev/tty1) main process (2040) killed by TERM signalFeb  8 04:08:09 ip-10-59-100-122 init: newrelic-infra main process (799) killed by TERM signalFeb  8 04:08:10 ip-10-59-100-122 init: datadog-agent main process (1116) killed by TERM signalFeb  8 04:08:10 ip-10-59-100-122 init: datadog-agent-process main process (1127) killed by TERM signalFeb  8 04:08:10 ip-10-59-100-122 init: datadog-agent-trace main process (1128) killed by TERM signalFeb  8 04:08:12 ip-10-59-100-122 clamd[1749]: Pid file removed.Feb  8 04:08:12 ip-10-59-100-122 clamd[1749]: --- Stopped at Fri Feb  8 04:08:12 2019Feb  8 04:08:12 ip-10-59-100-122 clamd[1749]: Socket file removed.Feb  8 04:08:12 ip-10-59-100-122 kernel: nfsd: last server has exited, flushing export cacheFeb  8 04:08:12 ip-10-59-100-122 rpc.mountd[1424]: Caught signal 15, un-registering and exiting.Feb  8 04:08:13 ip-10-59-100-122 acpid: exitingFeb  8 04:08:13 ip-10-59-100-122 ntpd[1666]: ntpd exiting on signal 15Feb  8 04:08:17 ip-10-59-100-122 rpcbind: rpcbind terminating on signal. Restart with rpcbind -wFeb  8 04:08:17 ip-10-59-100-122 auditd[1135]: The audit daemon is exiting.Feb  8 04:08:17 ip-10-59-100-122 kernel: type=1305 audit(1549598897.136:625357): audit_pid=0 old=1135 auid=4294967295 ses=4294967295 res=1Feb  8 04:08:17 ip-10-59-100-122 kernel: type=1305 audit(1549598897.242:625358): audit_enabled=0 old=1 auid=4294967295 ses=4294967295 res=1-----------## Normally it happens when the kernel doesn't have enough resources to continue while the memory is used for all process when some high load occurs.Feb  8 04:06:01 ip-10-59-100-122 CROND[17459]: (root) CMD (/bin/bash /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/load.sh >> /var/tmp/shq-logs/crons/load.log 2>&1)Feb  8 04:07:01 ip-10-59-100-122 CROND[17589]: (root) CMD (/bin/bash /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/load.sh >> /var/tmp/shq-logs/crons/load.log 2>&1)Feb  8 04:08:01 ip-10-59-100-122 CROND[17724]: (root) CMD (/bin/bash /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/load.sh >> /var/tmp/shq-logs/crons/load.log 2>&1)Feb  8 04:08:12 ip-10-59-100-122 crond[1998]: (CRON) INFO (Shutting down)Feb  8 04:09:10 ip-10-59-100-122 crond[1992]: (CRON) STARTUP (1.4.4)Feb  8 04:09:10 ip-10-59-100-122 crond[1992]: (CRON) INFO (RANDOM_DELAY will be scaled with factor 58% if used.)Feb  8 04:09:10 ip-10-59-100-122 crond[1992]: (CRON) INFO (running with inotify support)Feb  8 04:10:01 ip-10-59-100-122 CROND[2250]: (root) CMD (/usr/bin/php /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/monitor_directories.php >> /var/tmp/shq-logs/crons/file-monitor.log 2>&1)Feb  8 04:10:01 ip-10-59-100-122 CROND[2251]: (root) CMD (/bin/bash /var/www/vhosts/secure.spendhq.com/public/app/scripts/monitoring/load.sh >> /var/tmp/shq-logs/crons/load.log 2>&1)Feb  8 04:10:01 ip-10-59-100-122 CROND[2254]: (root) CMD (/usr/lib64/sa/sa1 1 1)----------## from the above, we can observe the cron job is shutting down to execute the script and starting. Hope which caused the high load and SIGTERM happened.[ Continue comment ]","[ continue ]from httpd.errror also it showing of the SIGTERMsh: name: command not foundsh: Company: command not foundsh: name: command not foundPHP Fatal error:  Cannot call overloaded function for non-object in /var/www/vhosts/secure.spendhq.com/public/cake/libs/configure.php on line 140PHP Fatal error:  Cannot call overloaded function for non-object in /var/www/vhosts/secure.spendhq.com/public/app/vendors/htmlpurifier_lite/library/HTMLPurifier/Bootstrap.php on line 40[Fri Feb 08 04:08:10 2019] [notice] caught SIGTERM, shutting down[Fri Feb 08 04:09:10 2019] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Fri Feb 08 04:09:10 2019] [notice] Digest: generating secret for digest authentication ...[Fri Feb 08 04:09:10 2019] [notice] Digest: done[Fri Feb 08 04:09:11 2019] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operationsPlease review this & let me know i can convey the same to SHQ Team.Thanks","Hello Team,This is to inform you we received an alert regarding httpd &  Postfix service are down and both processes were recovered within one minute.We also verified by login the server.[root@ip-10-59-100-122 ~]# service httpd statushttpd (pid  1935) is running...[root@ip-10-59-100-122 ~]# service postfix statusmaster (pid  1890) is running...We are checking the logs why the process is down. Meanwhile please let us know if you have performed any activity from your side & which cause this alert we received.RegardsRafi R",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XCl6q,Cloud Engineer Level 1,Closed,1099839,Incident,10-06-2018 21:44,,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello Matthew,We haven't heard back from you.Please review our previous comment and let us know if you have any query.###Hello Matthew, This is a gentle reminder. We have shared VPN credentials with you in a separate mail. Please give a try and let us know if you facing any issues.###Hello Matthew,This is a gentle reminder.We have shared VPN credentials with you in a separate mail. Please give a try and let us know if you facing any issues.###Hello Matthew,We have shared VPN credentials with you in a separate mail. Please give a try and let us know if you facing any issues.###Hello Matthew,We will work on your request and will let you know the update.","Rean,I am unable to authenticate into the VPN. Can you please reset my password.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <http://go.reancloud.com/secure-your-cloud>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",VPN,,05-06-2018 19:12,123,0,SpendHQ,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello Matthew,We haven't heard back from you.Please review our previous comment and let us know if you have any query.","Hello Matthew, This is a gentle reminder. We have shared VPN credentials with you in a separate mail. Please give a try and let us know if you facing any issues.","Hello Matthew,This is a gentle reminder.We have shared VPN credentials with you in a separate mail. Please give a try and let us know if you facing any issues.","Hello Matthew,We have shared VPN credentials with you in a separate mail. Please give a try and let us know if you facing any issues.","Hello Matthew,We will work on your request and will let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Xx70V,Cloud Engineer Level 1,Closed,1100377,Incident,20-06-2018 05:34,,"Hi Matthew,Thanks for the update, we are now marking this case as closed. Thanks###From Matthew Watts Perfect, thank youSent from a mobile device.###Hello,Please find attached in the Attachment section logs for the said period. Kindly validate them from your end and feel free to get in touch with us in case you may have further queries.Thank you.###Need to share logs.###Hello Team, From our analysis on CloudWatch we could see a spike in Average Latency at 9:23:00 PM UTC with a value of 31841.1399 milliseconds. We also noted a spike in Request Count(s) from 9:23:00 PM UTC to around 9:39:00 PM UTC with an average value of 105.5 for the said period. We also had a spike in Estimated ALB Active Connection Count at 9:23:00 PM UTC with a value of 94.Thank you.###Hello SpendHQ Team, This is to inform you that we received a site down alert on URL: https://preview.spendhq.com/login. The downtime lasted for 1 minute and eventually got recovered within 1 minute. We are analyzing this and will get back to you with further details on the issue. Thank you.","Tue, 19 Jun 2018 17:23:17 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30022 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): New Jersey US, London UK, Dallas-B US, Frankfurt DE-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,20-06-2018 02:54,3,0,SpendHQ,"Hi Matthew,Thanks for the update, we are now marking this case as closed. Thanks","From Matthew Watts Perfect, thank youSent from a mobile device.","Hello,Please find attached in the Attachment section logs for the said period. Kindly validate them from your end and feel free to get in touch with us in case you may have further queries.Thank you.",Need to share logs.,"Hello Team, From our analysis on CloudWatch we could see a spike in Average Latency at 9:23:00 PM UTC with a value of 31841.1399 milliseconds. We also noted a spike in Request Count(s) from 9:23:00 PM UTC to around 9:39:00 PM UTC with an average value of 105.5 for the said period. We also had a spike in Estimated ALB Active Connection Count at 9:23:00 PM UTC with a value of 94.Thank you.","Hello SpendHQ Team, This is to inform you that we received a site down alert on URL: https://preview.spendhq.com/login. The downtime lasted for 1 minute and eventually got recovered within 1 minute. We are analyzing this and will get back to you with further details on the issue. Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DpNJJ,Cloud Engineer Level 1,Closed,1066789,Incident,07-07-2017 17:12,,"Today's evening call, Praveen updated to close this case. Hence closing this case.###Next Action:Evening Shift. Check whether we are receiving any reply from customer else send reminder###Oh ok. Just making sure because I was trying to start the supervisor jobs. All good then if you got it Matthew. Thanks! Allen Herrera | Developer | SpendHQ®###Matthew WattsI revoked everyone's access. Let's discuss in the morning. Sent from my iPhone###It appears I don’t have sudo access anymore on the production web server. I’m running sudo supervisorctlAnd get the message‘aherrera is not in the sudoers file.  This incident will be reported.’ I had sudo access on this box earlier today. Rean can you confirm the ip of the boxes you touched? Allen Herrera | Developer | SpendHQ®###Hello Allen,We have completed the maintenance and was able to sudo into the machine successfully. Please start the services in the instance and let us know if you have any queries.Note: Going forward please edit the sudoers file using visudo command so that we will be notified if there is an error while saving the configuration post editing.###The restart scheduled on today 7:30 AM IST hours. Praveen sent out a calendar invite. After restart update with Aleen so that he can enable the applications.###Matthew updated,We cannot restart during business hours. Delay this until I'm back.###Praveen has reply,Hello Allen, When the sudoers file is corrupted the only way to fix this issue is: stop the instance, attach the root volume some other instance, correct the file, reattach to the machine and start it.  We need to wait until you give us a maintenance window of 20 mins to perform this activity. Regards,-Praveen###Allen Herrera has reply,Also I was told to make it clear, Do Not Restart That Server As it also has our production Redis DB on it. Which will bring our main app down if it fails###Hello Allen,We are checking on this and let you know the update","---------- Forwarded message ----------From: Allen Herrera <aherrera@insightsourcing.com>Date: Wed, Jul 5, 2017 at 9:55 PMSubject: DB2 downTo: REAN Managed Services <ms@reancloud.com>, Spendhq Support <spendhq-support@reancloud.com>, Matthew Watts <mwatts@spendhq.com>, DustyFowler <dfowler@spendhq.com>Hey our Mysql instance on DB2 (10.59.10.12) is down.I attempting to resolve the issue we tried giving sudo access to dmackeybut messed up the syntax in the sudoers file. Now none of us can edit thefile since no one has root access.Do you have access as root to edit the /etc/sudoers file. If so could youmake dmackey/dfowler a sudoer.*Allen Herrera* | Developer | *Spend**HQ®*M: 360-888-3938 | aherrera@spendhq.comwww.spendhq.com | *A SaaS Spend Visibility solution from Insight SourcingGroup*-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: DB2 down,,05-07-2017 22:03,43,0,SpendHQ,"Today's evening call, Praveen updated to close this case. Hence closing this case.",Next Action:Evening Shift. Check whether we are receiving any reply from customer else send reminder,Oh ok. Just making sure because I was trying to start the supervisor jobs. All good then if you got it Matthew. Thanks! Allen Herrera | Developer | SpendHQ®,Matthew WattsI revoked everyone's access. Let's discuss in the morning. Sent from my iPhone,It appears I don’t have sudo access anymore on the production web server. I’m running sudo supervisorctlAnd get the message‘aherrera is not in the sudoers file.  This incident will be reported.’ I had sudo access on this box earlier today. Rean can you confirm the ip of the boxes you touched? Allen Herrera | Developer | SpendHQ®,"Hello Allen,We have completed the maintenance and was able to sudo into the machine successfully. Please start the services in the instance and let us know if you have any queries.Note: Going forward please edit the sudoers file using visudo command so that we will be notified if there is an error while saving the configuration post editing.",The restart scheduled on today 7:30 AM IST hours. Praveen sent out a calendar invite. After restart update with Aleen so that he can enable the applications.,"Matthew updated,We cannot restart during business hours. Delay this until I'm back.","Praveen has reply,Hello Allen, When the sudoers file is corrupted the only way to fix this issue is: stop the instance, attach the root volume some other instance, correct the file, reattach to the machine and start it.  We need to wait until you give us a maintenance window of 20 mins to perform this activity. Regards,-Praveen","Allen Herrera has reply,Also I was told to make it clear, Do Not Restart That Server As it also has our production Redis DB on it. Which will bring our main app down if it fails","Hello Allen,We are checking on this and let you know the update",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FeWFJ,Cloud Engineer Level 2,Closed,1073446,Incident,18-08-2017 08:24,,"Hello SpendHQ-Team,We haven't heard back from you regarding this case.As of now, we are marking this case as resolved. Kindly validate these details from your end and revert back in case of any further queries.Regards,Sumod.K.Bose###Hello SpendHQ-Team,Do we have any updates on this case?The outage happened for the URL https://preview.spendhq.com/login was due to increase in the unhealthy instances behind the NewPreview-ELB. From cloud trail logs, we were able to figure out that the IAM user MWatts has changed the ELB health check to HTTPS:443/login which caused this outage. To resolve this scenario, we have modified this value from HTTPS:443/login to TCP:80 that resolved the issue. Refer the CloudTrail API Call details of this activity,{ eventVersion: 1.04, userIdentity: { type: IAMUser, principalId: AIDAJSEENI7RP2ECZY3IO, arn: arn:aws:iam::261234435984:user/MWatts, accountId: 261234435984, accessKeyId: ASIAJWXLJG5HYQT3ZRTA, userName: MWatts, sessionContext: { attributes: { mfaAuthenticated: false, creationDate: 2017-08-16T17:15:42Z } }, invokedBy: signin.amazonaws.com }, eventTime: 2017-08-16T18:37:35Z, eventSource: elasticloadbalancing.amazonaws.com, eventName: ConfigureHealthCheck, awsRegion: us-east-1, sourceIPAddress: 74.115.22.44, userAgent: signin.amazonaws.com, requestParameters: { healthCheck: { target: HTTPS:443/login, interval: 10, timeout: 5, unhealthyThreshold: 2, healthyThreshold: 5 }, loadBalancerName: NewPreview-ELB }, responseElements: { healthCheck: { target: HTTPS:443/login, interval: 10, timeout: 5, unhealthyThreshold: 2, healthyThreshold: 5 } }, requestID: f8f668e8-82b1-11e7-a491-1b30001e375a, eventID: 8d6001c4-9a8a-426c-9298-922c6ec3a9fa, eventType: AwsApiCall, apiVersion: 2012-06-01, recipientAccountId: 261234435984 }We kindly request your team to inform us before making any changes that may result in an outage for the resources. So that, we will be able to avoid this kind of scenarios in future. Kindly validate these details and let us know if your team have any further queries regarding this outage.Regards,Sumod.K.Bose###Next Action: Morning Shift: Inform these details with Yogesh and send the reminder in the evening shift.###yesterday also we got a site down and We have verified from cloud trail that the Matthew made changes to ELB health check to HTTPS:443/login. We have modified this value to TCP:80 that resolved the issue.###On checking the cloudtrail{    eventVersion: 1.04,    userIdentity: {        type: IAMUser,        principalId: AIDAJSEENI7RP2ECZY3IO,        arn: arn:aws:iam::261234435984:user/MWatts,        accountId: 261234435984,        accessKeyId: ASIAJWXLJG5HYQT3ZRTA,        userName: MWatts,        sessionContext: {            attributes: {                mfaAuthenticated: false,                creationDate: 2017-08-16T17:15:42Z            }        },        invokedBy: signin.amazonaws.com    },    eventTime: 2017-08-16T18:37:35Z,    eventSource: elasticloadbalancing.amazonaws.com,    eventName: ConfigureHealthCheck,    awsRegion: us-east-1,    sourceIPAddress: 74.115.22.44,    userAgent: signin.amazonaws.com,    requestParameters: {        healthCheck: {            target: HTTPS:443/login,            interval: 10,            timeout: 5,            unhealthyThreshold: 2,            healthyThreshold: 5        },        loadBalancerName: NewPreview-ELB    },    responseElements: {        healthCheck: {            target: HTTPS:443/login,            interval: 10,            timeout: 5,            unhealthyThreshold: 2,            healthyThreshold: 5        }    },    requestID: f8f668e8-82b1-11e7-a491-1b30001e375a,    eventID: 8d6001c4-9a8a-426c-9298-922c6ec3a9fa,    eventType: AwsApiCall,    apiVersion: 2012-06-01,    recipientAccountId: 261234435984}###Hello SpendHQ Team,This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. While checking we could see that the 2 instance behind the ELB was out of service. We have verified from cloud trail that the Matthew made changes to ELB health check to HTTPS:443/login. We have modified this value to TCP:80 that resolved the issue.Please confirm this from your end and let us know if you are performing any activity.###Yogesh discussed on bi-weekly call and asked Matthew to check the version control for latest code changes, Matthew informed they will be analyzing it.Next Action: Evening Shift: Send a reminder to the customer in the case of no response.###Followed up with Yogesh for the update but no response yet.Next Action: Morning Shift: Check with Yogesh for the status.###We were able to access the machines during the time and no files were deleted. Matthew Watts###Sent an email to SpendHQ team:Hi Team,Can you please check if there was any latest code push/pull was done recently on these preview servers. We assume that index.html file was being removed from the code base recently which caused this ELB health check failure.Please check internally and let us know the update.###Yogesh updated on morning ops call that he will look further on this.###We have checked the http access log and could see the below entry10.59.100.97 - - [15/Aug/2017:18:48:51 +0000] GET /index.html HTTP/1.1 200 37475 - ELB-HealthChecker/1.010.59.101.149 - - [15/Aug/2017:18:49:00 +0000] GET /index.html HTTP/1.1 200 37475 - ELB-HealthChecker/1.010.59.100.97 - - [15/Aug/2017:18:49:01 +0000] GET /index.html HTTP/1.1 200 37475 - ELB-HealthChecker/1.010.59.101.149 - - [15/Aug/2017:18:49:04 +0000] GET /index.html HTTP/1.1 404 33369 - ELB-HealthChecker/1.010.59.101.149 - - [15/Aug/2017:18:49:10 +0000] GET /index.html HTTP/1.1 404 33369 - ELB-HealthChecker/1.010.59.100.97 - - [15/Aug/2017:18:49:11 +0000] GET /index.html HTTP/1.1 404 33369 - ELB-HealthChecker/1.0We have also checked the bash history of each user which was accessed today for getting if anyone has removed the index.html file, but couldn't find any.Need to investigate further.###Allen Herrera2:42 AM (1 hour ago)to Matthew, me, Dusty, REAN I didn’t do any maintenance today either###Matthew Watts2:10 AM (1 minute ago)to me, Allen, Dusty, REAN We made no changes and both of those machines were accessible inside the VPN. Please research this further.###Matthew Watts1:14 AM (57 minutes ago)to me, Allen, Rean, Dusty This has been resolved. What was the issue.###Hello Matthew,While checking, We could see that the two instance behind the NewPreview-ELB went out of service. We have checked the Health Check configuration on ELB level and found that it was set to HTTP:80/index.html. Please find the screenshot below.​We have checked and verified that the index.html page was not present that causes the ELB health check failure. Because of this the instances behind the ELB went out of service and  ELB stops serving the request. So we have modified the health check configuration to TCP:80 that resolved this issue. Please let us know if you have made any changes in the instance level.###Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. The site is still down and we are unable to access the website. We are currently analyzing this issue and will get back to you with further updates. Meanwhile please let us know if your team is performing any activity from your end which has caused this outage.","Tue, 15 Aug 2017 14:51:04 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): London UK, Atlanta-B US, Frankfurt DE, Dallas-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,16-08-2017 00:21,56,0,SpendHQ,"Hello SpendHQ-Team,We haven't heard back from you regarding this case.As of now, we are marking this case as resolved. Kindly validate these details from your end and revert back in case of any further queries.Regards,Sumod.K.Bose","Hello SpendHQ-Team,Do we have any updates on this case?The outage happened for the URL https://preview.spendhq.com/login was due to increase in the unhealthy instances behind the NewPreview-ELB. From cloud trail logs, we were able to figure out that the IAM user MWatts has changed the ELB health check to HTTPS:443/login which caused this outage. To resolve this scenario, we have modified this value from HTTPS:443/login to TCP:80 that resolved the issue. Refer the CloudTrail API Call details of this activity,{ eventVersion: 1.04, userIdentity: { type: IAMUser, principalId: AIDAJSEENI7RP2ECZY3IO, arn: arn:aws:iam::261234435984:user/MWatts, accountId: 261234435984, accessKeyId: ASIAJWXLJG5HYQT3ZRTA, userName: MWatts, sessionContext: { attributes: { mfaAuthenticated: false, creationDate: 2017-08-16T17:15:42Z } }, invokedBy: signin.amazonaws.com }, eventTime: 2017-08-16T18:37:35Z, eventSource: elasticloadbalancing.amazonaws.com, eventName: ConfigureHealthCheck, awsRegion: us-east-1, sourceIPAddress: 74.115.22.44, userAgent: signin.amazonaws.com, requestParameters: { healthCheck: { target: HTTPS:443/login, interval: 10, timeout: 5, unhealthyThreshold: 2, healthyThreshold: 5 }, loadBalancerName: NewPreview-ELB }, responseElements: { healthCheck: { target: HTTPS:443/login, interval: 10, timeout: 5, unhealthyThreshold: 2, healthyThreshold: 5 } }, requestID: f8f668e8-82b1-11e7-a491-1b30001e375a, eventID: 8d6001c4-9a8a-426c-9298-922c6ec3a9fa, eventType: AwsApiCall, apiVersion: 2012-06-01, recipientAccountId: 261234435984 }We kindly request your team to inform us before making any changes that may result in an outage for the resources. So that, we will be able to avoid this kind of scenarios in future. Kindly validate these details and let us know if your team have any further queries regarding this outage.Regards,Sumod.K.Bose",Next Action: Morning Shift: Inform these details with Yogesh and send the reminder in the evening shift.,yesterday also we got a site down and We have verified from cloud trail that the Matthew made changes to ELB health check to HTTPS:443/login. We have modified this value to TCP:80 that resolved the issue.,"On checking the cloudtrail{    eventVersion: 1.04,    userIdentity: {        type: IAMUser,        principalId: AIDAJSEENI7RP2ECZY3IO,        arn: arn:aws:iam::261234435984:user/MWatts,        accountId: 261234435984,        accessKeyId: ASIAJWXLJG5HYQT3ZRTA,        userName: MWatts,        sessionContext: {            attributes: {                mfaAuthenticated: false,                creationDate: 2017-08-16T17:15:42Z            }        },        invokedBy: signin.amazonaws.com    },    eventTime: 2017-08-16T18:37:35Z,    eventSource: elasticloadbalancing.amazonaws.com,    eventName: ConfigureHealthCheck,    awsRegion: us-east-1,    sourceIPAddress: 74.115.22.44,    userAgent: signin.amazonaws.com,    requestParameters: {        healthCheck: {            target: HTTPS:443/login,            interval: 10,            timeout: 5,            unhealthyThreshold: 2,            healthyThreshold: 5        },        loadBalancerName: NewPreview-ELB    },    responseElements: {        healthCheck: {            target: HTTPS:443/login,            interval: 10,            timeout: 5,            unhealthyThreshold: 2,            healthyThreshold: 5        }    },    requestID: f8f668e8-82b1-11e7-a491-1b30001e375a,    eventID: 8d6001c4-9a8a-426c-9298-922c6ec3a9fa,    eventType: AwsApiCall,    apiVersion: 2012-06-01,    recipientAccountId: 261234435984}","Hello SpendHQ Team,This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. While checking we could see that the 2 instance behind the ELB was out of service. We have verified from cloud trail that the Matthew made changes to ELB health check to HTTPS:443/login. We have modified this value to TCP:80 that resolved the issue.Please confirm this from your end and let us know if you are performing any activity.","Yogesh discussed on bi-weekly call and asked Matthew to check the version control for latest code changes, Matthew informed they will be analyzing it.Next Action: Evening Shift: Send a reminder to the customer in the case of no response.",Followed up with Yogesh for the update but no response yet.Next Action: Morning Shift: Check with Yogesh for the status.,We were able to access the machines during the time and no files were deleted. Matthew Watts,"Sent an email to SpendHQ team:Hi Team,Can you please check if there was any latest code push/pull was done recently on these preview servers. We assume that index.html file was being removed from the code base recently which caused this ELB health check failure.Please check internally and let us know the update.",Yogesh updated on morning ops call that he will look further on this.,"We have checked the http access log and could see the below entry10.59.100.97 - - [15/Aug/2017:18:48:51 +0000] GET /index.html HTTP/1.1 200 37475 - ELB-HealthChecker/1.010.59.101.149 - - [15/Aug/2017:18:49:00 +0000] GET /index.html HTTP/1.1 200 37475 - ELB-HealthChecker/1.010.59.100.97 - - [15/Aug/2017:18:49:01 +0000] GET /index.html HTTP/1.1 200 37475 - ELB-HealthChecker/1.010.59.101.149 - - [15/Aug/2017:18:49:04 +0000] GET /index.html HTTP/1.1 404 33369 - ELB-HealthChecker/1.010.59.101.149 - - [15/Aug/2017:18:49:10 +0000] GET /index.html HTTP/1.1 404 33369 - ELB-HealthChecker/1.010.59.100.97 - - [15/Aug/2017:18:49:11 +0000] GET /index.html HTTP/1.1 404 33369 - ELB-HealthChecker/1.0We have also checked the bash history of each user which was accessed today for getting if anyone has removed the index.html file, but couldn't find any.Need to investigate further.","Allen Herrera2:42 AM (1 hour ago)to Matthew, me, Dusty, REAN I didn’t do any maintenance today either","Matthew Watts2:10 AM (1 minute ago)to me, Allen, Dusty, REAN We made no changes and both of those machines were accessible inside the VPN. Please research this further.","Matthew Watts1:14 AM (57 minutes ago)to me, Allen, Rean, Dusty This has been resolved. What was the issue.","Hello Matthew,While checking, We could see that the two instance behind the NewPreview-ELB went out of service. We have checked the Health Check configuration on ELB level and found that it was set to HTTP:80/index.html. Please find the screenshot below.​We have checked and verified that the index.html page was not present that causes the ELB health check failure. Because of this the instances behind the ELB went out of service and  ELB stops serving the request. So we have modified the health check configuration to TCP:80 that resolved this issue. Please let us know if you have made any changes in the instance level.","Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. The site is still down and we are unable to access the website. We are currently analyzing this issue and will get back to you with further updates. Meanwhile please let us know if your team is performing any activity from your end which has caused this outage.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001dfI09,Cloud Engineer Level 1,Closed,1106889,Incident,30-10-2018 07:36,,"Hello Kristen,Thanks for the updateWe are marking this case as resolved. Please let us know in case of any issues on this case.###Kristen Stretch12:50 AM (6 hours ago)to me, Matthew, ms@reancloud.comI am able to reach the dashboard now, thanks!###Hello Kristen,We have whitelisted port 8080 in the security group of JENKINS_MASTER instance. Later, we are able to see the Jenkins dashboard. Please check from your end and let us know if the issue still persists.###Hello Kristen,We are checking this issue and will let you know the updates.","Hi,I am having trouble connecting to the Jenkins dashboard after the installation on the server, Server Details:Instance Name: JENKINS_MASTERInstance ID : i-079130613ab17ad30Private IP: 10.59.100.188Could you tell me if there is a security restriction that is keeping me from being able to access http://10.59.100.188:8080/ ? Is port 8080 already in use? Do we need to add a  custom tcp rule? Firewall? I cannot see the dashboard so I am unable to trouble shoot...Please let me know if there are any security groups preventing access to the dashboard so that I can finish the set-up.Thanks,-Kristen Stretch--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Jenkins server security groups? Blocked.,,29-10-2018 22:31,9,0,SpendHQ,"Hello Kristen,Thanks for the updateWe are marking this case as resolved. Please let us know in case of any issues on this case.","Kristen Stretch12:50 AM (6 hours ago)to me, Matthew, ms@reancloud.comI am able to reach the dashboard now, thanks!","Hello Kristen,We have whitelisted port 8080 in the security group of JENKINS_MASTER instance. Later, we are able to see the Jenkins dashboard. Please check from your end and let us know if the issue still persists.","Hello Kristen,We are checking this issue and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hRF8a,Cloud Engineer Level 1,Closed,1110219,Incident,04-01-2019 02:57,,"Hello Dan,Thanks for the Update. We are marking this case as closed.###Rean, The database is currently offline. You can ignore the monitors. Best Regards,","Rean,The database is currently offline. You can ignore the monitors.Best Regards,Dan Mackay | Spend Solutions DBA | SpendHQO: 770-741-0157 | dmackay@spendhq.com<mailto:dmackay@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Database Offline,,04-01-2019 02:52,0,0,SpendHQ,"Hello Dan,Thanks for the Update. We are marking this case as closed.","Rean, The database is currently offline. You can ignore the monitors. Best Regards,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001i9KmA,Cloud Engineer Level 1,Closed,1111115,Incident,06-02-2019 22:43,,"Hello Mathew,As the alert is still in open state for a while and the disk has a capacity of 8TB and only 6.2 TB is in use, we have just changed the Alert threshold to 90% to resolve the alert.The current Disk utilization is 87%. Kindly check with that from your side.As of now, we don't have any action item pending on this case We are marking this case as closed. Let us know if you have any queries.Thanks###Hello Matthew, This is a follow up on the alert EBS High Disk Usage on sphq-db3-20180830 - 10.59.10.235. The current disk usage is 87%. Please look into the issue and let us know if you need any assistance on the same.###Hello Matthew,This is a follow up on the alert  EBS High Disk Usage on  sphq-db3-20180830 - 10.59.10.235.The current disk usage is 86.6%. Please look into the issue and let us know if you need any assistance on the same.###Hello Matthew,We Haven't received any update from you.The current disk usage is 84.3%. Please have a look into the issue and please delete or zip the unused files###Hello Matthew,Thanks for the update,We are looking forward for further updates from you on this.Thanks###Thank you, we will look into this.Get Outlook for iOS###Hello Team This is a quick followup, The alert is still in open state with the value of 83.6% of Disk usage. kindly check with the detailed analysis shared with you on the previous comment and delete or zip the unused files to resolve this alert. Let us know if you have any queries. Thanks###Hello Team The alert is triggered by the ISCSI volumes and is still open state. Kindly look into this on priority and delete and/or zip files to free up space.Thanks###@Team:Its iSCSI Volume and taken care by SpendHQ team only.Ask them to take care of this.###Hello Team, This is a gentle reminder that the alert is still in open state with the value of 87.3%. Please zip/delete for unnecessary files or directories to reduce the disk storage. Thanks###Hello Team, This is a gentle reminder that the alert is still in open state with the value of 86.2%. Please zip/delete for unnecessary files or directories to reduce the disk storage.Thanks###Hello Team,This is a gentle reminder that the alert is still in open state with the value of 83.9% and perform zip/delete for unnecessary files or directories.Thanks###Hello Team,This is a quick follow up. The alerts regarding EBS High Disk usage for /usr/local/mariadb is still open state with a value 83.5%.please check the usage details we shared in the previous mail. and let us know you update.Regards###@TeamThe alert is still in open state with a value of 82.2%###Hello Team, This is to inform you that we received an alert for EBS High Disk Usage for the host in production. On checking the details we can see that /usr/local/MariaDB Consuming the high usage. below are the details [root@ip-10-59-10-235 ~]# df -ThFilesystem     Type      Size  Used Avail Use% Mounted on/dev/nvme0n1p1 xfs       100G  2.8G   98G   3% /devtmpfs       devtmpfs   63G     0   63G   0% /devtmpfs          tmpfs      63G   51M   63G   1% /dev/shmtmpfs          tmpfs      63G  193M   62G   1% /runtmpfs          tmpfs      63G     0   63G   0% /sys/fs/cgroup/dev/sda       ext4      8.0T  6.2T  1.4T  82% /usr/local/mariadbtmpfs          tmpfs      13G     0   13G   0% /run/user/0tmpfs          tmpfs      13G     0   13G   0% /run/user/1000[root@ip-10-59-10-235 ~]# ** /dev/sda       ext4      8.0T  6.2T  1.4T  82% /usr/local/mariadb **6.2T	total1.4T	/usr/local/mariadb/columnstore/data3/000.dir/009.dir1.3T	/usr/local/mariadb/columnstore/data3/000.dir/007.dir1.3T	/usr/local/mariadb/columnstore/data3/000.dir/006.dir1.2T	/usr/local/mariadb/columnstore/data3/000.dir/010.dir922G	/usr/local/mariadb/columnstore/data3/000.dir/008.dir288G	/usr/local/mariadb/columnstore/data3/000.dir/011.dir64G	/usr/local/mariadb/columnstore/data3/000.dir/006.dir/035.dir27G	/usr/local/mariadb/columnstore/data3/000.dir/006.dir/034.dir25G	/usr/local/mariadb/columnstore/data3/000.dir/006.dir/032.dir13G	/usr/local/mariadb/columnstore/data3/000.dir/011.dir/050.dir13G	/usr/local/mariadb/columnstore/data3/000.dir/007.dir/090.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/011.dir/059.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/228.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/209.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/161.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/159.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/059.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/055.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/038.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/036.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/249.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/224.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/213.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/175.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/173.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/168.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/148.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/146.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/109.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/104.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/088.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/007.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/008.dir/221.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/008.dir/179.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/008.dir/082.dirPlease check these details and let us know your update.Resources DetailsIp: 10.59.10.235Instance ID:i-0e76e98abf08a1b70Name:SPHQ-DB3-20180830###Hello Team,This is to bring to your attention that the disk on SPHQ-DB3-20180830 is currently at 80.27% full, we are currently investigating the issue and we'll get back to you with detailed information.Resource detailsInstance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Region	us-east-1Private IP Address	10.59.10.235","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sda ) -sphq-db3-20180830 - 10.59.10.235High Disk Usage detected on the device /dev/sda@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1548338139000&group=device%3A%2Fdev%2Fsda%2Chost%3Ai-0e76e98abf08a1b70&from_ts=1548334539000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc}by {host,device} * 100 > 80The monitor was last triggered at Thu Jan 24 2019 13:55:49 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fsda%2Chost%3Ai-0e76e98abf08a1b70>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [Viewi-0e76e98abf08a1b70<https://app.datadoghq.com/infrastructure?filter=i-0e76e98abf08a1b70>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1548338269000&tags=host%3Ai-0e76e98abf08a1b70&from_ts=1548337249000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4765992439509495137>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db3-20180830 - 10.59.10.235,,24-01-2019 19:29,315,0,SpendHQ,"Hello Mathew,As the alert is still in open state for a while and the disk has a capacity of 8TB and only 6.2 TB is in use, we have just changed the Alert threshold to 90% to resolve the alert.The current Disk utilization is 87%. Kindly check with that from your side.As of now, we don't have any action item pending on this case We are marking this case as closed. Let us know if you have any queries.Thanks","Hello Matthew, This is a follow up on the alert EBS High Disk Usage on sphq-db3-20180830 - 10.59.10.235. The current disk usage is 87%. Please look into the issue and let us know if you need any assistance on the same.","Hello Matthew,This is a follow up on the alert  EBS High Disk Usage on  sphq-db3-20180830 - 10.59.10.235.The current disk usage is 86.6%. Please look into the issue and let us know if you need any assistance on the same.","Hello Matthew,We Haven't received any update from you.The current disk usage is 84.3%. Please have a look into the issue and please delete or zip the unused files","Hello Matthew,Thanks for the update,We are looking forward for further updates from you on this.Thanks","Thank you, we will look into this.Get Outlook for iOS","Hello Team This is a quick followup, The alert is still in open state with the value of 83.6% of Disk usage. kindly check with the detailed analysis shared with you on the previous comment and delete or zip the unused files to resolve this alert. Let us know if you have any queries. Thanks",Hello Team The alert is triggered by the ISCSI volumes and is still open state. Kindly look into this on priority and delete and/or zip files to free up space.Thanks,@Team:Its iSCSI Volume and taken care by SpendHQ team only.Ask them to take care of this.,"Hello Team, This is a gentle reminder that the alert is still in open state with the value of 87.3%. Please zip/delete for unnecessary files or directories to reduce the disk storage. Thanks","Hello Team, This is a gentle reminder that the alert is still in open state with the value of 86.2%. Please zip/delete for unnecessary files or directories to reduce the disk storage.Thanks","Hello Team,This is a gentle reminder that the alert is still in open state with the value of 83.9% and perform zip/delete for unnecessary files or directories.Thanks","Hello Team,This is a quick follow up. The alerts regarding EBS High Disk usage for /usr/local/mariadb is still open state with a value 83.5%.please check the usage details we shared in the previous mail. and let us know you update.Regards",@TeamThe alert is still in open state with a value of 82.2%,"Hello Team, This is to inform you that we received an alert for EBS High Disk Usage for the host in production. On checking the details we can see that /usr/local/MariaDB Consuming the high usage. below are the details [root@ip-10-59-10-235 ~]# df -ThFilesystem     Type      Size  Used Avail Use% Mounted on/dev/nvme0n1p1 xfs       100G  2.8G   98G   3% /devtmpfs       devtmpfs   63G     0   63G   0% /devtmpfs          tmpfs      63G   51M   63G   1% /dev/shmtmpfs          tmpfs      63G  193M   62G   1% /runtmpfs          tmpfs      63G     0   63G   0% /sys/fs/cgroup/dev/sda       ext4      8.0T  6.2T  1.4T  82% /usr/local/mariadbtmpfs          tmpfs      13G     0   13G   0% /run/user/0tmpfs          tmpfs      13G     0   13G   0% /run/user/1000[root@ip-10-59-10-235 ~]# ** /dev/sda       ext4      8.0T  6.2T  1.4T  82% /usr/local/mariadb **6.2T	total1.4T	/usr/local/mariadb/columnstore/data3/000.dir/009.dir1.3T	/usr/local/mariadb/columnstore/data3/000.dir/007.dir1.3T	/usr/local/mariadb/columnstore/data3/000.dir/006.dir1.2T	/usr/local/mariadb/columnstore/data3/000.dir/010.dir922G	/usr/local/mariadb/columnstore/data3/000.dir/008.dir288G	/usr/local/mariadb/columnstore/data3/000.dir/011.dir64G	/usr/local/mariadb/columnstore/data3/000.dir/006.dir/035.dir27G	/usr/local/mariadb/columnstore/data3/000.dir/006.dir/034.dir25G	/usr/local/mariadb/columnstore/data3/000.dir/006.dir/032.dir13G	/usr/local/mariadb/columnstore/data3/000.dir/011.dir/050.dir13G	/usr/local/mariadb/columnstore/data3/000.dir/007.dir/090.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/011.dir/059.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/228.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/209.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/161.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/159.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/059.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/055.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/038.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/010.dir/036.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/249.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/224.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/213.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/175.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/173.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/168.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/148.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/146.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/109.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/104.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/088.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/009.dir/007.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/008.dir/221.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/008.dir/179.dir12G	/usr/local/mariadb/columnstore/data3/000.dir/008.dir/082.dirPlease check these details and let us know your update.Resources DetailsIp: 10.59.10.235Instance ID:i-0e76e98abf08a1b70Name:SPHQ-DB3-20180830","Hello Team,This is to bring to your attention that the disk on SPHQ-DB3-20180830 is currently at 80.27% full, we are currently investigating the issue and we'll get back to you with detailed information.Resource detailsInstance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Region	us-east-1Private IP Address	10.59.10.235",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VqbYk,Cloud Engineer Level 1,Closed,1098001,Incident,04-05-2018 03:06,,"Hello Allen,We are looking into this issue and will let you know the updates.###Hi Allen,The ISCSI Volumes are not mounted permanently as this device name changes everytime we reboot the machine. Therefore, we cannot make a fstab entry for the same which also create the issue when we reboot it. The ISCSI volumes needs to be mounted manually whenever the reboot happens as it get unmounted. We are working on resolving the mount issue of ISCSI volumes. For now, we have re-mounted the ISCSI volumes again to the folders /usr/local/mariadb and /mnt/mysqldumps. Please verify the data and let us know if you have any issue in accessing the same. Thanks !Regards,Rohit Puri","ReanWhy did this happen again.I rebooted the server 10.59.10.180 and both my 4TB mounts are missing.Please remount this ASAP and permanently resolve this issue.For starters I see in the fstab the mounts are commented out.*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com--  <http://go.reancloud.com/gartner-magic-quadrant>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Mounts Missing,,04-05-2018 03:05,0,0,SpendHQ,"Hello Allen,We are looking into this issue and will let you know the updates.","Hi Allen,The ISCSI Volumes are not mounted permanently as this device name changes everytime we reboot the machine. Therefore, we cannot make a fstab entry for the same which also create the issue when we reboot it. The ISCSI volumes needs to be mounted manually whenever the reboot happens as it get unmounted. We are working on resolving the mount issue of ISCSI volumes. For now, we have re-mounted the ISCSI volumes again to the folders /usr/local/mariadb and /mnt/mysqldumps. Please verify the data and let us know if you have any issue in accessing the same. Thanks !Regards,Rohit Puri",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d1hdB,Cloud Engineer Level 1,Closed,1106143,Incident,12-10-2018 06:40,,"Hello Team,We haven't heard back from you regarding this case in a while. Please look into our previously shared analysis and get back to us if you need any more clarifications.As the issue got resolved, we are currently marking the case resolved and hence closing the case.Please reach out to us for continued support.Thanks.###Team ,Please close this case at the end of your shift if there is no response###Hello Team,This is a follow up on the analysis we shared earlier on this issue.Please review and let us know your thoughts on the same.###Hello Team, The site down alert for the URL:https://secure.spendhq.com/login  got resolved and Estimated Downtime was 5 minute. As mentioned in the previous comment we checked all the metrics from AWS and found the sudden spike in ELB Latency. From the instance level, there is no suspicious activity during the time of the alert. As this alert was triggered because of latency and the backend server was unable to handle the request within time. And after a minute backend server started working fine and the site got recovered.Kindly validate the logs in the attachment.Thank you###Hello Team, The site down alert for the URL:https://secure.spendhq.com/login While checking the backend ELB, Instance, we found the below details. 1. From the NewPreview-ELB load balancer, we could see Latency was around 634428.3166xx NewPreview-ELB From the Backend Instance PRD-WW2_6, we could see all the metrics are looking normal.We are collecting the logs and update you shortly.Thank you.###Matthew Watts6:58 AM (0 minutes ago)to Rean, spendhq-support@reancloud.comWe were not performing any maintenance. Please provide RCA.Sent from a mobile device.###Hello Team,This is to inform you that we received a site down for  URL: https://secure.spendhq.com/login  and it recovered within 5 minutes. The site up and accessible now. we are analyzing the issue and will get back with an update.Meanwhile please let us know if you are performing any activity Thank you","Wed, 10 Oct 2018 21:16:32 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: Forbidden",Detected Error on SpendHQ Secure,,11-10-2018 06:47,24,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case in a while. Please look into our previously shared analysis and get back to us if you need any more clarifications.As the issue got resolved, we are currently marking the case resolved and hence closing the case.Please reach out to us for continued support.Thanks.","Team ,Please close this case at the end of your shift if there is no response","Hello Team,This is a follow up on the analysis we shared earlier on this issue.Please review and let us know your thoughts on the same.","Hello Team, The site down alert for the URL:https://secure.spendhq.com/login  got resolved and Estimated Downtime was 5 minute. As mentioned in the previous comment we checked all the metrics from AWS and found the sudden spike in ELB Latency. From the instance level, there is no suspicious activity during the time of the alert. As this alert was triggered because of latency and the backend server was unable to handle the request within time. And after a minute backend server started working fine and the site got recovered.Kindly validate the logs in the attachment.Thank you","Hello Team, The site down alert for the URL:https://secure.spendhq.com/login While checking the backend ELB, Instance, we found the below details. 1. From the NewPreview-ELB load balancer, we could see Latency was around 634428.3166xx NewPreview-ELB From the Backend Instance PRD-WW2_6, we could see all the metrics are looking normal.We are collecting the logs and update you shortly.Thank you.","Matthew Watts6:58 AM (0 minutes ago)to Rean, spendhq-support@reancloud.comWe were not performing any maintenance. Please provide RCA.Sent from a mobile device.","Hello Team,This is to inform you that we received a site down for  URL: https://secure.spendhq.com/login  and it recovered within 5 minutes. The site up and accessible now. we are analyzing the issue and will get back with an update.Meanwhile please let us know if you are performing any activity Thank you",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gbqzw,Cloud Engineer Level 1,Closed,1109523,Incident,15-12-2018 10:02,,we already have a ticket for this so closing this.case link: https://reancloud.cloudforce.com/5002I00001gbanL,"Rean,Has any activity on these servers happened in the last couple of hours?Get Outlook for iOS<https://aka.ms/o0ukef>-- \\-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",On boarding,,15-12-2018 07:36,2,0,SpendHQ,we already have a ticket for this so closing this.case link: https://reancloud.cloudforce.com/5002I00001gbanL,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001b2Oqf,Cloud Engineer Level 1,Closed,1104232,Incident,08-09-2018 05:51,,"Hello Allen,Thanks for the update.At this time we are marking the case as closed and please revert back to us in case of further queries.###Thank you ! the server is back online Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###Hello Allen,The machine 10.59.10.82 is accessible from our end.Could you please let us know is the issue is resolved on your end.Thanks & Regards,Anjali G Nair###REAN, Could we please prioritize this. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting###Hello Mathew,We are working on it and will get back to you with more details.Stephen Kimani###Hello Allen,We acknowledge the delivery of your email.We will look into the issue and will get back to you with an update.","From: Allen Herrera <aherrera@spendhq.com>Date: Sat, Sep 8, 2018 at 1:49 AMSubject: 10.59.10.82 won't restartTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Hey rean,I issued a reboot to 10.59.10.82 and its not coming back online. Pleasecorrect this issue and investigate why. We need this by Monday.*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: 10.59.10.82 won't restart,,08-09-2018 02:02,4,0,SpendHQ,"Hello Allen,Thanks for the update.At this time we are marking the case as closed and please revert back to us in case of further queries.",Thank you ! the server is back online Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com,"Hello Allen,The machine 10.59.10.82 is accessible from our end.Could you please let us know is the issue is resolved on your end.Thanks & Regards,Anjali G Nair","REAN, Could we please prioritize this. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting","Hello Mathew,We are working on it and will get back to you with more details.Stephen Kimani","Hello Allen,We acknowledge the delivery of your email.We will look into the issue and will get back to you with an update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013uxPn,Cloud Engineer Level 1,Closed,1030237,Incident,10-11-2016 04:01,,"Hello Team, Please ignore this alert because one of our Rean Team member was trying to login.","Failed WebAdmin login attempt from 10.242.2.4 at 2016-11-09 22:28:04 with username admin.        -- System Uptime      : 165 days 16 hours 55 minutesSystem Load        : 0.10System Version     : Sophos UTM 9.403-4Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][WARN-005] Failed WebAdmin login,,10-11-2016 03:58,0,0,SpendHQ,"Hello Team, Please ignore this alert because one of our Rean Team member was trying to login.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013vuWi,Cloud Engineer Level 1,Closed,1030972,Incident,12-11-2016 13:09,,"Team,It was because of maintenance.","System was restartedReason: (unknown)-- System Uptime      : 0 days 0 hours 4 minutesSystem Load        : 1.81System Version     : Sophos UTM 9.403-4Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][INFO-000] System was restarted,,12-11-2016 13:01,0,0,SpendHQ,"Team,It was because of maintenance.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015Yhre,Cloud Engineer Level 1,Closed,1040935,Incident,04-01-2017 15:35,,"As per discussed on internally we are closing the issue here and opened a problem ticket and assigned the ticket to Sudheer for performing more analysis.Ticket Number: 01041814###Hi Team,When we checked we couldn't find multipath config file. So we tried  # multipath -ll command which prints out multipathed paths that show which devices are multipathed.$ sudo multipath -llJan 04 00:58:40 | DM multipath kernel driver not loadedJan 04 00:58:40 | /etc/multipath.conf does not exist, blacklisting all devices.Jan 04 00:58:40 | A sample multipath.conf file is located atJan 04 00:58:40 | /usr/share/doc/device-mapper-multipath-0.4.9/multipath.confJan 04 00:58:40 | You can run /sbin/mpathconf to create or modify /etc/multipath.confJan 04 00:58:40 | DM multipath kernel driver not loadedWe have received this error when listing device that are multipathed which says DM multipath kernel driver not loaded and  /etc/multipath.conf does not exist.###Chris updated that.Hi Everyone,I have been working this with Nimble. We have checked out the Nimble array  and verified there are not any issues with either the storage or the network on our end.The error message suggests that issue is on the host (which makes sense since that where the error log is being generated).There was- and  currently - a broken/re-connection issue associated with this AWS machine.This leads us to believe that it is a multipath config issue.I need REAN review the attached config sheet and verify that the mulitpath.conf file is correct - and verify it is correct for the version of Red Hat that is running.Make Note - NCM is not loaded on the AWS machine.  See the configuration sheet for those minor config details.I will be happy to help out with this as needed - as will Nimble.###Hi Chris,Do you have any update from Nimble Team to see if there are any configurations that might have caused this issue.Please let us know the updates.###Chris was not picking up the phone call, Sent a reminder to Chris for updates.Hi Chris,This is a quick followup,Do we have any update from Nimble Team to see if there are any configurations that might cause this issue?###Chris updated that he will engaging the Nimble Team to see if there are any configurations that might/may cause this occasional issue. This probably will result in a Nimble/REAN call and exchange of ideas. Chris will drive this.###Hello Team,We had a call with Chris yesterday he updated that he had already raised a support ticket with the nimble team and he informed that he will try to get Andromeda, REAN and Nimble Team in a single call to troubleshoot the issue.@Chris: Could you please send an email detailing the  dependency on Nimble Team as we had discussed in yesterday's  call.###We had a call with Chris from Andromeda, he updated that he is also not able to figure out the exact issue so that he already raised a support ticket with nimble team and he informed that he will try to get Andromeda, REAN and Nimble Team in a single call.Chris told that he will  send an email detailing the updates regarding the issue.###We informed Chris with following details and asked his availability to set up a call.Hello Chris,The initiator IQN you have sent is same as that of TEST-SPHQ-WEB-SERVER01(10.59.100.125) instance. Please find the initiator IQN of all DB servers.TEST-SPHQ-WEB-SERVER01(10.59.100.125)    : iqn.1994-05.com.redhat:a7565668c72aDBserver01(10.59.10.137)                 : stoppedDBserver02(10.59.10.12)                  : iqn.1994-05.com.redhat:573c3f4764bDBserver03(10.59.10.148)                 : iqn.1994-05.com.redhat:64d02cf6d2ceDBserver04(10.59.10.91)                  : iqn.1994-05.com.redhat:64d02cf6d2ceDBserver05(10.59.10.135)                 : iqn.1994-05.com.redhat:64d02cf7e3dfPlease let us know your availability to get on a call to discuss following issues.The file system that is mounted to .118 (PRD) became read-only on DEC 23rd. For this issue, we got a reply from AWS support that there is no network outage/direct connect issue from AWS side at that time.  The error messages that we are getting in /var/log/messages on .118 and .135 instances, we have already shared the error logs in CMP.Also, did you get a chance to log on to the account? We have already sent you an invite with your login ID and link to set up your password for REAN ticketing tool.###​Chris askedLooks good - but i want to verify my initiator IQN on my side.Would you send me the IQN of the AWS instance that is running the DB that is mounts SHQ1Files01?It should be     iqn.1994-05.com.redhat:a7565668c72a###Hi SpendHQ,We got a reply from AWS EC2 networking team about their investigation on the Direct connect.AWS Support says that they can not see any networking issue that could be related to this behavior we faced. Also at the specific time, we did not face any issue with the DX connection.Now, we are waiting for Andromeda3 team to check whether there is any issue with the IQN ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31-lun-0 volume mounted on the instance 10.59.100.125.###Mail from AWS.Hello, Just an update. The DX interfaces are up and running for 12w 4d 23h and 7w 3d 16h, respectively. So, at the specific time we did not face any issue with the DX connection. Also checking the instance (i-1426f28b), I can see that you did a stop/start 3 days ago (2016-12-23 15:51:26 GMT). The instance now is running in another underlying hardware. Checking on the hardware that the instance was running before (on the specified time), I can not see any networking issue that could be related to this behavior you faced.I will keep this case locked to me, please let us know if you face this issue again. Have a nice day.Best regards,George F.Amazon Web Services###We have followed-up with AWS on this.We asked: Did we hear back from EC2 networking team on their investigation on the Direct connect?Joel from Support has reached out to someone from Networking and also operation team too and will continue the follow-up and will provide and update.###AWS updated that the EC2 networking team informed that everything looks good such as route propagation from VPC perspective. Everything was OK with the underlying hardware too. From the latest update, the networking team are still conducting further investigation on the Direct connect.###We have asked ChrisThis is a quick follow-up. Please let us know if you get a chance to check whether there is any issue with the IQN ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31-lun-0 volume mounted on the instance 10.59.100.125.###We have updated  Chris thatWe have verified the configuration on 10.59.100.118 and found that the configuration values are same as the values you have sent.Please find the snapshot attached for details.###Chris from Andromeda asked Hi - can we verify that /etc/iscsid.conf is configured as follows:node.session.timeo.replacement_timeout = 10node.conn[0].timeo.noop_out_timeout = 10###Hello Matthew,We have added the cron job and will let you know the further updates.###Hello Matthew,Thanks for the confirmation.We will set the cron job and let you know the updates.###Let's go ahead and do this please. Just keep an eye on the tmpfs as it will quickly fill up. Thank you.###Hello Matthew,To perform further analysis on this issue as per the ticket raised with AWS they informed that packet tracing will provide more information about what could be causing this issue. For this we need to create a script in /tmp with this content (i.e. /tmp/tcp.sh): #!/bin/bash /usr/bin/killall tcpdump /usr/sbin/tcpdump -pni eth0 -s 64 -c 20 -G 10 -w '/tmp/trace_packet.pcap%M' Which can be schedule to run every minute on cron. This script will run every minute and capture 20 packets from the iSCSI traffic every minute and save in a file called /tmp/trace_packetMINUTE. So it will create 60 files (one for every minute in an hour) and will overwrite the files on the next hour. When the issue happens again, we can analyze these files (/tmp/trace_packet*)  and send to AWS support with the time that the issue happened. So please let us know whether we can go ahead and create this script in order to troubleshoot the issue further.###We have contacted AWS support to check whether there is any y network related issue for instance i-1426f28b from  Dec 22 22:00 UTC to Dec 22 23:59 UTC as well as if there is any issue regarding the direct connect around that time.###Hello Matthew,We got a reply from AWS support and they confirmed that everything was OK with the underlying hardware. Our engineering team is further investigating on this to find the root cause and will update you regarding the progress.###Hi Matthew,AWS support team is still investigating from their end, We will update you as soon as we get an update from them.###[Sumith CP]Hi Team,Could you please provide health status of the underlying hardware and network of i-1426f28b. At this point what we need to conclude is whether any network issue from AWS caused this issue or not.We will internally discuss enable the script you provided. This is the third time we are witnessing this issue and It's a production server we don't want this issue to happen again that why we are investigating the root cause.Cloud you please provide the health status AWS host in between Dec 22 22:00 UTC to Dec 22 22:00 UTC as soon as possible and consider this as a critical issue.###[AWS Support]Hello,Thank you for quick reply.As my colleague stated before, this issue has been internally escalated and we are still investigating this issue.For now we need some information from your side, as we don't have access to the instance operating system level.A packet tracing will provide us more information about what could be causing this issue.Can you please create a script in /tmp with this content (i.e. /tmp/tcp.sh):#!/bin/bash/usr/bin/killall tcpdump/usr/sbin/tcpdump -pni eth0 -s 64 -c 20 -G 10 -w '/tmp/trace_packet.pcap%M'Then schedule to run every minute on cron. (i.e. $ sudo crontab -e)* * * * * /tmp/tcp.shThis script will run every minute and capture 20 packets from the iSCSI traffic every minute and save in a file called /tmp/trace_packetMINUTE. So it will create 60 files (one for every minute in an hour) and will overwrite the files on the next hour.When the issue happen again, please send these files (/tmp/trace_packet*) to me with the time that the issue happened.You can compact the files with,$ tar czfv files_case_1993328101.tgz /tmp/trace_packet*And then send ‘files_case_1993328101.tgz’ using the URL below.AWS Support - S3 Uploaderhttps://aws-support-uploader.s3.amazonaws.com/uploader?account-id=261234435984&case-id=1993328101&expiration=1483782999&key=7d8d614d6753b383ecaf563724582cab37f5f0ff24528339ab39385c77e35379Expires on: 2017-01-07 09:56:39 UTC (Sat Jan 07 2017 11:56:39 GMT+0200 (SAST))Once the data has been uploaded correctly, please reply to this case to solicit a review of the data provided.###Aws Team.Hello,Thank you for contacting AWS Support.This issue has been escalated internally and is under investigation.  We do not have anything conclusive to report back at this time.In the meantime, if you could find a way to take a packet capture at the time of one of these events, it would be very helpful.Also, we did see authentication failures in your system log attachments:Dec 23 15:52:27 ip-10-59-100-125 iscsid: conn 0 login rejected: initiator failed authorization with targetDec 23 15:52:27 ip-10-59-100-125 iscsid: Connection3:0 to [target: iqn.2007-11.com.nimblestorage:spend4-v777bb21358661922.00000009.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is shutdown.Dec 23 15:52:27 ip-10-59-100-125 iscsid: Connection5:0 to [target: iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is operational nowDec 23 15:52:27 ip-10-59-100-125 iscsid: Connection4:0 to [target: iqn.2007-11.com.nimblestorage:shq1files01-shqsshot-12-14-16-v777bb21358661922.00000008.2f1dab31.s777bb21358661922.00000008.00004bf2, portal: 172.23.104.77,3260] through [iface: iSCSI1] is operational nowDec 23 15:52:27 ip-10-59-100-125 iscsid: conn 0 login rejected: initiator failed authorization with targetDec 23 15:52:27 ip-10-59-100-125 iscsid: Connection6:0 to [target: iqn.2007-11.com.nimblestorage:spendhq-db4-v777bb21358661922.00000010.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is shutdown.Dec 23 15:52:27 ip-10-59-100-125 iscsid: Connection7:0 to [target: iqn.2007-11.com.nimblestorage:shqfiles01a-v777bb21358661922.00000013.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is operational nowDec 23 15:52:27 ip-10-59-100-125 iscsid: conn 0 login rejected: initiator failed authorization with targetDec 23 15:52:27 ip-10-59-100-125 iscsid: Connection1:0 to [target: iqn.2007-11.com.nimblestorage:db-backup-12-16-16.clone-v777bb21358661922.00000014.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is shutdown.Dec 23 15:52:27 ip-10-59-100-125 iscsid: conn 0 login rejected: initiator failed authorization with targetDec 23 15:52:27 ip-10-59-100-125 iscsid: Connection2:0 to [target: iqn.2007-11.com.nimblestorage:spend5-v777bb21358661922.0000000d.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is shutdown.Is this a separate issue, and do you know what the cause was?###Hi Team,We are aware of this and we don't have any issue at that point of time. We want to to know the status of [TIMINGS]###Hi Chris,The issue is with the ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31-lun-0 volume which is mounted on the instance 10.59.100.125.###We informed AWS team that,Hi Team,We again received an issue regarding the iSCSI connection was disconnected around Dec 22 23:06:41 UTC, for the below-mentioned instance.Instance id:  i-1426f28bRegion:        us-east-1Please let us know if you have any outage at your end and find the log details in the attachment section.Instance ID(s): i-1426f28bPlease find the attached system log file for more details.###Sudheer,Hi Matthew,From the error logs, we see that the ISCSI connection failed with the error Network is unreachable. We have already raised a support ticket to AWS to check if there is any network outage with the Instance underlying hardware.@Chris - Can you also please check from your end if there were any network failures with the ISCSI between Dec 22 22:50:00 UTC and Dec 22 23:20:00 UTC###Hello,I have checked the logs and have come up empty - nothing showing any network issues.  W also have redundancy built into our architecture.###chris,REAN,Can you confirm that IQN of the instance isiqn.1994-05.com.redhat:a7565668c72aThanks,Chris###MatthewYes, that is correct. We reported the issue at 10:15 this morning, however it commenced late yesterday afternoon thus placing those errors in the right time frame.###Matthew Informed that I have just reviewed the log files on .125 (File Server) and it appears that we had some issues early on in the afternoon, which ultimately got worse. It seems that with the Journal Commit Error’s that the drive got enough errors that the Operating System took it to read-only mode. Especially considering we have multiple entries for I/O Errors on specific blocks that retried and ultimately resulted in the read only mount. Can you advise if you think this is a storage issue error or other? Dec 22 23:06:31 ip-10-59-100-125 kernel: connection3:0: ping timeout of 10 secs expired, recv timeout 5, last rx 4705624002, last ping 4705629002, now 4705639002Dec 22 23:06:32 ip-10-59-100-125 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)Dec 22 23:06:36 ip-10-59-100-125 iscsid: connect to 172.23.104.77:3260 failed (Network is unreachable)Dec 22 23:06:41 ip-10-59-100-125 kernel: sd 4:0:0:0: rejecting I/O to offline deviceDec 22 23:06:41 ip-10-59-100-125 kernel: sd 4:0:0:0: [sda] killing requestDec 22 23:06:41 ip-10-59-100-125 kernel: JBD2: Detected IO errors while flushing file data on sda-8Dec 22 23:06:41 ip-10-59-100-125 kernel: JBD2: I/O error detected when updating journal superblock for sda-8.Dec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs error (device sda) in ext4_dirty_inode: Journal has abortedDec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_journal_start_sb: Detected aborted journalDec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs (sda): Remounting filesystem read-onlyDec 22 23:06:45 ip-10-59-100-125 kernel: journal commit I/O error###Praveen informed that.Hello Matthew, We noticed this error. But this error is on Dec 22nd. By any time zone the issue you reported time was 23rd. So our team is looking further to understand the issue further. We will get back to you ASAP as soon as we finishes our analysis. Thank you for your findings.###Hello Matthew,As we have restarted the NFS service on the server .125, this issue got resolved.We are currently working on the root cause of this issue and will get back to you with the updates.###Hello Matthew,We are currently working on this issue as a high priority one. For discussing more on this issue, could you please join the bridge join.me/REANCloudTraining###Can we get on a webex asap to resolve. This issue is affecting all PRD machines.###Hello Matthew,We acknowledge the delivery of your email.We will work on this issue and will get back to you with the updates soon.","The file system that is mounted to .118 (PRD) has become read-only.  This needs to be resolved asap.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SEV ONE: Read Only File System,,23-12-2016 20:45,283,0,SpendHQ,As per discussed on internally we are closing the issue here and opened a problem ticket and assigned the ticket to Sudheer for performing more analysis.Ticket Number: 01041814,"Hi Team,When we checked we couldn't find multipath config file. So we tried  # multipath -ll command which prints out multipathed paths that show which devices are multipathed.$ sudo multipath -llJan 04 00:58:40 | DM multipath kernel driver not loadedJan 04 00:58:40 | /etc/multipath.conf does not exist, blacklisting all devices.Jan 04 00:58:40 | A sample multipath.conf file is located atJan 04 00:58:40 | /usr/share/doc/device-mapper-multipath-0.4.9/multipath.confJan 04 00:58:40 | You can run /sbin/mpathconf to create or modify /etc/multipath.confJan 04 00:58:40 | DM multipath kernel driver not loadedWe have received this error when listing device that are multipathed which says DM multipath kernel driver not loaded and  /etc/multipath.conf does not exist.","Chris updated that.Hi Everyone,I have been working this with Nimble. We have checked out the Nimble array  and verified there are not any issues with either the storage or the network on our end.The error message suggests that issue is on the host (which makes sense since that where the error log is being generated).There was- and  currently - a broken/re-connection issue associated with this AWS machine.This leads us to believe that it is a multipath config issue.I need REAN review the attached config sheet and verify that the mulitpath.conf file is correct - and verify it is correct for the version of Red Hat that is running.Make Note - NCM is not loaded on the AWS machine.  See the configuration sheet for those minor config details.I will be happy to help out with this as needed - as will Nimble.","Hi Chris,Do you have any update from Nimble Team to see if there are any configurations that might have caused this issue.Please let us know the updates.","Chris was not picking up the phone call, Sent a reminder to Chris for updates.Hi Chris,This is a quick followup,Do we have any update from Nimble Team to see if there are any configurations that might cause this issue?",Chris updated that he will engaging the Nimble Team to see if there are any configurations that might/may cause this occasional issue. This probably will result in a Nimble/REAN call and exchange of ideas. Chris will drive this.,"Hello Team,We had a call with Chris yesterday he updated that he had already raised a support ticket with the nimble team and he informed that he will try to get Andromeda, REAN and Nimble Team in a single call to troubleshoot the issue.@Chris: Could you please send an email detailing the  dependency on Nimble Team as we had discussed in yesterday's  call.","We had a call with Chris from Andromeda, he updated that he is also not able to figure out the exact issue so that he already raised a support ticket with nimble team and he informed that he will try to get Andromeda, REAN and Nimble Team in a single call.Chris told that he will  send an email detailing the updates regarding the issue.","We informed Chris with following details and asked his availability to set up a call.Hello Chris,The initiator IQN you have sent is same as that of TEST-SPHQ-WEB-SERVER01(10.59.100.125) instance. Please find the initiator IQN of all DB servers.TEST-SPHQ-WEB-SERVER01(10.59.100.125)    : iqn.1994-05.com.redhat:a7565668c72aDBserver01(10.59.10.137)                 : stoppedDBserver02(10.59.10.12)                  : iqn.1994-05.com.redhat:573c3f4764bDBserver03(10.59.10.148)                 : iqn.1994-05.com.redhat:64d02cf6d2ceDBserver04(10.59.10.91)                  : iqn.1994-05.com.redhat:64d02cf6d2ceDBserver05(10.59.10.135)                 : iqn.1994-05.com.redhat:64d02cf7e3dfPlease let us know your availability to get on a call to discuss following issues.The file system that is mounted to .118 (PRD) became read-only on DEC 23rd. For this issue, we got a reply from AWS support that there is no network outage/direct connect issue from AWS side at that time.  The error messages that we are getting in /var/log/messages on .118 and .135 instances, we have already shared the error logs in CMP.Also, did you get a chance to log on to the account? We have already sent you an invite with your login ID and link to set up your password for REAN ticketing tool.",​Chris askedLooks good - but i want to verify my initiator IQN on my side.Would you send me the IQN of the AWS instance that is running the DB that is mounts SHQ1Files01?It should be     iqn.1994-05.com.redhat:a7565668c72a,"Hi SpendHQ,We got a reply from AWS EC2 networking team about their investigation on the Direct connect.AWS Support says that they can not see any networking issue that could be related to this behavior we faced. Also at the specific time, we did not face any issue with the DX connection.Now, we are waiting for Andromeda3 team to check whether there is any issue with the IQN ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31-lun-0 volume mounted on the instance 10.59.100.125.","Mail from AWS.Hello, Just an update. The DX interfaces are up and running for 12w 4d 23h and 7w 3d 16h, respectively. So, at the specific time we did not face any issue with the DX connection. Also checking the instance (i-1426f28b), I can see that you did a stop/start 3 days ago (2016-12-23 15:51:26 GMT). The instance now is running in another underlying hardware. Checking on the hardware that the instance was running before (on the specified time), I can not see any networking issue that could be related to this behavior you faced.I will keep this case locked to me, please let us know if you face this issue again. Have a nice day.Best regards,George F.Amazon Web Services",We have followed-up with AWS on this.We asked: Did we hear back from EC2 networking team on their investigation on the Direct connect?Joel from Support has reached out to someone from Networking and also operation team too and will continue the follow-up and will provide and update.,"AWS updated that the EC2 networking team informed that everything looks good such as route propagation from VPC perspective. Everything was OK with the underlying hardware too. From the latest update, the networking team are still conducting further investigation on the Direct connect.",We have asked ChrisThis is a quick follow-up. Please let us know if you get a chance to check whether there is any issue with the IQN ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31-lun-0 volume mounted on the instance 10.59.100.125.,We have updated  Chris thatWe have verified the configuration on 10.59.100.118 and found that the configuration values are same as the values you have sent.Please find the snapshot attached for details.,Chris from Andromeda asked Hi - can we verify that /etc/iscsid.conf is configured as follows:node.session.timeo.replacement_timeout = 10node.conn[0].timeo.noop_out_timeout = 10,"Hello Matthew,We have added the cron job and will let you know the further updates.","Hello Matthew,Thanks for the confirmation.We will set the cron job and let you know the updates.",Let's go ahead and do this please. Just keep an eye on the tmpfs as it will quickly fill up. Thank you.,"Hello Matthew,To perform further analysis on this issue as per the ticket raised with AWS they informed that packet tracing will provide more information about what could be causing this issue. For this we need to create a script in /tmp with this content (i.e. /tmp/tcp.sh): #!/bin/bash /usr/bin/killall tcpdump /usr/sbin/tcpdump -pni eth0 -s 64 -c 20 -G 10 -w '/tmp/trace_packet.pcap%M' Which can be schedule to run every minute on cron. This script will run every minute and capture 20 packets from the iSCSI traffic every minute and save in a file called /tmp/trace_packetMINUTE. So it will create 60 files (one for every minute in an hour) and will overwrite the files on the next hour. When the issue happens again, we can analyze these files (/tmp/trace_packet*)  and send to AWS support with the time that the issue happened. So please let us know whether we can go ahead and create this script in order to troubleshoot the issue further.",We have contacted AWS support to check whether there is any y network related issue for instance i-1426f28b from  Dec 22 22:00 UTC to Dec 22 23:59 UTC as well as if there is any issue regarding the direct connect around that time.,"Hello Matthew,We got a reply from AWS support and they confirmed that everything was OK with the underlying hardware. Our engineering team is further investigating on this to find the root cause and will update you regarding the progress.","Hi Matthew,AWS support team is still investigating from their end, We will update you as soon as we get an update from them.","[Sumith CP]Hi Team,Could you please provide health status of the underlying hardware and network of i-1426f28b. At this point what we need to conclude is whether any network issue from AWS caused this issue or not.We will internally discuss enable the script you provided. This is the third time we are witnessing this issue and It's a production server we don't want this issue to happen again that why we are investigating the root cause.Cloud you please provide the health status AWS host in between Dec 22 22:00 UTC to Dec 22 22:00 UTC as soon as possible and consider this as a critical issue.","[AWS Support]Hello,Thank you for quick reply.As my colleague stated before, this issue has been internally escalated and we are still investigating this issue.For now we need some information from your side, as we don't have access to the instance operating system level.A packet tracing will provide us more information about what could be causing this issue.Can you please create a script in /tmp with this content (i.e. /tmp/tcp.sh):#!/bin/bash/usr/bin/killall tcpdump/usr/sbin/tcpdump -pni eth0 -s 64 -c 20 -G 10 -w '/tmp/trace_packet.pcap%M'Then schedule to run every minute on cron. (i.e. $ sudo crontab -e)* * * * * /tmp/tcp.shThis script will run every minute and capture 20 packets from the iSCSI traffic every minute and save in a file called /tmp/trace_packetMINUTE. So it will create 60 files (one for every minute in an hour) and will overwrite the files on the next hour.When the issue happen again, please send these files (/tmp/trace_packet*) to me with the time that the issue happened.You can compact the files with,$ tar czfv files_case_1993328101.tgz /tmp/trace_packet*And then send ‘files_case_1993328101.tgz’ using the URL below.AWS Support - S3 Uploaderhttps://aws-support-uploader.s3.amazonaws.com/uploader?account-id=261234435984&case-id=1993328101&expiration=1483782999&key=7d8d614d6753b383ecaf563724582cab37f5f0ff24528339ab39385c77e35379Expires on: 2017-01-07 09:56:39 UTC (Sat Jan 07 2017 11:56:39 GMT+0200 (SAST))Once the data has been uploaded correctly, please reply to this case to solicit a review of the data provided.","Aws Team.Hello,Thank you for contacting AWS Support.This issue has been escalated internally and is under investigation.  We do not have anything conclusive to report back at this time.In the meantime, if you could find a way to take a packet capture at the time of one of these events, it would be very helpful.Also, we did see authentication failures in your system log attachments:Dec 23 15:52:27 ip-10-59-100-125 iscsid: conn 0 login rejected: initiator failed authorization with targetDec 23 15:52:27 ip-10-59-100-125 iscsid: Connection3:0 to [target: iqn.2007-11.com.nimblestorage:spend4-v777bb21358661922.00000009.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is shutdown.Dec 23 15:52:27 ip-10-59-100-125 iscsid: Connection5:0 to [target: iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is operational nowDec 23 15:52:27 ip-10-59-100-125 iscsid: Connection4:0 to [target: iqn.2007-11.com.nimblestorage:shq1files01-shqsshot-12-14-16-v777bb21358661922.00000008.2f1dab31.s777bb21358661922.00000008.00004bf2, portal: 172.23.104.77,3260] through [iface: iSCSI1] is operational nowDec 23 15:52:27 ip-10-59-100-125 iscsid: conn 0 login rejected: initiator failed authorization with targetDec 23 15:52:27 ip-10-59-100-125 iscsid: Connection6:0 to [target: iqn.2007-11.com.nimblestorage:spendhq-db4-v777bb21358661922.00000010.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is shutdown.Dec 23 15:52:27 ip-10-59-100-125 iscsid: Connection7:0 to [target: iqn.2007-11.com.nimblestorage:shqfiles01a-v777bb21358661922.00000013.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is operational nowDec 23 15:52:27 ip-10-59-100-125 iscsid: conn 0 login rejected: initiator failed authorization with targetDec 23 15:52:27 ip-10-59-100-125 iscsid: Connection1:0 to [target: iqn.2007-11.com.nimblestorage:db-backup-12-16-16.clone-v777bb21358661922.00000014.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is shutdown.Dec 23 15:52:27 ip-10-59-100-125 iscsid: conn 0 login rejected: initiator failed authorization with targetDec 23 15:52:27 ip-10-59-100-125 iscsid: Connection2:0 to [target: iqn.2007-11.com.nimblestorage:spend5-v777bb21358661922.0000000d.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is shutdown.Is this a separate issue, and do you know what the cause was?","Hi Team,We are aware of this and we don't have any issue at that point of time. We want to to know the status of [TIMINGS]","Hi Chris,The issue is with the ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31-lun-0 volume which is mounted on the instance 10.59.100.125.","We informed AWS team that,Hi Team,We again received an issue regarding the iSCSI connection was disconnected around Dec 22 23:06:41 UTC, for the below-mentioned instance.Instance id:  i-1426f28bRegion:        us-east-1Please let us know if you have any outage at your end and find the log details in the attachment section.Instance ID(s): i-1426f28bPlease find the attached system log file for more details.","Sudheer,Hi Matthew,From the error logs, we see that the ISCSI connection failed with the error Network is unreachable. We have already raised a support ticket to AWS to check if there is any network outage with the Instance underlying hardware.@Chris - Can you also please check from your end if there were any network failures with the ISCSI between Dec 22 22:50:00 UTC and Dec 22 23:20:00 UTC","Hello,I have checked the logs and have come up empty - nothing showing any network issues.  W also have redundancy built into our architecture.","chris,REAN,Can you confirm that IQN of the instance isiqn.1994-05.com.redhat:a7565668c72aThanks,Chris","MatthewYes, that is correct. We reported the issue at 10:15 this morning, however it commenced late yesterday afternoon thus placing those errors in the right time frame.","Matthew Informed that I have just reviewed the log files on .125 (File Server) and it appears that we had some issues early on in the afternoon, which ultimately got worse. It seems that with the Journal Commit Error’s that the drive got enough errors that the Operating System took it to read-only mode. Especially considering we have multiple entries for I/O Errors on specific blocks that retried and ultimately resulted in the read only mount. Can you advise if you think this is a storage issue error or other? Dec 22 23:06:31 ip-10-59-100-125 kernel: connection3:0: ping timeout of 10 secs expired, recv timeout 5, last rx 4705624002, last ping 4705629002, now 4705639002Dec 22 23:06:32 ip-10-59-100-125 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)Dec 22 23:06:36 ip-10-59-100-125 iscsid: connect to 172.23.104.77:3260 failed (Network is unreachable)Dec 22 23:06:41 ip-10-59-100-125 kernel: sd 4:0:0:0: rejecting I/O to offline deviceDec 22 23:06:41 ip-10-59-100-125 kernel: sd 4:0:0:0: [sda] killing requestDec 22 23:06:41 ip-10-59-100-125 kernel: JBD2: Detected IO errors while flushing file data on sda-8Dec 22 23:06:41 ip-10-59-100-125 kernel: JBD2: I/O error detected when updating journal superblock for sda-8.Dec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs error (device sda) in ext4_dirty_inode: Journal has abortedDec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_journal_start_sb: Detected aborted journalDec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs (sda): Remounting filesystem read-onlyDec 22 23:06:45 ip-10-59-100-125 kernel: journal commit I/O error","Praveen informed that.Hello Matthew, We noticed this error. But this error is on Dec 22nd. By any time zone the issue you reported time was 23rd. So our team is looking further to understand the issue further. We will get back to you ASAP as soon as we finishes our analysis. Thank you for your findings.","Hello Matthew,As we have restarted the NFS service on the server .125, this issue got resolved.We are currently working on the root cause of this issue and will get back to you with the updates.","Hello Matthew,We are currently working on this issue as a high priority one. For discussing more on this issue, could you please join the bridge join.me/REANCloudTraining",Can we get on a webex asap to resolve. This issue is affecting all PRD machines.,"Hello Matthew,We acknowledge the delivery of your email.We will work on this issue and will get back to you with the updates soon.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000017Q0Nv,Cloud Engineer Level 1,Closed,1042756,Incident,02-02-2017 15:50,,"Hi SpendHQ Team,Regarding this incident which you have provided we have previously blocked the IP when this issue has occurred.Please refer this case for the details: Case Number- 01041772 At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Dear Andrew,  As per your request, we have analyzed the virus attack you have pointed on the Sophos report.  The IP address [10.59.1.167 ] you have mentioned belonged to the preview ELB IP. According to SpendHQ architecture, Sophos instance is coming under the ELB, this was the reason you have seen a private IP in the report. We have further analyzed the logs from the ELB and was able to find that all the request came from AWS accounts from the different regions. We have attached the findings in attachments section.   All the requests come from Windows instances from the different regions of AWS,  the counts are so low that we are not able to report an abuse to AWS. If we are looking into the hits and visits, looks like some kind of network scan/spy bots which was blocked by Sophos.###We are looking into this and we will update you with our findings.###From the Sophos Executive report, it appears that a malware attack was detected and prevented. Do we know what device/system 10.59.1.167 is?","From the Sophos Executive report, it appears that a malware attack was detected and prevented. Do we know what device/system 10.59.1.167 is?",Sophos Executive Report - Malware Detection,,01-02-2017 22:02,19,0,SpendHQ,"Hi SpendHQ Team,Regarding this incident which you have provided we have previously blocked the IP when this issue has occurred.Please refer this case for the details: Case Number- 01041772 At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Dear Andrew,  As per your request, we have analyzed the virus attack you have pointed on the Sophos report.  The IP address [10.59.1.167 ] you have mentioned belonged to the preview ELB IP. According to SpendHQ architecture, Sophos instance is coming under the ELB, this was the reason you have seen a private IP in the report. We have further analyzed the logs from the ELB and was able to find that all the request came from AWS accounts from the different regions. We have attached the findings in attachments section.   All the requests come from Windows instances from the different regions of AWS,  the counts are so low that we are not able to report an abuse to AWS. If we are looking into the hits and visits, looks like some kind of network scan/spy bots which was blocked by Sophos.",We are looking into this and we will update you with our findings.,"From the Sophos Executive report, it appears that a malware attack was detected and prevented. Do we know what device/system 10.59.1.167 is?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001YMj7t,Cloud Engineer Level 1,Closed,1100986,Incident,04-07-2018 01:04,,"Hello Team, Seeing as the alert has recovered and EBS Disk Usage gone down to 69.4% when we last checked, we are moving forward and marking this case as closed.Thank you.###Hello Team, When investigating this, EBS Disk usage was at 95%The breakdown is as follows:Filesystem      Size  Used Avail Use% Mounted on/dev/xvda1      7.8G  7.0G  441M  95% /tmpfs           7.3G     0  7.3G   0% /dev/shmDisk usage per directories in /:6.4G    total                                                                                                    4.1G    /opt                                                                                                     1.2G    /usr                                                                                                     560M    /home                                                                                                    286M    /lib234M    /var44M     /boot32M     /root30M     /etc18M     /lib6411M     /sbin6.1M    /bin140K    /dev136K    /tmp16K     /lost+found8.0K    /run8.0K    /installed-list.txt4.0K    /srv4.0K    /selinux4.0K    /mntTop Disk consuming directories/files in /opt:4.6G    .3.5G    ./tomcat2.9G    ./tomcat/webapps2.7G    ./tomcat/webapps/InfoGo1.1G    ./tomcat/webapps/InfoGo/rdDataCache813M    ./Discovery808M    ./Discovery/platform651M    ./tomcat/logs451M    ./tomcat/webapps/InfoGo/WEB-INF/lib451M    ./tomcat/webapps/InfoGo/WEB-INF430M    ./tomcat/webapps/InfoGo/rdErrorLog320M    ./tomcat/webapps/InfoGo/.git319M    ./tomcat/webapps/InfoGo/.git/objects318M    ./tomcat/webapps/InfoGo/.git/objects/pack318M    ./datadog-agent240M    ./datadog-agent/embedded236M    ./tomcat/webapps/InfoGo/rdDownload195M    ./tomcat/webapps/test123188M    ./Discovery/platform/java/jre1.8.0_102188M    ./Discovery/platform/javaTop Disk consuming directories/files in /usr:1.2G    .340M    ./java/jdk1.8.0_131340M    ./java237M    ./share190M    ./java/jdk1.8.0_131/jre189M    ./java/jdk1.8.0_131/jre/lib163M    ./bin134M    ./lib64132M    ./lib117M    ./java/jdk1.8.0_131/lib95M     ./lib/locale93M     ./java/jdk1.8.0_131/jre/lib/amd6465M     ./local/bin65M     ./local60M     ./share/locale60M     ./java/jdk1.8.0_131/lib/missioncontrol54M     ./java/jdk1.8.0_131/lib/missioncontrol/plugins51M     ./share/doc34M     ./lib64/python2.633M     ./libexecPlease clean up or ZIP any unwanted files to have this resolved soon. Feel free to get in touch with us in case you have any further queries.Thank you.###Hello Team, This is to inform you that we have received an alert regarding EBS High Disk Usage on ( /dev/xvda1 ) - prd_logi - 10.59.10.20The current value is at 80.08 which is slightly above the set threshold of 80. We are analyzing this and will get back to you with further details.Resource Details:Instance Name: PRD LogiInstance ID: i-013c59912babfa7cdInstance Type: c4.2xlargeIPv4: 10.59.10.20Availability Zone: us-east-1bVPC ID: vpc-76df7212Subnet ID: subnet-0fdde924","[image: Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd_logi -10.59.10.20High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1530639339000&group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.20&from_ts=1530635739000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 80The monitor was last triggered at Tue Jul 03 2018 17:35:49 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.20>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [View10.59.10.20 <https://app.datadoghq.com/infrastructure?filter=10.59.10.20>]· [Show Processes<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1530639349000&tags=host%3A10.59.10.20&from_ts=1530638449000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4469055828182209888>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Hosea B. Getusi,*Cloud Engineer,**REĀN Cloud. **Mobile*: +254713404220 | *Skype*: hoseagetusi*hosea.getusi@reancloud.com <hosea.getusi@reancloud.com>* |  *www.reancloud.com<http://www.reancloud.com>*-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd_logi - 10.59.10.20,,03-07-2018 23:22,2,0,SpendHQ,"Hello Team, Seeing as the alert has recovered and EBS Disk Usage gone down to 69.4% when we last checked, we are moving forward and marking this case as closed.Thank you.","Hello Team, When investigating this, EBS Disk usage was at 95%The breakdown is as follows:Filesystem      Size  Used Avail Use% Mounted on/dev/xvda1      7.8G  7.0G  441M  95% /tmpfs           7.3G     0  7.3G   0% /dev/shmDisk usage per directories in /:6.4G    total                                                                                                    4.1G    /opt                                                                                                     1.2G    /usr                                                                                                     560M    /home                                                                                                    286M    /lib234M    /var44M     /boot32M     /root30M     /etc18M     /lib6411M     /sbin6.1M    /bin140K    /dev136K    /tmp16K     /lost+found8.0K    /run8.0K    /installed-list.txt4.0K    /srv4.0K    /selinux4.0K    /mntTop Disk consuming directories/files in /opt:4.6G    .3.5G    ./tomcat2.9G    ./tomcat/webapps2.7G    ./tomcat/webapps/InfoGo1.1G    ./tomcat/webapps/InfoGo/rdDataCache813M    ./Discovery808M    ./Discovery/platform651M    ./tomcat/logs451M    ./tomcat/webapps/InfoGo/WEB-INF/lib451M    ./tomcat/webapps/InfoGo/WEB-INF430M    ./tomcat/webapps/InfoGo/rdErrorLog320M    ./tomcat/webapps/InfoGo/.git319M    ./tomcat/webapps/InfoGo/.git/objects318M    ./tomcat/webapps/InfoGo/.git/objects/pack318M    ./datadog-agent240M    ./datadog-agent/embedded236M    ./tomcat/webapps/InfoGo/rdDownload195M    ./tomcat/webapps/test123188M    ./Discovery/platform/java/jre1.8.0_102188M    ./Discovery/platform/javaTop Disk consuming directories/files in /usr:1.2G    .340M    ./java/jdk1.8.0_131340M    ./java237M    ./share190M    ./java/jdk1.8.0_131/jre189M    ./java/jdk1.8.0_131/jre/lib163M    ./bin134M    ./lib64132M    ./lib117M    ./java/jdk1.8.0_131/lib95M     ./lib/locale93M     ./java/jdk1.8.0_131/jre/lib/amd6465M     ./local/bin65M     ./local60M     ./share/locale60M     ./java/jdk1.8.0_131/lib/missioncontrol54M     ./java/jdk1.8.0_131/lib/missioncontrol/plugins51M     ./share/doc34M     ./lib64/python2.633M     ./libexecPlease clean up or ZIP any unwanted files to have this resolved soon. Feel free to get in touch with us in case you have any further queries.Thank you.","Hello Team, This is to inform you that we have received an alert regarding EBS High Disk Usage on ( /dev/xvda1 ) - prd_logi - 10.59.10.20The current value is at 80.08 which is slightly above the set threshold of 80. We are analyzing this and will get back to you with further details.Resource Details:Instance Name: PRD LogiInstance ID: i-013c59912babfa7cdInstance Type: c4.2xlargeIPv4: 10.59.10.20Availability Zone: us-east-1bVPC ID: vpc-76df7212Subnet ID: subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d4iKL,Cloud Engineer Level 1,Closed,1106456,Incident,29-10-2018 06:05,,"Hello  TeamWe haven't heard back from you regarding this case.At this time, we're marking this case as closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,Rafi RameshPune India###Hello Matthew,This is the gentle reminder.This request has been completed.Kindly check from your end and let us know if you have any queries related to it.###Hello Matthew,We sure do hope you got the chance to validate the instance. If so, do let us know if we are good to close this case.Thank you.###Hello Matthew,We haven't received any response from you. Please validate the instance and kindly confirm that whether we are good to close this cases. And please let us know if you have any queries regarding the same.###Matthew Watts3:44 PM (2 minutes ago)to ReanPerfect. Thank you. Let me validate and get back to you.###Hello Matthew,As per your request, we have created WW3_WEB_PROD instance. We have also updated schedule time for this instance to 07:00 AM to 19:00 PM EST.Resource Details: Name: WW3_WEB_PROD Instance ID: i-0ddc7cdc07d158214 Instance type: m4.2xlarge Availability zone: us-east-1c Private IPs: 10.59.101.57 Security groups: SpendHQ_Private_test_Webserver_Security_Group VPC ID: vpc-76df7212 Subnet ID: subnet-29b09361 IAM role: SystemsManagerInstance Key pair name: Instance Schedule Timing : 07:00 AM to 19:00 PM ESTSchedule Tag : spendhq-office-hours-webPlease review the complete details and let us know if you have any queries.###@teamChecked the lambda function and adjusted it correctly.###please check the lambda and instance status at 0700 - 1900 hours###@team,Also, I added the instance to the existing lambda functions###Hello Mathew,Below is the detail for the new server that was cloned from 10.59.101.6.Resource Details:Name: WW3_WEB_PRODInstance ID: i-0ddc7cdc07d158214Instance type: m4.2xlargeAvailability zone: us-east-1cPrivate IPs: 10.59.101.57Security groups: SpendHQ_Private_test_Webserver_Security_GroupVPC ID: vpc-76df7212Subnet ID: subnet-29b09361IAM role: SystemsManagerInstanceKey pair name: InstanceWe have also scheduled the instance as mentioned in your comment.Please review the above details and let us know your thoughts on the same.###Matthew WattsThu, Oct 18, 11:47 PM (24 minutes ago)to ReanThis server can have a 0700-1900 policy. It does not need to be on for the weekend###Hello Matthew,We will work on this request and once done will let you know the update.Thanks,","We need this escalated if possible.KeyValueInstance Name(Name of the instance to identify in the AWS Console)WW3_WEB_PRODInstance Type(RAM and CPU)Clone(Yes/No)YesIf Yes(Machine Details)10.59.101.6Subnet in which it must be Launch(If this instance need to have network connectivity with another instance)Same as cloneVolume Size(Root)Same as cloneSecondary Volume(Not needed/iSCSI Volume/ENS Volume)Same as cloneIf it is Cloned iSCSI Volume, then provide the details of volume and provide SizeSame as clone.Security Group Details(Required ports need to be open for this instance)Same as clone.SSH User Details(Details of the user who will need to have ssh access to this instance)Same as clone.Need to create new SSH Keys or copy the existing key(Provide the instance details from which we need to copy the keys)Same as clone.Sudo Access(Details of the user who should have sudo access)Same as clone.Operating SystemSame as clone.Onboard for REAN MonitoringSame as clone.BackupSame as clone.Environment(Production/Dev/Test/PoC)Same as clone.Requester Email ID(Email id of the owner of the instance)mwatts@spendhq.comAdditional Software(Give details of any specific software need to install on an instance or need to configure Public or Internal ELB, domain configuration etc.)Same as clone.Schedule Run Time of Instance(Does the server need to be turned on all the time or you want us to apply any scheduled downtime to stop/start)Same as clone.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",New Server Request,,19-10-2018 02:13,244,0,SpendHQ,"Hello  TeamWe haven't heard back from you regarding this case.At this time, we're marking this case as closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,Rafi RameshPune India","Hello Matthew,This is the gentle reminder.This request has been completed.Kindly check from your end and let us know if you have any queries related to it.","Hello Matthew,We sure do hope you got the chance to validate the instance. If so, do let us know if we are good to close this case.Thank you.","Hello Matthew,We haven't received any response from you. Please validate the instance and kindly confirm that whether we are good to close this cases. And please let us know if you have any queries regarding the same.",Matthew Watts3:44 PM (2 minutes ago)to ReanPerfect. Thank you. Let me validate and get back to you.,"Hello Matthew,As per your request, we have created WW3_WEB_PROD instance. We have also updated schedule time for this instance to 07:00 AM to 19:00 PM EST.Resource Details: Name: WW3_WEB_PROD Instance ID: i-0ddc7cdc07d158214 Instance type: m4.2xlarge Availability zone: us-east-1c Private IPs: 10.59.101.57 Security groups: SpendHQ_Private_test_Webserver_Security_Group VPC ID: vpc-76df7212 Subnet ID: subnet-29b09361 IAM role: SystemsManagerInstance Key pair name: Instance Schedule Timing : 07:00 AM to 19:00 PM ESTSchedule Tag : spendhq-office-hours-webPlease review the complete details and let us know if you have any queries.",@teamChecked the lambda function and adjusted it correctly.,please check the lambda and instance status at 0700 - 1900 hours,"@team,Also, I added the instance to the existing lambda functions","Hello Mathew,Below is the detail for the new server that was cloned from 10.59.101.6.Resource Details:Name: WW3_WEB_PRODInstance ID: i-0ddc7cdc07d158214Instance type: m4.2xlargeAvailability zone: us-east-1cPrivate IPs: 10.59.101.57Security groups: SpendHQ_Private_test_Webserver_Security_GroupVPC ID: vpc-76df7212Subnet ID: subnet-29b09361IAM role: SystemsManagerInstanceKey pair name: InstanceWe have also scheduled the instance as mentioned in your comment.Please review the above details and let us know your thoughts on the same.","Matthew WattsThu, Oct 18, 11:47 PM (24 minutes ago)to ReanThis server can have a 0700-1900 policy. It does not need to be on for the weekend","Hello Matthew,We will work on this request and once done will let you know the update.Thanks,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Fei5W,Cloud Engineer Level 1,Closed,1073556,Incident,16-08-2017 20:42,,"Hello Matthew,As we discussed on the call, we have fixed the issue.As we restarted the instance in order to fix the defunct process issue, the iSCSI volume mapping was changed automatically. Now, we have remounted the iSCSI volume /dev/sdd instead of the older volume /dev/sdb to the Infobright directory and the issue has fixed. We have confirmed that the alerts has been resolved and the application is loading and serving well now.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM###Hello Matthew,We acknowledge the delivery of your email.We will be calling you for further discussion on this issue within the next few minutes. Revert back in case of any further issues.Regards,Sumod.K.Bose","We have a defunct process on our database and need to restart the server immediately. Please call me on 904.868.8848 asap. This is a SEV ONE.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",CRITICAL,,16-08-2017 19:46,1,0,SpendHQ,"Hello Matthew,As we discussed on the call, we have fixed the issue.As we restarted the instance in order to fix the defunct process issue, the iSCSI volume mapping was changed automatically. Now, we have remounted the iSCSI volume /dev/sdd instead of the older volume /dev/sdb to the Infobright directory and the issue has fixed. We have confirmed that the alerts has been resolved and the application is loading and serving well now.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM","Hello Matthew,We acknowledge the delivery of your email.We will be calling you for further discussion on this issue within the next few minutes. Revert back in case of any further issues.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DnuKZ,Cloud Engineer Level 1,Closed,1065712,Incident,30-06-2017 05:41,,"Hello Mathew,We haven't heard back from you.As of now, We have disabled the maintenance mode for the URL https://preview.spendhq.com/login and marking this as resolved. Please let us know if you have any queries.###Hello Matthew,Please let us know if you are still working on  preview.spendhq.com. We could see that the site is still down. Kindly inform us once you are done with the maintenance.###Hello SpendHq Team,As discussed with Andrew we have enabled maintenance mode for preview.spendhq.com and will disable it  after receiving confirmation from your team.###Hello SpendHQ Team, This is to inform you that we got a site down alert for the url https://preview.spendhq.com/login.We are analyzing the issue form our end. Please let us know if you are performing any activity from your end.","Thu, 29 Jun 2017 10:38:41 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): London UK, California US, Atlanta-B US, Sydney-C AU-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,29-06-2017 20:08,11,0,SpendHQ,"Hello Mathew,We haven't heard back from you.As of now, We have disabled the maintenance mode for the URL https://preview.spendhq.com/login and marking this as resolved. Please let us know if you have any queries.","Hello Matthew,Please let us know if you are still working on  preview.spendhq.com. We could see that the site is still down. Kindly inform us once you are done with the maintenance.","Hello SpendHq Team,As discussed with Andrew we have enabled maintenance mode for preview.spendhq.com and will disable it  after receiving confirmation from your team.","Hello SpendHQ Team, This is to inform you that we got a site down alert for the url https://preview.spendhq.com/login.We are analyzing the issue form our end. Please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ETtKO,Cloud Engineer Level 1,Closed,1067494,Incident,13-07-2017 01:48,,"Hello Team,This is to notify you that the alert regarding volume usage for dev-sphq-db-server02_redis - 10.59.10.12 instance got resolved and returned to normal with a value of 75%. The violation lasted for 23 Hours 52 Minutes.###Hello Team,This is to inform you that the alert regarding volume usage for dev-sphq-db-server02_redis - 10.59.10.12 instance is still in an open state. The current usage is 92%. Please see the usage details below.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/sdi       ext4   4.0T  3.5T  325G  92% /mnt/db_backup_07_11_2017Usage under /mnt/db_backup_07_11_2017:3.5T    total2.8T    data662G    tmp9.8G    dmackay4.6G    watts4.1G    postgresUsage under /mnt/db_backup_07_11_2017/data:2.8T    total2.5T    isg50G     isg_metronic48G     ip-10-59-10-12.log33G     isg_metronic_bk24G     isg_medtronic_bk23G     isg_att21G     isg_thlee20120G     isg_ares216G     isg_att_01_07_2017Please remove/zip unwanted files to reduce current usage.###Next action: Night shift: Need to share the volume breakdown details.###Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for  dev-sphq-db-server02_redis - 10.59.10.12  instance has exceeded a threshold value of 90% to 92%. From our initial analysis, we could see /dev/sdi mounted on /mnt/db_backup_07_11_2017 consuming high volume usage. Out of 3.5T there is only 325GB available for use.","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sdi ) - dev-sphq-db-server02_redis - 10.59.10.12  High Disk Usage detected on the device /dev/sdi     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 91.5This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fsdi%2Chost%3Ai-a594d794 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3951686918623243576 · View i-a594d794: https://app.datadoghq.com/infrastructure?hostname=i-a594d794-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sdi ) - dev-sphq-db-server02_redis - 10.59.10.12,,12-07-2017 01:06,25,0,SpendHQ,"Hello Team,This is to notify you that the alert regarding volume usage for dev-sphq-db-server02_redis - 10.59.10.12 instance got resolved and returned to normal with a value of 75%. The violation lasted for 23 Hours 52 Minutes.","Hello Team,This is to inform you that the alert regarding volume usage for dev-sphq-db-server02_redis - 10.59.10.12 instance is still in an open state. The current usage is 92%. Please see the usage details below.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/sdi       ext4   4.0T  3.5T  325G  92% /mnt/db_backup_07_11_2017Usage under /mnt/db_backup_07_11_2017:3.5T    total2.8T    data662G    tmp9.8G    dmackay4.6G    watts4.1G    postgresUsage under /mnt/db_backup_07_11_2017/data:2.8T    total2.5T    isg50G     isg_metronic48G     ip-10-59-10-12.log33G     isg_metronic_bk24G     isg_medtronic_bk23G     isg_att21G     isg_thlee20120G     isg_ares216G     isg_att_01_07_2017Please remove/zip unwanted files to reduce current usage.",Next action: Night shift: Need to share the volume breakdown details.,"Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for  dev-sphq-db-server02_redis - 10.59.10.12  instance has exceeded a threshold value of 90% to 92%. From our initial analysis, we could see /dev/sdi mounted on /mnt/db_backup_07_11_2017 consuming high volume usage. Out of 3.5T there is only 325GB available for use.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001SVS5M,Cloud Engineer Level 2,Closed,1093265,Incident,18-03-2018 19:01,,"Hello Team,We haven't heard back from you.At this time we are marking the case as closed. Please revert back to us in case of further queries.###Hello Team,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.###Hello Team,This is a gentle reminder.Please review the previous comment and let us know if you have any queries.###Hello Team,Please find the attachment section for the RCA regarding SpendHQ Outage that happened on 14th March 2018.Please review the RCA and let us know if you have any queries.###@Yogesh,We have updated the Corrective Actions with exact timing. Please review the RCA and let us know if you have any further modification needed.###[via slack from yogesh]For Secure RCA I have done few updates..Please try to add exact times under Corrective Actions.###Yogesh updated that he will review.###The RCA has been created and assigning Yogesh for review.https://docs.google.com/document/d/1dHYPdW_R5msJQ-csanw-rlF68QXvNTJGnN63pckHlUw/edit#@Yogesh Maloo. Please review the RCA and let us know if any modification needs to be performed.###Hello Team,We are working on the RCA regarding the SpendHQ production outage and will get back to you with an update ASAP.###Hello Team,The Production is back up! We want SpendHQ to verify the data at /usr/local/infobright-products/iee/postgres mounted at /dev/sde on 10.59.10.190 server. As we had to restore this volume from March 6th because there was no latest backup available.We will be following up again with the next actions. Thank you for all your support. Regards,Yogesh MalooSenior Cloud Engineer, REĀN Cloud###What is the status here?  Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com###Hello Matthew,Please Join the below bridge.https://www.uberconference.com/anjaligopinadhanPhone: 857-216-4098Pin: 21266###Hello Chris,Please join the below bridge. We are waiting for you to join the call.https://www.uberconference.com/anjaligopinadhanPhone: 857-216-4098Pin: 21266###Praveen Muppala4:53 PM (4 hours ago)to me, Matthew, Chris, Yogesh, Robert, David, David, Technology, Spendhq Matt can you join the bridge. Chris is on the bridge. Regards,-Praveen###Chris Veillette4:19 PM (5 hours ago)to Yogesh, Robert, David, David, Technology, Matthew, Spendhq Sorry just saw this - what is the status?###Matthew Watts4:22 PM (5 hours ago)to Chris, Yogesh, Robert, David, David, Technology, Spendhq REAN and A3 I need you on a bridge asap. Matthew Watts | Manager, Application Development | SpendHQ®###We are waiting for the response from Andromeda and SpendHQ###I have sent an email to David and Chris Andromedia to join mgse2 quickly.###Robert Little11:37 AM (5 minutes ago)to Technology, Matthew, Yogesh, David, Spendhq Team, I am unable to reach anyone on the team right now. I have been on this call with REAN since 12AM. We have the mysql-ib service running but the mount for postgress seems to have an issue as there is no data on the drive and we cannot start the service. At this time we only have 2 options from what we can tell. 1 -  get a backup of the drive and see if any data is there.2 -  point the webservers to the preview postgres db. I have asked that the Rean teamwork to get the backup of the drive mounted, but in the meantime it sounded like they recommended us going with option 2. I do not have access to the webservers and thus cannot modify the connection to Postgres. With no one answering, I cannot get an approval to be granted this access either. I am sending this out in hopes someone sees it and can help move this process along. If anyone sees this please respond to this thread and get in touch with REAN to get this SEV 1 handeled. I will be online for another 15 minutes just incase someone answers this. After that, since I am making no progress, I will be going offline and waiting. Thanks,###Hello David,Would you like to get on a screen-share to handle it quickly? If possible, Please join the below bridge:You are invited to a Zoom meeting now. Join from PC, Mac, Linux, iOS or Android: https://reancloud.zoom.us/j/2112766542Or iPhone one-tap:    US: +16465588656,,2112766542#  or +16699006833,,2112766542# Or Telephone:    Dial(for higher quality, dial a number based on your current location):         US: +1 646 558 8656  or +1 669 900 6833  or +1 855 880 1246 (Toll Free) or +1 877 369 0926 (Toll Free)    Meeting ID: 211 276 6542    International numbers available: https://reancloud.zoom.us/zoomconference?m=luruqehFeMEXMJJozmJoVkDz41q0lzSjRegards,Yogesh MalooSenior Cloud Engineer, REĀN Cloud Mobile: +918003126272 | Skype: ykmaloo yogesh.maloo@reancloud.com | www.reancloud.com###Hello David,Would you like to get on a screen-share to handle it quickly? If possible, Please join the below bridge:https://reancloud.zoom.us/j/2112766542###Hello David,We will work on this and will get back to you with updates.","Rean,We are experiencing a SEV1 on our production DB server (10.59.10.190).  We have a mysql-ib process that won’t stop running (2120858).  Please advise we need to kill this process id as it’s inhibiting clients from accessing our tool.Let me know if you have any questionsThank YouDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sev1,,14-03-2018 09:44,105,0,SpendHQ,"Hello Team,We haven't heard back from you.At this time we are marking the case as closed. Please revert back to us in case of further queries.","Hello Team,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.","Hello Team,This is a gentle reminder.Please review the previous comment and let us know if you have any queries.","Hello Team,Please find the attachment section for the RCA regarding SpendHQ Outage that happened on 14th March 2018.Please review the RCA and let us know if you have any queries.","@Yogesh,We have updated the Corrective Actions with exact timing. Please review the RCA and let us know if you have any further modification needed.",[via slack from yogesh]For Secure RCA I have done few updates..Please try to add exact times under Corrective Actions.,Yogesh updated that he will review.,The RCA has been created and assigning Yogesh for review.https://docs.google.com/document/d/1dHYPdW_R5msJQ-csanw-rlF68QXvNTJGnN63pckHlUw/edit#@Yogesh Maloo. Please review the RCA and let us know if any modification needs to be performed.,"Hello Team,We are working on the RCA regarding the SpendHQ production outage and will get back to you with an update ASAP.","Hello Team,The Production is back up! We want SpendHQ to verify the data at /usr/local/infobright-products/iee/postgres mounted at /dev/sde on 10.59.10.190 server. As we had to restore this volume from March 6th because there was no latest backup available.We will be following up again with the next actions. Thank you for all your support. Regards,Yogesh MalooSenior Cloud Engineer, REĀN Cloud","What is the status here?  Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com","Hello Matthew,Please Join the below bridge.https://www.uberconference.com/anjaligopinadhanPhone: 857-216-4098Pin: 21266","Hello Chris,Please join the below bridge. We are waiting for you to join the call.https://www.uberconference.com/anjaligopinadhanPhone: 857-216-4098Pin: 21266","Praveen Muppala4:53 PM (4 hours ago)to me, Matthew, Chris, Yogesh, Robert, David, David, Technology, Spendhq Matt can you join the bridge. Chris is on the bridge. Regards,-Praveen","Chris Veillette4:19 PM (5 hours ago)to Yogesh, Robert, David, David, Technology, Matthew, Spendhq Sorry just saw this - what is the status?","Matthew Watts4:22 PM (5 hours ago)to Chris, Yogesh, Robert, David, David, Technology, Spendhq REAN and A3 I need you on a bridge asap. Matthew Watts | Manager, Application Development | SpendHQ®",We are waiting for the response from Andromeda and SpendHQ,I have sent an email to David and Chris Andromedia to join mgse2 quickly.,"Robert Little11:37 AM (5 minutes ago)to Technology, Matthew, Yogesh, David, Spendhq Team, I am unable to reach anyone on the team right now. I have been on this call with REAN since 12AM. We have the mysql-ib service running but the mount for postgress seems to have an issue as there is no data on the drive and we cannot start the service. At this time we only have 2 options from what we can tell. 1 -  get a backup of the drive and see if any data is there.2 -  point the webservers to the preview postgres db. I have asked that the Rean teamwork to get the backup of the drive mounted, but in the meantime it sounded like they recommended us going with option 2. I do not have access to the webservers and thus cannot modify the connection to Postgres. With no one answering, I cannot get an approval to be granted this access either. I am sending this out in hopes someone sees it and can help move this process along. If anyone sees this please respond to this thread and get in touch with REAN to get this SEV 1 handeled. I will be online for another 15 minutes just incase someone answers this. After that, since I am making no progress, I will be going offline and waiting. Thanks,","Hello David,Would you like to get on a screen-share to handle it quickly? If possible, Please join the below bridge:You are invited to a Zoom meeting now. Join from PC, Mac, Linux, iOS or Android: https://reancloud.zoom.us/j/2112766542Or iPhone one-tap:    US: +16465588656,,2112766542#  or +16699006833,,2112766542# Or Telephone:    Dial(for higher quality, dial a number based on your current location):         US: +1 646 558 8656  or +1 669 900 6833  or +1 855 880 1246 (Toll Free) or +1 877 369 0926 (Toll Free)    Meeting ID: 211 276 6542    International numbers available: https://reancloud.zoom.us/zoomconference?m=luruqehFeMEXMJJozmJoVkDz41q0lzSjRegards,Yogesh MalooSenior Cloud Engineer, REĀN Cloud Mobile: +918003126272 | Skype: ykmaloo yogesh.maloo@reancloud.com | www.reancloud.com","Hello David,Would you like to get on a screen-share to handle it quickly? If possible, Please join the below bridge:https://reancloud.zoom.us/j/2112766542","Hello David,We will work on this and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001m1JIE,Cloud Engineer Level 1,Closed,1113651,Incident,18-03-2019 12:58,,"Hello Team,This is to inform you that we have verified that the SG (sg-090c124c4e47c9ba1) is not in use anywhere.We have deleted the SG. As of now, we don't have any action item pending, therefore, we are marking this case resolved and closing this case.Feel free to reach us if you have any queries.###@Team:First verify this SG is not been used then please go ahead and delete this. And send a closure mail. Thanks.###Hello Team,This is a gentle reminder regarding unused security group.Please have a look at the details shared with you previously and let us know if we can have your approval to delete it.Thanks###Hello Team,We received a Managed Cloud Unused Security Groups Alert,  Currently which has only one rule attached to that and which was for SSH for a subnet range. Below are the details of the SG,Amazon Resource Name: arn:aws:ec2:us-east-1:261234435984:security-group/sg-090c124c4e47c9ba1Resource type: AWS::EC2::SecurityGroupResource ID: sg-090c124c4e47c9ba1Resource name: CentOS 7 -x86_64- - with Updates HVM-1805_01-AutogenByAWSMP-Group name: CentOS 7 -x86_64- - with Updates HVM-1805_01-AutogenByAWSMP-Group description: This security group was generated by AWS Marketplace and is based on recommended settings for CentOS 7 (x86_64) - with Updates HVM version 1805_01 provided by Centos.orgPlease review the details and let us know, we clean up the SG.Regards-Rafi","***** EXTERNAL EMAIL *****REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::EC2::SecurityGroup resources were affected:________________________________  *   Violation: Security group is not in use.  *   Recommendation: None  *   Action taken: None  *   Resource details:Resource ID     Region  VPC IDsg-090c124c4e47c9ba1    us-east-1       vpc-76df7212________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.",Fw: [Managed Cloud: spendhq] Unused Security Groups Alert,,16-03-2019 19:59,41,0,SpendHQ,"Hello Team,This is to inform you that we have verified that the SG (sg-090c124c4e47c9ba1) is not in use anywhere.We have deleted the SG. As of now, we don't have any action item pending, therefore, we are marking this case resolved and closing this case.Feel free to reach us if you have any queries.",@Team:First verify this SG is not been used then please go ahead and delete this. And send a closure mail. Thanks.,"Hello Team,This is a gentle reminder regarding unused security group.Please have a look at the details shared with you previously and let us know if we can have your approval to delete it.Thanks","Hello Team,We received a Managed Cloud Unused Security Groups Alert,  Currently which has only one rule attached to that and which was for SSH for a subnet range. Below are the details of the SG,Amazon Resource Name: arn:aws:ec2:us-east-1:261234435984:security-group/sg-090c124c4e47c9ba1Resource type: AWS::EC2::SecurityGroupResource ID: sg-090c124c4e47c9ba1Resource name: CentOS 7 -x86_64- - with Updates HVM-1805_01-AutogenByAWSMP-Group name: CentOS 7 -x86_64- - with Updates HVM-1805_01-AutogenByAWSMP-Group description: This security group was generated by AWS Marketplace and is based on recommended settings for CentOS 7 (x86_64) - with Updates HVM version 1805_01 provided by Centos.orgPlease review the details and let us know, we clean up the SG.Regards-Rafi",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001HVHfl,Cloud Engineer Level 1,Closed,1079092,Incident,19-09-2017 05:55,,"Hello SpendHQ-Team,This is to inform you that we have received an alert regarding high Network OUT on the instance prd-db1. The Network Outbound was above the threshold of 2.22 GB/Min with a value of 4.64 GB/Min. The alert got resolved automatically and returned to a normal state with a value of 0.035 GB/Min. The overall violation lasted for 10 minutes.Resource Details:-Availability-zone:us-east-1bImage:ami-453f3053Instance-type:r4.8xlargeInstance Name:prd-db1Region:us-east-1Instance ID: i-03ccfddd9f02cacb9As the alert is in the resolved state, we are marking this case as closed. Kindly validate these details from your end and revert back in case of any further queries.Regards,Sumod.K.Bose","[Triggered] [SpendHQ] - High Network OUT on host - prd-db1 -  - db Status  High Network OUT on the instance. Please check the list open TCP Connections    @support@reancloud.comaws.ec2.network_out over datadog_monitor:on,host:i-03ccfddd9f02cacb9 was > 2220000000.0 at all times during the last 5m.Metric value: 2261017088.0This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024199?group=host%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2024199/edit · Event URL: https://app.datadoghq.com/event/event?id=4051894562735490109 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - prd-db1 - - db Status,,19-09-2017 04:13,2,0,SpendHQ,"Hello SpendHQ-Team,This is to inform you that we have received an alert regarding high Network OUT on the instance prd-db1. The Network Outbound was above the threshold of 2.22 GB/Min with a value of 4.64 GB/Min. The alert got resolved automatically and returned to a normal state with a value of 0.035 GB/Min. The overall violation lasted for 10 minutes.Resource Details:-Availability-zone:us-east-1bImage:ami-453f3053Instance-type:r4.8xlargeInstance Name:prd-db1Region:us-east-1Instance ID: i-03ccfddd9f02cacb9As the alert is in the resolved state, we are marking this case as closed. Kindly validate these details from your end and revert back in case of any further queries.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001S4hVN,Cloud Engineer Level 1,Closed,1092598,Incident,07-03-2018 19:17,,"Hello Team,This is to notify that whoever creating VPC workflow logs from 28th April 2018 need to have IAM PassRole permission.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Parvesh###Hello Team, This is to notify that we have received the AWS VPC Operational Notification. AWS is updating the VPC Flow Logs from 28th April 2018 for the security best practices. AWS users who call CreateFlowLogs will be required to have the IAM PassRole permission whoever doesn't have the permission the system will return an access denied message from 28th April 2018. There will be no impact on existing VPC Flow Logs. Please review this details and let us know your thoughts regarding this.","Starting on 28 April, 2018, VPC Flow Logs will be implementing additional access controls to enhance security best practices for our customers. Effective 28 April, 2018, AWS users who call CreateFlowLogs will be required to have the IAM PassRole permission[1].  To prepare for this update, we request that you review your users’ IAM policies to ensure that the iam:PassRole permission on the IAM role used in the CreateFlowLogs call is granted appropriately.  If the user who calls CreateFlowLogs[2] does not have the IAM PassRole permission, the system will return an access denied message.  This change only affects the creation of new Flow Logs starting from 28 April, 2018. There is no impact to existing VPC Flow Logs.  The example below demonstrates how you can verify if the correct permission is already assigned to users that have created VPC Flow Logs in the past 90-days. Should you have any additional questions or concerns, the AWS Support team is available on the community forums and via AWS Premium Support[3].  EXAMPLE USING AWS CLI Below is the sequence of steps to be executed using the AWS CLI to determine if users who created VPC Flow Logs have the correct permissions assigned to them:  1) Check your CloudTrail logs for events related to creating Flow Logs, by searching for attributes with a key of “EventName” and a value of “CreateFlowLogs”.  In this example, only one CreateFlowLogs event is found, and this command was invoked by the user “admin-temp”.  % aws cloudtrail lookup-events --lookup-attributes AttributeKey=EventName, \\       AttributeValue=CreateFlowLogs {     Events: [         {             EventName: CreateFlowLogs,             Resources: [                 {                     ResourceType: AWS::IAM::Role,                     ResourceName: arn:aws:iam::123456789012:role/flowlogsRole                 },                 {                     ResourceType: AWS::Logs::LogGroup,                     ResourceName: example-flow-logs                 },                 {                     ResourceType: AWS::EC2::FlowLog,                     ResourceName: fl-1a1a1a1a                 },                 {                     ResourceName: vpc-2b2b2b2b                 }             ],             EventId: 1a1a1a1a-ffff-1111-9999-1234567890af,             EventTime: 1514764800.0,             Username: admin-temp,   2) Audit the permissions assigned to the IAM user “admin-temp”. Specifically, look for the PolicyNames assigned to this IAM user.  In this example, the policy name assigned is “inline-pass-role-policy”. Using the CLI, review the details of this user policy. Look for the “iam:PassRole” permission. In this example, the user policy does include the iam:PassRole permission. % aws iam list-user-policies --user-name admin-temp {     PolicyNames: [         inline-pass-role-policy     ] }  % aws iam get-user-policy --user-name admin-temp --policy-name inline-pass-role-policy {     UserName: admin-temp,     PolicyName: inline-pass-role-policy,     PolicyDocument: {         Version: 2012-10-17,         Statement: [             {                 Sid: VisualEditor0,                 Action: iam:PassRole,                 Effect: Allow,                 Resource: arn:aws:iam::123456789012:role/flowLogsRole             }         ]     } }  3) Using the credentials of the admin-temp IAM user, attempt to create a new Flow Log and verify that the Flow Log can be created successfully.  % aws ec2 create-flow-logs --deliver-logs-permission-arn \\       arn:aws:iam::123456789012:role/flowlogsRole \\       --log-group-name example-flow-logs --resource-ids vpc-2b2b2b2b \\       --resource-type VPC --traffic-type ALL  Because this user has the correct permission iam:PassRole on the role arn:aws:iam::123456789012:role/flowLogsRole it uses in the CreateFlowLogs call, this call will succeed.  Please refer to the AWS Documentation on “IAM Roles for Flow Logs” for more information[4].  [1] https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_passrole.html [2] https://docs.aws.amazon.com/cli/latest/reference/ec2/create-flow-logs.html [3] http://aws.amazon.com/support [4] https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/flow-logs.html#flow-logs-iam For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:298575795379:AWS_Health_Dashboard_Notification:e0ff2515-689c-4e3f-a9d4-871f7cb3c436&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_VPC_OPERATIONAL_NOTIFICATION,,06-03-2018 23:36,20,0,SpendHQ,"Hello Team,This is to notify that whoever creating VPC workflow logs from 28th April 2018 need to have IAM PassRole permission.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Parvesh","Hello Team, This is to notify that we have received the AWS VPC Operational Notification. AWS is updating the VPC Flow Logs from 28th April 2018 for the security best practices. AWS users who call CreateFlowLogs will be required to have the IAM PassRole permission whoever doesn't have the permission the system will return an access denied message from 28th April 2018. There will be no impact on existing VPC Flow Logs. Please review this details and let us know your thoughts regarding this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001WZoPt,Cloud Engineer Level 1,Closed,1099710,Incident,01-06-2018 20:05,,"Hello Spendhq-Team, This is to inform you that the alert regarding EBS High Disk Usage on prd-sv1 (10.59.100.193) got resolved and back to its normal state with the value of 76.62%.###Hello Spendhq-Team,The alert regarding EBS High Disk Usage on prd-sv1 (10.59.100.193) has exceeded the threshold value of 80 and reached 91%. Please find the usage details in the attachment section. Please zip/clean unwanted files.###Hello Team,Please find the detailed EBS High Disk Usage details in the attachment section.Kindly validate the details and zip/clean the unwanted files###Hello Team, This is to inform you that we have received an alert regarding EBS High Disk Usage on prd-sv1 (10.59.100.193) has exceeded the threshold value of 80 to 81.7%. Please find the resources details and disk usage below. Resource Details:- Instance ID: i-048e66836110e8d7bInstance Name: prd-sv1Private IP: 10.59.100.193We are analyzing this and will get back to you with the updates.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Fri, Jun 1, 2018 at 1:34 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prd-sv1 - 10.59.100.193To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-sv1 -10.59.100.193High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1527797079000&group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-048e66836110e8d7b&from_ts=1527793479000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 80The monitor was last triggered at Thu May 31 2018 20:04:49 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-048e66836110e8d7b>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [Viewi-048e66836110e8d7b<https://app.datadoghq.com/infrastructure?hostname=i-048e66836110e8d7b>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1527797089000&tags=host%3Ai-048e66836110e8d7b&from_ts=1527796189000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4421370616704258484>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <http://go.reancloud.com/secure-your-cloud> <http://go.reancloud.com/aws-public-sector-summit-2018>--  <http://go.reancloud.com/secure-your-cloud> <http://go.reancloud.com/aws-public-sector-summit-2018>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-sv1 - 10.59.100.193,,01-06-2018 02:04,22,0,SpendHQ,"Hello Spendhq-Team, This is to inform you that the alert regarding EBS High Disk Usage on prd-sv1 (10.59.100.193) got resolved and back to its normal state with the value of 76.62%.","Hello Spendhq-Team,The alert regarding EBS High Disk Usage on prd-sv1 (10.59.100.193) has exceeded the threshold value of 80 and reached 91%. Please find the usage details in the attachment section. Please zip/clean unwanted files.","Hello Team,Please find the detailed EBS High Disk Usage details in the attachment section.Kindly validate the details and zip/clean the unwanted files","Hello Team, This is to inform you that we have received an alert regarding EBS High Disk Usage on prd-sv1 (10.59.100.193) has exceeded the threshold value of 80 to 81.7%. Please find the resources details and disk usage below. Resource Details:- Instance ID: i-048e66836110e8d7bInstance Name: prd-sv1Private IP: 10.59.100.193We are analyzing this and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001CcF9r,Cloud Engineer Level 1,Closed,1056062,Incident,25-05-2017 12:35,,"Hello Team,This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address are10.59.5.111 and 10.59.1.167  which belongs to the Preview ELB.Please find the ELB logs details.1. 2017-05-25T05:47:06.531471Z preview-spendhq-xelb 93.174.93.136:46138 10.59.1.192:8080 0.000034 0.00161 0.000021 403 403 0 232 GET http://www.baidu.com:8080/cache/global/img/gs.gif HTTP/1.1 Mozilla -2. 2017-05-25T05:47:06.531471Z preview-spendhq-xelb 93.174.93.136:46138 10.59.1.192:8080 0.000034 0.00161 0.000021 403 403 0 232 GET http://www.baidu.com:8080/cache/global/img/gs.gif HTTP/1.1 Mozilla - -3. 2017-05-25T06:11:25.672478Z preview-spendhq-xelb 185.40.4.109:37130 10.59.1.192:80 0.000033 0.002082 0.000021 403 403 0 220 GET http://52.6.177.194:80/recordings/ HTTP/1.1 curl/7.29.0 - -4. 2017-05-25T06:11:25.685908Z preview-spendhq-xelb 185.40.4.109:37138 10.59.1.192:80 0.000017 0.001611 0.000016 403 403 0 209 GET http://52.6.177.194:80/ HTTP/1.1 curl/7.29.0 - -IP address Details:IP Address: 93.174.93.136Organization:  Quasi Networks LTD.Country: SeychellesIP Address:185.40.4.109Organization: MediaServicePlus LLCCountry: RussiaAs Andrew from SpeedHQ informs that no need to inform Intrusion Prevention Alert.So we are close this case.",1.Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41819Time...........: 2017-05-25 05:10:23Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 62852Destination IP address: 10.59.1.192 (spendhq)Destination port: 8080 (http-alt)2.Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-25 05:10:23Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 62852Destination IP address: 10.59.1.192 (spendhq)Destination port: 8080 (http-alt)--System Uptime      : 193 days 21 hours 25 minutesSystem Load        : 0.12System Version     : Sophos UTM 9.408-4Please refer to the manual for detailed instructions.3.Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41819Time...........: 2017-05-25 05:12:10Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.111Source port: 63622Destination IP address: 10.59.1.192 (spendhq)Destination port: 8080 (http-alt)4. Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-25 05:12:10Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.111Source port: 63622Destination IP address: 10.59.1.192 (spendhq)Destination port: 8080 (http-alt)--System Uptime      : 193 days 21 hours 26 minutesSystem Load        : 0.10System Version     : Sophos UTM 9.408-4,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,25-05-2017 11:48,1,0,SpendHQ,"Hello Team,This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address are10.59.5.111 and 10.59.1.167  which belongs to the Preview ELB.Please find the ELB logs details.1. 2017-05-25T05:47:06.531471Z preview-spendhq-xelb 93.174.93.136:46138 10.59.1.192:8080 0.000034 0.00161 0.000021 403 403 0 232 GET http://www.baidu.com:8080/cache/global/img/gs.gif HTTP/1.1 Mozilla -2. 2017-05-25T05:47:06.531471Z preview-spendhq-xelb 93.174.93.136:46138 10.59.1.192:8080 0.000034 0.00161 0.000021 403 403 0 232 GET http://www.baidu.com:8080/cache/global/img/gs.gif HTTP/1.1 Mozilla - -3. 2017-05-25T06:11:25.672478Z preview-spendhq-xelb 185.40.4.109:37130 10.59.1.192:80 0.000033 0.002082 0.000021 403 403 0 220 GET http://52.6.177.194:80/recordings/ HTTP/1.1 curl/7.29.0 - -4. 2017-05-25T06:11:25.685908Z preview-spendhq-xelb 185.40.4.109:37138 10.59.1.192:80 0.000017 0.001611 0.000016 403 403 0 209 GET http://52.6.177.194:80/ HTTP/1.1 curl/7.29.0 - -IP address Details:IP Address: 93.174.93.136Organization:  Quasi Networks LTD.Country: SeychellesIP Address:185.40.4.109Organization: MediaServicePlus LLCCountry: RussiaAs Andrew from SpeedHQ informs that no need to inform Intrusion Prevention Alert.So we are close this case.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001YLdZf,Cloud Engineer Level 1,Closed,1100870,Incident,29-06-2018 22:48,,"Hello Team,We have terminated the instances mentioned in the description. At this time we are marking this case as resolved and closing this case. Please let us know if you have any further queries.###Hello Team,We will work on this case and will get back to you with updates.","---------- Forwarded message ----------From: Allen Herrera <aherrera@spendhq.com>Date: Fri, Jun 29, 2018 at 8:50 PMSubject: Delete test automation serversTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Hey Reanplease delete the test automation servers below.Instance ID: i-0323db693c5312672 Private IP: 10.59.100.188Instance ID: i-03fe1454eb96251be   Private IP: 10.59.100.126Instance ID: i-000043e5d88d1d738   Private IP: 10.59.100.187Thank you*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Delete test automation servers,,29-06-2018 21:09,11,0,SpendHQ,"Hello Team,We have terminated the instances mentioned in the description. At this time we are marking this case as resolved and closing this case. Please let us know if you have any further queries.","Hello Team,We will work on this case and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001cHr3D,Cloud Engineer Level 1,Closed,1105298,Incident,04-10-2018 17:21,,"@Team,As per the updates from OPS call, I am closing this case.###Hello Matthew,We haven't heard back from you,There will be no effect for the scheduled AWS Direct Connect maintenance.Please let us know if you have any queries.Thanks.###Hello Matthew, We haven't heard back from you.There will be no effect. Please let us know if you have any queries related to it.###Hello Matthew,There will be no effect.Please let us know if you have any queries related to it.###Matthew Watts10:15 AM (2 minutes ago)to Rean, spendhq-support@reancloud.comWhat will this effect?###Hello SpendHQ-Team, This is to inform you that we received notification from AWS stating planned maintenance has been scheduled on an AWS Direct Connect router in Equinix Equinix DC2/DC11 Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 1Gbps may become unavailable. Connection name: SpendHQ Connection ID: dxcon-fg50qjyw Your Peer IP: 169.254.255.46/30 Amazon Peer IP: 169.254.255.45/30 AWS Scheduled Maintenance Window:- Start time: October 5, 2018 at 8:31:00 AM UTC+5:30 End time: October 5, 2018 at 1:31:00 PM UTC+5:30AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same.","Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. During this maintenance window, your AWS Direct Connect services associated with this event may become unavailable.This maintenance is scheduled to avoid disrupting redundant connections at the same time.If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED,,28-09-2018 07:41,154,0,SpendHQ,"@Team,As per the updates from OPS call, I am closing this case.","Hello Matthew,We haven't heard back from you,There will be no effect for the scheduled AWS Direct Connect maintenance.Please let us know if you have any queries.Thanks.","Hello Matthew, We haven't heard back from you.There will be no effect. Please let us know if you have any queries related to it.","Hello Matthew,There will be no effect.Please let us know if you have any queries related to it.","Matthew Watts10:15 AM (2 minutes ago)to Rean, spendhq-support@reancloud.comWhat will this effect?","Hello SpendHQ-Team, This is to inform you that we received notification from AWS stating planned maintenance has been scheduled on an AWS Direct Connect router in Equinix Equinix DC2/DC11 Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 1Gbps may become unavailable. Connection name: SpendHQ Connection ID: dxcon-fg50qjyw Your Peer IP: 169.254.255.46/30 Amazon Peer IP: 169.254.255.45/30 AWS Scheduled Maintenance Window:- Start time: October 5, 2018 at 8:31:00 AM UTC+5:30 End time: October 5, 2018 at 1:31:00 PM UTC+5:30AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Cdu8w,Cloud Engineer Level 1,Closed,1058407,Incident,01-06-2017 22:34,,"Hello SpendHQ Team, Since the issue is resolved and we are waiting for the reply from Andromeda team, we are closing this case and we will follow up in case id: 01058351###Hello Matthew,Thanks for the approval. We have gone ahead and restarted the DB05 instance. Now the /mnt/db_backup_04_24_17 is currently in the rw mode. Refer the details  below,[root@ip-10-59-10-135 ~]# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   26G   21G  56% /tmpfs          tmpfs  121G     0  121G   0% /dev/shm/dev/xvdf      ext4   2.0T  100G  1.8T   6% /mnt/drtest2016/dev/sdb       ext4   4.0T  2.3T  1.5T  61% /var/infobright/dev/sdc       ext4   4.0T  2.1T  1.8T  55% /mnt/db_backup-12-16-16/dev/sdb       ext4   4.0T  2.3T  1.5T  61% /mnt/db_backup_04_24_17/dev/sda       ext4   4.0T  1.6T  2.2T  43% /mnt/db_backup_02_02_2017[root@ip-10-59-10-135 ~]# cat /proc/mounts/dev/sdb /var/infobright ext4 rw,relatime,barrier=1,data=ordered 0 0/dev/sdc /mnt/db_backup-12-16-16 ext4 rw,relatime,barrier=1,data=ordered 0 0/dev/sdb /mnt/db_backup_04_24_17 ext4 rw,relatime,barrier=1,data=ordered 0 0/dev/sda /mnt/db_backup_02_02_2017 ext4 rw,relatime,barrier=1,data=ordered 0 0We have checked and validated these changes from our end. Please check and let us if you have any further queries. Meanwhile, we will also check along with Andromeda team regarding this ro issue and will get back to you with the details.Regards,Sumod.K.Bose###Hello Matthew,On further analysis, we came to figure out that the mount point /mnt/db_backup_04_24_17 has gone to read only mode. Refer the below details,[root@10 infobright]# df -hTFilesystem     Type   Size  Used Avail Use% Mounted on/dev/sdc       ext4   4.0T  2.3T  1.5T  61% /mnt/db_backup_04_24_17[root@10 infobright]# cat /proc/mounts/dev/sdc /mnt/db_backup_04_24_17 ext4 ro,relatime,barrier=1,data=ordered 0 0[root@10 infobright]# touch /mnt/db_backup_04_24_17/touch 1.txttouch: cannot touch `1.txt': Read-only file systemHere, we could see that the mount point /mnt/db_backup_04_24_17 has gone to read only mode. To resolve this scenario, we need to perform a  reboot action on the DB05 instance. Please let us know if we have the permission to move forward with the reboot activity on this instance. Let us know if you have any further queries.Regards,Sumod.K.Bose###Hello Matthew,We acknowledge the delivery of your email.We are currently working on getting the DB05 instance work with the ISCSI volume and we will try to complete it less than one hour. Let us know if your team have any further queries.Regards,Sumod.K.Bose","Please can we prioritize getting DB05 (10.59.10.135) back up and running with the ISCSI. Please advise on an ETA asap.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Database Issues,,31-05-2017 23:19,23,0,SpendHQ,"Hello SpendHQ Team, Since the issue is resolved and we are waiting for the reply from Andromeda team, we are closing this case and we will follow up in case id: 01058351","Hello Matthew,Thanks for the approval. We have gone ahead and restarted the DB05 instance. Now the /mnt/db_backup_04_24_17 is currently in the rw mode. Refer the details  below,[root@ip-10-59-10-135 ~]# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   26G   21G  56% /tmpfs          tmpfs  121G     0  121G   0% /dev/shm/dev/xvdf      ext4   2.0T  100G  1.8T   6% /mnt/drtest2016/dev/sdb       ext4   4.0T  2.3T  1.5T  61% /var/infobright/dev/sdc       ext4   4.0T  2.1T  1.8T  55% /mnt/db_backup-12-16-16/dev/sdb       ext4   4.0T  2.3T  1.5T  61% /mnt/db_backup_04_24_17/dev/sda       ext4   4.0T  1.6T  2.2T  43% /mnt/db_backup_02_02_2017[root@ip-10-59-10-135 ~]# cat /proc/mounts/dev/sdb /var/infobright ext4 rw,relatime,barrier=1,data=ordered 0 0/dev/sdc /mnt/db_backup-12-16-16 ext4 rw,relatime,barrier=1,data=ordered 0 0/dev/sdb /mnt/db_backup_04_24_17 ext4 rw,relatime,barrier=1,data=ordered 0 0/dev/sda /mnt/db_backup_02_02_2017 ext4 rw,relatime,barrier=1,data=ordered 0 0We have checked and validated these changes from our end. Please check and let us if you have any further queries. Meanwhile, we will also check along with Andromeda team regarding this ro issue and will get back to you with the details.Regards,Sumod.K.Bose","Hello Matthew,On further analysis, we came to figure out that the mount point /mnt/db_backup_04_24_17 has gone to read only mode. Refer the below details,[root@10 infobright]# df -hTFilesystem     Type   Size  Used Avail Use% Mounted on/dev/sdc       ext4   4.0T  2.3T  1.5T  61% /mnt/db_backup_04_24_17[root@10 infobright]# cat /proc/mounts/dev/sdc /mnt/db_backup_04_24_17 ext4 ro,relatime,barrier=1,data=ordered 0 0[root@10 infobright]# touch /mnt/db_backup_04_24_17/touch 1.txttouch: cannot touch `1.txt': Read-only file systemHere, we could see that the mount point /mnt/db_backup_04_24_17 has gone to read only mode. To resolve this scenario, we need to perform a  reboot action on the DB05 instance. Please let us know if we have the permission to move forward with the reboot activity on this instance. Let us know if you have any further queries.Regards,Sumod.K.Bose","Hello Matthew,We acknowledge the delivery of your email.We are currently working on getting the DB05 instance work with the ISCSI volume and we will try to complete it less than one hour. Let us know if your team have any further queries.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DHEWI,Cloud Engineer Level 1,Closed,1063407,Incident,18-06-2017 09:57,,This was related to the change case 01063190 and communicated over there.,"Sat, 17 Jun 2017 23:48:38 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Atlanta-B US, Frankfurt DE, London UK, Dallas-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,18-06-2017 09:18,1,0,SpendHQ,This was related to the change case 01063190 and communicated over there.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DHxpg,Cloud Engineer Level 1,Closed,1063918,Incident,21-06-2017 06:10,,"Hello Team, The alert related volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume  got resolved and returned to normal value of 57%.###Hello Team, This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% and reached to a value of 99%. We are analyzing the disk usage details and will share it with you shortly.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Tue, Jun 20, 2017 at 11:40 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjT0LwyAYhH9N3Cqv-ibVwSEkLYXOHdqlWDUfkESbmKH_vgaO4-Hg7pwu1ceTUXNgZ6iyS1BYUgZCAqN1i7KSF5Rtw1tRqwLBJddTG8igvYTKqu4jhOuMRcVRcu7RGyM5ogcy6SGluBWiLvg1y8RInUnGhX745o35yKwN-5IyxTV04-Qz7Sd4QfO-_54PdtvJquctH6_eLHYKuzuaJOk5LGMK6x9MtjpT>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj8uOgzAMRb8mLCPnSbzIApXhN0YhSQGpNBTSaj5_DJrFSJYf1_LRdfIGx9wsXoJowVJ2gNpwAcqB4F2vnXVf2vU32asOmYZU08RjaWYPNtlksrkHM7ZtEMpkqVHrmMDGOELz8HOt28FUx-RAEbaNp1BDKtP8IsZK2lqeSy37waSSIBVaZGqo5bvSWS80tuikUAgATNppL--N9JQ_S8xMmpNs5EDzVX8-KYizu83lqNdeADdI73CyR4T7Xtb_bMCL3ex-Pei5PYdnfJR3Ot011f-5-wVMn1Mj>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Tue Jun 20 2017 18:09:00 UTC (*44 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtTsuOgzAM_JrkGNnOg-SQAyrLf2RxFpBKQyGt9vM3VCtZ4xlbmhmONnxnuUYC7MA19BCMVQjaA6p-MN75L-OHGw26D8IAV57VVOQSWXv-CdZ6zp4oZejQcc7kESeXOyPvcal1P4XuBY1t0r4rTjVxmZdn89jabSuPtZbjFKQJSAcXhB7no7x2oQfO73XKguzlYGls-rN_35zwYrelnPXzR1A2tNoKtZVH3M5W9cjpMd3Li68sWeN_1h_8p0ZE>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjcsKwyAURL9Gl3K9Gh8LF6Fp_-NGzQOSmCb2_2uhMMziwJlJofNj5mtAkBZMawded0KCciBFP2hn3FO74YGD6j3TkGqaRSx8CXaiESkaaz2qzqpJYjQJfAuNljLfwlLreTPVM3y10HmKRJVSmZd329gb28ux1nLdDBUCKm98gzmtlV9hv9vflemIW_mkn8Br-AtfLLc2lg>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVTkkOhCAQfA0cCavCgYMZx380Ni7JKA62_x8mqVQqldSC0YWU-R61VL3sGnsZrBNKGi-VGEbrO_-2fnzp0QyBWYmEq5gL32IKDr3yLnmA1KSWgLlbFpNsrzQu_BM3outmZmB6aoDrEggEWNbt2zqO5u3nUuGm-sz01MzMtJWbTjiaHJUULrQrQhnHazzuNl8znPOnPPjPc4pHOXcq9QfaWDwt>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jc0OgyAQhJ9GjgbYVdgDB1Pqe6CLP4mKVdrnL700mcwkXzIz7BoaolidlsrItriVhE2tJFip6s6jbe0TrX9oDx1VKDnzXI9JLM5gQGPCRDypcVS6ZRUjTgMxGGKLYnNLzuddQVfpviicZ80hB07z8iobe2HxE4_8T-hXrsADaaUaQttYCUSgEcXl9rvcXzEc45be_OuL7PZ0rDldX1XOOfA>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjUkOwyAUQ08Tlog5sGARNe09fvhkkBqghNy_RLIs68my0Wu3RHJ4wfjITHfLnNKUM2kZp9OsrLFvZeeXmOXkBsWw4UZDJrsHh9wFhxpWLU2IoOUyOmYcRiGUAvL1e2vlGuQ0iE8XlEIRGmDe9l_fOB8WQr5T66nUuMYaU4gXqf68-leNkMI33_iUSfNnTkfL9Q-hNDcC>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,21-06-2017 01:26,5,0,SpendHQ,"Hello Team, The alert related volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume  got resolved and returned to normal value of 57%.","Hello Team, This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% and reached to a value of 99%. We are analyzing the disk usage details and will share it with you shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ETHvO,Cloud Engineer Level 1,Closed,1067271,Incident,10-07-2017 10:09,,"Hello SpendHQ Team, This is to notify you that we have received an alert that the network outbound for prod-sphq-db-server05 is above the threshold of 2220000000.0.The alert got resolved within few minutes and returned to normal. Resource details: Instance Name - prod-sphq-db-server05 Instance ID - i-008d43ad00357e47a VPC ID - vpc-76df7212 Instance type - r3.8xlarge","[Triggered] [SpendHQ] - High Network OUT on host - prod-sphq-db-server05 - 10.59.10.135 - db Status  High Network OUT on the instance. Please check the list open TCP Connections    @support@reancloud.comaws.ec2.network_out over host:10.59.10.135,monitoring:on was > 2220000000.0 at all times during the last 5m.Metric value: 9042123776.0This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024199?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2024199/edit · Event URL: https://app.datadoghq.com/event/event?id=3949278403019451148 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - prod-sphq-db-server05 - 10.59.10.135 - db Status,,10-07-2017 09:13,1,0,SpendHQ,"Hello SpendHQ Team, This is to notify you that we have received an alert that the network outbound for prod-sphq-db-server05 is above the threshold of 2220000000.0.The alert got resolved within few minutes and returned to normal. Resource details: Instance Name - prod-sphq-db-server05 Instance ID - i-008d43ad00357e47a VPC ID - vpc-76df7212 Instance type - r3.8xlarge",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001J33vC,Cloud Engineer Level 1,Closed,1082502,Incident,19-10-2017 20:35,,"Hello Andrew,AWS Team has increased the limit to 30. We have also verified from our end. As the limit got increased, we are marking this case as resolved. Please let us know if you have any queries.###Hello,PJ here from AWS billing and accounts.I trust this email finds you well.I’m happy to inform you that we've approved and processed your limit increase request and your new limit is 30 Please keep in mind that it can sometimes take up to 15 minutes for this to propagate and become available for use.Best regards,PJAmazon Web Services###Hello Andrew,I have placed an AWS support case requesting to increase the AWS IAM Server certificates limits from 20 to 30. We will update you once this is completed. Please let me know if you have any further queries.AWS Case ID: 4557587461Thank You,Safuvan KM###AWS Support case: 4557587461Limit increase request 1Service: IAM Groups and UsersLimit name: Server Certificate LimitNew limit value: 30------------Use case description: Hello AWS Team,Greetings from REANCloud,Could you please increase the AWS IAM Server certificates limits from 20 to 30? Please let me know if you have any queries about this.Thank You,Safuvan KM###Andrew Kim7:56 PM (0 minutes ago)to Rean, spendhq-support Perfect. I believe we should only have two active SSL certificates*.spendhq.comsecure.spendhq.com Since there is no additional cost, please increate the limit to 30. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Please find the list of Server Certificate that currently being uploaded/used in AWS IAM.            ServerCertificateId: ASCAIKXODI7A2LLLU3KR2,            ServerCertificateId: ASCAI2TDPINRXEGNTM5DY,            ServerCertificateId: ASCAJCCXHZGHEZW23QRKM,            ServerCertificateId: ASCAJCUJT4LBSY7W374Z6,            ServerCertificateId: ASCAJD4C23MDX7M2EEIVA,            ServerCertificateId: ASCAJ7PIZNLUU5IHCWLAK,            ServerCertificateId: ASCAIUREVKOPCRSNMXSRO,            ServerCertificateId: ASCAJ745TXVHBYXDTTEUU,            ServerCertificateId: ASCAJ542S6OQV3P3Q2GFM,            ServerCertificateId: ASCAIHUB2E3GKIQGDNFCK,            ServerCertificateId: ASCAIETKHW76TDF3KYBY4,            ServerCertificateId: ASCAIFVRWNS46SGEDM72C,            ServerCertificateId: ASCAJG4QA6BACUTPOZ2O2,            ServerCertificateId: ASCAI7NDGXECJULSVUY66,            ServerCertificateId: ASCAIVKHMMRHI5U6KCKBU,            ServerCertificateId: ASCAJ3ZTGOY45DOQOSPNA,Please refer the attachment section for the metadata list of the currently uploaded Server Certificates.Thank You,Safuvan KM###Hello Andrew,>>What does the IAM Server Certificate do/used for?IAM Server Certificate is used to store the SSL/TLS server certificate to enable HTTPS connections to your website or application in AWS.>>Is there an additional cost?There is no cost to use IAM to store and deploy server certificates. You pay only for your certificate you should obtain from an external provider for use with AWS and the AWS resources you create to run your application.>>What is the recommended new value?It is dependent on your requirement. Only If you are planning to provision more web servers in future and also they require to have more SSL/TLS certificates than you currently have, we suggest to keep it to a higher value to avoid any blockers or delay at that time. There is no security or cost factor associated with increasing the limit. I suggest 30 would be sufficient.Thank You,Safuvan KM###Can you provide additional information?    What does the IAM Server Certificate do/used for?    Is there an additional cost?    What is the recommended new value?Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hello SpendHq Team,We have received an AWS warning notification that the IAM Server Certificate has almost reached its limit.The Current value is 16 and limit value 20.Please let us know if we can increse the limit for the resource.","Thanks & Regards,Gourav PokhraREĀN Cloud Solutions | Reach, Engage, Activate, Nurture4th Floor, 26, Tulsi Complex,100 Feet Road, New BhupalpuraUdaipur, Rajasthan 313001Gourav.pokhra@reancloud.com |+918696096500| www.reancloud.com<http://www.reancloudsolutions.com/>Toll-Free Number: +12015828406---------- Forwarded message ----------From: AWS-Limit <no-reply@sns.amazonaws.com>Date: Thu, Oct 19, 2017 at 3:00 PMSubject: REAN CLOUD AWS limit checker ALERT for spendhq - WARNINGTo: ms@reancloud.comBelow are resource details that cross limitsREGION       RESOURCE   LIMIT          USAGE          SERVICE-               IAM               20              16              Servercertificates--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-west-2.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-west-2:210278571640:AWS-Limit:1217fddf-d8e0-4042-af10-1de467aaca07&Endpoint=ms@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: REAN CLOUD AWS limit checker ALERT for spendhq - WARNING,,19-10-2017 15:35,5,0,SpendHQ,"Hello Andrew,AWS Team has increased the limit to 30. We have also verified from our end. As the limit got increased, we are marking this case as resolved. Please let us know if you have any queries.","Hello,PJ here from AWS billing and accounts.I trust this email finds you well.I’m happy to inform you that we've approved and processed your limit increase request and your new limit is 30 Please keep in mind that it can sometimes take up to 15 minutes for this to propagate and become available for use.Best regards,PJAmazon Web Services","Hello Andrew,I have placed an AWS support case requesting to increase the AWS IAM Server certificates limits from 20 to 30. We will update you once this is completed. Please let me know if you have any further queries.AWS Case ID: 4557587461Thank You,Safuvan KM","AWS Support case: 4557587461Limit increase request 1Service: IAM Groups and UsersLimit name: Server Certificate LimitNew limit value: 30------------Use case description: Hello AWS Team,Greetings from REANCloud,Could you please increase the AWS IAM Server certificates limits from 20 to 30? Please let me know if you have any queries about this.Thank You,Safuvan KM","Andrew Kim7:56 PM (0 minutes ago)to Rean, spendhq-support Perfect. I believe we should only have two active SSL certificates*.spendhq.comsecure.spendhq.com Since there is no additional cost, please increate the limit to 30. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Please find the list of Server Certificate that currently being uploaded/used in AWS IAM.            ServerCertificateId: ASCAIKXODI7A2LLLU3KR2,            ServerCertificateId: ASCAI2TDPINRXEGNTM5DY,            ServerCertificateId: ASCAJCCXHZGHEZW23QRKM,            ServerCertificateId: ASCAJCUJT4LBSY7W374Z6,            ServerCertificateId: ASCAJD4C23MDX7M2EEIVA,            ServerCertificateId: ASCAJ7PIZNLUU5IHCWLAK,            ServerCertificateId: ASCAIUREVKOPCRSNMXSRO,            ServerCertificateId: ASCAJ745TXVHBYXDTTEUU,            ServerCertificateId: ASCAJ542S6OQV3P3Q2GFM,            ServerCertificateId: ASCAIHUB2E3GKIQGDNFCK,            ServerCertificateId: ASCAIETKHW76TDF3KYBY4,            ServerCertificateId: ASCAIFVRWNS46SGEDM72C,            ServerCertificateId: ASCAJG4QA6BACUTPOZ2O2,            ServerCertificateId: ASCAI7NDGXECJULSVUY66,            ServerCertificateId: ASCAIVKHMMRHI5U6KCKBU,            ServerCertificateId: ASCAJ3ZTGOY45DOQOSPNA,Please refer the attachment section for the metadata list of the currently uploaded Server Certificates.Thank You,Safuvan KM","Hello Andrew,>>What does the IAM Server Certificate do/used for?IAM Server Certificate is used to store the SSL/TLS server certificate to enable HTTPS connections to your website or application in AWS.>>Is there an additional cost?There is no cost to use IAM to store and deploy server certificates. You pay only for your certificate you should obtain from an external provider for use with AWS and the AWS resources you create to run your application.>>What is the recommended new value?It is dependent on your requirement. Only If you are planning to provision more web servers in future and also they require to have more SSL/TLS certificates than you currently have, we suggest to keep it to a higher value to avoid any blockers or delay at that time. There is no security or cost factor associated with increasing the limit. I suggest 30 would be sufficient.Thank You,Safuvan KM","Can you provide additional information?    What does the IAM Server Certificate do/used for?    Is there an additional cost?    What is the recommended new value?Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Hello SpendHq Team,We have received an AWS warning notification that the IAM Server Certificate has almost reached its limit.The Current value is 16 and limit value 20.Please let us know if we can increse the limit for the resource.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TmYvv,Cloud Engineer Level 1,Closed,1094644,Incident,30-03-2018 21:07,,"Hello Andrew,Thanks for the update.We are closing this case.###Andrew Kim9:04 PM (0 minutes ago)to Rean, spendhq-support Thank you. We have put in a temporary bypass. You can close this ticket.###Hello SpendHQ-Team, This is to notify you that the SES Daily sending quota has reached the limit. Please find the sending statistics details below:Sending Quota:	send 100000 emails per 24 hour periodQuota Used:	100% as of 2018-03-30 18:08 UTC+5:30Max Send Rate:	28 emails/secondLast updated:	2018-03-30 18:08 UTC+5:30Current usage seems to be 105498Please let us know if you want us know to increase the limit.","-- REĀN Cloud | Reach, Engage, Āctivate, NurtureOn Fri, Mar 30, 2018 at 3:00 PM, AWS-Limit <no-reply@sns.amazonaws.com>wrote:> Below are resource details that cross limits>> REGION       RESOURCE   LIMIT          USAGE          SERVICE> us-east-1       SES               100000          105498          Daily> sending quota>> --> If you wish to stop receiving notifications from this topic, please click> or visit the link below to unsubscribe:> https://sns.us-west-2.amazonaws.com/unsubscribe.> html?SubscriptionArn=arn:aws:sns:us-west-2:210278571640:> AWS-Limit:1217fddf-d8e0-4042-af10-1de467aaca07&Endpoint=ms@reancloud.com>> Please do not reply directly to this email. If you have any questions or> comments regarding this email, please contact us at> https://aws.amazon.com/support>-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: REAN CLOUD AWS limit checker ALERT for spendhq - WARNING,,30-03-2018 15:06,6,0,SpendHQ,"Hello Andrew,Thanks for the update.We are closing this case.","Andrew Kim9:04 PM (0 minutes ago)to Rean, spendhq-support Thank you. We have put in a temporary bypass. You can close this ticket.","Hello SpendHQ-Team, This is to notify you that the SES Daily sending quota has reached the limit. Please find the sending statistics details below:Sending Quota:	send 100000 emails per 24 hour periodQuota Used:	100% as of 2018-03-30 18:08 UTC+5:30Max Send Rate:	28 emails/secondLast updated:	2018-03-30 18:08 UTC+5:30Current usage seems to be 105498Please let us know if you want us know to increase the limit.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001V9led,Cloud Engineer Level 1,Closed,1097335,Incident,25-04-2018 22:43,,"We got an update from AWS ream stating that between 11:15 AM and 12:48 PM PDT, they experienced delays in connection provisioning and delivery of CloudWatch Metrics for some AWS Direct Connect customers in US-EAST-1. The issue has been resolved and the service is operating normally. We assumed that because that this alert got triggered.Email subj: AWS_DIRECTCONNECT_OPERATIONAL_ISSUE###Need to analyze this case.","---------- Forwarded message ----------From: SPHQ-DXMon <no-reply@sns.amazonaws.com>Date: Wed, Apr 25, 2018 at 12:43 AMSubject: OK: DX-ConnectionBpsIngress-SpendHQ-Equinix-1Gb in US East (N.Virginia)To: spendhq-support@reancloud.comYou are receiving this email because your Amazon CloudWatch AlarmDX-ConnectionBpsIngress-SpendHQ-Equinix-1Gb in the US East (N. Virginia)region has entered the OK state, because Threshold Crossed: 1 datapoint[0.0 (24/04/18 19:08:00)] was not greater than or equal to the threshold(6.0E8). at Tuesday 24 April, 2018 19:13:59 UTC.View this alarm in the AWS Management Console:https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#s=Alarms&alarm=DX-ConnectionBpsIngress-SpendHQ-Equinix-1GbAlarm Details:- Name:                       DX-ConnectionBpsIngress-SpendHQ-Equinix-1Gb- Description:                The bit rate for inbound data to the AWS sideof the connection.- State Change:               INSUFFICIENT_DATA -> OK- Reason for State Change:    Threshold Crossed: 1 datapoint [0.0 (24/04/1819:08:00)] was not greater than or equal to the threshold (6.0E8).- Timestamp:                  Tuesday 24 April, 2018 19:13:59 UTC- AWS Account:                261234435984Threshold:- The alarm is in the ALARM state when the metric isGreaterThanOrEqualToThreshold 6.0E8 for 300 seconds.Monitored Metric:- MetricNamespace:                     AWS/DX- MetricName:                          ConnectionBpsIngress- Dimensions:                          [ConnectionId = dxcon-fg50qjyw]- Period:                              300 seconds- Statistic:                           Average- Unit:                                not specifiedState Change Actions:- OK: [arn:aws:sns:us-east-1:261234435984:SpendHQ-DirectConnect-Cloudwatch-Monitoring]- ALARM:- INSUFFICIENT_DATA:--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQ-DirectConnect-Cloudwatch-Monitoring:24ff3fa5-5763-4bc5-b430-6ec72c0bae22&Endpoint=spendhq-support@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support--  <http://go.reancloud.com/gartner-magic-quadrant>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: OK: DX-ConnectionBpsIngress-SpendHQ-Equinix-1Gb in US East (N. Virginia),,25-04-2018 18:05,12,0,SpendHQ,"We got an update from AWS ream stating that between 11:15 AM and 12:48 PM PDT, they experienced delays in connection provisioning and delivery of CloudWatch Metrics for some AWS Direct Connect customers in US-EAST-1. The issue has been resolved and the service is operating normally. We assumed that because that this alert got triggered.Email subj: AWS_DIRECTCONNECT_OPERATIONAL_ISSUE",Need to analyze this case.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XxrIM,Cloud Engineer Level 1,Closed,1100518,Incident,27-06-2018 02:39,,"Hello Andrew,Thanks for the update, feel free to contact us again in case of any further queries.###Thank you. The only thing we saw was a space at the end of the Initiator Name which we changed. Other than that, everything looks good.You can close this case.Andrew Kim###Hello Andrew,This is the gentle reminder.We have changed the initiatorName on 10.59.10.180 server. Please check and let us know if you have any queries.###We have changed the initiatorName on 10.59.10.180 server. Waiting an confirmation from client###Allen Herrera2:53 AM (11 minutes ago)to Rean, Matthew Looks good now – Andrew will email about changing the iqn###Hello Andrew,We have changed the initiatorName on 10.59.10.180 server. Please check and let us know if you have any queries.###Andrew Kim2:55 AM (0 minutes ago)to Rean, spendhq-support REAN – we believe the reason the volume continues to move into a “Read-Only” mode is because the iscsi initiator name is the same on 10.59.10.180 and 10.59.10.68 and may be causing a conflict on the JetStor and Nimble SANs. We recommend changing the iscsi initiator name on 10.59.10.180/etc/iscsi/initiatorname.iscsisudo service iscsid restart Please change the iscsi initiator name on 10.59.10.180 – please change to: InitiatorName=iqn.1994-05.com.redhat:8af27b9bf2b Thank you,###Hello Allen,We unmounted, remounted it again and we tested it from our end. Please check from your end and let us know if you are still facing any issues.###Hello AllenWe are checking on this issue and will get back to you with the feedback ASAP###REAN,Please treat this as a SEV ONE and resolve immediately. Once resolved I would like an explanation as to why this keeps happening.Matthew Watts | Manager, Application Development | SpendHQ®###Hey Reanthe same mount went into read only mode again. Can we get this remounted ASAP. I need to get critical work done tonight. Server: 10.59.10.180Mount:     /dev/sdg        4.0T  2.9G  3.8T   1% /usr/local/mariadbAllen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###As of now, we are marking this case as closed###Hi Allen,Thanks for the update. Please reach to us if you have any queries.###From Allen HerreraLooks good so far. Ill reach out when it happens again … because it’s happening quite often. I’ll need quick response times if it does because this is very high priority work.Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###Hello Allen,We haven't heard back from you.We have killed all processes folding the volume. We unmounted, remounted it again and we tested it from our end. Please check from your end and let us know if you are still facing any issues.###Hello Allen,We have killed all processes folding the volume. We unmounted, remounted it again and we tested it from our end. Please check from your end and let us know if you are still  facing any issues.###Hello Allen,We are checking and will let you know the update.###Allen Herrera9:03 AM (1 hour ago)to Rean, spendhq-support It’s in read only mode again. Please remount and kill any processes keeping the device busy.###Hello Allen,We have re-mounted the volume again on the server 10.59.10.180. Please check and verify from your end.Kindly reach out to us if you have any issue.###Hello Matthew,Thanks for the update.We will work on this request and will let you know the update.###Matthew Watts10:38 PM (5 minutes ago)to Rean, spendhq-support You don’t need to kill the machine. Just run lsof and grep the volume and then kill the process.Please advise once this is done and please no not restart the machine###Hello Allen,We have unmounted the disk and tried to back it mount as rw mode but we are unable to mount it back and it is showing that the device is busy. Could you please provide us with an approval to reboot the machine so that we can mount the device back.###Hello Allen,Thanks for the update. We will kill the mentioned running processes and re-mount the volume in the server 10.59.10.180###Allen Herrera9:24 PM (2 minutes ago)to Rean, spendhq-support Yeah kill the processes. Sorry for the delayed response.###Hello Allen,We have checked that some processes are using the directory /usr/local/mariadb. Please give us the approval to stop these process or please stop the process from your end so that we can re-mount the volume again in the server 10.59.10.180 Please find the running processes details in the attachment section.###Hello Allen,We will work on this and let you know the update.","I need immediate help to resolve a read only mount on 10.59.10.180The mount is/dev/sdg        4.0T   12G  3.8T   1% /usr/local/mariadbPlease reattach asap and make sure the mount is writable.*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Mount ins read only 10.59.10.180,,22-06-2018 19:50,103,0,SpendHQ,"Hello Andrew,Thanks for the update, feel free to contact us again in case of any further queries.","Thank you. The only thing we saw was a space at the end of the Initiator Name which we changed. Other than that, everything looks good.You can close this case.Andrew Kim","Hello Andrew,This is the gentle reminder.We have changed the initiatorName on 10.59.10.180 server. Please check and let us know if you have any queries.",We have changed the initiatorName on 10.59.10.180 server. Waiting an confirmation from client,"Allen Herrera2:53 AM (11 minutes ago)to Rean, Matthew Looks good now – Andrew will email about changing the iqn","Hello Andrew,We have changed the initiatorName on 10.59.10.180 server. Please check and let us know if you have any queries.","Andrew Kim2:55 AM (0 minutes ago)to Rean, spendhq-support REAN – we believe the reason the volume continues to move into a “Read-Only” mode is because the iscsi initiator name is the same on 10.59.10.180 and 10.59.10.68 and may be causing a conflict on the JetStor and Nimble SANs. We recommend changing the iscsi initiator name on 10.59.10.180/etc/iscsi/initiatorname.iscsisudo service iscsid restart Please change the iscsi initiator name on 10.59.10.180 – please change to: InitiatorName=iqn.1994-05.com.redhat:8af27b9bf2b Thank you,","Hello Allen,We unmounted, remounted it again and we tested it from our end. Please check from your end and let us know if you are still facing any issues.",Hello AllenWe are checking on this issue and will get back to you with the feedback ASAP,"REAN,Please treat this as a SEV ONE and resolve immediately. Once resolved I would like an explanation as to why this keeps happening.Matthew Watts | Manager, Application Development | SpendHQ®",Hey Reanthe same mount went into read only mode again. Can we get this remounted ASAP. I need to get critical work done tonight. Server: 10.59.10.180Mount:     /dev/sdg        4.0T  2.9G  3.8T   1% /usr/local/mariadbAllen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com,"As of now, we are marking this case as closed","Hi Allen,Thanks for the update. Please reach to us if you have any queries.",From Allen HerreraLooks good so far. Ill reach out when it happens again … because it’s happening quite often. I’ll need quick response times if it does because this is very high priority work.Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com,"Hello Allen,We haven't heard back from you.We have killed all processes folding the volume. We unmounted, remounted it again and we tested it from our end. Please check from your end and let us know if you are still facing any issues.","Hello Allen,We have killed all processes folding the volume. We unmounted, remounted it again and we tested it from our end. Please check from your end and let us know if you are still  facing any issues.","Hello Allen,We are checking and will let you know the update.","Allen Herrera9:03 AM (1 hour ago)to Rean, spendhq-support It’s in read only mode again. Please remount and kill any processes keeping the device busy.","Hello Allen,We have re-mounted the volume again on the server 10.59.10.180. Please check and verify from your end.Kindly reach out to us if you have any issue.","Hello Matthew,Thanks for the update.We will work on this request and will let you know the update.","Matthew Watts10:38 PM (5 minutes ago)to Rean, spendhq-support You don’t need to kill the machine. Just run lsof and grep the volume and then kill the process.Please advise once this is done and please no not restart the machine","Hello Allen,We have unmounted the disk and tried to back it mount as rw mode but we are unable to mount it back and it is showing that the device is busy. Could you please provide us with an approval to reboot the machine so that we can mount the device back.","Hello Allen,Thanks for the update. We will kill the mentioned running processes and re-mount the volume in the server 10.59.10.180","Allen Herrera9:24 PM (2 minutes ago)to Rean, spendhq-support Yeah kill the processes. Sorry for the delayed response.","Hello Allen,We have checked that some processes are using the directory /usr/local/mariadb. Please give us the approval to stop these process or please stop the process from your end so that we can re-mount the volume again in the server 10.59.10.180 Please find the running processes details in the attachment section.","Hello Allen,We will work on this and let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hQHFM,Cloud Engineer Level 1,Closed,1110077,Incident,01-01-2019 17:02,,"Hello Team,Since this alert is recovered we are marking this case as closed.As per your request, we are keeping a close eye on it and will update you if it occurs again.Let us know if you have any concerns.Thanks.###Hello Matt,This is to let you know that this alert recovered and has been in OK state.Kindly let us know if we are good with closing this case.Thanks.###Hi Matthew,Thanks for the quick response.The alert has currently recovered and in okay state. The violation lasted 49 minutes.Thanks.###Matthew Watts8:09 PM (2 minutes ago)to Rean, spendhq-support@reancloud.comAcknowledged. Please keep us updated if this does not go down over the 15 minutes interval.###Hello Team,We have analyzed the issue and from the instance level we could see the process PrimProc consuming the most CPU with about 1442% of the total CPU usage.The average CPU load is also relatively high hitting 34.13, 33.19 and 31.14 percent over a 1, 5 and 15 minute interval.top - 16:50:35 up 16 days, 18:17,  1 user,  load average: 34.13, 33.19, 31.14Tasks: 202 total,   5 running, 197 sleeping,   0 stopped,   0 zombie%Cpu(s): 97.7 us,  1.6 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.7 si,  0.0 stKiB Mem : 13035632+total,   690688 free, 68269392 used, 61396244 buff/cacheKiB Swap:        0 total,        0 free,        0 used. 60766884 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                                                                                                     1150 root      19  -1   98.4g  61.9g  55688 S  1442 49.8   1471:48 PrimProc                                                                                                                                                                                                   27636 root      20   0   30296   4160   1136 R  31.6  0.0   0:01.71 semodule                                                                                                                                                                                                     860 root      20   0  669968  99776  62440 R  26.3  0.1   6:18.20 workernode                                                                                                                                                                                                     1 root      20   0   55292   7340   3868 S   0.0  0.0  22:12.68 systemd                                                                                                                                                                                                        2 root      20   0       0      0      0 S   0.0  0.0   0:00.44 kthreadd                                                                                                                                                                                                       3 root      20   0       0      0      0 S   0.0  0.0   0:03.75 ksoftirqd/0                                                                                                                                                                                                    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H  To get an overview of what PrimProc is; It is the Primary Process, or PrimProc and handles query execution. The User Modules process queries from the application into instructions that are sent to the Performance Module. PrimProc executes these instructions as block oriented I/O operations to perform predicate filtering, join processing, and the initial aggregation of data, after which PrimProc sends the data back to the User Module.Please review these and let us know if you are performing any activities on your side.See the attachment section for full CPU utilization details and let us know if you have any concerns.Thanks.###Hello Team,This is to notify you that we have received an alert regarding High CPU Utilization on the host sphq-db1-20180830 - 10.59.10.26. CPU usage on the server has exceeded the set threshold of 90% reaching up to 100%.We are analyzing the issue and will get back with an update.---Resource Details:---Instance Name: SPHQ-DB1-20180830Instance ID: i-009c4b64628c39954Private IP: 10.59.10.26Instance Type: r5.4xlargeAvailability Zone: us-east-1bVPC ID: vpc-76df7212Subnet ID: subnet-0fdde924--Thanks.","---------- Forwarded message ---------From: Datadog Alerting <alert@dtdg.co>Date: Mon, Dec 31, 2018 at 7:09 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on thehost sphq-db1-20180830 - 10.59.10.26 -To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High CPU Utilization on the host sphq-db1-20180830- 10.59.10.26 -High CPU Utilization on the host. Log in to the machine and verify whichprocess is consuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024189?to_ts=1546272559000&group=host%3Ai-009c4b64628c39954&from_ts=1546265359000>avg(last_30m):avg:system.cpu.stolen{datadog_monitor:on} by {host} +avg:system.cpu.user{datadog_monitor:on} by {host} +avg:system.cpu.system{datadog_monitor:on} by {host} > 85The monitor was last triggered at Mon Dec 31 2018 16:09:29 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024189?group=host%3Ai-009c4b64628c39954>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024189/edit>] · [Viewi-009c4b64628c39954<https://app.datadoghq.com/infrastructure?filter=i-009c4b64628c39954>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1546272689000&tags=host%3Ai-009c4b64628c39954&from_ts=1546271669000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4731337741055869386>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on the host sphq-db1-20180830 - 10.59.10.26 -,,31-12-2018 22:21,19,0,SpendHQ,"Hello Team,Since this alert is recovered we are marking this case as closed.As per your request, we are keeping a close eye on it and will update you if it occurs again.Let us know if you have any concerns.Thanks.","Hello Matt,This is to let you know that this alert recovered and has been in OK state.Kindly let us know if we are good with closing this case.Thanks.","Hi Matthew,Thanks for the quick response.The alert has currently recovered and in okay state. The violation lasted 49 minutes.Thanks.","Matthew Watts8:09 PM (2 minutes ago)to Rean, spendhq-support@reancloud.comAcknowledged. Please keep us updated if this does not go down over the 15 minutes interval.","Hello Team,We have analyzed the issue and from the instance level we could see the process PrimProc consuming the most CPU with about 1442% of the total CPU usage.The average CPU load is also relatively high hitting 34.13, 33.19 and 31.14 percent over a 1, 5 and 15 minute interval.top - 16:50:35 up 16 days, 18:17,  1 user,  load average: 34.13, 33.19, 31.14Tasks: 202 total,   5 running, 197 sleeping,   0 stopped,   0 zombie%Cpu(s): 97.7 us,  1.6 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.7 si,  0.0 stKiB Mem : 13035632+total,   690688 free, 68269392 used, 61396244 buff/cacheKiB Swap:        0 total,        0 free,        0 used. 60766884 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                                                                                                     1150 root      19  -1   98.4g  61.9g  55688 S  1442 49.8   1471:48 PrimProc                                                                                                                                                                                                   27636 root      20   0   30296   4160   1136 R  31.6  0.0   0:01.71 semodule                                                                                                                                                                                                     860 root      20   0  669968  99776  62440 R  26.3  0.1   6:18.20 workernode                                                                                                                                                                                                     1 root      20   0   55292   7340   3868 S   0.0  0.0  22:12.68 systemd                                                                                                                                                                                                        2 root      20   0       0      0      0 S   0.0  0.0   0:00.44 kthreadd                                                                                                                                                                                                       3 root      20   0       0      0      0 S   0.0  0.0   0:03.75 ksoftirqd/0                                                                                                                                                                                                    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H  To get an overview of what PrimProc is; It is the Primary Process, or PrimProc and handles query execution. The User Modules process queries from the application into instructions that are sent to the Performance Module. PrimProc executes these instructions as block oriented I/O operations to perform predicate filtering, join processing, and the initial aggregation of data, after which PrimProc sends the data back to the User Module.Please review these and let us know if you are performing any activities on your side.See the attachment section for full CPU utilization details and let us know if you have any concerns.Thanks.","Hello Team,This is to notify you that we have received an alert regarding High CPU Utilization on the host sphq-db1-20180830 - 10.59.10.26. CPU usage on the server has exceeded the set threshold of 90% reaching up to 100%.We are analyzing the issue and will get back with an update.---Resource Details:---Instance Name: SPHQ-DB1-20180830Instance ID: i-009c4b64628c39954Private IP: 10.59.10.26Instance Type: r5.4xlargeAvailability Zone: us-east-1bVPC ID: vpc-76df7212Subnet ID: subnet-0fdde924--Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001GGuQ6,Cloud Engineer Level 1,Closed,1073752,Incident,18-08-2017 19:44,,"Hello Allen,Thanks for joining the call.As you have updated that your issue got resolved, we are marking this case as closed. Please revert back to us in case of further queries.###Hello Allen,Please use the following bridge details to get on a call at 10 AM EST hours to discussing the issue.URL: https://reancloud.zoom.us/my/engg1Phone: +14086380968Code: 5535058879###Hello Allen,We will be available for a web conference to discuss this issue at 18th August 2017 10 AM EST (7.30 PM IST). We will share a calendar invite with the bridge details.","Hey Rean we are having issues with our 10.59.10.20 box (maybe tomcat?) and the ELB/domain lp.spendhq.comWhen using the ELB to connect our Navigator app into our SpendHQ app, we get errors that don't appear when we simply connect directly with the ip address. Can we set up a meeting tomorrow to tackle this issue over a call with some support from your side.Please set up a web conference for 10am.Allen Herrera | Developer | SpendHQ(r)M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",lp.spendhq.com issues!,,18-08-2017 00:55,19,0,SpendHQ,"Hello Allen,Thanks for joining the call.As you have updated that your issue got resolved, we are marking this case as closed. Please revert back to us in case of further queries.","Hello Allen,Please use the following bridge details to get on a call at 10 AM EST hours to discussing the issue.URL: https://reancloud.zoom.us/my/engg1Phone: +14086380968Code: 5535058879","Hello Allen,We will be available for a web conference to discuss this issue at 18th August 2017 10 AM EST (7.30 PM IST). We will share a calendar invite with the bridge details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001ErueE,Cloud Engineer Level 1,Closed,1069144,Incident,21-07-2017 09:52,,"Hello Team,This is to notify you that we have received an alert regarding High CPU load on sphq-db-server05 and it has crossed the threshold of 3 with a value of 3.01.Later the alert got resolved automatically and returned to normal with a value of 2.9.","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.01This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3965231465311545632 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,21-07-2017 09:21,1,0,SpendHQ,"Hello Team,This is to notify you that we have received an alert regarding High CPU load on sphq-db-server05 and it has crossed the threshold of 3 with a value of 3.01.Later the alert got resolved automatically and returned to normal with a value of 2.9.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001f6Hg9,Cloud Engineer Level 2,Closed,1108631,Incident,30-11-2018 15:10,,"Hello Team,Kindly note that as of now the EBS High Disk Usage issue has been resolved. As a permanent solution for this issue, we have enabled the log rotation on this instance PRD-WW1_122 .Hence we are closing this case from our end. Please review the details from your end and let us know if you have any queries.###@Team:Please proceed on this. THanks !###Check with CC before implementing this:----------------------------------------1.vi /etc/logrotate.d/datadog2.Add below config /var/log/datadog/*.log{    rotate 4    weakly    missingok    notifyempty    compress    dateext    dateformat -%Y-%m-%d.log}3. use below comment to check the working of file rotationlogrotate -d /var/logrotate.d/datadog###)Hello AllenAs of now we will remove the process-error.log file and will enable the logrotaion for the /var/log/datadog folder to rotate the logfiles periodically with the interval of 7 days.We will upadate you once this is done.Thanks###Allen HerreraThu, Nov 29, 11:50 PM (25 minutes ago)to Matthew, spendhq-support@reancloud.comRean why is this happening again. I’m deleting the log file because its 28 GB ! 2018-11-29 18:19:16 DEBUG (process_linux.go:849) - Unable to access /proc/14905/exe, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:858) - Unable to access /proc/14905/fd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:830) - Unable to access /proc/20521/io, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:841) - Unable to access /proc/20521/cwd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:849) - Unable to access /proc/20521/exe, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:858) - Unable to access /proc/20521/fd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:830) - Unable to access /proc/20590/io, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:841) - Unable to access /proc/20590/cwd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:849) - Unable to access /proc/20590/exe, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:858) - Unable to access /proc/20590/fd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:830) - Unable to access /proc/27395/io, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:841) - Unable to access /proc/27395/cwd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:849) - Unable to access /proc/27395/exe, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:858) - Unable to access /proc/27395/fd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:830) - Unable to access /proc/29452/io, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:841) - Unable to access /proc/29452/cwd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:849) - Unable to access /proc/29452/exe, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:858) - Unable to access /proc/29452/fd, permission denied2018-11-29 18:19:16 DEBUG (process.go:106) - collected processes in 56.521047ms###@Team:Please go ahead and clean up the datadog logs and enable the log rotation for 7 days.###@TeamThe same issue was discussed in the Ticket 01106908 and we had made some configuration changes in DD configuration files as recommended by Datadog support team but the alert again triggers with the same cause. So kindly check with the CC for the next action on this.###Hello Teamwe have analyzed the Disk usage and could see that the files under /var/log/datadog consumes 27 GB of disk space. As the Datadog agent log files are consuming high Disksapce we went ahead and checked with Datadog configuration file and couldn't see anything suspicious.----------------------------------------------------------------------disable_file_logging: falselog_enabled: falselog_format_json: falselog_level: INFO----------------------------------------------------------So kindly check with the below disk usage details and provide us an approval to clean up the /var/log/datadog/process-errors.log which has a size of 26GB and to implement the log rotation for the log files under /var/log/datadog folder to avoid this issue in future.##=======##======####=======##======####=======##======##Disk usage as per Directories in /var==>>27G	log4.2G	www573M	lib411M	tmp129M	cache15M	spool1.1M	db132K	run12K	lock8.0K	empty##=======##======####=======##======####=======##======##You are in the /var/cache directory==>>127M	yum2.0M	man24K	ldconfig12K	rpcbind8.0K	fontconfig4.0K	php-pear4.0K	mod_ssl4.0K	mod_proxy##=======##======####=======##======####=======##======##38G	/var/www/vhosts/files.spendhq.com/etl_uploads/petsmart_201402_201810.out26G	/var/log/datadog/process-errors.log25G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/att.out20G	/var/www/vhosts/files.spendhq.com/etl_uploads/sony_201503_201807.out20G	/var/www/vhosts/files.spendhq.com/etl_uploads/gpc_201510_201809.out17G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/serta_simmons.out17G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/raytheon.out16G	/var/www/vhosts/files.spendhq.com/etl_uploads/aarons_201104_201809_dm.out15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_region_vertical.out15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_pe.out--------------------------------------------------------------------------------------------------------------------Let us know if you have any queries.ThanksNishad Ali###Hello TeamThis is to notify you that we have received an alert EBS high disk usage on  /dev/xvda1 for the instance prd-ww1_122 - 10.59.100.122. The current value of Disk usage is 80%. We are analyzing the issue. Will let you know with the details.------------------------------------------Instance Name: prd-ww1_122 Instance ID: i-0ace70ce06368e4a7IP:10.59.100.122---------------------------------------------","Date: Thu, Nov 29, 2018 at 5:16 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prd-ww1_122 - 10.59.100.122To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-ww1_122 -10.59.100.122High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1543448799000&group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-0ace70ce06368e4a7&from_ts=1543445199000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc}by {host,device} * 100 > 80The monitor was last triggered at Wed Nov 28 2018 23:46:49 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-0ace70ce06368e4a7>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?filter=i-0ace70ce06368e4a7>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1543448929000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1543447909000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQ",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-ww1_122 - 10.59.100.122,,29-11-2018 05:18,34,0,SpendHQ,"Hello Team,Kindly note that as of now the EBS High Disk Usage issue has been resolved. As a permanent solution for this issue, we have enabled the log rotation on this instance PRD-WW1_122 .Hence we are closing this case from our end. Please review the details from your end and let us know if you have any queries.",@Team:Please proceed on this. THanks !,Check with CC before implementing this:----------------------------------------1.vi /etc/logrotate.d/datadog2.Add below config /var/log/datadog/*.log{    rotate 4    weakly    missingok    notifyempty    compress    dateext    dateformat -%Y-%m-%d.log}3. use below comment to check the working of file rotationlogrotate -d /var/logrotate.d/datadog,)Hello AllenAs of now we will remove the process-error.log file and will enable the logrotaion for the /var/log/datadog folder to rotate the logfiles periodically with the interval of 7 days.We will upadate you once this is done.Thanks,"Allen HerreraThu, Nov 29, 11:50 PM (25 minutes ago)to Matthew, spendhq-support@reancloud.comRean why is this happening again. I’m deleting the log file because its 28 GB ! 2018-11-29 18:19:16 DEBUG (process_linux.go:849) - Unable to access /proc/14905/exe, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:858) - Unable to access /proc/14905/fd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:830) - Unable to access /proc/20521/io, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:841) - Unable to access /proc/20521/cwd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:849) - Unable to access /proc/20521/exe, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:858) - Unable to access /proc/20521/fd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:830) - Unable to access /proc/20590/io, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:841) - Unable to access /proc/20590/cwd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:849) - Unable to access /proc/20590/exe, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:858) - Unable to access /proc/20590/fd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:830) - Unable to access /proc/27395/io, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:841) - Unable to access /proc/27395/cwd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:849) - Unable to access /proc/27395/exe, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:858) - Unable to access /proc/27395/fd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:830) - Unable to access /proc/29452/io, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:841) - Unable to access /proc/29452/cwd, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:849) - Unable to access /proc/29452/exe, permission denied2018-11-29 18:19:16 DEBUG (process_linux.go:858) - Unable to access /proc/29452/fd, permission denied2018-11-29 18:19:16 DEBUG (process.go:106) - collected processes in 56.521047ms",@Team:Please go ahead and clean up the datadog logs and enable the log rotation for 7 days.,@TeamThe same issue was discussed in the Ticket 01106908 and we had made some configuration changes in DD configuration files as recommended by Datadog support team but the alert again triggers with the same cause. So kindly check with the CC for the next action on this.,Hello Teamwe have analyzed the Disk usage and could see that the files under /var/log/datadog consumes 27 GB of disk space. As the Datadog agent log files are consuming high Disksapce we went ahead and checked with Datadog configuration file and couldn't see anything suspicious.----------------------------------------------------------------------disable_file_logging: falselog_enabled: falselog_format_json: falselog_level: INFO----------------------------------------------------------So kindly check with the below disk usage details and provide us an approval to clean up the /var/log/datadog/process-errors.log which has a size of 26GB and to implement the log rotation for the log files under /var/log/datadog folder to avoid this issue in future.##=======##======,#=======##======,"#=======##======##Disk usage as per Directories in /var==>>27G	log4.2G	www573M	lib411M	tmp129M	cache15M	spool1.1M	db132K	run12K	lock8.0K	empty##=======##======",#=======##======,"#=======##======##You are in the /var/cache directory==>>127M	yum2.0M	man24K	ldconfig12K	rpcbind8.0K	fontconfig4.0K	php-pear4.0K	mod_ssl4.0K	mod_proxy##=======##======",#=======##======,"#=======##======##38G	/var/www/vhosts/files.spendhq.com/etl_uploads/petsmart_201402_201810.out26G	/var/log/datadog/process-errors.log25G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/att.out20G	/var/www/vhosts/files.spendhq.com/etl_uploads/sony_201503_201807.out20G	/var/www/vhosts/files.spendhq.com/etl_uploads/gpc_201510_201809.out17G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/serta_simmons.out17G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/raytheon.out16G	/var/www/vhosts/files.spendhq.com/etl_uploads/aarons_201104_201809_dm.out15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_region_vertical.out15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_pe.out--------------------------------------------------------------------------------------------------------------------Let us know if you have any queries.ThanksNishad Ali",Hello TeamThis is to notify you that we have received an alert EBS high disk usage on  /dev/xvda1 for the instance prd-ww1_122 - 10.59.100.122. The current value of Disk usage is 80%. We are analyzing the issue. Will let you know with the details.------------------------------------------Instance Name: prd-ww1_122 Instance ID: i-0ace70ce06368e4a7IP:10.59.100.122---------------------------------------------,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013V3V4,Cloud Engineer Level 1,Closed,1026374,Incident,28-10-2016 19:25,,Thanks for the update.,"I had responded in the ticket itself, however I assume you never go  the message. We can close this issue for now.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: noreply@salesforce.com [mailto:noreply@salesforce.com] On Behalf Of Rean SupportSent: Friday, October 28, 2016 3:52 AMTo: Matthew Watts <mwatts@spendhq.com>Subject: Priority Low - P4 | Update on Case # SR-01025297Hello Matthew,Below comment added in reference to the case : 01025297.Hello Matthew,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.Case link: https://reancloud.force.com/customers/5000G000013TzShYou can click on the above link to add your comments or to review the progress. Thank you for your support and patience.Please do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at your respective REAN distribution email address.REAN Cloud-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Priority Low - P4 | Update on Case # SR-01025297,,28-10-2016 19:12,0,0,SpendHQ,Thanks for the update.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015Yndv,Cloud Engineer Level 1,Closed,1040942,Incident,,,,"I have just reviewed the log files on .125 (File Server) and it appears that we had some issues early on in the afternoon, which ultimately got worse. It seems that with the Journal Commit Error's that the drive got enough errors that the Operating System took it to read-only mode. Especially considering we have multiple entries for I/O Errors on specific blocks that retried and ultimately resulted in the read only mount.Can you advise if you think this is a storage issue error or other?Dec 22 23:06:31 ip-10-59-100-125 kernel: connection3:0: ping timeout of 10 secs expired, recv timeout 5, last rx 4705624002, last ping 4705629002, now 4705639002Dec 22 23:06:32 ip-10-59-100-125 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)Dec 22 23:06:36 ip-10-59-100-125 iscsid: connect to 172.23.104.77:3260 failed (Network is unreachable)Dec 22 23:06:41 ip-10-59-100-125 kernel: sd 4:0:0:0: rejecting I/O to offline deviceDec 22 23:06:41 ip-10-59-100-125 kernel: sd 4:0:0:0: [sda] killing requestDec 22 23:06:41 ip-10-59-100-125 kernel: JBD2: Detected IO errors while flushing file data on sda-8Dec 22 23:06:41 ip-10-59-100-125 kernel: JBD2: I/O error detected when updating journal superblock for sda-8.Dec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs error (device sda) in ext4_dirty_inode: Journal has abortedDec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_journal_start_sb: Detected aborted journalDec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs (sda): Remounting filesystem read-onlyDec 22 23:06:45 ip-10-59-100-125 kernel: journal commit I/O errorMatthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SEV One: Review,,24-12-2016 01:25,4,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000019rED2,Cloud Engineer Level 1,Closed,1045163,Incident,25-03-2017 05:56,,"Hello SpendHQ,From the VPN logs, we could see that generic user has been successfully logged in.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Regards,Safuvan KM###From the logs, we could see that the generic user has been successfully logged in. Closing the case.###2017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 OPTIONS IMPORT: reading client specific options from: /etc/openvpn/conf.d/shq_system2017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 MULTI_sva: pool returned IPv4=10.242.2.9, IPv6=(Not enabled)2017:03:23-20:58:04 spendhq openvpn[4194]: id=2201 severity=info sys=SecureNet sub=vpn event=Connection started username=shq_system variant=ssl srcip=74.115.22.44 virtual_ip=10.242.2.92017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 PLUGIN_CALL: POST /usr/lib/openvpn/plugins/openvpn-plugin-utm.so/PLUGIN_CLIENT_CONNECT status=02017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 OPTIONS IMPORT: reading client specific options from: /tmp/openvpn_cc_c89eb4b64d428d9c2a6b90dff464ecca.tmp2017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 MULTI: Learn: 10.242.2.9 -> shq_system/74.115.22.44:200132017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 MULTI: primary virtual IP for shq_system/74.115.22.44:20013: 10.242.2.92017:03:23-20:58:07 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 PUSH: Received control message: 'PUSH_REQUEST'2017:03:23-20:58:07 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 send_push_reply(): safe_cap=9402017:03:23-20:58:07 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 SENT CONTROL [shq_system]: 'PUSH_REPLY,route-gateway 10.242.2.1,route-gateway 10.242.2.1,topology subnet,ping 10,ping-restart 120,route 10.59.0.0 255.255.0.0,ifconfig 10.242.2.9 255.255.255.0' (status=1)###Hello Robert,We have reset the password and sent to you in a separate email. Please check and confirm the access.###Hello Robert,There is no password expiry for the Sophos user account. Please let us know if we can reset the password for you.###Robert replied back,Yes, please reset the password for me. Will you send me a new password or is there a way for me to change it once it is reset?###Hello Robert,We are looking into this issue and will get back to you with details.","Hello, We currently have an account called shq_system in Sophos to connect a remote server to our production servers. We cannot seem to find the credentials for this account to log back in now. Is there a process for resetting the password or something of that nature? Thanks, Robert",Sophos VPN Forgot PW,,24-03-2017 06:05,24,0,SpendHQ,"Hello SpendHQ,From the VPN logs, we could see that generic user has been successfully logged in.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Regards,Safuvan KM","From the logs, we could see that the generic user has been successfully logged in. Closing the case.","2017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 OPTIONS IMPORT: reading client specific options from: /etc/openvpn/conf.d/shq_system2017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 MULTI_sva: pool returned IPv4=10.242.2.9, IPv6=(Not enabled)2017:03:23-20:58:04 spendhq openvpn[4194]: id=2201 severity=info sys=SecureNet sub=vpn event=Connection started username=shq_system variant=ssl srcip=74.115.22.44 virtual_ip=10.242.2.92017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 PLUGIN_CALL: POST /usr/lib/openvpn/plugins/openvpn-plugin-utm.so/PLUGIN_CLIENT_CONNECT status=02017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 OPTIONS IMPORT: reading client specific options from: /tmp/openvpn_cc_c89eb4b64d428d9c2a6b90dff464ecca.tmp2017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 MULTI: Learn: 10.242.2.9 -> shq_system/74.115.22.44:200132017:03:23-20:58:04 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 MULTI: primary virtual IP for shq_system/74.115.22.44:20013: 10.242.2.92017:03:23-20:58:07 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 PUSH: Received control message: 'PUSH_REQUEST'2017:03:23-20:58:07 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 send_push_reply(): safe_cap=9402017:03:23-20:58:07 spendhq openvpn[4194]: shq_system/74.115.22.44:20013 SENT CONTROL [shq_system]: 'PUSH_REPLY,route-gateway 10.242.2.1,route-gateway 10.242.2.1,topology subnet,ping 10,ping-restart 120,route 10.59.0.0 255.255.0.0,ifconfig 10.242.2.9 255.255.255.0' (status=1)","Hello Robert,We have reset the password and sent to you in a separate email. Please check and confirm the access.","Hello Robert,There is no password expiry for the Sophos user account. Please let us know if we can reset the password for you.","Robert replied back,Yes, please reset the password for me. Will you send me a new password or is there a way for me to change it once it is reset?","Hello Robert,We are looking into this issue and will get back to you with details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001UlGGo,Cloud Engineer Level 1,Closed,1095987,Incident,20-04-2018 17:49,,"Hi Mathew,As the team updated you on this ticket that AWS has scheduled maintenance on AWS Direct Connect. This maintenance will start on April 26, 2018 at 8:31:00 AM UTC+5:30 and end on April 26, 2018 at 1:31:00 PM UTC+5:30. During this maintenance, the connection will be affected is the Secondary Connection of 1Gbps. No downtime on Primary Connection will be there. Therefore, there is nothing needs to be done from our end on this. We are closing this case. Thanks.###Hi Mathew,As the team mentioned, the AWS Direct Connect services associated with port speed 1Gbps which is the Secondary Connection will be affected. So this will not affect your environment as the Primary Connection 10Gbps will not be affected.###Hi Mathew,As the team mentioned, the AWS Direct Connect services associated with port speed 1Gbps which is the Secondary Connection will be affected. So this will not affect your environment as the Primary Connection 10Gbps will not be affected.###Matthew Watts5:35 PM (6 minutes ago)to Rean Is this going to affect us?###Hello Team,We haven't heard back from you.We received notification from AWS stating planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 1Gbps may become unavailable. Connection name: SpendHQ Connection ID: dxcon-fg50qjyw Your Peer IP: 169.254.255.46/30 Amazon Peer IP: 169.254.255.45/30 AWS Scheduled Maintenance Window:- Start time April 26, 2018 at 8:31:00 AM UTC+5:30 End time April 26, 2018 at 1:31:00 PM UTC+5:30 AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same.###Hello Team,Please review the details and let us know if you have any further concerns regarding this.###Hello SpendHQ-Team, This is a quick follow up.Kindly review the previous comment and let us know in case of any queries.###Hello SpendHQ-Team,This is to inform you that we received notification from AWS stating planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 1Gbps may become unavailable.Connection name: SpendHQ Connection ID: dxcon-fg50qjywYour Peer IP: 169.254.255.46/30Amazon Peer IP: 169.254.255.45/30AWS Scheduled Maintenance Window:- Start timeApril 26, 2018 at 8:31:00 AM UTC+5:30End timeApril 26, 2018 at 1:31:00 PM UTC+5:30AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same.###Need to check with Rohit before sending info to the customer.","Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 & DC10 - DC12, Ashburn, VA. During this maintenance window, your AWS Direct Connect services associated with this event may become unavailable.This maintenance is scheduled to avoid disrupting redundant connections at the same time.If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED,,12-04-2018 07:43,224,0,SpendHQ,"Hi Mathew,As the team updated you on this ticket that AWS has scheduled maintenance on AWS Direct Connect. This maintenance will start on April 26, 2018 at 8:31:00 AM UTC+5:30 and end on April 26, 2018 at 1:31:00 PM UTC+5:30. During this maintenance, the connection will be affected is the Secondary Connection of 1Gbps. No downtime on Primary Connection will be there. Therefore, there is nothing needs to be done from our end on this. We are closing this case. Thanks.","Hi Mathew,As the team mentioned, the AWS Direct Connect services associated with port speed 1Gbps which is the Secondary Connection will be affected. So this will not affect your environment as the Primary Connection 10Gbps will not be affected.","Hi Mathew,As the team mentioned, the AWS Direct Connect services associated with port speed 1Gbps which is the Secondary Connection will be affected. So this will not affect your environment as the Primary Connection 10Gbps will not be affected.",Matthew Watts5:35 PM (6 minutes ago)to Rean Is this going to affect us?,"Hello Team,We haven't heard back from you.We received notification from AWS stating planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 1Gbps may become unavailable. Connection name: SpendHQ Connection ID: dxcon-fg50qjyw Your Peer IP: 169.254.255.46/30 Amazon Peer IP: 169.254.255.45/30 AWS Scheduled Maintenance Window:- Start time April 26, 2018 at 8:31:00 AM UTC+5:30 End time April 26, 2018 at 1:31:00 PM UTC+5:30 AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same.","Hello Team,Please review the details and let us know if you have any further concerns regarding this.","Hello SpendHQ-Team, This is a quick follow up.Kindly review the previous comment and let us know in case of any queries.","Hello SpendHQ-Team,This is to inform you that we received notification from AWS stating planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 1Gbps may become unavailable.Connection name: SpendHQ Connection ID: dxcon-fg50qjywYour Peer IP: 169.254.255.46/30Amazon Peer IP: 169.254.255.45/30AWS Scheduled Maintenance Window:- Start timeApril 26, 2018 at 8:31:00 AM UTC+5:30End timeApril 26, 2018 at 1:31:00 PM UTC+5:30AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same.",Need to check with Rohit before sending info to the customer.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ESPKy,Cloud Engineer Level 1,Closed,1066941,Incident,07-07-2017 01:08,,"Hello Dusty,Thanks for the information.We have on board the machine into REAN MGS. Please let us know if you have any further queries regarding this.###Dusty Fowler9:21 PM (1 hour ago)￼￼￼to Rean, spendhq-support￼This appears to have corrected my issue.  Thank you. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com###Hello Dusty,We have enabled internet connectivity to the instance. Please check and verify it from your end.We will onboard the instance and will let you know once it is done.###Yes, please onboard this machine. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com###Hello Dusty,While checking we could see that there is no internet connectivity on this 10.59.100.79 machine. That is why you are not able to pull the code from the bitbucket. And also this instance is not under a part of REAN monitoring. Please let us know if you want us to onboard this instance.###Hello Dusty,We will work on this and will get back to your further updates.Thanks & Regards,Gourav Pokhra","Hello,I am having issues connecting via ssh to bitbucket to pull our code repository onto the 10.59.100.79 machine.  Whenever I attempt a connection I get the following error:ssh: connect to host bitbucket.org port 22: Network is unreachablefatal: The remote end hung up unexpectedlyCould you check to ensure connections are open on port 22 and nothing is blocking the ability to connect to bitbucket.org?Thanks!Dusty Fowler | Developer | SpendHQ(r)O: 770.628.0026 | dfowler@spendhq.com<mailto:dfowler@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Issues connecting to bitbucket,,06-07-2017 18:37,7,0,SpendHQ,"Hello Dusty,Thanks for the information.We have on board the machine into REAN MGS. Please let us know if you have any further queries regarding this.","Dusty Fowler9:21 PM (1 hour ago)￼￼￼to Rean, spendhq-support￼This appears to have corrected my issue.  Thank you. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com","Hello Dusty,We have enabled internet connectivity to the instance. Please check and verify it from your end.We will onboard the instance and will let you know once it is done.","Yes, please onboard this machine. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com","Hello Dusty,While checking we could see that there is no internet connectivity on this 10.59.100.79 machine. That is why you are not able to pull the code from the bitbucket. And also this instance is not under a part of REAN monitoring. Please let us know if you want us to onboard this instance.","Hello Dusty,We will work on this and will get back to your further updates.Thanks & Regards,Gourav Pokhra",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001deIAm,Cloud Engineer Level 1,Closed,1106766,Incident,26-10-2018 02:22,,"Hi Kristen,Thanks for the confirmation. At this point we are marking this case as resolved and hence closing it.Please feel free to get in touch if you have any questions or concerns.Best Regards.###Kristen Stretch11:45 PM (2 minutes ago)to meHi Stephen, I was able to successfully log in. Thanks!###Hello Kristen,This request is completed.We have created the user kstretch and provided sudo access to the server. We have also shared the login credentials with you separately.Please try logging in using the shared credentials and let us know if you have any issues.Thanks & Regards.###Hello Matthew,Thanks for the approval, We will work on this and update the user.Thanks.###APPROVED. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting###Hello Kristen,We can see you do not have a user setup in the server.@Matthew please provide approval to create the user to allow the necessary access to the server for Kristen.Thanks.###Hello Kristen,We acknowledge receipt of your request.We will look into it and get back to you with the updates.Thanks","Hi, I am having issues sshing into the following:Instance Name:   JENKINS_MASTERInstance ID :         i-079130613ab17ad30Private IP:            10.59.100.188[cid:image003.jpg@01D46C66.4CA9FDE0]If I do not have an account on this server I need one to be set up ASAP. My public key is:ssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAgEAqzyxcyk+UX6HRuXtDYDv+MT1VrgI2LlMmznZgsmRU1PIU925cE2aDr59I2FDWL58jytu2iWrIGS9KuoK1ptT9pKUQkSj8OWeuh0906RQMEs/FyJLJa+WUY8+LxXhUn4v3ujQEyDwnWzOIcDhk6I37WM6ngd9V198kmSRbc29oC4O3KSMp1p3EY/J7D7DMTWfqIWhiOC1hUOG+NStlJ+z+DGayo/GfI0hu6oPFzoqE0v1yoYgdaWbQU9ruZR9ns7Htlb2zXRLHkDpn3nrCMEfZXT7ubA6AeNiC+8UmNeeHR6r7fyrQXTlv8s7xcPkrPhC3n2UcCV/UPRurihHLctTHloJpYLXRKaN/iUtKFBGhrB+hei9b+5PVMeS+yuhVCeAgU7vNNtI6xheOrS8rrQJ5x32NzWzxwJa4tJRRPSbhbiBCxOGTlaq463n0xImiQHg1fDjP/Oi10KdpUBfRI/s87pZbuW2EvWKcXpLcLT7JI1vAD6F6EiBejKJZ920TURh8dN1uWKeJ9yF1bk/m3fHEyjETcMTxQOHz5AbBKSpP21QX9kb9dN8z2CaKQOWgUOgtivIN7JNAN1hgxd02qAmsokA3iBSS+hi05+qZxeME79/UwOG3Ih7dRwTBCO5rGQUH6wb1op9MBM+FRzPQ5iSYCS9+N9OkJzeRDpMhpX8F18= rsa-key-20180913Let me know if you require any other info.Thanks,Kristen Stretch--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Server access error,,25-10-2018 22:56,3,0,SpendHQ,"Hi Kristen,Thanks for the confirmation. At this point we are marking this case as resolved and hence closing it.Please feel free to get in touch if you have any questions or concerns.Best Regards.","Kristen Stretch11:45 PM (2 minutes ago)to meHi Stephen, I was able to successfully log in. Thanks!","Hello Kristen,This request is completed.We have created the user kstretch and provided sudo access to the server. We have also shared the login credentials with you separately.Please try logging in using the shared credentials and let us know if you have any issues.Thanks & Regards.","Hello Matthew,Thanks for the approval, We will work on this and update the user.Thanks.","APPROVED. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting","Hello Kristen,We can see you do not have a user setup in the server.@Matthew please provide approval to create the user to allow the necessary access to the server for Kristen.Thanks.","Hello Kristen,We acknowledge receipt of your request.We will look into it and get back to you with the updates.Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015ZD1Y,Cloud Engineer Level 1,Closed,1041373,Incident,04-01-2017 11:36,,"We are closing this case her and tracking it over the ticket number  01040935.https://reancloud.cloudforce.com/5000G000015Yhre###Chris updated that. Hi Everyone, I have been working this with Nimble. We have checked out the Nimble array and verified there are not any issues with either the storage or the network on our end. The error message suggests that issue is on the host (which makes sense since that where the error log is being generated). There was- and currently - a broken/re-connection issue associated with this AWS machine. This leads us to believe that it is a multipath config issue. I need REAN review the attached config sheet and verify that the mulitpath.conf file is correct - and verify it is correct for the version of Red Hat that is running. Make Note - NCM is not loaded on the AWS machine. See the configuration sheet for those minor config details. I will be happy to help out with this as needed - as will Nimble.###Chris was not picking up the phone call, Sent a reminder to Chris for updates. Hi Chris, This is a quick followup, Do we have any update from Nimble Team to see if there are any configurations that might cause this issue?###Chris updated that he will engaging the Nimble Team to see if there are any configurations that might/may cause this occasional issue.This probably will result in a Nimble/REAN call and exchange of ideas. Chris will drive this.###We had a call with Chris from Andromeda, he updated that he is also not able to figure out the exact issue so that he already raised a support ticket with nimble team and he informed that he will try to get Andromeda, REAN and Nimble Team in a single call.Chris told that he will  send an email detailing the updates regarding the issue.###We have asked Chris for his availability to set up a call.###Chirodeep has replied to Chris.Hi Chris, I have sent you an invite with your login ID and link to set up your password for REAN ticketing tool. Let me know if you are facing any issues in access and viewing the cases.###Hi SpendHQ Team,We see the device /dev/sdc mounted on /var/infobright with the size of 4TB.[centos@ip-10-59-10-12 infobright]$ df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    99G   80G   15G  85% /tmpfs          tmpfs  121G     0  121G   0% /dev/shm/dev/sdc       ext4   4.0T  1.6T  2.2T  42% /var/infobrightWe have performed the benchmarking test on this drive and below are the test result:[root@ip-10-59-10-12 iotest]# dd if=/dev/zero of=iotest.txt bs=4M count=500 oflag=dsync500+0 records in500+0 records out2097152000 bytes (2.1 GB) copied, 14.188 s, 148 MB/s[root@ip-10-59-10-12 iotest]# dd if=/dev/zero of=iotest.txt bs=4M count=500 oflag=dsync500+0 records in500+0 records out2097152000 bytes (2.1 GB) copied, 14.1635 s, 148 MB/s[root@ip-10-59-10-12 iotest]# dd if=/dev/zero of=iotest.txt bs=4M count=500 oflag=dsync500+0 records in500+0 records out2097152000 bytes (2.1 GB) copied, 14.3183 s, 146 MB/s[root@ip-10-59-10-12 iotest]# dd if=/dev/zero of=iotest.txt bs=4M count=500 oflag=dsync500+0 records in500+0 records out2097152000 bytes (2.1 GB) copied, 14.3917 s, 146 MB/s[root@ip-10-59-10-12 iotest]# pwd/var/infobright/iotestWe can see from last 4 test that the write performance on this device about 146 MB/s. Please let us know if this was the expected result or not. Thanks###Chris has sent an email.Okay we will.Rean, I need an account though to log on to see the case history however.... can you provide Andromeda3 a login/account ID?Thanks! ��Chris Veillette###Hello Matthew,We were analyzing more on this and we have compared the iscsid.conf file on both the instances 10.59.100.118 and 10.59.100.125 and we have verified that there is no difference in the configuration of both servers.@ Andromeda team, please check the errors that we got on the server 10.59.100.118 attached in the attachment section and let us know your thoughts regarding this.###Hi Team,We have analyzed the issue and shared the details with client, for now only action pending from our end is compare the configuration file of 10.59.100.118 and 10.59.100.125 why we are dong this means we are not facing any errors in 10.59.100.125 machine.configuration file is under /etc/iscsi/iscsid.conf path, Inform the A3 team about errors we have seen on 10.59.100.118 possible reasons for that share configuration file details also, if we found any  difference in configuration.###Hi Matthew,We have analyzed the issue on 10.59.10.12 and able to figure out that there are network connection established to 10.59.100.125 and 10.59.100.118 .We could also see that the server 10.59.100.125 experienced a Network unreachable issue on DEC 24th and 10.59.100.118 became read only on DEC 23rd. We have checked the two machines(10.59.100.125 and 10.59.100.118) and we could not find any errors with 10.59.100.125 and coming to 10.59.100.118 we are noticing that connection are getting disconnected and attempting to reconnect per minute.Approximately it got disconnected 40 times, which might be the reason for the slowness in 10.59.10.12 machine.Find the snapshot of logs from attachment section for details.Please let us know if you have any queries on test results of I/O we have shared, and let us know whether you need anymore details. Meanwhile we will investigate on these errors with the help of A3.###Hi Matthew,Please find the initial testing result below:### Using hdparm to benchmark root volume ###[centos@ip-10-59-10-12 ~]$ sudo hdparm -Tt /dev/xvda1/dev/xvda1: Timing cached reads:   18444 MB in  2.00 seconds = 9231.97 MB/sec Timing buffered disk reads: 524 MB in  3.01 seconds = 173.89 MB/sec[centos@ip-10-59-10-12 ~]$[centos@ip-10-59-10-12 ~]$ sudo hdparm -Tt /dev/sdc/dev/sdc: Timing cached reads:   18794 MB in  2.00 seconds = 9407.27 MB/sec Timing buffered disk reads: 318 MB in  3.02 seconds = 105.39 MB/sec### Using dd || iotop to benchmark root volume #####On terminal 1: ##sudo iotop (keeping it running to see the throughput)## On terminal 2: ### When using (oflag=direct) Use direct I/O for data, avoiding the buffer cache #[centos@ip-10-59-10-12 ~]$ dd if=/dev/zero of=/home/centos/testfile.txt bs=1G count=2 oflag=direct2+0 records in2+0 records out2147483648 bytes (2.1 GB) copied, 21.5577 s, 99.6 MB/s[centos@ip-10-59-10-12 ~]$[centos@ip-10-59-10-12 ~]$ dd if=/home/centos/testfile.txt of=/home/centos/testfile2.txt bs=1G count=2 oflag=direct2+0 records in2+0 records out2147483648 bytes (2.1 GB) copied, 31.2526 s, 68.7 MB/s# When using (oflag=dsync) Use synchronized I/O for data. For the output file, this forces a physical write of output data on each write #[centos@ip-10-59-10-12 ~]$ dd if=/dev/zero of=/home/centos/testfile.txt bs=1G count=2 oflag=dsync2+0 records in2+0 records out2147483648 bytes (2.1 GB) copied, 21.8588 s, 98.2 MB/s[centos@ip-10-59-10-12 ~]$ dd if=/home/centos/testfile.txt of=/home/centos/testfile2.txt bs=1G count=2 oflag=dsync2+0 records in2+0 records out2147483648 bytes (2.1 GB) copied, 19.4145 s, 111 MB/sAttaching the screenshot for parallel iotop output when performing the testing using dd command.We will check internally why the disk I/O performance is low and let you know with our findings.###Hello Matthew,We are still investigating this issue and will get back to you with updates.###Do we have an update here?###Hello Matthew,We will look into this issue. We will provide you with an update after check with our internal team.","Can we please run some benchmarks on I/O on the PRD Database (10.59.10.12) to see why persists to disk are taking so long. We are noticing unusual delays that are affecting business operations. If you need any additional information, then please do not hesitate to ask.Thank you in advance for your assistance.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",I/O,,26-12-2016 02:19,213,0,SpendHQ,We are closing this case her and tracking it over the ticket number  01040935.https://reancloud.cloudforce.com/5000G000015Yhre,"Chris updated that. Hi Everyone, I have been working this with Nimble. We have checked out the Nimble array and verified there are not any issues with either the storage or the network on our end. The error message suggests that issue is on the host (which makes sense since that where the error log is being generated). There was- and currently - a broken/re-connection issue associated with this AWS machine. This leads us to believe that it is a multipath config issue. I need REAN review the attached config sheet and verify that the mulitpath.conf file is correct - and verify it is correct for the version of Red Hat that is running. Make Note - NCM is not loaded on the AWS machine. See the configuration sheet for those minor config details. I will be happy to help out with this as needed - as will Nimble.","Chris was not picking up the phone call, Sent a reminder to Chris for updates. Hi Chris, This is a quick followup, Do we have any update from Nimble Team to see if there are any configurations that might cause this issue?",Chris updated that he will engaging the Nimble Team to see if there are any configurations that might/may cause this occasional issue.This probably will result in a Nimble/REAN call and exchange of ideas. Chris will drive this.,"We had a call with Chris from Andromeda, he updated that he is also not able to figure out the exact issue so that he already raised a support ticket with nimble team and he informed that he will try to get Andromeda, REAN and Nimble Team in a single call.Chris told that he will  send an email detailing the updates regarding the issue.",We have asked Chris for his availability to set up a call.,"Chirodeep has replied to Chris.Hi Chris, I have sent you an invite with your login ID and link to set up your password for REAN ticketing tool. Let me know if you are facing any issues in access and viewing the cases.","Hi SpendHQ Team,We see the device /dev/sdc mounted on /var/infobright with the size of 4TB.[centos@ip-10-59-10-12 infobright]$ df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    99G   80G   15G  85% /tmpfs          tmpfs  121G     0  121G   0% /dev/shm/dev/sdc       ext4   4.0T  1.6T  2.2T  42% /var/infobrightWe have performed the benchmarking test on this drive and below are the test result:[root@ip-10-59-10-12 iotest]# dd if=/dev/zero of=iotest.txt bs=4M count=500 oflag=dsync500+0 records in500+0 records out2097152000 bytes (2.1 GB) copied, 14.188 s, 148 MB/s[root@ip-10-59-10-12 iotest]# dd if=/dev/zero of=iotest.txt bs=4M count=500 oflag=dsync500+0 records in500+0 records out2097152000 bytes (2.1 GB) copied, 14.1635 s, 148 MB/s[root@ip-10-59-10-12 iotest]# dd if=/dev/zero of=iotest.txt bs=4M count=500 oflag=dsync500+0 records in500+0 records out2097152000 bytes (2.1 GB) copied, 14.3183 s, 146 MB/s[root@ip-10-59-10-12 iotest]# dd if=/dev/zero of=iotest.txt bs=4M count=500 oflag=dsync500+0 records in500+0 records out2097152000 bytes (2.1 GB) copied, 14.3917 s, 146 MB/s[root@ip-10-59-10-12 iotest]# pwd/var/infobright/iotestWe can see from last 4 test that the write performance on this device about 146 MB/s. Please let us know if this was the expected result or not. Thanks","Chris has sent an email.Okay we will.Rean, I need an account though to log on to see the case history however.... can you provide Andromeda3 a login/account ID?Thanks! ��Chris Veillette","Hello Matthew,We were analyzing more on this and we have compared the iscsid.conf file on both the instances 10.59.100.118 and 10.59.100.125 and we have verified that there is no difference in the configuration of both servers.@ Andromeda team, please check the errors that we got on the server 10.59.100.118 attached in the attachment section and let us know your thoughts regarding this.","Hi Team,We have analyzed the issue and shared the details with client, for now only action pending from our end is compare the configuration file of 10.59.100.118 and 10.59.100.125 why we are dong this means we are not facing any errors in 10.59.100.125 machine.configuration file is under /etc/iscsi/iscsid.conf path, Inform the A3 team about errors we have seen on 10.59.100.118 possible reasons for that share configuration file details also, if we found any  difference in configuration.","Hi Matthew,We have analyzed the issue on 10.59.10.12 and able to figure out that there are network connection established to 10.59.100.125 and 10.59.100.118 .We could also see that the server 10.59.100.125 experienced a Network unreachable issue on DEC 24th and 10.59.100.118 became read only on DEC 23rd. We have checked the two machines(10.59.100.125 and 10.59.100.118) and we could not find any errors with 10.59.100.125 and coming to 10.59.100.118 we are noticing that connection are getting disconnected and attempting to reconnect per minute.Approximately it got disconnected 40 times, which might be the reason for the slowness in 10.59.10.12 machine.Find the snapshot of logs from attachment section for details.Please let us know if you have any queries on test results of I/O we have shared, and let us know whether you need anymore details. Meanwhile we will investigate on these errors with the help of A3.","Hi Matthew,Please find the initial testing result below:",Using hdparm to benchmark root volume,[centos@ip-10-59-10-12 ~]$ sudo hdparm -Tt /dev/xvda1/dev/xvda1: Timing cached reads:   18444 MB in  2.00 seconds = 9231.97 MB/sec Timing buffered disk reads: 524 MB in  3.01 seconds = 173.89 MB/sec[centos@ip-10-59-10-12 ~]$[centos@ip-10-59-10-12 ~]$ sudo hdparm -Tt /dev/sdc/dev/sdc: Timing cached reads:   18794 MB in  2.00 seconds = 9407.27 MB/sec Timing buffered disk reads: 318 MB in  3.02 seconds = 105.39 MB/sec,Using dd || iotop to benchmark root volume,##On terminal 1: ##sudo iotop (keeping it running to see the throughput)## On terminal 2:,"When using (oflag=direct) Use direct I/O for data, avoiding the buffer cache #[centos@ip-10-59-10-12 ~]$ dd if=/dev/zero of=/home/centos/testfile.txt bs=1G count=2 oflag=direct2+0 records in2+0 records out2147483648 bytes (2.1 GB) copied, 21.5577 s, 99.6 MB/s[centos@ip-10-59-10-12 ~]$[centos@ip-10-59-10-12 ~]$ dd if=/home/centos/testfile.txt of=/home/centos/testfile2.txt bs=1G count=2 oflag=direct2+0 records in2+0 records out2147483648 bytes (2.1 GB) copied, 31.2526 s, 68.7 MB/s# When using (oflag=dsync) Use synchronized I/O for data. For the output file, this forces a physical write of output data on each write #[centos@ip-10-59-10-12 ~]$ dd if=/dev/zero of=/home/centos/testfile.txt bs=1G count=2 oflag=dsync2+0 records in2+0 records out2147483648 bytes (2.1 GB) copied, 21.8588 s, 98.2 MB/s[centos@ip-10-59-10-12 ~]$ dd if=/home/centos/testfile.txt of=/home/centos/testfile2.txt bs=1G count=2 oflag=dsync2+0 records in2+0 records out2147483648 bytes (2.1 GB) copied, 19.4145 s, 111 MB/sAttaching the screenshot for parallel iotop output when performing the testing using dd command.We will check internally why the disk I/O performance is low and let you know with our findings.","Hello Matthew,We are still investigating this issue and will get back to you with updates.",Do we have an update here?,"Hello Matthew,We will look into this issue. We will provide you with an update after check with our internal team.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Dp5F5,Cloud Engineer Level 1,Closed,1066536,Incident,04-07-2017 06:19,,"Hello Andrew,Thanks for the update.We will make the required changes to the script and make sure that the instance DEV-SPHQ-DB-SERVER02 doesn't get stopped by it.We will follow up with you regarding an update on this on case ID 01066566.We are marking this case as closed now.###Also, I manually started the DEV-SPHQ-DB-SERVER02 from the AWS console. The schedule to start/stop this instance should be removed as per case 01066566.###Determined the root cause was the web application not being able to access the Redis server which is currently on DEV-SPHQ-DB-SERVER02, which was scheduled to stop at 7:30.The SHQ team will work on migrating Redis to another server.This ticket may be closed.###Hello Team,In our analysis, we found that the process count on both the servers ie PROD-SPHQ-WEB-SERVER03 and PROD-SPHQ-WEB-SERVER02_PREVIEW is very high.Hence, in order to resolve this issue please let us know if we can go ahead and restart the instances.###Hello Team,This is to notify you that we have received a site down alert for both https://preview.spendhq.com and https://secure.spendhq.com.We are looking into the issue and will get back to you with the updates.","Mon, 03 Jul 2017 19:35:01 -0400Detected Error on SpendHQEstimated Downtime: 2 minutes https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30004 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: --------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): London UK, Atlanta-B US, Sydney-C AU, California US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,04-07-2017 05:05,1,0,SpendHQ,"Hello Andrew,Thanks for the update.We will make the required changes to the script and make sure that the instance DEV-SPHQ-DB-SERVER02 doesn't get stopped by it.We will follow up with you regarding an update on this on case ID 01066566.We are marking this case as closed now.","Also, I manually started the DEV-SPHQ-DB-SERVER02 from the AWS console. The schedule to start/stop this instance should be removed as per case 01066566.","Determined the root cause was the web application not being able to access the Redis server which is currently on DEV-SPHQ-DB-SERVER02, which was scheduled to stop at 7:30.The SHQ team will work on migrating Redis to another server.This ticket may be closed.","Hello Team,In our analysis, we found that the process count on both the servers ie PROD-SPHQ-WEB-SERVER03 and PROD-SPHQ-WEB-SERVER02_PREVIEW is very high.Hence, in order to resolve this issue please let us know if we can go ahead and restart the instances.","Hello Team,This is to notify you that we have received a site down alert for both https://preview.spendhq.com and https://secure.spendhq.com.We are looking into the issue and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001SVAMC,Cloud Engineer Level 1,Closed,1093204,Incident,13-03-2018 23:09,,"Hello Spendhq-Team,This is to inform you that we have received an alert regarding high memory Utilization on prd-ww1_122 (10.59.100.122) has exceeded the threshold value of 85 to 86.93%. The alert got resolved and returned to normal with a value of 54.39%. The violation lasted for 6 minutes. Please find the resources details below. Resource Details:- Instance ID: i-0ace70ce06368e4a7 Instance Name: prd-ww1_122 Private IP: 10.59.100.122 Please  find memory utilisation deatils below: USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDapache   17118  0.3 10.0 1912884 1541128 ?     S    06:45   2:11 /usr/sbin/httpdapache   26446  0.6  9.1 1775424 1402652 ?     S    15:19   0:46 /usr/sbin/httpdclam      1635  0.0  3.6 714208 552064 ?       Ssl  Mar06   1:05 clamdtomcat    1787  0.0  3.3 5916696 517416 ?      Sl   Mar06   6:26 /usr/java/default/bin/java -Djava.util.logging.config.file=/opt/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Dfile.encoding=UTF-8 -Dnet.sf.ehcache.skipUpdateCheck=true -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+UseParNewGC -XX:MaxPermSize=128m -Xms512m -Xmx512m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -classpath /opt/tomcat/bin/bootstrap.jar:/opt/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/opt/tomcat -Dcatalina.home=/opt/tomcat -Djava.io.tmpdir=/opt/tomcat/temp org.apache.catalina.startup.Bootstrap startapache   17307  0.5  3.3 880400 514964 ?       S    13:26   1:20 /usr/sbin/httpdapache   27592  0.4  2.3 731732 359156 ?       S    08:55   2:31 /usr/sbin/httpdapache    3034  1.1  1.9 671352 305188 ?       S    17:08   0:12 /usr/sbin/httpdapache   19418  0.4  1.8 655996 290196 ?       S    13:52   0:53 /usr/sbin/httpdapache    3565  0.3  1.8 648820 277080 ?       S    10:37   1:16 /usr/sbin/httpdapache   27007  0.3  1.7 638380 273048 ?       S    15:26   0:25 /usr/sbin/httpdHence the alert got recovered we are marking this as resolved. Please let us know if you have any queries.","Regards,*Yogesh Maloo**Senior Cloud Engineer,**REĀN Cloud **Mobile*: +918003126272 | *Skype*: ykmalooyogesh.maloo@reancloud.com | www.reancloud.com<http://twitter.com/ykmaloo> <http://us.linkedin.com/in/ykmaloo><http://facebook.com/ykmaloo><http://github.com/ykmaloo>---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Tue, Mar 13, 2018 at 10:26 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Memory UtilizationAlert on host - prd-ww1_122 - 10.59.100.122 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww1_122- 10.59.100.122 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1520960207000&group=host%3Ai-0ace70ce06368e4a7&from_ts=1520959907000>avg(last_5m):( avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 85The monitor was last triggered at Tue Mar 13 2018 16:56:57 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-0ace70ce06368e4a7>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?hostname=i-0ace70ce06368e4a7>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1520960217000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1520959317000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4306666934537780072>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww1_122 - 10.59.100.122 - web,,13-03-2018 22:47,9,0,SpendHQ,"Hello Spendhq-Team,This is to inform you that we have received an alert regarding high memory Utilization on prd-ww1_122 (10.59.100.122) has exceeded the threshold value of 85 to 86.93%. The alert got resolved and returned to normal with a value of 54.39%. The violation lasted for 6 minutes. Please find the resources details below. Resource Details:- Instance ID: i-0ace70ce06368e4a7 Instance Name: prd-ww1_122 Private IP: 10.59.100.122 Please  find memory utilisation deatils below: USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDapache   17118  0.3 10.0 1912884 1541128 ?     S    06:45   2:11 /usr/sbin/httpdapache   26446  0.6  9.1 1775424 1402652 ?     S    15:19   0:46 /usr/sbin/httpdclam      1635  0.0  3.6 714208 552064 ?       Ssl  Mar06   1:05 clamdtomcat    1787  0.0  3.3 5916696 517416 ?      Sl   Mar06   6:26 /usr/java/default/bin/java -Djava.util.logging.config.file=/opt/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Dfile.encoding=UTF-8 -Dnet.sf.ehcache.skipUpdateCheck=true -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+UseParNewGC -XX:MaxPermSize=128m -Xms512m -Xmx512m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -classpath /opt/tomcat/bin/bootstrap.jar:/opt/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/opt/tomcat -Dcatalina.home=/opt/tomcat -Djava.io.tmpdir=/opt/tomcat/temp org.apache.catalina.startup.Bootstrap startapache   17307  0.5  3.3 880400 514964 ?       S    13:26   1:20 /usr/sbin/httpdapache   27592  0.4  2.3 731732 359156 ?       S    08:55   2:31 /usr/sbin/httpdapache    3034  1.1  1.9 671352 305188 ?       S    17:08   0:12 /usr/sbin/httpdapache   19418  0.4  1.8 655996 290196 ?       S    13:52   0:53 /usr/sbin/httpdapache    3565  0.3  1.8 648820 277080 ?       S    10:37   1:16 /usr/sbin/httpdapache   27007  0.3  1.7 638380 273048 ?       S    15:26   0:25 /usr/sbin/httpdHence the alert got recovered we are marking this as resolved. Please let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XFVA7,Cloud Engineer Level 1,Closed,1100157,Incident,18-06-2018 23:22,,"Hello Team,We haven't heard back from you.At this time we are closing this case. Please reach us out if you have any query.###Hello Team,We have checked this issue and from the Sophos logs, we could see that your authentication was successful. 2018:06:14-11:30:47 spendhq aua[22054]: id=3004 severity=info sys=System sub=auth name=Authentication successful srcip=159.100.161.41 host= user=matthew caller=openvpn engine=local. Next Action : Please send a final remainder and close this case by EOD.###Hello Matthew, We haven't heard back from you. Please let us know if you are still facing the issue.###Hello Matthew,We haven't heard back from you.Please let us know if you are still facing the issue.###Hello Matthew,We have checked this issue and from the Sophos logs, we could see that your authentication was successful.2018:06:14-11:30:47 spendhq aua[22054]: id=3004 severity=info sys=System sub=auth name=Authentication successful srcip=159.100.161.41 host= user=matthew caller=openvpn engine=local.Please let us know if you are still facing this issue and kindly revert back to us in case of any queries.###Thenmozhy D <thenmozhy.d@reancloud.com>6:10 PM (54 minutes ago)to REAN, Matthew Hello Matthew,We will check on this and will let you know the updates.","I am unable to get onto the vpn. Please diagnose the issue. I am using the password you sent.-- Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",VPN,,14-06-2018 16:54,102,0,SpendHQ,"Hello Team,We haven't heard back from you.At this time we are closing this case. Please reach us out if you have any query.","Hello Team,We have checked this issue and from the Sophos logs, we could see that your authentication was successful. 2018:06:14-11:30:47 spendhq aua[22054]: id=3004 severity=info sys=System sub=auth name=Authentication successful srcip=159.100.161.41 host= user=matthew caller=openvpn engine=local. Next Action : Please send a final remainder and close this case by EOD.","Hello Matthew, We haven't heard back from you. Please let us know if you are still facing the issue.","Hello Matthew,We haven't heard back from you.Please let us know if you are still facing the issue.","Hello Matthew,We have checked this issue and from the Sophos logs, we could see that your authentication was successful.2018:06:14-11:30:47 spendhq aua[22054]: id=3004 severity=info sys=System sub=auth name=Authentication successful srcip=159.100.161.41 host= user=matthew caller=openvpn engine=local.Please let us know if you are still facing this issue and kindly revert back to us in case of any queries.","Thenmozhy D <thenmozhy.d@reancloud.com>6:10 PM (54 minutes ago)to REAN, Matthew Hello Matthew,We will check on this and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001lPl0J,Cloud Engineer Level 1,Closed,1112896,Incident,11-03-2019 08:38,,"Hello Team, This is to inform you that EBS high Disk usage alert for /dev/sda disk on sphq-db2-20180830 - (10.59.10.45) got recovered. Current utilization is 81.8% As of now, we are marking this case resolved. Feel free to reopen if you have any related queries.###Current Value: 93.4###Hello Team,This is a quick follow up.We have informed that the alert is a still open state with a value of  92.8%.The current utilization for the Disk usages 92.8% /dev/sda        8.0T  7.0T  558G  93% /usr/local/mariadbPlease check the below-mentioned Disk utilization details:/usr/local/mariadb/*7.0T    /usr/local/mariadb/columnstore16K     /usr/local/mariadb/lost+found=================================/usr/local/mariadb/columnstore/*109M    /usr/local/mariadb/columnstore/bin1.3G    /usr/local/mariadb/columnstore/data12K     /usr/local/mariadb/columnstore/data17.0T    /usr/local/mariadb/columnstore/data24.0K    /usr/local/mariadb/columnstore/data3268K    /usr/local/mariadb/columnstore/etc258M    /usr/local/mariadb/columnstore/lib40K     /usr/local/mariadb/columnstore/local665M    /usr/local/mariadb/columnstore/mysql24K     /usr/local/mariadb/columnstore/post4.0K    /usr/local/mariadb/columnstore/releasenum=============================================Please review the details and delete the unwanted files.Thanks###@Team:Please share the latest utilization with the customer and ask them for clean up or increase the size.###Hello Team, We haven't heard back from you. Please see the analysis we shared with you in the previous comment and let us know your update Regards###Current utilization- 90.8###Hello Team This is to notify you that we have received an EBS high Disk usage alert with a current value of 90.2%. While checking we could see that the folder is consuming 6.8TB of space and having 760 GB free space. Resource details : Instance name : SPHQ-DB2-20180830 Instance ID : i-0105d8ab19d508dd6 private IP : 10.59.10.45 The following is the disk usage details : 6.8T	/usr/local/mariadb/columnstore 16K	/usr/local/mariadb/lost+found Since this ISCSI volume is not manged from our end, please check the details from your end and let us know if you have any further queries. Regards Athira###Hello Team This is to notify you that we have received an EBS high Disk usage alert for thesphq-db2-20180830 - 10.59.10.45The current disk utilization is 90.1%. We will fetch the disk usage details and will get back to you. Regards","________________________________From: Datadog Alerting <alert@dtdg.co>Sent: 06 March 2019 8:05 PMTo: REAN Managed ServicesSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db2-20180830 - 10.59.10.45***** EXTERNAL EMAIL *****[Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db2-20180830 - 10.59.10.45High Disk Usage detected on the device /dev/sda   @rean_ms@hitachivantara.com[Metric Graph]<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUoWkg1TaDWRbuj3-2F0I-2Fq2mUlX9yrNoT3ot3yo8ed0x-2FsMX0XPJvvWCi-2Frhw44rvs0xdOjpLMHyo2YJwCTzNnzYjG-2BS9APzRqg01Jjjdwxq2x6fOWAW4stLrE0VRKiEfMCADwEWpsf-2FyVaQaR7Xu-2FM8eA-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij3048rcRGk9MzHmKYZc8y28nqJj9QSdNmD-2F6TV-2FMAhc4oyut1grUNFvFhAa3-2FrAv3g-2FCF8s2H0W1WtN0GBhG1xd5smuH-2F34MsfZCdMs-2FP7bAunCGqXJcJSpasdHqAHNejlj4YKGnOw7KCWkhYh3mixPHrW9n3T88EYpMU-2FJNKeknwpwkgaFiEzyAzMjpQQR1kaEhoZ-2FJYBwPh1uTFIbLnAvd&data=01%7C01%7Canu.pappachan%40hitachivantara.com%7C806e4b584b904e444e5f08d6a241091f%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=D3O6t976QExsbj8pyTKRarHzvlqYfKJq%2BY54WAmzQgo%3D&reserved=0>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 90The monitor was last triggered at Wed Mar 06 2019 14:35:49 UTC (2 secs ago).________________________________[Monitor Status<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUoKvcGnAzkyStJKdzb6NVcA5t2M-2BrFxoMN2TmHLeZCbSYfp82eDhSdg741ilgwakJA2sRnb5OtKBGKtkhY-2BP1lUA-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij3048rcRGk9MzHmKYZc8y28nqJj9QSdNmD-2F6TV-2FMAhc4o1FxynyMgyvMHMMO0LPtb2quFyUGO8c33GdYgvWSvzrhkZ4Qw9BgxEnSYEnEKfkO9jO1QBLoc8J-2B-2B73zRzB-2FtHEGRtNoXN-2BIHnMFxk1faJH2aIZ1QUrc1Z-2Bf1wXKk-2BdIukrDb3g4R-2BsgHqXqEna95w8UffUoo3HoJcy3d8Fnt-2BaI&data=01%7C01%7Canu.pappachan%40hitachivantara.com%7C806e4b584b904e444e5f08d6a241091f%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=GzRmX%2Fhia1%2FILF6uoYq0JnD%2FKEpHICcahayK2IdpVW0%3D&reserved=0>] · [Edit Monitor<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUo3IM-2FbEP-2FJM89epazZbNBUA-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij3048rcRGk9MzHmKYZc8y28nqJj9QSdNmD-2F6TV-2FMAhc4o-2BhLVzNHPKYfEu6-2Fm3j2rfqDWRic0cDuVaOGIv8xRKu9VpJjA2UNR5XmRkQIuAK2eQ8Ymw1BJjMypjuwrnx-2BZWc-2BL7Jys5Uo63BBCddtVR3dXz1ET9Z1i-2FWhgyK2C4VyKhRqJUkwckrNZEUWQlSSAhTtHBguKvZmc6TIlmPNohvV&data=01%7C01%7Canu.pappachan%40hitachivantara.com%7C806e4b584b904e444e5f08d6a241091f%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=kOWQVXhFFXHSawPEPa%2FjQjbf5TFrUT0ao7knZk2RJM4%3D&reserved=0>] · [View i-0105d8ab19d508dd6<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEDKT1NZt0tnkwEaAxSQZgjulmG8eAXgJiEQQ1IARF6DGABH4uVqjj5aQfIiB59UCaQ-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij3048rcRGk9MzHmKYZc8y28nqJj9QSdNmD-2F6TV-2FMAhc4oxp0FstzF-2B6DGQW5uvl8O9jimug3rJbwT8TW7xUxrFPM8-2FDGY5ItvPsIMfP2ZOXREzjBRbzGifmJxqVUkcu6o9yk4htyNqmAAVhBSl2uS9VdeHNaNFN1ag7MgEbdQS8mG1awe7FQoe3ZfRAtUvfPQw9Sug01QWqQoDT1kVLZWDAm&data=01%7C01%7Canu.pappachan%40hitachivantara.com%7C806e4b584b904e444e5f08d6a241091f%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=SQk50oQfl7gQlegyUJ8nQasW7iUslUf4tnhGDK0R2mk%3D&reserved=0>] · [Show Processes<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQED-2FFPDBbKPsalSo1i1ufo6S-2FX4pKstbDP3BrKs5ghv717DsrKU2LyIwuf4p8Z2rdAaAjQ68Va2pk9B-2FGQPPGNJgF7zE-2Buf-2BoeZntek7wd3Datl8i1ZGKs39HFAkEfiQicz6azjJOyT0-2F0-2B96nIb9aaf8tgc5XwE8x2oUKCSBTYtT5VP4kt8HeUznSDUzh0AsvA-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij3048rcRGk9MzHmKYZc8y28nqJj9QSdNmD-2F6TV-2FMAhc4o-2FKWKsoNYu6QLB8Aj4C9ydoRLe7PlM4xV73NdQJA9EbVbb4Oarw1Y94D-2BHuCySw1i-2B-2Bv5n11oflRDXl-2BKuIyB3z0iElJMMPjr7lygQod1Fr7Vb91uHm0br-2BgOQ6YhfqmNd2-2BWGG2KPkQGxXTDvcaQiH96-2BcxR7-2Bzg2DFVqYGUwub&data=01%7C01%7Canu.pappachan%40hitachivantara.com%7C806e4b584b904e444e5f08d6a241091f%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=YQPf%2BaQI8%2Bp8ICt3CKpOgb5q4YA86qudWBTLzUqfow0%3D&reserved=0>]This alert was raised by account SpendHQComment in Datadog<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAYJwPp8omKJuncXDFvQtom5GoxdzuV1WE6iEwEBaonjqrcqlYEuTAkje-2FB9fDB1-2Bs-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij3048rcRGk9MzHmKYZc8y28nqJj9QSdNmD-2F6TV-2FMAhc4o9PUqJAh-2FyHtvMLvsIf82kpQXvWzERxBd9b0XgMrm849RezoT3BpanQs44l8ltzC6N03ELreqt5vWEJJHy-2F7DvujLMYpX-2B6khQAjhshhGq3k2T6k2dXrpW9VvN54nvYn6XX1o4EqZCPYl3Zv39IUGHOXlsRlaIFlo4n42wINjK-2BK&data=01%7C01%7Canu.pappachan%40hitachivantara.com%7C806e4b584b904e444e5f08d6a241091f%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=GiPIu%2Ft0s06R2qwtiyApcxr8y%2B8rfFljqR8%2BWFojVIs%3D&reserved=0>To manage your Datadog subscriptions, click here<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECkg7AnUPKGn51plZlHct1NB9fwJzgmRoiq4UZtJ-2F9d6Q-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij3048rcRGk9MzHmKYZc8y28nqJj9QSdNmD-2F6TV-2FMAhc4oxTklsMSJ8QD-2FTQG-2F5mOztkrqhggwg5wxo2VDi1LmPKPq2e8FCRNrlW-2BWjmGFtCn9mYfzHMo2CHzQbqFLj1-2BakZi5bZmGCbO-2BkbZ8HtYM6gjmL5CTRZP1RRvZ6FRsl-2Bj9u4ejukrTW8GS2iG81-2F5HzZmQWX3UOQM8VifSTMAhlcR&data=01%7C01%7Canu.pappachan%40hitachivantara.com%7C806e4b584b904e444e5f08d6a241091f%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=2RLT%2BQaGnGWC2XH1szJHbqZdfrpbZJxL9U0QI4wD7so%3D&reserved=0>.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db2-20180830 - 10.59.10.45,,06-03-2019 20:39,108,0,SpendHQ,"Hello Team, This is to inform you that EBS high Disk usage alert for /dev/sda disk on sphq-db2-20180830 - (10.59.10.45) got recovered. Current utilization is 81.8% As of now, we are marking this case resolved. Feel free to reopen if you have any related queries.",Current Value: 93.4,"Hello Team,This is a quick follow up.We have informed that the alert is a still open state with a value of  92.8%.The current utilization for the Disk usages 92.8% /dev/sda        8.0T  7.0T  558G  93% /usr/local/mariadbPlease check the below-mentioned Disk utilization details:/usr/local/mariadb/*7.0T    /usr/local/mariadb/columnstore16K     /usr/local/mariadb/lost+found=================================/usr/local/mariadb/columnstore/*109M    /usr/local/mariadb/columnstore/bin1.3G    /usr/local/mariadb/columnstore/data12K     /usr/local/mariadb/columnstore/data17.0T    /usr/local/mariadb/columnstore/data24.0K    /usr/local/mariadb/columnstore/data3268K    /usr/local/mariadb/columnstore/etc258M    /usr/local/mariadb/columnstore/lib40K     /usr/local/mariadb/columnstore/local665M    /usr/local/mariadb/columnstore/mysql24K     /usr/local/mariadb/columnstore/post4.0K    /usr/local/mariadb/columnstore/releasenum=============================================Please review the details and delete the unwanted files.Thanks",@Team:Please share the latest utilization with the customer and ask them for clean up or increase the size.,"Hello Team, We haven't heard back from you. Please see the analysis we shared with you in the previous comment and let us know your update Regards",Current utilization- 90.8,"Hello Team This is to notify you that we have received an EBS high Disk usage alert with a current value of 90.2%. While checking we could see that the folder is consuming 6.8TB of space and having 760 GB free space. Resource details : Instance name : SPHQ-DB2-20180830 Instance ID : i-0105d8ab19d508dd6 private IP : 10.59.10.45 The following is the disk usage details : 6.8T	/usr/local/mariadb/columnstore 16K	/usr/local/mariadb/lost+found Since this ISCSI volume is not manged from our end, please check the details from your end and let us know if you have any further queries. Regards Athira",Hello Team This is to notify you that we have received an EBS high Disk usage alert for thesphq-db2-20180830 - 10.59.10.45The current disk utilization is 90.1%. We will fetch the disk usage details and will get back to you. Regards,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VPRPk,Cloud Engineer Level 2,Closed,1097689,Incident,09-05-2018 06:37,,"Hello Allen,This is the gentle reminder.Please review the previous comment and let us know if you have queries.###Hi Allen,The ISCSI Volumes are not mounted permanently as this device name changes everytime we reboot the machine. Therefore, we cannot make a fstab entry for the same which also create the issue when we reboot it. The ISCSI volumes needs to be mounted manually whenever the reboot happens as it get unmounted. We are working on resolving the mount issue of ISCSI volumes. For now, we have re-mounted the ISCSI volumes again to the folders /usr/local/mariadb and /mnt/mysqldumps. Please verify the data and let us know if you have any issue in accessing the same. Thanks !Regards,Rohit Puri###We have mounted the two volume and inform customer###We have received another mail from Allen :  Mounts Missing(01098001)Why did this happen again. I rebooted the server 10.59.10.180 and both my 4TB mounts are missing. Please remount this ASAP and permanently resolve this issue. For starters I see in the fstab the mounts are commented out. Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###Evening OPS call Rohit updated that he will check and update.Next action: Please check with Rohit in morning hours.###I have unmounted the /dev/sdq from the mount point /mnt/mysqldumps.as per the customer update, we have to mount it to 4TB mount.Please check with Rohit to get the mount details.###Allen Herrera8:42 PM (7 minutes ago)to Jamelunissa, Rohit, REAN NOPE!Bad mount./mnt/mysqldumps isn’t what it used to be.It was a 4TB mount.Please remove whatever you did here for this mount and put on the correct one.###Hello Allen,We will revert back the changes and will let you know the updates.###Hello Allen, We haven't heard back from you.We have mounted all mount points back to the instance. Please find the details in attachments section.Please let us know if you have any queries.###Hello Allen,We have mounted all mount points back to the instance. Please find the details in attachments section.Please let us know if you have any queries.###Hello Allen,We will check on this and will let you know the updates.###Allen Herrera2:24 AM (7 minutes ago)to Rohit, Matthew, spendhq-support, REAN, Andrew Status? Why isn’t /mnt/mysqldumps still not up###Allen Herrera11:15 PM (1 hour ago)to Rohit, Matthew, spendhq-support, REAN, Andrew Yup /usr/local/mariadb looks good. What about the mount @ /mnt/mysqldumps###Allen Herrera11:11 PM (1 hour ago)to Rohit, Matthew, spendhq-support, REAN, Andrew Yeah my 4TB mount should be at /usr/local/mariadbDon’t forget the other mount for /mnt/mysqldumps###Hi Allen,We analysed the issue, we found that the instances was not coming up because it was looking for the ISCSI volumes for which the entries made in the /etc/fstab file. As the device location changes for ISCSI volumes once it reboot therefore it was looking for the device to be mounted and it was failing to do. We have commented the /etc/fstab entry for ISCSI volumes. The instance is up now. We are bit confuse to mount the ISCSI Volume. Please let us know where you want us to mount the ISCSI Volume either to /usr/local/mariadb or /usr/local/mariadb-2018-04-17. Thanks!Regards,Rohit Puri###Hi Allen,We have mounted the 4TB volume to the /usr/local/mariadb. Please verify the data. Thanks !Regards,Rohit Puri###Hello Allen,We have performed the restart on the instance but the instance but still, the instance status got failed.In order to troubleshoot further on this, we need to launch a new test instance and attach the root volume of the instance  10.59.10.180  to the test instance.We will perform the analysis and will get back to you with the updates.###Hello Allen,We are checking on this issue and will get back to you with the updates.###Hello Allen,While checking we could see that the instance status got failed for the instance  10.59.10.180 .We are unable to login to this instance. Please provide us your approval to perform stop and start on the instance.","Hey Rean,I need 10.59.10.180 back online asap so I can continue working on our new database.Last Thursday I ran a reboot and the server never came back upAllen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",10.59.10.180 Server not coming back online after reboot,,30-04-2018 18:59,238,0,SpendHQ,"Hello Allen,This is the gentle reminder.Please review the previous comment and let us know if you have queries.","Hi Allen,The ISCSI Volumes are not mounted permanently as this device name changes everytime we reboot the machine. Therefore, we cannot make a fstab entry for the same which also create the issue when we reboot it. The ISCSI volumes needs to be mounted manually whenever the reboot happens as it get unmounted. We are working on resolving the mount issue of ISCSI volumes. For now, we have re-mounted the ISCSI volumes again to the folders /usr/local/mariadb and /mnt/mysqldumps. Please verify the data and let us know if you have any issue in accessing the same. Thanks !Regards,Rohit Puri",We have mounted the two volume and inform customer,We have received another mail from Allen :  Mounts Missing(01098001)Why did this happen again. I rebooted the server 10.59.10.180 and both my 4TB mounts are missing. Please remount this ASAP and permanently resolve this issue. For starters I see in the fstab the mounts are commented out. Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com,Evening OPS call Rohit updated that he will check and update.Next action: Please check with Rohit in morning hours.,"I have unmounted the /dev/sdq from the mount point /mnt/mysqldumps.as per the customer update, we have to mount it to 4TB mount.Please check with Rohit to get the mount details.","Allen Herrera8:42 PM (7 minutes ago)to Jamelunissa, Rohit, REAN NOPE!Bad mount./mnt/mysqldumps isn’t what it used to be.It was a 4TB mount.Please remove whatever you did here for this mount and put on the correct one.","Hello Allen,We will revert back the changes and will let you know the updates.","Hello Allen, We haven't heard back from you.We have mounted all mount points back to the instance. Please find the details in attachments section.Please let us know if you have any queries.","Hello Allen,We have mounted all mount points back to the instance. Please find the details in attachments section.Please let us know if you have any queries.","Hello Allen,We will check on this and will let you know the updates.","Allen Herrera2:24 AM (7 minutes ago)to Rohit, Matthew, spendhq-support, REAN, Andrew Status? Why isn’t /mnt/mysqldumps still not up","Allen Herrera11:15 PM (1 hour ago)to Rohit, Matthew, spendhq-support, REAN, Andrew Yup /usr/local/mariadb looks good. What about the mount @ /mnt/mysqldumps","Allen Herrera11:11 PM (1 hour ago)to Rohit, Matthew, spendhq-support, REAN, Andrew Yeah my 4TB mount should be at /usr/local/mariadbDon’t forget the other mount for /mnt/mysqldumps","Hi Allen,We analysed the issue, we found that the instances was not coming up because it was looking for the ISCSI volumes for which the entries made in the /etc/fstab file. As the device location changes for ISCSI volumes once it reboot therefore it was looking for the device to be mounted and it was failing to do. We have commented the /etc/fstab entry for ISCSI volumes. The instance is up now. We are bit confuse to mount the ISCSI Volume. Please let us know where you want us to mount the ISCSI Volume either to /usr/local/mariadb or /usr/local/mariadb-2018-04-17. Thanks!Regards,Rohit Puri","Hi Allen,We have mounted the 4TB volume to the /usr/local/mariadb. Please verify the data. Thanks !Regards,Rohit Puri","Hello Allen,We have performed the restart on the instance but the instance but still, the instance status got failed.In order to troubleshoot further on this, we need to launch a new test instance and attach the root volume of the instance  10.59.10.180  to the test instance.We will perform the analysis and will get back to you with the updates.","Hello Allen,We are checking on this issue and will get back to you with the updates.","Hello Allen,While checking we could see that the instance status got failed for the instance  10.59.10.180 .We are unable to login to this instance. Please provide us your approval to perform stop and start on the instance.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XzNYN,Cloud Engineer Level 1,Closed,1100632,Incident,26-06-2018 02:51,,"The Alert being recovered, we are marking the case as resolved and therefore closing the case.Please reach out to us in case of any concerns.Thanks.###Hello team, From our analysis we found the below mentioned top 10 processes that took most CPU time.TIME CMD:57:45 /opt/datadog-agent/embedded/bin/python /opt/datadog-:50:26 /usr/sbin/nrsysmond -c /etc/newrelic/nrsysmond.cfg -:49:53 /usr/java/default/bin/java -Djava.util.logging.confi:46:35 /opt/datadog-agent/embedded/bin/python /opt/datadog-:46:04 /usr/sbin/httpd:44:42 /opt/datadog-agent/bin/trace-agent:44:14 /usr/sbin/httpd:42:46 /usr/sbin/httpd:42:23 /usr/sbin/httpd###Hello team,This is to notify you that we have received an alert regarding high CPU load on the instance PRD-WW2_6. The CPU load exceeded the set threshold of 3 but eventually got recovered after 22 mins. We are analyzing on this and we will update you on the findings.Instance Details:Instance ID: i-01ac95c23ac66a40eInstance Name: PRD-WW2_6Instance Type: m4.2xlargeVPC: vpc-76df7212IP: 10.59.101.6","[image: Datadog][Triggered] [SpendHQ] - High CPU Load on host prd-ww2_6 - 10.59.101.6 - webDetected High CPU load. Log in to the machine and verify which process isconsuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023975?to_ts=1529956185000&group=host%3Ai-01ac95c23ac66a40e&from_ts=1529952585000>*system.load.15* over *datadog_monitor:on,host:i-01ac95c23ac66a40e* was *>3.0* on average during the *last 5m*.The monitor was last triggered at Mon Jun 25 2018 19:49:55 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023975?group=host%3Ai-01ac95c23ac66a40e>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023975/edit>] · [Viewi-01ac95c23ac66a40e<https://app.datadoghq.com/infrastructure?filter=i-01ac95c23ac66a40e>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1529956195000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1529955295000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4457594396500710019>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Paul MulonziaREĀN Cloud | Reach, Engage, Āctivate, Nurtur-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on host prd-ww2_6 - 10.59.101.6 - web,,26-06-2018 01:36,1,0,SpendHQ,"The Alert being recovered, we are marking the case as resolved and therefore closing the case.Please reach out to us in case of any concerns.Thanks.","Hello team, From our analysis we found the below mentioned top 10 processes that took most CPU time.TIME CMD:57:45 /opt/datadog-agent/embedded/bin/python /opt/datadog-:50:26 /usr/sbin/nrsysmond -c /etc/newrelic/nrsysmond.cfg -:49:53 /usr/java/default/bin/java -Djava.util.logging.confi:46:35 /opt/datadog-agent/embedded/bin/python /opt/datadog-:46:04 /usr/sbin/httpd:44:42 /opt/datadog-agent/bin/trace-agent:44:14 /usr/sbin/httpd:42:46 /usr/sbin/httpd:42:23 /usr/sbin/httpd","Hello team,This is to notify you that we have received an alert regarding high CPU load on the instance PRD-WW2_6. The CPU load exceeded the set threshold of 3 but eventually got recovered after 22 mins. We are analyzing on this and we will update you on the findings.Instance Details:Instance ID: i-01ac95c23ac66a40eInstance Name: PRD-WW2_6Instance Type: m4.2xlargeVPC: vpc-76df7212IP: 10.59.101.6",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001f5Jee,Cloud Engineer Level 3,Closed,1108465,Incident,30-11-2018 14:15,,"Hello Team,Your ticket #01108465 is auto closed. We are closing the ticket as no action was performed from your end. If the ticket is closed erroneously, feel free to reopen the ticket. For any escalation, please send an email to reansupportescalation@reancloud.com .We look forward to serve you. Feel free to reach out to us at support@reancloud.com for any additional queries.Rean Cloud Solutionssupport@reancloud.com###@Team:Wormly issue is a separate thing. We will check on that internally and make the changes. Do send a closure email on this case today itself. Thanks.###Please check with Rohit on the wormly response.###[Wormly Response]Hello,Thanks very much for contacting us. The SpendHQ Secure host is using the REAN Support alert group which is set to alert after 1 minute of downtime. However, if you look at the details of the downtime the host would show an error and then recover on the next check, so it was never actually down and unavailable for 1 minute. In order to be alerted the host would need to fail 2 consecutive checks (the initial check and the one a minute later) or you would need to change the alert group to alert on initial failure.If there is anything further that we can help you with, please don't hesitate to contact us. Best Regards,Henrik Hudson###Hello Mattew,This is a followup email,Please let us know if we are good to close this case.###@team, We have raised a support ticket with Wormly but didn't get any response. Please check with CC for the next update.###Matthew Watts7:12 PM (7 minutes ago)to Rean﻿Thank you for the update. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting###Hello Team,This is a follow up for the RCA. Please review our analysis below.We checked all the related resources to the secure.spendhq.com site down an issue. 1. On ELB level we compared the metrics of both the ELBs (external and Internal) and we do not see any issue at SOPHOS level as the metrics resemble the same for both at given site downtime. 2. We have re-check the logs of instances attached behind the NewPreview-ELB i.e PRD-WW2_6 and WW3_WEB_PROD. We found the below logs: [Mon Nov 26 15:21:43 2018] [error] [client 10.59.101.180] PHP Fatal error: Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710 [Mon Nov 26 15:21:43 2018] [error] [client 10.59.101.180] PHP Fatal error: Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710 [Mon Nov 26 15:22:03 2018] [error] [client 10.59.101.180] PHP Fatal error: Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710 [Mon Nov 26 15:33:20 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50594738 [Mon Nov 26 15:34:53 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50087076 [Mon Nov 26 15:39:46 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/category_detail/subcategories/category:U2l0ZSBTZXJ2aWNlcw/ [Mon Nov 26 15:44:43 2018] [error] [client 10.59.101.180] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50087076 [Mon Nov 26 15:44:46 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c788 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c788. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/ [Mon Nov 26 15:44:50 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c847 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c847. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/ [Mon Nov 26 15:45:31 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c525 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c525. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/ [Mon Nov 26 15:50:19 2018] [error] [client 10.59.100.64] SHQ_Exception: [11]: New Table Mapper version for company_db isg_otpp is 68 in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/super_admin_controller.php on line 3366 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/ Along with PHP Fatal error, we also noticed some table missing from the ISG db. 3. We checked the PRD-DB1 instance for more analysis, we didn't find much on this as there any such logs to analysis and we do not have access to there database. Please let us know if want more to discuss on this or have any other concerns regarding the same and we are available to jump on a call as per your availability.Regards,Rafi Ramesh Pune India###@Praveen:We checked all the related resources to the secure.spendhq.com site down issue. Here are conclusion on this:1. On ELB level we compared the metrics of both the ELBs (external and Internal) and we do not see any issue at SOPHOS level (this was what we came to on conclusion yesterday too in the Ops Call) as the metrics resembles the same for both at given site down time.2. We have re-check the logs of instances attached behind the NewPreview-ELB i.e PRD-WW2_6 and WW3_WEB_PROD. We found the below logs:[Mon Nov 26 15:21:43 2018] [error] [client 10.59.101.180] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710[Mon Nov 26 15:21:43 2018] [error] [client 10.59.101.180] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710[Mon Nov 26 15:22:03 2018] [error] [client 10.59.101.180] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710[Mon Nov 26 15:33:20 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50594738[Mon Nov 26 15:34:53 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50087076[Mon Nov 26 15:39:46 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/category_detail/subcategories/category:U2l0ZSBTZXJ2aWNlcw/[Mon Nov 26 15:44:43 2018] [error] [client 10.59.101.180] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50087076[Mon Nov 26 15:44:46 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c788 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c788. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/[Mon Nov 26 15:44:50 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c847 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c847. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/[Mon Nov 26 15:45:31 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c525 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c525. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/[Mon Nov 26 15:50:19 2018] [error] [client 10.59.100.64] SHQ_Exception: [11]: New Table Mapper version for company_db isg_otpp is 68 in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/super_admin_controller.php on line 3366 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/Along with PHP Fatal error, we also noticed some table missing from the ISG db.3. We checked the PRD-DB1 instance for more analysis, we dint find much on this as there no such logs to analysis and we do not have access to there database.4. For Wormly, we have raised the support ticket and made changes to the Alert Group to Rean Support for now.Please let us know your thoughts on this. Thanks !###@team,on ops call Praveen asked some queries. cc said he will check and consolidate that details with that queries and update customer through the mail or call.###Hello Team,We have analyzed the issue and created an RCA document regarding the outage it contains the information regarding 1. Affected resource details 2. Root Cause Analysis  3. Corrective Actions4. Preventive actions 5. The sequence of events performed by REAN team. Please review the RCA document which is attached in the ticket attachments. Provide approval to perform the action items as mentioned in the Preventive actions sections And let us know if you have any further queries.###@Team:I reviewed the RCA please share with the customer.###Hello Matthew,No, there was no issue with the Sophos. We mentioned Sophos to point out the ELB target.The issue was because of High Latency. From the CloudWatch Metrics, we can see high spikes in Latency Graph. We also could see that the failure was because the requests were coming from the Sophos server “10.59.1.192” and giving 500 response code and wormly was expecting 200 code. Please find the ELB logs in the attachment section and let us know if you have any queries.###Matthew Watts12:23 AM (0 minutes ago)to ReanAre we suggesting this was a Sophos issue?###The URL was inaccessible for 1 min and we have the testing interval set to 1 min in wormly so we were not notified while the URL was inaccessible.###Hello Team,We have further checked the details, the Secure-SpendHQ-ELB is pointed to the Sophos Instance and from there, it is pointed to PRD-WW2_6(10.59.101.6) WebServer instance which is attached to the NewPeview-ELB. And the backend DB server is PRD-DB1(10.59.10.190).We have analyzed the WebServer Instance metrics where it usage looks fine and from Instance level, we have analyzed the system messages, httpd logs which are also good at the time of this issue.We couldn’t find any suspicious activity from both AWS and instance level for the backend server.Only we could able to see the high spike on average latency from the ELB metrics. The value is reached to 66144 ms during the time of the issue. Please find the screenshot for the same in the attachment section.From the wormly tool, we could see that the response code was 500 and On further checking the ELB logs, we found that the requests were coming from the Sophos server “10.59.1.192” and giving 500 response code. We have attached the logs in the attachment section.Kindly review this details and revert back to us in case of any queries.###Mail to leads sent.###Hello Matthew,We acknowledge your request, we are looking in it and will update you soon. As we can see now that the url: https://secure.spendhq.com/login is accessible and working fine now.","The domain secure.spendhq.com is down. Can you investigate REAN. No changes were made on this side.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://hubs.ly/H0fzGbl0>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SEV ONE,,26-11-2018 20:52,89,0,SpendHQ,"Hello Team,Your ticket #01108465 is auto closed. We are closing the ticket as no action was performed from your end. If the ticket is closed erroneously, feel free to reopen the ticket. For any escalation, please send an email to reansupportescalation@reancloud.com .We look forward to serve you. Feel free to reach out to us at support@reancloud.com for any additional queries.Rean Cloud Solutionssupport@reancloud.com",@Team:Wormly issue is a separate thing. We will check on that internally and make the changes. Do send a closure email on this case today itself. Thanks.,Please check with Rohit on the wormly response.,"[Wormly Response]Hello,Thanks very much for contacting us. The SpendHQ Secure host is using the REAN Support alert group which is set to alert after 1 minute of downtime. However, if you look at the details of the downtime the host would show an error and then recover on the next check, so it was never actually down and unavailable for 1 minute. In order to be alerted the host would need to fail 2 consecutive checks (the initial check and the one a minute later) or you would need to change the alert group to alert on initial failure.If there is anything further that we can help you with, please don't hesitate to contact us. Best Regards,Henrik Hudson","Hello Mattew,This is a followup email,Please let us know if we are good to close this case.","@team, We have raised a support ticket with Wormly but didn't get any response. Please check with CC for the next update.","Matthew Watts7:12 PM (7 minutes ago)to Rean﻿Thank you for the update. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting","Hello Team,This is a follow up for the RCA. Please review our analysis below.We checked all the related resources to the secure.spendhq.com site down an issue. 1. On ELB level we compared the metrics of both the ELBs (external and Internal) and we do not see any issue at SOPHOS level as the metrics resemble the same for both at given site downtime. 2. We have re-check the logs of instances attached behind the NewPreview-ELB i.e PRD-WW2_6 and WW3_WEB_PROD. We found the below logs: [Mon Nov 26 15:21:43 2018] [error] [client 10.59.101.180] PHP Fatal error: Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710 [Mon Nov 26 15:21:43 2018] [error] [client 10.59.101.180] PHP Fatal error: Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710 [Mon Nov 26 15:22:03 2018] [error] [client 10.59.101.180] PHP Fatal error: Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710 [Mon Nov 26 15:33:20 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50594738 [Mon Nov 26 15:34:53 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50087076 [Mon Nov 26 15:39:46 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/category_detail/subcategories/category:U2l0ZSBTZXJ2aWNlcw/ [Mon Nov 26 15:44:43 2018] [error] [client 10.59.101.180] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50087076 [Mon Nov 26 15:44:46 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c788 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c788. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/ [Mon Nov 26 15:44:50 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c847 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c847. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/ [Mon Nov 26 15:45:31 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c525 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c525. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/ [Mon Nov 26 15:50:19 2018] [error] [client 10.59.100.64] SHQ_Exception: [11]: New Table Mapper version for company_db isg_otpp is 68 in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/super_admin_controller.php on line 3366 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/ Along with PHP Fatal error, we also noticed some table missing from the ISG db. 3. We checked the PRD-DB1 instance for more analysis, we didn't find much on this as there any such logs to analysis and we do not have access to there database. Please let us know if want more to discuss on this or have any other concerns regarding the same and we are available to jump on a call as per your availability.Regards,Rafi Ramesh Pune India","@Praveen:We checked all the related resources to the secure.spendhq.com site down issue. Here are conclusion on this:1. On ELB level we compared the metrics of both the ELBs (external and Internal) and we do not see any issue at SOPHOS level (this was what we came to on conclusion yesterday too in the Ops Call) as the metrics resembles the same for both at given site down time.2. We have re-check the logs of instances attached behind the NewPreview-ELB i.e PRD-WW2_6 and WW3_WEB_PROD. We found the below logs:[Mon Nov 26 15:21:43 2018] [error] [client 10.59.101.180] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710[Mon Nov 26 15:21:43 2018] [error] [client 10.59.101.180] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710[Mon Nov 26 15:22:03 2018] [error] [client 10.59.101.180] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4710[Mon Nov 26 15:33:20 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50594738[Mon Nov 26 15:34:53 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50087076[Mon Nov 26 15:39:46 2018] [error] [client 10.59.100.64] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/category_detail/subcategories/category:U2l0ZSBTZXJ2aWNlcw/[Mon Nov 26 15:44:43 2018] [error] [client 10.59.101.180] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:50087076[Mon Nov 26 15:44:46 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c788 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c788. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/[Mon Nov 26 15:44:50 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c847 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c847. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/[Mon Nov 26 15:45:31 2018] [error] [client 10.59.100.64] SHQ_Exception: [10]: Table spend_visibility_c525 is missing from ISG db. Run sv_migrate_company.php shell script to create spend_visibility_c525. Documentation on sharepoint > developers in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 826 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/[Mon Nov 26 15:50:19 2018] [error] [client 10.59.100.64] SHQ_Exception: [11]: New Table Mapper version for company_db isg_otpp is 68 in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/super_admin_controller.php on line 3366 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/super_admin/manage_company/Along with PHP Fatal error, we also noticed some table missing from the ISG db.3. We checked the PRD-DB1 instance for more analysis, we dint find much on this as there no such logs to analysis and we do not have access to there database.4. For Wormly, we have raised the support ticket and made changes to the Alert Group to Rean Support for now.Please let us know your thoughts on this. Thanks !","@team,on ops call Praveen asked some queries. cc said he will check and consolidate that details with that queries and update customer through the mail or call.","Hello Team,We have analyzed the issue and created an RCA document regarding the outage it contains the information regarding 1. Affected resource details 2. Root Cause Analysis  3. Corrective Actions4. Preventive actions 5. The sequence of events performed by REAN team. Please review the RCA document which is attached in the ticket attachments. Provide approval to perform the action items as mentioned in the Preventive actions sections And let us know if you have any further queries.",@Team:I reviewed the RCA please share with the customer.,"Hello Matthew,No, there was no issue with the Sophos. We mentioned Sophos to point out the ELB target.The issue was because of High Latency. From the CloudWatch Metrics, we can see high spikes in Latency Graph. We also could see that the failure was because the requests were coming from the Sophos server “10.59.1.192” and giving 500 response code and wormly was expecting 200 code. Please find the ELB logs in the attachment section and let us know if you have any queries.",Matthew Watts12:23 AM (0 minutes ago)to ReanAre we suggesting this was a Sophos issue?,The URL was inaccessible for 1 min and we have the testing interval set to 1 min in wormly so we were not notified while the URL was inaccessible.,"Hello Team,We have further checked the details, the Secure-SpendHQ-ELB is pointed to the Sophos Instance and from there, it is pointed to PRD-WW2_6(10.59.101.6) WebServer instance which is attached to the NewPeview-ELB. And the backend DB server is PRD-DB1(10.59.10.190).We have analyzed the WebServer Instance metrics where it usage looks fine and from Instance level, we have analyzed the system messages, httpd logs which are also good at the time of this issue.We couldn’t find any suspicious activity from both AWS and instance level for the backend server.Only we could able to see the high spike on average latency from the ELB metrics. The value is reached to 66144 ms during the time of the issue. Please find the screenshot for the same in the attachment section.From the wormly tool, we could see that the response code was 500 and On further checking the ELB logs, we found that the requests were coming from the Sophos server “10.59.1.192” and giving 500 response code. We have attached the logs in the attachment section.Kindly review this details and revert back to us in case of any queries.",Mail to leads sent.,"Hello Matthew,We acknowledge your request, we are looking in it and will update you soon. As we can see now that the url: https://secure.spendhq.com/login is accessible and working fine now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001geOdm,Cloud Engineer Level 1,Closed,1109902,Incident,27-12-2018 07:17,,"Hello Team,We have cleaned up the IAM user shqstaging.ses-smtp-user.20151110. As this user is inactive and not used since last 90 days. At this time we are marking this case as resolved and closing this case. Please let us know if you have any further queries.###The user is already inactive and not used since last 90 days please clean it up.Praveen MuppalaCloud Architect / Tech Lead, Managed ServicesHitachi Vantara###Hello Team,This is to bring to your attention that the following user has been inactive and not used for more than 90 days. Please review and lets know if we can clean it up.Resource ID: AIDAJK3FYACFOPSPRP7E4User Name:shqstaging.ses-smtp-user.20151110Password Last Used: NeverAccess Keys Last Used: 2018-09-21","REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::IAM::User resources were affected:________________________________  *   Violation: The user account is not enabled and Inactive since last 90 days.  *   Recommendation: To prevent your account from getting Deleted, please LogIn to your account or user your API Keys.  *   Action taken: None  *   Resource details:Resource IDUser NamePassword Last UsedAccess Keys Last UsedAIDAJK3FYACFOPSPRP7E4shqstaging.ses-smtp-user.20151110Never2018-09-21________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Managed Cloud: spendhq] Inactive IAM Users Alert,,26-12-2018 17:22,14,0,SpendHQ,"Hello Team,We have cleaned up the IAM user shqstaging.ses-smtp-user.20151110. As this user is inactive and not used since last 90 days. At this time we are marking this case as resolved and closing this case. Please let us know if you have any further queries.","The user is already inactive and not used since last 90 days please clean it up.Praveen MuppalaCloud Architect / Tech Lead, Managed ServicesHitachi Vantara","Hello Team,This is to bring to your attention that the following user has been inactive and not used for more than 90 days. Please review and lets know if we can clean it up.Resource ID: AIDAJK3FYACFOPSPRP7E4User Name:shqstaging.ses-smtp-user.20151110Password Last Used: NeverAccess Keys Last Used: 2018-09-21",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001NQBZk,Cloud Engineer Level 1,Closed,1088117,Incident,08-01-2018 22:14,,"Hello Steven,Thanks for the update. At this time, we are marking this case as resolved. Kindly revert back incase of any further queries.Regards,Sumod.K.Bose###[Steven updated the case via Email]You can disregard this as she was familiarizing herself with the login. Steven Ng | Full Stack Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.com###Hello SpendHQ-Team,This is to inform you that we have received a notification stating Too many failed logins on Sophos web admin from the username grunnels. We have attached the authentication logs along with this ticket. Kindly validate it from your end and let us know if the user still faces any issues while trying to access the webadmin console. Also revert back incase of any further queries.Regards,Sumod.K.Bose",Too many failed logins from 10.242.2.7 for facility webadmin.Further logins will be blocked for 600 seconds.Failed WebAdmin login attempt from 10.242.2.7 at 2018-01-08 13:48:35 with username grunnels.,[spendhq][WARN-070] Too many failed logins,,08-01-2018 19:45,2,0,SpendHQ,"Hello Steven,Thanks for the update. At this time, we are marking this case as resolved. Kindly revert back incase of any further queries.Regards,Sumod.K.Bose",[Steven updated the case via Email]You can disregard this as she was familiarizing herself with the login. Steven Ng | Full Stack Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.com,"Hello SpendHQ-Team,This is to inform you that we have received a notification stating Too many failed logins on Sophos web admin from the username grunnels. We have attached the authentication logs along with this ticket. Kindly validate it from your end and let us know if the user still faces any issues while trying to access the webadmin console. Also revert back incase of any further queries.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001PfUAd,Cloud Engineer Level 1,Closed,1090371,Incident,15-02-2018 07:44,,"Andrew Kim <Akim@spendhq.com>8:36 PM (11 hours ago)to Rean, spendhq-support Thank you. Initial inspection appears that everything is working. We will continue to monitor and will reach out if additional assistance is needed. This ticket can be closed. Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hello Team,The maintenance scheduled on a AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA has been completed. Please verify it from your end and let us know if you are facing any issues.###Hello Team,This is to inform you that the planned maintenance scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA has been started from AWS. During this maintenance window, 1 Gbps AWS Direct Connect service ( Connection ID: dxcon-fg50qjyw) may become unavailable. We will get back to you once the maintenance is completed.###Created the calendar invite to inform customer regarding the maintenance###During Ops call, Praveen updated to inform team after the scheduled maintenance.###Hello SpendHQ-Team/Chris,This is to notify you that we have received a notification from AWS that there is a planned maintenance scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA from Wed, 14 Feb 2018 08:00:00 GMT to Wed, 14 Feb 2018 12:00:00 GMT for 4 hours. During this maintenance window, 1 Gbps AWS Direct Connect service ( Connection ID: dxcon-fg50qjyw) may become unavailable. We are using 10gbps and the 1 Gbps connection is used as a backup plan, this scheduled maintenance will not affect the environment. Please review and let us know if you have any queries.###Hello SpendHQ-Team, This is to notify you that we have received a notification from AWS that there is a planned maintenance scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA from Wed, 14 Feb 2018 08:00:00 GMT to Wed, 14 Feb 2018 12:00:00 GMT for 4 hours. During this maintenance window, 1 Gbps AWS Direct Connect service ( Connection ID: dxcon-fg50qjyw) may become unavailable. As the 1 Gbps connection is used as a backup plan, this scheduled maintenance will not affect the environment. Please review and let us know if you have any queries.","Thank You,Sanket Dangi---------- Forwarded message ----------From: Amazon Web Services, Inc. <no-reply-aws@amazon.com>Date: Wed, Feb 7, 2018 at 2:08 PMSubject: AWS Direct Connect Planned Maintenance Notification [AWS Account:261234435984]To: spendhq@reancloudsolutions.comHello AWS Direct Connect Customer,Planned maintenance has been scheduled on an AWS Direct Connect router inEquinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA from Wed, 14 Feb 201808:00:00 GMT to Wed, 14 Feb 2018 12:00:00 GMT for 4 hours. During thismaintenance window, your AWS Direct Connect services listed below maybecome unavailable.dxvif-fffiuqt9dxcon-fg50qjywThis maintenance is scheduled to avoid disrupting redundant connections atthe same time.If you encounter any problems with your connection after the end of thismaintenance window, please contact us at https://aws.amazon.com/support .Regards,The AWS Direct Connect TeamAmazon Web Services, Inc. is a subsidiary of Amazon.com, Inc. Amazon.com isa registered trademark of Amazon.com, Inc. This message was produced anddistributed by Amazon Web Services Inc., 410 Terry Ave. North, Seattle, WA98109-5210--  <https://signup.paloaltonetworks.com/ehome/305324>--  <https://signup.paloaltonetworks.com/ehome/305324>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: AWS Direct Connect Planned Maintenance Notification [AWS Account: 261234435984],,07-02-2018 14:40,185,0,SpendHQ,"Andrew Kim <Akim@spendhq.com>8:36 PM (11 hours ago)to Rean, spendhq-support Thank you. Initial inspection appears that everything is working. We will continue to monitor and will reach out if additional assistance is needed. This ticket can be closed. Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Hello Team,The maintenance scheduled on a AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA has been completed. Please verify it from your end and let us know if you are facing any issues.","Hello Team,This is to inform you that the planned maintenance scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA has been started from AWS. During this maintenance window, 1 Gbps AWS Direct Connect service ( Connection ID: dxcon-fg50qjyw) may become unavailable. We will get back to you once the maintenance is completed.",Created the calendar invite to inform customer regarding the maintenance,"During Ops call, Praveen updated to inform team after the scheduled maintenance.","Hello SpendHQ-Team/Chris,This is to notify you that we have received a notification from AWS that there is a planned maintenance scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA from Wed, 14 Feb 2018 08:00:00 GMT to Wed, 14 Feb 2018 12:00:00 GMT for 4 hours. During this maintenance window, 1 Gbps AWS Direct Connect service ( Connection ID: dxcon-fg50qjyw) may become unavailable. We are using 10gbps and the 1 Gbps connection is used as a backup plan, this scheduled maintenance will not affect the environment. Please review and let us know if you have any queries.","Hello SpendHQ-Team, This is to notify you that we have received a notification from AWS that there is a planned maintenance scheduled on an AWS Direct Connect router in Equinix DC1 - DC6 &amp; DC10 - DC12, Ashburn, VA from Wed, 14 Feb 2018 08:00:00 GMT to Wed, 14 Feb 2018 12:00:00 GMT for 4 hours. During this maintenance window, 1 Gbps AWS Direct Connect service ( Connection ID: dxcon-fg50qjyw) may become unavailable. As the 1 Gbps connection is used as a backup plan, this scheduled maintenance will not affect the environment. Please review and let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TlcCj,Cloud Engineer Level 1,Closed,1094483,Incident,30-03-2018 03:47,,"Hello SpendHQ Team,Please review our previous Comments and let us know if you have any query regarding this case.###Hello SpendHQ-Team, Please find the screenshot of the high network out on host - prd-db1 in the attachment section and let us know if you have performed any activity on your end.###Hello SpendHQ-Team,This is to notify you that we received an alert regarding High Network OUT on host - prd-db1 - - db has crossed the threshold value of 5 GB/min and reached to the value of 7.69 GB/min.The alert got resolved within 10 min. We are analyzing more on this issue and will get back to you with details.Resources Details:Instance:  i-03ccfddd9f02cacb9 (PRD-DB1)VPC ID: vpc-76df7212Subnet ID: subnet-0fdde924","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Wed, Mar 28, 2018 at 9:23 PMSubject: [Monitor Alert] Triggered: [SpendHQ] [DB] - High Network OUT onhost - prd-db1 - - dbTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] [DB] - High Network OUT on host - prd-db1 - - dbHigh Network OUT on the instance. Please check the list open TCPConnections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#4090577?to_ts=1522252387000&group=host%3Ai-03ccfddd9f02cacb9&from_ts=1522252087000>*aws.ec2.network_out* over *host:i-03ccfddd9f02cacb9* was *> 5368709120.0*at all times during the *last 5m*.The monitor was last triggered at Wed Mar 28 2018 15:53:17 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#4090577?group=host%3Ai-03ccfddd9f02cacb9>]· [Edit Monitor <https://app.datadoghq.com/monitors#4090577/edit>] · [Viewi-03ccfddd9f02cacb9<https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1522252397000&tags=host%3Ai-03ccfddd9f02cacb9&from_ts=1522251497000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4328346113417293986>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Regards,Jamelunissa MohammedHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081jamelunissa.mohammed@reancloud.com  | www.reancloud.com-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] [DB] - High Network OUT on host - prd-db1 - - db,,28-03-2018 21:26,89,0,SpendHQ,"Hello SpendHQ Team,Please review our previous Comments and let us know if you have any query regarding this case.","Hello SpendHQ-Team, Please find the screenshot of the high network out on host - prd-db1 in the attachment section and let us know if you have performed any activity on your end.","Hello SpendHQ-Team,This is to notify you that we received an alert regarding High Network OUT on host - prd-db1 - - db has crossed the threshold value of 5 GB/min and reached to the value of 7.69 GB/min.The alert got resolved within 10 min. We are analyzing more on this issue and will get back to you with details.Resources Details:Instance:  i-03ccfddd9f02cacb9 (PRD-DB1)VPC ID: vpc-76df7212Subnet ID: subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001CeLse,Cloud Engineer Level 1,Closed,1058808,Incident,02-06-2017 18:29,,"Hello Steven,We have disabled the maintenance mode for the URL https://preview.spendhq.com/login.Please let us know if you have any further queries.###As this is a maintenance activity we are closing this case.###Hello Steven,Thanks for the update. We have enabled maintenance mode for the URL https://preview.spendhq.com/login and will disable it on  6/2/2017 8 am EDT(05:30 PM IST).Let us know if you have any further queries.Regards,Sumod.K.Bose###We are in the middle of testing. Please put this in maintenance mode till 6/2/2017 8 am EDT. Steven Ng | Full Stack Developer | SpendHQ®O: 770-628-0692 | sng@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group###Hello SpendHQ-Team,This is to inform you that the alert regarding site down for the URL https://preview.spendhq.com/login got resolved and returned to a normal state. The site is accessible now and serving well as expected. During the time of this outage, we were able to witness an issue like  Error: An Internal Error Has Occurred. Please let us know if your team was performing any activity from your end during the time of this issue.We are currently analyzing more on this issue and will get back to you with further updates.Regards,Sumod.K.Bose###Hello SpendHQ-Team,This is to inform you that we received an alert regarding site down for the URL https://preview.spendhq.com/login. While accessing the page, we could see an error like Error: An Internal Error Has Occurred. We are analyzing more on this issue and will revert back to your team with more updates. Meanwhile please let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Thu, 01 Jun 2017 14:25:53 -0400Detected Error on SpendHQEstimated Downtime: 59 seconds https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Atlanta-B US, California US, Dallas-B US, London UK-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,01-06-2017 23:55,12,0,SpendHQ,"Hello Steven,We have disabled the maintenance mode for the URL https://preview.spendhq.com/login.Please let us know if you have any further queries.",As this is a maintenance activity we are closing this case.,"Hello Steven,Thanks for the update. We have enabled maintenance mode for the URL https://preview.spendhq.com/login and will disable it on  6/2/2017 8 am EDT(05:30 PM IST).Let us know if you have any further queries.Regards,Sumod.K.Bose",We are in the middle of testing. Please put this in maintenance mode till 6/2/2017 8 am EDT. Steven Ng | Full Stack Developer | SpendHQ®O: 770-628-0692 | sng@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group,"Hello SpendHQ-Team,This is to inform you that the alert regarding site down for the URL https://preview.spendhq.com/login got resolved and returned to a normal state. The site is accessible now and serving well as expected. During the time of this outage, we were able to witness an issue like  Error: An Internal Error Has Occurred. Please let us know if your team was performing any activity from your end during the time of this issue.We are currently analyzing more on this issue and will get back to you with further updates.Regards,Sumod.K.Bose","Hello SpendHQ-Team,This is to inform you that we received an alert regarding site down for the URL https://preview.spendhq.com/login. While accessing the page, we could see an error like Error: An Internal Error Has Occurred. We are analyzing more on this issue and will revert back to your team with more updates. Meanwhile please let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001SW2cr,Cloud Engineer Level 1,Closed,1093401,Incident,20-03-2018 06:16,,"Hello Team,We have blocked 96.85.173.42 IP at NACL level.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you and Please revert back to us for any further queries.###[via mail from AWS]Hello,We have approved and processed your limit increase request(s).  It can sometimes take up to 30 minutes for this to propagate and become available for use.  I hope this helps, but please reopen this case if you encounter any issues.Summary of limit(s) requested for increase:  [US East (Northern Virginia)]: VPC / Rules per Network ACL, New Limit = 40###Hello Andrew, As we have met the rules per ACL limit for acl-1cf66c65 so we were unable to block the IP at this point. We did raise a support case to AWS to increase the limit from 20 to 40. We will block the IP once the limit is raised and update you.Thank You,Safuvan KM###SubjectLimit Increase: VPCCase ID4937757611StatusUnassignedCreatedMar 20, 201803:11 AM +0530SeverityBusiness impairing questionCase typeService LimitsCategoryService Limit Increase, VPCByspendhq@reancloudsolutions.comCCd emailsms@reancloud.comCorrespondenceReplyClose CaseREANMSAdmin (Role)Mar 20, 201803:11 AM +0530Limit increase request 1Service: VPCRegion: US East (Northern Virginia)Limit name: Rules per Network ACLNew limit value: 40------------Use case description: Hello there,We would like to increase the rule per NACL limit for our production NACL acl-1cf66c65 as we have a requirement to block a new IP in the list. As we already met 20 rules, we unable to do it. Please assist us on this by increasing the limit.Thank You,Safuvan KM###Hello Andrew,When we try to block the ip address we received a limit reach alert by AWS for the Nacl as below :- The maximum number of network acl entries has been reached. (Service: AmazonEC2; Status Code: 400; Error Code: NetworkAclEntryLimitExceeded; Request ID: 92057499-0d8a-475f-9092-d5f6f3d2d20c) We request you to provide an approval to increase the limit of the nacl.###Hello Andrew,Thanks for the update.We will block the IP in the NACL level and will let you know the updates.###Yes, please block. Thank you.###Hello Team,We haven't heard back from you regarding this issue,Please let us know whether we need to block this IP in the NACL level as we could see that this IP has been reported as the abused total of 1 times on March 14th, 2018 (https://www.abuseipdb.com/check/96.85.173.42) and let us know if you have any queries.###Hello Team,We haven't heard back from you regarding this issue, Please review the below comment and let us know if you are having any further queries.###Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.0.102 which belongs to the preview-spendhq ELB. Please find the Intrusion Prevention Logs: 2018:03:15-11:50:17 spendhq snort[18759]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.102 dstip=10.59.1.192 proto=6 srcport=58016 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP  96.85.173.42 which belongs to the organization -	Comcast Cable Communications LLC and country United States was trying to execute the Oracle WebLogic Server Remote Code Execution . This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001.Please find the ELB logs details below, 2018-03-15T11:50:17.354772Z preview-spendhq-xelb 96.85.173.42:5897 - -1 -1 -1 504 0 1216 0 POST http://54.156.248.248:80/wls-wsat/CoordinatorPortType HTTP/1.1 Mozilla/5.0 (Windows NT 6.1; rv:5.0) Gecko/20100101 Firefox/5.0 - -Please let us know whether we need to block this IP in the NACL level as we could see that this IP  has been reported as abused total of 1 times on March 14th 2018 (https://www.abuseipdb.com/check/96.85.173.42) and let us know if you have any queries.","---------- Forwarded message ----------From: Firewall Notification System <manage-spendhq@reancloud.com>Date: Thu, Mar 15, 2018 at 5:20 PMSubject: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped)To: event-5domgd23@dtdg.co, spendhq-support@reancloud.com, ms@reancloud.comIntrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-ORACLE Oracle WebLogic Server remote commandexecution attemptDetails........: https://www.snort.org/search?query=45304Time...........: 2018-03-15 11:50:17Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.0.102Source port: 58016Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 80 days 4 hours 47 minutesSystem Load        : 0.18System Version     : Sophos UTM 9.506-2Please refer to the manual for detailed instructions.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,15-03-2018 17:28,109,0,SpendHQ,"Hello Team,We have blocked 96.85.173.42 IP at NACL level.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you and Please revert back to us for any further queries.","[via mail from AWS]Hello,We have approved and processed your limit increase request(s).  It can sometimes take up to 30 minutes for this to propagate and become available for use.  I hope this helps, but please reopen this case if you encounter any issues.Summary of limit(s) requested for increase:  [US East (Northern Virginia)]: VPC / Rules per Network ACL, New Limit = 40","Hello Andrew, As we have met the rules per ACL limit for acl-1cf66c65 so we were unable to block the IP at this point. We did raise a support case to AWS to increase the limit from 20 to 40. We will block the IP once the limit is raised and update you.Thank You,Safuvan KM","SubjectLimit Increase: VPCCase ID4937757611StatusUnassignedCreatedMar 20, 201803:11 AM +0530SeverityBusiness impairing questionCase typeService LimitsCategoryService Limit Increase, VPCByspendhq@reancloudsolutions.comCCd emailsms@reancloud.comCorrespondenceReplyClose CaseREANMSAdmin (Role)Mar 20, 201803:11 AM +0530Limit increase request 1Service: VPCRegion: US East (Northern Virginia)Limit name: Rules per Network ACLNew limit value: 40------------Use case description: Hello there,We would like to increase the rule per NACL limit for our production NACL acl-1cf66c65 as we have a requirement to block a new IP in the list. As we already met 20 rules, we unable to do it. Please assist us on this by increasing the limit.Thank You,Safuvan KM","Hello Andrew,When we try to block the ip address we received a limit reach alert by AWS for the Nacl as below :- The maximum number of network acl entries has been reached. (Service: AmazonEC2; Status Code: 400; Error Code: NetworkAclEntryLimitExceeded; Request ID: 92057499-0d8a-475f-9092-d5f6f3d2d20c) We request you to provide an approval to increase the limit of the nacl.","Hello Andrew,Thanks for the update.We will block the IP in the NACL level and will let you know the updates.","Yes, please block. Thank you.","Hello Team,We haven't heard back from you regarding this issue,Please let us know whether we need to block this IP in the NACL level as we could see that this IP has been reported as the abused total of 1 times on March 14th, 2018 (https://www.abuseipdb.com/check/96.85.173.42) and let us know if you have any queries.","Hello Team,We haven't heard back from you regarding this issue, Please review the below comment and let us know if you are having any further queries.","Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.0.102 which belongs to the preview-spendhq ELB. Please find the Intrusion Prevention Logs: 2018:03:15-11:50:17 spendhq snort[18759]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.102 dstip=10.59.1.192 proto=6 srcport=58016 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP  96.85.173.42 which belongs to the organization -	Comcast Cable Communications LLC and country United States was trying to execute the Oracle WebLogic Server Remote Code Execution . This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001.Please find the ELB logs details below, 2018-03-15T11:50:17.354772Z preview-spendhq-xelb 96.85.173.42:5897 - -1 -1 -1 504 0 1216 0 POST http://54.156.248.248:80/wls-wsat/CoordinatorPortType HTTP/1.1 Mozilla/5.0 (Windows NT 6.1; rv:5.0) Gecko/20100101 Firefox/5.0 - -Please let us know whether we need to block this IP in the NACL level as we could see that this IP  has been reported as abused total of 1 times on March 14th 2018 (https://www.abuseipdb.com/check/96.85.173.42) and let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ayh1B,Cloud Engineer Level 1,Closed,1103218,Incident,26-08-2018 23:27,,"Hello Team,We have further checked the details, the Secure-SpendHQ-ELB is pointed to the Sophos Instance and from there, it is pointed to PRD-WW2_6(10.59.101.6) WebServer instance which is attached to the NewPeview-ELB. And the backend DB server is PRD-DB1(10.59.10.190). We have analyzed the WebServer Instance metrics where it usage looks fine and from Instance level, we have analyzed the system messages, httpd logs, and tomcat logs which is also good at the time of this issue. We couldn't find any suspicious activity from both AWS and instance level for the backend DB server.Only we could able to see the high spike on average latency from the ELB metrics. The value is reached to 125973 ms during the time of the alert. Please find the screenshot for the same in the attachment section.We were able to see that https://secure.spendhq.com/login was not down at the time of this alert. At Wormly, the URL Timeout was set to 30 seconds but during this outage time, your ELB latency was around 125 seconds. Hence wormly was throwing the URL down alert since the portal didn't respond in less than 30 seconds.Kindly review this details and revert back to us in case of any queries.###Hello Team,This is to inform you that we have received a site down alert for the URL: https://secure.spendhq.com/login.This alert got recovered and the violation lasted for 31 minutes. We will analyze this and will get back to you with the updates.","---------- Forwarded message ----------From: <ms@reancloud.com>Date: Sun, Aug 26, 2018 at 7:28 PMSubject: Detected Error on SpendHQ SecureTo: ms@reancloud.comSun, 26 Aug 2018 09:58:37 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30004 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, London UK, California US, Atlanta-B US--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Secure,,26-08-2018 19:29,11,0,SpendHQ,"Hello Team,We have further checked the details, the Secure-SpendHQ-ELB is pointed to the Sophos Instance and from there, it is pointed to PRD-WW2_6(10.59.101.6) WebServer instance which is attached to the NewPeview-ELB. And the backend DB server is PRD-DB1(10.59.10.190). We have analyzed the WebServer Instance metrics where it usage looks fine and from Instance level, we have analyzed the system messages, httpd logs, and tomcat logs which is also good at the time of this issue. We couldn't find any suspicious activity from both AWS and instance level for the backend DB server.Only we could able to see the high spike on average latency from the ELB metrics. The value is reached to 125973 ms during the time of the alert. Please find the screenshot for the same in the attachment section.We were able to see that https://secure.spendhq.com/login was not down at the time of this alert. At Wormly, the URL Timeout was set to 30 seconds but during this outage time, your ELB latency was around 125 seconds. Hence wormly was throwing the URL down alert since the portal didn't respond in less than 30 seconds.Kindly review this details and revert back to us in case of any queries.","Hello Team,This is to inform you that we have received a site down alert for the URL: https://secure.spendhq.com/login.This alert got recovered and the violation lasted for 31 minutes. We will analyze this and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bjxr6,Cloud Engineer Level 1,Closed,1104481,Incident,13-09-2018 22:50,,"Hello Andrew,This request has completed.Let us know if you have any queries.###Hello AndrewWe have received your request we have stopped the instance please confirm from your end and get back to usregards.","Stephen KimaniJunior Cloud Engineerreancloud.com---------- Forwarded message ----------From: Andrew Kim <Akim@spendhq.com>Date: Thu, Sep 13, 2018 at 6:20 PMSubject: Stop EC2 InstanceTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Please put the following EC2 instance into a STOPPED state. Do notterminate.Name: Clone of PRD-LG1ID: i-0ed30e530bfccff3bIP: 10.59.1.145*Andrew Kim* | Director of Information Technology & Security | *Spend**HQ®*O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Stop EC2 Instance,,13-09-2018 21:30,1,0,SpendHQ,"Hello Andrew,This request has completed.Let us know if you have any queries.",Hello AndrewWe have received your request we have stopped the instance please confirm from your end and get back to usregards.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d0o9a,Cloud Engineer Level 1,Closed,1105962,Incident,08-10-2018 23:12,,Duplicate of SR-01105963.,"REAN,Do you have time to jump on a call on Wednesday at 1300 Hours to discuss an infrastructure related request. We would like to replicate PROD and I would like to discuss this prior to executing.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",QA Infrastructure,,08-10-2018 23:05,0,0,SpendHQ,Duplicate of SR-01105963.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XDFTX,Cloud Engineer Level 1,Closed,1099894,Incident,08-06-2018 00:03,,"Turner Ozmer12:00 AM (0 minutes ago)to me Hi Guorav, I think everything is working now. I will email you if I have any more questions. Thanks, Turner###Hello Allen,. We have created the VPN user for Turner and shared the credentials and VPN setup document with him separately. Kindly let us know if you have any queries.@Turner, Please verify and let us know if you are facing any issues.###Hello Andrew,We will work on your request and will let you know the update.","Please create a user account for Turner Ozmer (username: tozmer) andprovide instructions on how to set up.tozmer@insightsourcing.comThank you,*Andrew Kim* | Director of Information Technology & Security | *Spend**HQ®*O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- ISSA Conference1st June - Cyber Security At Scale <https://www.fbcinc.com/e/ISSA-ISC/agendarow.aspx>Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- ISSA Conference1st June - Cyber Security At Scale <https://www.fbcinc.com/e/ISSA-ISC/agendarow.aspx>Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Please create Sophos VPN user tozmer,,06-06-2018 23:30,32,0,SpendHQ,"Turner Ozmer12:00 AM (0 minutes ago)to me Hi Guorav, I think everything is working now. I will email you if I have any more questions. Thanks, Turner","Hello Allen,. We have created the VPN user for Turner and shared the credentials and VPN setup document with him separately. Kindly let us know if you have any queries.@Turner, Please verify and let us know if you are facing any issues.","Hello Andrew,We will work on your request and will let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001aNjBb,Cloud Engineer Level 1,Closed,1102801,Incident,16-08-2018 08:01,,"Hello Team,Hello Team,The alert regarding High Memory Utilization on spendhq-memsql-server3-2018-04-01 - 10.59.100.230 got recovered with a current value of 87.45%. The violation lasted for a day.Since the alert is recovered, we are marking this case as resolved. Please let us know if you have any questions.Thanks.###Hello Team,This is a gentle reminder.The alert regarding High Memory Utilization on spendhq-memsql-server3-2018-04-01 - 10.59.100.230 has recovered and currently has a reading og 82.2% below the set threshold of 95%. Below is a breakdown of currnet utilization.top - 22:43:46 up 135 days, 23:18,  0 users,  load average: 0.28, 6.72, 7.91Tasks: 312 total,   1 running, 311 sleeping,   0 stopped,   0 zombie%Cpu(s):  2.3 us,  0.0 sy,  0.0 ni, 97.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total, 23132356 free, 22590614+used,  2536520 buff/cacheKiB Swap:        0 total,        0 free,        0 used. 19166432 avail Mem    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND 14438 memsql    20   0  0.120t 0.104t  16556 S  18.8 44.5  15766:11 memsqld 14443 memsql    20   0  0.119t 0.104t  16568 S  62.5 44.2  15612:09 memsqld 96540 memsql    20   0 12.281g 335256   2612 S  12.5  0.1  22136:19 memsql-ops 66834 dd-agent  20   0 5449424  45824   7984 S   0.0  0.0 192:10.72 agent 14448 memsql    20   0  247236  42188   1160 S   0.0  0.0   0:00.98 memsqld 14447 memsql    20   0  247216  42184   1160 S   0.0  0.0   0:00.99 memsqld   587 root      20   0   99500  37356  36936 S   0.0  0.0   2:52.73 systemd-j+   878 root      20   0  496816  24124  22576 S   0.0  0.0   7:56.65 rsyslogd  1165 root      20   0  562396  13636   2896 S   0.0  0.0  17:13.42 tuned  1106 root      20   0  113372  13168    672 S   0.0  0.0   0:08.17 dhclient 66702 root      20   0 2688252  11856   5600 S   0.0  0.0  40:27.42 amazon-ss+124304 root      20   0  355544  10120   5596 S   0.0  0.0   0:00.01 ssm-docum+   876 polkitd   20   0  534252   8848   2364 S   0.0  0.0   0:06.59 polkitd     1 root      20   0  195696   8060   3292 S   0.0  0.0   8:37.27 systemd 20709 root      10 -10   34360   5736   4064 S   0.0  0.0   0:20.84 iscsidPlease review the details and let us know if you have any further queries in regards to this.Thank you.###Hello Team,alert regarding High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 is still an open state. Please review the details from the previous comments and let us know if you have any further queries.###Hello Team, We have analyzed the issue and below are the details: Instance Id: i-0382b753fdc5a21bd USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDmemsql    14045 13.7 46.9 135139716 118060628 ? Sl   May29 15405:18 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsqlmemsql    14050 13.7 46.7 134780100 117567032 ? Sl   May29 15477:55 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/data/memsqld.pid --user=memsqlmemsql    96752 15.2  0.1 12885828 332464 ?     Sl   May07 21925:21 /var/lib/memsql-ops/lib/memsql-ops start --port 9000dd-agent  66299  0.2  0.0 5432776 52740 ?       Ssl  Jun22 190:00 /opt/datadog-agent/bin/agent/agent start -p /opt/datadog-agent/run/agent.pidmemsql    14055  0.0  0.0 247236 42188 ?        Ssl  May29   0:01 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsqlmemsql    14054  0.0  0.0 247232 42184 ?        Ssl  May29   0:01 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/data/memsqld.pid --user=memsqlroot        593  0.0  0.0  87128 33016 ?        Ss   Apr01   2:54 /usr/lib/systemd/systemd-journaldroot        904  0.0  0.0 488384 21524 ?        Ssl  Apr01   7:54 /usr/sbin/rsyslogd -nroot       1172  0.0  0.0 562396 15420 ?        Ssl  Apr01  17:12 /usr/bin/python -Es /usr/sbin/tuned -l -Proot       1113  0.0  0.0 113372 13172 ?        Ss   Apr01   0:08 /sbin/dhclient -1 -q -lf /var/lib/dhclient/dhclient--eth0.lease -pf /var/run/dhclient-eth0.pid eth0###Hello Team, We have received an alert regarding High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 which has crossed the threshold and reached to the value of 95%. we are analyzing the issue and will back to you with the update. Resource Details: Instance ID: i-093eff6fae479397c IP: 10-59-100-230 Region: us-east-1","---------- Forwarded message ----------From: Datadog Alerting <alert@dtdg.co>Date: Wed, Aug 15, 2018 at 5:47 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Memory UtilizationAlert on host - spendhq-memsql-server2-2018-04-01 - 10.59.100.171 -To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host -spendhq-memsql-server2-2018-04-01 - 10.59.100.171 -Detected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1534335467000&group=host%3Ai-0382b753fdc5a21bd&from_ts=1534328267000>avg(last_30m):(avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 95The monitor was last triggered at Wed Aug 15 2018 12:17:57 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-0382b753fdc5a21bd>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-0382b753fdc5a21bd<https://app.datadoghq.com/infrastructure?filter=i-0382b753fdc5a21bd>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1534335597000&tags=host%3Ai-0382b753fdc5a21bd&from_ts=1534334577000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4531066552412315201>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - spendhq-memsql-server2-2018-04-01 - 10.59.100.171 -,,15-08-2018 17:57,14,0,SpendHQ,"Hello Team,Hello Team,The alert regarding High Memory Utilization on spendhq-memsql-server3-2018-04-01 - 10.59.100.230 got recovered with a current value of 87.45%. The violation lasted for a day.Since the alert is recovered, we are marking this case as resolved. Please let us know if you have any questions.Thanks.","Hello Team,This is a gentle reminder.The alert regarding High Memory Utilization on spendhq-memsql-server3-2018-04-01 - 10.59.100.230 has recovered and currently has a reading og 82.2% below the set threshold of 95%. Below is a breakdown of currnet utilization.top - 22:43:46 up 135 days, 23:18,  0 users,  load average: 0.28, 6.72, 7.91Tasks: 312 total,   1 running, 311 sleeping,   0 stopped,   0 zombie%Cpu(s):  2.3 us,  0.0 sy,  0.0 ni, 97.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total, 23132356 free, 22590614+used,  2536520 buff/cacheKiB Swap:        0 total,        0 free,        0 used. 19166432 avail Mem    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND 14438 memsql    20   0  0.120t 0.104t  16556 S  18.8 44.5  15766:11 memsqld 14443 memsql    20   0  0.119t 0.104t  16568 S  62.5 44.2  15612:09 memsqld 96540 memsql    20   0 12.281g 335256   2612 S  12.5  0.1  22136:19 memsql-ops 66834 dd-agent  20   0 5449424  45824   7984 S   0.0  0.0 192:10.72 agent 14448 memsql    20   0  247236  42188   1160 S   0.0  0.0   0:00.98 memsqld 14447 memsql    20   0  247216  42184   1160 S   0.0  0.0   0:00.99 memsqld   587 root      20   0   99500  37356  36936 S   0.0  0.0   2:52.73 systemd-j+   878 root      20   0  496816  24124  22576 S   0.0  0.0   7:56.65 rsyslogd  1165 root      20   0  562396  13636   2896 S   0.0  0.0  17:13.42 tuned  1106 root      20   0  113372  13168    672 S   0.0  0.0   0:08.17 dhclient 66702 root      20   0 2688252  11856   5600 S   0.0  0.0  40:27.42 amazon-ss+124304 root      20   0  355544  10120   5596 S   0.0  0.0   0:00.01 ssm-docum+   876 polkitd   20   0  534252   8848   2364 S   0.0  0.0   0:06.59 polkitd     1 root      20   0  195696   8060   3292 S   0.0  0.0   8:37.27 systemd 20709 root      10 -10   34360   5736   4064 S   0.0  0.0   0:20.84 iscsidPlease review the details and let us know if you have any further queries in regards to this.Thank you.","Hello Team,alert regarding High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 is still an open state. Please review the details from the previous comments and let us know if you have any further queries.","Hello Team, We have analyzed the issue and below are the details: Instance Id: i-0382b753fdc5a21bd USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDmemsql    14045 13.7 46.9 135139716 118060628 ? Sl   May29 15405:18 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsqlmemsql    14050 13.7 46.7 134780100 117567032 ? Sl   May29 15477:55 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/data/memsqld.pid --user=memsqlmemsql    96752 15.2  0.1 12885828 332464 ?     Sl   May07 21925:21 /var/lib/memsql-ops/lib/memsql-ops start --port 9000dd-agent  66299  0.2  0.0 5432776 52740 ?       Ssl  Jun22 190:00 /opt/datadog-agent/bin/agent/agent start -p /opt/datadog-agent/run/agent.pidmemsql    14055  0.0  0.0 247236 42188 ?        Ssl  May29   0:01 /mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3306-MI3e93e860/data/memsqld.pid --user=memsqlmemsql    14054  0.0  0.0 247232 42184 ?        Ssl  May29   0:01 /mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsqld --defaults-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/memsql.cnf --pid-file=/mnt/memsql_storage/memsql/leaf-3308-MI55573fab/data/memsqld.pid --user=memsqlroot        593  0.0  0.0  87128 33016 ?        Ss   Apr01   2:54 /usr/lib/systemd/systemd-journaldroot        904  0.0  0.0 488384 21524 ?        Ssl  Apr01   7:54 /usr/sbin/rsyslogd -nroot       1172  0.0  0.0 562396 15420 ?        Ssl  Apr01  17:12 /usr/bin/python -Es /usr/sbin/tuned -l -Proot       1113  0.0  0.0 113372 13172 ?        Ss   Apr01   0:08 /sbin/dhclient -1 -q -lf /var/lib/dhclient/dhclient--eth0.lease -pf /var/run/dhclient-eth0.pid eth0","Hello Team, We have received an alert regarding High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 which has crossed the threshold and reached to the value of 95%. we are analyzing the issue and will back to you with the update. Resource Details: Instance ID: i-093eff6fae479397c IP: 10-59-100-230 Region: us-east-1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001deDml,Cloud Engineer Level 1,Closed,1106757,Incident,26-10-2018 10:40,,"Hello Matthew,Thanks for the update.At this time we are marking this case closed and let us know if you have any queries.###Matthew Watts10:29 AM (10 minutes ago)to Stephen, Chandrapratap, ms Perfect. Thank you###Hello Matthew,We have made the necessary changes on the directory permissions for the user mwatts.Please try once and let us know if you are able to connect to the instance.###Hello Matthew,We will look into this and will let you know the update.Thanks,","REAN,I am unable to authenticate into the server:| => ssh 10.59.100.188The authenticity of host '10.59.100.188 (10.59.100.188)' can't be established.ECDSA key fingerprint is SHA256:eHdfz8oUcoAd3VgX4cvHUOTPLdDa4LkDCmXE0WniPM8.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '10.59.100.188' (ECDSA) to the list of known hosts.Permission denied (publickey,gssapi-keyex,gssapi-with-mic).Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>On 10/11/18, 6:48 AM, Chandrapratap Singh <chandrapratap.singh@reancloud.com<mailto:chandrapratap.singh@reancloud.com>> wrote:Hello Matthew,As per your server request, we have created your user mwatts :Password : 4=T7@*O.prF@)6WInstance details are as follows :Instance Name:   JENKINS_MASTERInstance ID :         i-079130613ab17ad30Private IP:            10.59.100.188Thanks and regards,Chandrapratap SinghJr. Cloud Engineer[Image removed by sender.]www.reancloud.com<http://www.reancloud.com>[Image removed by sender.]<https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018<http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018<http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018<http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",New Server Credentials,,25-10-2018 20:40,14,0,SpendHQ,"Hello Matthew,Thanks for the update.At this time we are marking this case closed and let us know if you have any queries.","Matthew Watts10:29 AM (10 minutes ago)to Stephen, Chandrapratap, ms Perfect. Thank you","Hello Matthew,We have made the necessary changes on the directory permissions for the user mwatts.Please try once and let us know if you are able to connect to the instance.","Hello Matthew,We will look into this and will let you know the update.Thanks,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014IPYu,Cloud Engineer Level 1,Closed,1032032,Incident,17-11-2016 04:10,,This is closed.###We have created the AMI of the instance and Andromeda team worked on snapshot creation. We informed the client and asked them that whether they have any action items for us.###asked andromeda team to take snapshots.,"Team,Can we please request that a backup/snapshot of the PRD-DB2 (10.59.10.12) Instance is taken at 1700 Hours today. I would also like to request that you provide a confirmation upon successful completion.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Instance Snapshot Request,,16-11-2016 21:14,7,0,SpendHQ,This is closed.,We have created the AMI of the instance and Andromeda team worked on snapshot creation. We informed the client and asked them that whether they have any action items for us.,asked andromeda team to take snapshots.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014Ii02,Cloud Engineer Level 1,Closed,1032098,Incident,29-11-2016 14:06,,"Hello Andrew,Thanks for the update. We are closing this request now. However, if you want to reopen the request please drop a mail to us.Regards###Hello Andrew,Thanks for the update.###Andrew Kim (SpendHQ)3:15 AM (1 minute ago)to Rean, spendhq-support Hello, We are discussing internally and will follow up when we are ready.###Hi Matthew,This is a quick follow up.Let us know whether you got a chance to check with Andrew and please update us regarding anti virus protection enabling via Sophos advanced mode.###Matthew sent e-mail to case comment that he will check with Andrew on monday to get an update on this.###Hi Matthew,Thanks a loot for the update.We will wait till monday to get an update on the anti virus protection enabling via Sophos advanced mode.###Hello Andrew, We haven't heard back from you regarding this case. Could you please have a look in to the suggestions from Sanket and let us if we can do anti virus by Sophos Advanced WAF Protection.###Hello Andrew,Just a quick follow up regarding enabling the WAF Protection on your preview environment. Let us know your thoughts on this.###Hello Team,As per you updates, we will follow up with you after the thanksgiving service(24th Nov 2016) regarding your suggestions on this case.At this time, we are marking this case as resolved.###Mathew informed that we can delay this and review after thanksgiving(Thursday 24 Nov 2016).###Hello Matthew,Thanks for the update. We will follow up with you after the Thanksgiving.Regards,###Hello Matthew,Enabling WAF on preview load balancer will not interfere with the PROD load balancer.###Hello Andrew,We haven't heard back from you. We are awaiting your reply regarding enable the WAF Protection on your preview environment.Please let us know if you want to proceed on this.###Hi Andrew,For this, we don't antivirus protection enabled for our environment as Sophos web application firewall profiles are disabled. Sophos Advanced WAF Protection does have the capability to perform single antivirus scan or dual antivirus scans. These scans can be carried out for Upload only files, download only files or both. Apart from this, if there is any unscannable content, it can straight away block that.As an initial step, we can enable this for preview environment and later, enable for securre environment. Let us know if you want us to enable this.###Hi Andrew,We are looking into this and will get back to you with details.","Andrew Kim (SpendHQ)10:48 PM (15 hours ago)to Spendhq Hello, We had a penetration test performed, and one item that came back was a lack of antivirus. APP08 – Lack of Anti-Virus Scanning on Uploaded Files Multiple formats of the EICAR anti-virus test file were uploaded successfully with the Bravo Two account. The files in question are located on 10.59.100.125 # ls -lah /var/www/vhosts/files.spendhq.com/public_html/uploaded/ | grep eicarCan we receive verification that AntiVirus is installed and working on this server?",Antivirus,,17-11-2016 14:29,288,0,SpendHQ,"Hello Andrew,Thanks for the update. We are closing this request now. However, if you want to reopen the request please drop a mail to us.Regards","Hello Andrew,Thanks for the update.","Andrew Kim (SpendHQ)3:15 AM (1 minute ago)to Rean, spendhq-support Hello, We are discussing internally and will follow up when we are ready.","Hi Matthew,This is a quick follow up.Let us know whether you got a chance to check with Andrew and please update us regarding anti virus protection enabling via Sophos advanced mode.",Matthew sent e-mail to case comment that he will check with Andrew on monday to get an update on this.,"Hi Matthew,Thanks a loot for the update.We will wait till monday to get an update on the anti virus protection enabling via Sophos advanced mode.","Hello Andrew, We haven't heard back from you regarding this case. Could you please have a look in to the suggestions from Sanket and let us if we can do anti virus by Sophos Advanced WAF Protection.","Hello Andrew,Just a quick follow up regarding enabling the WAF Protection on your preview environment. Let us know your thoughts on this.","Hello Team,As per you updates, we will follow up with you after the thanksgiving service(24th Nov 2016) regarding your suggestions on this case.At this time, we are marking this case as resolved.",Mathew informed that we can delay this and review after thanksgiving(Thursday 24 Nov 2016).,"Hello Matthew,Thanks for the update. We will follow up with you after the Thanksgiving.Regards,","Hello Matthew,Enabling WAF on preview load balancer will not interfere with the PROD load balancer.","Hello Andrew,We haven't heard back from you. We are awaiting your reply regarding enable the WAF Protection on your preview environment.Please let us know if you want to proceed on this.","Hi Andrew,For this, we don't antivirus protection enabled for our environment as Sophos web application firewall profiles are disabled. Sophos Advanced WAF Protection does have the capability to perform single antivirus scan or dual antivirus scans. These scans can be carried out for Upload only files, download only files or both. Apart from this, if there is any unscannable content, it can straight away block that.As an initial step, we can enable this for preview environment and later, enable for securre environment. Let us know if you want us to enable this.","Hi Andrew,We are looking into this and will get back to you with details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XDgqD,Cloud Engineer Level 1,Closed,1099951,Incident,08-06-2018 08:06,,"Hello Allen,Thanks for the update,At this time we are marking this case as closed and let us know if you have any further queries.###I caused this outage testing some new code. Sorry for not warning the team. Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###@Team,On further analyzed the issue and the URL https://preview.spendhq.com/login pointed to preview-spendhq-xelb load balancer which is then redirected to internal load balancer Preview-api-spendhq-com through Sophos WAF. I have checked from the backend instance PRD-WW1_122, there is the high number of connection which is in TIME_WAIT condition and found the logs in /var/www/vhosts/files.spendhq.com/w2/logs directory.[Thu Jun 07 13:40:19 2018] [error] [client 10.59.1.192] PHP Fatal error:  Uncaught exception 'Exception' with message 'Cannot safely perform decryption with message Integrity check failed.' in /var/www/vhosts/secure.spendhq.com/public/app/vendors/shqcore/Security/Security_Encryption.php:175\\nStack trace:\\n#0 /var/www/vhosts/secure.spendhq.com/public/app/libs/cache/session_cache.php(48): Security_Encryption->decrypt('Config|a:3:{s:9...')\\n#1 [internal function]: SessionCache::read('jr8ltkhdphotjsk...')\\n#2 /var/www/vhosts/secure.spendhq.com/public/cake/libs/cake_session.php(617): session_start()\\n#3 /var/www/vhosts/secure.spendhq.com/public/app/controllers/components/shq_session.php(74): CakeSession->__startSession()\\n#4 /var/www/vhosts/secure.spendhq.com/public/cake/libs/cake_session.php(249): ShqSessionComponent->__startSession()\\n#5 /var/www/vhosts/secure.spendhq.com/public/cake/libs/controller/components/session.php(287): CakeSession->start()\\n#6 /var/www/vhosts/secure.spendhq.com/public/cake/libs/controller/components/session.php(173): SessionComponent->__start()\\n#7 /var/www/vhosts/sec in /var/www/vhosts/secure.spendhq.com/public/app/vendors/shqcore/Security/Security_Encryption.php on line 175I I didn't find any logs before the time Thu Jun 07 13:40:19 2018. I suspect this alert was due to latency Need to analyze more on this issue.###Hello Team,This is to inform you that the site down alert for URL: https://preview.spendhq.com/login got recovered. The site is up and running fine now. The violation lasted for 18 minutes. We are checking more on this and will keep you posted.###Hello Team,This is to inform you that we received a site down alert for URL: https://preview.spendhq.com/login. While accessing the site it is showing the error Database table cake_session_salts for model SessionSalt was not found. We are analyzing on this issue and will keep you posted. Kindly let us know if you are performing any activity on your end.","---------- Forwarded message ----------From: <ms@reancloud.com>Date: Fri, Jun 8, 2018 at 2:48 AMSubject: Detected Error on SpendHQ PreviewTo: ms@reancloud.comThu, 07 Jun 2018 17:18:45 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): Dallas-B US, Frankfurt DE, California US, New JerseyUS-- Thanks & Regards,Kapil BokdiaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture4th Floor, 26, Tulsi Complex,100 Feet Road, New BhupalpuraUdaipur, Rajasthan 313001kapil.bokdia@reancloud.com |+917300421033| www.reancloud.com<http://www.reancloudsolutions.com/>Toll-Free Number: +12015828406-- Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Preview,,08-06-2018 02:50,5,0,SpendHQ,"Hello Allen,Thanks for the update,At this time we are marking this case as closed and let us know if you have any further queries.",I caused this outage testing some new code. Sorry for not warning the team. Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com,"@Team,On further analyzed the issue and the URL https://preview.spendhq.com/login pointed to preview-spendhq-xelb load balancer which is then redirected to internal load balancer Preview-api-spendhq-com through Sophos WAF. I have checked from the backend instance PRD-WW1_122, there is the high number of connection which is in TIME_WAIT condition and found the logs in /var/www/vhosts/files.spendhq.com/w2/logs directory.[Thu Jun 07 13:40:19 2018] [error] [client 10.59.1.192] PHP Fatal error:  Uncaught exception 'Exception' with message 'Cannot safely perform decryption with message Integrity check failed.' in /var/www/vhosts/secure.spendhq.com/public/app/vendors/shqcore/Security/Security_Encryption.php:175\\nStack trace:\\n#0 /var/www/vhosts/secure.spendhq.com/public/app/libs/cache/session_cache.php(48): Security_Encryption->decrypt('Config|a:3:{s:9...')\\n#1 [internal function]: SessionCache::read('jr8ltkhdphotjsk...')\\n#2 /var/www/vhosts/secure.spendhq.com/public/cake/libs/cake_session.php(617): session_start()\\n#3 /var/www/vhosts/secure.spendhq.com/public/app/controllers/components/shq_session.php(74): CakeSession->__startSession()\\n#4 /var/www/vhosts/secure.spendhq.com/public/cake/libs/cake_session.php(249): ShqSessionComponent->__startSession()\\n#5 /var/www/vhosts/secure.spendhq.com/public/cake/libs/controller/components/session.php(287): CakeSession->start()\\n#6 /var/www/vhosts/secure.spendhq.com/public/cake/libs/controller/components/session.php(173): SessionComponent->__start()\\n#7 /var/www/vhosts/sec in /var/www/vhosts/secure.spendhq.com/public/app/vendors/shqcore/Security/Security_Encryption.php on line 175I I didn't find any logs before the time Thu Jun 07 13:40:19 2018. I suspect this alert was due to latency Need to analyze more on this issue.","Hello Team,This is to inform you that the site down alert for URL: https://preview.spendhq.com/login got recovered. The site is up and running fine now. The violation lasted for 18 minutes. We are checking more on this and will keep you posted.","Hello Team,This is to inform you that we received a site down alert for URL: https://preview.spendhq.com/login. While accessing the site it is showing the error Database table cake_session_salts for model SessionSalt was not found. We are analyzing on this issue and will keep you posted. Kindly let us know if you are performing any activity on your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Xzx7Z,Cloud Engineer Level 1,Closed,1100762,Incident,06-07-2018 23:23,,"Hello Matthew,Thanks for the update.At this time we are marking this case closed and let us know if you have any queries.###Matthew Watts11:21 PM (1 minute ago)to Daniel, Robert, Rean, spendhq-support This has been completed.###Hello Team,We haven't heard back from you.Please review our previous comments and let us know if you want us to increase the threshold to 85%.Regards,###Hello Team, We will recommend you to increase the threshold from 80% to 85% as the current value is 80.4% which is stable from past few days. Kindly provide us your approval if you want us to increase the threshold###Hello Team,This is a gentle reminder.Please review our previous comment and let us know that we can have your approval or not to proceed on the action###Hello Team,We will recommend you to increase the threshold from 80% to 85% as the current value is 80.3% which is stable from past few days.Kindly provide us your approval if you want us to increase the threshold.###Hello Team, We haven't heard back from you. The alert still in open state with the value of 80.2%. Kindly validate the details and zip/clean the unwanted files. Kindly revert back to us in case of any queries.###Hello Team, We haven't heard back from you. The alert still in open state with the value of 80.2%. Kindly validate the details and zip/clean the unwanted files. Kindly revert back to us in case of any queries.###@Rohit the alert is still in open state with the value of  80.1%###@Team:As asked on yesterday evening call. Did we check the current status of the alert? What is the present value?###Hello Team,We haven't heard back from you.Please review our previous comments and let us know if you have any queries.###Hello Team,The current EBS disk usage on /dev/xvda1 on the instance PRD-SV1 is at 80%. Instance name: PRD-SV1 Instance ID: i-1426f28b Private IP: 10.59.100.125The breakdown is as below:Filesystem      Size  Used  Avail  Use% Mounted on/dev/xvda1      7.8G  5.9G  1.5G   80%   /tmpfs           3.6G     0  3.6G   0%   /dev/shm/dev/sda        2.0T  750G  1.2T   40%   /var/www/vhosts/files.spendhq.comDisk usage as per directories in /:1.6T	total843G	/var750G	/exports_production1.3G	/usr285M	/lib209M	/opt44M	/boot30M	/etc24M	/home19M	/lib6414M	/tmp14M	/sbin6.2M	/bin5.5M	/root152K	/dev16K	/lost+found8.0K	/run4.0K	/srv4.0K	/selinux4.0K	/mntThe top disk consuming directories/files in /var:843G	total843G	/var/www281M	/var/log170M	/var/tmp149M	/var/cache50M	/var/spool49M	/var/libDisk usage as per directories in /exports_production:750G	total750G	/exports_production/files.spendhq.comThe top disk consuming directories/files in /exports_production/files.spendhq.com/*:750G	total289G	/exports_production/files.spendhq.com/public_html147G	/exports_production/files.spendhq.com/reports90G	/exports_production/files.spendhq.com/tmp80G	/exports_production/files.spendhq.com/new_w265G	/exports_production/files.spendhq.com/public_backup40G	/exports_production/files.spendhq.com/newer_w217G	/exports_production/files.spendhq.com/w26.6G	/exports_production/files.spendhq.com/robert6.1G	/exports_production/files.spendhq.com/etl_test_uploads_2.27.184.1G	/exports_production/files.spendhq.com/logs2.4G	/exports_production/files.spendhq.com/w32.3G	/exports_production/files.spendhq.com/shq-logs2.0G	/exports_production/files.spendhq.com/contract_files1.3G	/exports_production/files.spendhq.com/shit313M	/exports_production/files.spendhq.com/php_tmp_uploadsPlease clean up any unwanted files and let us know if you have any queries.Thanks###Hello Team,We have received an alert on EBS High Disk Usage ( /dev/xvda1 ) - prd-fs1 - 10.59.100.125, we are analyzing we will get back to you with details.Resource details:Instance ID:i-1426f28bAZ: us-east-1bPrivate IP:10.59.100.125","Stephen KimaniJunior Cloud EngineerReanCloudreancloud.com---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Wed, Jun 27, 2018 at 6:32 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prd-fs1 - 10.59.100.125To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-fs1 -10.59.100.125High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1530113559000&group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-1426f28b&from_ts=1530109959000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 80The monitor was last triggered at Wed Jun 27 2018 15:32:49 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-1426f28b>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [Viewi-1426f28b <https://app.datadoghq.com/infrastructure?filter=i-1426f28b>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1530113569000&tags=host%3Ai-1426f28b&from_ts=1530112669000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4460234687229498855>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-fs1 - 10.59.100.125,,27-06-2018 21:15,218,0,SpendHQ,"Hello Matthew,Thanks for the update.At this time we are marking this case closed and let us know if you have any queries.","Matthew Watts11:21 PM (1 minute ago)to Daniel, Robert, Rean, spendhq-support This has been completed.","Hello Team,We haven't heard back from you.Please review our previous comments and let us know if you want us to increase the threshold to 85%.Regards,","Hello Team, We will recommend you to increase the threshold from 80% to 85% as the current value is 80.4% which is stable from past few days. Kindly provide us your approval if you want us to increase the threshold","Hello Team,This is a gentle reminder.Please review our previous comment and let us know that we can have your approval or not to proceed on the action","Hello Team,We will recommend you to increase the threshold from 80% to 85% as the current value is 80.3% which is stable from past few days.Kindly provide us your approval if you want us to increase the threshold.","Hello Team, We haven't heard back from you. The alert still in open state with the value of 80.2%. Kindly validate the details and zip/clean the unwanted files. Kindly revert back to us in case of any queries.","Hello Team, We haven't heard back from you. The alert still in open state with the value of 80.2%. Kindly validate the details and zip/clean the unwanted files. Kindly revert back to us in case of any queries.",@Rohit the alert is still in open state with the value of  80.1%,@Team:As asked on yesterday evening call. Did we check the current status of the alert? What is the present value?,"Hello Team,We haven't heard back from you.Please review our previous comments and let us know if you have any queries.","Hello Team,The current EBS disk usage on /dev/xvda1 on the instance PRD-SV1 is at 80%. Instance name: PRD-SV1 Instance ID: i-1426f28b Private IP: 10.59.100.125The breakdown is as below:Filesystem      Size  Used  Avail  Use% Mounted on/dev/xvda1      7.8G  5.9G  1.5G   80%   /tmpfs           3.6G     0  3.6G   0%   /dev/shm/dev/sda        2.0T  750G  1.2T   40%   /var/www/vhosts/files.spendhq.comDisk usage as per directories in /:1.6T	total843G	/var750G	/exports_production1.3G	/usr285M	/lib209M	/opt44M	/boot30M	/etc24M	/home19M	/lib6414M	/tmp14M	/sbin6.2M	/bin5.5M	/root152K	/dev16K	/lost+found8.0K	/run4.0K	/srv4.0K	/selinux4.0K	/mntThe top disk consuming directories/files in /var:843G	total843G	/var/www281M	/var/log170M	/var/tmp149M	/var/cache50M	/var/spool49M	/var/libDisk usage as per directories in /exports_production:750G	total750G	/exports_production/files.spendhq.comThe top disk consuming directories/files in /exports_production/files.spendhq.com/*:750G	total289G	/exports_production/files.spendhq.com/public_html147G	/exports_production/files.spendhq.com/reports90G	/exports_production/files.spendhq.com/tmp80G	/exports_production/files.spendhq.com/new_w265G	/exports_production/files.spendhq.com/public_backup40G	/exports_production/files.spendhq.com/newer_w217G	/exports_production/files.spendhq.com/w26.6G	/exports_production/files.spendhq.com/robert6.1G	/exports_production/files.spendhq.com/etl_test_uploads_2.27.184.1G	/exports_production/files.spendhq.com/logs2.4G	/exports_production/files.spendhq.com/w32.3G	/exports_production/files.spendhq.com/shq-logs2.0G	/exports_production/files.spendhq.com/contract_files1.3G	/exports_production/files.spendhq.com/shit313M	/exports_production/files.spendhq.com/php_tmp_uploadsPlease clean up any unwanted files and let us know if you have any queries.Thanks","Hello Team,We have received an alert on EBS High Disk Usage ( /dev/xvda1 ) - prd-fs1 - 10.59.100.125, we are analyzing we will get back to you with details.Resource details:Instance ID:i-1426f28bAZ: us-east-1bPrivate IP:10.59.100.125",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TjqOk,Cloud Engineer Level 1,Closed,1094256,Incident,30-03-2018 21:38,,"Hello Andrew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello Andrew,This is a gentle reminder.Please review our previous comments and let us know if have any query.###Hello Andrew, We have whitelisted Ip in Intrusion prevention under network protection section. Please let us know if you have any queries.###Hello Andrew,We have whitelisted Ip in Intrusion prevention under network protection section.Please let us know if you have any queries.###Hello Andrew,We will work on this and will let you know the updates.###Andrew Kim6:38 PM (47 minutes ago)to Rean, spendhq-support Hello – this is a tool we are using internally. Can you add an exception for this? The IP 74.115.21.213 is our main office and should NOT be blocked. Thank you,###Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.172  which belongs to the preview-spendhq ELB.Please find the Intrusion Prevention Logs: 2018:03:24-17:32:31 spendhq snort[18763]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.172 dstip=10.59.1.192 proto=6 srcport=56240 dstport=8080 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02018:03:24-17:32:36 spendhq snort[18763]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.172 dstip=10.59.1.192 proto=6 srcport=56260 dstport=8080 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 74.115.21.213 which belongs to the organization -	Faction and country United States was trying to execute the Oracle WebLogic Server Remote Code Execution . This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. Find the ELB logs details below,2018-03-24T17:32:15.497869Z preview-spendhq-xelb 74.115.21.213:20023 10.59.1.192:443 0.000037 0.153147 0.00004 302 302 0 0 GET https://preview.spendhq.com:443/ HTTP/1.1 Monit/5.14 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Please let us know whether we need to block this IP in the NACL level.","---------- Forwarded message ----------From: Firewall Notification System <manage-spendhq@reancloud.com>Date: Sat, Mar 24, 2018 at 11:02 PMSubject: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped)To: event-5domgd23@dtdg.co, spendhq-support@reancloud.com, ms@reancloud.comIntrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-ORACLE Oracle WebLogic Server remote commandexecution attemptDetails........: https://www.snort.org/search?query=45304Time...........: 2018-03-24 17:32:36Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.172Source port: 56260Destination IP address: 10.59.1.192 (spendhq)Destination port: 8080 (http-alt)--System Uptime      : 89 days 10 hours 29 minutesSystem Load        : 0.15System Version     : Sophos UTM 9.506-2Please refer to the manual for detailed instructions.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,25-03-2018 04:50,137,0,SpendHQ,"Hello Andrew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello Andrew,This is a gentle reminder.Please review our previous comments and let us know if have any query.","Hello Andrew, We have whitelisted Ip in Intrusion prevention under network protection section. Please let us know if you have any queries.","Hello Andrew,We have whitelisted Ip in Intrusion prevention under network protection section.Please let us know if you have any queries.","Hello Andrew,We will work on this and will let you know the updates.","Andrew Kim6:38 PM (47 minutes ago)to Rean, spendhq-support Hello – this is a tool we are using internally. Can you add an exception for this? The IP 74.115.21.213 is our main office and should NOT be blocked. Thank you,","Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.172  which belongs to the preview-spendhq ELB.Please find the Intrusion Prevention Logs: 2018:03:24-17:32:31 spendhq snort[18763]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.172 dstip=10.59.1.192 proto=6 srcport=56240 dstport=8080 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02018:03:24-17:32:36 spendhq snort[18763]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.172 dstip=10.59.1.192 proto=6 srcport=56260 dstport=8080 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 74.115.21.213 which belongs to the organization -	Faction and country United States was trying to execute the Oracle WebLogic Server Remote Code Execution . This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. Find the ELB logs details below,2018-03-24T17:32:15.497869Z preview-spendhq-xelb 74.115.21.213:20023 10.59.1.192:443 0.000037 0.153147 0.00004 302 302 0 0 GET https://preview.spendhq.com:443/ HTTP/1.1 Monit/5.14 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Please let us know whether we need to block this IP in the NACL level.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001genm5,Cloud Engineer Level 1,Closed,1109979,Incident,28-12-2018 07:05,,"Hello Team,Seeing as all this alerts recovered, we are proceeing with marking this case as closed. If you however have any other queries or doubts regarding this, feel free to reopen this and we'll be sure to assist you further.Thanks.###In essence, what we should be worried about is ESTABLISHED connections which isn't as high as the TIME_WAIT connections. 1 established)     67 ESTABLISHED      1 Foreign     17 LISTEN   2952 TIME_WAITHaving some connections in TIME_WAIT is a normal part of the TCP connection. Remember it is costlier (resource-wise) to establish a new comm channel than keeping an existing one, especially if, the client is going to make multiple requests from your server.And we've looked at the TIME_WAIT interval which is currently at 60. # sudo cat /proc/sys/net/ipv4/tcp_fin_timeout  60###Hello Matt,So we've tried to check both the for CPU utilization and the network stats and from what we can see is that there  are two processes consuming majority of the CPU on the 10.59.10.26 instance.Load Average of the System0.55, 0.36, 0.27################################################   Processes with highest CPU usage################################################ USER       PID  PPID CMD                         %CPUroot     20974   687 semodule -l                 80.0root      1150 25966 [PrimProc]                  15.9root     26248 25966 [ProcMgr]                    1.7root       687     1 /usr/bin/newrelic-infra      0.8root     25966 25965 /usr/local/mariadb/columnst  0.4root       860 25966 /usr/local/mariadb/columnst  0.2root      1212 25966 [WriteEngineServ]            0.2root       767 25966 /usr/local/mariadb/columnst  0.1dd-agent  8384     1 /opt/datadog-agent/bin/agen  0.1root     12407     2 [kworker/u32:1]              0.1For the actual network statistics we have these:################################################ Below are netstat summary (network statistics) ################################################ Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    tcp        0      0 0.0.0.0:8603            0.0.0.0:*               LISTEN      26248/              tcp        0      0 0.0.0.0:8700            0.0.0.0:*               LISTEN      860/workernode      tcp        0      0 0.0.0.0:8604            0.0.0.0:*               LISTEN      25966/ProcMon       tcp        0      0 0.0.0.0:8606            0.0.0.0:*               LISTEN      26248/              tcp        0      0 localhost:8126          0.0.0.0:*               LISTEN      8385/trace-agent    tcp        0      0 0.0.0.0:sunwebadmin     0.0.0.0:*               LISTEN      25966/ProcMon       tcp        0      0 0.0.0.0:8616            0.0.0.0:*               LISTEN      767/controllernode  tcp        0      0 localhost:commplex-main 0.0.0.0:*               LISTEN      8384/agent          tcp        0      0 localhost:commplex-link 0.0.0.0:*               LISTEN      8384/agent          tcp        0      0 0.0.0.0:8620            0.0.0.0:*               LISTEN      1150/               tcp        0      0 0.0.0.0:8622            0.0.0.0:*               LISTEN      822/ServerMonitor   tcp        0      0 localhost:9199          0.0.0.0:*               LISTEN      1027/               tcp        0      0 0.0.0.0:sunrpc          0.0.0.0:*               LISTEN      691/rpcbind         tcp        0      0 0.0.0.0:8630            0.0.0.0:*               LISTEN      1212/               tcp        0      0 0.0.0.0:ssh             0.0.0.0:*               LISTEN      1156/sshd           tcp6       0      0 [::]:sunrpc             [::]:*                  LISTEN      691/rpcbind         tcp6       0      0 [::]:ssh                [::]:*                  LISTEN      1156/sshd           udp        0      0 0.0.0.0:bootpc          0.0.0.0:*                           954/dhclient        udp        0      0 0.0.0.0:sunrpc          0.0.0.0:*                           691/rpcbind         udp        0      0 localhost:323           0.0.0.0:*                           697/chronyd         udp        0      0 0.0.0.0:iscsi           0.0.0.0:*                           691/rpcbind         udp        0      0 localhost:8125          0.0.0.0:*                           8384/agent###Hello Matt,Let us look into that and get back to you.Thanks.###[Via Mail]Any idea what service is causing this? Those TCP packets are being delayed. Can we see why?Matthew Watts | Manager, Application Development | SpendHQ®###Hello Team,As of now all the alerts have recovered. Total violation time for the three alerts was around 11 minutes. Below is a breakdown of current network stats on the three instances:10.59.10.45Below are TIME_WAIT connection summary ################################################tcp        0      0 10.59.10.45:54636       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54630       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54698       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54700       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54634       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54640       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54638       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54632       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54696       10.59.10.26:8603        TIME_WAIT   -                         1 established)     20 ESTABLISHED      1 Foreign     14 LISTEN      9 TIME_WAIT10.59.10.235Below are TIME_WAIT connection summary ################################################tcp        0      0 10.59.10.235:45776      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:45768      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:49742      52.94.233.129:443       TIME_WAIT   -                   tcp        0      0 10.59.10.235:45774      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:45772      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:45770      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:45778      10.59.10.26:8603        TIME_WAIT   -                         1 established)     21 ESTABLISHED      1 Foreign     14 LISTEN      7 TIME_WAIT10.59.10.26Below are TIME_WAIT connection summary ################################################tcp        0      0 10.59.10.26:8604        10.59.10.26:48742       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.235:45810      TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:50486       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:48018       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:47762       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:51060       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:50346       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:47962       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:52146       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.210:53042      TIME_WAIT   -                   ----------|||Output truncated|||---------|||Output truncated|||--------------------10.59.10.26 is the one instance that still has the highest number of TIME_WAIT connections despite not being in ALARM state: 1 established)     63 ESTABLISHED      1 Foreign     17 LISTEN   3017 TIME_WAITWe have attached it's full analysis in the attachment section for your perusal. Feel free to get in touch if you have any other queries regarding this.Thanks###[Via Mail]Please do. This is suspicious. Please treat as high priority.###Hello Team,This is  to inform you that we've received alerts regarding high Network Out on the following instances:10.59.10.23510.59.10.2610.59.10.45We are currently analyzing this and will be sharing more details.Thanks.","[image: Datadog][Triggered] [SpendHQ] - High Network OUT on host - sphq-db3-20180830 -10.59.10.235 -High Network OUT on the instance. Please check the list open TCPConnections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024199?to_ts=1545932249000&group=host%3Ai-0e76e98abf08a1b70&from_ts=1545925049000>*aws.ec2.network_out* over *datadog_monitor:on,host:i-0e76e98abf08a1b70*was *> 1100000000.0* at all times during the *last 30m*.The monitor was last triggered at Thu Dec 27 2018 17:37:39 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024199?group=host%3Ai-0e76e98abf08a1b70>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024199/edit>] · [Viewi-0e76e98abf08a1b70<https://app.datadoghq.com/infrastructure?filter=i-0e76e98abf08a1b70>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1545932379000&tags=host%3Ai-0e76e98abf08a1b70&from_ts=1545931359000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4725628304599546295>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - sphq-db3-20180830 - 10.59.10.235 -,,27-12-2018 23:13,8,0,SpendHQ,"Hello Team,Seeing as all this alerts recovered, we are proceeing with marking this case as closed. If you however have any other queries or doubts regarding this, feel free to reopen this and we'll be sure to assist you further.Thanks.","In essence, what we should be worried about is ESTABLISHED connections which isn't as high as the TIME_WAIT connections. 1 established)     67 ESTABLISHED      1 Foreign     17 LISTEN   2952 TIME_WAITHaving some connections in TIME_WAIT is a normal part of the TCP connection. Remember it is costlier (resource-wise) to establish a new comm channel than keeping an existing one, especially if, the client is going to make multiple requests from your server.And we've looked at the TIME_WAIT interval which is currently at 60. # sudo cat /proc/sys/net/ipv4/tcp_fin_timeout  60","Hello Matt,So we've tried to check both the for CPU utilization and the network stats and from what we can see is that there  are two processes consuming majority of the CPU on the 10.59.10.26 instance.Load Average of the System0.55, 0.36, 0.27",,,,,,,,,,,,,,,,Processes with highest CPU usage,,,,,,,,,,,,,,,,USER       PID  PPID CMD                         %CPUroot     20974   687 semodule -l                 80.0root      1150 25966 [PrimProc]                  15.9root     26248 25966 [ProcMgr]                    1.7root       687     1 /usr/bin/newrelic-infra      0.8root     25966 25965 /usr/local/mariadb/columnst  0.4root       860 25966 /usr/local/mariadb/columnst  0.2root      1212 25966 [WriteEngineServ]            0.2root       767 25966 /usr/local/mariadb/columnst  0.1dd-agent  8384     1 /opt/datadog-agent/bin/agen  0.1root     12407     2 [kworker/u32:1]              0.1For the actual network statistics we have these:,,,,,,,,,,,,,,,,Below are netstat summary (network statistics),,,,,,,,,,,,,,,,Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    tcp        0      0 0.0.0.0:8603            0.0.0.0:*               LISTEN      26248/              tcp        0      0 0.0.0.0:8700            0.0.0.0:*               LISTEN      860/workernode      tcp        0      0 0.0.0.0:8604            0.0.0.0:*               LISTEN      25966/ProcMon       tcp        0      0 0.0.0.0:8606            0.0.0.0:*               LISTEN      26248/              tcp        0      0 localhost:8126          0.0.0.0:*               LISTEN      8385/trace-agent    tcp        0      0 0.0.0.0:sunwebadmin     0.0.0.0:*               LISTEN      25966/ProcMon       tcp        0      0 0.0.0.0:8616            0.0.0.0:*               LISTEN      767/controllernode  tcp        0      0 localhost:commplex-main 0.0.0.0:*               LISTEN      8384/agent          tcp        0      0 localhost:commplex-link 0.0.0.0:*               LISTEN      8384/agent          tcp        0      0 0.0.0.0:8620            0.0.0.0:*               LISTEN      1150/               tcp        0      0 0.0.0.0:8622            0.0.0.0:*               LISTEN      822/ServerMonitor   tcp        0      0 localhost:9199          0.0.0.0:*               LISTEN      1027/               tcp        0      0 0.0.0.0:sunrpc          0.0.0.0:*               LISTEN      691/rpcbind         tcp        0      0 0.0.0.0:8630            0.0.0.0:*               LISTEN      1212/               tcp        0      0 0.0.0.0:ssh             0.0.0.0:*               LISTEN      1156/sshd           tcp6       0      0 [::]:sunrpc             [::]:*                  LISTEN      691/rpcbind         tcp6       0      0 [::]:ssh                [::]:*                  LISTEN      1156/sshd           udp        0      0 0.0.0.0:bootpc          0.0.0.0:*                           954/dhclient        udp        0      0 0.0.0.0:sunrpc          0.0.0.0:*                           691/rpcbind         udp        0      0 localhost:323           0.0.0.0:*                           697/chronyd         udp        0      0 0.0.0.0:iscsi           0.0.0.0:*                           691/rpcbind         udp        0      0 localhost:8125          0.0.0.0:*                           8384/agent,"Hello Matt,Let us look into that and get back to you.Thanks.","[Via Mail]Any idea what service is causing this? Those TCP packets are being delayed. Can we see why?Matthew Watts | Manager, Application Development | SpendHQ®","Hello Team,As of now all the alerts have recovered. Total violation time for the three alerts was around 11 minutes. Below is a breakdown of current network stats on the three instances:10.59.10.45Below are TIME_WAIT connection summary",,,,,,,,,,,,,,,,tcp        0      0 10.59.10.45:54636       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54630       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54698       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54700       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54634       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54640       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54638       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54632       10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.45:54696       10.59.10.26:8603        TIME_WAIT   -                         1 established)     20 ESTABLISHED      1 Foreign     14 LISTEN      9 TIME_WAIT10.59.10.235Below are TIME_WAIT connection summary,,,,,,,,,,,,,,,,tcp        0      0 10.59.10.235:45776      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:45768      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:49742      52.94.233.129:443       TIME_WAIT   -                   tcp        0      0 10.59.10.235:45774      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:45772      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:45770      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:45778      10.59.10.26:8603        TIME_WAIT   -                         1 established)     21 ESTABLISHED      1 Foreign     14 LISTEN      7 TIME_WAIT10.59.10.26Below are TIME_WAIT connection summary,,,,,,,,,,,,,,,,tcp        0      0 10.59.10.26:8604        10.59.10.26:48742       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.235:45810      TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:50486       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:48018       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:47762       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:51060       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:50346       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:47962       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.26:52146       TIME_WAIT   -                   tcp        0      0 10.59.10.26:8604        10.59.10.210:53042      TIME_WAIT   -                   ----------|||Output truncated|||---------|||Output truncated|||--------------------10.59.10.26 is the one instance that still has the highest number of TIME_WAIT connections despite not being in ALARM state: 1 established)     63 ESTABLISHED      1 Foreign     17 LISTEN   3017 TIME_WAITWe have attached it's full analysis in the attachment section for your perusal. Feel free to get in touch if you have any other queries regarding this.Thanks,[Via Mail]Please do. This is suspicious. Please treat as high priority.,"Hello Team,This is  to inform you that we've received alerts regarding high Network Out on the following instances:10.59.10.23510.59.10.2610.59.10.45We are currently analyzing this and will be sharing more details.Thanks.",,,,,,,,,,,,,,,,,,0
5002I00001hQumj,Cloud Engineer Level 1,Closed,1110168,Incident,03-01-2019 11:04,,"Hello Team,While checking We witnessed the site down for the URL's is not completely down this because of high latency and the root cause of the issue is same as mentioned on the case ID :  01110088.We are closing this case and please revert back to us in the above case if you have any queries.###Hello Team,This is to inform you that we have received a site down alert for the URL: https://preview.spendhq.com/login.We will check and let you know you the update on this meanwhile let us know if you are performing any activity from your end.","--------- Forwarded message ---------From: <ms@reancloud.com>Date: Thu, Jan 3, 2019 at 7:33 AMSubject: Detected Error on SpendHQ PreviewTo: <ms@reancloud.com>Wed, 02 Jan 2019 21:03:12 -0500Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): Sydney-C AU, Dallas-B US, Frankfurt-B DE, New JerseyUS-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Preview,,03-01-2019 08:04,3,0,SpendHQ,"Hello Team,While checking We witnessed the site down for the URL's is not completely down this because of high latency and the root cause of the issue is same as mentioned on the case ID :  01110088.We are closing this case and please revert back to us in the above case if you have any queries.","Hello Team,This is to inform you that we have received a site down alert for the URL: https://preview.spendhq.com/login.We will check and let you know you the update on this meanwhile let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001KoQ1f,Cloud Engineer Level 1,Closed,1085011,Incident,23-11-2017 08:15,,"Hello Allen.We haven't  heard back from youThis request has been completed. Please verify from your side and let us know if you are facing any issues. [root@ip-10-59-10-243 centos]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 xfs 100G 8.0G 93G 8% / devtmpfs devtmpfs 30G 0 30G 0% /dev tmpfs tmpfs 30G 0 30G 0% /dev/shm tmpfs tmpfs 30G 17M 30G 1% /run tmpfs tmpfs 30G 0 30G 0% /sys/fs/cgroup tmpfs tmpfs 6.0G 0 6.0G 0% /run/user/1001 tmpfs tmpfs 6.0G 0 6.0G 0% /run/user/1000Kindly review the details and let us know if you have any further queries on this.###Hello Allen,This request has been completed. Please verify from your side and let us know if you are facing any issues.[root@ip-10-59-10-243 centos]# df -ThFilesystem     Type      Size  Used Avail Use% Mounted on/dev/xvda1     xfs       100G  8.0G   93G   8% /devtmpfs       devtmpfs   30G     0   30G   0% /devtmpfs          tmpfs      30G     0   30G   0% /dev/shmtmpfs          tmpfs      30G   17M   30G   1% /runtmpfs          tmpfs      30G     0   30G   0% /sys/fs/cgrouptmpfs          tmpfs     6.0G     0  6.0G   0% /run/user/1001tmpfs          tmpfs     6.0G     0  6.0G   0% /run/user/1000###Hello Allen,We will work on this and will let you know, the updates.","APPROVEDFrom: Allen Herrera <aherrera@spendhq.com>Date: Tuesday, November 21, 2017 at 1:42 PMTo: Rean Support <support@reancloud.com>, spendhq-support@reancloud.com <spendhq-support@reancloud.com>, REAN Managed Services <ms@reancloud.com>Cc: Matthew Watts <mwatts@spendhq.com>Subject: Root Partition IncreaseHey Rean,On the new box 10.59.10.243, we have already filled the 8G space.We need the root partition expanded to 100GB asap. We need this done today.Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Root Partition Increase,,22-11-2017 00:14,47,0,SpendHQ,Hello Allen.We haven't  heard back from youThis request has been completed. Please verify from your side and let us know if you are facing any issues. [root@ip-10-59-10-243 centos]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 xfs 100G 8.0G 93G 8% / devtmpfs devtmpfs 30G 0 30G 0% /dev tmpfs tmpfs 30G 0 30G 0% /dev/shm tmpfs tmpfs 30G 17M 30G 1% /run tmpfs tmpfs 30G 0 30G 0% /sys/fs/cgroup tmpfs tmpfs 6.0G 0 6.0G 0% /run/user/1001 tmpfs tmpfs 6.0G 0 6.0G 0% /run/user/1000Kindly review the details and let us know if you have any further queries on this.,"Hello Allen,This request has been completed. Please verify from your side and let us know if you are facing any issues.[root@ip-10-59-10-243 centos]# df -ThFilesystem     Type      Size  Used Avail Use% Mounted on/dev/xvda1     xfs       100G  8.0G   93G   8% /devtmpfs       devtmpfs   30G     0   30G   0% /devtmpfs          tmpfs      30G     0   30G   0% /dev/shmtmpfs          tmpfs      30G   17M   30G   1% /runtmpfs          tmpfs      30G     0   30G   0% /sys/fs/cgrouptmpfs          tmpfs     6.0G     0  6.0G   0% /run/user/1001tmpfs          tmpfs     6.0G     0  6.0G   0% /run/user/1000","Hello Allen,We will work on this and will let you know, the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001S5FK6,Cloud Engineer Level 1,Closed,1092683,Incident,08-03-2018 00:49,,"Hello Team,This is to inform you that we have received aa AWS notification for AWS_DIRECTCONNECT_CONNECT.  Between 9:07 AM and 9:14 AM PST (12:07 PM- 12:14 PM EST) Today, they have experienced elevated packet loss, possibly impacting AWS Direct Connect connectivity for customers in the US-EAST-1 Region. The issue has been resolved and the service is operating normally.Please find the below issue details from AWS Health Dashboard. Event:DirectConnect connectivity issueStatus: ClosedRegion/AZ:us-east-1Start time:March 7, 2018 at 10:37:00 PM UTC+5:30End time:March 7, 2018 at 10:44:00 PM UTC+5:30Kindly review this details and let us know if you have any further concerns on this.","Between 9:07 AM and 9:14 AM PST, we experienced elevated packet loss, possibly impacting AWS Direct Connect connectivity for customers in the US-EAST-1 Region. The issue has been resolved and the service is operating normally. For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_CONNECTIVITY_ISSUE,,08-03-2018 00:32,39,0,SpendHQ,"Hello Team,This is to inform you that we have received aa AWS notification for AWS_DIRECTCONNECT_CONNECT.  Between 9:07 AM and 9:14 AM PST (12:07 PM- 12:14 PM EST) Today, they have experienced elevated packet loss, possibly impacting AWS Direct Connect connectivity for customers in the US-EAST-1 Region. The issue has been resolved and the service is operating normally.Please find the below issue details from AWS Health Dashboard. Event:DirectConnect connectivity issueStatus: ClosedRegion/AZ:us-east-1Start time:March 7, 2018 at 10:37:00 PM UTC+5:30End time:March 7, 2018 at 10:44:00 PM UTC+5:30Kindly review this details and let us know if you have any further concerns on this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ZBGn5,Cloud Engineer Level 2,Closed,1101797,Incident,20-08-2018 12:19,,"Hello Team,This is to inform you that maintenance for ElastiCache node is completed.Resources details: Cluster Name: sph-preview Primary Endpoint: sph-preview.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Engine: ClusterRedis Number of Nodes: 3 Nodes Multi-AZ: Enabled Node type: cache.m3.medium As the maintenance is completed by AWS and no action is required hence we are marking this case as closed.###@Team:Please close this case. This maintenance is over.###Hello Allen,Thanks for the update.###Allen Herrera11:18 PM (0 minutes ago)to Rean, spendhq-support No downtime / no affect sounds good.###Hello Allen, We haven't heard back from you.The Cluster sph-preview has Multi-AZ enabled, during replacing the primary node will triggers a failover to a read replica so there will no affect on the application during the replacement maintenance.###Hello Allen,The Cluster sph-preview has Multi-AZ enabled, during replacing the primary node will triggers a failover to a read replica so there will no affect on the application during the replacement maintenance.###We have one primary --> sph-preview-001Two replica -->  sph-preview-002                         sph-preview-003@Rohit, according to AWS documentation, they will be a glitch. We can ignore the replica maintenance. Please guide us if we are wrong at any point.###Hello Allen, We will check on your queries and get back with a response soon.Thanks.###Will this bring the entire cluster down? Or just 2 nodes of the cluster.Furthermore can you provide information on the two redis clusters we have. From my records I don’t see an endpoint prefixed with sph-preview.Allen Herrera###Hello Team, This is to inform you that we received notification from AWS Team that one of our ElastiCache node(s) are scheduled for replacement due to maintenance, which includes mandatory patches to improve security, reliability and operational performance. The maintenance will occur during the time range provided for each node. Please note that this is mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s). Affected resources details Cluster Name: sph-preview Nodes: sph-preview-001(Primary) and sph-preview-003(Replica)Primary Endpoint: sph-preview.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Engine: ClusterRedis AWS Scheduled Maintenance Window:- Region/AZ:us-east-1 Start time: August 6, 2018, at 5:30:00 AM UTC+5:30 End time: August 20, 2018, at 5:29:00 AM UTC+5:30###@Team:Please update the affected resource details. Node 001 and 003 will be affected. Out of which one is primary n other one is replica. Send the detailed information to the customer.###Hello Team,This is to inform you that we received notification from AWS Team that one of our  ElastiCache node(s) are scheduled for replacement due to maintenance, which includes mandatory patches to improve security, reliability and operational performance. The maintenance will occur during the time range provided for each node. Please note that this is mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s).Affected resources detailsCluster Name: sph-previewPrimary Endpoint: sph-preview.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379Engine: ClusterRedisNumber of Nodes: 3 NodesMulti-AZ: EnabledNode type: cache.m3.mediumAWS Scheduled Maintenance Window:- Region/AZ:us-east-1Start time: August 6, 2018, at 5:30:00 AM UTC+5:30End time: August 20, 2018, at 5:29:00 AM UTC+5:30@Rohit Please review this details.","Your Amazon ElastiCache node(s) associated with this event are scheduled for replacement due to maintenance, which includes mandatory patches to improve security, reliability and operational performance. The maintenance will occur during the time range provided for each node. Please note that this is mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s). Replacements generally take few minutes to complete, syncing the data from the master node can take additional time. The nodes will be unavailable to service requests during this period. Refer to ElastiCache Maintenance FAQs for more details - https://aws.amazon.com/elasticache/elasticache-maintenance/. If you have any questions or concerns, please contact the AWS Support Team at http://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- Raleigh Convention Center25th July, 2018 <http://go.reancloud.com/raleigh-email-sign>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_ELASTICACHE_REDIS_MAINTENANCE_SCHEDULED,,21-07-2018 16:33,716,0,SpendHQ,"Hello Team,This is to inform you that maintenance for ElastiCache node is completed.Resources details: Cluster Name: sph-preview Primary Endpoint: sph-preview.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Engine: ClusterRedis Number of Nodes: 3 Nodes Multi-AZ: Enabled Node type: cache.m3.medium As the maintenance is completed by AWS and no action is required hence we are marking this case as closed.",@Team:Please close this case. This maintenance is over.,"Hello Allen,Thanks for the update.","Allen Herrera11:18 PM (0 minutes ago)to Rean, spendhq-support No downtime / no affect sounds good.","Hello Allen, We haven't heard back from you.The Cluster sph-preview has Multi-AZ enabled, during replacing the primary node will triggers a failover to a read replica so there will no affect on the application during the replacement maintenance.","Hello Allen,The Cluster sph-preview has Multi-AZ enabled, during replacing the primary node will triggers a failover to a read replica so there will no affect on the application during the replacement maintenance.","We have one primary --> sph-preview-001Two replica -->  sph-preview-002                         sph-preview-003@Rohit, according to AWS documentation, they will be a glitch. We can ignore the replica maintenance. Please guide us if we are wrong at any point.","Hello Allen, We will check on your queries and get back with a response soon.Thanks.",Will this bring the entire cluster down? Or just 2 nodes of the cluster.Furthermore can you provide information on the two redis clusters we have. From my records I don’t see an endpoint prefixed with sph-preview.Allen Herrera,"Hello Team, This is to inform you that we received notification from AWS Team that one of our ElastiCache node(s) are scheduled for replacement due to maintenance, which includes mandatory patches to improve security, reliability and operational performance. The maintenance will occur during the time range provided for each node. Please note that this is mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s). Affected resources details Cluster Name: sph-preview Nodes: sph-preview-001(Primary) and sph-preview-003(Replica)Primary Endpoint: sph-preview.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379 Engine: ClusterRedis AWS Scheduled Maintenance Window:- Region/AZ:us-east-1 Start time: August 6, 2018, at 5:30:00 AM UTC+5:30 End time: August 20, 2018, at 5:29:00 AM UTC+5:30",@Team:Please update the affected resource details. Node 001 and 003 will be affected. Out of which one is primary n other one is replica. Send the detailed information to the customer.,"Hello Team,This is to inform you that we received notification from AWS Team that one of our  ElastiCache node(s) are scheduled for replacement due to maintenance, which includes mandatory patches to improve security, reliability and operational performance. The maintenance will occur during the time range provided for each node. Please note that this is mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s).Affected resources detailsCluster Name: sph-previewPrimary Endpoint: sph-preview.4ptbnu.ng.0001.use1.cache.amazonaws.com:6379Engine: ClusterRedisNumber of Nodes: 3 NodesMulti-AZ: EnabledNode type: cache.m3.mediumAWS Scheduled Maintenance Window:- Region/AZ:us-east-1Start time: August 6, 2018, at 5:30:00 AM UTC+5:30End time: August 20, 2018, at 5:29:00 AM UTC+5:30@Rohit Please review this details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EVUlV,Cloud Engineer Level 1,Closed,1068273,Incident,16-07-2017 21:06,,"Hello Team, This is to notify you that the alert regarding high CPU load on prod-sphq-db-server05 got resolved and has returned to normal with a value of 2.832.###Hello SpendHQ Team,In our analysis the MySQL process with PID 5519 is is taking a lot of CPU and memory which is hogging the system and is responsible for high CPU load on the system, Please check and verify it from your end and let us know if you have any more queries regarding this issue.###Hello Team, This is to notify you that we have received an alert that High CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0 on average with the value of 4.106. We are analyzing further on this issue and will get back to you with the updates.","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 4.106This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3958507281273367365 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,16-07-2017 18:01,3,0,SpendHQ,"Hello Team, This is to notify you that the alert regarding high CPU load on prod-sphq-db-server05 got resolved and has returned to normal with a value of 2.832.","Hello SpendHQ Team,In our analysis the MySQL process with PID 5519 is is taking a lot of CPU and memory which is hogging the system and is responsible for high CPU load on the system, Please check and verify it from your end and let us know if you have any more queries regarding this issue.","Hello Team, This is to notify you that we have received an alert that High CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0 on average with the value of 4.106. We are analyzing further on this issue and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ZBpUO,Cloud Engineer Level 1,Closed,1101882,Incident,24-07-2018 07:47,,"Hello Team,The alert High CPU Load on host prd-ww2_6 - 10.59.101.6 - web got recovered and have CPU load of 0.17, we are therefor marking this case as resolved and hence closing it.###Hello TeamWe have received an alert on High CPU Load on host prd-ww2_6 - 10.59.101.6 - web, We are analyzing the alert and  we will get back to you with details.Resource detailsInstance ID: i-01ac95c23ac66a40eInstance state: runningInstance type: m4.2xlargeAvailability zone: us-east-1cPrivate IPs: 10.59.101.6","Stephen KimaniJunior Cloud Engineerreancloud.com---------- Forwarded message ----------From: Datadog Alerting <alert@dtdg.co>Date: Mon, Jul 23, 2018 at 9:08 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on hostprd-ww2_6 - 10.59.101.6 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High CPU Load on host prd-ww2_6 - 10.59.101.6 - webDetected High CPU load. Log in to the machine and verify which process isconsuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023975?to_ts=1532369325000&group=host%3Ai-01ac95c23ac66a40e&from_ts=1532362125000>*system.load.15* over *datadog_monitor:on,host:i-01ac95c23ac66a40e* was *>4.0* on average during the *last 30m*.The monitor was last triggered at Mon Jul 23 2018 18:08:55 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023975?group=host%3Ai-01ac95c23ac66a40e>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023975/edit>] · [Viewi-01ac95c23ac66a40e<https://app.datadoghq.com/infrastructure?filter=i-01ac95c23ac66a40e>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1532369335000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1532368435000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4498080176610410560>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Raleigh Convention Center25th July, 2018 <http://go.reancloud.com/raleigh-email-sign>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>-- Raleigh Convention Center25th July, 2018 <http://go.reancloud.com/raleigh-email-sign>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on host prd-ww2_6 - 10.59.101.6 - web,,24-07-2018 01:55,6,0,SpendHQ,"Hello Team,The alert High CPU Load on host prd-ww2_6 - 10.59.101.6 - web got recovered and have CPU load of 0.17, we are therefor marking this case as resolved and hence closing it.","Hello TeamWe have received an alert on High CPU Load on host prd-ww2_6 - 10.59.101.6 - web, We are analyzing the alert and  we will get back to you with details.Resource detailsInstance ID: i-01ac95c23ac66a40eInstance state: runningInstance type: m4.2xlargeAvailability zone: us-east-1cPrivate IPs: 10.59.101.6",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001aNbcF,Cloud Engineer Level 1,Closed,1102775,Incident,16-08-2018 08:05,,"Hello Team,The alert regarding CPU utilization on spendhq-memsql-server3-2018-04-01 - 10.59.100.230 instance got recovered and is now in okay state with a value of 90.53%. The violation lasted for a day.Since the alert is recovered, we are marking this case as resolved. Please let us know if you have any questions. Thanks.###Hello Team,This is a gentle reminder.Please have a look at our previous comment and revert us back in case of any query.###Hello Team,CPU utilization is currently at 95.59%.Below is a breakdown of CPU utilization on spendhq-memsql-server3-2018-04-01 - 10.59.100.230 instance:Load Average of the System0.07, 0.16, 0.21################################################ Processes with highest CPU usage################################################ USER        PID   PPID CMD                         %CPUmemsql    96540      1 /var/lib/memsql-ops/lib/mem 15.3memsql    14438      1 /mnt/memsql_storage/memsql/ 13.5memsql    14443      1 /mnt/memsql_storage/memsql/ 13.4dd-agent  66834      1 /opt/datadog-agent/bin/agen  0.2root          1      0 /usr/lib/systemd/systemd --  0.0                                                          root          2      0 [kthreadd]                   0.0                                                          root          3      2 [ksoftirqd/0]                0.0                                                          root          5      2 [kworker/0:0H]               0.0                                                          root          7      2 [migration/0]                0.0                                                          root          8      2 [rcu_bh]                     0.0################################################ Netstat Summary################################################ Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    tcp        0      0 0.0.0.0:mysql           0.0.0.0:*               LISTEN      14443/memsqld       tcp        0      0 0.0.0.0:opsession-prxy  0.0.0.0:*               LISTEN      14438/memsqld       tcp        0      0 0.0.0.0:sunrpc          0.0.0.0:*               LISTEN      1/systemd           tcp        0      0 0.0.0.0:ssh             0.0.0.0:*               LISTEN      1797/sshd           tcp        0      0 localhost:smtp          0.0.0.0:*               LISTEN      1284/master         tcp        0      0 localhost:8126          0.0.0.0:*               LISTEN      66835/trace-agent   tcp        0      0 localhost:commplex-main 0.0.0.0:*               LISTEN      66834/agent         tcp        0      0 0.0.0.0:cslistener      0.0.0.0:*               LISTEN      96540/memsql-ops    tcp        0      0 localhost:commplex-link 0.0.0.0:*               LISTEN      66834/agent         tcp6       0      0 [::]:sunrpc             [::]:*                  LISTEN      1/systemd           tcp6       0      0 [::]:ssh                [::]:*                  LISTEN      1797/sshd           tcp6       0      0 localhost:smtp          [::]:*                  LISTEN      1284/master         udp        0      0 0.0.0.0:20777           0.0.0.0:*                           1106/dhclient       udp        0      0 0.0.0.0:bootpc          0.0.0.0:*                           1106/dhclient       udp        0      0 ip-10-59-100-230.ec:ntp 0.0.0.0:*                           80026/ntpd          udp        0      0 localhost:ntp           0.0.0.0:*                           80026/ntpd          udp        0      0 0.0.0.0:ntp             0.0.0.0:*                           80026/ntpd          udp        0      0 localhost:8125          0.0.0.0:*                           66834/agent         udp6       0      0 [::]:51185              [::]:*                              1106/dhclient       udp6       0      0 ip-10-59-100-230.ec:ntp [::]:*                              80026/ntpd          udp6       0      0 localhost:ntp           [::]:*                              80026/ntpd          TIME_WAIT connection summary ################################################ tcp        0      0 10.59.100.230:51512     52.94.233.129:443       TIME_WAIT   -                       806 ESTABLISHED      1 Foreign     12 LISTEN      1 T###Hello Team,We have received an alert regarding High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 which has crossed the threshold and reached to the value of 95.53%. We are analyzing the issue and will back you with the update.Resource details:Instance id : i-093eff6fae479397cRegion: us-east-1IP: 10-59-100-230","[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host -spendhq-memsql-server3-2018-04-01 - 10.59.100.230 -Detected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1534278527000&group=host%3Ai-093eff6fae479397c&from_ts=1534271327000>avg(last_30m):(avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 95The monitor was last triggered at Tue Aug 14 2018 20:28:57 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-093eff6fae479397c>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-093eff6fae479397c<https://app.datadoghq.com/infrastructure?filter=i-093eff6fae479397c>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1534278657000&tags=host%3Ai-093eff6fae479397c&from_ts=1534277637000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4530111256995074495>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 -,,15-08-2018 02:05,30,0,SpendHQ,"Hello Team,The alert regarding CPU utilization on spendhq-memsql-server3-2018-04-01 - 10.59.100.230 instance got recovered and is now in okay state with a value of 90.53%. The violation lasted for a day.Since the alert is recovered, we are marking this case as resolved. Please let us know if you have any questions. Thanks.","Hello Team,This is a gentle reminder.Please have a look at our previous comment and revert us back in case of any query.","Hello Team,CPU utilization is currently at 95.59%.Below is a breakdown of CPU utilization on spendhq-memsql-server3-2018-04-01 - 10.59.100.230 instance:Load Average of the System0.07, 0.16, 0.21",,,,,,,,,,,,,,,,Processes with highest CPU usage,,,,,,,,,,,,,,,,USER        PID   PPID CMD                         %CPUmemsql    96540      1 /var/lib/memsql-ops/lib/mem 15.3memsql    14438      1 /mnt/memsql_storage/memsql/ 13.5memsql    14443      1 /mnt/memsql_storage/memsql/ 13.4dd-agent  66834      1 /opt/datadog-agent/bin/agen  0.2root          1      0 /usr/lib/systemd/systemd --  0.0                                                          root          2      0 [kthreadd]                   0.0                                                          root          3      2 [ksoftirqd/0]                0.0                                                          root          5      2 [kworker/0:0H]               0.0                                                          root          7      2 [migration/0]                0.0                                                          root          8      2 [rcu_bh]                     0.0,,,,,,,,,,,,,,,,Netstat Summary,,,,,,,,,,,,,,,,Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    tcp        0      0 0.0.0.0:mysql           0.0.0.0:*               LISTEN      14443/memsqld       tcp        0      0 0.0.0.0:opsession-prxy  0.0.0.0:*               LISTEN      14438/memsqld       tcp        0      0 0.0.0.0:sunrpc          0.0.0.0:*               LISTEN      1/systemd           tcp        0      0 0.0.0.0:ssh             0.0.0.0:*               LISTEN      1797/sshd           tcp        0      0 localhost:smtp          0.0.0.0:*               LISTEN      1284/master         tcp        0      0 localhost:8126          0.0.0.0:*               LISTEN      66835/trace-agent   tcp        0      0 localhost:commplex-main 0.0.0.0:*               LISTEN      66834/agent         tcp        0      0 0.0.0.0:cslistener      0.0.0.0:*               LISTEN      96540/memsql-ops    tcp        0      0 localhost:commplex-link 0.0.0.0:*               LISTEN      66834/agent         tcp6       0      0 [::]:sunrpc             [::]:*                  LISTEN      1/systemd           tcp6       0      0 [::]:ssh                [::]:*                  LISTEN      1797/sshd           tcp6       0      0 localhost:smtp          [::]:*                  LISTEN      1284/master         udp        0      0 0.0.0.0:20777           0.0.0.0:*                           1106/dhclient       udp        0      0 0.0.0.0:bootpc          0.0.0.0:*                           1106/dhclient       udp        0      0 ip-10-59-100-230.ec:ntp 0.0.0.0:*                           80026/ntpd          udp        0      0 localhost:ntp           0.0.0.0:*                           80026/ntpd          udp        0      0 0.0.0.0:ntp             0.0.0.0:*                           80026/ntpd          udp        0      0 localhost:8125          0.0.0.0:*                           66834/agent         udp6       0      0 [::]:51185              [::]:*                              1106/dhclient       udp6       0      0 ip-10-59-100-230.ec:ntp [::]:*                              80026/ntpd          udp6       0      0 localhost:ntp           [::]:*                              80026/ntpd          TIME_WAIT connection summary,,,,,,,,,,,,,,,,tcp        0      0 10.59.100.230:51512     52.94.233.129:443       TIME_WAIT   -                       806 ESTABLISHED      1 Foreign     12 LISTEN      1 T,"Hello Team,We have received an alert regarding High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 which has crossed the threshold and reached to the value of 95.53%. We are analyzing the issue and will back you with the update.Resource details:Instance id : i-093eff6fae479397cRegion: us-east-1IP: 10-59-100-230",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d4Wbk,Cloud Engineer Level 1,Closed,1106429,Incident,19-10-2018 15:23,,"@teamthis 5xx has occurred after the site down of url:https://secure.spendhq.com/login we are doing the analysis for the site down in case 01106408.  so closing this case with confirmation of cc###Hi Team,On our Analysis we identified the Below URLs to have had High 5xx request Counts:GET https://secure.spendhq.com:443/login HTTP/1.1GET https://secure.spendhq.com:443/ HTTP/1.1We also identified the below IP to have had multiple requests that resulted to 5xx errors during the time of the alert:10.59.1.192. The Ip belongs to the PROD-SPHQ-SOPHOS-UTM-VPN01 Instance in us-east-1 region.The alert lasted for 20 minutes and later got recovered. We have attached the full Logs in the ticket, please have a look and let us know if you have any queries.Thanks.###Hello Team,This is to notify you that we have received an alert regarding ELB High 5xx Request Count on the ELB NewPreview-ELB in us-east-1 region. We are further analyzing the issue and we will get back to you with more details.Thanks.Resource Details:Load Balancer Name:	NewPreview-ELB	Region:	us-east-1Scheme:	internal	VPC ID: 	vpc-76df7212","[Triggered] [SpendHQ] - ELB 5XX Request Countnewpreview-elb,prd-secure-int-elb - - webELB 5XX request Count is above the threshold@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>avg(last_30m):avg:aws.elb.httpcode_elb_5xx{datadog_monitor:on} by{host}.as_count() > 30The monitor was last triggered at Thu Oct 18 2018 13:53:15 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024235?group=host%3Ainternal-NewPreview-ELB-1657548324.us-east-1.elb.amazonaws.com>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024235/edit>] · [Viewinternal-NewPreview-ELB-1657548324.us-east-1.elb.amazonaws.com<https://app.datadoghq.com/infrastructure?filter=internal-NewPreview-ELB-1657548324.us-east-1.elb.amazonaws.com>]· [Show Processes<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1539870915000&tags=host%3Ainternal-NewPreview-ELB-1657548324.us-east-1.elb.amazonaws.com&from_ts=1539869895000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQ","Fwd: [Monitor Alert] Triggered: [SpendHQ] - ELB 5XX Request Count newpreview-elb,prd-secure-int-elb - - web",,18-10-2018 19:37,20,0,SpendHQ,@teamthis 5xx has occurred after the site down of url:https://secure.spendhq.com/login we are doing the analysis for the site down in case 01106408.  so closing this case with confirmation of cc,"Hi Team,On our Analysis we identified the Below URLs to have had High 5xx request Counts:GET https://secure.spendhq.com:443/login HTTP/1.1GET https://secure.spendhq.com:443/ HTTP/1.1We also identified the below IP to have had multiple requests that resulted to 5xx errors during the time of the alert:10.59.1.192. The Ip belongs to the PROD-SPHQ-SOPHOS-UTM-VPN01 Instance in us-east-1 region.The alert lasted for 20 minutes and later got recovered. We have attached the full Logs in the ticket, please have a look and let us know if you have any queries.Thanks.","Hello Team,This is to notify you that we have received an alert regarding ELB High 5xx Request Count on the ELB NewPreview-ELB in us-east-1 region. We are further analyzing the issue and we will get back to you with more details.Thanks.Resource Details:Load Balancer Name:	NewPreview-ELB	Region:	us-east-1Scheme:	internal	VPC ID: 	vpc-76df7212",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Eu5BI,Cloud Engineer Level 1,Closed,1070713,Incident,01-08-2017 16:22,,"Hi Team,I have successfully installed and configured the NTP service on the instance. NTP clock is now in sync with Sophos.I have also verified the timings are correct.###On evening ops call, Yogesh updated that he will perform the ntp syn on the instance and will update us.Please check with Yogesh, whether he performed the change and close this ticket.###We had a discussion with Yogesh and share him the steps to enable  NTP. Check with Yogesh whether we can create a deployment plan and share it with the customer or can we close this ticket and track it in Jira.###We had a call with Yogesh and he updated to check the Current time zone and whether NTP installation causes any downtime. After that we tried to call, but he was not available.###Next Action: Need to check with CC whether we can go ahead and recommend NTP service installation.###Hi Team,We have checked and confirmed that NTP service is not installed in this instance which resulted in this issue.","[Triggered on {host:10.59.10.107}] [Auto] Clock in sync with NTP  Triggers if any host's clock goes out of sync with the time given by NTP. The offset threshold is configured in the Agent's `ntp.yaml` file.Please read the [KB article](http://help.datadoghq.com/hc/en-us/articles/204282095-Network-Time-Protocol-NTP-Offset-Issues) on NTP Offset issues for more details on cause and resolution. @support@reancloud.comOffset -60.0279948711 secs higher than offset threshold (60 secs)This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#1953584?group=host%3A10.59.10.107 · Edit Monitor: https://app.datadoghq.com/monitors#1953584/edit · Event URL: https://app.datadoghq.com/event/event?id=3978173873069211336 · View 10.59.10.107: https://app.datadoghq.com/infrastructure?hostname=10.59.10.107-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [Auto] Clock in sync with NTP on host:10.59.10.107,,30-07-2017 07:38,62,0,SpendHQ,"Hi Team,I have successfully installed and configured the NTP service on the instance. NTP clock is now in sync with Sophos.I have also verified the timings are correct.","On evening ops call, Yogesh updated that he will perform the ntp syn on the instance and will update us.Please check with Yogesh, whether he performed the change and close this ticket.",We had a discussion with Yogesh and share him the steps to enable  NTP. Check with Yogesh whether we can create a deployment plan and share it with the customer or can we close this ticket and track it in Jira.,"We had a call with Yogesh and he updated to check the Current time zone and whether NTP installation causes any downtime. After that we tried to call, but he was not available.",Next Action: Need to check with CC whether we can go ahead and recommend NTP service installation.,"Hi Team,We have checked and confirmed that NTP service is not installed in this instance which resulted in this issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Tm9TQ,Cloud Engineer Level 1,Closed,1094582,Incident,30-03-2018 23:19,,"Hello Team,As the alert got recovered, hence we are marking this case as resolved.Please revert back to us if you have any query regarding this case.###Hello Team, Please review our previous comments and let us know if you have any query regarding this issue.###Hello Team,The alert regarding high RDS CPU utilization has recovered and returned to the normal value.Please find the attached screenshot of RDS CPU utilization in the attachment section and let us know if you have performed any activity on your end.###Hello SpendHQ Team,This is to notify you that we received an alert regarding high RDS CPU Utilization for spendhqdb has crossed the threshold value of 85%.Resouces Details:DB Name: spendhqdbEngine: Aurora MySQL 5.6.10aEndpoint: spendhqdb.cnq3fody8qqu.us-east-1.rds.amazonaws.comVPC: SpendHQ-VPC (vpc-76df7212)We are analyzing more on this and will let you know the details.","[Triggered] [SpendHQ][PROD] High RDS CPU Utilization for  - spendhqdb - us-east-1  RDS CPU Utilization is above threshold  - spendhqdb    @support@reancloud.comaws.rds.cpuutilization over dbname:spendhqdb,host:db-QQCSORNBURRYJMGDFXN7MIV2IM was > 85.0 on average during the last 5m.Metric value: 99.667This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#3218209?group=host%3Adb-QQCSORNBURRYJMGDFXN7MIV2IM · Edit Monitor: https://app.datadoghq.com/monitors#3218209/edit · Event URL: https://app.datadoghq.com/event/event?id=4329786166811178082 · View db-QQCSORNBURRYJMGDFXN7MIV2IM: https://app.datadoghq.com/infrastructure?hostname=db-QQCSORNBURRYJMGDFXN7MIV2IM · Show Processes: https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=None&tags=host%3Adb-QQCSORNBURRYJMGDFXN7MIV2IM&from_ts=None&live=false&showSummaryGraphs=true-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ][PROD] High RDS CPU Utilization for  - spendhqdb - us-east-1,,29-03-2018 21:13,26,0,SpendHQ,"Hello Team,As the alert got recovered, hence we are marking this case as resolved.Please revert back to us if you have any query regarding this case.","Hello Team, Please review our previous comments and let us know if you have any query regarding this issue.","Hello Team,The alert regarding high RDS CPU utilization has recovered and returned to the normal value.Please find the attached screenshot of RDS CPU utilization in the attachment section and let us know if you have performed any activity on your end.","Hello SpendHQ Team,This is to notify you that we received an alert regarding high RDS CPU Utilization for spendhqdb has crossed the threshold value of 85%.Resouces Details:DB Name: spendhqdbEngine: Aurora MySQL 5.6.10aEndpoint: spendhqdb.cnq3fody8qqu.us-east-1.rds.amazonaws.comVPC: SpendHQ-VPC (vpc-76df7212)We are analyzing more on this and will let you know the details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001azpTB,Cloud Engineer Level 1,Closed,1103390,Incident,30-08-2018 21:58,,"Rohit Puri9:56 PM (1 minute ago)to Matthew, Rean, spendhq-support@reancloud.comHi Mathew,We have remounted the iSCSI Volume on the instances including production and preview. Now this has been resolved. Please verify from your end and let us know if you face any issue. Thanks !Regards,Rohit Puri###Matthew Watts4:56 PM (3 minutes ago)to Rean, spendhq-support@reancloud.comDo you need help or consent?###Hello Matthew,We tried to reach out to you via phone but seems you were not available at that time. Could you please help us to stop the process so that we can re-mount the volumes.###Hello Matthew,We did lsof on the mount points before unmounting and could see that the processes are locked on the mount point. Could you please help us to stop the process so that we can re-mount the volume.Please join the bridge below:https://reancloud.zoom.us/my/mgse1###Hello Spendhq-Team,This is to inform you we could see that the below ISCSI volumes are in read-only mode. We are going to re-mount them in next few minutes.i-03ccfddd9f02cacb9 PRD-DB1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-170819-v777bb21358661922.00000028.2f1dab31-lun-0 sdn /mnt/production_19082017 ro i-073579ff33c73d3cd SpendHQ-memsql-server1-2018-04-01 ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server1-2018-04-01:dev10.ctr1-lun-0 sdb /mnt/memsql_storage ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /var/www/vhosts/files.spendhq.com ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /var/www/vhosts/secure.spendhq.com/public/app/tmp ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /exports_production/files.spendhq.com ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /exports_production/files.spendhq.com ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /exports_production/files.spendhq.com ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /exports_production/files.spendhq.com/tmp ro","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Thu, Aug 30, 2018 at 10:31 AMSubject: ISCSI Device Details which are in RO modeTo: <ms@reancloud.com>The daily report of ISCSI devices which are in RO modeInstance_IDInstance_NameISCSI_NameMachine_Level_Disk_NameMount_DirectoryMount_Propertiesi-03ccfddd9f02cacb9 PRD-DB1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-170819-v777bb21358661922.00000028.2f1dab31-lun-0sdn /mnt/production_19082017 roi-073579ff33c73d3cd SpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server1-2018-04-01:dev10.ctr1-lun-0sdb /mnt/memsql_storage roi-1426f28b PRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0sda /var/www/vhosts/files.spendhq.com roi-1426f28b PRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0sda /var/www/vhosts/secure.spendhq.com/public/app/tmp roi-1426f28b PRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0sda /exports_production/files.spendhq.com roi-1426f28b PRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0sda /exports_production/files.spendhq.com roi-1426f28b PRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0sda /exports_production/files.spendhq.com roi-1426f28b PRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0sda /exports_production/files.spendhq.com/tmp ro-- Regards,Jamelunissa MohammedHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081jamelunissa.mohammed@reancloud.com  | www.reancloud.com--  <https://hubs.ly/H0d8gJ20>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: ISCSI Device Details which are in RO mode,,30-08-2018 10:38,25,0,SpendHQ,"Rohit Puri9:56 PM (1 minute ago)to Matthew, Rean, spendhq-support@reancloud.comHi Mathew,We have remounted the iSCSI Volume on the instances including production and preview. Now this has been resolved. Please verify from your end and let us know if you face any issue. Thanks !Regards,Rohit Puri","Matthew Watts4:56 PM (3 minutes ago)to Rean, spendhq-support@reancloud.comDo you need help or consent?","Hello Matthew,We tried to reach out to you via phone but seems you were not available at that time. Could you please help us to stop the process so that we can re-mount the volumes.","Hello Matthew,We did lsof on the mount points before unmounting and could see that the processes are locked on the mount point. Could you please help us to stop the process so that we can re-mount the volume.Please join the bridge below:https://reancloud.zoom.us/my/mgse1","Hello Spendhq-Team,This is to inform you we could see that the below ISCSI volumes are in read-only mode. We are going to re-mount them in next few minutes.i-03ccfddd9f02cacb9 PRD-DB1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-170819-v777bb21358661922.00000028.2f1dab31-lun-0 sdn /mnt/production_19082017 ro i-073579ff33c73d3cd SpendHQ-memsql-server1-2018-04-01 ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server1-2018-04-01:dev10.ctr1-lun-0 sdb /mnt/memsql_storage ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /var/www/vhosts/files.spendhq.com ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /var/www/vhosts/secure.spendhq.com/public/app/tmp ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /exports_production/files.spendhq.com ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /exports_production/files.spendhq.com ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /exports_production/files.spendhq.com ro i-1426f28b PRD-FS1 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 sda /exports_production/files.spendhq.com/tmp ro",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EUYiF,Cloud Engineer Level 1,Closed,1067795,Incident,14-07-2017 05:29,,"Hello SpendHQ Team,The alert related to High CPU Load for PROD-SPHQ-DB-SERVER05 instance got resolved with a value of 2.4 and violation lasted for 40 minutes.###Hello SpendHQ Team,On further analysis, We found that the high CPU load has occurred due to the MySQL process.We were able to find that the server is getting hogged due to high CPU and Memory usage.The MySQL process running with PID 126238 is using a lot of CPU and Memory which is, in turn, causing this issue.Please find the details in the attachments.Kindly review our findings and let us know if you have any further queries.###Hello Team, This is to notify you that we have received an alert that High CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 3.702.We are analysing further on this issue and will get back to you with the updates.","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.072This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3954225075650602101 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,13-07-2017 19:07,10,0,SpendHQ,"Hello SpendHQ Team,The alert related to High CPU Load for PROD-SPHQ-DB-SERVER05 instance got resolved with a value of 2.4 and violation lasted for 40 minutes.","Hello SpendHQ Team,On further analysis, We found that the high CPU load has occurred due to the MySQL process.We were able to find that the server is getting hogged due to high CPU and Memory usage.The MySQL process running with PID 126238 is using a lot of CPU and Memory which is, in turn, causing this issue.Please find the details in the attachments.Kindly review our findings and let us know if you have any further queries.","Hello Team, This is to notify you that we have received an alert that High CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 3.702.We are analysing further on this issue and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001OYbPp,Cloud Engineer Level 1,Closed,1088942,Incident,19-01-2018 00:04,,"Hello David,As we have completed all the three requests during the call, we are marking this case as resolved.###David Miller10:23 PM (12 minutes ago)￼￼￼to me, Spendhq￼None of the ssh keys are also working on 10.59.1.132###David Miller10:22 PM (12 minutes ago)￼￼￼to me, Spendhq￼I am not able to access any of the servers, I receiving a permission denied, can you check that the keys all have the proper permissions on them on all the servers listed Do you need to ad my user to the ssh group or anything like that? Here is the error log when I try to ssh OpenSSH_7.5p1, LibreSSL 2.5.4debug1: Reading configuration data /Users/dmiller/.ssh/configdebug1: /Users/dmiller/.ssh/config line 1: Applying options for *debug1: Reading configuration data /etc/ssh/ssh_configdebug1: /etc/ssh/ssh_config line 52: Applying options for *debug1: Connecting to 10.59.10.183 [10.59.10.183] port 22.debug1: Connection established.debug1: identity file /Users/dmiller/.ssh/id_rsa type 1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_rsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_dsa type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_dsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_ecdsa type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_ecdsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_ed25519 type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_ed25519-cert type -1debug1: Enabling compatibility mode for protocol 2.0debug1: Local version string SSH-2.0-OpenSSH_7.5debug1: Remote protocol version 2.0, remote software version OpenSSH_7.4debug1: match: OpenSSH_7.4 pat OpenSSH* compat 0x04000000debug1: Authenticating to 10.59.10.183:22 as 'dmiller'debug1: SSH2_MSG_KEXINIT sentdebug1: SSH2_MSG_KEXINIT receiveddebug1: kex: algorithm: curve25519-sha256debug1: kex: host key algorithm: ecdsa-sha2-nistp256debug1: kex: server->client cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: nonedebug1: kex: client->server cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: nonedebug1: expecting SSH2_MSG_KEX_ECDH_REPLYdebug1: Server host key: ecdsa-sha2-nistp256 SHA256:imqFkpD+l72vNF5XsLCSiAkfBEeeOkoTen90f0CXAiQdebug1: Host '10.59.10.183' is known and matches the ECDSA host key.debug1: Found key in /Users/dmiller/.ssh/known_hosts:65debug1: rekey after 134217728 blocksdebug1: SSH2_MSG_NEWKEYS sentdebug1: expecting SSH2_MSG_NEWKEYSdebug1: SSH2_MSG_NEWKEYS receiveddebug1: rekey after 134217728 blocksdebug1: SSH2_MSG_EXT_INFO receiveddebug1: kex_input_ext_info: server-sig-algs=<rsa-sha2-256,rsa-sha2-512>debug1: SSH2_MSG_SERVICE_ACCEPT receiveddebug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-micdebug1: Next authentication method: publickeydebug1: Offering RSA public key: /Users/dmiller/.ssh/id_rsadebug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-micdebug1: Trying private key: /Users/dmiller/.ssh/id_dsadebug1: Trying private key: /Users/dmiller/.ssh/id_ecdsadebug1: Trying private key: /Users/dmiller/.ssh/id_ed25519debug1: No more authentication methods to try.Permission denied (publickey,gssapi-keyex,gssapi-with-mic).###Hello David,All of those requests are completed and updated via respective CMP cases.I need ssh access for dmiller on 10.59.10.190 (copy key from 10.59.10.135)We have copied SSH keys for your user. Kindly check and let us know if you are able to access the server 10.59.10.190 using your own credentials. CMP case ID: 01088868I need all ssh keys copied from (10.59.1.145) to (10.59.1.132)We have copied SSH keys from 10.59.1.145 to 10.59.1.132. Please try to log in and let us know if you have any queries. CMP case ID: 01088837I need ssh access for dmiller on 10.59.10.183 or at least redis turned on so we can utilize this server.We have added your ssh keys to 10.59.10.183. Kindly check and let us know if you are able to access the server 10.59.10.183 using your own credentials. CMP case ID: 01088642","Rean,I have sent several requests today and no response on any of them.  Can we get an update on our tickets please so we can move forward with our projects on our end.  Here is a summary of the latest requests.  *   I need ssh access for dmiller on 10.59.10.190 (copy key from 10.59.10.135)  *   I need all ssh keys copied from (10.59.1.145) to (10.59.1.132)  *   I need ssh access for dmiller on 10.59.10.183 or at least redis turned on so we can utilize this server.Thank youDavidDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Status Updates,,18-01-2018 21:13,3,0,SpendHQ,"Hello David,As we have completed all the three requests during the call, we are marking this case as resolved.","David Miller10:23 PM (12 minutes ago)￼￼￼to me, Spendhq￼None of the ssh keys are also working on 10.59.1.132","David Miller10:22 PM (12 minutes ago)￼￼￼to me, Spendhq￼I am not able to access any of the servers, I receiving a permission denied, can you check that the keys all have the proper permissions on them on all the servers listed Do you need to ad my user to the ssh group or anything like that? Here is the error log when I try to ssh OpenSSH_7.5p1, LibreSSL 2.5.4debug1: Reading configuration data /Users/dmiller/.ssh/configdebug1: /Users/dmiller/.ssh/config line 1: Applying options for *debug1: Reading configuration data /etc/ssh/ssh_configdebug1: /etc/ssh/ssh_config line 52: Applying options for *debug1: Connecting to 10.59.10.183 [10.59.10.183] port 22.debug1: Connection established.debug1: identity file /Users/dmiller/.ssh/id_rsa type 1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_rsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_dsa type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_dsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_ecdsa type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_ecdsa-cert type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_ed25519 type -1debug1: key_load_public: No such file or directorydebug1: identity file /Users/dmiller/.ssh/id_ed25519-cert type -1debug1: Enabling compatibility mode for protocol 2.0debug1: Local version string SSH-2.0-OpenSSH_7.5debug1: Remote protocol version 2.0, remote software version OpenSSH_7.4debug1: match: OpenSSH_7.4 pat OpenSSH* compat 0x04000000debug1: Authenticating to 10.59.10.183:22 as 'dmiller'debug1: SSH2_MSG_KEXINIT sentdebug1: SSH2_MSG_KEXINIT receiveddebug1: kex: algorithm: curve25519-sha256debug1: kex: host key algorithm: ecdsa-sha2-nistp256debug1: kex: server->client cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: nonedebug1: kex: client->server cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: nonedebug1: expecting SSH2_MSG_KEX_ECDH_REPLYdebug1: Server host key: ecdsa-sha2-nistp256 SHA256:imqFkpD+l72vNF5XsLCSiAkfBEeeOkoTen90f0CXAiQdebug1: Host '10.59.10.183' is known and matches the ECDSA host key.debug1: Found key in /Users/dmiller/.ssh/known_hosts:65debug1: rekey after 134217728 blocksdebug1: SSH2_MSG_NEWKEYS sentdebug1: expecting SSH2_MSG_NEWKEYSdebug1: SSH2_MSG_NEWKEYS receiveddebug1: rekey after 134217728 blocksdebug1: SSH2_MSG_EXT_INFO receiveddebug1: kex_input_ext_info: server-sig-algs=<rsa-sha2-256,rsa-sha2-512>debug1: SSH2_MSG_SERVICE_ACCEPT receiveddebug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-micdebug1: Next authentication method: publickeydebug1: Offering RSA public key: /Users/dmiller/.ssh/id_rsadebug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-micdebug1: Trying private key: /Users/dmiller/.ssh/id_dsadebug1: Trying private key: /Users/dmiller/.ssh/id_ecdsadebug1: Trying private key: /Users/dmiller/.ssh/id_ed25519debug1: No more authentication methods to try.Permission denied (publickey,gssapi-keyex,gssapi-with-mic).","Hello David,All of those requests are completed and updated via respective CMP cases.I need ssh access for dmiller on 10.59.10.190 (copy key from 10.59.10.135)We have copied SSH keys for your user. Kindly check and let us know if you are able to access the server 10.59.10.190 using your own credentials. CMP case ID: 01088868I need all ssh keys copied from (10.59.1.145) to (10.59.1.132)We have copied SSH keys from 10.59.1.145 to 10.59.1.132. Please try to log in and let us know if you have any queries. CMP case ID: 01088837I need ssh access for dmiller on 10.59.10.183 or at least redis turned on so we can utilize this server.We have added your ssh keys to 10.59.10.183. Kindly check and let us know if you are able to access the server 10.59.10.183 using your own credentials. CMP case ID: 01088642",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oLIy,Cloud Engineer Level 1,Closed,1042243,Incident,,,,"Fri, 13 Jan 2017 22:43:23 -0500SpendHQ has RecoveredEstimated Downtime: 7 minutes 26 seconds https://www.wormly.com/edithost/hostid/50743----------HTTP is UP----------Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SpendHQ has Recovered,,14-01-2017 09:13,0,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001f6P9M,Cloud Engineer Level 2,Closed,1108658,Incident,30-11-2018 13:19,,"@Team:I verified everything on SOPHOS UTM Portal. We did not find any certificate getting expired. I raised the same concern yesterday itself with SOPHOS and they told us that its a bug and they are working on this Proxy CA expiration notification. We need to ignore these alerts. Please close this ticket as we do not have to do much on this. SOPHOS Support Response FYI,Hello Rohit,This is regarding your service request number 8493671, with the reported issue. As discussed on the call, you have checked SSL certificate and it will expire in 2020. As discussed on the call, this is a false notification and the sophos support is aware about this behavior. You can simply ignore emails regarding this notifications. Rest be assured that everything is working properly on the UTM. As agreed, I am closing this case from my side. If you face any trouble with regards to this issue, please bring it to our notice with the same service request number within 14 days so that we may reopen the case log and assist you further.All notes from our interactions to date will be stored in our call logging system under the case number 8493671. This may be referenced in any new case that you raise with us in the future if you experience a similar issue.###Team,Please check with CC on this case.","1 certificate(s) will expire within the next 30 days:Proxy CAAccount Name - SpendHQAccount DL - ms@reancloud.comUTM Hostname - spendhq-utmPrivate IP - 10.59.1.192Public IP - 52.0.17.10Device URL - https://52.0.17.10:4444-- System Uptime      : 187 days 4 hours 12 minutesSystem Load        : 0.15System Version     : Sophos UTM 9.509-3Please refer to the manual for detailed instructions.--  <https://hubs.ly/H0fzGbl0>--  <https://hubs.ly/H0fzGbl0>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[SpendHQ] [10.59.1.192] [WARN-600] Certificate(s) will expire,,29-11-2018 21:31,16,0,SpendHQ,"@Team:I verified everything on SOPHOS UTM Portal. We did not find any certificate getting expired. I raised the same concern yesterday itself with SOPHOS and they told us that its a bug and they are working on this Proxy CA expiration notification. We need to ignore these alerts. Please close this ticket as we do not have to do much on this. SOPHOS Support Response FYI,Hello Rohit,This is regarding your service request number 8493671, with the reported issue. As discussed on the call, you have checked SSL certificate and it will expire in 2020. As discussed on the call, this is a false notification and the sophos support is aware about this behavior. You can simply ignore emails regarding this notifications. Rest be assured that everything is working properly on the UTM. As agreed, I am closing this case from my side. If you face any trouble with regards to this issue, please bring it to our notice with the same service request number within 14 days so that we may reopen the case log and assist you further.All notes from our interactions to date will be stored in our call logging system under the case number 8493671. This may be referenced in any new case that you raise with us in the future if you experience a similar issue.","Team,Please check with CC on this case.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oL8o,Cloud Engineer Level 1,Closed,1042242,Incident,14-01-2017 09:19,,This alert is due to the maintenance.,"Fri, 13 Jan 2017 22:36:57 -0500Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Dallas-B US, Atlanta-B US, California US, Frankfurt DE-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,14-01-2017 09:07,0,0,SpendHQ,This alert is due to the maintenance.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000017QEZy,Cloud Engineer Level 2,Closed,1042782,Incident,06-02-2017 05:47,,"Hello SpendHQ Team,By investigating further regarding this issue, We were able to sort out one request from access log made from one IP address 114.113.87.8. Please find the request details below.Time   : 2017-02-02T08:31:09 UTCELB Name : Secure-SpendHQ-ELBClient IP Address : 114.113.87.8Response Code : 504Requests : GET http://10.59.5.74:80/zecmd/zecmd.jsp?comment=id HTTP/1.0The requested client IP address 114.113.87.8 is from China and the organization name is Beijing RHTD Network Technology Co., Ltd.  As per https://www.abuseipdb.com, this IP address has been reported a total of 5 times for web app attack and port scan. Please find the report here https://www.abuseipdb.com/check/114.113.87.8 I have blocked this IP in NACL. I have pulled out last 30 days elb access logs and verified there are no requests came from the same IP or to the same requests URL.At this time, we're marking this case as Resolved.Thanks & Regards,Safuvan KM###I did some more analysis regarding this case. Pulled out the elb access logs around 2 minutes time of the alert and searched for the logs at exact reported time. The alert has the time for threat was reported at 2017-02-02 08:31:09 UTC. From the logs, I found a log exactly around that time with 504 response code and infinite loop. [root@localhost lblogan]# cat spendhq.csv | grep 08:31:09 2017-02-02T08:31:09.112462Z,Secure-SpendHQ-ELB,114.113.87.8:60238,-,-1,-1,-1,504,0,0,0,GET http://10.59.5.74:80/zecmd/zecmd.jsp?comment=id HTTP/1.0,-,-The requested client IP address 114.113.87.8 is from China and the organization name is Beijing RHTD Network Technology Co., Ltd. As per https://www.abuseipdb.com, this IP address has been reported a total of 5 times for web app attack and port scan. Please find the report here https://www.abuseipdb.com/check/114.113.87.8 I have blocked this IP in NACL. I have pulled out last 30 days elb access logs and verified there are no requests came from the same IP or to the same requests URL. Need to check with Sudheer whether we can close this by this action as the ticket was with Sudheer.###We tried to contact Sudheer for more updates regarding this case but he was not reachable.###Hello Andrew,Sorry for the late response.As of now, we have escalated this issue to our engineering team and they are currently reviewing this case. Will get back to you with further updates once we heard back from them.###Checked through established TCP connections, Apache log files and searched through the file system for any file with eval or such suspicious keyword, but didn't found anything. Escalating to sanket.###We have escalated this issue to Sushant for further analysis on this case.###We are not able to find more on this issue and escalating to Sriram###Hello Andrew,We are still working on this issue and we will provide you an update once we have any progress on it.###Hello Andrew,We will analyze further and let you know the updates.###We are not aware of any scans from Zscaler.###Hi SpendHQ Team,We have received an Intrusion Prevention Alert from Sophos and the source IP address 10.59.5.74 belongs to the secure ELB. We have analyzed the ELB logs and found that the most of the hits came from the AWS accounts from different regions.  On further analyzing the logs we could see the logs occurred at the time 2017-02-02 08:31:09 containing the ip 165.225.76.105 which belongs to a Zscaler Inc. Zscaler is a global cloud-based information security that provides Internet security. Please let us know if you are using any services from zscaler which runs any kind of scan.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: MALWARE-BACKDOOR JSP webshell backdoor detectedDetails........: https://www.snort.org/search?query=38719Time...........: 2017-02-02 08:31:09Packet dropped.: yesPriority.......: highClassification.: A Network Trojan was DetectedIP protocol....: 6 (TCP)Source IP address: 10.59.5.74Source port: 33720Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http),[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,02-02-2017 14:42,87,0,SpendHQ,"Hello SpendHQ Team,By investigating further regarding this issue, We were able to sort out one request from access log made from one IP address 114.113.87.8. Please find the request details below.Time   : 2017-02-02T08:31:09 UTCELB Name : Secure-SpendHQ-ELBClient IP Address : 114.113.87.8Response Code : 504Requests : GET http://10.59.5.74:80/zecmd/zecmd.jsp?comment=id HTTP/1.0The requested client IP address 114.113.87.8 is from China and the organization name is Beijing RHTD Network Technology Co., Ltd.  As per https://www.abuseipdb.com, this IP address has been reported a total of 5 times for web app attack and port scan. Please find the report here https://www.abuseipdb.com/check/114.113.87.8 I have blocked this IP in NACL. I have pulled out last 30 days elb access logs and verified there are no requests came from the same IP or to the same requests URL.At this time, we're marking this case as Resolved.Thanks & Regards,Safuvan KM","I did some more analysis regarding this case. Pulled out the elb access logs around 2 minutes time of the alert and searched for the logs at exact reported time. The alert has the time for threat was reported at 2017-02-02 08:31:09 UTC. From the logs, I found a log exactly around that time with 504 response code and infinite loop. [root@localhost lblogan]# cat spendhq.csv | grep 08:31:09 2017-02-02T08:31:09.112462Z,Secure-SpendHQ-ELB,114.113.87.8:60238,-,-1,-1,-1,504,0,0,0,GET http://10.59.5.74:80/zecmd/zecmd.jsp?comment=id HTTP/1.0,-,-The requested client IP address 114.113.87.8 is from China and the organization name is Beijing RHTD Network Technology Co., Ltd. As per https://www.abuseipdb.com, this IP address has been reported a total of 5 times for web app attack and port scan. Please find the report here https://www.abuseipdb.com/check/114.113.87.8 I have blocked this IP in NACL. I have pulled out last 30 days elb access logs and verified there are no requests came from the same IP or to the same requests URL. Need to check with Sudheer whether we can close this by this action as the ticket was with Sudheer.",We tried to contact Sudheer for more updates regarding this case but he was not reachable.,"Hello Andrew,Sorry for the late response.As of now, we have escalated this issue to our engineering team and they are currently reviewing this case. Will get back to you with further updates once we heard back from them.","Checked through established TCP connections, Apache log files and searched through the file system for any file with eval or such suspicious keyword, but didn't found anything. Escalating to sanket.",We have escalated this issue to Sushant for further analysis on this case.,We are not able to find more on this issue and escalating to Sriram,"Hello Andrew,We are still working on this issue and we will provide you an update once we have any progress on it.","Hello Andrew,We will analyze further and let you know the updates.",We are not aware of any scans from Zscaler.,"Hi SpendHQ Team,We have received an Intrusion Prevention Alert from Sophos and the source IP address 10.59.5.74 belongs to the secure ELB. We have analyzed the ELB logs and found that the most of the hits came from the AWS accounts from different regions.  On further analyzing the logs we could see the logs occurred at the time 2017-02-02 08:31:09 containing the ip 165.225.76.105 which belongs to a Zscaler Inc. Zscaler is a global cloud-based information security that provides Internet security. Please let us know if you are using any services from zscaler which runs any kind of scan.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eO0Na,Cloud Engineer Level 1,Closed,1107267,Incident,08-11-2018 16:59,,"Hello Mathew,We haven't heard back from you regarding the issue that you had before with the WW3_WEB_PROD Instance. The instance is currently in running state.Let us know if we are good to close this case.###Nishad Alli--------------------Hello Mathew,We used the tag to schedule the instances stop and start. It happened as a mistake from our part on the tags that we added to the instance. I had already removed the schedule tag from that instance and the cross-account lambda will avoid this instance in the future. We will also ensure that we will not add the schedule tag for the instance do not require a stop and start for any future requests. As of now, We will keep an Eye on the instance to ensure that it won't get stopped as before at the scheduled time.Kindly get back to us if you have any queriesThanks###@TeamI had removed the Tag from the instance   key: schedule, value:spendhq-office-hours-web tag###Hello Mathew, As already mentioned over the email, We apologize for the issue that you had due to the mistake from our part. We had checked with the instance WW3_WEB_PROD and could see that our team had mistakenly given the instance schedule tag for this also and that tag caused the instance to stop and start as scheduled. We will be removing the same and will ensure that the instance won't stop in future. Let us know if you have any queries. Instance Name : WW3_WEB_PROD Instance Id: i-0ddc7cdc07d158214 Private IP: 10.59.101.57","FYI, I have personally initiated a start request of this server as I need it to support the current webserver on the load balancer. Please DO NOT turn it off.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>On 11/7/18, 3:23 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:REAN,Why, if this instance was onboarded the same as the PRD box (10.59.101.6), was this server offline? This is a PRD machine and must be onboarded and monitored as a PRD box, as initially requested.Please advise why this was the case.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>On 10/18/18, 4:43 PM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:We need this escalated if possible.KeyValueInstance Name(Name of the instance to identify in the AWS Console)WW3_WEB_PRODInstance Type(RAM and CPU)Clone(Yes/No)YesIf Yes(Machine Details)10.59.101.6Subnet in which it must be Launch(If this instance need to have network connectivity with another instance)Same as cloneVolume Size(Root)Same as cloneSecondary Volume(Not needed/iSCSI Volume/ENS Volume)Same as cloneIf it is Cloned iSCSI Volume, then provide the details of volume and provide SizeSame as clone.Security Group Details(Required ports need to be open for this instance)Same as clone.SSH User Details(Details of the user who will need to have ssh access to this instance)Same as clone.Need to create new SSH Keys or copy the existing key(Provide the instance details from which we need to copy the keys)Same as clone.Sudo Access(Details of the user who should have sudo access)Same as clone.Operating SystemSame as clone.Onboard for REAN MonitoringSame as clone.BackupSame as clone.Environment(Production/Dev/Test/PoC)Same as clone.Requester Email ID(Email id of the owner of the instance)mwatts@spendhq.comAdditional Software(Give details of any specific software need to install on an instance or need to configure Public or Internal ELB, domain configuration etc.)Same as clone.Schedule Run Time of Instance(Does the server need to be turned on all the time or you want us to apply any scheduled downtime to stop/start)Same as clone.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: New Server Request,,07-11-2018 13:54,27,0,SpendHQ,"Hello Mathew,We haven't heard back from you regarding the issue that you had before with the WW3_WEB_PROD Instance. The instance is currently in running state.Let us know if we are good to close this case.","Nishad Alli--------------------Hello Mathew,We used the tag to schedule the instances stop and start. It happened as a mistake from our part on the tags that we added to the instance. I had already removed the schedule tag from that instance and the cross-account lambda will avoid this instance in the future. We will also ensure that we will not add the schedule tag for the instance do not require a stop and start for any future requests. As of now, We will keep an Eye on the instance to ensure that it won't get stopped as before at the scheduled time.Kindly get back to us if you have any queriesThanks","@TeamI had removed the Tag from the instance   key: schedule, value:spendhq-office-hours-web tag","Hello Mathew, As already mentioned over the email, We apologize for the issue that you had due to the mistake from our part. We had checked with the instance WW3_WEB_PROD and could see that our team had mistakenly given the instance schedule tag for this also and that tag caused the instance to stop and start as scheduled. We will be removing the same and will ensure that the instance won't stop in future. Let us know if you have any queries. Instance Name : WW3_WEB_PROD Instance Id: i-0ddc7cdc07d158214 Private IP: 10.59.101.57",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EtKKL,Cloud Engineer Level 1,Closed,1070148,Incident,29-07-2017 22:16,,"Hello SpendHQ, We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Next Action: Evening shift: Send a final reminder to the customer in the case of no response.###Hello SpendHQ,We haven't heard back from you regarding the RCA report.Did you get a chance to look into the RCA and provide your thoughts on that?Regards,Safuvan KM###Hello SpendHQ-Team, Please find the RCA for the outage happened on 27/7/2017 in the attachment section and let us know if you have any queries.###We tried to reach out Praveen but he was not available.Next Action: Morning shift: Get the RCA reviewed by Sanket/CC and share it with the customer.###We have informed Praveen/Yogesh to review the RCA. Check with them regarding the status and share the RCA with client accordingly.###Hello SpendHQ-Team,We are currently working on preparing the RCA for this outage and will be sharing the report with your team shortly.Meanwhile please let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###I added few comments. Please review the RCA###Provided the RCA to Yogesh for Review https://docs.google.com/document/d/17wjRpGWISqgWkXKsNN9x4pH0f7e75362AlSPy5PtDGI/edit####Next Action: Morning Shift: Start preparing the RCA document with the information added in the ticket and get it reviewed to share with the customer.###We have investigated further on the incident to figure out the root cause. From our analysis, we could see that the site down was because of the time out due to the high latency that reached a value of 300 seconds. We have analyzed the ELB access logs and sorted out the requests with high latency. Please refer the attached document with the latency logs details.On investigating further to the instance level to identify the reason for high latency, we were able to see a high number of HTTP connections with TIME_WAIT state and we suspect this is due to the application DB related problem because of the connections from Apache to the DB was not closing properly. Please refer the attachment section for the details of the open connections with TIME_WAIT state. Please find the error message that we figured out while loading the website during the incident time.Warning (2): mysqli_connect(): (08004/1040): Too many connections [CORE/cake/libs/model/datasources/dbo/dbo_mysqli.php, line 63] Warning (2): mysqli_set_charset() expects parameter 1 to be mysqli, boolean given [APP/models/datasources/dbo/dbo_mysqli_enhanced.php, line 84] Warning (2): pg_connect(): Unable to connect to PostgreSQL server: FATAL: sorry, too many clients already [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 119] Warning (2): pg_set_client_encoding() expects parameter 1 to be resource, boolean given [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 867] While checking the DB instance health, we went across a high-level resource utilization statistics like the network IN was around 10,000 MB/s, network OUT was around 11,000 MB/s, CPU usage was at 88% and CPU load reached 28.22. Please refer the attachment section for the graph related to these statistics. This indicated that the DB server was running out of resources and that was the reason the DB was unable to respond to the requests from the web server properly. Please review these details and let us know if this high traffic is expected, then we recommend upgrading the instance type to meet the resource utilization requirement for the application.Thank You,Safuvan KM###Hello Team,This is to notify you that the site down alert for the URLs https://preview.spendhq.com/login and https://secure.spendhq.com/login has resolved automatically and lasted for 5 minutes. The URLs are accessible now. We are analyzing the root cause and will get back to you with updates.###Hello SpendHq-Team,This is to notify you that we have received a site down alert for the URLs https://preview.spendhq.com/login and https://secure.spendhq.com/login. While checking we could see that the URL https://secure.spendhq.com/login is accessible and the URL https://preview.spendhq.com/login is having the below errors on the page.Warning (2): mysqli_connect(): (08004/1040): Too many connections [CORE/cake/libs/model/datasources/dbo/dbo_mysqli.php, line 63]Warning (2): mysqli_set_charset() expects parameter 1 to be mysqli, boolean given [APP/models/datasources/dbo/dbo_mysqli_enhanced.php, line 84]Warning (2): pg_connect(): Unable to connect to PostgreSQL server: FATAL:  sorry, too many clients already [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 119]Warning (2): pg_set_client_encoding() expects parameter 1 to be resource, boolean given [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 867]Please find the attached screenshot from the attachment section. We are investigating more on this and let us know if you are performing any activity from your end.","Wed, 26 Jul 2017 17:54:07 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: --------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): California US, Dallas-B US, Sydney-C AU, Atlanta-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,27-07-2017 03:24,67,0,SpendHQ,"Hello SpendHQ, We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.",Next Action: Evening shift: Send a final reminder to the customer in the case of no response.,"Hello SpendHQ,We haven't heard back from you regarding the RCA report.Did you get a chance to look into the RCA and provide your thoughts on that?Regards,Safuvan KM","Hello SpendHQ-Team, Please find the RCA for the outage happened on 27/7/2017 in the attachment section and let us know if you have any queries.",We tried to reach out Praveen but he was not available.Next Action: Morning shift: Get the RCA reviewed by Sanket/CC and share it with the customer.,We have informed Praveen/Yogesh to review the RCA. Check with them regarding the status and share the RCA with client accordingly.,"Hello SpendHQ-Team,We are currently working on preparing the RCA for this outage and will be sharing the report with your team shortly.Meanwhile please let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose",I added few comments. Please review the RCA,Provided the RCA to Yogesh for Review https://docs.google.com/document/d/17wjRpGWISqgWkXKsNN9x4pH0f7e75362AlSPy5PtDGI/edit,#Next Action: Morning Shift: Start preparing the RCA document with the information added in the ticket and get it reviewed to share with the customer.,"We have investigated further on the incident to figure out the root cause. From our analysis, we could see that the site down was because of the time out due to the high latency that reached a value of 300 seconds. We have analyzed the ELB access logs and sorted out the requests with high latency. Please refer the attached document with the latency logs details.On investigating further to the instance level to identify the reason for high latency, we were able to see a high number of HTTP connections with TIME_WAIT state and we suspect this is due to the application DB related problem because of the connections from Apache to the DB was not closing properly. Please refer the attachment section for the details of the open connections with TIME_WAIT state. Please find the error message that we figured out while loading the website during the incident time.Warning (2): mysqli_connect(): (08004/1040): Too many connections [CORE/cake/libs/model/datasources/dbo/dbo_mysqli.php, line 63] Warning (2): mysqli_set_charset() expects parameter 1 to be mysqli, boolean given [APP/models/datasources/dbo/dbo_mysqli_enhanced.php, line 84] Warning (2): pg_connect(): Unable to connect to PostgreSQL server: FATAL: sorry, too many clients already [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 119] Warning (2): pg_set_client_encoding() expects parameter 1 to be resource, boolean given [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 867] While checking the DB instance health, we went across a high-level resource utilization statistics like the network IN was around 10,000 MB/s, network OUT was around 11,000 MB/s, CPU usage was at 88% and CPU load reached 28.22. Please refer the attachment section for the graph related to these statistics. This indicated that the DB server was running out of resources and that was the reason the DB was unable to respond to the requests from the web server properly. Please review these details and let us know if this high traffic is expected, then we recommend upgrading the instance type to meet the resource utilization requirement for the application.Thank You,Safuvan KM","Hello Team,This is to notify you that the site down alert for the URLs https://preview.spendhq.com/login and https://secure.spendhq.com/login has resolved automatically and lasted for 5 minutes. The URLs are accessible now. We are analyzing the root cause and will get back to you with updates.","Hello SpendHq-Team,This is to notify you that we have received a site down alert for the URLs https://preview.spendhq.com/login and https://secure.spendhq.com/login. While checking we could see that the URL https://secure.spendhq.com/login is accessible and the URL https://preview.spendhq.com/login is having the below errors on the page.Warning (2): mysqli_connect(): (08004/1040): Too many connections [CORE/cake/libs/model/datasources/dbo/dbo_mysqli.php, line 63]Warning (2): mysqli_set_charset() expects parameter 1 to be mysqli, boolean given [APP/models/datasources/dbo/dbo_mysqli_enhanced.php, line 84]Warning (2): pg_connect(): Unable to connect to PostgreSQL server: FATAL:  sorry, too many clients already [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 119]Warning (2): pg_set_client_encoding() expects parameter 1 to be resource, boolean given [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 867]Please find the attached screenshot from the attachment section. We are investigating more on this and let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001RSgdL,Cloud Engineer Level 1,Closed,1091973,Incident,28-02-2018 23:16,,"Hello Team,This is to inform you the alert regarding the high disk usage on the volume /dev/xvda1 for the prd-fs1 got resolved. The current utilization is at 75%. At this time, we are marking this case resolved. Please revert back to us if you have any queries.###Hello Team,We haven't heard back from you.The alert regarding high disk usage on the instance prd-fs1 is still in the open state. On further analysis, we could see that Root volume is consuming high disk usage on this instance. Refer the below volume breakdown details. 1.9T total 1015G var 922G exports_production 1.2G usr 615M tmp 285M lib 213M home 209M opt 44M boot 30M etc Delete/Zip unwanted files or folders to reduce the current volume usage on this instance. Kindly validate these details from your end and let us know your thoughts regarding the same.###Hello SpendHQ team,The alert regarding high disk usage on the instance  prd-fs1  is still in the open state. On further analysis, we could see that Root volume is consuming high disk usage on this instance. Refer the below volume breakdown details. 1.9T    total1015G   var922G    exports_production1.2G    usr615M    tmp285M    lib213M    home209M    opt44M     boot30M     etcDelete/Zip unwanted files or folders to reduce the current volume usage on this instance. Kindly validate these details from your end and let us know your thoughts regarding the same.###Hello SpendHQ team,This is to notify you that we have received a EBS High Disk Usage ( /dev/xvda1 ) prd-fs1 alert it crossed the threshold value of 85% and reached a value of 86.9%. We will analyze more on this.Please find the resource details below.Name:prd-fs1Instance Id: i-1426f28bPrivate Ip: 10.59.100.125instance-type:c4.xlargeavailability-zone:us-east-1b","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Tue, Feb 27, 2018 at 9:26 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prd-fs1 - 10.59.100.125To: support@reancloud.com[image: Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-fs1 -10.59.100.125High Disk Usage detected on the device /dev/xvda1@support@reancloud.com[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1519703799000&group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-1426f28b&from_ts=1519703499000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 85The monitor was last triggered at Tue Feb 27 2018 03:56:49 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-1426f28b>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [Viewi-1426f28b <https://app.datadoghq.com/infrastructure?hostname=i-1426f28b>]· [Show Processes<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1519703809000&tags=host%3Ai-1426f28b&from_ts=1519702909000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4285587910667724303>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>Virus-free.www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail><#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-fs1 - 10.59.100.125,,27-02-2018 09:38,38,0,SpendHQ,"Hello Team,This is to inform you the alert regarding the high disk usage on the volume /dev/xvda1 for the prd-fs1 got resolved. The current utilization is at 75%. At this time, we are marking this case resolved. Please revert back to us if you have any queries.","Hello Team,We haven't heard back from you.The alert regarding high disk usage on the instance prd-fs1 is still in the open state. On further analysis, we could see that Root volume is consuming high disk usage on this instance. Refer the below volume breakdown details. 1.9T total 1015G var 922G exports_production 1.2G usr 615M tmp 285M lib 213M home 209M opt 44M boot 30M etc Delete/Zip unwanted files or folders to reduce the current volume usage on this instance. Kindly validate these details from your end and let us know your thoughts regarding the same.","Hello SpendHQ team,The alert regarding high disk usage on the instance  prd-fs1  is still in the open state. On further analysis, we could see that Root volume is consuming high disk usage on this instance. Refer the below volume breakdown details. 1.9T    total1015G   var922G    exports_production1.2G    usr615M    tmp285M    lib213M    home209M    opt44M     boot30M     etcDelete/Zip unwanted files or folders to reduce the current volume usage on this instance. Kindly validate these details from your end and let us know your thoughts regarding the same.","Hello SpendHQ team,This is to notify you that we have received a EBS High Disk Usage ( /dev/xvda1 ) prd-fs1 alert it crossed the threshold value of 85% and reached a value of 86.9%. We will analyze more on this.Please find the resource details below.Name:prd-fs1Instance Id: i-1426f28bPrivate Ip: 10.59.100.125instance-type:c4.xlargeavailability-zone:us-east-1b",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001aMvJ3,Cloud Engineer Level 1,Closed,1102667,Incident,21-08-2018 20:55,,"Hello Team,We have verified that all these are replica nodes and there won't be any impact on production environment due to the Scheduled Amazon ElastiCache (Redis) Maintenance.As a result we will proceed to close this case. Please feel free to reopen it if you have any concerns or reach us for any queries.Thanks.###Hello Team, This is a gentle reminder. We have checked the impact on the ElastiCache (Redis) Maintenance for the spendhq-redis and sph-preview. 1. There are 4 nodes under the spendhq-redis and only single AZ enabled. We have received the maintenance for the 2 replica nodes mentioned in the different time frame. As this maintenance scheduled on the replica node, we will not face any down since the primary node is available. Please see the maintenance details below. spendhq-redis-002, Region: us-east-1, replacementTime: 08:30 UTC, Oct 24, 2018 spendhq-redis-004, Region: us-east-1, replacementTime: 08:30 UTC, Aug 29, 2018 2. There are 3 nodes for sph-preview which is in MultiAZ, and the maintenance received for a replica node. Here alos we will not have any downtime for the environment. The replica node will be replaced on the maintenance window provided by the AWS NodeName: sph-preview-002, Region: us-east-1, replacementTime: 05:00 UTC, Oct 07, 2018 Kindly review the details and let us know if you have any concerns.###Hello Team, This is a gentle reminder.We have checked the impact on the ElastiCache (Redis) Maintenance for the spendhq-redis and sph-preview. 1. There are 4 nodes under the spendhq-redis and only single AZ enabled. We have received the maintenance for the 2 replica nodes mentioned in the different time frame. As this maintenance scheduled on the replica node, we will not face any down since the primary node is available. Please see the maintenance details below. spendhq-redis-002, Region: us-east-1, replacementTime: 08:30 UTC, Oct 24, 2018 spendhq-redis-004, Region: us-east-1, replacementTime: 08:30 UTC, Aug 29, 2018 2. There are 3 nodes for sph-preview which is in MultiAZ, and the maintenance received for a replica node. Here alos we will not have any downtime for the environment. The replica node will be replaced on the maintenance window provided by the AWS NodeName: sph-preview-002, Region: us-east-1, replacementTime: 05:00 UTC, Oct 07, 2018 Kindly review the details and let us know if you have any concerns.###Hello Team, We haven't heard back from you.Please review the details provided and let us know if you have any further concerns on this.###Hello Team,Please review the details provided and let us know if you have any further concerns on this.###Hello Team,We have checked impact on the ElastiCache (Redis) Maintenance for the spendhq-redis and sph-preview.  1. There are 4 nodes under the spendhq-redis and only single AZ enabled. We have received the maintenance for the 2 replica nodes mentioned in the different time frame. As this maintenance scheduled on the replica node, we will not face any down since the primary node is available. Please see the maintenance details below.spendhq-redis-002, Region: us-east-1, replacementTime: 08:30 UTC, Oct 24, 2018 spendhq-redis-004, Region: us-east-1, replacementTime: 08:30 UTC, Aug 29, 2018 2.  There are 3 nodes for sph-preview which is in MultiAZ, and the maintenance received for a replica node. Here alos we will not have any downtime for the environment. The replica node will be replaced on the maintenance window provided by the AWSNodeName: sph-preview-002, Region: us-east-1, replacementTime: 05:00 UTC, Oct 07, 2018 Kindly review the details and let us know if you have any concerns.###Shubhankar Raman <shubhankar.raman@reancloud.com>5:42 AM (0 minutes ago)to Matthew, Rean, spendhq-support We will check internally and will let you know.###Matthew Watts5:38 AM (2 minutes ago)to Rean, spendhq-support Will this cause downtime?###Hello Team,We have received a notification from AWS regarding Amazon ElastiCache (Redis) Maintenance [AWS Account: 261234435984]. In which it is mentioned that below are scheduled for replacement due to maintenance, which includes mandatory patches to improve security, reliability and operational performance. The maintenance will occur during the time range provided for each node. Please note that this is mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s).Your ElastiCache instances scheduled for maintenance:1) ClusterName: spendhq-redis, NodeName: spendhq-redis-002, Region: us-east-1, replacementTime: 08:30 UTC, Oct 24, 2018 2) ClusterName: sph-preview, NodeName: sph-preview-002, Region: us-east-1, replacementTime: 05:00 UTC, Oct 07, 2018 3) ClusterName: spendhq-redis, NodeName: spendhq-redis-004, Region: us-east-1, replacementTime: 08:30 UTC, Aug 29, 2018 Replacements generally take few minutes to complete, syncing the data from the master node can take additional time. The nodes will be unavailable to service requests during this period.","Do we have a ticket to track this?Thank You,Sanket DangiOn Fri, Aug 10, 2018 at 3:42 PM, Amazon Web Services, Inc. <no-reply-aws@amazon.com> wrote:> Dear Amazon ElastiCache Customer,>> Your Amazon ElastiCache node(s) listed below are scheduled for replacement> due to maintenance, which includes mandatory patches to improve security,> reliability and operational performance. The maintenance will occur during> the time range provided for each node. Please note that this is mandatory> maintenance that will begin in your cluster’s maintenance window but may> finish outside the window depending on the data and the load on the node(s).>> Your ElastiCache instances scheduled for maintenance:>  ClusterName: spendhq-redis, NodeName: spendhq-redis-002, Region:> us-east-1, replacementTime: 08:30 UTC, Oct 24, 2018>  ClusterName: sph-preview, NodeName: sph-preview-002, Region: us-east-1,> replacementTime: 05:00 UTC, Oct 07, 2018>  ClusterName: spendhq-redis, NodeName: spendhq-redis-004, Region:> us-east-1, replacementTime: 08:30 UTC, Aug 29, 2018>>> Replacements generally take few minutes to complete, syncing the data from> the master node can take additional time. The nodes will be unavailable to> service requests during this period.>> Refer to ElastiCache Maintenance FAQs for more details -> https://aws.amazon.com/elasticache/elasticache-maintenance/.>> If you have any questions or concerns, please contact the AWS Support Team> at http://aws.amazon.com/support>> Sincerely,> Amazon Web Services>> This message was produced and distributed by Amazon Web Services LLC, 410> Terry Avenue North, Seattle, Washington 98109> <https://maps.google.com/?q=410+Terry+Avenue+North,+Seattle,+Washington+98109&entry=gmail&source=g>> -5210.<https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Scheduled Amazon ElastiCache (Redis) Maintenance [AWS Account: 261234435984],,12-08-2018 23:46,214,0,SpendHQ,"Hello Team,We have verified that all these are replica nodes and there won't be any impact on production environment due to the Scheduled Amazon ElastiCache (Redis) Maintenance.As a result we will proceed to close this case. Please feel free to reopen it if you have any concerns or reach us for any queries.Thanks.","Hello Team, This is a gentle reminder. We have checked the impact on the ElastiCache (Redis) Maintenance for the spendhq-redis and sph-preview. 1. There are 4 nodes under the spendhq-redis and only single AZ enabled. We have received the maintenance for the 2 replica nodes mentioned in the different time frame. As this maintenance scheduled on the replica node, we will not face any down since the primary node is available. Please see the maintenance details below. spendhq-redis-002, Region: us-east-1, replacementTime: 08:30 UTC, Oct 24, 2018 spendhq-redis-004, Region: us-east-1, replacementTime: 08:30 UTC, Aug 29, 2018 2. There are 3 nodes for sph-preview which is in MultiAZ, and the maintenance received for a replica node. Here alos we will not have any downtime for the environment. The replica node will be replaced on the maintenance window provided by the AWS NodeName: sph-preview-002, Region: us-east-1, replacementTime: 05:00 UTC, Oct 07, 2018 Kindly review the details and let us know if you have any concerns.","Hello Team, This is a gentle reminder.We have checked the impact on the ElastiCache (Redis) Maintenance for the spendhq-redis and sph-preview. 1. There are 4 nodes under the spendhq-redis and only single AZ enabled. We have received the maintenance for the 2 replica nodes mentioned in the different time frame. As this maintenance scheduled on the replica node, we will not face any down since the primary node is available. Please see the maintenance details below. spendhq-redis-002, Region: us-east-1, replacementTime: 08:30 UTC, Oct 24, 2018 spendhq-redis-004, Region: us-east-1, replacementTime: 08:30 UTC, Aug 29, 2018 2. There are 3 nodes for sph-preview which is in MultiAZ, and the maintenance received for a replica node. Here alos we will not have any downtime for the environment. The replica node will be replaced on the maintenance window provided by the AWS NodeName: sph-preview-002, Region: us-east-1, replacementTime: 05:00 UTC, Oct 07, 2018 Kindly review the details and let us know if you have any concerns.","Hello Team, We haven't heard back from you.Please review the details provided and let us know if you have any further concerns on this.","Hello Team,Please review the details provided and let us know if you have any further concerns on this.","Hello Team,We have checked impact on the ElastiCache (Redis) Maintenance for the spendhq-redis and sph-preview.  1. There are 4 nodes under the spendhq-redis and only single AZ enabled. We have received the maintenance for the 2 replica nodes mentioned in the different time frame. As this maintenance scheduled on the replica node, we will not face any down since the primary node is available. Please see the maintenance details below.spendhq-redis-002, Region: us-east-1, replacementTime: 08:30 UTC, Oct 24, 2018 spendhq-redis-004, Region: us-east-1, replacementTime: 08:30 UTC, Aug 29, 2018 2.  There are 3 nodes for sph-preview which is in MultiAZ, and the maintenance received for a replica node. Here alos we will not have any downtime for the environment. The replica node will be replaced on the maintenance window provided by the AWSNodeName: sph-preview-002, Region: us-east-1, replacementTime: 05:00 UTC, Oct 07, 2018 Kindly review the details and let us know if you have any concerns.","Shubhankar Raman <shubhankar.raman@reancloud.com>5:42 AM (0 minutes ago)to Matthew, Rean, spendhq-support We will check internally and will let you know.","Matthew Watts5:38 AM (2 minutes ago)to Rean, spendhq-support Will this cause downtime?","Hello Team,We have received a notification from AWS regarding Amazon ElastiCache (Redis) Maintenance [AWS Account: 261234435984]. In which it is mentioned that below are scheduled for replacement due to maintenance, which includes mandatory patches to improve security, reliability and operational performance. The maintenance will occur during the time range provided for each node. Please note that this is mandatory maintenance that will begin in your cluster’s maintenance window but may finish outside the window depending on the data and the load on the node(s).Your ElastiCache instances scheduled for maintenance:1) ClusterName: spendhq-redis, NodeName: spendhq-redis-002, Region: us-east-1, replacementTime: 08:30 UTC, Oct 24, 2018 2) ClusterName: sph-preview, NodeName: sph-preview-002, Region: us-east-1, replacementTime: 05:00 UTC, Oct 07, 2018 3) ClusterName: spendhq-redis, NodeName: spendhq-redis-004, Region: us-east-1, replacementTime: 08:30 UTC, Aug 29, 2018 Replacements generally take few minutes to complete, syncing the data from the master node can take additional time. The nodes will be unavailable to service requests during this period.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001698W2,Cloud Engineer Level 1,Closed,1041772,Incident,03-01-2017 12:12,,"Hi SpendHQ Team,We have analyzed the ELB access logs and sorted out the requests from the IP 46.101.132.199.POST http://52.4.199.57:80/1/loading.php HTTP/1.1POST http://52.4.199.57:80/admin/loading.php HTTP/1.1POST http://52.4.199.57:80/a/loading.php HTTP/1.1POST http://52.4.199.57:80/aspq/aspx.gif HTTP/1.1POST http://52.4.199.57:80/dh/count.asp HTTP/1.1POST http://52.4.199.57:80/do.php HTTP/1.1POST http://52.4.199.57:80/extralog/loading.php HTTP/1.1POST http://52.4.199.57:80/folder/gate.php HTTP/1.1POST http://52.4.199.57:80/forum/login.php HTTP/1.1POST http://52.4.199.57:80/gate HTTP/1.1POST http://52.4.199.57:80/jackposprivate12/loading.php HTTP/1.1POST http://52.4.199.57:80/jacpos/loading.php HTTP/1.1POST http://52.4.199.57:80/jk/loading.php HTTP/1.1POST http://52.4.199.57:80/kp/loading.php HTTP/1.1POST http://52.4.199.57:80/loading.php HTTP/1.1POST http://52.4.199.57:80/panel2asdasd/up.php HTTP/1.1POST http://52.4.199.57:80/Panelll/loading.php HTTP/1.1POST http://52.4.199.57:80/panel/loading.php HTTP/1.1POST http://52.4.199.57:80/Panel/loading.php HTTP/1.1POST http://52.4.199.57:80/post/echo HTTP/1.1POST http://52.4.199.57:80/pub/adobe/reader/win/11.x/11.0.11/misc/AdbeRdrUpd11011_incr.msp HTTP/1.1POST http://52.4.199.57:80/tj.php HTTP/1.1POST http://52.4.199.57:80/vcxud91x83/loading.php HTTP/1.1POST http://52.4.199.57:80/whynot/sam.php HTTP/1.1POST http://52.4.199.57:80/wordpress/post.php HTTP/1.1POST http://52.4.199.57:80/wp-log/push.php HTTP/1.1POST http://52.4.199.57:80/alinew/loading.php HTTP/1.1POST http://52.4.199.57:80/jackpos/loading.php HTTP/1.1POST http://52.4.199.57:80/jackposv1/loading.php HTTP/1.1POST http://52.4.199.57:80/jackposv2/loading.php HTTP/1.1POST http://52.4.199.57:80/alina/loading.php HTTP/1.1The reported Threat name C2/Zbot-A (SID: 25050). The threat details are as below.Threat name : C2/Zbot-AAliases         : ZeusCharacteristics : Enables remote accessHow it spreads : Browsing, DownloadsWe have blocked this IP in NACL level. Please find the attached sheets for elb logs and let us know if you have any queries on this.###Hi SpendhQ Team,On analyzing the logs we found that all the request at the time: 2017-01-02 21:21:33 were from IP 46.101.132.199 and is having 403 response code. IP address details:IP Address	          Country	Region     	City46.101.132.199	Germany 	Bayern	FrankfurtPlease let us know if you want us to block this IP.###Hi SpendHQ Team,On further analysis, we found that 10.59.1.167 IP is assigned to the preview-spendhq-xelb loadbalancer in your environment. We are analyzing the logs and will provide you the updates.###Hi SpendHQ Team,We want to inform you that we have received an alert notification from Sophos in your environment. The source IP/host 10.59.1.167  was found to communicate with a potentially malicious site outside your company. We are analyzing this issue and will provide you the updates.",Advanced Threat ProtectionA threat has been detected in your networkThe source IP/host listed below was found to communicate with a potentially malicious site outside your company.Details about the alert:Threat name....: C2/Zbot-A (SID: 25050)Details........: http://www.sophos.com/en-us/threat-center/threat-analyses/viruses-and-spyware/C2~Zbot-A.aspxTime...........: 2017-01-02 21:21:33Traffic blocked: noSource IP address or host: 10.59.1.167,Advanced Threat Protection Alert,,03-01-2017 03:00,9,0,SpendHQ,"Hi SpendHQ Team,We have analyzed the ELB access logs and sorted out the requests from the IP 46.101.132.199.POST http://52.4.199.57:80/1/loading.php HTTP/1.1POST http://52.4.199.57:80/admin/loading.php HTTP/1.1POST http://52.4.199.57:80/a/loading.php HTTP/1.1POST http://52.4.199.57:80/aspq/aspx.gif HTTP/1.1POST http://52.4.199.57:80/dh/count.asp HTTP/1.1POST http://52.4.199.57:80/do.php HTTP/1.1POST http://52.4.199.57:80/extralog/loading.php HTTP/1.1POST http://52.4.199.57:80/folder/gate.php HTTP/1.1POST http://52.4.199.57:80/forum/login.php HTTP/1.1POST http://52.4.199.57:80/gate HTTP/1.1POST http://52.4.199.57:80/jackposprivate12/loading.php HTTP/1.1POST http://52.4.199.57:80/jacpos/loading.php HTTP/1.1POST http://52.4.199.57:80/jk/loading.php HTTP/1.1POST http://52.4.199.57:80/kp/loading.php HTTP/1.1POST http://52.4.199.57:80/loading.php HTTP/1.1POST http://52.4.199.57:80/panel2asdasd/up.php HTTP/1.1POST http://52.4.199.57:80/Panelll/loading.php HTTP/1.1POST http://52.4.199.57:80/panel/loading.php HTTP/1.1POST http://52.4.199.57:80/Panel/loading.php HTTP/1.1POST http://52.4.199.57:80/post/echo HTTP/1.1POST http://52.4.199.57:80/pub/adobe/reader/win/11.x/11.0.11/misc/AdbeRdrUpd11011_incr.msp HTTP/1.1POST http://52.4.199.57:80/tj.php HTTP/1.1POST http://52.4.199.57:80/vcxud91x83/loading.php HTTP/1.1POST http://52.4.199.57:80/whynot/sam.php HTTP/1.1POST http://52.4.199.57:80/wordpress/post.php HTTP/1.1POST http://52.4.199.57:80/wp-log/push.php HTTP/1.1POST http://52.4.199.57:80/alinew/loading.php HTTP/1.1POST http://52.4.199.57:80/jackpos/loading.php HTTP/1.1POST http://52.4.199.57:80/jackposv1/loading.php HTTP/1.1POST http://52.4.199.57:80/jackposv2/loading.php HTTP/1.1POST http://52.4.199.57:80/alina/loading.php HTTP/1.1The reported Threat name C2/Zbot-A (SID: 25050). The threat details are as below.Threat name : C2/Zbot-AAliases         : ZeusCharacteristics : Enables remote accessHow it spreads : Browsing, DownloadsWe have blocked this IP in NACL level. Please find the attached sheets for elb logs and let us know if you have any queries on this.","Hi SpendhQ Team,On analyzing the logs we found that all the request at the time: 2017-01-02 21:21:33 were from IP 46.101.132.199 and is having 403 response code. IP address details:IP Address	          Country	Region     	City46.101.132.199	Germany 	Bayern	FrankfurtPlease let us know if you want us to block this IP.","Hi SpendHQ Team,On further analysis, we found that 10.59.1.167 IP is assigned to the preview-spendhq-xelb loadbalancer in your environment. We are analyzing the logs and will provide you the updates.","Hi SpendHQ Team,We want to inform you that we have received an alert notification from Sophos in your environment. The source IP/host 10.59.1.167  was found to communicate with a potentially malicious site outside your company. We are analyzing this issue and will provide you the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DDl4I,Cloud Engineer Level 1,Closed,1063044,Incident,16-06-2017 00:36,,"Hello SpendHQ Team,This is to notify you that we have received an volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% to 93.1%. Later the alert got resolved and has returned to normal with a value of 49.1%. The violation has lasted for 13 minutes.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Fri, Jun 16, 2017 at 12:09 AMSubject: [Monitor Alert] Warn: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Warn on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS High DiskUsage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135@ms@reancloud.com<http://email.dtdg.co/c/eJwVjT0LgzAURX-N2Sp5ar6GDK0ghc4d2qUkeYkKaqzGof--Ee5wuHDuRc2U9WTUFQVBOTCQtWKyFI1oaKnqCroOQFU3Dm3Li4Ziwr50kQyaOUWR0SCFszIwBIPgZUbLgxHSkkkPKa17UV-Lqssx61qiSQZjP3zzxnx2zsVjSZnWLYZx8pmOC33T9vP4vZ5wP8im5z0fb94sbooHniZJeo7LmOL2B1mVOqg>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj01uhDAMhU8TlpGdxAleZNGh4hpVIAFGGiYUMqMevwF1Ucnyz7P86Tl64iE1d68AHVgkbDVTK51xBiRrhX2PyOpmseusMBBLnOWYm8Vzy8DahWGaOOAwJDPwmEZuKQaDlpqHX0rZDqE_hOprhG2TMZQQ87x8V8ZatTU_7yXvh1BagdJsWei-5K9Szz7RsCNC1gwAQtl5z6-t6jG972MSik4yqb7OV_15x4Bn1y35KNceQRLLmlFTJUx7Xv-zwV3sZvfrUZ_bU3iOj_yKp7um-D93vzp6Uxw>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Thu Jun 15 2017 18:39:00 UTC (*57 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtjk2OwyAMhU8DS4QNBFiwmGbEPQg_SaSmZBJa9fgl1UjWs_0sfc_JKTtlujrkoPkACoywyjAtteTMCgTvASzeBhjHgUieWppZrHRxvAAWmWwuU4jG6jJZ5LpTopZgTKF3t7S2n0T8EPS9wr6zFFpIdV7-OmPr3lYfa6vHSVAgR2EHS4Sfj_rcifhN-bXGTFBdBIW-79_-fqUA1zQu9WzfO3CmLOsKQtHDbWd_9cjhEe_1ma4s2tx_1ge9-kX7>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjcsKwyAQRb9Gl-KMccwsXLSB_IePvCCpaWL_vxYKd3XgnJu95TjJzaMGpwks9IZtr1znOq3YIIwjAOOTYBhIdDrXvKhU5OqxD5YMRWtSTAFmDayRUgzs5jg7krtfaz1vYR4Cx7ZwniqHGnJZ1ndrHI0d5bXVct0CDWo0TNzglLcqL3_c7e-awivt5ZN_gqz-L3wB9ag2Rg>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVjUsKwzAQQ08TL43Hfy-8aFNyj0mcHyRxak_uXxeEEA8kpWjCOLM9SgFOWDDgVTCeO-204EFJGAaAIN8W-t52WiRKK58y2-LiUTvhMIVJWSnEsijrLCD6WSrtR3bEjeiunXp1cmjC--YJCVNet2_bOBvbr6VgpfJM9JS5U8OWK114tvgBwU3gzUEZVuJZ232Z8ZqO_KR_n1E887VTLj9J8Dsi>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jU0KwyAUhE-jS_H5_F24aFO8h1GbBJKYJrbnr90UBgaGb2ayV24sdPGCg-EaFFh0yjIjjeTMoYAQAJy4axgGTSTPLU8sVTp7EQ2YZMAmOdo0dqpo1FkbBMefutDVz60dF8EbEaErHgfLscVcp_nVN7aelU_Z298xLJngAx2gkwKkASmtReUsPf129fuzxD2t9Z1_fdr8Vvel1fMLveU44Q>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjcEOgyAQRL9GjsQVFDlwaE38j3V3qyZVKOL_F5M5TF4mbzj0fhG1h64F1w7Qw2h8P2pnnW21Nx3MM4Dv3gNM09DYlguvmqLaguDCQJ4RyTI7RkLpLYklZ8WbUX3DVkq6GvNqurkGU9KMBTmu2686jocRxfsstaUsH8lyklwqh-OqX1nwpG-8-RmrEo547iXmP_v9N_4>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Warn: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,16-06-2017 00:31,0,0,SpendHQ,"Hello SpendHQ Team,This is to notify you that we have received an volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% to 93.1%. Later the alert got resolved and has returned to normal with a value of 49.1%. The violation has lasted for 13 minutes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FeiO9,Cloud Engineer Level 1,Closed,1073559,Incident,16-08-2017 23:37,,"Hello SpendHQ-Team,As we tracking this case under 01073556, we are marking this case as resolved. Revert back in case of any further queries.Regards,Sumod.K.Bose","Wed, 16 Aug 2017 10:29:04 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Dallas-B US, Atlanta-B US, California US, Sydney-C AU-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,16-08-2017 19:59,4,0,SpendHQ,"Hello SpendHQ-Team,As we tracking this case under 01073556, we are marking this case as resolved. Revert back in case of any further queries.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hR3nq,Cloud Engineer Level 1,Closed,1110195,Incident,07-01-2019 07:27,,"Hello Team, We haven't heard back from you.This is to inform you that the alert regarding High Network In on the host SPHQ-DB4-20180830 is in a recovered state, therefore we are marking this case resolved and closing this case.Please get back to us if you have any concerns.###Hello Team,We haven't heard back from you.please review our analysis shared regarding the High Network In alert on the host SPHQ-DB4-20180830 and let us know if you have any concerns on the same. Thanks.###Hello Team,This is a quick follow up, please review our analysis shared regarding the High Network In alert on the host SPHQ-DB4-20180830 and let us know if you have any concerns on the same.Thanks.###Hello Team,We would like to bring to your attention that we have received an alert regarding High Network In on the host SPHQ-DB4-20180830.We checked on the alert and identified a lot of connections that are still in the TIME_WAIT state.A lot of theses connections were being initiated from the servers SPHQ-DB4-20180830 (10.59.10.210) and PRD-WW1_122 (10.59.100.122).We have attached the full list of open TCP connections during the time of the alert. Please have a look and let us know if you have any queries.The alert lasted for 12 minutes and later got recovered.Resource Details:Instance ID:	i-082d412700b276f44	Instance Name:	SPHQ-DB4-20180830	Instance Type: 	r4.8xlarge	Availability Zone:	us-east-1b	Region:	us-east-1Subnet ID: 	subnet-0fdde924	VPC: 	vpc-76df7212Private IP Address: 	10.59.10.210","[image: Datadog][Triggered] [SpendHQ] - High Network IN on host - sphq-db4-20180830 -10.59.10.210 -High Network IN on the instance. Please check the list open TCP Connections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024210?to_ts=1546532140000&group=host%3Ai-082d412700b276f44&from_ts=1546524940000>*aws.ec2.network_in* over *datadog_monitor:on,host:i-082d412700b276f44* was *>2436870912.0* at all times during the *last 30m*.The monitor was last triggered at Thu Jan 03 2019 16:15:50 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024210?group=host%3Ai-082d412700b276f44>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024210/edit>] · [Viewi-082d412700b276f44<https://app.datadoghq.com/infrastructure?filter=i-082d412700b276f44>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1546532270000&tags=host%3Ai-082d412700b276f44&from_ts=1546531250000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4735692785316788563>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.---- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network IN on host - sphq-db4-20180830 - 10.59.10.210 -,,03-01-2019 21:54,82,0,SpendHQ,"Hello Team, We haven't heard back from you.This is to inform you that the alert regarding High Network In on the host SPHQ-DB4-20180830 is in a recovered state, therefore we are marking this case resolved and closing this case.Please get back to us if you have any concerns.","Hello Team,We haven't heard back from you.please review our analysis shared regarding the High Network In alert on the host SPHQ-DB4-20180830 and let us know if you have any concerns on the same. Thanks.","Hello Team,This is a quick follow up, please review our analysis shared regarding the High Network In alert on the host SPHQ-DB4-20180830 and let us know if you have any concerns on the same.Thanks.","Hello Team,We would like to bring to your attention that we have received an alert regarding High Network In on the host SPHQ-DB4-20180830.We checked on the alert and identified a lot of connections that are still in the TIME_WAIT state.A lot of theses connections were being initiated from the servers SPHQ-DB4-20180830 (10.59.10.210) and PRD-WW1_122 (10.59.100.122).We have attached the full list of open TCP connections during the time of the alert. Please have a look and let us know if you have any queries.The alert lasted for 12 minutes and later got recovered.Resource Details:Instance ID:	i-082d412700b276f44	Instance Name:	SPHQ-DB4-20180830	Instance Type: 	r4.8xlarge	Availability Zone:	us-east-1b	Region:	us-east-1Subnet ID: 	subnet-0fdde924	VPC: 	vpc-76df7212Private IP Address: 	10.59.10.210",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oc9t,Cloud Engineer Level 1,Closed,1042303,Incident,16-01-2017 19:56,,We have reset his password and Andrew confirmed that he is able to login.,"Please reset my AKim AWS console password. Thank you,",Reset akim AWS Console Password,,16-01-2017 19:52,0,0,SpendHQ,We have reset his password and Andrew confirmed that he is able to login.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001HVKdC,Cloud Engineer Level 1,Closed,1079106,Incident,19-09-2017 12:17,,"Hello SpendHQ-Team, This is to inform you that we have received an alert regarding high Network IN on the instance prd-db1. The Network Outbound was above the threshold of 2.22 GB/Min. The alert got resolved automatically and returned to a normal state.The overall violation lasted for 10 minutes. Resource Details:- Availability-zone:us-east-1b Image:ami-453f3053 Instance-type:r4.8xlarge Instance Name:prd-db1 Region:us-east-1 Instance ID: i-03ccfddd9f02cacb9 As the alert is in the resolved state, we are marking this case as closed. Kindly validate these details from your end and revert back in case of any further queries.","[Triggered] [SpendHQ] - High Network IN  on host - prd-db1 -  - db Status  High Network IN on the instance. Please check the list open TCP Connections    @support@reancloud.comaws.ec2.network_in over datadog_monitor:on,host:i-03ccfddd9f02cacb9 was > 2200000000.0 at all times during the last 5m.Metric value: 2372984832.0This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024210?group=host%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2024210/edit · Event URL: https://app.datadoghq.com/event/event?id=4052277025261456778 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network IN on host - prd-db1 - - db Status,,19-09-2017 10:33,2,0,SpendHQ,"Hello SpendHQ-Team, This is to inform you that we have received an alert regarding high Network IN on the instance prd-db1. The Network Outbound was above the threshold of 2.22 GB/Min. The alert got resolved automatically and returned to a normal state.The overall violation lasted for 10 minutes. Resource Details:- Availability-zone:us-east-1b Image:ami-453f3053 Instance-type:r4.8xlarge Instance Name:prd-db1 Region:us-east-1 Instance ID: i-03ccfddd9f02cacb9 As the alert is in the resolved state, we are marking this case as closed. Kindly validate these details from your end and revert back in case of any further queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001IGh5B,Cloud Engineer Level 1,Closed,1081693,Incident,11-10-2017 03:16,,"Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 3.153.The alert got resolved automatically and has reduced to a value of 2.977. Let us know if you have any further queries. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1","[Triggered] [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over datadog_monitor:on,host:i-03ccfddd9f02cacb9 was > 3.0 on average during the last 5m.Metric value: 3.153This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=4083622596498776624 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db,,11-10-2017 01:32,2,0,SpendHQ,"Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 3.153.The alert got resolved automatically and has reduced to a value of 2.977. Let us know if you have any further queries. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Ko7ZM,Cloud Engineer Level 1,Closed,1084906,Incident,21-11-2017 22:01,,"david has confirmed it and hence closing the ticket.###Hello David,We haven't heard back from you.Please validate the details and let us know wi you have any further queries regarding this.###The URLs have onboarded to MGS team as per the confirmation by SpendHQ team.###I will talk to SpendHQ in the evening to confirm if the resources related to the https://api.spendhq.com and https://preview-api.spendhq.com are needed to be onboard to MGS.###Hello David,The issue regarding https://preview-api.spendhq.com/ - Service unavailable (ip: 10.59.100.210) has also been fixed.From Sophos level, we were able to see that everything was fine but while we have analyzed from the instance level, we could see that the instance was not listening to port 80 and 443. Refer the screenshot below,Inline images 1Hence we have restarted the httpd service to resolve this issue. Kindly validate these details and let us know if you have any further queries regarding this case.Regards,Sumod.K.Bose###Hello David,The issue has been fixed on https://api.spendhq.com/ - Proxy Error (ip: 10.59.100.78 and 10.59.101.78).Please check and confirm the same. We are further analyzing the issue on https://preview-api.spendhq.com/ - Service unavailable (ip: 10.59.100.210) and will get back to you with the updates shortly.-- Best Regards,Sumod Kurian Bose","Hello,The following domains are currently not functional.  We need these resolved asap.https://api.spendhq.com/ - Proxy Error (ip: 10.59.100.78 and 10.59.101.78)https://preview-api.spendhq.com/ - Service unavailable (ip: 10.59.100.210)Please let me know when this issue has been resolved so we can notify all parties involved.Thank YouDavidDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/>--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Api Servers are Down,,21-11-2017 03:32,18,0,SpendHQ,david has confirmed it and hence closing the ticket.,"Hello David,We haven't heard back from you.Please validate the details and let us know wi you have any further queries regarding this.",The URLs have onboarded to MGS team as per the confirmation by SpendHQ team.,I will talk to SpendHQ in the evening to confirm if the resources related to the https://api.spendhq.com and https://preview-api.spendhq.com are needed to be onboard to MGS.,"Hello David,The issue regarding https://preview-api.spendhq.com/ - Service unavailable (ip: 10.59.100.210) has also been fixed.From Sophos level, we were able to see that everything was fine but while we have analyzed from the instance level, we could see that the instance was not listening to port 80 and 443. Refer the screenshot below,Inline images 1Hence we have restarted the httpd service to resolve this issue. Kindly validate these details and let us know if you have any further queries regarding this case.Regards,Sumod.K.Bose","Hello David,The issue has been fixed on https://api.spendhq.com/ - Proxy Error (ip: 10.59.100.78 and 10.59.101.78).Please check and confirm the same. We are further analyzing the issue on https://preview-api.spendhq.com/ - Service unavailable (ip: 10.59.100.210) and will get back to you with the updates shortly.-- Best Regards,Sumod Kurian Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VrXQs,Cloud Engineer Level 1,Closed,1098244,Incident,08-05-2018 10:40,,"Hello Team,We are tracking this case on 01098242 and closing the case from here.###Hello Spendhq-Team,This is to inform you that we received site down alert on the URL: https://preview.spendhq.com/login.It got recovered within 2 minutes. Please let us know if you are performing any changes on your end.We will analysis further in this case and will let you know the updates.","Mon, 07 May 2018 23:09:34 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30005 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: Atlanta-B USConfirmed by node(s): California US, London UK, Dallas-B US, New Jersey US--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,08-05-2018 08:39,2,0,SpendHQ,"Hello Team,We are tracking this case on 01098242 and closing the case from here.","Hello Spendhq-Team,This is to inform you that we received site down alert on the URL: https://preview.spendhq.com/login.It got recovered within 2 minutes. Please let us know if you are performing any changes on your end.We will analysis further in this case and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013wa5F,Cloud Engineer Level 1,Closed,1031541,Incident,16-11-2016 00:16,,"From: Andrew Kim (SpendHQ) <Akim@spendhq.com>Date: Tuesday 15 November 2016Subject: RE: Priority Critical - P1 | Update on Case # I-01031541To: Rean Support <notifications@reancloud.com>No. You can close this case. Thank you, Andrew Kim | Development Manager | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Gentle Reminder,Please let us know if need any further information regarding this issue.###Hi Team, On further analysis of the PHP logs, we found that there was an error in /var/www/vhosts/secure.spendhq.com/public/app/config/server.config.php.Please find the error detailed below:PHP Parse error:  syntax error, unexpected ''mwatts@spendhq.com'' (T_CONSTANT_ENCAPSED_STRING), expecting ')' in /var/www/vhosts/secure.spendhq.com/public/app/config/server.config.php on line 195, referer: https://secure.spendhq.com/spend-visibility/reports_and_statisticsp.s: Quite a time before the above error PHP had some memory exhaustion. Below is the detailed error:PHP Fatal error:  Allowed memory size of 2147483648 bytes exhausted (tried to allocate 130968 bytes) in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4639, referer: https://secure.spendhq.com/loginIt will be recommended that you increase the memory allocated to PHP to avoid any error due to above issue in near future.###We didn't get any 4xx or 5xx errors since 10:56am eastern.###Hi Team,On checking ELB logs, we can see a number of 5xx and 4xx errors.Please check the below details and graphs for more details.Sl_No   Client_Ip       Count_4xx1       208.82.124.93   2052       50.76.228.97    83       144.15.255.227  84       65.216.219.5    45       204.10.44.254   26       75.73.224.243   1Sl_No   Client_Ip       Count_5xx1       216.235.157.68  692       69.27.253.226   613       50.76.228.97    304       54.250.253.197  195       54.248.220.5    196       54.244.52.229   197       54.228.16.37    198       54.183.255.165  199       177.71.207.133  1910      54.243.31.197   1811      54.232.40.101   1812      176.34.159.197  1813      107.23.255.37   1814      54.252.79.133   1715      54.252.254.229  1716      54.245.168.5    1717      54.241.32.69    1718      208.82.124.93   1719      107.77.234.106  1320      54.244.253.127  1021      184.75.215.98   1022      146.148.119.250 10###This is to notify you that we got an alert of site down for https://secure.spendhq.com/login . The alert got resolved within 8 minute. We have verified that the site is up and running. We are checking on this and will get back to you with the details.Please let us know if you performed any activity from your end.","Mon, 14 Nov 2016 10:45:20 -0500Detected Error on SpendHQEstimated Downtime: 59 seconds https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): California US, Frankfurt DE, London UK, Dallas-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,14-11-2016 21:15,27,0,SpendHQ,"From: Andrew Kim (SpendHQ) <Akim@spendhq.com>Date: Tuesday 15 November 2016Subject: RE: Priority Critical - P1 | Update on Case # I-01031541To: Rean Support <notifications@reancloud.com>No. You can close this case. Thank you, Andrew Kim | Development Manager | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Gentle Reminder,Please let us know if need any further information regarding this issue.","Hi Team, On further analysis of the PHP logs, we found that there was an error in /var/www/vhosts/secure.spendhq.com/public/app/config/server.config.php.Please find the error detailed below:PHP Parse error:  syntax error, unexpected ''mwatts@spendhq.com'' (T_CONSTANT_ENCAPSED_STRING), expecting ')' in /var/www/vhosts/secure.spendhq.com/public/app/config/server.config.php on line 195, referer: https://secure.spendhq.com/spend-visibility/reports_and_statisticsp.s: Quite a time before the above error PHP had some memory exhaustion. Below is the detailed error:PHP Fatal error:  Allowed memory size of 2147483648 bytes exhausted (tried to allocate 130968 bytes) in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4639, referer: https://secure.spendhq.com/loginIt will be recommended that you increase the memory allocated to PHP to avoid any error due to above issue in near future.",We didn't get any 4xx or 5xx errors since 10:56am eastern.,"Hi Team,On checking ELB logs, we can see a number of 5xx and 4xx errors.Please check the below details and graphs for more details.Sl_No   Client_Ip       Count_4xx1       208.82.124.93   2052       50.76.228.97    83       144.15.255.227  84       65.216.219.5    45       204.10.44.254   26       75.73.224.243   1Sl_No   Client_Ip       Count_5xx1       216.235.157.68  692       69.27.253.226   613       50.76.228.97    304       54.250.253.197  195       54.248.220.5    196       54.244.52.229   197       54.228.16.37    198       54.183.255.165  199       177.71.207.133  1910      54.243.31.197   1811      54.232.40.101   1812      176.34.159.197  1813      107.23.255.37   1814      54.252.79.133   1715      54.252.254.229  1716      54.245.168.5    1717      54.241.32.69    1718      208.82.124.93   1719      107.77.234.106  1320      54.244.253.127  1021      184.75.215.98   1022      146.148.119.250 10",This is to notify you that we got an alert of site down for https://secure.spendhq.com/login . The alert got resolved within 8 minute. We have verified that the site is up and running. We are checking on this and will get back to you with the details.Please let us know if you performed any activity from your end.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Cf7Nm,Cloud Engineer Level 1,Closed,1059376,Incident,03-06-2017 18:11,,"This is to inform you that we received an Intrusion Prevention Alert again from Sophos and the source IP address is 10.59.1.167 which belongs to the preview-spendhq-xelb. Please find the Intrusion Prevention Log details: Name: Intrusion protection alert Action: drop Reason: BLACKLIST User-Agent known malicious user-agent string - Win.Trojan.Batlopma Class: A Network Trojan was Detected ELB Logs:2017-06-03T10:03:03.835679Z preview-spendhq-xelb 184.105.247.194:53652 10.59.1.192:443 0.000041 0.001012 0.00002 403 403 0 209 GET https://52.4.199.57:443/ HTTP/1.1 - ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2IP Details:IP Address: 184.105.247.194	Country: United States 	ISP: Hurricane Electric Inc.This Ip was reported abusive from https://www.abuseipdb.com. We have blocked the IP in NACL and let us know if you have any queries.###This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167 which belongs to the preview-spendhq-xelb. Please find the Intrusion Prevention Log details:Name: Intrusion protection alertAction: dropReason: BLACKLIST User-Agent known malicious user-agent string - Win.Trojan.BatlopmaClass: A Network Trojan was DetectedSource IP and Destination IP Port Mapping: 10.59.1.167:13173 ==> 10.59.1.192:80Log entry in IPS log:2017:06:03-08:12:21 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=BLACKLIST User-Agent known malicious user-agent string - Win.Trojan.Batlopma group=500 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=13173 dstport=80 sid=39361 class=A Network Trojan was Detected priority=1 generator=1 msgid=0On further analyzing the ELB logs at the time of the alert, We were able to figure out a request with 504 response code from IP address  52.76.85.66 which belongs to the organization Amazon Technologies Inc.Please find the ELB logs details below:2017-06-03T08:23:15.851743Z	preview-spendhq-xelb	52.76.85.66:33021	-	-1	-1	-1	504	0	0	0	HEAD https://preview.spendhq.com:443/login HTTP/1.1	Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.67 Safari/537.36	ECDHE-RSA-AES128-GCM-SHA256	TLSv1.2											Please let us know if you need further information regarding this.Regards,Safuvan KM",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: BLACKLIST User-Agent known malicious user-agent string - Win.Trojan.BatlopmaDetails........: https://www.snort.org/search?query=39361Time...........: 2017-06-03 08:12:21Packet dropped.: yesPriority.......: highClassification.: A Network Trojan was DetectedIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 13173Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 203 days 0 hours 27 minutesSystem Load        : 0.12System Version     : Sophos UTM 9.408-4Please refer to the manual for detailed instructions.,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,03-06-2017 13:51,10,0,SpendHQ,"This is to inform you that we received an Intrusion Prevention Alert again from Sophos and the source IP address is 10.59.1.167 which belongs to the preview-spendhq-xelb. Please find the Intrusion Prevention Log details: Name: Intrusion protection alert Action: drop Reason: BLACKLIST User-Agent known malicious user-agent string - Win.Trojan.Batlopma Class: A Network Trojan was Detected ELB Logs:2017-06-03T10:03:03.835679Z preview-spendhq-xelb 184.105.247.194:53652 10.59.1.192:443 0.000041 0.001012 0.00002 403 403 0 209 GET https://52.4.199.57:443/ HTTP/1.1 - ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2IP Details:IP Address: 184.105.247.194	Country: United States 	ISP: Hurricane Electric Inc.This Ip was reported abusive from https://www.abuseipdb.com. We have blocked the IP in NACL and let us know if you have any queries.","This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167 which belongs to the preview-spendhq-xelb. Please find the Intrusion Prevention Log details:Name: Intrusion protection alertAction: dropReason: BLACKLIST User-Agent known malicious user-agent string - Win.Trojan.BatlopmaClass: A Network Trojan was DetectedSource IP and Destination IP Port Mapping: 10.59.1.167:13173 ==> 10.59.1.192:80Log entry in IPS log:2017:06:03-08:12:21 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=BLACKLIST User-Agent known malicious user-agent string - Win.Trojan.Batlopma group=500 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=13173 dstport=80 sid=39361 class=A Network Trojan was Detected priority=1 generator=1 msgid=0On further analyzing the ELB logs at the time of the alert, We were able to figure out a request with 504 response code from IP address  52.76.85.66 which belongs to the organization Amazon Technologies Inc.Please find the ELB logs details below:2017-06-03T08:23:15.851743Z	preview-spendhq-xelb	52.76.85.66:33021	-	-1	-1	-1	504	0	0	0	HEAD https://preview.spendhq.com:443/login HTTP/1.1	Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.67 Safari/537.36	ECDHE-RSA-AES128-GCM-SHA256	TLSv1.2											Please let us know if you need further information regarding this.Regards,Safuvan KM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Krvzk,Cloud Engineer Level 1,Closed,1086058,Incident,08-12-2017 11:18,,"Hi Andrew,We can confirm on the AWS console that the SES limit in us-east-1 is now 100000 per day. Hence, We are closing this case. Please let us know if you see this issue again. Thanks###Hello Andrew,We have again received an update from AWS support team.They have increased the SES daily sending quota to 100,000 messages per day. Thank you.###Hello Andrew,We have received an update from AWS support team. They have increased the SES daily sending quota to 75000 messages per day. Thank you.###Hello Andrew,We are still waiting for an update from AWS support team regarding SES limit increase. We will let you know once we received an update from AWS support team.###Hello Andrew,We have reached out to AWS support team to increase the SES limit.We will let you know once the limit got increased.###Andrew Kim12:53 AM (6 minutes ago)to Rean, spendhq-support Hi Rean – it appears that we’ve hit the 50,000 threshold again according to AWS. We suspect this is due to the bulk email that was sent yesterday, and we don’t believe we have a way to stop the bulk emails. Can we temporarily increate the threshold to 100,000? This is high priority. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hi Andrew, Thanks for the update. We have closed the AWS Support case holding the limit increase for now.Please let us know if we see the email limit exceeds again.Closing this CMP case as confirmed by you. Thanks###No. We identified that a error catch sent about 50,000 emails yesterday to our internal team. We don’t expect to hit this limit under normal circumstances, and are working on a process to mitigate. Thanks, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hi Andrew,Just having a doubt. Are you really sending 50000 email a day?###Andrew Kim11:13 PM (15 minutes ago)to Rean, spendhq-support Thank you. Based on the SES dashboard, it appears that we have 20,536 remaining emails and new emails appear to be sending. We can close this case.###Hello Andrew,We are checking with AWS support team and will get back to you with the updates ASAP.###Andrew Kim10:41 PM (13 minutes ago)to Rean, spendhq-support Can we try and escalate? At this time, clients are not receiving emails from our web application. Thank you,###Hello Andrew,We have raised support tickets with AWS. We will get back to once we heard back from them.###Yes, please increase. Also, do we have any reporting to see what’s driving the volume? 50,000 per 24 hours seems extremely high. Thank you,Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 |akim@spendhq.com###Hello SpendHQ-Team,This is to notify you that the SES Daily sending quota has reached the limit. Please find the Sending Statistics below.Sending Quota: 	send 50000 emails per 24 hour periodQuota Used: 	100% as of 2017-12-07 16:35 UTC+5:30Max Send Rate: 	14 emails/secondLast updated: 	2017-12-07 16:35 UTC+5:30Please let us know if you want us to increase the limit to a higher value.","-------- Forwarded message ----------From: AWS-Limit <no-reply@sns.amazonaws.com>Date: Thu, Dec 7, 2017 at 4:15 PMSubject: REAN CLOUD AWS limit checker ALERT for spendhq - WARNINGTo: ms@reancloud.comBelow are resource details that cross limitsREGION       RESOURCE   LIMIT          USAGE          SERVICEus-east-1       SES               50000           57987           Dailysending quota--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-west-2.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-west-2:210278571640:AWS-Limit:1217fddf-d8e0-4042-af10-1de467aaca07&Endpoint=ms@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: REAN CLOUD AWS limit checker ALERT for spendhq - WARNING,,07-12-2017 16:22,19,0,SpendHQ,"Hi Andrew,We can confirm on the AWS console that the SES limit in us-east-1 is now 100000 per day. Hence, We are closing this case. Please let us know if you see this issue again. Thanks","Hello Andrew,We have again received an update from AWS support team.They have increased the SES daily sending quota to 100,000 messages per day. Thank you.","Hello Andrew,We have received an update from AWS support team. They have increased the SES daily sending quota to 75000 messages per day. Thank you.","Hello Andrew,We are still waiting for an update from AWS support team regarding SES limit increase. We will let you know once we received an update from AWS support team.","Hello Andrew,We have reached out to AWS support team to increase the SES limit.We will let you know once the limit got increased.","Andrew Kim12:53 AM (6 minutes ago)to Rean, spendhq-support Hi Rean – it appears that we’ve hit the 50,000 threshold again according to AWS. We suspect this is due to the bulk email that was sent yesterday, and we don’t believe we have a way to stop the bulk emails. Can we temporarily increate the threshold to 100,000? This is high priority. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Hi Andrew, Thanks for the update. We have closed the AWS Support case holding the limit increase for now.Please let us know if we see the email limit exceeds again.Closing this CMP case as confirmed by you. Thanks","No. We identified that a error catch sent about 50,000 emails yesterday to our internal team. We don’t expect to hit this limit under normal circumstances, and are working on a process to mitigate. Thanks, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Hi Andrew,Just having a doubt. Are you really sending 50000 email a day?","Andrew Kim11:13 PM (15 minutes ago)to Rean, spendhq-support Thank you. Based on the SES dashboard, it appears that we have 20,536 remaining emails and new emails appear to be sending. We can close this case.","Hello Andrew,We are checking with AWS support team and will get back to you with the updates ASAP.","Andrew Kim10:41 PM (13 minutes ago)to Rean, spendhq-support Can we try and escalate? At this time, clients are not receiving emails from our web application. Thank you,","Hello Andrew,We have raised support tickets with AWS. We will get back to once we heard back from them.","Yes, please increase. Also, do we have any reporting to see what’s driving the volume? 50,000 per 24 hours seems extremely high. Thank you,Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 |akim@spendhq.com","Hello SpendHQ-Team,This is to notify you that the SES Daily sending quota has reached the limit. Please find the Sending Statistics below.Sending Quota: 	send 50000 emails per 24 hour periodQuota Used: 	100% as of 2017-12-07 16:35 UTC+5:30Max Send Rate: 	14 emails/secondLast updated: 	2017-12-07 16:35 UTC+5:30Please let us know if you want us to increase the limit to a higher value.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VtDBk,Cloud Engineer Level 1,Closed,1098798,Incident,23-05-2018 18:54,,"Thank you guys! sorry for replying late, looks good to me so far ill email back in the future if i find anything wrong with it.###Hello Allen,We haven't heard back from you regarding the case for a while.At this time we are marking the case as closed. Please revert back to us in case of further queries.###Hello Allen,This is the gentle reminder.Please review the previous comment and let us know if you are facing any issue.###Hi Allen,We have sent you an invite to join the REAN CMP ticketing system. You will receive an email from REAN/Salesforce asking you to create a password. If not received in inbox, kindly do check in spam folder. Your username to login is aherrera@spendhq.comLet us know if you have any questions. RegardsChirodeep###Need to check the CMP access for Allen###I have informed to Chirodeep for the customer account access.Assigned this ticket to Chirodeep.###Hello Allen,As you asked us to raise the timeout to 10 minutes (600 seconds) for elb, we did so.Please check it on your end and let us know if you have any query.###Allen Herrera8:01 AM (9 minutes ago)to Rean, spendhq-support Um. What was this issue again? I can’t see the comments as I don’t have a rean support account. Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###Hello Allen,We haven't heard back from you.Please review the previous comment and let us know if you have any queries.###Hello Allen,We have changed the timeout at ELB level to 600 seconds. Please check for your end and let us know if you have any queries.###Hello Allen,We acknowledge the delivery of your request.We will check this issue and will let you know the updates.","---------- Forwarded message ----------From: Allen Herrera <aherrera@spendhq.com>Date: Mon, May 14, 2018 at 6:22 PMSubject: Timeouts on 10-59-100-240To: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Hey Rean,I’m getting 504 (GATEWAY_TIMEOUT) after approx. 60 seconds onsandbox.spendhq.com (10-59-100-240) . Can you check the server or the elb or for anything related to sandbox.spendhq.com and raise the timeout to 10minutes (600 seconds)*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- Regards,Jamelunissa MohammedHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081jamelunissa.mohammed@reancloud.com  | www.reancloud.com--  <https://www.reancloud.com/news/47lining-achieves-aws-machine-learning-competency-status/>--  <https://www.reancloud.com/news/47lining-achieves-aws-machine-learning-competency-status/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Timeouts on 10-59-100-240,,14-05-2018 18:33,200,0,SpendHQ,"Thank you guys! sorry for replying late, looks good to me so far ill email back in the future if i find anything wrong with it.","Hello Allen,We haven't heard back from you regarding the case for a while.At this time we are marking the case as closed. Please revert back to us in case of further queries.","Hello Allen,This is the gentle reminder.Please review the previous comment and let us know if you are facing any issue.","Hi Allen,We have sent you an invite to join the REAN CMP ticketing system. You will receive an email from REAN/Salesforce asking you to create a password. If not received in inbox, kindly do check in spam folder. Your username to login is aherrera@spendhq.comLet us know if you have any questions. RegardsChirodeep",Need to check the CMP access for Allen,I have informed to Chirodeep for the customer account access.Assigned this ticket to Chirodeep.,"Hello Allen,As you asked us to raise the timeout to 10 minutes (600 seconds) for elb, we did so.Please check it on your end and let us know if you have any query.","Allen Herrera8:01 AM (9 minutes ago)to Rean, spendhq-support Um. What was this issue again? I can’t see the comments as I don’t have a rean support account. Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com","Hello Allen,We haven't heard back from you.Please review the previous comment and let us know if you have any queries.","Hello Allen,We have changed the timeout at ELB level to 600 seconds. Please check for your end and let us know if you have any queries.","Hello Allen,We acknowledge the delivery of your request.We will check this issue and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001aNYjc,Cloud Engineer Level 1,Closed,1102766,Incident,15-08-2018 09:13,,"We are tracking this issue on another ticket 01102775 hence we are closing this case.###For Instance Id:  i-093eff6fae479397c ############ CPU utilization ############ top - 19:19:22 up 134 days, 19:53,  0 users,  load average: 0.07, 0.18, 1.64Tasks: 311 total,   2 running, 309 sleeping,   0 stopped,   0 zombie%Cpu(s):  1.0 us,  0.2 sy,  0.0 ni, 98.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total,  6782168 free, 24083024+used,  3962628 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  3536900 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND14443 memsql    20   0  0.127t 0.111t  13424 S  33.3 47.4  14847:38 memsqld96540 memsql    20   0 12.281g 335252   2612 S  20.0  0.1  21875:15 memsql-ops61683 root      20   0  157876   2248   1472 R   6.7  0.0   0:00.01 top    1 root      20   0  195696   8060   3292 S   0.0  0.0   8:36.68 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:01.51 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:13.79 ksoftirqd+    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.36 migration+    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0  59:02.88 rcu_sched   10 root      rt   0       0      0      0 S   0.0  0.0   0:57.22 watchdog/0   11 root      rt   0       0      0      0 S   0.0  0.0   0:51.08 watchdog/1   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.41 migration+   13 root      20   0       0      0      0 S   0.0  0.0   0:03.68 ksoftirqd+   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1+   16 root      rt   0       0      0      0 S   0.0  0.0   0:50.68 watchdog/2   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.35 migration+   18 root      20   0       0      0      0 S   0.0  0.0   0:02.83 ksoftirqd+   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2+   21 root      rt   0       0      0      0 S   0.0  0.0   0:51.62 watchdog/3   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.18 migration+   23 root      20   0       0      0      0 S   0.0  0.0   0:01.57 ksoftirqd+   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/3+   26 root      rt   0       0      0      0 S   0.0  0.0   0:50.16 watchdog/4   27 root      rt   0       0      0      0 S   0.0  0.0   0:00.30 migration+   28 root      20   0       0      0 ################# Connection Summary ################# 1) netstat | wc -l 10002) netstat | grep TIME_WAIT | wc -l 1 3) netstat | grep ESTABLISHED | wc -l 868###Hello Team,We have analyzed the issue and below are the details:Instance Id: i-0382b753fdc5a21bd ############CPU utilization############top - 19:19:22 up 134 days, 22:18,  0 users,  load average: 0.26, 0.30, 1.72Tasks: 311 total,   1 running, 310 sleeping,   0 stopped,   0 zombie%Cpu(s):  0.6 us,  0.2 sy,  0.0 ni, 99.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total,  4394044 free, 24219427+used,  4986708 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  1675692 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND96752 memsql    20   0 12.289g 332456   2604 S  13.3  0.1  21764:06 memsql-ops34376 root      20   0  157876   2236   1472 R   6.7  0.0   0:00.01 top    1 root      20   0  195564   8568   3804 S   0.0  0.0   6:05.90 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:01.48 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:15.99 ksoftirqd+    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.30 migration+    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0  56:51.55 rcu_sched   10 root      rt   0       0      0      0 S   0.0  0.0   0:56.30 watchdog/0   11 root      rt   0       0      0      0 S   0.0  0.0   0:50.35 watchdog/1   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.14 migration+   13 root      20   0       0      0      0 S   0.0  0.0   0:04.84 ksoftirqd+   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1+   16 root      rt   0       0      0      0 S   0.0  0.0   0:49.66 watchdog/2   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.32 migration+   18 root      20   0       0      0      0 S   0.0  0.0   0:02.18 ksoftirqd+   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2+   21 root      rt   0       0      0      0 S   0.0  0.0   0:50.66 watchdog/3   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.06 migration+   23 root      20   0       0      0      0 S   0.0  0.0   0:01.43 ksoftirqd+   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/3+   26 root      rt   0       0      0      0 S   0.0  0.0   0:49.45 watchdog/4   27 root      rt   0       0      0      0 S   0.0  0.0   0:00.29 migration+   28 root      20   0       0      0      0 S   0.0  0.0   0:02.38 ksoftirqd+   30 root       0 -20       0      0#################Connection Summary#################1) netstat | wc -l9992) netstat | grep TIME_WAIT | wc -l03) netstat | grep ESTABLISHED | wc -l868###Hello Team,We have received an alert regarding High Memory Utilization Alert on host - spendhq-memsql-server2-2018-04-01 - 10.59.100.171 which has crossed the threshold and reached to the value of 95.93%. we are analyzing the issue and will back to you with the update. Resource Details: Instance ID: i-0382b753fdc5a21bd IP: 10-59-100-171Region: us-east-1###Hello Team,We have received an alert regarding  High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 which has crossed the threshold and reached to the value of 95.58%. we are analyzing the issue and will back to you with the update.Resource Details:Instance ID: i-093eff6fae479397cIP: 10-59-100-230Region: us-east-1","[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host -spendhq-memsql-server3-2018-04-01 - 10.59.100.230 -Detected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1534272587000&group=host%3Ai-093eff6fae479397c&from_ts=1534265387000>avg(last_30m):(avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 95The monitor was last triggered at Tue Aug 14 2018 18:49:57 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-093eff6fae479397c>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-093eff6fae479397c<https://app.datadoghq.com/infrastructure?filter=i-093eff6fae479397c>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1534272717000&tags=host%3Ai-093eff6fae479397c&from_ts=1534271697000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4530011639389394619>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 -,,15-08-2018 00:31,9,0,SpendHQ,We are tracking this issue on another ticket 01102775 hence we are closing this case.,For Instance Id:  i-093eff6fae479397c,,,,CPU utilization,,,,"top - 19:19:22 up 134 days, 19:53,  0 users,  load average: 0.07, 0.18, 1.64Tasks: 311 total,   2 running, 309 sleeping,   0 stopped,   0 zombie%Cpu(s):  1.0 us,  0.2 sy,  0.0 ni, 98.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total,  6782168 free, 24083024+used,  3962628 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  3536900 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND14443 memsql    20   0  0.127t 0.111t  13424 S  33.3 47.4  14847:38 memsqld96540 memsql    20   0 12.281g 335252   2612 S  20.0  0.1  21875:15 memsql-ops61683 root      20   0  157876   2248   1472 R   6.7  0.0   0:00.01 top    1 root      20   0  195696   8060   3292 S   0.0  0.0   8:36.68 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:01.51 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:13.79 ksoftirqd+    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.36 migration+    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0  59:02.88 rcu_sched   10 root      rt   0       0      0      0 S   0.0  0.0   0:57.22 watchdog/0   11 root      rt   0       0      0      0 S   0.0  0.0   0:51.08 watchdog/1   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.41 migration+   13 root      20   0       0      0      0 S   0.0  0.0   0:03.68 ksoftirqd+   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1+   16 root      rt   0       0      0      0 S   0.0  0.0   0:50.68 watchdog/2   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.35 migration+   18 root      20   0       0      0      0 S   0.0  0.0   0:02.83 ksoftirqd+   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2+   21 root      rt   0       0      0      0 S   0.0  0.0   0:51.62 watchdog/3   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.18 migration+   23 root      20   0       0      0      0 S   0.0  0.0   0:01.57 ksoftirqd+   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/3+   26 root      rt   0       0      0      0 S   0.0  0.0   0:50.16 watchdog/4   27 root      rt   0       0      0      0 S   0.0  0.0   0:00.30 migration+   28 root      20   0       0      0",,,,,## Connection Summary,,,,,## 1) netstat | wc -l 10002) netstat | grep TIME_WAIT | wc -l 1 3) netstat | grep ESTABLISHED | wc -l 868,"Hello Team,We have analyzed the issue and below are the details:Instance Id: i-0382b753fdc5a21bd",,,,CPU utilization,,,,"top - 19:19:22 up 134 days, 22:18,  0 users,  load average: 0.26, 0.30, 1.72Tasks: 311 total,   1 running, 310 sleeping,   0 stopped,   0 zombie%Cpu(s):  0.6 us,  0.2 sy,  0.0 ni, 99.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total,  4394044 free, 24219427+used,  4986708 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  1675692 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND96752 memsql    20   0 12.289g 332456   2604 S  13.3  0.1  21764:06 memsql-ops34376 root      20   0  157876   2236   1472 R   6.7  0.0   0:00.01 top    1 root      20   0  195564   8568   3804 S   0.0  0.0   6:05.90 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:01.48 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:15.99 ksoftirqd+    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.30 migration+    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0  56:51.55 rcu_sched   10 root      rt   0       0      0      0 S   0.0  0.0   0:56.30 watchdog/0   11 root      rt   0       0      0      0 S   0.0  0.0   0:50.35 watchdog/1   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.14 migration+   13 root      20   0       0      0      0 S   0.0  0.0   0:04.84 ksoftirqd+   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1+   16 root      rt   0       0      0      0 S   0.0  0.0   0:49.66 watchdog/2   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.32 migration+   18 root      20   0       0      0      0 S   0.0  0.0   0:02.18 ksoftirqd+   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2+   21 root      rt   0       0      0      0 S   0.0  0.0   0:50.66 watchdog/3   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.06 migration+   23 root      20   0       0      0      0 S   0.0  0.0   0:01.43 ksoftirqd+   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/3+   26 root      rt   0       0      0      0 S   0.0  0.0   0:49.45 watchdog/4   27 root      rt   0       0      0      0 S   0.0  0.0   0:00.29 migration+   28 root      20   0       0      0      0 S   0.0  0.0   0:02.38 ksoftirqd+   30 root       0 -20       0      0",,,,,##Connection Summary,,,,,##1) netstat | wc -l9992) netstat | grep TIME_WAIT | wc -l03) netstat | grep ESTABLISHED | wc -l868,"Hello Team,We have received an alert regarding High Memory Utilization Alert on host - spendhq-memsql-server2-2018-04-01 - 10.59.100.171 which has crossed the threshold and reached to the value of 95.93%. we are analyzing the issue and will back to you with the update. Resource Details: Instance ID: i-0382b753fdc5a21bd IP: 10-59-100-171Region: us-east-1","Hello Team,We have received an alert regarding  High Memory Utilization Alert on host - spendhq-memsql-server3-2018-04-01 - 10.59.100.230 which has crossed the threshold and reached to the value of 95.58%. we are analyzing the issue and will back to you with the update.Resource Details:Instance ID: i-093eff6fae479397cIP: 10-59-100-230Region: us-east-1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5002I00001hQUwO,Cloud Engineer Level 1,Closed,1110113,Incident,02-01-2019 07:46,,"Hello Team, This is to inform we again received a site down alert for URL: https://preview.spendhq.com/login We are actively checking on this issue and we are tracking this issue on the case 01110088. Closing this case will get back to you with an update.","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Wed, Jan 2, 2019 at 7:33 AMSubject: Detected Error on SpendHQ PreviewTo: <ms@reancloud.com>Tue, 01 Jan 2019 21:03:02 -0500Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): New Jersey US, London UK, Frankfurt-B DE, Dallas-C US-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Preview,,02-01-2019 07:36,0,0,SpendHQ,"Hello Team, This is to inform we again received a site down alert for URL: https://preview.spendhq.com/login We are actively checking on this issue and we are tracking this issue on the case 01110088. Closing this case will get back to you with an update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016o0xQ,Cloud Engineer Level 1,Closed,1042179,Incident,15-01-2017 09:51,,"We are following this under the ticket 01041864###Hi Andrew,We have analyzed the logs and here are the details.This kind error messages normally popup in iSCSI client machines connected to a server with which there are multiple clients already connected to it and the iqn names are same. In our case, we have verified the iqn names and found that for PROD-SPHQ-DB-SERVER03 and PROD-SPHQ-DB-SERVER04, the iqn names are same. So we recommend changing the iqn name as per the naming convention document shared last week. Please refer the case 01041864 for details. Please find the below list of iqn names across all servers in SpendHQ environment.Servers having same iqn:PROD-SPHQ-DB-SERVER03        10.59.10.148         iqn.1994-05.com.redhat:64d02cf6d2cePROD-SPHQ-DB-SERVER04        10.59.10.91	        iqn.1994-05.com.redhat:64d02cf6d2ceTEST-SPHQ-WEB-SERVER01      10.59.100.125       iqn.1994-05.com.redhat:a7565668c72aPROD-SPHQ-WEB-SERVER02    10.59.100.118       iqn.1994-05.com.redhat:a7565668c72aFixed Servers:PROD-SPHQ-WEB-SERVER04    10.59.100.104       iqn.1994-05.com.redhat:201701100104PROD-SPHQ-WEB-SERVER03    10.59.100.94        iqn.1994-05.com.redhat:201701110094Other Servers:PROD-SPHQ-DB-SERVER02        10.59.10.12          iqn.1994-05.com.redhat:573c3f4764bPROD-SPHQ-DB-SERVER05        10.59.10.135         iqn.1994-05.com.redhat:64d02cf7e3dfPlease let us know if we can go ahead and change the iqn names for the remaining servers so that to avoid this kind of iqn errors. Please feel free to ask in case of any queries.We are waiting for your response to resolve this case.Thanks,Safuvan KM###Also showing the same error on:10.59.10.135 Andrew Kim | Development Manager | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hi Andrew,We will look into this and will get back to you ASAP.","Hello, we’re seeing iscsi Jan 12 22:14:27 ip-10-59-10-148 iscsid: Kernel reported iSCSI connection 2:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Jan 12 22:14:27 ip-10-59-10-148 iscsid: Kernel reported iSCSI connection 4:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Jan 12 22:14:28 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Jan 12 22:14:30 ip-10-59-10-148 iscsid: connection4:0 is operational after recovery (1 attempts)Jan 12 22:14:30 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Jan 12 22:14:30 ip-10-59-10-148 iscsid: connection2:0 is operational after recovery (1 attempts)Jan 12 22:14:31 ip-10-59-10-148 kernel: connection4:0: detected conn error (1020)Jan 12 22:14:31 ip-10-59-10-148 kernel: connection2:0: detected conn error (1020)Jan 12 22:14:32 ip-10-59-10-148 iscsid: Kernel reported iSCSI connection 4:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Jan 12 22:14:32 ip-10-59-10-148 iscsid: Kernel reported iSCSI connection 2:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Jan 12 22:14:32 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04) Andrew Kim | Development Manager | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com",iscsid errors on 10.59.10.91,,13-01-2017 03:58,54,0,SpendHQ,We are following this under the ticket 01041864,"Hi Andrew,We have analyzed the logs and here are the details.This kind error messages normally popup in iSCSI client machines connected to a server with which there are multiple clients already connected to it and the iqn names are same. In our case, we have verified the iqn names and found that for PROD-SPHQ-DB-SERVER03 and PROD-SPHQ-DB-SERVER04, the iqn names are same. So we recommend changing the iqn name as per the naming convention document shared last week. Please refer the case 01041864 for details. Please find the below list of iqn names across all servers in SpendHQ environment.Servers having same iqn:PROD-SPHQ-DB-SERVER03        10.59.10.148         iqn.1994-05.com.redhat:64d02cf6d2cePROD-SPHQ-DB-SERVER04        10.59.10.91	        iqn.1994-05.com.redhat:64d02cf6d2ceTEST-SPHQ-WEB-SERVER01      10.59.100.125       iqn.1994-05.com.redhat:a7565668c72aPROD-SPHQ-WEB-SERVER02    10.59.100.118       iqn.1994-05.com.redhat:a7565668c72aFixed Servers:PROD-SPHQ-WEB-SERVER04    10.59.100.104       iqn.1994-05.com.redhat:201701100104PROD-SPHQ-WEB-SERVER03    10.59.100.94        iqn.1994-05.com.redhat:201701110094Other Servers:PROD-SPHQ-DB-SERVER02        10.59.10.12          iqn.1994-05.com.redhat:573c3f4764bPROD-SPHQ-DB-SERVER05        10.59.10.135         iqn.1994-05.com.redhat:64d02cf7e3dfPlease let us know if we can go ahead and change the iqn names for the remaining servers so that to avoid this kind of iqn errors. Please feel free to ask in case of any queries.We are waiting for your response to resolve this case.Thanks,Safuvan KM",Also showing the same error on:10.59.10.135 Andrew Kim | Development Manager | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com,"Hi Andrew,We will look into this and will get back to you ASAP.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C3S7c,Cloud Engineer Level 1,Closed,1055176,Incident,21-05-2017 06:43,,We are following this under 01054804,"Sat, 20 May 2017 20:41:47 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Sydney-C AU, California US, Frankfurt DE, London UK-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,21-05-2017 06:11,1,0,SpendHQ,We are following this under 01054804,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015YTk3,Cloud Engineer Level 1,Closed,1040746,Incident,23-12-2016 02:18,,"Closing this ticket, The action needs to be performed on 28th December 2016 at 13:00 EST.We will create a change ticket for this request.","Rean Team,We will need your assistance on Wednesday 28th December 2016, to mount a drive onto the DB4 server at 1300 Hours EST. Please advise if you can assist at this time.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Database Copy and Mount,,23-12-2016 02:07,0,0,SpendHQ,"Closing this ticket, The action needs to be performed on 28th December 2016 at 13:00 EST.We will create a change ticket for this request.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKqo,Cloud Engineer Level 1,Closed,1042235,Incident,,,,"Can you image the Production Machine – Spend4. We just want to create a clone.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Friday, January 13, 2017 10:06 PMTo: Matthew Watts <mwatts@spendhq.com>; Mrigank Saxena <mrigank.saxena@reancloud.com>Cc: REAN Support <support@reancloud.com>Subject: Re: MaintenanceHI Matt -Sorry - didn't know which vol to image - and if you want to clone it ...Can you let me know - I am standing byChris VeilletteCTO[1450833261212_7186d8e7bdbb48853119db07d964f770.jpg]www.Andromeda3.com<http://www.Andromeda3.com>cveillette@andromeda3.com<mailto:cveillette@andromeda3.com>Mobile: 703.447.4124Office:   571.781.0428________________________________From: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Sent: Friday, January 13, 2017 9:52 PMTo: Mrigank Saxena; Chris VeilletteCc: REAN SupportSubject: RE: MaintenanceChris,Did you manage to image the machine?Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]Sent: Friday, January 13, 2017 9:37 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,As mentioned earlier, Andromeda team is going to clone the volume before we proceed with the patching of the instance.Please let us know if that is done so that we can proceed with the security patching.On Sat, Jan 14, 2017 at 8:00 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Please update the 10.59.10.12 machine first and advise when complete.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com<mailto:mrigank.saxena@reancloud.com>]Sent: Friday, January 13, 2017 9:24 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,We are ready for the maintenance. Please let us know once you start making the changes.On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Rean Team are you ready to commence the updates as planned on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Maintenance,,14-01-2017 08:38,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001T9mkV,Cloud Engineer Level 1,Closed,1093694,Incident,20-03-2018 06:02,,"Hello Team,This is to notify that an alert regarding High memory Utilization got resolved, We have shared the screenshot of the memory utilization at the time of alert in the attachments.At this time we are marking this case as resolved and Please revert back to us for any further queries.###Hello Team,This is to notify that we have received multiple alerts regarding the High Memory utilization on PRD-WW1_122 it exceeded the threshold value from 85 to 87.7. Resource Details:-Instance Name:- PRD-WW1_122Instance ID:-i-0ace70ce06368e4a7Instance Type:-c4.2xlargePrivate IP:-10.59.100.122We are analyzing the issue, Meanwhile Please let us know if there is any activity is performing on your end.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Tue, Mar 20, 2018 at 5:32 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Memory UtilizationAlert on host - prd-ww1_122 - 10.59.100.122 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww1_122- 10.59.100.122 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1521504107000&group=host%3Ai-0ace70ce06368e4a7&from_ts=1521503807000>avg(last_5m):( avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 85The monitor was last triggered at Tue Mar 20 2018 00:01:57 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-0ace70ce06368e4a7>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?hostname=i-0ace70ce06368e4a7>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1521504117000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1521503217000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4315792076681476026>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww1_122 - 10.59.100.122 - web,,20-03-2018 05:33,0,0,SpendHQ,"Hello Team,This is to notify that an alert regarding High memory Utilization got resolved, We have shared the screenshot of the memory utilization at the time of alert in the attachments.At this time we are marking this case as resolved and Please revert back to us for any further queries.","Hello Team,This is to notify that we have received multiple alerts regarding the High Memory utilization on PRD-WW1_122 it exceeded the threshold value from 85 to 87.7. Resource Details:-Instance Name:- PRD-WW1_122Instance ID:-i-0ace70ce06368e4a7Instance Type:-c4.2xlargePrivate IP:-10.59.100.122We are analyzing the issue, Meanwhile Please let us know if there is any activity is performing on your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EVV1d,Cloud Engineer Level 1,Closed,1068280,Incident,,,,"[Triggered] [SpendHQ] - High Network IN  on host - prod-sphq-db-server05 - 10.59.10.135 - db Status  High Network IN on the instance. Please check the list open TCP Connections    @support@reancloud.comaws.ec2.network_in over host:10.59.10.135,monitoring:on was > 2200000000.0 at all times during the last 5m.Metric value: 2556748288.0This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024210?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2024210/edit · Event URL: https://app.datadoghq.com/event/event?id=3958569621515710350 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network IN on host - prod-sphq-db-server05 - 10.59.10.135 - db Status,,16-07-2017 19:03,3,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001LtyoY,Cloud Engineer Level 1,Closed,1086326,Incident,13-12-2017 07:58,,"Hello Team,This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.18.The alert got resolved and returned to normal state.###Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.18. The MySQL process was consuming the usage. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1 We are analyzing more on this and get back to you with details.","[Triggered] [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over datadog_monitor:on,host:i-03ccfddd9f02cacb9 was > 3.0 on average during the last 5m.Metric value: 3.061This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=4174494347828472664 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db,,12-12-2017 18:05,14,0,SpendHQ,"Hello Team,This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.18.The alert got resolved and returned to normal state.","Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.18. The MySQL process was consuming the usage. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1 We are analyzing more on this and get back to you with details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001WYIof,Cloud Engineer Level 2,Closed,1099514,Incident,04-06-2018 14:43,,"Thenmozhy D <thenmozhy.d@reancloud.com>2:42 PM (4 minutes ago)to Robert, REAN, Matthew, Daniel, Praveen Hello Robert,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hi Robert, We haven't heard back from you.We have re-mounted the volume on /mnt/memsql_storage in the server 10.59.100.191 as requested. Please verify from your side and let us know if you have any further queries.###Hi Robert, We have re-mounted the volume on /mnt/memsql_storage in the server 10.59.100.191 as requested. Please verify from your side and let us know if you have any further queries.Thank you.###Hi Robert,We have re-mounted the volume on /mnt/memsql_storage in the server 10.59.100.191. Please verify from your side. Thanks !Regards,Rohit Puri###Hello Robert,Thanks for the update.We will remount the ISCSI volume on /mnt/memsql_storage in the server 10.59.100.191 and will let you know the update.###Robert Little7:17 PM (4 minutes ago)to Rohit, REAN, Matthew, Daniel, Praveen Hey Rohit,I believe I have stopped the process now, but If you still see anything running it is fine to kill those processes.###Hi Robert,This is a gentle reminder.We have re-mounted the ISCSI volumes on /mnt/memsql_storage in the servers 10.59.100.230 and 10.59.100.171. But we have not done in the server 10.59.100.191 as some process are using the /mnt/memsql_storage folder. Here are details for the same below: bash 17613 rlittle cwd DIR 8,16 4096 4194305 /mnt/memsql_storage/reports sudo 17956 root cwd DIR 8,16 4096 4194305 /mnt/memsql_storage/reports bash 17961 root cwd DIR 8,16 4096 4194305 /mnt/memsql_storage/reports bash 60342 root cwd DIR 8,16 4096 2 /mnt/memsql_storage Please give us the approval to stop these process or please stop the process from your end so that we re-mount the volume again in the server 10.59.100.191. Regards, Rohit Puri###Hi Robert,We have re-mounted the ISCSI volumes on /mnt/memsql_storage in the servers 10.59.100.230 and 10.59.100.171. But we have not done in the server 10.59.100.191 as some process are using the /mnt/memsql_storage folder. Here are details for the same below:bash      17613       rlittle  cwd       DIR               8,16      4096    4194305 /mnt/memsql_storage/reportssudo      17956          root  cwd       DIR               8,16      4096    4194305 /mnt/memsql_storage/reportsbash      17961          root  cwd       DIR               8,16      4096    4194305 /mnt/memsql_storage/reportsbash      60342          root  cwd       DIR               8,16      4096          2 /mnt/memsql_storagePlease give us the approval to stop these process or please stop the process from your end so that we re-mount the volume again in the server 10.59.100.191.Regards,Rohit Puri###Hello Rob, We will get it fixed. For now, we don’t have any such kind of solution to automate this. We will come up with a strategy to address this in future. Regards,-Praveen","---------- Forwarded message ----------From: Robert Little <RLittle@spendhq.com>Date: Fri, May 25, 2018 at 7:06 PMSubject: Read Only MountTo: REAN Managed Services <ms@reancloud.com>Cc: Matthew Watts <mwatts@spendhq.com>, Daniel Mackay <dmackay@spendhq.com>Rean,Our memsql cluster’s file system has been put in read only mode. I am surethis has something to do with network maintenance. Please make the filesystem writable for the following servers. Please try to do this withoutrestarting any machines. Also, as this seems to happen a lot, is there anyway we can have you do this automatically in the future so we do not haveto request it?10.59.100.19110.59.100.23010.59.100.171Thanks*Robert Little *| Spend Solutions DBA | *Spend**HQ®*O: 770-628-0898 | *rlittle@spendhq.com <rlittle@spendhq.com>**A SaaS Spend Visibility solution from Insight Sourcing Group**www.spendhq.com <http://www.spendhq.com/>* | *www.insightsourcing.com<http://www.insightsourcing.com>*-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <http://go.reancloud.com/secure-your-cloud>--  <http://go.reancloud.com/secure-your-cloud>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Read Only Mount,,25-05-2018 20:48,234,0,SpendHQ,"Thenmozhy D <thenmozhy.d@reancloud.com>2:42 PM (4 minutes ago)to Robert, REAN, Matthew, Daniel, Praveen Hello Robert,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hi Robert, We haven't heard back from you.We have re-mounted the volume on /mnt/memsql_storage in the server 10.59.100.191 as requested. Please verify from your side and let us know if you have any further queries.","Hi Robert, We have re-mounted the volume on /mnt/memsql_storage in the server 10.59.100.191 as requested. Please verify from your side and let us know if you have any further queries.Thank you.","Hi Robert,We have re-mounted the volume on /mnt/memsql_storage in the server 10.59.100.191. Please verify from your side. Thanks !Regards,Rohit Puri","Hello Robert,Thanks for the update.We will remount the ISCSI volume on /mnt/memsql_storage in the server 10.59.100.191 and will let you know the update.","Robert Little7:17 PM (4 minutes ago)to Rohit, REAN, Matthew, Daniel, Praveen Hey Rohit,I believe I have stopped the process now, but If you still see anything running it is fine to kill those processes.","Hi Robert,This is a gentle reminder.We have re-mounted the ISCSI volumes on /mnt/memsql_storage in the servers 10.59.100.230 and 10.59.100.171. But we have not done in the server 10.59.100.191 as some process are using the /mnt/memsql_storage folder. Here are details for the same below: bash 17613 rlittle cwd DIR 8,16 4096 4194305 /mnt/memsql_storage/reports sudo 17956 root cwd DIR 8,16 4096 4194305 /mnt/memsql_storage/reports bash 17961 root cwd DIR 8,16 4096 4194305 /mnt/memsql_storage/reports bash 60342 root cwd DIR 8,16 4096 2 /mnt/memsql_storage Please give us the approval to stop these process or please stop the process from your end so that we re-mount the volume again in the server 10.59.100.191. Regards, Rohit Puri","Hi Robert,We have re-mounted the ISCSI volumes on /mnt/memsql_storage in the servers 10.59.100.230 and 10.59.100.171. But we have not done in the server 10.59.100.191 as some process are using the /mnt/memsql_storage folder. Here are details for the same below:bash      17613       rlittle  cwd       DIR               8,16      4096    4194305 /mnt/memsql_storage/reportssudo      17956          root  cwd       DIR               8,16      4096    4194305 /mnt/memsql_storage/reportsbash      17961          root  cwd       DIR               8,16      4096    4194305 /mnt/memsql_storage/reportsbash      60342          root  cwd       DIR               8,16      4096          2 /mnt/memsql_storagePlease give us the approval to stop these process or please stop the process from your end so that we re-mount the volume again in the server 10.59.100.191.Regards,Rohit Puri","Hello Rob, We will get it fixed. For now, we don’t have any such kind of solution to automate this. We will come up with a strategy to address this in future. Regards,-Praveen",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hT5RA,Cloud Engineer Level 1,Closed,1110502,Incident,09-01-2019 23:39,,"Hello Team, We are continuosly receiving site down alert for this url https://www.wormly.com/edithost/hostid/50743  with the same error Operation timed out from our anaylysis its due to latency issue we are tracking this case on this ticketCase ID	I-01110144Based on the recommendations on this ticket please review the recommendations and get back to us.We therefore closing this case to be tracked on this Case ID	I-01110144","Wed, 09 Jan 2019 12:41:21 -0500Detected Error on SpendHQ SecureEstimated Downtime: 2 minutes 1 secondhttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 60006 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Frankfurt-B DE, California US, Frankfurt DE,Atlanta-B US-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,09-01-2019 23:20,0,0,SpendHQ,"Hello Team, We are continuosly receiving site down alert for this url https://www.wormly.com/edithost/hostid/50743  with the same error Operation timed out from our anaylysis its due to latency issue we are tracking this case on this ticketCase ID	I-01110144Based on the recommendations on this ticket please review the recommendations and get back to us.We therefore closing this case to be tracked on this Case ID	I-01110144",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001i6f9Y,Cloud Engineer Level 1,Closed,1110759,Incident,16-01-2019 03:31,,"Hi Dusty,Thank you for the confirmation. On that note we are marking this case as closed.Please feel  free to keep in touch for continued support.Regards.###[Via Email]Looks like I have access to the server.  Thank you.Dusty Fowler | Developer | SpendHQ®###Hello Dusty,We have completed this request and shared the credentials with you separately.Please try accessing the server 10.59.10.210 and let us know if you are facing any issues.Thanks.###Hello Dusty,We acknowledge your request we will work on it and get back to you with more information","I need to gain ssh access to 10.59.10.210 and also be given sudo ability on this server.  My keys can be copied from 10.59.10.135 if they are not already present.  Thanks!Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com<mailto:dfowler@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Server access,,15-01-2019 19:44,8,0,SpendHQ,"Hi Dusty,Thank you for the confirmation. On that note we are marking this case as closed.Please feel  free to keep in touch for continued support.Regards.",[Via Email]Looks like I have access to the server.  Thank you.Dusty Fowler | Developer | SpendHQ®,"Hello Dusty,We have completed this request and shared the credentials with you separately.Please try accessing the server 10.59.10.210 and let us know if you are facing any issues.Thanks.","Hello Dusty,We acknowledge your request we will work on it and get back to you with more information",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C30Dc,Cloud Engineer Level 1,Closed,1054881,Incident,19-05-2017 17:22,,"Hello SpendHq-Team,On further analyzing the Preview ELB logs at the time of the alert, We are able to find the IP's 110.90.95.163 and 175.197.37.159.The IP 110.90.95.163 belongs to Fujian region in China and the IP 175.197.37.159 belongs to Gyeonggi-do region in the Republic of Korea.  These both IP's was trying to execute the SERVER-APACHE Apache Struts remote code.As a fix, we have blocked the IP's at NACL level. Please find the logs details below,Intrusion Prevention Logs:2017:05:19-09:16:03 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=8690 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:19-09:22:04 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.111 dstip=10.59.1.192 proto=6 srcport=27301 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0 ELB Logs:2017-05-19T10:36:43.140542Z,preview-spendhq-xelb,175.197.37.159,64101,10.59.1.192,8080,0.000033,0.001515,0.00002,403,403,0,221,GET http://52.4.199.57:8080/manager/html HTTP/1.1,Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0),-,-2017-05-19T10:43:12.514152Z,preview-spendhq-xelb,110.90.95.163,1879,10.59.1.192,8080,0.000035,0.001743,0.00002,403,403,0,209,POST http://52.4.199.57:8080/ HTTP/1.1,Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.101 Safari/537.36,-,-Let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167 and 10.59.5.111 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",1.Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-19 09:16:03Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 8690Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)2.Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-19 09:22:04Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.111Source port: 27301Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 188 days 1 hour 36 minutesSystem Load        : 0.11,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,19-05-2017 14:47,3,0,SpendHQ,"Hello SpendHq-Team,On further analyzing the Preview ELB logs at the time of the alert, We are able to find the IP's 110.90.95.163 and 175.197.37.159.The IP 110.90.95.163 belongs to Fujian region in China and the IP 175.197.37.159 belongs to Gyeonggi-do region in the Republic of Korea.  These both IP's was trying to execute the SERVER-APACHE Apache Struts remote code.As a fix, we have blocked the IP's at NACL level. Please find the logs details below,Intrusion Prevention Logs:2017:05:19-09:16:03 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=8690 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:19-09:22:04 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.111 dstip=10.59.1.192 proto=6 srcport=27301 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0 ELB Logs:2017-05-19T10:36:43.140542Z,preview-spendhq-xelb,175.197.37.159,64101,10.59.1.192,8080,0.000033,0.001515,0.00002,403,403,0,221,GET http://52.4.199.57:8080/manager/html HTTP/1.1,Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0),-,-2017-05-19T10:43:12.514152Z,preview-spendhq-xelb,110.90.95.163,1879,10.59.1.192,8080,0.000035,0.001743,0.00002,403,403,0,209,POST http://52.4.199.57:8080/ HTTP/1.1,Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.101 Safari/537.36,-,-Let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167 and 10.59.5.111 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ETsGG,Cloud Engineer Level 1,Closed,1067484,Incident,12-07-2017 02:44,,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Matthew updated,We have solved this issue. Thank you for the help.###Hello Team,On further analysis, we found that the sum of request was high at the time of the alert. There was a slight spike in the latency also. While checking the instance metrics we could see that the there was spike in the CPU utilization from the normal rate. The Network In was also hig for the instance at the time of the alert. Please review the attachment for details.While analyzing the tomcat Catalina logs we found the below errors.11-Jul-2017 18:57:38.035 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib]11-Jul-2017 18:57:38.144 SEVERE [main] org.apache.coyote.AbstractProtocol.init Failed to initialize end point associated with ProtocolHandler [http-nio-80] java.net.SocketException: Permission denied        at sun.nio.ch.Net.bind0(Native Method)        at sun.nio.ch.Net.bind(Net.java:433)        at sun.nio.ch.Net.bind(Net.java:425)        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)        at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:210)        at org.apache.tomcat.util.net.AbstractEndpoint.init(AbstractEndpoint.java:970)        at org.apache.tomcat.util.net.AbstractJsseEndpoint.init(AbstractJsseEndpoint.java:244)        at org.apache.coyote.AbstractProtocol.init(AbstractProtocol.java:613)        at org.apache.coyote.http11.AbstractHttp11Protocol.init(AbstractHttp11Protocol.java:66)        at org.apache.catalina.connector.Connector.initInternal(Connector.java:997)        at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:107)        at org.apache.catalina.core.StandardService.initInternal(StandardService.java:549)        at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:107)        at org.apache.catalina.core.StandardServer.initInternal(StandardServer.java:875)        at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:107)        at org.apache.catalina.startup.Catalina.load(Catalina.java:607)        at org.apache.catalina.startup.Catalina.load(Catalina.java:630)        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:498)        at org.apache.catalina.startup.Bootstrap.load(Bootstrap.java:311)        at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:494)Tomcat not able to find the library that allows optimal performance in a production environment. There is a Permission Denied while trying to initialize endpoint. Apache Portable Runtime (APR) is a highly portable library which is used for optimal performance. The initialization failed as the APR library was unable to find inturn caused the port bind to fail which caused this site down issue.Please let us know if you have performed any activity and reach out to us if you have any queries.###Hello Team,This is to notify you that the alert regarding site down for the URL http://l.spendhq.com got resolved. The site is well up and running now. We are further looking into the issue and will update you with the details.###Hello Team,This is to inform you that we have received a site down alert for the URL http://l.spendhq.com.We are looking into it and will update you with the progress.","Tue, 11 Jul 2017 14:58:27 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 200Sensor parameters:url: http://l.spendhq.comexpect: 200wantedstring: unwantedstring: Reported by node: New Jersey USConfirmed by node(s): Atlanta-B US, London UK, Sydney-C AU, California US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,12-07-2017 00:28,2,0,SpendHQ,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Matthew updated,We have solved this issue. Thank you for the help.","Hello Team,On further analysis, we found that the sum of request was high at the time of the alert. There was a slight spike in the latency also. While checking the instance metrics we could see that the there was spike in the CPU utilization from the normal rate. The Network In was also hig for the instance at the time of the alert. Please review the attachment for details.While analyzing the tomcat Catalina logs we found the below errors.11-Jul-2017 18:57:38.035 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: [/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib]11-Jul-2017 18:57:38.144 SEVERE [main] org.apache.coyote.AbstractProtocol.init Failed to initialize end point associated with ProtocolHandler [http-nio-80] java.net.SocketException: Permission denied        at sun.nio.ch.Net.bind0(Native Method)        at sun.nio.ch.Net.bind(Net.java:433)        at sun.nio.ch.Net.bind(Net.java:425)        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)        at org.apache.tomcat.util.net.NioEndpoint.bind(NioEndpoint.java:210)        at org.apache.tomcat.util.net.AbstractEndpoint.init(AbstractEndpoint.java:970)        at org.apache.tomcat.util.net.AbstractJsseEndpoint.init(AbstractJsseEndpoint.java:244)        at org.apache.coyote.AbstractProtocol.init(AbstractProtocol.java:613)        at org.apache.coyote.http11.AbstractHttp11Protocol.init(AbstractHttp11Protocol.java:66)        at org.apache.catalina.connector.Connector.initInternal(Connector.java:997)        at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:107)        at org.apache.catalina.core.StandardService.initInternal(StandardService.java:549)        at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:107)        at org.apache.catalina.core.StandardServer.initInternal(StandardServer.java:875)        at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:107)        at org.apache.catalina.startup.Catalina.load(Catalina.java:607)        at org.apache.catalina.startup.Catalina.load(Catalina.java:630)        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:498)        at org.apache.catalina.startup.Bootstrap.load(Bootstrap.java:311)        at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:494)Tomcat not able to find the library that allows optimal performance in a production environment. There is a Permission Denied while trying to initialize endpoint. Apache Portable Runtime (APR) is a highly portable library which is used for optimal performance. The initialization failed as the APR library was unable to find inturn caused the port bind to fail which caused this site down issue.Please let us know if you have performed any activity and reach out to us if you have any queries.","Hello Team,This is to notify you that the alert regarding site down for the URL http://l.spendhq.com got resolved. The site is well up and running now. We are further looking into the issue and will update you with the details.","Hello Team,This is to inform you that we have received a site down alert for the URL http://l.spendhq.com.We are looking into it and will update you with the progress.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Uv7gx,Cloud Engineer Level 1,Closed,1101275,Incident,10-07-2018 16:16,,"Hello Team,The alert regarding High Number of Process Count prd-ww2_6 - 10.59.101.6 has recovered and returned to the normal state. At this time we are marking this as resolved and closing this case. Please reach out to us if you have any query.###Hello Team,On further analysis we could see about 455 processes running at the time of the alert. The Apache httpd process amount for 93 of these process and forms the top 5 processes consuming the most CPU.$ ps aux | wc -l455$ ps -C httpd | wc -l93$ps aux | sort -nrk 3,3 | head -n 5apache    9683 10.1  1.9 995448 629776 ?       S    14:59   5:02 /usr/sbin/httpdapache   20013  5.9  1.0 718624 354876 ?       S    15:41   0:27 /usr/sbin/httpdapache    9766  3.6  0.2 449308 77524 ?        S    14:59   1:46 /usr/sbin/httpdapache   20162  3.0  0.2 436700 70684 ?        S    15:41   0:12 /usr/sbin/httpdapache   12889  3.0  0.1 421884 50092 ?        S    15:12   1:07 /usr/sbin/httpdPlease see the attachment section for detailed CPU utilization output and let us know if you have any queries.###Hello Team,This is to inform you that the alert regarding High Number of Process Count prd-ww2_6 - 10.59.101.6 got recovered and back to its normal state with the value of 31.3###Hello  Team,We have analyzed the issue and found that there were spikes in cloudwatch matrics for CPU utilization, network in and out. We have attached the screenshot in the attachment section, please have a look on it and revert us back in case of any query.###Hello Team,We have received an alert regarding High Number of Process Count prd-ww2_6 - 10.59.101.6 - web which has crossed the threshold value and reached to 44.21. We are analyzing the issue and will back to you with the update.Resource Details:Instance Id: i-01ac95c23ac66a40eInstance-type: m4.2xlargeIP: 10-59-101-6Availability-zone: us-east-1c","[image: Datadog][Triggered] [SpendHQ] - High Number of Process Count prd-ww2_6 -10.59.101.6 - webThis is to inform you that there are a high number of processes running inthe instances. Execute ps aux and find out if there are any unwantedprocesses running in the instance@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024191?to_ts=1531148961000&group=host%3Ai-01ac95c23ac66a40e&from_ts=1531141761000>*system.processes.number* over *datadog_monitor:on,host:i-01ac95c23ac66a40e*was *> 40.0* on average during the *last 10m*.The monitor was last triggered at Mon Jul 09 2018 15:09:31 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024191?group=host%3Ai-01ac95c23ac66a40e>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024191/edit>] · [Viewi-01ac95c23ac66a40e<https://app.datadoghq.com/infrastructure?filter=i-01ac95c23ac66a40e>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1531148971000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1531148071000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4477605862945785177>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Number of Process Count prd-ww2_6 - 10.59.101.6 - web,,09-07-2018 20:52,19,0,SpendHQ,"Hello Team,The alert regarding High Number of Process Count prd-ww2_6 - 10.59.101.6 has recovered and returned to the normal state. At this time we are marking this as resolved and closing this case. Please reach out to us if you have any query.","Hello Team,On further analysis we could see about 455 processes running at the time of the alert. The Apache httpd process amount for 93 of these process and forms the top 5 processes consuming the most CPU.$ ps aux | wc -l455$ ps -C httpd | wc -l93$ps aux | sort -nrk 3,3 | head -n 5apache    9683 10.1  1.9 995448 629776 ?       S    14:59   5:02 /usr/sbin/httpdapache   20013  5.9  1.0 718624 354876 ?       S    15:41   0:27 /usr/sbin/httpdapache    9766  3.6  0.2 449308 77524 ?        S    14:59   1:46 /usr/sbin/httpdapache   20162  3.0  0.2 436700 70684 ?        S    15:41   0:12 /usr/sbin/httpdapache   12889  3.0  0.1 421884 50092 ?        S    15:12   1:07 /usr/sbin/httpdPlease see the attachment section for detailed CPU utilization output and let us know if you have any queries.","Hello Team,This is to inform you that the alert regarding High Number of Process Count prd-ww2_6 - 10.59.101.6 got recovered and back to its normal state with the value of 31.3","Hello  Team,We have analyzed the issue and found that there were spikes in cloudwatch matrics for CPU utilization, network in and out. We have attached the screenshot in the attachment section, please have a look on it and revert us back in case of any query.","Hello Team,We have received an alert regarding High Number of Process Count prd-ww2_6 - 10.59.101.6 - web which has crossed the threshold value and reached to 44.21. We are analyzing the issue and will back to you with the update.Resource Details:Instance Id: i-01ac95c23ac66a40eInstance-type: m4.2xlargeIP: 10-59-101-6Availability-zone: us-east-1c",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001V9PIn,Cloud Engineer Level 1,Closed,1097297,Incident,25-04-2018 02:39,,"Hello Team,Just an updateWe witnessed there was an event earlier today in the us-east-1 (Virginia) region experienced that delays in connection provisioning and delivery of CloudWatch Metrics for some AWS Direct Connect customers. AWS Team identified the issue and has resolved it and everything is now working as expected. It wasn't related to anything on your end and it was independent of individual direct connect connection.","Between 11:15 AM and 12:48 PM PDT, we experienced delays in connection provisioning and delivery of CloudWatch Metrics for some AWS Direct Connect customers in US-EAST-1. The issue has been resolved and the service is operating normally.  For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_OPERATIONAL_ISSUE,,25-04-2018 01:36,1,0,SpendHQ,"Hello Team,Just an updateWe witnessed there was an event earlier today in the us-east-1 (Virginia) region experienced that delays in connection provisioning and delivery of CloudWatch Metrics for some AWS Direct Connect customers. AWS Team identified the issue and has resolved it and everything is now working as expected. It wasn't related to anything on your end and it was independent of individual direct connect connection.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Vs2AQ,Cloud Engineer Level 1,Closed,1098380,Incident,10-05-2018 15:00,,"Hello Allen, We have rebooted the machine and mounted the device back. Also, we are able to create files in the directory /usr/local/mariadb. Please verify from your end and let us know if you are facing any issues.###Hello Allen,We have rebooted the machine and mounted the device back.Also, we are able to create files in the directory /usr/local/mariadb. Please verify from your end and let us know if you are facing any issues.Thanks & Regards,Anjali G Nair###Hello Allen,We will look into this issue and will get back to you with updates.###Allen Herrera10:57 PM (11 minutes ago)to Anjali, REAN, me Yes 10.59.10.180 is safe to reboot.###Anjali Gopinadhan Nair10:55 PM (12 minutes ago)to Allen, REAN, me Hello Allen,We have unmounted the disk and tried to back it mount as rw mode but we are unable to mount it back and it is showing that the device is busy. Could you please provide us with an approval to reboot the machine so that we can mount the device back.","Hey Rean,My mount on /usr/local/mariadb on 10.59.10.180 is on read only. This is preventing me from starting up the database for my testing purposes and is blocking my work for the day. Please correct this.Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",10.59.10.180 mounts are read only,,09-05-2018 21:23,18,0,SpendHQ,"Hello Allen, We have rebooted the machine and mounted the device back. Also, we are able to create files in the directory /usr/local/mariadb. Please verify from your end and let us know if you are facing any issues.","Hello Allen,We have rebooted the machine and mounted the device back.Also, we are able to create files in the directory /usr/local/mariadb. Please verify from your end and let us know if you are facing any issues.Thanks & Regards,Anjali G Nair","Hello Allen,We will look into this issue and will get back to you with updates.","Allen Herrera10:57 PM (11 minutes ago)to Anjali, REAN, me Yes 10.59.10.180 is safe to reboot.","Anjali Gopinadhan Nair10:55 PM (12 minutes ago)to Allen, REAN, me Hello Allen,We have unmounted the disk and tried to back it mount as rw mode but we are unable to mount it back and it is showing that the device is busy. Could you please provide us with an approval to reboot the machine so that we can mount the device back.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d2n6k,Cloud Engineer Level 1,Closed,1106267,Incident,24-10-2018 15:32,,"Hello Team,This is a quick follow up.Please find below-unused EBS volume details. Volume ID Region Days ================== ===================== ========= vol-08525b5a8797e3935 Us-east-1	158 vol-060c6db8b26f5244f	Us-east-1 130 vol-0e921824fccece88c Us-east-1 121 vol-78e4f4c5	Us-west-1 872 We haven't received any confirmation from your end for clean up EBS volume. As of now, we are closing this case. Please let us know if you need any support in the future.###Hello Team, This is a gentle reminder. Please find below-unused EBS volume details and provide an approval to clean them up. Volume ID Region Days ================== ===================== ========= vol-08525b5a8797e3935 Us-east-1	158 vol-060c6db8b26f5244f	Us-east-1 130 vol-0e921824fccece88c Us-east-1 121 vol-78e4f4c5	Us-west-1 872 Thanks,###Hello Team, This is a gentle reminder. Please find below-unused EBS volume details and provide an approval to clean them up. Volume ID Region Days ================== ===================== ========= vol-08525b5a8797e3935 Us-east-1	158 vol-060c6db8b26f5244f	Us-east-1 130 vol-0e921824fccece88c Us-east-1 121 vol-78e4f4c5	Us-west-1 872Thanks,###Hello Team,We haven't got any response from your end regarding Ununsed Ebs Volume check. Please find the below details and let us know whether we can proceed with the deletion of the unused volume.Volume ID Region Days ================== ===================== ========= vol-08525b5a8797e3935 Us-east-1	158 vol-060c6db8b26f5244f	Us-east-1 130 vol-0e921824fccece88c Us-east-1 121 vol-78e4f4c5	Us-west-1 872We await your reply.###Hello Team, This is a gentle reminder.Please find below-unused EBS volume details and provide an approval to clean them up.Volume ID Region Days ================== ===================== ========= vol-08525b5a8797e3935 Us-east-1	158 vol-060c6db8b26f5244f	Us-east-1 130 vol-0e921824fccece88c Us-east-1 121 vol-78e4f4c5	Us-west-1 872###Hello Team,Please find the below-unused volume details and provide an approval to clean up those         Volume ID                                                      Region                                           Days==================                             =====================                  =========vol-08525b5a8797e3935                                        Us-east-1	                                       158vol-060c6db8b26f5244f	                                        Us-east-1                                       130vol-0e921824fccece88c                                          Us-east-1                                       121vol-78e4f4c5	                                                        Us-west-1                                       872","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Mon, Oct 15, 2018 at 7:34 PMSubject: [Managed Cloud: spendhq] Ununsed Ebs Volume checkTo: <spendhq-support@reancloud.com>REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environmentby REAN Managed Cloud.The following *AWS::EC2::Volume* resources were affected:------------------------------   - *Violation:* EBS volume is not attached any stopped or running EC2   instance.   - *Recommendation:* Review the use of the unattached EBS volume.   Unattached EBS volume are chargeable.   - *Action taken:* None   - *Resource details:*   Resource ID Volume Name Type Owner Region Creation Date Size Age   vol-08525b5a8797e3935 A3-DX-Failover-Test-Fix General Purpose SSD   us-east-1 2018-05-10 500 GiB 158 days   vol-060c6db8b26f5244f General Purpose SSD spendhq-support@reancloud.com   us-east-1 2018-06-07 8 GiB 130 days   vol-0e921824fccece88c SpendHQ-Server1-2018-06-15clone General Purpose SSD   spendhq-support@reancloud.com us-east-1 2018-06-16 50 GiB 121 days   vol-78e4f4c5 CloudEndure Volume u978v Standard us-west-1 2016-05-25 10   GiB 872 days------------------------------Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Managed Cloud: spendhq] Ununsed Ebs Volume check,,15-10-2018 19:42,212,0,SpendHQ,"Hello Team,This is a quick follow up.Please find below-unused EBS volume details. Volume ID Region Days ================== ===================== ========= vol-08525b5a8797e3935 Us-east-1	158 vol-060c6db8b26f5244f	Us-east-1 130 vol-0e921824fccece88c Us-east-1 121 vol-78e4f4c5	Us-west-1 872 We haven't received any confirmation from your end for clean up EBS volume. As of now, we are closing this case. Please let us know if you need any support in the future.","Hello Team, This is a gentle reminder. Please find below-unused EBS volume details and provide an approval to clean them up. Volume ID Region Days ================== ===================== ========= vol-08525b5a8797e3935 Us-east-1	158 vol-060c6db8b26f5244f	Us-east-1 130 vol-0e921824fccece88c Us-east-1 121 vol-78e4f4c5	Us-west-1 872 Thanks,","Hello Team, This is a gentle reminder. Please find below-unused EBS volume details and provide an approval to clean them up. Volume ID Region Days ================== ===================== ========= vol-08525b5a8797e3935 Us-east-1	158 vol-060c6db8b26f5244f	Us-east-1 130 vol-0e921824fccece88c Us-east-1 121 vol-78e4f4c5	Us-west-1 872Thanks,","Hello Team,We haven't got any response from your end regarding Ununsed Ebs Volume check. Please find the below details and let us know whether we can proceed with the deletion of the unused volume.Volume ID Region Days ================== ===================== ========= vol-08525b5a8797e3935 Us-east-1	158 vol-060c6db8b26f5244f	Us-east-1 130 vol-0e921824fccece88c Us-east-1 121 vol-78e4f4c5	Us-west-1 872We await your reply.","Hello Team, This is a gentle reminder.Please find below-unused EBS volume details and provide an approval to clean them up.Volume ID Region Days ================== ===================== ========= vol-08525b5a8797e3935 Us-east-1	158 vol-060c6db8b26f5244f	Us-east-1 130 vol-0e921824fccece88c Us-east-1 121 vol-78e4f4c5	Us-west-1 872","Hello Team,Please find the below-unused volume details and provide an approval to clean up those         Volume ID                                                      Region                                           Days==================                             =====================                  =========vol-08525b5a8797e3935                                        Us-east-1	                                       158vol-060c6db8b26f5244f	                                        Us-east-1                                       130vol-0e921824fccece88c                                          Us-east-1                                       121vol-78e4f4c5	                                                        Us-west-1                                       872",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001T9fk7,Cloud Engineer Level 1,Closed,1093682,Incident,20-03-2018 08:33,,"Hello Team,This is to notify that alert regarding the High CPU Load got resolved and the current load is 0.0033.At this time we are marking this case as resolved, Please revert back to us for any further queries.###Hello Team,This is to notify that we have received an alert regarding the High CPU load on prd-ww1_122.It exceeded the threshold value.Resource Details:-Instance name:-PRD-WW1_122Instance ID:-i-0ace70ce06368e4a7Instance type:-c4.2xlargeVPC ID;-vpc-76df7212Subnet ID:-subnet-0d093d27Private IP:-10.59.100.122We have analyzed the issue its cause due to the high usage by apache user that we have shared with you in attachment, Meanwhile Please let us know if there is any activity is performing on your end.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Tue, Mar 20, 2018 at 1:18 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on hostprd-ww1_122 - 10.59.100.122 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High CPU Load on host prd-ww1_122 - 10.59.100.122 -webDetected High CPU load. Log in to the machine and verify which process isconsuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023975?to_ts=1521488925000&group=host%3Ai-0ace70ce06368e4a7&from_ts=1521488625000>*system.load.15* over *datadog_monitor:on,host:i-0ace70ce06368e4a7* was *>2.0* on average during the *last 5m*.The monitor was last triggered at Mon Mar 19 2018 19:48:55 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023975?group=host%3Ai-0ace70ce06368e4a7>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023975/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?hostname=i-0ace70ce06368e4a7>]· [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1521488935000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1521488035000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4315537350996496911>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on host prd-ww1_122 - 10.59.100.122 - web,,20-03-2018 01:37,7,0,SpendHQ,"Hello Team,This is to notify that alert regarding the High CPU Load got resolved and the current load is 0.0033.At this time we are marking this case as resolved, Please revert back to us for any further queries.","Hello Team,This is to notify that we have received an alert regarding the High CPU load on prd-ww1_122.It exceeded the threshold value.Resource Details:-Instance name:-PRD-WW1_122Instance ID:-i-0ace70ce06368e4a7Instance type:-c4.2xlargeVPC ID;-vpc-76df7212Subnet ID:-subnet-0d093d27Private IP:-10.59.100.122We have analyzed the issue its cause due to the high usage by apache user that we have shared with you in attachment, Meanwhile Please let us know if there is any activity is performing on your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XyC63,Cloud Engineer Level 1,Closed,1100560,Incident,24-06-2018 00:14,,"Hello Team,This is to inform you that we have received an alert regarding clock in sync with NTP on host:10.59.10.20. The alert got resolved and the violation lasted for within 1 min. We have checked the NTP status which is synced on this host. As the alert in recovered state, We are marking this case as resolved and hence closing the case. Kindly revert back to us in case of any queries.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Sat, Jun 23, 2018 at 11:35 PMSubject: [Monitor Alert] Triggered: [Auto] Clock in sync with NTP onhost:10.59.10.20To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {host:10.59.10.20}] [Auto] Clock in sync with NTPTriggers if any host's clock goes out of sync with the time given by NTP.The offset threshold is configured in the Agent's ntp.yaml file.Please read the KB article<http://help.datadoghq.com/hc/en-us/articles/204282095-Network-Time-Protocol-NTP-Offset-Issues>on NTP Offset issues for more details on cause and resolution.@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>Offset 77 secs higher than offset threshold (60 secs)The monitor was last triggered at Sat Jun 23 2018 18:04:57 UTC (*6 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#1953584?group=host%3A10.59.10.20>] · [EditMonitor <https://app.datadoghq.com/monitors#1953584/edit>] · [View10.59.10.20 <https://app.datadoghq.com/infrastructure?filter=10.59.10.20>]· [Show Processes<https://app.datadoghq.com/process?sort=memory%2CASC&to_ts=1529777097000&tags=host%3A10.59.10.20&from_ts=1529776197000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4454589713011754261>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [Auto] Clock in sync with NTP on host:10.59.10.20,,24-06-2018 00:12,0,0,SpendHQ,"Hello Team,This is to inform you that we have received an alert regarding clock in sync with NTP on host:10.59.10.20. The alert got resolved and the violation lasted for within 1 min. We have checked the NTP status which is synced on this host. As the alert in recovered state, We are marking this case as resolved and hence closing the case. Kindly revert back to us in case of any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d2n6a,Cloud Engineer Level 1,Closed,1106266,Incident,15-10-2018 19:49,,"Hello Team,We have added the missing tags to the load balancer. Hence we are marking this case as closed.","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Mon, Oct 15, 2018 at 7:34 PMSubject: [Managed Cloud: spendhq] ELB Required tag checkTo: <spendhq-support@reancloud.com>REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environmentby REAN Managed Cloud.The following *AWS::ElasticLoadBalancingV2::LoadBalancer* resources wereaffected:------------------------------   - *Violation:* The Load Balancer does not have required tag.   - *Recommendation:* None   - *Action taken:* None   - *Resource details:*   Resource ID Type Region Creation Date Missing tags   proxy-spendhq-ALB application us-east-1 2018-09-19 Name,Owner,Monitoring------------------------------Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Managed Cloud: spendhq] ELB Required tag check,,15-10-2018 19:41,0,0,SpendHQ,"Hello Team,We have added the missing tags to the load balancer. Hence we are marking this case as closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hTNaZ,Cloud Engineer Level 1,Closed,1110531,Incident,10-01-2019 19:08,,"Hello Team,We received an informational notification from AWS that they were investigating increased packet loss impacting AWS Direct Connect connectivity to the US-EAST-1 Region.The issue happened between January 9 11:30 PM and January 10 1:09 AM PST.Currently, the issue has been resolved and the service is operating normally.Since we have no further action item on this we are marking this case as resolved and closing it.Please reach out to us for continued support.Thanks,","﻿On 10/01/19, 2:18 PM, SPHQAWS <no-reply@sns.amazonaws.com> wrote:    We are investigating increased packet loss impacting AWS Direct Connect connectivity to the US-EAST-1 Region. For more details, please see https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fphd.aws.amazon.com%2Fphd%2Fhome%3Fregion%3Dus-east-1%23%2Fdashboard%2Fopen-issues&amp;data=01%7C01%7Cnishad.ali%40hitachivantara.com%7C4cdca7d92af14b18c52608d676d86df4%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=L75%2BJSUoXWLE90s%2BvVZKtylnmQ%2BUVYS9TEV%2Fs%2B3V0HY%3D&amp;reserved=0        --    If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:    https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsns.us-east-1.amazonaws.com%2Funsubscribe.html%3FSubscriptionArn%3Darn%3Aaws%3Asns%3Aus-east-1%3A261234435984%3ASpendHQAWSHealth%3A09fe47fc-f599-46ea-b1c2-8fc7ba31782b%26Endpoint%3Dsupport%40reancloud.com&amp;data=01%7C01%7Cnishad.ali%40hitachivantara.com%7C4cdca7d92af14b18c52608d676d86df4%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=ntmjqh2HncyOCz%2BOrpWJofJ80ZSKnHe0VDe%2BQRi6pdg%3D&amp;reserved=0        Please do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Faws.amazon.com%2Fsupport&amp;data=01%7C01%7Cnishad.ali%40hitachivantara.com%7C4cdca7d92af14b18c52608d676d86df4%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=ONHT0JXi%2B25eF8%2BR4voSSEhkVWc7EF0UmM3x5VkA9t4%3D&amp;reserved=0        --             -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_OPERATIONAL_ISSUE,,10-01-2019 18:21,5,0,SpendHQ,"Hello Team,We received an informational notification from AWS that they were investigating increased packet loss impacting AWS Direct Connect connectivity to the US-EAST-1 Region.The issue happened between January 9 11:30 PM and January 10 1:09 AM PST.Currently, the issue has been resolved and the service is operating normally.Since we have no further action item on this we are marking this case as resolved and closing it.Please reach out to us for continued support.Thanks,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001CfE5f,Cloud Engineer Level 1,Closed,1059598,Incident,05-06-2017 19:15,,"Hello Mattehew,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.###Hello Matthew,We haven't heard back from you.As per your request, we have launched a new Server from the image of the instance PROD-SPHQ-WEB-SERVER03(10.59.100.94). Instance Name: PROD-SPHQ-WEB-SERVER03_Clone_June-04-2017 Instance ID: i-0e6be3e38cb040512 Private IP: 10.59.100.153 Instance type: c4.2xlarge Availability zone: us-east-1b Key pair name: Instance.pem VPC ID: vpc-76df7212 AMI ID: AMI for New Server (ami-2496c032) Subnet ID: subnet-0d093d27 Kindly validate these details and let us know if we need to on board this instance and start monitoring it###Hello Matthew,As per your request, we have launched one new Server from the image of the instance PROD-SPHQ-WEB-SERVER03(10.59.100.94). Refer the below resource details,Instance Name: PROD-SPHQ-WEB-SERVER03_Clone_June-04-2017Instance ID: i-0e6be3e38cb040512Private IP: 10.59.100.153Instance type: c4.2xlargeAvailability zone: us-east-1bKey pair name: Instance.pemVPC ID: vpc-76df7212AMI ID: AMI for New Server (ami-2496c032)Subnet ID: subnet-0d093d27Kindly validate these details and let know if you have any further queries regarding this case.Regards,Sumod.K.Bose###Hello Matthew,We acknowledge the delivery of your email. We will launch a new server from the AMI of the instance 10.59.100.94 and will get back to you with further details once it is done. Let us know if you have any further queries.Regards,Sumod.K.Bose","Rean Team,Can we please create a new server based from the image of 10.59.100.94Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",New Server,,04-06-2017 02:41,41,0,SpendHQ,"Hello Mattehew,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.","Hello Matthew,We haven't heard back from you.As per your request, we have launched a new Server from the image of the instance PROD-SPHQ-WEB-SERVER03(10.59.100.94). Instance Name: PROD-SPHQ-WEB-SERVER03_Clone_June-04-2017 Instance ID: i-0e6be3e38cb040512 Private IP: 10.59.100.153 Instance type: c4.2xlarge Availability zone: us-east-1b Key pair name: Instance.pem VPC ID: vpc-76df7212 AMI ID: AMI for New Server (ami-2496c032) Subnet ID: subnet-0d093d27 Kindly validate these details and let us know if we need to on board this instance and start monitoring it","Hello Matthew,As per your request, we have launched one new Server from the image of the instance PROD-SPHQ-WEB-SERVER03(10.59.100.94). Refer the below resource details,Instance Name: PROD-SPHQ-WEB-SERVER03_Clone_June-04-2017Instance ID: i-0e6be3e38cb040512Private IP: 10.59.100.153Instance type: c4.2xlargeAvailability zone: us-east-1bKey pair name: Instance.pemVPC ID: vpc-76df7212AMI ID: AMI for New Server (ami-2496c032)Subnet ID: subnet-0d093d27Kindly validate these details and let know if you have any further queries regarding this case.Regards,Sumod.K.Bose","Hello Matthew,We acknowledge the delivery of your email. We will launch a new server from the AMI of the instance 10.59.100.94 and will get back to you with further details once it is done. Let us know if you have any further queries.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DpGtC,Cloud Engineer Level 1,Closed,1066748,Incident,06-07-2017 02:53,,"Hi Team,The alert got resolved and returned to a normal value of 63%.###Hello Team,This is to inform you that the alert got retriggered again and the current usage is at 96%.Please delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case###Hello Team,This is to inform you that the alert got triggered again and the usage is at 96%. The device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. Delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.###Hello Team,This is to inform you that the volume usage reached a value of 100%. Please find the usage details below.Size    Folders19G     usr15G     tmp12G     var474M    homeFiles consuming volume usage under /tmp folder14G     liger_view_1906b7ba4cda3ebf75b2479542ca0558.csv323M    liger_view_3db82f98557411ed1cfdf6d673e7a5c0.csv221M    spark-2.1.0-bin-hadoop2.7157M    liger_view_2d49ec9ed8eee6a7b1573ca23cb854de.csv78M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm49M     reportsDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.###Hello Team,This is to notify you that we got an alert regarding EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135. The volume usage on this instance is above the threshold value of 90% with a value of 93%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135 Delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 93.25This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3942567776313976235 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,05-07-2017 18:07,9,0,SpendHQ,"Hi Team,The alert got resolved and returned to a normal value of 63%.","Hello Team,This is to inform you that the alert got retriggered again and the current usage is at 96%.Please delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case","Hello Team,This is to inform you that the alert got triggered again and the usage is at 96%. The device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. Delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.","Hello Team,This is to inform you that the volume usage reached a value of 100%. Please find the usage details below.Size    Folders19G     usr15G     tmp12G     var474M    homeFiles consuming volume usage under /tmp folder14G     liger_view_1906b7ba4cda3ebf75b2479542ca0558.csv323M    liger_view_3db82f98557411ed1cfdf6d673e7a5c0.csv221M    spark-2.1.0-bin-hadoop2.7157M    liger_view_2d49ec9ed8eee6a7b1573ca23cb854de.csv78M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm49M     reportsDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.","Hello Team,This is to notify you that we got an alert regarding EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135. The volume usage on this instance is above the threshold value of 90% with a value of 93%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135 Delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ETowz,Cloud Engineer Level 1,Closed,1067462,Incident,12-07-2017 05:16,,"Hello Team,This is to notify you that the alert regarding high CPU load on prod-sphq-db-server05 got resolved and has returned to normal with a value of 2.8. The violation lasted for 7 hours.###Hello Team,This is to notify you that we got an alert regarding High CPU Load prod-sphq-db-server05. The alert has crossed a threshold of 3 and reached a value of 4.24. The mysqld process is causing this usage.Resource Details:Name:prod-sphq-db-server05Availability-zone:us-east-1bInstance-type:r3.8xlargeRegion:us-east-1","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.443This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3951530419376664050 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,11-07-2017 22:30,7,0,SpendHQ,"Hello Team,This is to notify you that the alert regarding high CPU load on prod-sphq-db-server05 got resolved and has returned to normal with a value of 2.8. The violation lasted for 7 hours.","Hello Team,This is to notify you that we got an alert regarding High CPU Load prod-sphq-db-server05. The alert has crossed a threshold of 3 and reached a value of 4.24. The mysqld process is causing this usage.Resource Details:Name:prod-sphq-db-server05Availability-zone:us-east-1bInstance-type:r3.8xlargeRegion:us-east-1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001iup2A,Cloud Engineer Level 1,Closed,1111332,Incident,08-02-2019 23:35,,"Hello TeamWe haven't heard back from you.Kindly note that there are few EBS volumes which are in the available state,i.e not attached to any of the  Ec2 instances which will cause with the unnecessary billing.  Also, be noted that all the below volumes which are not in use are of a 100GB in size which will cause 10$ for each per month.Volume ID:=========vol-0d793683da4a353d5 vol-0b8b05226011f70fa vol-063ec2a500aff2fce vol-03bb2e540439de641 vol-033226b7865749a1c vol-060ead255265d72cf vol-07b02316f2e598a66 vol-06933b08567d38ea2 vol-0ed35d3b0ed8182a9 vol-08ad95d1971e54759 vol-02790557852195f6d As we haven't heard back from you for a while we are marking this case as closed. Feel free to reopen this case if you wish us to remove these volumes or if you have any other queries.RegardsNishad Ali###@Team:Send a final closure mail today.###@Team,Please check with cc on further action item, since we have done more than 3 followups.###Hi Matthew,Please let us know an update on this case.Thank you.###Hello Matthew,Could you please let us know the update on this ticket.###Hello Matthew,Thanks for the update. We are waiting for your response.###I will review these shortly.Matthew Watts <mwatts@spendhq.com>###Hello Team, This is a gentle reminder. Please have a look at the details shared with you previously and please provide your approval to clean them.###Hello Team, This is a gentle reminder. Please have a look at the details shared with you previously and please provide your approval to clean them.###Hello Team,Please have a look at the unused EBS volume details shared below and please provide your approval to clean them.------------------------------------* Resource details: Resource ID Volume Name Type Region Creation Date Size Age vol-07b02316f2e598a66 General Purpose SSD us-east-1 2018-08-22 8 GiB 159 days -------------------------------------vol-06933b08567d38ea2 SPHQ-centos-2018-07-27 Copy General Purpose SSD us-east-1 2018-08-27 100 GiB 154 days ---------------------------------------vol-0ed35d3b0ed8182a9 SPHQ-centos-2018-07-27 Copy General Purpose SSD us-east-1 2018-08-27 100 GiB 154 days -------------------------------------vol-08ad95d1971e54759 General Purpose SSD us-east-1 2018-08-28 100 GiB 153 days -------------------------------------vol-0f8fd205592bc1512 SPHQ-centos-2018-07-27 General Purpose SSD us-east-1 2018-08-28 100 GiB 153 days -------------------------------------vol-00e6b8cc2bd1decbc SPHQ-centos-2018-07-27 General Purpose SSD us-east-1 2018-08-28 100 GiB 153 days -------------------------------------vol-025fcf03d123cf334 SPHQ-centos-2018-07-27 General Purpose SSD us-east-1 2018-08-28 100 GiB 153 days -------------------------------------vol-02790557852195f6d General Purpose SSD us-east-1 2018-08-29 100 GiB 152 days -------------------------------------vol-060ead255265d72cf General Purpose SSD us-east-1 2018-08-29 100 GiB 152 days -------------------------------------vol-033226b7865749a1c General Purpose SSD us-east-1 2018-09-04 100 GiB 146 days -------------------------------------vol-03bb2e540439de641 General Purpose SSD us-east-1 2018-09-20 50 GiB 130 days -------------------------------------vol-063ec2a500aff2fce General Purpose SSD us-east-1 2018-10-02 100 GiB 118 days -------------------------------------vol-0b8b05226011f70fa General Purpose SSD us-east-1 2018-10-02 100 GiB 118 days -------------------------------------vol-0d793683da4a353d5 General Purpose SSD us-east-1 2018-10-15 8 GiB 106 days Regards,###Hello Team,This is a gentle reminder.Please have a look at the details shared with you previously and please provide your approval to clean them.###Hello Team,Please find the unused EBS volume details document from the attachments section and please provide your approval to clean them.","Hello Team,Review this and get it addressed ASAP.Praveen MuppalaCloud Architect / Tech Lead, Managed ServicesHitachi Vantara[https://www.hitachivantara.com/go/invite/signature/images/clip-image.png]m: 609-369-8481e: praveen.muppala@HitachiVantara.com<mailto:praveen.muppala@HitachiVantara.com>2201 Cooperative Way, Herndon, VA, USAFollow Hitachi Vantarawww.HitachiVantara.com<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.hitachivantara.com%2Fen-us%2Fhome.html&data=01%7C01%7Cpraveen.muppala%40hitachivantara.com%7C7c4cee88317a4a0d6e8608d6392511f7%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=jTb7VojH6xvhYg5VChqsVe2KiDIZWdUk3e%2B0EV43uYQ%3D&reserved=0> | community.HitachiVantara.com<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcommunity.hitachivantara.com%2F&data=01%7C01%7Cpraveen.muppala%40hitachivantara.com%7C7c4cee88317a4a0d6e8608d6392511f7%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=gYkxWer0xqrDC%2Fo1jZvc%2Bztaff6iJiBL4IaaUlJonlQ%3D&reserved=0>From: notifications@mnc-notify.com <notifications@mnc-notify.com>Sent: January 29, 2019 9:45 AMTo: spendhq-support@reancloud.comSubject: [Managed Cloud: spendhq] Ununsed Ebs Volume checkREAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::EC2::Volume resources were affected:________________________________  *   Violation: EBS volume is not attached any stopped or running EC2 instance.  *   Recommendation: Review the use of the unattached EBS volume. Unattached EBS volume are chargeable.  *   Action taken: None  *   Resource details:Resource IDVolume NameTypeRegionCreation DateSizeAgevol-07b02316f2e598a66General Purpose SSDus-east-12018-08-228 GiB159 daysvol-06933b08567d38ea2SPHQ-centos-2018-07-27 CopyGeneral Purpose SSDus-east-12018-08-27100 GiB154 daysvol-0ed35d3b0ed8182a9SPHQ-centos-2018-07-27 CopyGeneral Purpose SSDus-east-12018-08-27100 GiB154 daysvol-08ad95d1971e54759General Purpose SSDus-east-12018-08-28100 GiB153 daysvol-0f8fd205592bc1512SPHQ-centos-2018-07-27General Purpose SSDus-east-12018-08-28100 GiB153 daysvol-00e6b8cc2bd1decbcSPHQ-centos-2018-07-27General Purpose SSDus-east-12018-08-28100 GiB153 daysvol-025fcf03d123cf334SPHQ-centos-2018-07-27General Purpose SSDus-east-12018-08-28100 GiB153 daysvol-02790557852195f6dGeneral Purpose SSDus-east-12018-08-29100 GiB152 daysvol-060ead255265d72cfGeneral Purpose SSDus-east-12018-08-29100 GiB152 daysvol-033226b7865749a1cGeneral Purpose SSDus-east-12018-09-04100 GiB146 daysvol-03bb2e540439de641General Purpose SSDus-east-12018-09-2050 GiB130 daysvol-063ec2a500aff2fceGeneral Purpose SSDus-east-12018-10-02100 GiB118 daysvol-0b8b05226011f70faGeneral Purpose SSDus-east-12018-10-02100 GiB118 daysvol-0d793683da4a353d5General Purpose SSDus-east-12018-10-158 GiB106 days________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: [Managed Cloud: spendhq] Ununsed Ebs Volume check,,29-01-2019 20:24,243,0,SpendHQ,"Hello TeamWe haven't heard back from you.Kindly note that there are few EBS volumes which are in the available state,i.e not attached to any of the  Ec2 instances which will cause with the unnecessary billing.  Also, be noted that all the below volumes which are not in use are of a 100GB in size which will cause 10$ for each per month.Volume ID:=========vol-0d793683da4a353d5 vol-0b8b05226011f70fa vol-063ec2a500aff2fce vol-03bb2e540439de641 vol-033226b7865749a1c vol-060ead255265d72cf vol-07b02316f2e598a66 vol-06933b08567d38ea2 vol-0ed35d3b0ed8182a9 vol-08ad95d1971e54759 vol-02790557852195f6d As we haven't heard back from you for a while we are marking this case as closed. Feel free to reopen this case if you wish us to remove these volumes or if you have any other queries.RegardsNishad Ali",@Team:Send a final closure mail today.,"@Team,Please check with cc on further action item, since we have done more than 3 followups.","Hi Matthew,Please let us know an update on this case.Thank you.","Hello Matthew,Could you please let us know the update on this ticket.","Hello Matthew,Thanks for the update. We are waiting for your response.",I will review these shortly.Matthew Watts <mwatts@spendhq.com>,"Hello Team, This is a gentle reminder. Please have a look at the details shared with you previously and please provide your approval to clean them.","Hello Team, This is a gentle reminder. Please have a look at the details shared with you previously and please provide your approval to clean them.","Hello Team,Please have a look at the unused EBS volume details shared below and please provide your approval to clean them.------------------------------------* Resource details: Resource ID Volume Name Type Region Creation Date Size Age vol-07b02316f2e598a66 General Purpose SSD us-east-1 2018-08-22 8 GiB 159 days -------------------------------------vol-06933b08567d38ea2 SPHQ-centos-2018-07-27 Copy General Purpose SSD us-east-1 2018-08-27 100 GiB 154 days ---------------------------------------vol-0ed35d3b0ed8182a9 SPHQ-centos-2018-07-27 Copy General Purpose SSD us-east-1 2018-08-27 100 GiB 154 days -------------------------------------vol-08ad95d1971e54759 General Purpose SSD us-east-1 2018-08-28 100 GiB 153 days -------------------------------------vol-0f8fd205592bc1512 SPHQ-centos-2018-07-27 General Purpose SSD us-east-1 2018-08-28 100 GiB 153 days -------------------------------------vol-00e6b8cc2bd1decbc SPHQ-centos-2018-07-27 General Purpose SSD us-east-1 2018-08-28 100 GiB 153 days -------------------------------------vol-025fcf03d123cf334 SPHQ-centos-2018-07-27 General Purpose SSD us-east-1 2018-08-28 100 GiB 153 days -------------------------------------vol-02790557852195f6d General Purpose SSD us-east-1 2018-08-29 100 GiB 152 days -------------------------------------vol-060ead255265d72cf General Purpose SSD us-east-1 2018-08-29 100 GiB 152 days -------------------------------------vol-033226b7865749a1c General Purpose SSD us-east-1 2018-09-04 100 GiB 146 days -------------------------------------vol-03bb2e540439de641 General Purpose SSD us-east-1 2018-09-20 50 GiB 130 days -------------------------------------vol-063ec2a500aff2fce General Purpose SSD us-east-1 2018-10-02 100 GiB 118 days -------------------------------------vol-0b8b05226011f70fa General Purpose SSD us-east-1 2018-10-02 100 GiB 118 days -------------------------------------vol-0d793683da4a353d5 General Purpose SSD us-east-1 2018-10-15 8 GiB 106 days Regards,","Hello Team,This is a gentle reminder.Please have a look at the details shared with you previously and please provide your approval to clean them.","Hello Team,Please find the unused EBS volume details document from the attachments section and please provide your approval to clean them.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKfv,Cloud Engineer Level 1,Closed,1042229,Incident,,,,"Hello Matthew,As mentioned earlier, Andromeda team is going to clone the volume before weproceed with the patching of the instance.Please let us know if that isdone so that we can proceed with the security patching.On Sat, Jan 14, 2017 at 8:00 AM, Matthew Watts <mwatts@spendhq.com> wrote:> Please update the 10.59.10.12 machine first and advise when complete.>>>> *Matthew Watts* | Manager, Data Intelligence Systems | *Spend**HQ®*>> O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com>> *A SaaS Spend Visibility solution from Insight Sourcing Group*>> www.spendhq.com | www.insightsourcing.com>>>> *From:* Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]> *Sent:* Friday, January 13, 2017 9:24 PM> *To:* Matthew Watts <mwatts@spendhq.com>> *Cc:* REAN Support <support@reancloud.com>> *Subject:* Re: Maintenance>>>> Hello Matthew,>>>> We are ready for the maintenance. Please let us know once you start making> the changes.>>>> On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com> wrote:>> Rean Team are you ready to commence the updates as planned on the> 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.>>>> *Matthew Watts* | Manager, Data Intelligence Systems | *Spend**HQ®*>> O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com>> *A SaaS Spend Visibility solution from Insight Sourcing Group*>> *www.spendhq.com <http://www.spendhq.com/>* | *www.insightsourcing.com> <http://www.insightsourcing.com/>*>>>>>>>> -->> Mrigank Saxena>> REĀN Cloud Solutions | Reach, Engage, Activate, Nurture>> 2201 Cooperative Way #250, Herndon, VA 20171>> Cloud Consulting | Secure Managed Services | AWS VAR>>>>> <https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>>>    - REAN Cloud Achieves AWS Financial Services Competency>    <https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>>    - REAN Cloud is Premier Consulting Partner 2017>    <https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>>    - REAN Cloud receives 8 AWS Service Designations>    <https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>>    - Accelerate the Application Life Cycle with REAN DevOpsNow>    <https://www.reancloud.com/devopsnow/>>>>-- Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Maintenance,,14-01-2017 08:06,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001b22Fy,Cloud Engineer Level 1,Closed,1104155,Incident,07-09-2018 11:43,,"Hello Matthew,We have terminated the Machines.At this time we are marking this case as closed and let us know if you have any queries.###All the conversation is going on mail thread###Sorry for the inconvenience caused we have terminated the machine now.###Hello Allen,The 10.59.10.74 machine is not destroyed and still in running state now.###Matthew Watts2:36 AM (9 minutes ago)to me, Allen, Rohit, spendhq-support, Rean Why is this not destroyed if a request was made to terminate days ago? Who will be paying for this?","What’s the status of the 10.59.10.74 machine being destroyed ?Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Allen Herrera <aherrera@spendhq.com>Date: Wednesday, August 29, 2018 at 5:48 PMTo: Rohit Puri <rohit.puri@reancloud.com>, Matthew Watts <mwatts@spendhq.com>Cc: spendhq-support@reancloud.com <spendhq-support@reancloud.com>, Rean Support <support@reancloud.com>Subject: Re: Network restart on 10.59.10.74Hey Rean,After talking with Matthew, we decided to trash this cluster and create a new one. Destroy each machine , the snapshot used and the ebs volumes. Please have this done as soon as you can. We need to start a migration of data onto this cluster. Please ensure eth0 is being used on these new machines and that network.service doesn’t have any issues. As well as maintaining 10.59.19.* subnet.We need 4 servers,  1 of them being two times as big as the other 3.1. Do you want us to onboard the new server? Which means do we will need to enable monitoring, backup, alerting on that server?      Do not onboard. Do not monitor. Do not backup.2. Will the server be a considered as a Production environment?       Not yet3. Do you want us to create any additional user on the server?      aherrera      mwatts      akim           add us 3 as sudoers, email us passwords, copy our ssh keys from 10.59.10.1354. Do we need to install any additional software/services? i.e. NFS?No additional software5. size of boxes(1)   244g of ram, 32 core cpu (r4.8xlarge)(3)   128gb,  16 cores   (r5.4xlarge)6. storage                100 GB root partition EBS on all 4 machines7. operating system                Centos 7    for all 4 machines8. additional notes      Make sure `systemctl status network.service`  shows a successful status and that eth0 is being used by all machines       Make sure all 4 machines are the 10.59.10.*   database subnet       These boxes will be within the network only accessible to us on the Sophos vpnAllen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Rohit Puri <rohit.puri@reancloud.com>Date: Wednesday, August 29, 2018 at 4:24 PMTo: Matthew Watts <mwatts@spendhq.com>Cc: Allen Herrera <aherrera@spendhq.com>, spendhq-support@reancloud.com <spendhq-support@reancloud.com>, Rean Support <support@reancloud.com>Subject: Re: Network restart on 10.59.10.74Hi Mathew,Please join https://reancloud.zoom.us/my/mgse1Regards,Rohit PuriOn Thu, Aug 30, 2018 at 12:16 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:REAN,Cold we please look into this as we need the cluster to start a migration process.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Allen Herrera <aherrera@spendhq.com<mailto:aherrera@spendhq.com>>Date: Wednesday, August 29, 2018 at 2:02 PMTo: spendhq-support@reancloud.com<mailto:spendhq-support@reancloud.com> <spendhq-support@reancloud.com<mailto:spendhq-support@reancloud.com>>Subject: Network restart on 10.59.10.74Hey reanCan we check the network configurations on the new boxes we had setup.I need all the ethernets to be using the same number ( example: eth0 )Currently 3 of the 4 boxes use ‘ens5’ and the other uses ‘ens3’Ip of boxes:10.59.10.7410.59.10.11710.59.10.14710.59.10.208/etc/init.d/network statusIs showing[cid:image001.png@01D43FA7.13A166A0]Can we get on a call to review this? This is high priority.Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--You received this message because you are subscribed to the Google Groups Spendhq Support group.To unsubscribe from this group and stop receiving emails from it, send an email to spendhq-support+unsubscribe@reancloud.com<mailto:spendhq-support+unsubscribe@reancloud.com>.----REĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>rohit.puri@reancloud.com<mailto:sivasankar.nagireddy@reancloud.com> | 900-195-2605 | www.reancloud.com<http://www.reancloudsolutions.com/>[Image removed by sender.]<https://hubs.ly/H0d8gJ20>Hynes Convention Center - Boston, MA28th Aug, 2018<http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018<http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018<http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Network restart on 10.59.10.74,,07-09-2018 01:54,10,0,SpendHQ,"Hello Matthew,We have terminated the Machines.At this time we are marking this case as closed and let us know if you have any queries.",All the conversation is going on mail thread,Sorry for the inconvenience caused we have terminated the machine now.,"Hello Allen,The 10.59.10.74 machine is not destroyed and still in running state now.","Matthew Watts2:36 AM (9 minutes ago)to me, Allen, Rohit, spendhq-support, Rean Why is this not destroyed if a request was made to terminate days ago? Who will be paying for this?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C2k0S,Cloud Engineer Level 1,Closed,1054798,Incident,19-05-2017 02:22,,"Hello SpendHQ Team,This is to notify you that we have received an alert that the network inbound for prod-sphq-db-server05 is above the threshold of 1660000000.0.The alert got resolved within few minutes and returned to normal.Resource details:Instance Name - prod-sphq-db-server05Instance ID - i-008d43ad00357e47aVPC ID - vpc-76df7212Instance type - r3.8xlarge","Please investigate Regards,-Praveen From: <alert=datadoghq.com@dtdg.co> on behalf of Datadog Alerting <alert@datadoghq.com>Reply-To: <alert@datadoghq.com>Date: Thursday, May 18, 2017 at 4:23 PMTo: REANCloud Support <ms@reancloud.com>Subject: [Monitor Alert] Triggered: [SpendHQ] - High Network IN on host - prod-sphq-db-server05 - 10.59.10.135 - db Status  [Triggered on {host:10.59.10.135}] [SpendHQ] - High Network IN on host - prod-sphq-db-server05 - 10.59.10.135 - db Status High Network IN on the instance. Please check the list open TCP Connections @ms@reancloud.comaws.ec2.network_in over host:10.59.10.135,monitoring:on was > 1660000000.0 at all times during the last 5m.The monitor was last triggered at Thu May 18 2017 20:23:00 UTC (14 secs ago).[Monitor Status] · [Edit Monitor] · [View 10.59.10.135]This alert was raised by account SpendHQComment in Datadog  To manage your Datadog subscriptions, click here.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: [Monitor Alert] Triggered: [SpendHQ] - High Network IN on host - prod-sphq-db-server05 - 10.59.10.135 - db Status,,19-05-2017 02:02,0,0,SpendHQ,"Hello SpendHQ Team,This is to notify you that we have received an alert that the network inbound for prod-sphq-db-server05 is above the threshold of 1660000000.0.The alert got resolved within few minutes and returned to normal.Resource details:Instance Name - prod-sphq-db-server05Instance ID - i-008d43ad00357e47aVPC ID - vpc-76df7212Instance type - r3.8xlarge",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001CfH0O,Cloud Engineer Level 2,Closed,1059677,Incident,07-06-2017 15:00,,"Hello Team,The issue occurred due to the httpd reload in the log rotation, inorder to find the issue we will be monitoring the next log rotation on 11th June 8:30 AM IST. As per the configuration, the httpd service will get reloaded after the log rotation but that won't cause any down time. While parsing the apache error logs, we found SIGHUP signal got triggered after log rotation which is a signal for the kill commandAt this time we are marking this case as resolved. We will be monitoring the log rotation and will let you know the update.###We need to analyze why the site went down when httpd service got reloaded###RCA: https://docs.google.com/a/reansolutionsinc.com/document/d/1Yg0dT6rOj8j77zVGVaIq3n4VLyttr63cndZ0RnJD8Wo/edit?usp=sharing###Sanket updated in Morning Ops call that to create a calendar invite to log into the server before the next log rotation happens and check if there is any impact on it. Check the server on 11th June 8:30 AM ISTSince the site went down at Sat, 03 Jun 2017 23:17:59 -0400, the log rotate may happen around 23.00.00 -0400 and the httpd process stopped some where in the middle.###The analysis by L1 team is correct, The webserver is crashing due segmentation fault error.###Escalated this issue to Sushant.###+++Internal Comment+++[Analysis]After analyzing the provided details, we could see that a log rotation happened just before the httpd service went down. On the log rotation configuration, it was given a httpd service reload to happen as a part of post rotate activity. To resolve this issue, we executed service httpd start  command to bring back the apache service. Also, we were able to witness the below httpd error logs during the time of this outage,[Sun Jun 04 03:16:01 2017] [notice] SIGHUP received. Attempting to restart [Sun Jun 04 03:16:01 2017] [notice] seg fault or similar nasty error detected in the parent process SIGHUP is a signal for the kill command, this was triggered due to the reload in the logrotate configuration postrotate. Here we believe that the Apache service went down while performing the service reload, if so the service will again get stopped during the next log rotation. In this case, we need to confirm this scenario whether the apache went down while reloading the service or not. For that, we need to recreate this issue once again.[Testing]It would be good if we can provision a new test server from the AMI of 10.59.100.118 where we can perform a reload action and check if the httpd crashes again or not. If it got crashed, then the server should start right back up using a “service httpd start” command and everything seemed to work fine unless httpd was told to restart or reload and then it will crash. If not then there is another cause of the outage which needs to figure out.[Recommendation]If we were able to confirm that the httpd went down due to service reload, then it is recommended to revisit the configurations of the Apache and PHP Modules. After referring multiple cases and blogs, it is referred that this issue might be a conflict between Apache HTTPD and the PHP extension/modules. Refer this link for more details https://www.ateamsystems.com/tech-blog/freebsd-apache-crashes-at-midnight/Share these details with oncall CE2 and check how to move forward with the analysis on this case.Regards,Sumod.K.Bose###On checking the kernel logs we could see the below errors:httpd[21575]: segfault at ffffffffffffff50 ip 00007f16cf9ac43c sp 00007ffc18defb20 error 4 in ld-2.12.so[7f16cf99e000+20000]httpd[20847]: segfault at ffffffffffffff50 ip 00007f16cf9ac43c sp 00007ffc18defb20 error 4 in ld-2.12.so[7f16cf99e000+20000]We have observed that apache is generating many core dumps and getting crashed regularly. When it generates the core dump, below is being printed in the http’s error log.[Thu Jun 01 12:16:39 2017] [notice] child pid 20847 exit signal Segmentation fault (11)[Fri Jun 02 13:34:02 2017] [notice] child pid 31842 exit signal Segmentation fault (11) The error glibc detected *** /usr/sbin/httpd: free(): invalid pointer observed from the httpd error log tells that the httpd process kept a pointer to a block of memory around even though the memory had already been freed for other use. So it can be the issue with the dynamic memory allocation.The logs show segmentation fault with httpd process. The segmentation fault occurs when a program attempts to access a memory location that it is not allowed to access, or attempts to access a memory location in a way that is not allowed.So this might be the issue with the PHP application side, validate the detail with CE2 and inform the client.###Matthew Watts12:16 PM (22 minutes ago)to Rean, spendhq-support Thank you for the information and the quick evaluation and resolution. Sent from my iPhone###On further analysis, we were able to see that the log rotation was executed just 1 minute before the incident for the apache logs. Please find the log rotation configuration here : [root@ip-10-59-100-118 ~]# cat /etc/logrotate.d/httpd /var/log/httpd/*log { missingok notifempty sharedscripts delaycompress postrotate /sbin/service httpd reload > /dev/null 2>/dev/null || true endscript } As per this configuration, the httpd service will get reloaded after the log rotation but that won't cause any down time. While parsing the apache error logs, we came across two log entries with the same time stamp that is: [Sun Jun 04 03:16:01 2017] [notice] SIGHUP received. Attempting to restart *** glibc detected *** /usr/sbin/httpd: free(): invalid pointer: 0x00007f16cfb33038 *** ======= Backtrace: ========= /lib64/libc.so.6(+0x75f3e)[0x7f16ce16ff3e] /lib64/libc.so.6(+0x78d8d)[0x7f16ce172d8d] /etc/httpd/modules/mod_ldap.so(+0x6630)[0x7f16cbebc630] /usr/lib64/libapr-1.so.0(apr_pool_destroy+0x7e)[0x7f16ce6c399e] /usr/lib64/libapr-1.so.0(apr_pool_clear+0x45)[0x7f16ce6c3be5] /usr/sbin/httpd(main+0xa45)[0x7f16cfbd7955] /lib64/libc.so.6(__libc_start_main+0xfd)[0x7f16ce118d1d] /usr/sbin/httpd(+0x16a09)[0x7f16cfbd6a09] ======= Memory map: ======== 7f16bc9e2000-7f16bca60000 rw-s 00000000 00:04 30051 /dev/zero (deleted) 7f16bca60000-7f16bcaca000 r-xp 00000000 ca:01 423182 /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so 7f16bcaca000-7f16bccca000 ---p 0006a000 ca:01 423182 /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so 7f16bccca000-7f16bcccf000 rw-p 0006a000 ca:01 423182 /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so 7f16bcccf000-7f16bcd1e000 rw-p 00000000 00:00 0 7f16bcd1e000-7f16bcd20000 r-xp 00000000 ca:01 273465 /usr/lib64/apr-util-1/apr_ldap-1.so 7f16bcd20000-7f16bcf1f000 ---p 00002000 ca:01 273465 /usr/lib64/apr-util-1/apr_ldap-1.so 7f16bcf1f000-7f16bcf20000 rw-p 00001000 ca:01 273465 /usr/lib64/apr-util-1/apr_ldap-1.so 7f16bcf20000-7f16bcf2d000 r-xp 00000000 ca:01 264231 /lib64/libnss_files-2.12.so 7f16bcf2d000-7f16bd12c000 ---p 0000d000 ca:01 264231 /lib64/libnss_files-2.12.so - - et cetera - - [Sun Jun 04 03:16:01 2017] [notice] seg fault or similar nasty error detected in the parent process SIGHUP is a signal for the kill command, this was triggered due to the reload in the logrotate configuration postrotate. Please find the complete error log details in the attachment section. This seems like an issue with the application configuration or PHP modules. Updating the Apache to the latest one is highly recommended. Need to investigate this further. We will proceed with the investigation and will update you.Regards,Safuvan KM###Other than this, I don't see anything to reach the root cause. Need to escalate this issue.###On further analysis, we were able to see that the log rotation was executed just 1 minute before the incident for the apache logs. Please find the log rotation configuration here :[root@ip-10-59-100-118 ~]# cat /etc/logrotate.d/httpd/var/log/httpd/*log {    missingok    notifempty    sharedscripts    delaycompress    postrotate        /sbin/service httpd reload > /dev/null 2>/dev/null || true    endscript}As per this configuration, the httpd service will get reloaded after the log rotation but that won't cause any down time. While parsing the apache error logs, we came across two log entries with the same time stamp that is:[Sun Jun 04 03:16:01 2017] [notice] SIGHUP received.  Attempting to restart*** glibc detected *** /usr/sbin/httpd: free(): invalid pointer: 0x00007f16cfb33038 ***======= Backtrace: =========/lib64/libc.so.6(+0x75f3e)[0x7f16ce16ff3e]/lib64/libc.so.6(+0x78d8d)[0x7f16ce172d8d]/etc/httpd/modules/mod_ldap.so(+0x6630)[0x7f16cbebc630]/usr/lib64/libapr-1.so.0(apr_pool_destroy+0x7e)[0x7f16ce6c399e]/usr/lib64/libapr-1.so.0(apr_pool_clear+0x45)[0x7f16ce6c3be5]/usr/sbin/httpd(main+0xa45)[0x7f16cfbd7955]/lib64/libc.so.6(__libc_start_main+0xfd)[0x7f16ce118d1d]/usr/sbin/httpd(+0x16a09)[0x7f16cfbd6a09]======= Memory map: ========7f16bc9e2000-7f16bca60000 rw-s 00000000 00:04 30051                      /dev/zero (deleted)7f16bca60000-7f16bcaca000 r-xp 00000000 ca:01 423182                     /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so7f16bcaca000-7f16bccca000 ---p 0006a000 ca:01 423182                     /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so7f16bccca000-7f16bcccf000 rw-p 0006a000 ca:01 423182                     /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so7f16bcccf000-7f16bcd1e000 rw-p 00000000 00:00 07f16bcd1e000-7f16bcd20000 r-xp 00000000 ca:01 273465                     /usr/lib64/apr-util-1/apr_ldap-1.so7f16bcd20000-7f16bcf1f000 ---p 00002000 ca:01 273465                     /usr/lib64/apr-util-1/apr_ldap-1.so7f16bcf1f000-7f16bcf20000 rw-p 00001000 ca:01 273465                     /usr/lib64/apr-util-1/apr_ldap-1.so7f16bcf20000-7f16bcf2d000 r-xp 00000000 ca:01 264231                     /lib64/libnss_files-2.12.so7f16bcf2d000-7f16bd12c000 ---p 0000d000 ca:01 264231                     /lib64/libnss_files-2.12.so--et cetera--[Sun Jun 04 03:16:01 2017] [notice] seg fault or similar nasty error detected in the parent processSIGHUP is a signal for the kill command, this was triggered due to the reload in the logrotate configuration postrotate. Please find the complete error log details in the attachment section.This seems like an issue with the application configuration or PHP modules. Updating the apache to the latest one is highly recommended.Need to investigate this further.###Matthew Watts9:08 AM (0 minutes ago)to Rean, spendhq-support Perfect. Thank you.###Hello Matthew,While checking from the instance level, the httpd process was down and we started it to resolve the issue.We verified that the https://secure.spendhq.com/login is loading fine now.Estimated Downtime: 13 minutes 59 secondsWe are looking to figure out the root cause and will update you soon.Regards,Safuvan KM###Matthew Watts9:03 AM (1 minute ago)to Rean, spendhq-support I have confirmed the issue has been resolved. Can we please work on an RCA for this downtime.###Matthew Watts8:57 AM (4 minutes ago)to Rean, spendhq-support Please update us as soon as you find the root cause. Sent from my iPhone###This is to inform you that we received a website down alert for the production URL https://secure.spendhq.com/loginWhile checking, we could see that the URL is returning a 503 error response(Service Unavailable). We are investigating the issue further and will get back to you with the updates.Regards,Safuvan KM","Detected Error on SpendHQEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Frankfurt DE, Sydney-C AU, London UK, Dallas-B US",Detected Error on SpendHQ,,04-06-2017 08:50,78,0,SpendHQ,"Hello Team,The issue occurred due to the httpd reload in the log rotation, inorder to find the issue we will be monitoring the next log rotation on 11th June 8:30 AM IST. As per the configuration, the httpd service will get reloaded after the log rotation but that won't cause any down time. While parsing the apache error logs, we found SIGHUP signal got triggered after log rotation which is a signal for the kill commandAt this time we are marking this case as resolved. We will be monitoring the log rotation and will let you know the update.",We need to analyze why the site went down when httpd service got reloaded,RCA: https://docs.google.com/a/reansolutionsinc.com/document/d/1Yg0dT6rOj8j77zVGVaIq3n4VLyttr63cndZ0RnJD8Wo/edit?usp=sharing,"Sanket updated in Morning Ops call that to create a calendar invite to log into the server before the next log rotation happens and check if there is any impact on it. Check the server on 11th June 8:30 AM ISTSince the site went down at Sat, 03 Jun 2017 23:17:59 -0400, the log rotate may happen around 23.00.00 -0400 and the httpd process stopped some where in the middle.","The analysis by L1 team is correct, The webserver is crashing due segmentation fault error.",Escalated this issue to Sushant.,"+++Internal Comment+++[Analysis]After analyzing the provided details, we could see that a log rotation happened just before the httpd service went down. On the log rotation configuration, it was given a httpd service reload to happen as a part of post rotate activity. To resolve this issue, we executed service httpd start  command to bring back the apache service. Also, we were able to witness the below httpd error logs during the time of this outage,[Sun Jun 04 03:16:01 2017] [notice] SIGHUP received. Attempting to restart [Sun Jun 04 03:16:01 2017] [notice] seg fault or similar nasty error detected in the parent process SIGHUP is a signal for the kill command, this was triggered due to the reload in the logrotate configuration postrotate. Here we believe that the Apache service went down while performing the service reload, if so the service will again get stopped during the next log rotation. In this case, we need to confirm this scenario whether the apache went down while reloading the service or not. For that, we need to recreate this issue once again.[Testing]It would be good if we can provision a new test server from the AMI of 10.59.100.118 where we can perform a reload action and check if the httpd crashes again or not. If it got crashed, then the server should start right back up using a “service httpd start” command and everything seemed to work fine unless httpd was told to restart or reload and then it will crash. If not then there is another cause of the outage which needs to figure out.[Recommendation]If we were able to confirm that the httpd went down due to service reload, then it is recommended to revisit the configurations of the Apache and PHP Modules. After referring multiple cases and blogs, it is referred that this issue might be a conflict between Apache HTTPD and the PHP extension/modules. Refer this link for more details https://www.ateamsystems.com/tech-blog/freebsd-apache-crashes-at-midnight/Share these details with oncall CE2 and check how to move forward with the analysis on this case.Regards,Sumod.K.Bose","On checking the kernel logs we could see the below errors:httpd[21575]: segfault at ffffffffffffff50 ip 00007f16cf9ac43c sp 00007ffc18defb20 error 4 in ld-2.12.so[7f16cf99e000+20000]httpd[20847]: segfault at ffffffffffffff50 ip 00007f16cf9ac43c sp 00007ffc18defb20 error 4 in ld-2.12.so[7f16cf99e000+20000]We have observed that apache is generating many core dumps and getting crashed regularly. When it generates the core dump, below is being printed in the http’s error log.[Thu Jun 01 12:16:39 2017] [notice] child pid 20847 exit signal Segmentation fault (11)[Fri Jun 02 13:34:02 2017] [notice] child pid 31842 exit signal Segmentation fault (11) The error glibc detected *** /usr/sbin/httpd: free(): invalid pointer observed from the httpd error log tells that the httpd process kept a pointer to a block of memory around even though the memory had already been freed for other use. So it can be the issue with the dynamic memory allocation.The logs show segmentation fault with httpd process. The segmentation fault occurs when a program attempts to access a memory location that it is not allowed to access, or attempts to access a memory location in a way that is not allowed.So this might be the issue with the PHP application side, validate the detail with CE2 and inform the client.","Matthew Watts12:16 PM (22 minutes ago)to Rean, spendhq-support Thank you for the information and the quick evaluation and resolution. Sent from my iPhone","On further analysis, we were able to see that the log rotation was executed just 1 minute before the incident for the apache logs. Please find the log rotation configuration here : [root@ip-10-59-100-118 ~]# cat /etc/logrotate.d/httpd /var/log/httpd/*log { missingok notifempty sharedscripts delaycompress postrotate /sbin/service httpd reload > /dev/null 2>/dev/null || true endscript } As per this configuration, the httpd service will get reloaded after the log rotation but that won't cause any down time. While parsing the apache error logs, we came across two log entries with the same time stamp that is: [Sun Jun 04 03:16:01 2017] [notice] SIGHUP received. Attempting to restart *** glibc detected *** /usr/sbin/httpd: free(): invalid pointer: 0x00007f16cfb33038 *** ======= Backtrace: ========= /lib64/libc.so.6(+0x75f3e)[0x7f16ce16ff3e] /lib64/libc.so.6(+0x78d8d)[0x7f16ce172d8d] /etc/httpd/modules/mod_ldap.so(+0x6630)[0x7f16cbebc630] /usr/lib64/libapr-1.so.0(apr_pool_destroy+0x7e)[0x7f16ce6c399e] /usr/lib64/libapr-1.so.0(apr_pool_clear+0x45)[0x7f16ce6c3be5] /usr/sbin/httpd(main+0xa45)[0x7f16cfbd7955] /lib64/libc.so.6(__libc_start_main+0xfd)[0x7f16ce118d1d] /usr/sbin/httpd(+0x16a09)[0x7f16cfbd6a09] ======= Memory map: ======== 7f16bc9e2000-7f16bca60000 rw-s 00000000 00:04 30051 /dev/zero (deleted) 7f16bca60000-7f16bcaca000 r-xp 00000000 ca:01 423182 /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so 7f16bcaca000-7f16bccca000 ---p 0006a000 ca:01 423182 /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so 7f16bccca000-7f16bcccf000 rw-p 0006a000 ca:01 423182 /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so 7f16bcccf000-7f16bcd1e000 rw-p 00000000 00:00 0 7f16bcd1e000-7f16bcd20000 r-xp 00000000 ca:01 273465 /usr/lib64/apr-util-1/apr_ldap-1.so 7f16bcd20000-7f16bcf1f000 ---p 00002000 ca:01 273465 /usr/lib64/apr-util-1/apr_ldap-1.so 7f16bcf1f000-7f16bcf20000 rw-p 00001000 ca:01 273465 /usr/lib64/apr-util-1/apr_ldap-1.so 7f16bcf20000-7f16bcf2d000 r-xp 00000000 ca:01 264231 /lib64/libnss_files-2.12.so 7f16bcf2d000-7f16bd12c000 ---p 0000d000 ca:01 264231 /lib64/libnss_files-2.12.so - - et cetera - - [Sun Jun 04 03:16:01 2017] [notice] seg fault or similar nasty error detected in the parent process SIGHUP is a signal for the kill command, this was triggered due to the reload in the logrotate configuration postrotate. Please find the complete error log details in the attachment section. This seems like an issue with the application configuration or PHP modules. Updating the Apache to the latest one is highly recommended. Need to investigate this further. We will proceed with the investigation and will update you.Regards,Safuvan KM","Other than this, I don't see anything to reach the root cause. Need to escalate this issue.","On further analysis, we were able to see that the log rotation was executed just 1 minute before the incident for the apache logs. Please find the log rotation configuration here :[root@ip-10-59-100-118 ~]# cat /etc/logrotate.d/httpd/var/log/httpd/*log {    missingok    notifempty    sharedscripts    delaycompress    postrotate        /sbin/service httpd reload > /dev/null 2>/dev/null || true    endscript}As per this configuration, the httpd service will get reloaded after the log rotation but that won't cause any down time. While parsing the apache error logs, we came across two log entries with the same time stamp that is:[Sun Jun 04 03:16:01 2017] [notice] SIGHUP received.  Attempting to restart*** glibc detected *** /usr/sbin/httpd: free(): invalid pointer: 0x00007f16cfb33038 ***======= Backtrace: =========/lib64/libc.so.6(+0x75f3e)[0x7f16ce16ff3e]/lib64/libc.so.6(+0x78d8d)[0x7f16ce172d8d]/etc/httpd/modules/mod_ldap.so(+0x6630)[0x7f16cbebc630]/usr/lib64/libapr-1.so.0(apr_pool_destroy+0x7e)[0x7f16ce6c399e]/usr/lib64/libapr-1.so.0(apr_pool_clear+0x45)[0x7f16ce6c3be5]/usr/sbin/httpd(main+0xa45)[0x7f16cfbd7955]/lib64/libc.so.6(__libc_start_main+0xfd)[0x7f16ce118d1d]/usr/sbin/httpd(+0x16a09)[0x7f16cfbd6a09]======= Memory map: ========7f16bc9e2000-7f16bca60000 rw-s 00000000 00:04 30051                      /dev/zero (deleted)7f16bca60000-7f16bcaca000 r-xp 00000000 ca:01 423182                     /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so7f16bcaca000-7f16bccca000 ---p 0006a000 ca:01 423182                     /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so7f16bccca000-7f16bcccf000 rw-p 0006a000 ca:01 423182                     /usr/lib/php/extensions/no-debug-non-zts-20131226/redis.so7f16bcccf000-7f16bcd1e000 rw-p 00000000 00:00 07f16bcd1e000-7f16bcd20000 r-xp 00000000 ca:01 273465                     /usr/lib64/apr-util-1/apr_ldap-1.so7f16bcd20000-7f16bcf1f000 ---p 00002000 ca:01 273465                     /usr/lib64/apr-util-1/apr_ldap-1.so7f16bcf1f000-7f16bcf20000 rw-p 00001000 ca:01 273465                     /usr/lib64/apr-util-1/apr_ldap-1.so7f16bcf20000-7f16bcf2d000 r-xp 00000000 ca:01 264231                     /lib64/libnss_files-2.12.so7f16bcf2d000-7f16bd12c000 ---p 0000d000 ca:01 264231                     /lib64/libnss_files-2.12.so--et cetera--[Sun Jun 04 03:16:01 2017] [notice] seg fault or similar nasty error detected in the parent processSIGHUP is a signal for the kill command, this was triggered due to the reload in the logrotate configuration postrotate. Please find the complete error log details in the attachment section.This seems like an issue with the application configuration or PHP modules. Updating the apache to the latest one is highly recommended.Need to investigate this further.","Matthew Watts9:08 AM (0 minutes ago)to Rean, spendhq-support Perfect. Thank you.","Hello Matthew,While checking from the instance level, the httpd process was down and we started it to resolve the issue.We verified that the https://secure.spendhq.com/login is loading fine now.Estimated Downtime: 13 minutes 59 secondsWe are looking to figure out the root cause and will update you soon.Regards,Safuvan KM","Matthew Watts9:03 AM (1 minute ago)to Rean, spendhq-support I have confirmed the issue has been resolved. Can we please work on an RCA for this downtime.","Matthew Watts8:57 AM (4 minutes ago)to Rean, spendhq-support Please update us as soon as you find the root cause. Sent from my iPhone","This is to inform you that we received a website down alert for the production URL https://secure.spendhq.com/loginWhile checking, we could see that the URL is returning a 503 error response(Service Unavailable). We are investigating the issue further and will get back to you with the updates.Regards,Safuvan KM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EqdBZ,Cloud Engineer Level 1,Closed,1068418,Incident,17-07-2017 20:35,,"Hello SpendHQ Team, This is to notify you that we have received an alert that High CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0. Later the alert got resolved automatically and return to normal state with the value of 2.867.###Hello SpendHQ Team, This is to notify you that we have received an alert that High CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0 on average with the value of 3.028.  We are analyzing further on this issue and will get back to you with the updates","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.028This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3960040417094313297 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,17-07-2017 19:24,2,0,SpendHQ,"Hello SpendHQ Team, This is to notify you that we have received an alert that High CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0. Later the alert got resolved automatically and return to normal state with the value of 2.867.","Hello SpendHQ Team, This is to notify you that we have received an alert that High CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0 on average with the value of 3.028.  We are analyzing further on this issue and will get back to you with the updates",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001m2FE7,Cloud Engineer Level 1,Closed,1114059,Incident,20-03-2019 11:25,,"Hello teamThis is to inform you that the alert regarding High CPU load on sphq-db2-20180830 instance  has got resolved with a value of 0.094. As the alert is in recovered state we don't have any pending action on this, So we are marking this case as closed.Let us know if you have any queries.Thanks###Hello Team,This is to inform you that the alert regarding  high CPU load on sphq-db2-20180830  got resolved with a value of 0.74.Please review the detail and let us know if you have any further queries.###Hello Team,This is to inform you that we have checked more on this High CPU utilization issue. While checking from console level we could see that there was a hike in netwok in and out. We have checked for the RCP connections from the instance level and it was normal. [root@ip-10-59-10-45 centos]#  netstat -a -n | grep -i established | wc -l27[root@ip-10-59-10-45 centos]#  netstat -a -n | grep -i time_wait | wc -l7[root@ip-10-59-10-45 centos]#  netstat -a -n | grep -i close_wait | wc -l10[root@ip-10-59-10-45 centos]#  netstat -a -n | grep -i LISTEN | wc -l23As of now, the CPU utilization got reduced to a value of 16.9. We are closely monitoring the server. Meanwhile please check this from your end aswell. Regards,Athira###Hello Team,Upon checking the alert we could see that the process  PrimProc  is consuming high CPU utilization in the server. The server load as well increased to a value of 100+. ```````````````````````````````````````top - 18:39:18 up 37 days,  6:47,  1 user,  load average: 104.20, 85.70, 68.39Tasks: 557 total,   3 running, 554 sleeping,   0 stopped,   0 zombie%Cpu(s): 99.9 us,  0.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 50341340+total, 57146084 free, 32074732 used, 41419260+buff/cacheKiB Swap: 26214396 total, 25374264 free,   840132 used. 46929628+avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND107594 root      19  -1  266.9g  27.2g  59156 S  6351  5.7   8890:10 PrimProc 12975 root      20   0   29292   3028   1136 R  44.0  0.0   0:03.63 semodule``````````````````````````````````````[centos@ip-10-59-10-45 ~]$ w 18:37:39 up 37 days,  6:45,  1 user,  load average: 119.57, 77.75, 64.04USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHATcentos   pts/0    10.59.1.192      18:36    3.00s  0.02s  0.01s w``````````````````````````````````````As of now, the server load got reduced to 45. Please check the details from your end and let us know if you have any further queries. Regards,Athira###Hello Team,We have received an alert regarding high CPU load on sphq-db2-20180830 which has crossed the threshold and reached to the value of 50.93. We are analyzing the issue and will let you know the updates.Resource Details:Name: sphq-db2-20180830IP: 10.59.10.45","From: Datadog Alerting <alert@dtdg.co>Reply-To: post-f796df07bd8649793334b2cd8ccaf00e58d59c39@dtdg.co <post-f796df07bd8649793334b2cd8ccaf00e58d59c39@dtdg.co>Date: Tuesday, 19 March 2019 at 11:32 PMTo: REAN Managed Services <rean_ms@hitachivantara.com>Subject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on host sphq-db2-20180830 - 10.59.10.45 -***** EXTERNAL EMAIL *****[Image removed by sender. Datadog][Triggered] [SpendHQ] - High CPU Load on host sphq-db2-20180830 - 10.59.10.45 -Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources   @rean_ms@hitachivantara.com[Image removed by sender. Metric Graph]<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUorEqM0R59Qpw2VuprDIQUYOL3koPcNPgDPXKKEnijbITD1vuuLFgJBncLbAFlXSCI3pF5NyKckO0orOlE0qNjAu1q5idG1qHtEAIsHbhkHuU-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij30ymA-2FgQNqOSEsXHODJw3F3yQ3LY1W8xbFZXZ9VtC0CX6t7EdBp5pCUX-2B0tQqxUxnk3CLTz19bCjZ-2FcFdbRS9ttVWAAIyZUP7sG44Y5CK7OtjclDJeTePk-2FwjErfbKMc1xIcImSHFG0OHWofWv5bBPrHzuYWVmiZj-2BbwB20ddW9um7XA2jkBsEplsprXqGea3GA10ErJdiNBm9pJLGQB7VP&data=01%7C01%7Cshubhankar.raman%40hitachivantara.com%7Caece28bb6dd447de42ea08d6ac94fbee%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=1Ohq4870knKzUl1veaUVE6dP9a5xjBmikgeTgGC%2FR8I%3D&reserved=0>system.load.15 over datadog_monitor:on,host:i-0105d8ab19d508dd6 was > 40.0 on average during the last 1h.The monitor was last triggered at Tue Mar 19 2019 18:01:55 UTC (3 secs ago).________________________________[Monitor Status<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUoPF-2BrY3JJD44DJNoDUJ3BjmyjQeiY6JhJVrDS0ZPjVJkOJK5hvtNtngwe9YIYEoqL_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij30ymA-2FgQNqOSEsXHODJw3F3yQ3LY1W8xbFZXZ9VtC0CX3pEv1CpQODfiXqYXDdIlQLmMC6ShoOS76Je8f7I9aW5LaeK-2BITr3YgqSEpIVDeB-2FIpI732YXb2wHRfdcWLJP0I3i87xyF5p3tPJXokmsZx8weslvy320B91jIdv991RlYdHBGRHgOrD30k07NlYdtjOAO-2FbHmguDG58Q1n9tXT3&data=01%7C01%7Cshubhankar.raman%40hitachivantara.com%7Caece28bb6dd447de42ea08d6ac94fbee%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=vVc6ZBJaQf9R2b4mDSL9fQ%2B3QsiVyMrmbJWfhmO%2BhIM%3D&reserved=0>] · [Edit Monitor<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUontWyGbVcEB-2BwpzT-2BRCQNVw-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij30ymA-2FgQNqOSEsXHODJw3F3yQ3LY1W8xbFZXZ9VtC0CX8jd7iknphz2MpdRGJJXlqgEDSYhVwFQVOFJheKHi43nTExQODEMpju3DY8PzEIfRJs4Sg0TVyKriW-2FV5iVyPWinm0RoD8IzQK4uGYhDSrD30xL6PHwyxlmwa63TcoY-2BT3LK51dxUOZWKHCZe-2Fnc6eaclt5n-2FIetIqHH5ZI-2FCjGX&data=01%7C01%7Cshubhankar.raman%40hitachivantara.com%7Caece28bb6dd447de42ea08d6ac94fbee%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=bog7ZGDSXd9YJ6DsB4JBd5XoWdmsEa9DG7hwcRebJ7g%3D&reserved=0>] · [View i-0105d8ab19d508dd6<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEDKT1NZt0tnkwEaAxSQZgjulmG8eAXgJiEQQ1IARF6DGABH4uVqjj5aQfIiB59UCaQ-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij30ymA-2FgQNqOSEsXHODJw3F3yQ3LY1W8xbFZXZ9VtC0CX02QmSB2OFETTjNX2jcz4Y135lr3BR0THkBejakolko3Y240YCxMpoH54NM3bG9-2BqBukJTwR-2FKzjO4qGZpUB7wrkdR-2Fcds8-2FP73vf5FZB6w00-2BeGhXNqoMX4oXn-2FXMOUI2hQi0Wc6WrK7n6EJl4sUaMAmUDal82ZovbMpsLKl6xN&data=01%7C01%7Cshubhankar.raman%40hitachivantara.com%7Caece28bb6dd447de42ea08d6ac94fbee%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=JsGCK6YGKEbvtYwqOYgS%2FW%2BG1M%2FHNbu5iwr%2BCzbwpBc%3D&reserved=0>] · [Show Processes<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECLDvprre2LoOuppP-2FbWTz1DiYnLqZr5tg3kFNvzlsuL5khh9nbwHsz3RVMiiudjQE6Fi2lhdZaMkALEGWufc-2Bqu-2Fl5zypmAwlDvyIpBrefLiotnXiAq-2F-2BCRo-2BLZ4xSucZ1gtNfmKEClLdA24h61MiFSx1nNvQEkhavC5RBe3Y6nZfYKVCaRy0aiiLTg86x9C4-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij30ymA-2FgQNqOSEsXHODJw3F3yQ3LY1W8xbFZXZ9VtC0CX-2BDIJV20-2FUi53cyNTNv3rfsrCd-2Bp6usKV4mHG3wjN5xtSeTnu7inkdu7zwUJQlDCKr-2FCjQfAJXK7cxKu-2Bear53DasIUj1XF4r0o0qAmqvtRr0jpHnBu-2FWDEp3OgwlC6FVEe5YcnTLjfK2va6S9JymdM-2B-2Bcmy-2BS6kSR-2FSTXmC-2FKmN&data=01%7C01%7Cshubhankar.raman%40hitachivantara.com%7Caece28bb6dd447de42ea08d6ac94fbee%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=dl%2BYS18IjvoHksefukAiKoU8zBEBA6lBugmhZeJGGqw%3D&reserved=0>]This alert was raised by account SpendHQComment in Datadog<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAYJwPp8omKJuncXDFvQtom9qeg84kgAiPr4SOazxgGp90x83qT12Vf51D-2BNTpZAck-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij30ymA-2FgQNqOSEsXHODJw3F3yQ3LY1W8xbFZXZ9VtC0CX6792l-2B1zC0CgtA1OBoe1N4-2BtdlgcCI-2FxHXkxAnxK3Y5uKzkaoeUG-2Bn4Yl4TCJNPrIOwrTmr0psbIlym929AS2l7Oui0PhV4T2laBVyIjeol7ffpBF7CQuHuP47kT6tFd5Fs7jPaA3GHgaI-2B3-2B4tAK5t1d0iBrotIkdtyIG9SkyX&data=01%7C01%7Cshubhankar.raman%40hitachivantara.com%7Caece28bb6dd447de42ea08d6ac94fbee%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=5qbBVv%2BklcMTyXS7%2FvT0onFfPNe%2FDQIhXd0VHP8gw4Y%3D&reserved=0>To manage your Datadog subscriptions, click here<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECkg7AnUPKGn51plZlHct1NB9fwJzgmRoiq4UZtJ-2F9d6Q-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij30ymA-2FgQNqOSEsXHODJw3F3yQ3LY1W8xbFZXZ9VtC0CX-2Frz0i0qbmgKz6rUs3vmV1Y7ORzs9gYBhHR5SgB06qns0FKLboT9ocyKsO9o3361nAREIks-2F0bBMsuPVzGzHf9jSVDLXRsEUbFc2cBlFUqLHbW3y20-2FwhKCuxq5II2XHxmWCIaA7-2BjfdvkcqOpW5V8PclD8Ax2JaU5Um2ZGh9-2BDw&data=01%7C01%7Cshubhankar.raman%40hitachivantara.com%7Caece28bb6dd447de42ea08d6ac94fbee%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=rVbufIH%2FdHuuKmmFbwmMWjUuXzp7hhI9CJpdgktfoEU%3D&reserved=0>.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load on host sphq-db2-20180830 - 10.59.10.45 -,,19-03-2019 23:47,12,0,SpendHQ,"Hello teamThis is to inform you that the alert regarding High CPU load on sphq-db2-20180830 instance  has got resolved with a value of 0.094. As the alert is in recovered state we don't have any pending action on this, So we are marking this case as closed.Let us know if you have any queries.Thanks","Hello Team,This is to inform you that the alert regarding  high CPU load on sphq-db2-20180830  got resolved with a value of 0.74.Please review the detail and let us know if you have any further queries.","Hello Team,This is to inform you that we have checked more on this High CPU utilization issue. While checking from console level we could see that there was a hike in netwok in and out. We have checked for the RCP connections from the instance level and it was normal. [root@ip-10-59-10-45 centos]#  netstat -a -n | grep -i established | wc -l27[root@ip-10-59-10-45 centos]#  netstat -a -n | grep -i time_wait | wc -l7[root@ip-10-59-10-45 centos]#  netstat -a -n | grep -i close_wait | wc -l10[root@ip-10-59-10-45 centos]#  netstat -a -n | grep -i LISTEN | wc -l23As of now, the CPU utilization got reduced to a value of 16.9. We are closely monitoring the server. Meanwhile please check this from your end aswell. Regards,Athira","Hello Team,Upon checking the alert we could see that the process  PrimProc  is consuming high CPU utilization in the server. The server load as well increased to a value of 100+. ```````````````````````````````````````top - 18:39:18 up 37 days,  6:47,  1 user,  load average: 104.20, 85.70, 68.39Tasks: 557 total,   3 running, 554 sleeping,   0 stopped,   0 zombie%Cpu(s): 99.9 us,  0.1 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 50341340+total, 57146084 free, 32074732 used, 41419260+buff/cacheKiB Swap: 26214396 total, 25374264 free,   840132 used. 46929628+avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND107594 root      19  -1  266.9g  27.2g  59156 S  6351  5.7   8890:10 PrimProc 12975 root      20   0   29292   3028   1136 R  44.0  0.0   0:03.63 semodule``````````````````````````````````````[centos@ip-10-59-10-45 ~]$ w 18:37:39 up 37 days,  6:45,  1 user,  load average: 119.57, 77.75, 64.04USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHATcentos   pts/0    10.59.1.192      18:36    3.00s  0.02s  0.01s w``````````````````````````````````````As of now, the server load got reduced to 45. Please check the details from your end and let us know if you have any further queries. Regards,Athira","Hello Team,We have received an alert regarding high CPU load on sphq-db2-20180830 which has crossed the threshold and reached to the value of 50.93. We are analyzing the issue and will let you know the updates.Resource Details:Name: sphq-db2-20180830IP: 10.59.10.45",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BZPHb,Cloud Engineer Level 1,Closed,1051779,Incident,06-05-2017 05:59,,"Hello SpendHQ Team,Thanks for the confirmation at this time we are marking this case as resolved.###Dusty Fowler <dfowler@insightsourcing.com>8:02 PM (16 minutes ago)￼￼￼to Rean, spendhq-support￼For right now that is the expected behavior on 8443.  Thank you very much.###Hello Team,We have enabled port 8080 and 8443 for server 10.59.100.94 and all the requests for port 8080 and 8443 for preview.spendhq.com are going to hit the 10.59.100.94 server.We have checked and verified that preview.spendhq.com:8080 is working fine.But preview.spendhq.com:8443 is not working.We have tried to hit the instance directly on that port and it was also not working.Please let us know if this is a expected behaviour.Also, do let us know if you have any more queries regarding this issue.Note: we have disabled the traffic for port 8080 and 8443 for instance 10.59.100.104 which we configured earlier.###Dusty Fowler <dfowler@insightsourcing.com>6:09 PM (1 minute ago)￼￼￼to Alsa, Allen, Spendhq, Matthew, Steven￼For the domain preview.spendhq.com can we have all traffic pointing to the 10.59.100.94 server (so ports 80, 4443, 8080, and 8443)?###Steven Ng5:41 PM (30 minutes ago)￼￼￼to Alsa, Allen, Dusty, Spendhq, Matthew￼Thank you for clatifying. Can you open ports 8080 and 8443 for the preview.apendhq.com domain on the IP address is 10.59.100.94Thank you.###Hello Allen/Dusty,Sorry for the confusion.We have opened the ports 8080 and 8443 for the domain preview.spendhq.com to 10.59.100.104.But the ports 80 and 443 for the domain preview.spendhq.com are opened to 10.59.100.94.Please let us know if you have any further queries.###Are those ports opened at the domain level ? (preview.spendhq.com) or IP address 10.59.100.104. Are those ports opened for the IP 10.59.100.94? In the below email you mentioned 10.59.100.104 but dusty requested for 10.59.100.94 to be opened.Was this a typo?did you actually open them for 10.59.100.94?###Hello Dusty,As per the request from Matthew We have added the Network definition for PROD-SPHQ-WEB-SERVER04 (10.59.100.104) in Sophos.We have enabled tomcat on preview environment and we have opened traffic coming from 8080 and 8443 on 10.59.100.104. We have tested the accessibility by hitting the preview.spendhq.com:8080 and it is working fine.But preview.spendhq.com:8443 was not accessible.Since Matthew confirmed that this was the desired outcome we closed this case last week.Note: At Sophos level, all the ports(80,443,8080,8443) for the domain preview.spendhq.com are pointing to PROD-SPHQ-WEB-SERVER04 (10.59.100.104).Please let us know if you have any queries.","I was curious if 10.59.100.94 had ports 8080 and 8443 open?  Also, are there any redirects in place for the preview.spendhq.com domain?  We are seeing an internal application on this server pointing to the wrong IP and was curious where that domain was pointing.",Preview.SpendHQ.com ports/redirects,,05-05-2017 02:53,27,0,SpendHQ,"Hello SpendHQ Team,Thanks for the confirmation at this time we are marking this case as resolved.","Dusty Fowler <dfowler@insightsourcing.com>8:02 PM (16 minutes ago)￼￼￼to Rean, spendhq-support￼For right now that is the expected behavior on 8443.  Thank you very much.","Hello Team,We have enabled port 8080 and 8443 for server 10.59.100.94 and all the requests for port 8080 and 8443 for preview.spendhq.com are going to hit the 10.59.100.94 server.We have checked and verified that preview.spendhq.com:8080 is working fine.But preview.spendhq.com:8443 is not working.We have tried to hit the instance directly on that port and it was also not working.Please let us know if this is a expected behaviour.Also, do let us know if you have any more queries regarding this issue.Note: we have disabled the traffic for port 8080 and 8443 for instance 10.59.100.104 which we configured earlier.","Dusty Fowler <dfowler@insightsourcing.com>6:09 PM (1 minute ago)￼￼￼to Alsa, Allen, Spendhq, Matthew, Steven￼For the domain preview.spendhq.com can we have all traffic pointing to the 10.59.100.94 server (so ports 80, 4443, 8080, and 8443)?","Steven Ng5:41 PM (30 minutes ago)￼￼￼to Alsa, Allen, Dusty, Spendhq, Matthew￼Thank you for clatifying. Can you open ports 8080 and 8443 for the preview.apendhq.com domain on the IP address is 10.59.100.94Thank you.","Hello Allen/Dusty,Sorry for the confusion.We have opened the ports 8080 and 8443 for the domain preview.spendhq.com to 10.59.100.104.But the ports 80 and 443 for the domain preview.spendhq.com are opened to 10.59.100.94.Please let us know if you have any further queries.",Are those ports opened at the domain level ? (preview.spendhq.com) or IP address 10.59.100.104. Are those ports opened for the IP 10.59.100.94? In the below email you mentioned 10.59.100.104 but dusty requested for 10.59.100.94 to be opened.Was this a typo?did you actually open them for 10.59.100.94?,"Hello Dusty,As per the request from Matthew We have added the Network definition for PROD-SPHQ-WEB-SERVER04 (10.59.100.104) in Sophos.We have enabled tomcat on preview environment and we have opened traffic coming from 8080 and 8443 on 10.59.100.104. We have tested the accessibility by hitting the preview.spendhq.com:8080 and it is working fine.But preview.spendhq.com:8443 was not accessible.Since Matthew confirmed that this was the desired outcome we closed this case last week.Note: At Sophos level, all the ports(80,443,8080,8443) for the domain preview.spendhq.com are pointing to PROD-SPHQ-WEB-SERVER04 (10.59.100.104).Please let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001S4Vxo,Cloud Engineer Level 2,Closed,1092549,Incident,09-03-2018 12:18,,"Hello Team,Please review the RCA attached to the attachment section for Production Application Outage that happened on 6th March 2018. Please review the RCA and revert back to us in case of further queries.###Hello Team,We are still working on the RCA and will get back to you with an update shortly.###@YogeshPlease review the RCA https://docs.google.com/document/d/1CNUtovDHUpofBq7TzXjlK8Qauj7psnpcEAEHENv3K3c/edit####Hello Team,We are currently working on the RCA and will get back to you with an update.###We have started the RCA:https://docs.google.com/document/d/1CNUtovDHUpofBq7TzXjlK8Qauj7psnpcEAEHENv3K3c/edit#Please complete the RCA and reviewed with Yogesh###Team, Please create an RCA on this.###Hello Steven,Thanks for the confirmation. On Tue, Mar 6, 2018 at 9:23 PM, Steven Ng <sng@spendhq.com> wrote:Thank you very much on getting this fixed. It is working as it should.###Hello Steven,We will work on this and will get back to you with details,###Hello Steven,We have changed the file system to writable.Please check from your end and let us know if you have any further queries.###I am able to write to the directory if I traverse deeper into the mount point. Not sure why is this the case. I believe this is all good then.  Rean, on the 10.59.10.135 server can we correct the mount /dev/sdn -> /mnt/production_20_11_2017 It is currently in READ-ONLY mode. Please recover the drive WITHOUT reformatting it.###Steven Ng9:23 PM (1 hour ago)to me, Chris, David, Yogesh, Alsa, Andrew, Matthew, Spendhq Thank you very much on getting this fixed. It is working as it should. Steven Ng | Full Stack LAMP Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.com###All, Great job on mitigating the issues that presented itself with the DX failing. On further inspection, on the 10.59.10.190 server the mount /dev/sde -> /usr/local/infobright-products/iee/postgres I tried to create an empty file on the drive. I got a “No space left message” but there is space available. See the attached image. Can we get this resolved? Steven Ng | Full Stack LAMP Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com From: David McLaughlin [mailto:dmclaughlin@Andromeda3.com] Sent: Tuesday, March 6, 2018 5:50 AMTo: Yogesh Maloo <yogesh.maloo@reancloud.com>; Alsa Thuruthel Alias <alsa.thuruthel@reancloud.com>Cc: Andrew Kim <Akim@spendhq.com>; Chris Veillette <cveillette@Andromeda3.com>; Matthew Watts <mwatts@spendhq.com>; Spendhq Support <spendhq-support@reancloud.com>Subject: Re: P1: Detected Error on SpendHQ Secure Getting the guys on line.  Monty is on the road at the moment.  Waiting on Demsas and chris Get Outlook for iOSFrom: Yogesh Maloo <yogesh.maloo@reancloud.com>Sent: Tuesday, March 6, 2018 5:33:18 AMTo: Alsa Thuruthel Alias; David McLaughlinCc: Andrew Kim (SpendHQ); Chris Veillette; Matthew Watts; Spendhq SupportSubject: Re: P1: Detected Error on SpendHQ Secure + Adding David  The failover from 10 Gbps to 1 Gbps connection didn't happen. We need to check the failover configuration on the Nimble side Router. Please join the below bridge immediately.: You are invited to a Zoom meeting now. Join from PC, Mac, Linux, iOS or Android: https://reancloud.zoom.us/my/mgse2Or iPhone one-tap:    US: +16465588656,,2112766542#  or +16699006833,,2112766542# Or Telephone:    Dial(for higher quality, dial a number based on your current location):         US: +1 646 558 8656  or +1 669 900 6833  or +1 855 880 1246 (Toll Free) or +1 877 369 0926 (Toll Free)    Meeting ID: 211 276 6542    International numbers available: https://reancloud.zoom.us/zoomconference?m=luruqehFeMEXMJJozmJoVkDz41q0lzSj Regards,Yogesh MalooSenior Cloud Engineer, REĀN Cloud Mobile: +918003126272 | Skype: ykmaloo yogesh.maloo@reancloud.com | www.reancloud.com###Hello Manideep,Thank you for contacting AWS Premium Support!.This is Entesar, it was a pleasure talking to you today. Here is the summary of our discussion on the chat.I understand that your traffics don't pass to the secondary DX connection (dxcon-fg50qjyw) while the maintenance has placed on the primary DX connection (dxcon-ffpmy711).I have checked the DX connections on AWS side, please find my troubleshooting findings:1- Primary Physical Connection ID (dxcon-ffpmy711)================================================VIF ID:      dxvif-fghkv44rType:        Private VIFstatus:      UPVGW ID:      vgw-ce8867a7Target VPC: (vpc-76df7212); VPC CIDR (10.59.0.0/16)As per the email you got from Amazon, this DX should be under maintenance from Tue, 6 Mar 2018 08:00:00 GMT to Tue, 6 Mar 2018 12:00:00 GMT for 4 hours.2- Secondary Physical Connection ID (dxcon-fg50qjyw)========================================================VIF ID:      dxvif-fffiuqt9Type:        Private VIFstatus:      UP Since 20 Days 17 MinutesVGW ID:      vgw-ce8867a7Target VPC: (vpc-76df7212); VPC CIDR (10.59.0.0/16)This connection should be used during the maintenance event of the primary connection if you configured your BGP to switch/pass the traffics to this VIF connection.I hope this information has been helpful. Please let me know if you need any further help or If I can clarify any of the details. If you have further queries please feel free to update the case.Best regards,Entesar A.Amazon Web ServicesCheck out the AWS Support Knowledge Center, a knowledge base of articles and videos that answer customer questions about AWS services: https://aws.amazon.com/premiumsupport/knowledge-center/?icmpid=support_email_categoryWe value your feedback. Please rate my response using the link below.===================================================To contact us again about this case, please return to the AWS Support Center using the following URL:https://console.aws.amazon.com/support/home#/case/?displayId=4911757631&language=en(If you are connecting by federation, log in before following the link.)*Please note: this e-mail was sent from an address that cannot accept incoming e-mail. Please use the link above if you need to contact us again about this same issue.====================================================================Learn to work with the AWS Cloud. Get started with free online videos and self-paced labs athttp://aws.amazon.com/training/====================================================================Amazon Web Services, Inc. is an affiliate of Amazon.com, Inc. Amazon.com is a registered trademark of Amazon.com, Inc. or its affiliates###Hello  Team, This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login.  The site is still down. This issue occurred due to maintenance activity associated with AWS Direct Connect services associated SpendHQ-Equinix-10Gb. We suspect that automatic switchover didn't happen. We could see that all mount points became read-only. as well as not able to discover iscsi mount points. We need to get on a call with Andromeda and your team, to resolve this ASAP. Meanwhile, we are raising a support ticket with AWS regarding direct connect fail over.###Hello Team,This issue occurred due to maintenance activity associated with AWS Direct Connect services associated with SpendHQ-Equinix-10Gb. We suspect that automatic switchover didn't happen. We could see that all mount points became read-only. We are not able to discover iscsi mount points. We need to get on a call with Andromeda and your team, to resolve this ASAP.###Hello Team,We have again received a site down for https://secure.spendhq.com/login. Please let us know is there any activity performing by your team. please find the screenshot of the error in the attachments section.###Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login and https://preview.spendhq.com/login. The alert got resolved within one minute and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.","Tue, 06 Mar 2018 03:45:34 -0500Detected Error on SpendHQ SecureEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30004 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Dallas-B US, California US, Frankfurt DE, Sydney-C AU-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,06-03-2018 14:15,70,0,SpendHQ,"Hello Team,Please review the RCA attached to the attachment section for Production Application Outage that happened on 6th March 2018. Please review the RCA and revert back to us in case of further queries.","Hello Team,We are still working on the RCA and will get back to you with an update shortly.",@YogeshPlease review the RCA https://docs.google.com/document/d/1CNUtovDHUpofBq7TzXjlK8Qauj7psnpcEAEHENv3K3c/edit,"#Hello Team,We are currently working on the RCA and will get back to you with an update.",We have started the RCA:https://docs.google.com/document/d/1CNUtovDHUpofBq7TzXjlK8Qauj7psnpcEAEHENv3K3c/edit#Please complete the RCA and reviewed with Yogesh,"Team, Please create an RCA on this.","Hello Steven,Thanks for the confirmation. On Tue, Mar 6, 2018 at 9:23 PM, Steven Ng <sng@spendhq.com> wrote:Thank you very much on getting this fixed. It is working as it should.","Hello Steven,We will work on this and will get back to you with details,","Hello Steven,We have changed the file system to writable.Please check from your end and let us know if you have any further queries.","I am able to write to the directory if I traverse deeper into the mount point. Not sure why is this the case. I believe this is all good then.  Rean, on the 10.59.10.135 server can we correct the mount /dev/sdn -> /mnt/production_20_11_2017 It is currently in READ-ONLY mode. Please recover the drive WITHOUT reformatting it.","Steven Ng9:23 PM (1 hour ago)to me, Chris, David, Yogesh, Alsa, Andrew, Matthew, Spendhq Thank you very much on getting this fixed. It is working as it should. Steven Ng | Full Stack LAMP Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.com","All, Great job on mitigating the issues that presented itself with the DX failing. On further inspection, on the 10.59.10.190 server the mount /dev/sde -> /usr/local/infobright-products/iee/postgres I tried to create an empty file on the drive. I got a “No space left message” but there is space available. See the attached image. Can we get this resolved? Steven Ng | Full Stack LAMP Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com From: David McLaughlin [mailto:dmclaughlin@Andromeda3.com] Sent: Tuesday, March 6, 2018 5:50 AMTo: Yogesh Maloo <yogesh.maloo@reancloud.com>; Alsa Thuruthel Alias <alsa.thuruthel@reancloud.com>Cc: Andrew Kim <Akim@spendhq.com>; Chris Veillette <cveillette@Andromeda3.com>; Matthew Watts <mwatts@spendhq.com>; Spendhq Support <spendhq-support@reancloud.com>Subject: Re: P1: Detected Error on SpendHQ Secure Getting the guys on line.  Monty is on the road at the moment.  Waiting on Demsas and chris Get Outlook for iOSFrom: Yogesh Maloo <yogesh.maloo@reancloud.com>Sent: Tuesday, March 6, 2018 5:33:18 AMTo: Alsa Thuruthel Alias; David McLaughlinCc: Andrew Kim (SpendHQ); Chris Veillette; Matthew Watts; Spendhq SupportSubject: Re: P1: Detected Error on SpendHQ Secure + Adding David  The failover from 10 Gbps to 1 Gbps connection didn't happen. We need to check the failover configuration on the Nimble side Router. Please join the below bridge immediately.: You are invited to a Zoom meeting now. Join from PC, Mac, Linux, iOS or Android: https://reancloud.zoom.us/my/mgse2Or iPhone one-tap:    US: +16465588656,,2112766542#  or +16699006833,,2112766542# Or Telephone:    Dial(for higher quality, dial a number based on your current location):         US: +1 646 558 8656  or +1 669 900 6833  or +1 855 880 1246 (Toll Free) or +1 877 369 0926 (Toll Free)    Meeting ID: 211 276 6542    International numbers available: https://reancloud.zoom.us/zoomconference?m=luruqehFeMEXMJJozmJoVkDz41q0lzSj Regards,Yogesh MalooSenior Cloud Engineer, REĀN Cloud Mobile: +918003126272 | Skype: ykmaloo yogesh.maloo@reancloud.com | www.reancloud.com","Hello Manideep,Thank you for contacting AWS Premium Support!.This is Entesar, it was a pleasure talking to you today. Here is the summary of our discussion on the chat.I understand that your traffics don't pass to the secondary DX connection (dxcon-fg50qjyw) while the maintenance has placed on the primary DX connection (dxcon-ffpmy711).I have checked the DX connections on AWS side, please find my troubleshooting findings:1- Primary Physical Connection ID (dxcon-ffpmy711)================================================VIF ID:      dxvif-fghkv44rType:        Private VIFstatus:      UPVGW ID:      vgw-ce8867a7Target VPC: (vpc-76df7212); VPC CIDR (10.59.0.0/16)As per the email you got from Amazon, this DX should be under maintenance from Tue, 6 Mar 2018 08:00:00 GMT to Tue, 6 Mar 2018 12:00:00 GMT for 4 hours.2- Secondary Physical Connection ID (dxcon-fg50qjyw)========================================================VIF ID:      dxvif-fffiuqt9Type:        Private VIFstatus:      UP Since 20 Days 17 MinutesVGW ID:      vgw-ce8867a7Target VPC: (vpc-76df7212); VPC CIDR (10.59.0.0/16)This connection should be used during the maintenance event of the primary connection if you configured your BGP to switch/pass the traffics to this VIF connection.I hope this information has been helpful. Please let me know if you need any further help or If I can clarify any of the details. If you have further queries please feel free to update the case.Best regards,Entesar A.Amazon Web ServicesCheck out the AWS Support Knowledge Center, a knowledge base of articles and videos that answer customer questions about AWS services: https://aws.amazon.com/premiumsupport/knowledge-center/?icmpid=support_email_categoryWe value your feedback. Please rate my response using the link below.===================================================To contact us again about this case, please return to the AWS Support Center using the following URL:https://console.aws.amazon.com/support/home#/case/?displayId=4911757631&language=en(If you are connecting by federation, log in before following the link.)*Please note: this e-mail was sent from an address that cannot accept incoming e-mail. Please use the link above if you need to contact us again about this same issue.====================================================================Learn to work with the AWS Cloud. Get started with free online videos and self-paced labs athttp://aws.amazon.com/training/====================================================================Amazon Web Services, Inc. is an affiliate of Amazon.com, Inc. Amazon.com is a registered trademark of Amazon.com, Inc. or its affiliates","Hello  Team, This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login.  The site is still down. This issue occurred due to maintenance activity associated with AWS Direct Connect services associated SpendHQ-Equinix-10Gb. We suspect that automatic switchover didn't happen. We could see that all mount points became read-only. as well as not able to discover iscsi mount points. We need to get on a call with Andromeda and your team, to resolve this ASAP. Meanwhile, we are raising a support ticket with AWS regarding direct connect fail over.","Hello Team,This issue occurred due to maintenance activity associated with AWS Direct Connect services associated with SpendHQ-Equinix-10Gb. We suspect that automatic switchover didn't happen. We could see that all mount points became read-only. We are not able to discover iscsi mount points. We need to get on a call with Andromeda and your team, to resolve this ASAP.","Hello Team,We have again received a site down for https://secure.spendhq.com/login. Please let us know is there any activity performing by your team. please find the screenshot of the error in the attachments section.","Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login and https://preview.spendhq.com/login. The alert got resolved within one minute and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001dfSv3,Cloud Engineer Level 2,Closed,1106908,Incident,12-11-2018 11:39,,"Hello Team,This is to inform you that the alert regarding High disk usage got recovered. In order to fix the issue, we checked with Datadog team they mentioned that the Datadog logs were consuming the high disk space as it was set to DEBUG which was generating a lot of logs. They suggest us to change from DEBUG level to INFO level so we performed the same action. As of now, the issue is resolved and is back to its normal state hence we are marking this case as closed. Please reach us out in case of any query.###@Team:Drop a mail to customer informing them about the debug level logs was consuming high disk usage. Now we have made the changes as recommended by the Datadog Support and close this case.###Check wirh Rohit if we are good with sharing Nishad's comment with the customer.###Hello TeamWe have checked further on this case with the Datadog support team for the cause why the Datadog logs are consuming High Disk space. They informed us that the Log_level value under the config file was set to DEBUG and this caused to the lots of logs and they suggested us to change it to INFO to fix the issue in future and we have performed that.------------------------------------------------------------[root@ip-10-59-100-122 datadog-agent]# cat datadog.yaml | grep log_levellog_level: INFO[root@ip-10-59-100-122 datadog-agent]# -------------------------------------------------------------The alert is still in the recovered state with the value of  32.1%. Let us know if you have any queries###Changed the log_level to Info###Please change the log_level to info as directed by the datadog support.###Team,Check with CC whether we can go ahead and make suggested changesI have also asked about the log rotation frequency (waiting for response)10:25 AM | So how frequent is the rotation done?Mohamed10:27 AM | I am not sure about the good frequency here, but I can get back to the dev team to ask them that10:28 AM | Is it ok for you if we take this case offline ? I will follow up with by mail later after my chat shift###Mohamed10:09 AM | Ok cool10:10 AM | As a first sight, it is not normal that the process log file takes this amount out disk10:10 AM | can you check for me what is the log level of the agent ?10:11 AM | You will find it in the datadog.yaml config file with the name `log_level`Isaac Mwania (isaac.muteti@reancloud.com)10:12 AM | log_level: DEBUGMohamed10:15 AM | Because the log level is in DEBUG, it produces lots of logs10:16 AM | Please keep this level as `info` or even `warning`10:16 AM | this will reduce significantly the amount of the agent logs###@team,Please reach out to Datadog team why the logs are consuming more space.###The alert is recovered. Current usage is 23.9%###Hello Matthew,We will keep a watchful eye on the rest of the machines and once we receive an alert we will keep you on the loop.Thanks,Kevin###I have cleaned up the logs inside the file process-errors.log.1 file which was consuming 22GB of the disk and process-errors.log consumed 13 GB.Below are the contents inside the files.2018-08-22 06:23:34 INFO (collector.go:233) - Detected 1 clients, enabling real-time mode2018-08-22 06:44:56 INFO (collector.go:236) - Detected 0 clients, disabling real-time mode2018-08-22 06:46:54 INFO (collector.go:86) - Finish check #800 in 43.052608ms2018-08-22 06:50:14 INFO (collector.go:86) - Finish check #820 in 39.039808ms2018-08-22 06:53:34 INFO (collector.go:86) - Finish check #840 in 41.541966ms2018-08-22 06:56:54 INFO (collector.go:86) - Finish check #860 in 40.130417ms2018-08-22 07:00:14 INFO (collector.go:86) - Finish check #880 in 39.306304ms2018-08-22 07:03:34 INFO (collector.go:86) - Finish check #900 in 50.946052ms2018-08-22 07:06:54 INFO (collector.go:86) - Finish check #920 in 40.675295ms2018-08-22 07:10:14 INFO (collector.go:86) - Finish check #940 in 38.873687ms2018-08-22 07:13:34 INFO (collector.go:86) - Finish check #960 in 39.381379ms2018-08-22 07:16:54 INFO (collector.go:86) - Finish check #980 in 37.679829ms2018-08-22 07:20:14 INFO (collector.go:86) - Finish check #1000 in 39.990924ms2018-08-22 07:23:34 INFO (collector.go:86) - Finish check #1020 in 40.95874ms2018-08-22 07:26:54 INFO (collector.go:86) - Finish check #1040 in 41.705799ms2018-08-22 07:30:14 INFO (collector.go:86) - Finish check #1060 in 42.508663ms2018-08-22 07:33:34 INFO (collector.go:86) - Finish check #1080 in 38.783384ms2018-08-22 07:36:54 INFO (collector.go:86) - Finish check #1100 in 43.556158ms2018-08-22 07:40:14 INFO (collector.go:86) - Finish check #1120 in 47.747825ms2018-08-22 07:43:34 INFO (collector.go:86) - Finish check #1140 in 46.330037ms2018-08-22 07:46:54 INFO (collector.go:86) - Finish check #1160 in 48.026594ms2018-08-22 07:50:14 INFO (collector.go:86) - Finish check #1180 in 41.084241ms2018-08-22 07:53:34 INFO (collector.go:86) - Finish check #1200 in 45.043853ms2018-08-22 07:56:54 INFO (collector.go:86) - Finish check #1220 in 49.600617ms2018-08-22 08:00:14 INFO (collector.go:86) - Finish check #1240 in 45.569305ms2018-08-22 08:03:34 INFO (collector.go:86) - Finish check #1260 in 38.204871ms...(etc)Need to check why the datadog filled up and come up with a resolution to fix it.###Matthew Watts8:21 PM (0 minutes ago)to Rean, spendhq-support@reancloud.comPlease ensure we keep a watchful eye on all the other machines.###Hello Team,We have cleaned up the logs and the utilization now reduced to 24%.We will check regarding the disk consumption of datadog and will ensure the issue won't happen in future.###Hello Jason,We are working this and will let you know the update once done.Thanks, Kevin###Allen Herrera6:03 AM (11 hours ago)to Matthew, spendhq-support@reancloud.comReanwhy is datadog putting out 34 GB of logs. We only have 50GB root partition space. This is your process consuming all the storage for this prod machine.process-errors.log  is spamming an error into the logs.Please clean up these log files.tail -f process-errors.log Unable to access /proc/30376/io, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:841) - Unable to access /proc/30376/cwd, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:849) - Unable to access /proc/30376/exe, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:858) - Unable to access /proc/30376/fd, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:830) - Unable to access /proc/30377/io, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:841) - Unable to access /proc/30377/cwd, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:849) - Unable to access /proc/30377/exe, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:858) - Unable to access /proc/30377/fd, permission denied2018-11-05 03:01:16 DEBUG (process.go:106) - collected processes in 49.563174msJason Bray <jbray@spendhq.com>5:56 PM (5 minutes ago)to Allen, Matthew, spendhq-support@reancloud.comRean Team - Did this get cleaned up? Also, we need a process put in place that will prevent this from happening.###Hello TeamThis is a quick followup.The EBS high disk usage that we have received are still in the Open state with the current value of 94.6%  disk usage. Kindly refer with the previous commands and proceed with the cleaning of the unwanted files.Lets us know if you have any queries.###@teamAlert is still in open state. Check with CC for next action###Hello TeamWe haven't heard back from you regarding the alert  EBS High Disk Usage ( /dev/xvda1 )  on prd-ww1_122 - 10.59.100.122 instance. The alert is still in open state with a value of 89.1% .As mentioned over the previous comments we could see that the files under the /var directory consume the high disk space. Kindly have a look at the files under /var directory and proceed with a cleanup of unwanted files.---------------------------------------22G	/var/log/datadog/process-errors.log.1 17G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/serta_simmons.out 17G	/var/www/vhosts/files.spendhq.com/etl_uploads/raytheon_201501_201712_dm.out 15G	/var/www/vhosts/secure.spendhq.com/public/app/tmp/logs/error.log 15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_region_vertical.out 15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_pe.out 15G	/var/www/vhosts/files.spendhq.com/newer_w2/tmp/logs/error.log 14G	/var/www/vhosts/files.spendhq.com/etl_uploads/gpc_201510_201807.out 9.9G /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log 9.1G /var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/cushman_wakefield.out ---------------------------------------------------------------------------------------------------------------------Let us know if you have any queriesThanksNishad Ali###Hello Team,We haven't received any response from you. Please review our analysis from the previous comment regarding alert EBS High Disk Usage on prd-ww1_122 - 10.59.100.122. And kindly let us know if you have any concern about the case.###Hello Team,This is a quick follow upWe have received EBS High Disk Usage on prd-ww1_122 - 10.59.100.122. We analyzed the Disk usage from the instance level and we could see that following files consuming high memory22G	/var/log/datadog/process-errors.log.1 17G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/serta_simmons.out 17G	/var/www/vhosts/files.spendhq.com/etl_uploads/raytheon_201501_201712_dm.out 15G	/var/www/vhosts/secure.spendhq.com/public/app/tmp/logs/error.log 15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_region_vertical.out 15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_pe.out 15G	/var/www/vhosts/files.spendhq.com/newer_w2/tmp/logs/error.log 14G	/var/www/vhosts/files.spendhq.com/etl_uploads/gpc_201510_201807.out 9.9G  /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log 9.1G  /var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/cushman_wakefield.out Please validate the same and let us know if you have any questions regarding the same.###Hello Team,On analyzing the issue we found below are the details:##=======##======####=======##======####=======##======##Disk usage as per Directories in /var==>>27G	log3.8G	www576M	lib408M	tmp129M	cache15M	spool836K	db128K	run12K	lock8.0K	empty##=======##======####=======##======####=======##======##You are in the /var/log directory==>>27G	datadog190M	file_monitor.log39M	amazon28M	audit21M	sa6.1M	newrelic2.4M	cron-201810282.4M	cron-201810212.4M	cron-201810142.4M	cron-20181007You are in the /var/tmp directory==>>102M	shq-logs91M	yum-sng-_8DLIG78M	yum-reanro-991xMl66M	yum-aherrera-9Eg3N560M	yum-mwatts-PnLKnb13M	yum-root-VWvI4w12K	monitor.php4.0K	yum-dmiller-EXt6n64.0K	yum-dfowler-MRADio4.0K	yum-centos-DK3q2u##=======##======####=======##======####=======##======##You are in the /var/www directory==>>3.8G	vhosts948K	icons216K	error4.0K	html4.0K	cgi-bin##=======##======####=======##======####=======##======####=======##======####=======##======####=======##======##The top disk consuming files in /var  are listed below==>>22G	/var/log/datadog/process-errors.log.117G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/serta_simmons.out17G	/var/www/vhosts/files.spendhq.com/etl_uploads/raytheon_201501_201712_dm.out15G	/var/www/vhosts/secure.spendhq.com/public/app/tmp/logs/error.log15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_region_vertical.out15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_pe.out15G	/var/www/vhosts/files.spendhq.com/newer_w2/tmp/logs/error.log14G	/var/www/vhosts/files.spendhq.com/etl_uploads/gpc_201510_201807.out9.9G	/var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log9.1G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/cushman_wakefield.outPlease have a look at it and let us know if you have any query.###Hello Team,We have received an alert regarding EBS High Disk Usage ( /dev/xvda1 ) on prd-ww1_122 - 10.59.100.122 which has reached the threshold value of 80%. We are analyzing the issue and will back to you with the update.Resource Details:Instance Id: i-0ace70ce06368e4a7IP: 10-59-100-122Name: prd-ww1_122","On Tue, Oct 30, 2018 at 5:51 AM Datadog Alerting <alert@dtdg.co> wrote:> [image: Datadog]>> [Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-ww1_122 -> 10.59.100.122>> High Disk Usage detected on the device /dev/xvda1> @ms@reancloud.com> <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>>> [image: Metric Graph]> <https://app.datadoghq.com/monitors#2023969?to_ts=1540858899000&group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-0ace70ce06368e4a7&from_ts=1540855299000>>> avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc}> by {host,device} * 100 > 80>> The monitor was last triggered at Tue Oct 30 2018 00:21:49 UTC (*4 secs> ago*).> ------------------------------>> [Monitor Status> <https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-0ace70ce06368e4a7>]> · [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [View> i-0ace70ce06368e4a7> <https://app.datadoghq.com/infrastructure?filter=i-0ace70ce06368e4a7>] · [Show> Processes> <https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1540859029000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1540858009000&live=false&showSummaryGraphs=true>> ]>> This alert was raised by account SpendHQ>> Comment in Datadog> <https://app.datadoghq.com/event/event?id=4640511626826007286>>> To manage your Datadog subscriptions, click here> <https://app.datadoghq.com/account/preferences>.>>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-ww1_122 - 10.59.100.122,,30-10-2018 05:57,318,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding High disk usage got recovered. In order to fix the issue, we checked with Datadog team they mentioned that the Datadog logs were consuming the high disk space as it was set to DEBUG which was generating a lot of logs. They suggest us to change from DEBUG level to INFO level so we performed the same action. As of now, the issue is resolved and is back to its normal state hence we are marking this case as closed. Please reach us out in case of any query.",@Team:Drop a mail to customer informing them about the debug level logs was consuming high disk usage. Now we have made the changes as recommended by the Datadog Support and close this case.,Check wirh Rohit if we are good with sharing Nishad's comment with the customer.,Hello TeamWe have checked further on this case with the Datadog support team for the cause why the Datadog logs are consuming High Disk space. They informed us that the Log_level value under the config file was set to DEBUG and this caused to the lots of logs and they suggested us to change it to INFO to fix the issue in future and we have performed that.------------------------------------------------------------[root@ip-10-59-100-122 datadog-agent]# cat datadog.yaml | grep log_levellog_level: INFO[root@ip-10-59-100-122 datadog-agent]# -------------------------------------------------------------The alert is still in the recovered state with the value of  32.1%. Let us know if you have any queries,Changed the log_level to Info,Please change the log_level to info as directed by the datadog support.,"Team,Check with CC whether we can go ahead and make suggested changesI have also asked about the log rotation frequency (waiting for response)10:25 AM | So how frequent is the rotation done?Mohamed10:27 AM | I am not sure about the good frequency here, but I can get back to the dev team to ask them that10:28 AM | Is it ok for you if we take this case offline ? I will follow up with by mail later after my chat shift","Mohamed10:09 AM | Ok cool10:10 AM | As a first sight, it is not normal that the process log file takes this amount out disk10:10 AM | can you check for me what is the log level of the agent ?10:11 AM | You will find it in the datadog.yaml config file with the name `log_level`Isaac Mwania (isaac.muteti@reancloud.com)10:12 AM | log_level: DEBUGMohamed10:15 AM | Because the log level is in DEBUG, it produces lots of logs10:16 AM | Please keep this level as `info` or even `warning`10:16 AM | this will reduce significantly the amount of the agent logs","@team,Please reach out to Datadog team why the logs are consuming more space.",The alert is recovered. Current usage is 23.9%,"Hello Matthew,We will keep a watchful eye on the rest of the machines and once we receive an alert we will keep you on the loop.Thanks,Kevin","I have cleaned up the logs inside the file process-errors.log.1 file which was consuming 22GB of the disk and process-errors.log consumed 13 GB.Below are the contents inside the files.2018-08-22 06:23:34 INFO (collector.go:233) - Detected 1 clients, enabling real-time mode2018-08-22 06:44:56 INFO (collector.go:236) - Detected 0 clients, disabling real-time mode2018-08-22 06:46:54 INFO (collector.go:86) - Finish check #800 in 43.052608ms2018-08-22 06:50:14 INFO (collector.go:86) - Finish check #820 in 39.039808ms2018-08-22 06:53:34 INFO (collector.go:86) - Finish check #840 in 41.541966ms2018-08-22 06:56:54 INFO (collector.go:86) - Finish check #860 in 40.130417ms2018-08-22 07:00:14 INFO (collector.go:86) - Finish check #880 in 39.306304ms2018-08-22 07:03:34 INFO (collector.go:86) - Finish check #900 in 50.946052ms2018-08-22 07:06:54 INFO (collector.go:86) - Finish check #920 in 40.675295ms2018-08-22 07:10:14 INFO (collector.go:86) - Finish check #940 in 38.873687ms2018-08-22 07:13:34 INFO (collector.go:86) - Finish check #960 in 39.381379ms2018-08-22 07:16:54 INFO (collector.go:86) - Finish check #980 in 37.679829ms2018-08-22 07:20:14 INFO (collector.go:86) - Finish check #1000 in 39.990924ms2018-08-22 07:23:34 INFO (collector.go:86) - Finish check #1020 in 40.95874ms2018-08-22 07:26:54 INFO (collector.go:86) - Finish check #1040 in 41.705799ms2018-08-22 07:30:14 INFO (collector.go:86) - Finish check #1060 in 42.508663ms2018-08-22 07:33:34 INFO (collector.go:86) - Finish check #1080 in 38.783384ms2018-08-22 07:36:54 INFO (collector.go:86) - Finish check #1100 in 43.556158ms2018-08-22 07:40:14 INFO (collector.go:86) - Finish check #1120 in 47.747825ms2018-08-22 07:43:34 INFO (collector.go:86) - Finish check #1140 in 46.330037ms2018-08-22 07:46:54 INFO (collector.go:86) - Finish check #1160 in 48.026594ms2018-08-22 07:50:14 INFO (collector.go:86) - Finish check #1180 in 41.084241ms2018-08-22 07:53:34 INFO (collector.go:86) - Finish check #1200 in 45.043853ms2018-08-22 07:56:54 INFO (collector.go:86) - Finish check #1220 in 49.600617ms2018-08-22 08:00:14 INFO (collector.go:86) - Finish check #1240 in 45.569305ms2018-08-22 08:03:34 INFO (collector.go:86) - Finish check #1260 in 38.204871ms...(etc)Need to check why the datadog filled up and come up with a resolution to fix it.","Matthew Watts8:21 PM (0 minutes ago)to Rean, spendhq-support@reancloud.comPlease ensure we keep a watchful eye on all the other machines.","Hello Team,We have cleaned up the logs and the utilization now reduced to 24%.We will check regarding the disk consumption of datadog and will ensure the issue won't happen in future.","Hello Jason,We are working this and will let you know the update once done.Thanks, Kevin","Allen Herrera6:03 AM (11 hours ago)to Matthew, spendhq-support@reancloud.comReanwhy is datadog putting out 34 GB of logs. We only have 50GB root partition space. This is your process consuming all the storage for this prod machine.process-errors.log  is spamming an error into the logs.Please clean up these log files.tail -f process-errors.log Unable to access /proc/30376/io, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:841) - Unable to access /proc/30376/cwd, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:849) - Unable to access /proc/30376/exe, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:858) - Unable to access /proc/30376/fd, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:830) - Unable to access /proc/30377/io, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:841) - Unable to access /proc/30377/cwd, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:849) - Unable to access /proc/30377/exe, permission denied2018-11-05 03:01:16 DEBUG (process_linux.go:858) - Unable to access /proc/30377/fd, permission denied2018-11-05 03:01:16 DEBUG (process.go:106) - collected processes in 49.563174msJason Bray <jbray@spendhq.com>5:56 PM (5 minutes ago)to Allen, Matthew, spendhq-support@reancloud.comRean Team - Did this get cleaned up? Also, we need a process put in place that will prevent this from happening.",Hello TeamThis is a quick followup.The EBS high disk usage that we have received are still in the Open state with the current value of 94.6%  disk usage. Kindly refer with the previous commands and proceed with the cleaning of the unwanted files.Lets us know if you have any queries.,@teamAlert is still in open state. Check with CC for next action,"Hello TeamWe haven't heard back from you regarding the alert  EBS High Disk Usage ( /dev/xvda1 )  on prd-ww1_122 - 10.59.100.122 instance. The alert is still in open state with a value of 89.1% .As mentioned over the previous comments we could see that the files under the /var directory consume the high disk space. Kindly have a look at the files under /var directory and proceed with a cleanup of unwanted files.---------------------------------------22G	/var/log/datadog/process-errors.log.1 17G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/serta_simmons.out 17G	/var/www/vhosts/files.spendhq.com/etl_uploads/raytheon_201501_201712_dm.out 15G	/var/www/vhosts/secure.spendhq.com/public/app/tmp/logs/error.log 15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_region_vertical.out 15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_pe.out 15G	/var/www/vhosts/files.spendhq.com/newer_w2/tmp/logs/error.log 14G	/var/www/vhosts/files.spendhq.com/etl_uploads/gpc_201510_201807.out 9.9G /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log 9.1G /var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/cushman_wakefield.out ---------------------------------------------------------------------------------------------------------------------Let us know if you have any queriesThanksNishad Ali","Hello Team,We haven't received any response from you. Please review our analysis from the previous comment regarding alert EBS High Disk Usage on prd-ww1_122 - 10.59.100.122. And kindly let us know if you have any concern about the case.","Hello Team,This is a quick follow upWe have received EBS High Disk Usage on prd-ww1_122 - 10.59.100.122. We analyzed the Disk usage from the instance level and we could see that following files consuming high memory22G	/var/log/datadog/process-errors.log.1 17G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/serta_simmons.out 17G	/var/www/vhosts/files.spendhq.com/etl_uploads/raytheon_201501_201712_dm.out 15G	/var/www/vhosts/secure.spendhq.com/public/app/tmp/logs/error.log 15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_region_vertical.out 15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_pe.out 15G	/var/www/vhosts/files.spendhq.com/newer_w2/tmp/logs/error.log 14G	/var/www/vhosts/files.spendhq.com/etl_uploads/gpc_201510_201807.out 9.9G  /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log 9.1G  /var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/cushman_wakefield.out Please validate the same and let us know if you have any questions regarding the same.","Hello Team,On analyzing the issue we found below are the details:##=======##======",#=======##======,"#=======##======##Disk usage as per Directories in /var==>>27G	log3.8G	www576M	lib408M	tmp129M	cache15M	spool836K	db128K	run12K	lock8.0K	empty##=======##======",#=======##======,"#=======##======##You are in the /var/log directory==>>27G	datadog190M	file_monitor.log39M	amazon28M	audit21M	sa6.1M	newrelic2.4M	cron-201810282.4M	cron-201810212.4M	cron-201810142.4M	cron-20181007You are in the /var/tmp directory==>>102M	shq-logs91M	yum-sng-_8DLIG78M	yum-reanro-991xMl66M	yum-aherrera-9Eg3N560M	yum-mwatts-PnLKnb13M	yum-root-VWvI4w12K	monitor.php4.0K	yum-dmiller-EXt6n64.0K	yum-dfowler-MRADio4.0K	yum-centos-DK3q2u##=======##======",#=======##======,"#=======##======##You are in the /var/www directory==>>3.8G	vhosts948K	icons216K	error4.0K	html4.0K	cgi-bin##=======##======",#=======##======,#=======##======,#=======##======,#=======##======,"#=======##======##The top disk consuming files in /var  are listed below==>>22G	/var/log/datadog/process-errors.log.117G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/serta_simmons.out17G	/var/www/vhosts/files.spendhq.com/etl_uploads/raytheon_201501_201712_dm.out15G	/var/www/vhosts/secure.spendhq.com/public/app/tmp/logs/error.log15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_region_vertical.out15G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/jll_pe.out15G	/var/www/vhosts/files.spendhq.com/newer_w2/tmp/logs/error.log14G	/var/www/vhosts/files.spendhq.com/etl_uploads/gpc_201510_201807.out9.9G	/var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-access.log9.1G	/var/www/vhosts/files.spendhq.com/preview.spendhq.com/etl_uploads/cushman_wakefield.outPlease have a look at it and let us know if you have any query.","Hello Team,We have received an alert regarding EBS High Disk Usage ( /dev/xvda1 ) on prd-ww1_122 - 10.59.100.122 which has reached the threshold value of 80%. We are analyzing the issue and will back to you with the update.Resource Details:Instance Id: i-0ace70ce06368e4a7IP: 10-59-100-122Name: prd-ww1_122",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001CdNw2,Cloud Engineer Level 1,Closed,1057812,Incident,31-05-2017 13:40,,"Hello Team,As per the notification from the AWS Team, the planned maintenance will be started now. We will be monitoring the resources and will in notify you in the case of any abnormal behavior. Please feel free to revert back to us in the case of any queries.--Thanks & Regards,Safuvan KM###Hello Team, Please actively monitor the SpendHQ DB iSCSI disks connectivity from Wednesday 1:30PM – 5:30PM IST because of the Direct Connect primary link maintenance activity by Amazon AWS. As per, Andromeda3 the backup link automatically takes control of the traffic and continue to support the traffic flow between AWS and Equinix Nimble Storage. If the connectivity is lost for iSCSI disks, please call Andromeda team for immediate assistance. However, you have Sanket for any further guidance on this issue. Regards,-Praveen###Praveen updated thatPlease actively monitor all the SpendHQ alerts and make sure the iSCSI disk connectivity from DB machines.###Hello Chris, As discussed over phone, SpendHQ 10GB Primary Direct Connect line is scheduled for maintenance window. Here are the details. Connection Details: ID -  dxvif-fghkv44r, Connection - dxcon-ffpmy711, Your Peer IP: 169.254.255.2/30 and Amazon Peer IP: 169.254.255.1/30Start time: May 31, 2017 at 4:00:00 AM UTC-4End time: May 31, 2017 at 8:00:00 AM UTC-4 During this maintenance window, we would like to fall back the connection to 1GB link. Please see the 1GB connection details here: Connection Details: ID -  dxvif-fffiuqt9, Connection - dxcon-fg50qjyw, Your Peer IP: 169.254.255.46/30 and Amazon Peer IP: 169.254.255.45/30 Please let us know how this switch will happen and also let us know if you need any additional information on it. @Andrew/Matthew, this doesn’t require any changes from our end. Please let us know, if you see any concerns with it. Regards,-Praveen###Yes we will be standing by should the need arise.Chris Veillette On May 30, 2017, at 5:27 PM, Praveen Kumar Muppala <praveen.muppala@reancloud.com> wrote:Hello Chris, I am sure your anticipation works the way it supposed work tonight, however by any chance, if it doesn’t go through will you be able to provide standby support to switchover manually to 1GB connection. Regards,-Praveen###We reached out to Praveen and he updated that he'll talk to SpendHQ and Andromeda team.###Aws team confirmed the scheduled maintenance is going to affect 10Gbps which is our primary Direct Connect. after checked with Sanket, he updated to reach out to Praveena nd make a call to Andrew to discuss this. If it is going to happen 10Gbps connection we can switch to 1 Gbps at during the maintenance. Also, need to reach out Andromeda team and inform this.###Hello SpendHQ-Team, This is to notify you that we have received a notification from AWS that there will be a planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6, DC10, Ashburn, VA. Start time: May 31, 2017 at 1:30:00 PM UTC+5:30End time: May 31, 2017 at 5:30:00 PM UTC+5:30 We will raise a support ticket with AWS team to confirm the DX connections which are going to affect. We will update you once we got a reply from AWS team.","Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6, DC10, Ashburn, VA. During this maintenance window, your AWS Direct Connect services associated with this event may become unavailable.This maintenance is scheduled to avoid disrupting redundant connections at the same time.If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED,,30-05-2017 11:04,39,0,SpendHQ,"Hello Team,As per the notification from the AWS Team, the planned maintenance will be started now. We will be monitoring the resources and will in notify you in the case of any abnormal behavior. Please feel free to revert back to us in the case of any queries.--Thanks & Regards,Safuvan KM","Hello Team, Please actively monitor the SpendHQ DB iSCSI disks connectivity from Wednesday 1:30PM – 5:30PM IST because of the Direct Connect primary link maintenance activity by Amazon AWS. As per, Andromeda3 the backup link automatically takes control of the traffic and continue to support the traffic flow between AWS and Equinix Nimble Storage. If the connectivity is lost for iSCSI disks, please call Andromeda team for immediate assistance. However, you have Sanket for any further guidance on this issue. Regards,-Praveen",Praveen updated thatPlease actively monitor all the SpendHQ alerts and make sure the iSCSI disk connectivity from DB machines.,"Hello Chris, As discussed over phone, SpendHQ 10GB Primary Direct Connect line is scheduled for maintenance window. Here are the details. Connection Details: ID -  dxvif-fghkv44r, Connection - dxcon-ffpmy711, Your Peer IP: 169.254.255.2/30 and Amazon Peer IP: 169.254.255.1/30Start time: May 31, 2017 at 4:00:00 AM UTC-4End time: May 31, 2017 at 8:00:00 AM UTC-4 During this maintenance window, we would like to fall back the connection to 1GB link. Please see the 1GB connection details here: Connection Details: ID -  dxvif-fffiuqt9, Connection - dxcon-fg50qjyw, Your Peer IP: 169.254.255.46/30 and Amazon Peer IP: 169.254.255.45/30 Please let us know how this switch will happen and also let us know if you need any additional information on it. @Andrew/Matthew, this doesn’t require any changes from our end. Please let us know, if you see any concerns with it. Regards,-Praveen","Yes we will be standing by should the need arise.Chris Veillette On May 30, 2017, at 5:27 PM, Praveen Kumar Muppala <praveen.muppala@reancloud.com> wrote:Hello Chris, I am sure your anticipation works the way it supposed work tonight, however by any chance, if it doesn’t go through will you be able to provide standby support to switchover manually to 1GB connection. Regards,-Praveen",We reached out to Praveen and he updated that he'll talk to SpendHQ and Andromeda team.,"Aws team confirmed the scheduled maintenance is going to affect 10Gbps which is our primary Direct Connect. after checked with Sanket, he updated to reach out to Praveena nd make a call to Andrew to discuss this. If it is going to happen 10Gbps connection we can switch to 1 Gbps at during the maintenance. Also, need to reach out Andromeda team and inform this.","Hello SpendHQ-Team, This is to notify you that we have received a notification from AWS that there will be a planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6, DC10, Ashburn, VA. Start time: May 31, 2017 at 1:30:00 PM UTC+5:30End time: May 31, 2017 at 5:30:00 PM UTC+5:30 We will raise a support ticket with AWS team to confirm the DX connections which are going to affect. We will update you once we got a reply from AWS team.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001CdlYP,Cloud Engineer Level 1,Closed,1058300,Incident,31-05-2017 18:00,,We are following in the ticket 01058275.,"Wed, 31 May 2017 08:19:10 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): London UK, Dallas-B US, California US, Frankfurt DE-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,31-05-2017 17:49,4,0,SpendHQ,We are following in the ticket 01058275.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DoyGB,Cloud Engineer Level 1,Closed,1066519,Incident,04-07-2017 08:10,,"This is to inform you that the volume usage alert for the instance PROD-SPHQ-DB-SERVER05 has resolved and returned to a normal value of 68.8%. The violation lasted for 4 hours. Regards,Safuvan KM###This is to inform you that we received an alert that the Disk utilization for the root partition in the PROD-SPHQ-DB-SERVER05 has crossed a threshold value of 90% with a value of 100%. While checking we could see that /dev/xvda1 partition has consumed 47G out of total size 50G and 255M is available on the disk. Please find the breakup details below and let us know if you can approve to delete or zip any specified files in order to resolve this issue. Please consider this as an high a priority as if the usage goes full, the instance will become inaccessible.47G     total19G     usr15G     tmp12G     var474M    home/usr:19G     total17G     local882M    share813M    lib/usr/local:17G     total17G     infobright-products100M    infobright-4.9.0-x86_64/tmp:15G     total14G     liger_view_cf0227139da65b51c8a1f7c95d143851.csv989M    liger_view_9bad59e44a03f607337211ae9a7d513e.csv221M    spark-2.1.0-bin-hadoop2.778M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm64M     liger_view_3db82f98557411ed1cfdf6d673e7a5c0.csv49M     reports44M     liger_view_3ae7710acc5a17dcd421882cea4d07f0.csv38M     liger_view_f064a104367b350eb54e043090a3c805.csv38M     liger_view_4587de86e6f613d39f748d62dfec7ac5.csv27M     spark-351c878d-7245-4f00-affa-34d5deff7414/var:12G     total7.4G    tmp2.2G    www2.1G    lib343M    log132M    cache/var/tmp:7.4G    total7.1G    robert_uploads171M    yum-mwatts-ylg2M968M     yum-centos-FX8Jlj/var/www:2.2G    vhosts2.2G    total944K    icons216K    error4.0K    html4.0K    cgi-bin/var/lib:2.1G    total1.6G    memsql-ops433M    pgsql44M     rpmResource Details:Instance Name: PROD-SPHQ-DB-SERVER05Instance ID: i-008d43ad00357e47aPrivate IPs: 10.59.10.135VPC ID: vpc-76df7212Subnet ID: subnet-0fdde924Regards,Safuvan KM","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 92.608This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3939983733030430911 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,03-07-2017 23:20,9,0,SpendHQ,"This is to inform you that the volume usage alert for the instance PROD-SPHQ-DB-SERVER05 has resolved and returned to a normal value of 68.8%. The violation lasted for 4 hours. Regards,Safuvan KM","This is to inform you that we received an alert that the Disk utilization for the root partition in the PROD-SPHQ-DB-SERVER05 has crossed a threshold value of 90% with a value of 100%. While checking we could see that /dev/xvda1 partition has consumed 47G out of total size 50G and 255M is available on the disk. Please find the breakup details below and let us know if you can approve to delete or zip any specified files in order to resolve this issue. Please consider this as an high a priority as if the usage goes full, the instance will become inaccessible.47G     total19G     usr15G     tmp12G     var474M    home/usr:19G     total17G     local882M    share813M    lib/usr/local:17G     total17G     infobright-products100M    infobright-4.9.0-x86_64/tmp:15G     total14G     liger_view_cf0227139da65b51c8a1f7c95d143851.csv989M    liger_view_9bad59e44a03f607337211ae9a7d513e.csv221M    spark-2.1.0-bin-hadoop2.778M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm64M     liger_view_3db82f98557411ed1cfdf6d673e7a5c0.csv49M     reports44M     liger_view_3ae7710acc5a17dcd421882cea4d07f0.csv38M     liger_view_f064a104367b350eb54e043090a3c805.csv38M     liger_view_4587de86e6f613d39f748d62dfec7ac5.csv27M     spark-351c878d-7245-4f00-affa-34d5deff7414/var:12G     total7.4G    tmp2.2G    www2.1G    lib343M    log132M    cache/var/tmp:7.4G    total7.1G    robert_uploads171M    yum-mwatts-ylg2M968M     yum-centos-FX8Jlj/var/www:2.2G    vhosts2.2G    total944K    icons216K    error4.0K    html4.0K    cgi-bin/var/lib:2.1G    total1.6G    memsql-ops433M    pgsql44M     rpmResource Details:Instance Name: PROD-SPHQ-DB-SERVER05Instance ID: i-008d43ad00357e47aPrivate IPs: 10.59.10.135VPC ID: vpc-76df7212Subnet ID: subnet-0fdde924Regards,Safuvan KM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Baf5E,Cloud Engineer Level 1,Closed,1052553,Incident,11-05-2017 16:14,,"Hello David,Since you have asked to keep the firewall turned off for the unscannable content until further notice, we are marking this case as resolved.Please reach out to us again when you want us to revert the changes so that we can again enable the settings to block the unscannable content.###Hello David,Thanks for the update. We will hold the current configuration setting on firewall level for preview.spendhq.com until further update from SpendHQ Team.The production, secure.spendhq.com is not coming under this current configuration manner. Let us know if your team have any further queries.###We need it turned off until further notice.  Is our Production environment setup in the same manor?Regards,David Miller###Hello David,Do we have any updates on this case? Please let us know when we can enable back the firewall profile mode to reject which will block virus affected and unscannable content.As of now, firewall profile mode is set as monitor which allows uploading any files.###As per the request from Davis, we have changed the SpendHQ Protection mode from reject to monitor. Once he is done with the changes, we need to revert back the changes.###Hello David,The firewall infront of preview.spendhq.com is an active firewall. Not a passive one. Here, if we upload any file, the firewall will perform a dual scan on the data which will block the unscannable content and filters common threats. The sample file which was uploaded earlier was holding virus which resulted in the upload to get rejected. Kindly validate these details and let us know if your team have nay further queries regarding this case.###Hello David,We acknowledge the delivery of your email.We will look on this request and will get back to you with further updates.","Can you tell me if the firewall that sits on top on preview.spendhq.com is a passive firewall in regards to file uploads?  We are uploading sample files that we want to scan for virus and other malicious files but the upload gets rejected immediately with the following:<!DOCTYPE HTML PUBLIC -//IETF//DTD HTML 2.0//EN><html><head><title>400 Bad Request</title></head><body><h1>Bad Request</h1><p>Your browser sent a request that this server could not understand.<br /><h2>Error Reason</h2>The request was blocked because an uploaded file contains a virus (Eicar-Test-Signature).</p></body></html>Thank YouDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Firewall Question,,10-05-2017 01:10,39,0,SpendHQ,"Hello David,Since you have asked to keep the firewall turned off for the unscannable content until further notice, we are marking this case as resolved.Please reach out to us again when you want us to revert the changes so that we can again enable the settings to block the unscannable content.","Hello David,Thanks for the update. We will hold the current configuration setting on firewall level for preview.spendhq.com until further update from SpendHQ Team.The production, secure.spendhq.com is not coming under this current configuration manner. Let us know if your team have any further queries.","We need it turned off until further notice.  Is our Production environment setup in the same manor?Regards,David Miller","Hello David,Do we have any updates on this case? Please let us know when we can enable back the firewall profile mode to reject which will block virus affected and unscannable content.As of now, firewall profile mode is set as monitor which allows uploading any files.","As per the request from Davis, we have changed the SpendHQ Protection mode from reject to monitor. Once he is done with the changes, we need to revert back the changes.","Hello David,The firewall infront of preview.spendhq.com is an active firewall. Not a passive one. Here, if we upload any file, the firewall will perform a dual scan on the data which will block the unscannable content and filters common threats. The sample file which was uploaded earlier was holding virus which resulted in the upload to get rejected. Kindly validate these details and let us know if your team have nay further queries regarding this case.","Hello David,We acknowledge the delivery of your email.We will look on this request and will get back to you with further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eNV61,Cloud Engineer Level 1,Closed,1107216,Incident,14-11-2018 04:48,,"Hello Team,We have received an alert regarding unused security groups as listed below .Resource ID Name Region VPC ID sg-090c124c4e47c9ba1 us-east-1 vpc-76df7212 sg-0ce80c7c us-east-1 vpc-76df7212 sg-0f2f99676c874cd34 us-east-1 vpc-76df7212 sg-161a8170 us-east-1 vpc-76df7212 sg-1a79b968 us-east-1 vpc-76df7212 sg-23e35e68 us-east-1 vpc-7837d002 sg-3732f349 us-east-1 vpc-76df7212 sg-3e849776 us-east-1 vpc-76df7212 sg-47f94b30 us-east-1 vpc-76df7212 sg-4d86243d us-east-1 vpc-76df7212 sg-4efc4c38 us-east-1 vpc-76df7212 sg-51597223 us-east-1 vpc-76df7212 sg-559fe82f DB2-Clone Security Group us-east-1 vpc-76df7212 sg-5a5c7728 us-east-1 vpc-76df7212 sg-5c63bd3a SPENDHQEast us-east-1 vpc-76df7212 sg-6663bd00 us-east-1 vpc-76df7212 sg-6723e02f us-east-1 vpc-76df7212 sg-772cfe00 us-east-1 vpc-76df7212 sg-79b5760b us-east-1 vpc-76df7212 sg-7d73ae0c us-east-1 vpc-76df7212 sg-855a34e3 us-east-1 vpc-76df7212 sg-9e869fd5 us-east-1 vpc-76df7212 sg-b18c9ff9 us-east-1 vpc-76df7212 sg-b70469ce us-east-1 vpc-76df7212 sg-b7775cc5 us-east-1 vpc-76df7212 sg-ba1f5dc4 us-east-1 vpc-76df7212 sg-be8093f6 us-east-1 vpc-76df7212 sg-c8baaeb8 us-east-1 vpc-76df7212 sg-c99f43b8 us-east-1 vpc-76df7212 sg-d24598aa us-east-1 vpc-76df7212 sg-e79089ac us-east-1 vpc-76df7212 sg-e9811f9f us-east-1 vpc-76df7212 sg-ec30819a us-east-1 vpc-76df7212 sg-f60d9f83 PRD-New-Centos-7-ELB-SG us-east-1 vpc-76df7212 sg-fc00c68d us-east-1 vpc-76df7212 sg-c23b8da6 us-west-1 vpc-e76a3982 sg-c63b8da2 us-west-1 vpc-e76a3982 sg-e087ea84 us-west-2 vpc-43cc9826 We haven't received any response from you. As of now, we are closing this case. Please let us know if you have any concerns regarding the same.###Hello Team This is a gentle reminder. Kindly check with the security groups mentioned in the previous comment and provide us the approval to remove them. Let us know if you have any queries. Thanks###Hello Team This is a gentle reminder. Kindly check with the security groups mentioned in the previous comment and provide us the approval to remove them. Let us know if you have any queries. ThanksKapil###Hello TeamThis is a quick followup regarding the Unused security group alert.Kindly check with the security groups mentioned in the previous comment and provide us the approval to remove them.Let us know if you have any queries.ThanksNishad Ali C###Hello Team,We have received an alert regarding unused security groups as listed belowResource ID Name Region VPC ID sg-090c124c4e47c9ba1 us-east-1 vpc-76df7212 sg-0ce80c7c us-east-1 vpc-76df7212 sg-0f2f99676c874cd34 us-east-1 vpc-76df7212 sg-161a8170 us-east-1 vpc-76df7212 sg-1a79b968 us-east-1 vpc-76df7212 sg-23e35e68 us-east-1 vpc-7837d002 sg-3732f349 us-east-1 vpc-76df7212 sg-3e849776 us-east-1 vpc-76df7212 sg-47f94b30 us-east-1 vpc-76df7212 sg-4d86243d us-east-1 vpc-76df7212 sg-4efc4c38 us-east-1 vpc-76df7212 sg-51597223 us-east-1 vpc-76df7212 sg-559fe82f DB2-Clone Security Group us-east-1 vpc-76df7212 sg-5a5c7728 us-east-1 vpc-76df7212 sg-5c63bd3a SPENDHQEast us-east-1 vpc-76df7212 sg-6663bd00 us-east-1 vpc-76df7212 sg-6723e02f us-east-1 vpc-76df7212 sg-772cfe00 us-east-1 vpc-76df7212 sg-79b5760b us-east-1 vpc-76df7212 sg-7d73ae0c us-east-1 vpc-76df7212 sg-855a34e3 us-east-1 vpc-76df7212 sg-9e869fd5 us-east-1 vpc-76df7212 sg-b18c9ff9 us-east-1 vpc-76df7212 sg-b70469ce us-east-1 vpc-76df7212 sg-b7775cc5 us-east-1 vpc-76df7212 sg-ba1f5dc4 us-east-1 vpc-76df7212 sg-be8093f6 us-east-1 vpc-76df7212 sg-c8baaeb8 us-east-1 vpc-76df7212 sg-c99f43b8 us-east-1 vpc-76df7212 sg-d24598aa us-east-1 vpc-76df7212 sg-e79089ac us-east-1 vpc-76df7212 sg-e9811f9f us-east-1 vpc-76df7212 sg-ec30819a us-east-1 vpc-76df7212 sg-f60d9f83 PRD-New-Centos-7-ELB-SG us-east-1 vpc-76df7212 sg-fc00c68d us-east-1 vpc-76df7212 sg-c23b8da6 us-west-1 vpc-e76a3982 sg-c63b8da2 us-west-1 vpc-e76a3982 sg-e087ea84 us-west-2 vpc-43cc9826 Please review and let us know if we can go ahead and clean up","_______________________________From: ms@reancloud.com <ms@reancloud.com>Sent: Tuesday, November 6, 2018 7:37 PMTo: spendhq-support@reancloud.comSubject: [Managed Cloud: spendhq] Unused Security Groups AlertREAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::EC2::SecurityGroup resources were affected:________________________________  *   Violation: Security group is not in use.  *   Recommendation: None  *   Action taken: None  *   Resource details:Resource ID     Name    Region  VPC IDsg-090c124c4e47c9ba1            us-east-1       vpc-76df7212sg-0ce80c7c             us-east-1       vpc-76df7212sg-0f2f99676c874cd34            us-east-1       vpc-76df7212sg-161a8170             us-east-1       vpc-76df7212sg-1a79b968             us-east-1       vpc-76df7212sg-23e35e68             us-east-1       vpc-7837d002sg-3732f349             us-east-1       vpc-76df7212sg-3e849776             us-east-1       vpc-76df7212sg-47f94b30             us-east-1       vpc-76df7212sg-4d86243d             us-east-1       vpc-76df7212sg-4efc4c38             us-east-1       vpc-76df7212sg-51597223             us-east-1       vpc-76df7212sg-559fe82f     DB2-Clone Security Group        us-east-1       vpc-76df7212sg-5a5c7728             us-east-1       vpc-76df7212sg-5c63bd3a     SPENDHQEast     us-east-1       vpc-76df7212sg-6663bd00             us-east-1       vpc-76df7212sg-6723e02f             us-east-1       vpc-76df7212sg-772cfe00             us-east-1       vpc-76df7212sg-79b5760b             us-east-1       vpc-76df7212sg-7d73ae0c             us-east-1       vpc-76df7212sg-855a34e3             us-east-1       vpc-76df7212sg-9e869fd5             us-east-1       vpc-76df7212sg-b18c9ff9             us-east-1       vpc-76df7212sg-b70469ce             us-east-1       vpc-76df7212sg-b7775cc5             us-east-1       vpc-76df7212sg-ba1f5dc4             us-east-1       vpc-76df7212sg-be8093f6             us-east-1       vpc-76df7212sg-c8baaeb8             us-east-1       vpc-76df7212sg-c99f43b8             us-east-1       vpc-76df7212sg-d24598aa             us-east-1       vpc-76df7212sg-e79089ac             us-east-1       vpc-76df7212sg-e9811f9f             us-east-1       vpc-76df7212sg-ec30819a             us-east-1       vpc-76df7212sg-f60d9f83     PRD-New-Centos-7-ELB-SG us-east-1       vpc-76df7212sg-fc00c68d             us-east-1       vpc-76df7212sg-c23b8da6             us-west-1       vpc-e76a3982sg-c63b8da2             us-west-1       vpc-e76a3982sg-e087ea84             us-west-2       vpc-43cc9826________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Managed Cloud: spendhq] Unused Security Groups Alert,,06-11-2018 19:46,177,0,SpendHQ,"Hello Team,We have received an alert regarding unused security groups as listed below .Resource ID Name Region VPC ID sg-090c124c4e47c9ba1 us-east-1 vpc-76df7212 sg-0ce80c7c us-east-1 vpc-76df7212 sg-0f2f99676c874cd34 us-east-1 vpc-76df7212 sg-161a8170 us-east-1 vpc-76df7212 sg-1a79b968 us-east-1 vpc-76df7212 sg-23e35e68 us-east-1 vpc-7837d002 sg-3732f349 us-east-1 vpc-76df7212 sg-3e849776 us-east-1 vpc-76df7212 sg-47f94b30 us-east-1 vpc-76df7212 sg-4d86243d us-east-1 vpc-76df7212 sg-4efc4c38 us-east-1 vpc-76df7212 sg-51597223 us-east-1 vpc-76df7212 sg-559fe82f DB2-Clone Security Group us-east-1 vpc-76df7212 sg-5a5c7728 us-east-1 vpc-76df7212 sg-5c63bd3a SPENDHQEast us-east-1 vpc-76df7212 sg-6663bd00 us-east-1 vpc-76df7212 sg-6723e02f us-east-1 vpc-76df7212 sg-772cfe00 us-east-1 vpc-76df7212 sg-79b5760b us-east-1 vpc-76df7212 sg-7d73ae0c us-east-1 vpc-76df7212 sg-855a34e3 us-east-1 vpc-76df7212 sg-9e869fd5 us-east-1 vpc-76df7212 sg-b18c9ff9 us-east-1 vpc-76df7212 sg-b70469ce us-east-1 vpc-76df7212 sg-b7775cc5 us-east-1 vpc-76df7212 sg-ba1f5dc4 us-east-1 vpc-76df7212 sg-be8093f6 us-east-1 vpc-76df7212 sg-c8baaeb8 us-east-1 vpc-76df7212 sg-c99f43b8 us-east-1 vpc-76df7212 sg-d24598aa us-east-1 vpc-76df7212 sg-e79089ac us-east-1 vpc-76df7212 sg-e9811f9f us-east-1 vpc-76df7212 sg-ec30819a us-east-1 vpc-76df7212 sg-f60d9f83 PRD-New-Centos-7-ELB-SG us-east-1 vpc-76df7212 sg-fc00c68d us-east-1 vpc-76df7212 sg-c23b8da6 us-west-1 vpc-e76a3982 sg-c63b8da2 us-west-1 vpc-e76a3982 sg-e087ea84 us-west-2 vpc-43cc9826 We haven't received any response from you. As of now, we are closing this case. Please let us know if you have any concerns regarding the same.",Hello Team This is a gentle reminder. Kindly check with the security groups mentioned in the previous comment and provide us the approval to remove them. Let us know if you have any queries. Thanks,Hello Team This is a gentle reminder. Kindly check with the security groups mentioned in the previous comment and provide us the approval to remove them. Let us know if you have any queries. ThanksKapil,Hello TeamThis is a quick followup regarding the Unused security group alert.Kindly check with the security groups mentioned in the previous comment and provide us the approval to remove them.Let us know if you have any queries.ThanksNishad Ali C,"Hello Team,We have received an alert regarding unused security groups as listed belowResource ID Name Region VPC ID sg-090c124c4e47c9ba1 us-east-1 vpc-76df7212 sg-0ce80c7c us-east-1 vpc-76df7212 sg-0f2f99676c874cd34 us-east-1 vpc-76df7212 sg-161a8170 us-east-1 vpc-76df7212 sg-1a79b968 us-east-1 vpc-76df7212 sg-23e35e68 us-east-1 vpc-7837d002 sg-3732f349 us-east-1 vpc-76df7212 sg-3e849776 us-east-1 vpc-76df7212 sg-47f94b30 us-east-1 vpc-76df7212 sg-4d86243d us-east-1 vpc-76df7212 sg-4efc4c38 us-east-1 vpc-76df7212 sg-51597223 us-east-1 vpc-76df7212 sg-559fe82f DB2-Clone Security Group us-east-1 vpc-76df7212 sg-5a5c7728 us-east-1 vpc-76df7212 sg-5c63bd3a SPENDHQEast us-east-1 vpc-76df7212 sg-6663bd00 us-east-1 vpc-76df7212 sg-6723e02f us-east-1 vpc-76df7212 sg-772cfe00 us-east-1 vpc-76df7212 sg-79b5760b us-east-1 vpc-76df7212 sg-7d73ae0c us-east-1 vpc-76df7212 sg-855a34e3 us-east-1 vpc-76df7212 sg-9e869fd5 us-east-1 vpc-76df7212 sg-b18c9ff9 us-east-1 vpc-76df7212 sg-b70469ce us-east-1 vpc-76df7212 sg-b7775cc5 us-east-1 vpc-76df7212 sg-ba1f5dc4 us-east-1 vpc-76df7212 sg-be8093f6 us-east-1 vpc-76df7212 sg-c8baaeb8 us-east-1 vpc-76df7212 sg-c99f43b8 us-east-1 vpc-76df7212 sg-d24598aa us-east-1 vpc-76df7212 sg-e79089ac us-east-1 vpc-76df7212 sg-e9811f9f us-east-1 vpc-76df7212 sg-ec30819a us-east-1 vpc-76df7212 sg-f60d9f83 PRD-New-Centos-7-ELB-SG us-east-1 vpc-76df7212 sg-fc00c68d us-east-1 vpc-76df7212 sg-c23b8da6 us-west-1 vpc-e76a3982 sg-c63b8da2 us-west-1 vpc-e76a3982 sg-e087ea84 us-west-2 vpc-43cc9826 Please review and let us know if we can go ahead and clean up",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hSVvm,Cloud Engineer Level 1,Closed,1110431,Incident,11-01-2019 03:54,,"Hello Chris,Thank you for the update. Soon, we will log out the initiators which are not in use and you can perform the cleanup. For now, we can close this case.@Rohit Puri- Please create a new ticket to see the unused iSCSI disks and send it to SpendHQ team for review and then plan for cleanup.###Hello Chris,Let us further investigate this issue and will get back to with more detailed analysis.Thanks###Hi - I took a extensive look at our environment and found no issues on the storage end that would cause the initiator errors - which makes sense since initiators are launched on the server / host side. There have been zero config changes in weeks (probably months).Chris###Hello Team,This is a gentle reminder. We waiting for further updates from your end regarding this ISCSI issue. Please let us know if you have any updates.###Hello Chris, Thank you for your updated response. We will await for further updates from your end regarding this ISCSI issue.###Ok I will look at this thus PM -  but generally any “initiator” issue is addressed on the machine side - we are just an “iSCSI target” Thanks,Chris###Hello Team,This is a quick followup.Please review our previous shared analysis regarding getting initiator error on the instance 10.59.10.135 and let us know your thoughts on the same.Thanks,###Hello SpendHQ-Team,On further checking the details from the instance 10.59.10.135, we could see only one ISCSI volume (/dev/sdao) mounted on the instance under the directory  /mnt/production_25_08_2018 and we cloud see there are a lot of ISCSI volumes logged in from the instance level. Please see the attached list of iqn names and kindly validate from your end and kindly let us know if we can log off from the ISCSI volume as these are generating lots of login error. Note: there is no downtime to log off from these  ISCSI volumes.###Hello Chris, The issue still persist on the server 10.59.10.135 and we can see the messages logs are still flooding with an error of iscsid: conn 0 login rejected: initiator error (02/04). Can we have a call to understand and resolve the same? Please let me know your availability. Thanks !",can you check instance 64d02cf7e3df - ip 10.59.10.135 I am getting an error in my end complaining that “login was rejected due to initiator error”...... it is filling up my error log file .... Chris Veillette,Getting  initiator error on the instance 10.59.10.135,,08-01-2019 19:15,57,0,SpendHQ,"Hello Chris,Thank you for the update. Soon, we will log out the initiators which are not in use and you can perform the cleanup. For now, we can close this case.@Rohit Puri- Please create a new ticket to see the unused iSCSI disks and send it to SpendHQ team for review and then plan for cleanup.","Hello Chris,Let us further investigate this issue and will get back to with more detailed analysis.Thanks",Hi - I took a extensive look at our environment and found no issues on the storage end that would cause the initiator errors - which makes sense since initiators are launched on the server / host side. There have been zero config changes in weeks (probably months).Chris,"Hello Team,This is a gentle reminder. We waiting for further updates from your end regarding this ISCSI issue. Please let us know if you have any updates.","Hello Chris, Thank you for your updated response. We will await for further updates from your end regarding this ISCSI issue.","Ok I will look at this thus PM -  but generally any “initiator” issue is addressed on the machine side - we are just an “iSCSI target” Thanks,Chris","Hello Team,This is a quick followup.Please review our previous shared analysis regarding getting initiator error on the instance 10.59.10.135 and let us know your thoughts on the same.Thanks,","Hello SpendHQ-Team,On further checking the details from the instance 10.59.10.135, we could see only one ISCSI volume (/dev/sdao) mounted on the instance under the directory  /mnt/production_25_08_2018 and we cloud see there are a lot of ISCSI volumes logged in from the instance level. Please see the attached list of iqn names and kindly validate from your end and kindly let us know if we can log off from the ISCSI volume as these are generating lots of login error. Note: there is no downtime to log off from these  ISCSI volumes.","Hello Chris, The issue still persist on the server 10.59.10.135 and we can see the messages logs are still flooding with an error of iscsid: conn 0 login rejected: initiator error (02/04). Can we have a call to understand and resolve the same? Please let me know your availability. Thanks !",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G0000159smm,Cloud Engineer Level 1,Closed,1038420,Incident,17-12-2016 09:56,,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Chris from A3, kindly performed the backup just now. I will drop an email over on Monday to advise on next steps. We can close this case for now.###Hi Andrew,As decided let us know whether you are performing the maintenance and update us if you need any assistance from our end.###Hello Matthew,Andromeda team confirmed that they will be available for the maintenance on Friday evening 23:00 EST hours.Once they provided us with the volume, we will mount it on db5 server.Thanks.###Hi Team,@Andromedateam: Please let us know whether we can perform the action on  Friday evening 23:00 EST hours.###Hello Matthew,Thanks for the update. We can do it on Friday evening 23:00 EST hours. Once Chris provided the volume we will ready to mount it on DB5 server.@Andromedateam: Please let us know whether we can do it on as per the above mentioned time.###Chris updated that  it would take all-told around 5 mins to take snapshot and Matthew asked whether we can do it on Friday 23:00 EST time.###The latter is the better option. Can we get timeframes for this before continuing. Perhaps we have an old backup we can use to prevent from having downtime.###Hi Matthew,Based on our analysis we can perform this by 2 ways.1. We can take DB dump and using the default MySQL dump it quickly spirals the server load out of control and locks up everything affecting the users. To dump large tables we can use single transaction with  option --quick. Taking the db dump will take 2-3 days based on the size of data. In this case there will be slight performance issue.2. To take the snapshot of the ISCSI volume with help of Andromeda team and attach it to the new DB. In this case, we need to stop the write operations which will require a downtime.@Andromeda Team: Could you please let us know how much time it will take to create the snapshot of ISCSI volume.  The total size is 4TB in which 1.5TB is currently used.Based on the time it will take to create the snapshot we can determine the total downtime.Please let us know your thoughts on this.###Do we have an update on this?###Hello Matthew,We will check internally and will let you know the updates.###We are looking to get the latest copy of the data from 10.59.10.12 and make it accessible on this machine. It does not have to be in any specific location but ideally would be mounted under /var/infobright. Regardless of which option is chosen the data cannot be symlinked from 10.59.10.12 and has to be a full backup. It cannot cause any downtime either. Please advise if you are unsure of anything or have any further questions.###Hello Matthew,We have checked the server and we have found the iscsi disk /dev/sdc which is mounted on  /var/infobright. So please confirm the backup details so that we will ask Andromeda team to take proper backup.###Hi Matthew,We will check on this and let you know the update.","Can we request a backup to be made of the database on PRD-DB2 (10.59.10.12) without affecting PRD. As soon as this is done can we mount that backup to DB5 (10.59.10.135).Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Database Backup,,12-12-2016 20:36,109,0,SpendHQ,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Chris from A3, kindly performed the backup just now. I will drop an email over on Monday to advise on next steps. We can close this case for now.","Hi Andrew,As decided let us know whether you are performing the maintenance and update us if you need any assistance from our end.","Hello Matthew,Andromeda team confirmed that they will be available for the maintenance on Friday evening 23:00 EST hours.Once they provided us with the volume, we will mount it on db5 server.Thanks.","Hi Team,@Andromedateam: Please let us know whether we can perform the action on  Friday evening 23:00 EST hours.","Hello Matthew,Thanks for the update. We can do it on Friday evening 23:00 EST hours. Once Chris provided the volume we will ready to mount it on DB5 server.@Andromedateam: Please let us know whether we can do it on as per the above mentioned time.",Chris updated that  it would take all-told around 5 mins to take snapshot and Matthew asked whether we can do it on Friday 23:00 EST time.,The latter is the better option. Can we get timeframes for this before continuing. Perhaps we have an old backup we can use to prevent from having downtime.,"Hi Matthew,Based on our analysis we can perform this by 2 ways.1. We can take DB dump and using the default MySQL dump it quickly spirals the server load out of control and locks up everything affecting the users. To dump large tables we can use single transaction with  option --quick. Taking the db dump will take 2-3 days based on the size of data. In this case there will be slight performance issue.2. To take the snapshot of the ISCSI volume with help of Andromeda team and attach it to the new DB. In this case, we need to stop the write operations which will require a downtime.@Andromeda Team: Could you please let us know how much time it will take to create the snapshot of ISCSI volume.  The total size is 4TB in which 1.5TB is currently used.Based on the time it will take to create the snapshot we can determine the total downtime.Please let us know your thoughts on this.",Do we have an update on this?,"Hello Matthew,We will check internally and will let you know the updates.",We are looking to get the latest copy of the data from 10.59.10.12 and make it accessible on this machine. It does not have to be in any specific location but ideally would be mounted under /var/infobright. Regardless of which option is chosen the data cannot be symlinked from 10.59.10.12 and has to be a full backup. It cannot cause any downtime either. Please advise if you are unsure of anything or have any further questions.,"Hello Matthew,We have checked the server and we have found the iscsi disk /dev/sdc which is mounted on  /var/infobright. So please confirm the backup details so that we will ask Andromeda team to take proper backup.","Hi Matthew,We will check on this and let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DnQ0F,Cloud Engineer Level 1,Closed,1065332,Incident,28-06-2017 08:55,,"Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 3.041 after that the alert got resolved automatically and return to a normal state with the value of 2.945.","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.041This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3931641225144178925 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,28-06-2017 05:12,4,0,SpendHQ,"Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 3.041 after that the alert got resolved automatically and return to a normal state with the value of 2.945.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Eukuz,Cloud Engineer Level 1,Closed,1071188,Incident,02-08-2017 06:16,,"Hello Team,We are closing this case for now.We will be following up with you over the change ticket regarding the updates for the network driver change.###Matthew replied:Perfect. Yes please. Dan will be leading this. He has been attached to the email.###Hello Team,We can schedule this change to 11:30 PM EST (9 AM IST) today.Please let us know if this is approved so that we can go ahead and make the required changes.###Hello Team,As discussed over the call with Matthew, We have performed a stop and start for the PROD-SPHQ-WEB-SERVER03_4th_July_2017 instance and it has resolved the issue of failed instance status checks.Also, As per our discussion, We will be checking with our team internally if we can create an image of this server and make the network driver update on it and then point the ELB to the new server.We will get back to you with the updates shortly.Kindly let us know if you have any other queries.###Hello Team,We have received site down alert for the URL https://secure.spendhq.com/login.We are not able to access the site. We will analyze the issue and meanwhile, please let us know if you are performing any activity from your end.","Tue, 01 Aug 2017 16:49:02 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30003 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Frankfurt DE, Dallas-B US, Atlanta-B US, London UK-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,02-08-2017 02:19,4,0,SpendHQ,"Hello Team,We are closing this case for now.We will be following up with you over the change ticket regarding the updates for the network driver change.",Matthew replied:Perfect. Yes please. Dan will be leading this. He has been attached to the email.,"Hello Team,We can schedule this change to 11:30 PM EST (9 AM IST) today.Please let us know if this is approved so that we can go ahead and make the required changes.","Hello Team,As discussed over the call with Matthew, We have performed a stop and start for the PROD-SPHQ-WEB-SERVER03_4th_July_2017 instance and it has resolved the issue of failed instance status checks.Also, As per our discussion, We will be checking with our team internally if we can create an image of this server and make the network driver update on it and then point the ELB to the new server.We will get back to you with the updates shortly.Kindly let us know if you have any other queries.","Hello Team,We have received site down alert for the URL https://secure.spendhq.com/login.We are not able to access the site. We will analyze the issue and meanwhile, please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001S68Lw,Cloud Engineer Level 1,Closed,1092846,Incident,13-03-2018 08:24,,"Hello Andrew,Thanks for the update.At this time we are marking this case as resolved. Please revert back to us if you have any queries.###This case may be closed. Thank you###Hello Team, This is a gentle reminder, Please review the details mentioned in the previous comment and let us know if you have any queries.###Hello Team,This is a gentle reminder,Please review the details mentioned in the previous comment and let us know if you have any questions or we are good to close this case.###Hello SpendHQ Team We have completed the analysis and we could confirm that the site was not actually down at the time of the alert but the wormly triggered alert due to the high latency on the website. Also, we could see the sum requests went high during this time period. From the attached ELB logs it is clear that there were many requests with high backend processing time.As this was not usual traffic please let us know if you were performing any activity from your end at the time of the alert. Also, let us know if you have any questions or we are good to close this case.###Need to further check on this and update customer###Hello Team,We further analyzed the issue and the url https://preview.spendhq.com/login pointed to preview-spendhq-xelb load balancer which is then redirected to internal load balancer Preview-api-spendhq-com through Sophos WAF. We have checked the ELB monitoring and found that the Latency and request count was hight at the time of the alert. The 4XX and 5XX  was normal at the time of the alert.   Please find the attached ELB graphs and Logs. The site was not actually down and this was a nonproduction site. We are reducing the priority to P2.###Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. The alert got resolved within one minute and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.","Fri, 09 Mar 2018 12:19:20 -0500Detected Error on SpendHQ PreviewEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30004 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: Atlanta-B USConfirmed by node(s): London UK, Frankfurt DE, Dallas-B US, California US-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,09-03-2018 22:49,81,0,SpendHQ,"Hello Andrew,Thanks for the update.At this time we are marking this case as resolved. Please revert back to us if you have any queries.",This case may be closed. Thank you,"Hello Team, This is a gentle reminder, Please review the details mentioned in the previous comment and let us know if you have any queries.","Hello Team,This is a gentle reminder,Please review the details mentioned in the previous comment and let us know if you have any questions or we are good to close this case.","Hello SpendHQ Team We have completed the analysis and we could confirm that the site was not actually down at the time of the alert but the wormly triggered alert due to the high latency on the website. Also, we could see the sum requests went high during this time period. From the attached ELB logs it is clear that there were many requests with high backend processing time.As this was not usual traffic please let us know if you were performing any activity from your end at the time of the alert. Also, let us know if you have any questions or we are good to close this case.",Need to further check on this and update customer,"Hello Team,We further analyzed the issue and the url https://preview.spendhq.com/login pointed to preview-spendhq-xelb load balancer which is then redirected to internal load balancer Preview-api-spendhq-com through Sophos WAF. We have checked the ELB monitoring and found that the Latency and request count was hight at the time of the alert. The 4XX and 5XX  was normal at the time of the alert.   Please find the attached ELB graphs and Logs. The site was not actually down and this was a nonproduction site. We are reducing the priority to P2.","Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. The alert got resolved within one minute and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016pc6m,Cloud Engineer Level 1,Closed,1042418,Incident,24-01-2017 06:02,,"We had a Discussion about sticky session configuration as SpendHQ is going to have a new release by end of february.Need to check how sticky sessions are going to work since sophos WAF configured on the instance .All the traffic from loadbalancer goes through Sophos WAF to the the backend instance.###Hello Matthew,We acknowledge the delivery of your email.Rean Team will be available for the meeting and will get back to you with further details.###Correction: I added the wrong date. This was meant to be Monday 23rd January 2017.","Rean Team,Can we please meet for 30 minutes on Monday 22nd January at 1600 Hours to go over the Load Balancing Solution for the upcoming release.Thank you.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Meeting,,20-01-2017 01:55,1866,0,SpendHQ,We had a Discussion about sticky session configuration as SpendHQ is going to have a new release by end of february.Need to check how sticky sessions are going to work since sophos WAF configured on the instance .All the traffic from loadbalancer goes through Sophos WAF to the the backend instance.,"Hello Matthew,We acknowledge the delivery of your email.Rean Team will be available for the meeting and will get back to you with further details.",Correction: I added the wrong date. This was meant to be Monday 23rd January 2017.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gdk14,Cloud Engineer Level 1,Closed,1109810,Incident,22-12-2018 01:50,,"Hello Team,This is to inform you that the alert High CPU Load on host spendhq-memsql-server3-2018-04-01(10.59.100.230) got recovered and the violation lasted for 30 minutes.As the alert in the recovered state, we are marking this case as resolved and hence closing this case. Kindly revert back to us in case of any queries.###Hello Team,We have received an alert regarding High CPU Load on host spendhq-memsql-server3-2018-04-01(10.59.100.230). We will check this alert and will get back to you.","---------- Forwarded message ---------From: Datadog Alerting <alert@dtdg.co>Date: Sat, Dec 22, 2018 at 1:07 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on hostspendhq-memsql-server3-2018-04-01 - 10.59.100.230 -To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High CPU Load on hostspendhq-memsql-server3-2018-04-01 - 10.59.100.230 -Detected High CPU load. Log in to the machine and verify which process isconsuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023975?to_ts=1545421005000&group=host%3Ai-093eff6fae479397c&from_ts=1545413805000>*system.load.15* over *datadog_monitor:on,host:i-093eff6fae479397c* was *>40.0* on average during the *last 1h*.The monitor was last triggered at Fri Dec 21 2018 19:36:55 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023975?group=host%3Ai-093eff6fae479397c>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023975/edit>] · [Viewi-093eff6fae479397c<https://app.datadoghq.com/infrastructure?filter=i-093eff6fae479397c>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1545421135000&tags=host%3Ai-093eff6fae479397c&from_ts=1545420115000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4717051052977372123>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on host spendhq-memsql-server3-2018-04-01 - 10.59.100.230 -,,22-12-2018 01:32,6,0,SpendHQ,"Hello Team,This is to inform you that the alert High CPU Load on host spendhq-memsql-server3-2018-04-01(10.59.100.230) got recovered and the violation lasted for 30 minutes.As the alert in the recovered state, we are marking this case as resolved and hence closing this case. Kindly revert back to us in case of any queries.","Hello Team,We have received an alert regarding High CPU Load on host spendhq-memsql-server3-2018-04-01(10.59.100.230). We will check this alert and will get back to you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5002I00001m2R5d,Cloud Engineer Level 1,Awaiting Customer Response,1114076,Incident,21-03-2019 03:54,,"Hello Team,This is a quick followup.Please let us know whether Robert is facing any issues in logging in to the Sophos web admin portal or whether we are good to close this case. Thank you.###Hello Team, This is to inform you that we are receiving multiple alerts regarding too many failed logins from 159.100.161.41 for facility openvpn. From checking the logs, we can see that the new robert user is having issue: --------------------------------------------------------------------------------------------------------- srcip=159.100.161.41 host= user=robert caller=openvpn reason=DENIED2019:03:19-21:23:46 spendhq aua[30702]: [WARN-070] Too many failed logins2019:03:19-21:25:53 spendhq aua[3210]: id=3005 severity=warn sys=System sub=auth name=Authentication failed srcip=159.100.161.41 host= user=robert caller=openvpn reason=Too many failures from client 159.100.161.41, still blocked for 173 seconds2019:03:19-21:26:06 spendhq aua[3210]: id=3005 severity=warn sys=System sub=auth name=Authentication failed srcip=159.100.161.41 host= user=robert caller=openvpn reason=Too many failures from client 159.100.161.41, still blocked for 160 seconds2019:03:19-21:27:46 spendhq aua[3210]: id=3005 severity=warn sys=System sub=auth name=Authentication failed srcip=159.100.161.41 host= user=robert caller=openvpn reason=Too many failures from client 159.100.161.41, still blocked for 60 seconds--------------------------------------------------------------------------------------------------------- Please let us know if the user Robert is facing any issues so we will be resetting the password.Thanks.",Too many failed logins from 159.100.161.41 for facility openvpn.Further logins will be blocked for 300 seconds.Account Name - SpendHQAccount DL - rean_spendhq_support@hitachivantara.comUTM Hostname - spendhq-utmPrivate IP - 10.59.1.192Public IP - 52.0.17.10Device URL - https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2F52.0.17.10%3A4444&amp;data=01%7C01%7Cathira.pk%40hitachivantara.com%7Ca53d57e066e64ca6f65608d6a0e4fa49%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=TpsSHULqx0fVGFHGqhgxxiR7ioAnk%2B%2B7u4sHdpakflM%3D&amp;reserved=0--System Uptime      : 282 days 15 hours 59 minutesSystem Load        : 0.16System Version     : Sophos UTM 9.509-3Please refer to the manual for detailed instructions.,[SpendHQ] [10.59.1.192] [WARN-070] Too many failed logins,,20-03-2019 05:54,30,1,SpendHQ,"Hello Team,This is a quick followup.Please let us know whether Robert is facing any issues in logging in to the Sophos web admin portal or whether we are good to close this case. Thank you.","Hello Team, This is to inform you that we are receiving multiple alerts regarding too many failed logins from 159.100.161.41 for facility openvpn. From checking the logs, we can see that the new robert user is having issue: --------------------------------------------------------------------------------------------------------- srcip=159.100.161.41 host= user=robert caller=openvpn reason=DENIED2019:03:19-21:23:46 spendhq aua[30702]: [WARN-070] Too many failed logins2019:03:19-21:25:53 spendhq aua[3210]: id=3005 severity=warn sys=System sub=auth name=Authentication failed srcip=159.100.161.41 host= user=robert caller=openvpn reason=Too many failures from client 159.100.161.41, still blocked for 173 seconds2019:03:19-21:26:06 spendhq aua[3210]: id=3005 severity=warn sys=System sub=auth name=Authentication failed srcip=159.100.161.41 host= user=robert caller=openvpn reason=Too many failures from client 159.100.161.41, still blocked for 160 seconds2019:03:19-21:27:46 spendhq aua[3210]: id=3005 severity=warn sys=System sub=auth name=Authentication failed srcip=159.100.161.41 host= user=robert caller=openvpn reason=Too many failures from client 159.100.161.41, still blocked for 60 seconds--------------------------------------------------------------------------------------------------------- Please let us know if the user Robert is facing any issues so we will be resetting the password.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ETHu6,Cloud Engineer Level 1,Closed,1067270,Incident,10-07-2017 10:12,,"Hello Spendhq Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0. The alert got resolved automatically and return to a normal state with the value of 2.948.###Hello Team, This is to notify you that we have received an alert that High CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 4.907","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 4.907This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3949273396144548514 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,10-07-2017 09:08,1,0,SpendHQ,"Hello Spendhq Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0. The alert got resolved automatically and return to a normal state with the value of 2.948.","Hello Team, This is to notify you that we have received an alert that High CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 4.907",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001SVGd2,Cloud Engineer Level 1,Closed,1093224,Incident,16-03-2018 06:50,,"Hello SpendHQ Team On further analysis and we could confirm that the site was not actually down at the time of the alert but the wormly triggered alert due to the high latency on the website. Also, we could see the sum requests went high during this time period. From the attached ELB logs Please let us know if you have any queries on this.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Hello SpendHQ Team On further analysis and we could confirm that the site was not actually down at the time of the alert but the wormly triggered alert due to the high latency on the website. Also, we could see the sum requests went high during this time period. From the attached ELB logs Pleas let us know if you have any queries on this.###Hello SpendHQ Team On further analysis and we could confirm that the site was not actually down at the time of the alert but the wormly triggered alert due to the high latency on the website. Also, we could see the sum requests went high during this time period. From the attached ELB logs Also, let us know if you have any queries on this.###Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. The alert got resolved within one minute and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.","Tue, 13 Mar 2018 15:43:44 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: Atlanta-B USConfirmed by node(s): Dallas-B US, London UK, Sydney-C AU, Frankfurt DE-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,14-03-2018 01:13,54,0,SpendHQ,"Hello SpendHQ Team On further analysis and we could confirm that the site was not actually down at the time of the alert but the wormly triggered alert due to the high latency on the website. Also, we could see the sum requests went high during this time period. From the attached ELB logs Please let us know if you have any queries on this.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Hello SpendHQ Team On further analysis and we could confirm that the site was not actually down at the time of the alert but the wormly triggered alert due to the high latency on the website. Also, we could see the sum requests went high during this time period. From the attached ELB logs Pleas let us know if you have any queries on this.","Hello SpendHQ Team On further analysis and we could confirm that the site was not actually down at the time of the alert but the wormly triggered alert due to the high latency on the website. Also, we could see the sum requests went high during this time period. From the attached ELB logs Also, let us know if you have any queries on this.","Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. The alert got resolved within one minute and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001i6br0,Cloud Engineer Level 2,Closed,1110746,Incident,28-01-2019 23:39,,"Hello Team,As mentioned earlier, the issue is resolved.On that note we are marking this case as closed.Please let us know if you have any concerns.Thanks.###@Team:Do a final follow up and close this.###@team,Please check with CC if we can close the case as we have done with 5 follow-ups.###Hello Team,We haven't heard back from you regarding the case for a while. Please go through the analysis we shared with you earlier. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.Regards,Rafi R###@TeamDone more than three follow-ups, Check with CC  whether we can close this case or not###Hello Matthew,We haven't heard back from you.The issue seems to be resolved, the site is also running up and fine. For now, we are reducing the priority of this ticket from P2 to P4.We will be looking forward to your response, please review the complete analysis shared here and let us know if you have any queries regarding it.###Hello Matthew,Just a quick email to see if there is an update on this case. Please have a look on the analysis that we have shared and let us know if you have any queries. Thank you.###Hello Team,This is a gentle reminder regarding the site down alert for URL:  https://secure.spendhq.com/login.Kindly review the shared analysis and let us know if you have any questions or concerns.###Hello Matthew, We haven't heard back from you regarding this case. Kindly review the shared analysis and let us know if you have any questions or concerns. Thanks###Hello TeamWe have again analyzed the logs and could find the same latency issue which caused the alert to get triggered.Kindly check with the analysis already shared with you and let us know if we have any queries.Thanks###@Rohit I had gone on chat with AWs support team regarding the Datapoint missing in the ELB Metrics and they updated that may be caused as the data was not present at the time.Later I had shared the ELB logs to the AWS team  they mentioned the following after analyzing the logs1.from logs they could only see latency 2. regarding the GAP in Datapoints in metric, When Latency metric is considered the GAP may be there and its don't  related to any connectivity issue###Hello TeamWe have again received site down alert for the same URL. We could see that the site is not actually down. We could see spike in the latency as similar to previous alerts.We will analyze more on this and will let you know the updates.Thanks###@Rohit, We have performed an analysis on recent site down alerts triggered at 3:31 AM And 3:40 AM IST.Upon checking the Cloudwatch metrics from on Secure ELB and UTM server everything looks normal.While checking the CloudWatch metrics for NewPreview ELB we can see there was a break in the metrics graph for two times. There are two instances attached to this ELB, for both the instances all the metrics are not for that time around.We verified all network, CPU metrics and can see that metrics are breaking for two times and for the interval of approx 10 minutes. Please let us know if we can go ahead and raise a support ticket with AWS to further investigate the issue. https://docs.google.com/document/d/1ARnI73bQB-ilCOeKx1_jW_iDiv0NYZRQEgkxmJDc2UA/edit?usp=sharingApart from this, we have also verified the ELB logs as well but we didn't find any URL which was taking higher than normal backend processing time. https://docs.google.com/spreadsheets/d/1vzYJp5HrRs0UGxgAIhPjnDfM7bcW7U-YGGynk4Td-Dg/edit?usp=sharingWe have verified all backend instances of both ELB's system logs as well but no issue found.###Hello Team,We are continuously receiving site down alerts for the URL: https://secure.spendhq.com/login which is getting recovered automatically in a minute. Upon checking the URL was loading slowly but it was up.We are analyzing more on this issue and will update you soon.###Hello Team,As mentioned earlier, below is the log analysis related to the site down alert. We have fetched logs for 1 hour within the time we received the alert.We had a total of 13902 (2xx+4xx+5xx) logs generated during the time period.Top URLs with 2xx response code:GET https://secure.spendhq.com:443/login HTTP/1.1  count 1955HEAD https://secure.spendhq.com:443/login HTTP/1.1 count 118GET https://secure.spendhq.com:443/spend-visibility HTTP/1.1 count 46GET https://secure.spendhq.com:443/css/jquery.tooltip.css?1499356036 HTTP/1.1 count 45GET https://secure.spendhq.com:443/css/css.5.5.css?1544891945 HTTP/1.1 count 44Top URLs with 4xx response code;POST https://secure.spendhq.com:443/errors/report/js HTTP/1.1 count 1945GET https://secure.spendhq.com:443/css/images/throbber.gif HTTP/1.1 count 61GET https://secure.spendhq.com:443/images/sort_both.png HTTP/1.1 count 3Top URLs with 5xx response code:GET https://secure.spendhq.com:443/login HTTP/1.1 count 48HEAD https://secure.spendhq.com:443/ HTTP/1.1 count 12GET https://secure.spendhq.com:443/ HTTP/1.1 count 11We had only one IP: 10.59.1.192 for all the requests and it is an internal IP for the PROD-SPHQ-SOPHOS-UTM-VPN01 instance.Below are the log details for the Secure-SpendHQ-ELB for 1 hour.We had a total of 13714 (2xx+4xx+5xx) logs generated.Top IPs with 2xx response:50.232.133.1  Requests > 1049159.100.161.41 Requests > 92383.70.73.108    Requests > 90999.108.156.53  Requests > 667Top IPs with 4xx response:146.247.40.253 Requests > 157976.191.72.1  Requests > 636209.165.134.1  Requests > 633208.87.236.201 Requests > 291Top IPs with 5xx response:54.245.168.2 Requests > 554.232.40.98 Requests > 554.228.16.34 Requests > 4Top URLs with high request count:GET https://secure.spendhq.com:443/login HTTP/1.1  count > 1939HEAD https://secure.spendhq.com:443/login HTTP/1.1 count > 114POST https://secure.spendhq.com:443/errors/report/js HTTP/1.1 > count 1944GET https://secure.spendhq.com:443/css/images/throbber.gif HTTP/1.1 count > 60GET https://secure.spendhq.com:443/login HTTP/1.1 count > 47HEAD https://secure.spendhq.com:443/ HTTP/1.1 count 12We checked the validity of the IPs and we could not find any of the listed IPs with any type of abuse.Kindly review the logs for both the ELBs on the attachment section and let us know your thoughts on the same.###Hello Team,On checking logs, we could see PHP fatal error. Please find them below:[Tue Jan 15 11:35:01 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com                                                                                /reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 11:35:01 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760[Tue Jan 15 11:35:01 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760[Tue Jan 15 11:35:01 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com                                                                                /reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 11:35:01 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com                                                                                /reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 11:35:02 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com                                                                                /reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 11:35:02 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com                                                                                /reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 11:35:03 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760[Tue Jan 15 11:35:03 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760[Tue Jan 15 11:35:03 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760###@Team,Please share the ELB logs with the customer.###Hello Team,On further checking from AWS console, we could see that there are spikes in latency and request count and at the same time spikes in HTTP 4xx matrics of the load balancer NewPreview-ELB.  We have checked the backend server (PRD-WW1_122 and PRD-WW2-11-01-2019) behavior and found that the CPU utilization was high (around 92%) on the server PRD-WW1_122. Other than we can see the spikes in network IN/Out matrics on both server.We could see that the connections were also high on the server 10.59.100.122 at the time of the alert.[root@ip-10-59-100-122 log]# netstat | grep TIME_WAIT | wc -l 1280[root@ip-10-59-100-207 log]# netstat | grep TIME_WAIT | wc -l136On checking the system logs of the server 10.59.100.122, we found that one of the several running httpd process with PID 21717 got killed by the “Out Of Memory killer” of Kernel. Please find the logs for the same below: Jan 15 16:27:55 ip-10-59-100-122 kernel: Out of memory: Kill process 21717 (httpd) score 125 or sacrifice childJan 15 16:27:55 ip-10-59-100-122 kernel: Killed process 21717, UID 48, (httpd) total-vm:8250616kB, anon-rss:7877840kB, file-rss:928kBWe have checked the other instances logs and did not find anything suspicious. Kindly review our findings and let us know if you have any more queries. We are now analyzing the ELB logs and will share with you shortly.###Hello Team,The site is accessible now. The alert got recovered in 14 minutes. We are looking into this and will update you.###Hello Team,We have again received the site down alert for URL: https://secure.spendhq.com/login. We are analyzing this and will be sharing more info. Thanks.###The site is up and running well. We have disabled the maintenance.###@TeamAs mentioned by Rohit, I had muted the URL  in wormly###Hello TeamWe again received site down alert for the same URL. All the alerts that we received today got recovered within 1 minute.We had analyzed the alert and could see the same issue of latency and high request count. The highest latency recorded in the log at the time of alert is 97.26 seconds.Kindly check with the logs and screenshots attached and get back to us if you have any queries.Thanks###Hello TeamOn our further analysis, we checked with the ELB logs for both internal facing Secure-SpendHQ-ELB load balancer and the internal ELB NewPreview-ELB load balance at the time frame of 3 hours over which we got multiple alerts. we found that there are 5763 of 403 responses from the Secure-SpendHQ-ELB logs and 5968 of 403 responses in the NewPreview-ELB logs.We could see that most of the Request was coming from the below four IP1. 98.253.118.1562.76.191.72.13.209.165.134.14. 103.213.251.95We had checked with the abusive Rating of the Above IPs and could see thattwo of them are abusive. 1. IP:	98.253.118.156Hostname:	c-98-253-118-156.hsd1.il.comcast.netISP:	Comcast CableOrganization:	Comcast CableContinent:	North AmericaCountry:	United States us flagState/Region:	IllinoisCity:	Forest Park2. IP:	103.213.251.95Hostname:	103.213.251.95Organization:	Cloudie LimitedContinent:	AsiaCountry:	Hong Kong hk flagWe have blocked the HongKong IP.(103.213.251.95).Kindly check with the other IP and also with the attached ELB logs and let us know if you have any queries.Thanks###Hi Team,When we checked on the instance level, we found the below errors in the error logs which are Non-static method SessionCache::delete() function is called:[Tue Jan 15 06:37:41 2019] [error] [client 10.59.101.139] PHP Strict Standards:  Non-static method SessionCache::delete() should not be called statically in /var/www/vhosts/secure.spendhq.com/public/app/controllers/components/shq_session.php on line 48[Tue Jan 15 06:37:41 2019] [error] [client 10.59.101.139] PHP Strict Standards:  Non-static method SessionCache::delete() should not be called statically in /var/www/vhosts/secure.spendhq.com/public/cake/libs/cake_session.php on line 674[Tue Jan 15 06:42:33 2019] [error] [client 10.59.101.139] PHP Strict Standards:  Non-static method SessionCache::delete() should not be called statically in /var/www/vhosts/secure.spendhq.com/public/cake/libs/cake_session.php on line 488[Tue Jan 15 06:42:33 2019] [error] [client 10.59.101.139] PHP Strict Standards:  Non-static method Cache::delete() should not be called statically in /var/www/vhosts/secure.spendhq.com/public/cake/libs/cake_session.php on line 592Please check the PHP application configuration.###Sent an email Mgsleads###Hello Team,From our analysis, we could see that the Site is not actually down because of latency and the backend server was unable to handle the request at that time.While checking the backend ELB, instance and DB servers, we found the below details. From NewPreview ELB:1. Spike in latency graph with a maximum value of 40260.21 ms 2. We can see a slight spike in Request Count and value has been reached to 200 3. We also found a sudden spike in active connection count and value was 300From Secure-SpendHQ-ELB:We have noticed that the same pattern of the graph. From the Instance level:We have checked system logs on both the backend instance attached to NewPreview ELB as well as the UTM instance attached to Secure-SpendHQ-ELB load balancer but didn't find any error.From the Backend DB server PRD-DB1, we could see all the cloudwatch metrics are looking normalAs previous we have mentioned the alert was triggered because of latency and the backend server was unable to handle the request at the time of the alert.As the issue is related to latency so we have downgraded the priority p1 to p2.###Hello Team, This is to inform you that we received a site down alert for the following URL: https://secure.spendhq.com/login which later on recovered automatically after a minute. We are analyzing this and will be sharing more info. Thanks.","From: ms@reancloud.com <ms@reancloud.com>Sent: Tuesday, January 15, 2019 10:15 AMTo: ms@reancloud.comSubject: Detected Error on SpendHQ SecureMon, 14 Jan 2019 23:45:36 -0500Detected Error on SpendHQ SecureEstimated Downtime: 2 minuteshttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 60000 milliseconds with 0 bytes receivedSensor parameters:url: https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsecure.spendhq.com%2Flogin&amp;data=01%7C01%7Cgourav.pokhra%40hitachivantara.com%7C9626b281be784bd612a608d67aa44c4b%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=6UY0iBkfwZPhFf9JnxNqyd24CEVDVEuUHk2IdAX%2BC84%3D&amp;reserved=0expect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Frankfurt-B DE, Frankfurt DE, Sydney-C AU, Dallas-C US-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,15-01-2019 10:21,325,0,SpendHQ,"Hello Team,As mentioned earlier, the issue is resolved.On that note we are marking this case as closed.Please let us know if you have any concerns.Thanks.",@Team:Do a final follow up and close this.,"@team,Please check with CC if we can close the case as we have done with 5 follow-ups.","Hello Team,We haven't heard back from you regarding the case for a while. Please go through the analysis we shared with you earlier. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.Regards,Rafi R","@TeamDone more than three follow-ups, Check with CC  whether we can close this case or not","Hello Matthew,We haven't heard back from you.The issue seems to be resolved, the site is also running up and fine. For now, we are reducing the priority of this ticket from P2 to P4.We will be looking forward to your response, please review the complete analysis shared here and let us know if you have any queries regarding it.","Hello Matthew,Just a quick email to see if there is an update on this case. Please have a look on the analysis that we have shared and let us know if you have any queries. Thank you.","Hello Team,This is a gentle reminder regarding the site down alert for URL:  https://secure.spendhq.com/login.Kindly review the shared analysis and let us know if you have any questions or concerns.","Hello Matthew, We haven't heard back from you regarding this case. Kindly review the shared analysis and let us know if you have any questions or concerns. Thanks",Hello TeamWe have again analyzed the logs and could find the same latency issue which caused the alert to get triggered.Kindly check with the analysis already shared with you and let us know if we have any queries.Thanks,"@Rohit I had gone on chat with AWs support team regarding the Datapoint missing in the ELB Metrics and they updated that may be caused as the data was not present at the time.Later I had shared the ELB logs to the AWS team  they mentioned the following after analyzing the logs1.from logs they could only see latency 2. regarding the GAP in Datapoints in metric, When Latency metric is considered the GAP may be there and its don't  related to any connectivity issue",Hello TeamWe have again received site down alert for the same URL. We could see that the site is not actually down. We could see spike in the latency as similar to previous alerts.We will analyze more on this and will let you know the updates.Thanks,"@Rohit, We have performed an analysis on recent site down alerts triggered at 3:31 AM And 3:40 AM IST.Upon checking the Cloudwatch metrics from on Secure ELB and UTM server everything looks normal.While checking the CloudWatch metrics for NewPreview ELB we can see there was a break in the metrics graph for two times. There are two instances attached to this ELB, for both the instances all the metrics are not for that time around.We verified all network, CPU metrics and can see that metrics are breaking for two times and for the interval of approx 10 minutes. Please let us know if we can go ahead and raise a support ticket with AWS to further investigate the issue. https://docs.google.com/document/d/1ARnI73bQB-ilCOeKx1_jW_iDiv0NYZRQEgkxmJDc2UA/edit?usp=sharingApart from this, we have also verified the ELB logs as well but we didn't find any URL which was taking higher than normal backend processing time. https://docs.google.com/spreadsheets/d/1vzYJp5HrRs0UGxgAIhPjnDfM7bcW7U-YGGynk4Td-Dg/edit?usp=sharingWe have verified all backend instances of both ELB's system logs as well but no issue found.","Hello Team,We are continuously receiving site down alerts for the URL: https://secure.spendhq.com/login which is getting recovered automatically in a minute. Upon checking the URL was loading slowly but it was up.We are analyzing more on this issue and will update you soon.","Hello Team,As mentioned earlier, below is the log analysis related to the site down alert. We have fetched logs for 1 hour within the time we received the alert.We had a total of 13902 (2xx+4xx+5xx) logs generated during the time period.Top URLs with 2xx response code:GET https://secure.spendhq.com:443/login HTTP/1.1  count 1955HEAD https://secure.spendhq.com:443/login HTTP/1.1 count 118GET https://secure.spendhq.com:443/spend-visibility HTTP/1.1 count 46GET https://secure.spendhq.com:443/css/jquery.tooltip.css?1499356036 HTTP/1.1 count 45GET https://secure.spendhq.com:443/css/css.5.5.css?1544891945 HTTP/1.1 count 44Top URLs with 4xx response code;POST https://secure.spendhq.com:443/errors/report/js HTTP/1.1 count 1945GET https://secure.spendhq.com:443/css/images/throbber.gif HTTP/1.1 count 61GET https://secure.spendhq.com:443/images/sort_both.png HTTP/1.1 count 3Top URLs with 5xx response code:GET https://secure.spendhq.com:443/login HTTP/1.1 count 48HEAD https://secure.spendhq.com:443/ HTTP/1.1 count 12GET https://secure.spendhq.com:443/ HTTP/1.1 count 11We had only one IP: 10.59.1.192 for all the requests and it is an internal IP for the PROD-SPHQ-SOPHOS-UTM-VPN01 instance.Below are the log details for the Secure-SpendHQ-ELB for 1 hour.We had a total of 13714 (2xx+4xx+5xx) logs generated.Top IPs with 2xx response:50.232.133.1  Requests > 1049159.100.161.41 Requests > 92383.70.73.108    Requests > 90999.108.156.53  Requests > 667Top IPs with 4xx response:146.247.40.253 Requests > 157976.191.72.1  Requests > 636209.165.134.1  Requests > 633208.87.236.201 Requests > 291Top IPs with 5xx response:54.245.168.2 Requests > 554.232.40.98 Requests > 554.228.16.34 Requests > 4Top URLs with high request count:GET https://secure.spendhq.com:443/login HTTP/1.1  count > 1939HEAD https://secure.spendhq.com:443/login HTTP/1.1 count > 114POST https://secure.spendhq.com:443/errors/report/js HTTP/1.1 > count 1944GET https://secure.spendhq.com:443/css/images/throbber.gif HTTP/1.1 count > 60GET https://secure.spendhq.com:443/login HTTP/1.1 count > 47HEAD https://secure.spendhq.com:443/ HTTP/1.1 count 12We checked the validity of the IPs and we could not find any of the listed IPs with any type of abuse.Kindly review the logs for both the ELBs on the attachment section and let us know your thoughts on the same.","Hello Team,On checking logs, we could see PHP fatal error. Please find them below:[Tue Jan 15 11:35:01 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com                                                                                /reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 11:35:01 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760[Tue Jan 15 11:35:01 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760[Tue Jan 15 11:35:01 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com                                                                                /reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 11:35:01 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com                                                                                /reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 11:35:02 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com                                                                                /reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 11:35:02 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com                                                                                /reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 11:35:03 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760[Tue Jan 15 11:35:03 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760[Tue Jan 15 11:35:03 2019] [error] [client 10.59.100.233] PHP Fatal error:  Call to a member function get_navigation() on                                                                                 null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760","@Team,Please share the ELB logs with the customer.","Hello Team,On further checking from AWS console, we could see that there are spikes in latency and request count and at the same time spikes in HTTP 4xx matrics of the load balancer NewPreview-ELB.  We have checked the backend server (PRD-WW1_122 and PRD-WW2-11-01-2019) behavior and found that the CPU utilization was high (around 92%) on the server PRD-WW1_122. Other than we can see the spikes in network IN/Out matrics on both server.We could see that the connections were also high on the server 10.59.100.122 at the time of the alert.[root@ip-10-59-100-122 log]# netstat | grep TIME_WAIT | wc -l 1280[root@ip-10-59-100-207 log]# netstat | grep TIME_WAIT | wc -l136On checking the system logs of the server 10.59.100.122, we found that one of the several running httpd process with PID 21717 got killed by the “Out Of Memory killer” of Kernel. Please find the logs for the same below: Jan 15 16:27:55 ip-10-59-100-122 kernel: Out of memory: Kill process 21717 (httpd) score 125 or sacrifice childJan 15 16:27:55 ip-10-59-100-122 kernel: Killed process 21717, UID 48, (httpd) total-vm:8250616kB, anon-rss:7877840kB, file-rss:928kBWe have checked the other instances logs and did not find anything suspicious. Kindly review our findings and let us know if you have any more queries. We are now analyzing the ELB logs and will share with you shortly.","Hello Team,The site is accessible now. The alert got recovered in 14 minutes. We are looking into this and will update you.","Hello Team,We have again received the site down alert for URL: https://secure.spendhq.com/login. We are analyzing this and will be sharing more info. Thanks.",The site is up and running well. We have disabled the maintenance.,"@TeamAs mentioned by Rohit, I had muted the URL  in wormly",Hello TeamWe again received site down alert for the same URL. All the alerts that we received today got recovered within 1 minute.We had analyzed the alert and could see the same issue of latency and high request count. The highest latency recorded in the log at the time of alert is 97.26 seconds.Kindly check with the logs and screenshots attached and get back to us if you have any queries.Thanks,"Hello TeamOn our further analysis, we checked with the ELB logs for both internal facing Secure-SpendHQ-ELB load balancer and the internal ELB NewPreview-ELB load balance at the time frame of 3 hours over which we got multiple alerts. we found that there are 5763 of 403 responses from the Secure-SpendHQ-ELB logs and 5968 of 403 responses in the NewPreview-ELB logs.We could see that most of the Request was coming from the below four IP1. 98.253.118.1562.76.191.72.13.209.165.134.14. 103.213.251.95We had checked with the abusive Rating of the Above IPs and could see thattwo of them are abusive. 1. IP:	98.253.118.156Hostname:	c-98-253-118-156.hsd1.il.comcast.netISP:	Comcast CableOrganization:	Comcast CableContinent:	North AmericaCountry:	United States us flagState/Region:	IllinoisCity:	Forest Park2. IP:	103.213.251.95Hostname:	103.213.251.95Organization:	Cloudie LimitedContinent:	AsiaCountry:	Hong Kong hk flagWe have blocked the HongKong IP.(103.213.251.95).Kindly check with the other IP and also with the attached ELB logs and let us know if you have any queries.Thanks","Hi Team,When we checked on the instance level, we found the below errors in the error logs which are Non-static method SessionCache::delete() function is called:[Tue Jan 15 06:37:41 2019] [error] [client 10.59.101.139] PHP Strict Standards:  Non-static method SessionCache::delete() should not be called statically in /var/www/vhosts/secure.spendhq.com/public/app/controllers/components/shq_session.php on line 48[Tue Jan 15 06:37:41 2019] [error] [client 10.59.101.139] PHP Strict Standards:  Non-static method SessionCache::delete() should not be called statically in /var/www/vhosts/secure.spendhq.com/public/cake/libs/cake_session.php on line 674[Tue Jan 15 06:42:33 2019] [error] [client 10.59.101.139] PHP Strict Standards:  Non-static method SessionCache::delete() should not be called statically in /var/www/vhosts/secure.spendhq.com/public/cake/libs/cake_session.php on line 488[Tue Jan 15 06:42:33 2019] [error] [client 10.59.101.139] PHP Strict Standards:  Non-static method Cache::delete() should not be called statically in /var/www/vhosts/secure.spendhq.com/public/cake/libs/cake_session.php on line 592Please check the PHP application configuration.",Sent an email Mgsleads,"Hello Team,From our analysis, we could see that the Site is not actually down because of latency and the backend server was unable to handle the request at that time.While checking the backend ELB, instance and DB servers, we found the below details. From NewPreview ELB:1. Spike in latency graph with a maximum value of 40260.21 ms 2. We can see a slight spike in Request Count and value has been reached to 200 3. We also found a sudden spike in active connection count and value was 300From Secure-SpendHQ-ELB:We have noticed that the same pattern of the graph. From the Instance level:We have checked system logs on both the backend instance attached to NewPreview ELB as well as the UTM instance attached to Secure-SpendHQ-ELB load balancer but didn't find any error.From the Backend DB server PRD-DB1, we could see all the cloudwatch metrics are looking normalAs previous we have mentioned the alert was triggered because of latency and the backend server was unable to handle the request at the time of the alert.As the issue is related to latency so we have downgraded the priority p1 to p2.","Hello Team, This is to inform you that we received a site down alert for the following URL: https://secure.spendhq.com/login which later on recovered automatically after a minute. We are analyzing this and will be sharing more info. Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Tm2tq,Cloud Engineer Level 1,Closed,1094565,Incident,04-04-2018 01:08,,"Hello Dusty,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello Dusty ,We haven't heard back from you regarding the case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.###Hello Dusty,Could you please verify again and let us know if you still facing issue to internet connectivity on the server 10.59.10.157###Hello Dusty,We haven't heard back from you.Please let us know if you are still facing any issue regarding this case.###Hello Dusty,Can you please try once now and let us know if you are still facing any issues.###Hello Dusty,We will check on this request and will get back to you with updates.","Can you guys ensure that web internet activity is available on the machine list below (10.59.10.157).Thanks!Dusty Fowler | Developer | SpendHQ(r)O: 770.628.0026 | dfowler@spendhq.com<mailto:dfowler@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Justin Gawthrop [mailto:Justin.Gawthrop@logianalytics.com]Sent: Tuesday, March 27, 2018 9:53 AMTo: Dusty Fowler <dfowler@spendhq.com>; Allen Herrera <aherrera@spendhq.com>Subject: Test BoxHi Dusty,Our support engineer is trying to close the loop on the phantomJS case and it looks like there's a firewall or something blocking us from running apps via a web browser on my machine when we are VPNed into your network and accessing the machine (10.59.10.157).Do you know what might be going on?Best,JUSTIN GAWTHROP //  Technical Account Manager  // Logi Analytics  //  o: 703.752.9700 x7043  //  justin.gawthrop@logianalytics.com<mailto:justin.gawthrop@logianalytics.com>> See why 100% of attendees found our 2016 conference worthwhile < <https://www.logianalytics.com/user-conference-2018/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: Test Box,,29-03-2018 17:37,128,0,SpendHQ,"Hello Dusty,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello Dusty ,We haven't heard back from you regarding the case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.","Hello Dusty,Could you please verify again and let us know if you still facing issue to internet connectivity on the server 10.59.10.157","Hello Dusty,We haven't heard back from you.Please let us know if you are still facing any issue regarding this case.","Hello Dusty,Can you please try once now and let us know if you are still facing any issues.","Hello Dusty,We will check on this request and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d2gl2,Cloud Engineer Level 1,Closed,1106248,Incident,21-10-2018 02:08,,"Hello Chris,We have updated the schedule activity as per your requirement.At this time we are marking this case as closed and let us know if you have any further queries related to it.###Hello Chirs,We have checked and verified the instance 10.59.100.135 have the same schedule.Please let us know if you have any further queries regarding this.###@team All instances are in stopped state at 10.30 am IST updated the sheet.https://docs.google.com/spreadsheets/d/1MWaBr52MOF3M2YQoWBfUMt4MGyAFkpIaenhKkl09V7M/edit#gid=0###@team,Updated the sheet on the status of the instances at 1800 EST.@Morning team,Please check the status of the running instances on the sheet at 10:30 am IST.###Hi Team,We have checked the instances mentioned in the sheet and we could see that the instances are started running at 4.30 pm IST. I have updated the status of instances in the ticket. Please review the sheet and check whether the instances are stopping at the respective timings. And please update the same on the sheet.###@Rohit, Please review the following sheet.We have attached the following tag as per the scheduled time requested by the customer.https://docs.google.com/spreadsheets/d/1MWaBr52MOF3M2YQoWBfUMt4MGyAFkpIaenhKkl09V7M/edit#gid=0We have throttled the lambda function running in Spendhq account to start/stop the instance.I have also created a calendar invite for shift team to monitor instances to start/stop.###@Rohit,Both mentioned instances started on time. I have tested both the tags from my end on the test instance and both tags are working as expected. We can remove the lambda functions that we have in spendhq account.###@team, As discussed with Rohit, I have launched a test instance (i-0dcf6aa57af97ffdb) in SpendHQ account and after attaching the tag (spendhq-office-hours), it should stop the instance as the tag is configured in a manner to run the instance between 7AM-19AM ET but it didn't stop the instance.I updated same to the DevOps team. They are analyzing the issue from there end and will update us. Meanwhile, I have created a calendar invite to monitor whether the instances are getting started or not.###@team, I checked with DevOps team and they updated that tags are working fine. I have created a calendar invite for 4:30 IST (7 AM ET). Please check the following instances get started or not at the same time.i-0faf50a3335630daai-079130613ab17ad30###Hello Rohit,The below details are the scheduled details provided by the customer.--------------------------------------------------------------------------------------------Running: Monday-Friday: 0700 – 0100 Not Running: Monday-Friday: 0100 – 0700 Running: Saturday and Sunday: 1200 - 0000 Not Running: Saturday and Sunday: 0000 – 1200---------------------------------------------------------------------------------------The team configured the lambda functions with this same timing. but while checking I can able notice the following details.1. we have two lambda functions for stop and start the servers on weekends.--> SpendHQstopEc2InstanceWeekend--> StartSpendhQInstancesWeekendThe stop lambda function is configured in such a way to get trigger at 9:30 AM IST(12:00 AM EST) and the start lambda function is configured in such a way to trigger at 9:30 PM IST (12:00 PM EST)2. The SpendHQstopEc2InstanceWeekend function was triggered with the same time period on the weekends exactly at 9:30 AM IST(12:00 AM EST). But the StartSpendhQInstancesWeekend is not triggered at 9:30 PM IST (12:00 PM EST) because the attached Cloudwatch event rule (SpendHq_Instance_Weekend_Start_Schedule) was disabled. so that the instance is not started at the same time so that I have manually started the instance after we notified by the customer.3. As mentioned by the customer in the description, all other instance was running state while I am checking. Also, there was another lambda function called StartInstances which configured to start the instances(10.59.100.25, 10.59.100.61, and 10.59.100.248 except 10.59.100.135) at 9:30 PM IST (12:00 PM EST).  4. There are 7 lambda functions for the same purpose and there was an issue with the schedule timing as a single instance is configured to triggered by multiple lambda functions.5. Also while checking, this tag [ key: Schedule value: spendhq-office-hours] is not working as of now and all the activity performed by the lambda functions.Also, I have attached the event logs for the instance in the attachment section.Please review all the lambda function and let us know how to proceed with this request.@Team, Do not change any configuration in the lambda functions without Rohit approval. reach out to him and work on it as per his comment.###Thenmozhy D3:40 AM (0 minutes ago)to Chris, spendhq-support, Matthew, latencio, meHello Chris,We have started the instance 10.59.100.135 now and we are updating the scheduled activity as per your requirements. We will let you once it is done.###Shubhankar Raman3:24 AM (0 minutes ago)to cmin, spendhq-support, Matthew, latencioHello Chris,We are looking at it and will update you soon.","Hi REAN,We asked 10.59.100.135 to be on the same schedule as 10.59.100.25, 10.59.100.61, and 10.59.100.248, but 10.59.100.135 is currently not accessible. It is supposed to be up from noon to midnight on weekends. Could you check its schedule?Thanks,Chris Min | Senior Data Engineer | SpendHQ®O: 470.204.0862 | C: 770.688.5695 | cmin@spendhq.com<mailto:cmin@spenhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com> | www.insightsourcing.com<http://www.insightsourcing.com/>",An instance is down,,15-10-2018 03:19,143,0,SpendHQ,"Hello Chris,We have updated the schedule activity as per your requirement.At this time we are marking this case as closed and let us know if you have any further queries related to it.","Hello Chirs,We have checked and verified the instance 10.59.100.135 have the same schedule.Please let us know if you have any further queries regarding this.",@team All instances are in stopped state at 10.30 am IST updated the sheet.https://docs.google.com/spreadsheets/d/1MWaBr52MOF3M2YQoWBfUMt4MGyAFkpIaenhKkl09V7M/edit#gid=0,"@team,Updated the sheet on the status of the instances at 1800 EST.@Morning team,Please check the status of the running instances on the sheet at 10:30 am IST.","Hi Team,We have checked the instances mentioned in the sheet and we could see that the instances are started running at 4.30 pm IST. I have updated the status of instances in the ticket. Please review the sheet and check whether the instances are stopping at the respective timings. And please update the same on the sheet.","@Rohit, Please review the following sheet.We have attached the following tag as per the scheduled time requested by the customer.https://docs.google.com/spreadsheets/d/1MWaBr52MOF3M2YQoWBfUMt4MGyAFkpIaenhKkl09V7M/edit#gid=0We have throttled the lambda function running in Spendhq account to start/stop the instance.I have also created a calendar invite for shift team to monitor instances to start/stop.","@Rohit,Both mentioned instances started on time. I have tested both the tags from my end on the test instance and both tags are working as expected. We can remove the lambda functions that we have in spendhq account.","@team, As discussed with Rohit, I have launched a test instance (i-0dcf6aa57af97ffdb) in SpendHQ account and after attaching the tag (spendhq-office-hours), it should stop the instance as the tag is configured in a manner to run the instance between 7AM-19AM ET but it didn't stop the instance.I updated same to the DevOps team. They are analyzing the issue from there end and will update us. Meanwhile, I have created a calendar invite to monitor whether the instances are getting started or not.","@team, I checked with DevOps team and they updated that tags are working fine. I have created a calendar invite for 4:30 IST (7 AM ET). Please check the following instances get started or not at the same time.i-0faf50a3335630daai-079130613ab17ad30","Hello Rohit,The below details are the scheduled details provided by the customer.--------------------------------------------------------------------------------------------Running: Monday-Friday: 0700 – 0100 Not Running: Monday-Friday: 0100 – 0700 Running: Saturday and Sunday: 1200 - 0000 Not Running: Saturday and Sunday: 0000 – 1200---------------------------------------------------------------------------------------The team configured the lambda functions with this same timing. but while checking I can able notice the following details.1. we have two lambda functions for stop and start the servers on weekends.--> SpendHQstopEc2InstanceWeekend--> StartSpendhQInstancesWeekendThe stop lambda function is configured in such a way to get trigger at 9:30 AM IST(12:00 AM EST) and the start lambda function is configured in such a way to trigger at 9:30 PM IST (12:00 PM EST)2. The SpendHQstopEc2InstanceWeekend function was triggered with the same time period on the weekends exactly at 9:30 AM IST(12:00 AM EST). But the StartSpendhQInstancesWeekend is not triggered at 9:30 PM IST (12:00 PM EST) because the attached Cloudwatch event rule (SpendHq_Instance_Weekend_Start_Schedule) was disabled. so that the instance is not started at the same time so that I have manually started the instance after we notified by the customer.3. As mentioned by the customer in the description, all other instance was running state while I am checking. Also, there was another lambda function called StartInstances which configured to start the instances(10.59.100.25, 10.59.100.61, and 10.59.100.248 except 10.59.100.135) at 9:30 PM IST (12:00 PM EST).  4. There are 7 lambda functions for the same purpose and there was an issue with the schedule timing as a single instance is configured to triggered by multiple lambda functions.5. Also while checking, this tag [ key: Schedule value: spendhq-office-hours] is not working as of now and all the activity performed by the lambda functions.Also, I have attached the event logs for the instance in the attachment section.Please review all the lambda function and let us know how to proceed with this request.@Team, Do not change any configuration in the lambda functions without Rohit approval. reach out to him and work on it as per his comment.","Thenmozhy D3:40 AM (0 minutes ago)to Chris, spendhq-support, Matthew, latencio, meHello Chris,We have started the instance 10.59.100.135 now and we are updating the scheduled activity as per your requirements. We will let you once it is done.","Shubhankar Raman3:24 AM (0 minutes ago)to cmin, spendhq-support, Matthew, latencioHello Chris,We are looking at it and will update you soon.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gdTTl,Cloud Engineer Level 1,Closed,1109760,Incident,21-12-2018 04:14,,"via mail:Matthew WattsConfirmed. Thank you.###Hello Matt,We can also confirm that the alert has since then recovered with total violation time of around 22 minutes. Seeing as this is resolved, we are marking this case as closed.Thanks.###Hello Team,This is to inform you that we;ve received an alert regarding high CPU utilization on the SPHQ-DB2-20180830 instance.From our analysis we can see that the PrimProc process is consuming majority of the CPU.top - 21:58:09 up 5 days, 23:24,  0 users,  load average: 15.52, 16.87, 18.31Tasks: 199 total,   1 running, 198 sleeping,   0 stopped,   0 zombie%Cpu(s): 99.6 us,  0.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 13035632+total,   778004 free, 52819152 used, 76759168 buff/cacheKiB Swap:        0 total,        0 free,        0 used. 76364416 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND23820 root      19  -1   98.6g  48.0g  73660 S  1600 38.6   1145:20 PrimProc 9440 root      20   0  299688   8396   5952 S   6.7  0.0   0:00.01 ssm-docume+23941 root      20   0 1368520  28504   8180 S   6.7  0.0   1:53.31 amazon-ssm+    1 root      20   0   55304   7384   3904 S   0.0  0.0   7:51.63 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:00.13 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:53.84 ksoftirqd/0    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.31 migration/0    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0   1:39.92 rcu_sched   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.99 watchdog/0   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.80 watchdog/1   13 root      rt   0       0      0      0 S   0.0  0.0   0:00.18 migration/1   14 root      20   0       0      0      0 S   0.0  0.0   0:00.43 ksoftirqd/1   16 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1:+   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.73 watchdog/2   18 root      rt   0       0      0      0 S   0.0  0.0   0:00.21 migration/2   19 root      20   0       0      0      0 S   0.0  0.0   0:00.43 ksoftirqd/2   21 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2:+   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.74 watchdog/3   23 root      rt   0       0      0      0 S   0.0  0.0   0:00.20 migration/3   24 root      20   0       0      0      0 S   0.0  0.0   0:00.32 ksoftirqd/3Resource Details:-----------------------Name: SPHQ-DB2-20180830Instance ID: i-0105d8ab19d508dd6Private IP: 10.59.10.45AZ: us-east-1bInstance Type: r5.4xlargeVPC ID: vpc-76df7212Please have a look into this and let us know if you have any other queries regarding this.Thanks.","[image: Datadog][Triggered] [SpendHQ] - High CPU Utilization on the host sphq-db2-20180830- 10.59.10.45 -High CPU Utilization on the host. Log in to the machine and verify whichprocess is consuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024189?to_ts=1545342199000&group=host%3Ai-0105d8ab19d508dd6&from_ts=1545334999000>avg(last_30m):avg:system.cpu.stolen{datadog_monitor:on} by {host} +avg:system.cpu.user{datadog_monitor:on} by {host} +avg:system.cpu.system{datadog_monitor:on} by {host} > 85The monitor was last triggered at Thu Dec 20 2018 21:43:29 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024189?group=host%3Ai-0105d8ab19d508dd6>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024189/edit>] · [Viewi-0105d8ab19d508dd6<https://app.datadoghq.com/infrastructure?filter=i-0105d8ab19d508dd6>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1545342329000&tags=host%3Ai-0105d8ab19d508dd6&from_ts=1545341309000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4715728914908475520>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on the host sphq-db2-20180830 - 10.59.10.45 -,,21-12-2018 03:27,1,0,SpendHQ,via mail:Matthew WattsConfirmed. Thank you.,"Hello Matt,We can also confirm that the alert has since then recovered with total violation time of around 22 minutes. Seeing as this is resolved, we are marking this case as closed.Thanks.","Hello Team,This is to inform you that we;ve received an alert regarding high CPU utilization on the SPHQ-DB2-20180830 instance.From our analysis we can see that the PrimProc process is consuming majority of the CPU.top - 21:58:09 up 5 days, 23:24,  0 users,  load average: 15.52, 16.87, 18.31Tasks: 199 total,   1 running, 198 sleeping,   0 stopped,   0 zombie%Cpu(s): 99.6 us,  0.4 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 13035632+total,   778004 free, 52819152 used, 76759168 buff/cacheKiB Swap:        0 total,        0 free,        0 used. 76364416 avail Mem   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND23820 root      19  -1   98.6g  48.0g  73660 S  1600 38.6   1145:20 PrimProc 9440 root      20   0  299688   8396   5952 S   6.7  0.0   0:00.01 ssm-docume+23941 root      20   0 1368520  28504   8180 S   6.7  0.0   1:53.31 amazon-ssm+    1 root      20   0   55304   7384   3904 S   0.0  0.0   7:51.63 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:00.13 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:53.84 ksoftirqd/0    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.31 migration/0    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0   1:39.92 rcu_sched   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.99 watchdog/0   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.80 watchdog/1   13 root      rt   0       0      0      0 S   0.0  0.0   0:00.18 migration/1   14 root      20   0       0      0      0 S   0.0  0.0   0:00.43 ksoftirqd/1   16 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1:+   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.73 watchdog/2   18 root      rt   0       0      0      0 S   0.0  0.0   0:00.21 migration/2   19 root      20   0       0      0      0 S   0.0  0.0   0:00.43 ksoftirqd/2   21 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2:+   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.74 watchdog/3   23 root      rt   0       0      0      0 S   0.0  0.0   0:00.20 migration/3   24 root      20   0       0      0      0 S   0.0  0.0   0:00.32 ksoftirqd/3Resource Details:-----------------------Name: SPHQ-DB2-20180830Instance ID: i-0105d8ab19d508dd6Private IP: 10.59.10.45AZ: us-east-1bInstance Type: r5.4xlargeVPC ID: vpc-76df7212Please have a look into this and let us know if you have any other queries regarding this.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001LugAr,Cloud Engineer Level 1,Closed,1086522,Incident,21-12-2017 23:47,,"Hi SpendHQ Team,As we discussed on the Bi-Weekly call yesterday, I have sent you a calendar invite for the maintenance on 25th December from 2 AM to 3 AM EST.We have also created a change ticket 01087145 to perform the maintenance and will be tracking the efforts there. Hence closing this ticket.Please let us know if you have any questions.Thanks and RegardsYogesh Maloo###Hello Team,We haven't heard back from you.Please review the details and let us know how to proceed with this case.###Hello SpendHQ Team, We haven't heard back from you. This is to inform you that we have received a notification that that one of the Amazon EC2 instances in the us-east-1 region requires important security and operational updates which will require a reboot of the instance. The maintenance window has been scheduled between Sat, 6 Jan 2018 16:00:00 GMT and Sun, 7 Jan 2018 11:00:00 GMT during which the EC2 service will automatically perform the required reboot. During the maintenance window, the affected instance will be unavailable for a short period of time as it reboots. Alternatively, we can perform a reboot on the instance at any time before the maintenance window. If we perform this, the maintenance will be marked as completed and no reboot will occur during the maintenance window Please review the detail and let us know how to proceed with this case. Please find the event details below Availability Zone: us-east-1b Event type: instance-reboot Event status: Scheduled Description: Scheduled Instance Reboot Maintenance Start time: January 6, 2018 at 9:30:00 PM UTC+5:30 End time: January 7, 2018 at 4:30:00 PM UTC+5:30 Resource Details: Instance Name : PROD-SPHQ-SOPHOS-VPN01 Instance: i-b891e407 Private IPs: 10.59.1.192 Availability zone: us-east-1b Subnet ID:subnet-01596c2a VPC ID:vpc-76df7212###Hello SpendHQ Team, We haven't heard back from you.This is to inform you that we have received a notification that that one of the Amazon EC2 instances in the us-east-1 region requires important security and operational updates which will require a reboot of the instance. The maintenance window has been scheduled between Sat, 6 Jan 2018 16:00:00 GMT and Sun, 7 Jan 2018 11:00:00 GMT during which the EC2 service will automatically perform the required reboot. During the maintenance window, the affected instance will be unavailable for a short period of time as it reboots. Alternatively, we can perform a reboot on the instance at any time before the maintenance window. If we perform this, the maintenance will be marked as completed and no reboot will occur during the maintenance window Please review the detail and let us know how to proceed with this case. Please find the event details below Availability Zone: us-east-1b Event type: instance-reboot Event status: Scheduled Description: Scheduled Instance Reboot Maintenance Start time: January 6, 2018 at 9:30:00 PM UTC+5:30 End time: January 7, 2018 at 4:30:00 PM UTC+5:30 Resource Details: Instance Name : PROD-SPHQ-SOPHOS-VPN01 Instance: i-b891e407 Private IPs: 10.59.1.192 Availability zone: us-east-1b Subnet ID:subnet-01596c2a VPC ID:vpc-76df7212###Hello SpendHQ Team,We haven't heard back from you please review the details in the previous comment and let us know if you any queries.###Hello SpendHQ Team,This is to inform you that we have received a notification that that one of the Amazon EC2 instances in the us-east-1 region requires important security and operational updates which will require a reboot of the instance.  The maintenance window has been scheduled between Sat, 6 Jan 2018 16:00:00 GMT and Sun, 7 Jan 2018 11:00:00 GMT during which the EC2 service will automatically perform the required reboot.   During the maintenance window, the affected instance will be unavailable for a short period of time as it reboots. Alternatively, we can perform a reboot on the instance at any time before the maintenance window. If we perform this, the maintenance will be marked as completed and no reboot will occur during the maintenance window Please review the detail and let us know how to proceed with this case. Please find the event details belowAvailability Zone: us-east-1bEvent type: instance-rebootEvent status: ScheduledDescription: Scheduled Instance Reboot MaintenanceStart time:  January 6, 2018 at 9:30:00 PM UTC+5:30End time: January 7, 2018 at 4:30:00 PM UTC+5:30Resource Details:Instance Name : PROD-SPHQ-SOPHOS-VPN01Instance:  i-b891e407Private IPs: 10.59.1.192Availability zone: us-east-1bSubnet ID:subnet-01596c2aVPC ID:vpc-76df7212","[Triggered on {host:i-b891e407}] [SpendHQ] - Maintenance Scheduled on the resource - Upcoming AWS maintenance event instance-reboot on instance i-b891e407 - %%%Scheduled Instance Reboot Maintenanceinstance-reboot will automatically happen between 2018-01-06 16:00:00 and 2018-01-07 11:00:00 if...  Maintenance Scheduled on the resource i-b891e407    @support@reancloud.com1 event triggered this monitor, here is the last one.- - -#### Upcoming AWS maintenance event instance-reboot on instance i-b891e407%%%Scheduled Instance Reboot Maintenanceinstance-reboot will automatically happen between 2018-01-06 16:00:00 and 2018-01-07 11:00:00 if not manually run before. [aws guide](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-instances-status-check_sched.html#schedevents_actions)%%%- - -Number of events matching priority:all AWS maintenance on host:i-b891e407 was > 0 during the last 5mThis alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024406?group=host%3Ai-b891e407 · Edit Monitor: https://app.datadoghq.com/monitors#2024406/edit · Event URL: https://app.datadoghq.com/event/event?id=4177742580574924745 · View i-b891e407: https://app.datadoghq.com/infrastructure?hostname=i-b891e407-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - Maintenance Scheduled on the resource - Upcoming AWS maintenance event instance-reboot on instance i-b891e407 - %%%Scheduled Instance Reboot Maintenanceinstance-reboot will automatically happen between 2018-01-06 16:,,14-12-2017 23:52,168,0,SpendHQ,"Hi SpendHQ Team,As we discussed on the Bi-Weekly call yesterday, I have sent you a calendar invite for the maintenance on 25th December from 2 AM to 3 AM EST.We have also created a change ticket 01087145 to perform the maintenance and will be tracking the efforts there. Hence closing this ticket.Please let us know if you have any questions.Thanks and RegardsYogesh Maloo","Hello Team,We haven't heard back from you.Please review the details and let us know how to proceed with this case.","Hello SpendHQ Team, We haven't heard back from you. This is to inform you that we have received a notification that that one of the Amazon EC2 instances in the us-east-1 region requires important security and operational updates which will require a reboot of the instance. The maintenance window has been scheduled between Sat, 6 Jan 2018 16:00:00 GMT and Sun, 7 Jan 2018 11:00:00 GMT during which the EC2 service will automatically perform the required reboot. During the maintenance window, the affected instance will be unavailable for a short period of time as it reboots. Alternatively, we can perform a reboot on the instance at any time before the maintenance window. If we perform this, the maintenance will be marked as completed and no reboot will occur during the maintenance window Please review the detail and let us know how to proceed with this case. Please find the event details below Availability Zone: us-east-1b Event type: instance-reboot Event status: Scheduled Description: Scheduled Instance Reboot Maintenance Start time: January 6, 2018 at 9:30:00 PM UTC+5:30 End time: January 7, 2018 at 4:30:00 PM UTC+5:30 Resource Details: Instance Name : PROD-SPHQ-SOPHOS-VPN01 Instance: i-b891e407 Private IPs: 10.59.1.192 Availability zone: us-east-1b Subnet ID:subnet-01596c2a VPC ID:vpc-76df7212","Hello SpendHQ Team, We haven't heard back from you.This is to inform you that we have received a notification that that one of the Amazon EC2 instances in the us-east-1 region requires important security and operational updates which will require a reboot of the instance. The maintenance window has been scheduled between Sat, 6 Jan 2018 16:00:00 GMT and Sun, 7 Jan 2018 11:00:00 GMT during which the EC2 service will automatically perform the required reboot. During the maintenance window, the affected instance will be unavailable for a short period of time as it reboots. Alternatively, we can perform a reboot on the instance at any time before the maintenance window. If we perform this, the maintenance will be marked as completed and no reboot will occur during the maintenance window Please review the detail and let us know how to proceed with this case. Please find the event details below Availability Zone: us-east-1b Event type: instance-reboot Event status: Scheduled Description: Scheduled Instance Reboot Maintenance Start time: January 6, 2018 at 9:30:00 PM UTC+5:30 End time: January 7, 2018 at 4:30:00 PM UTC+5:30 Resource Details: Instance Name : PROD-SPHQ-SOPHOS-VPN01 Instance: i-b891e407 Private IPs: 10.59.1.192 Availability zone: us-east-1b Subnet ID:subnet-01596c2a VPC ID:vpc-76df7212","Hello SpendHQ Team,We haven't heard back from you please review the details in the previous comment and let us know if you any queries.","Hello SpendHQ Team,This is to inform you that we have received a notification that that one of the Amazon EC2 instances in the us-east-1 region requires important security and operational updates which will require a reboot of the instance.  The maintenance window has been scheduled between Sat, 6 Jan 2018 16:00:00 GMT and Sun, 7 Jan 2018 11:00:00 GMT during which the EC2 service will automatically perform the required reboot.   During the maintenance window, the affected instance will be unavailable for a short period of time as it reboots. Alternatively, we can perform a reboot on the instance at any time before the maintenance window. If we perform this, the maintenance will be marked as completed and no reboot will occur during the maintenance window Please review the detail and let us know how to proceed with this case. Please find the event details belowAvailability Zone: us-east-1bEvent type: instance-rebootEvent status: ScheduledDescription: Scheduled Instance Reboot MaintenanceStart time:  January 6, 2018 at 9:30:00 PM UTC+5:30End time: January 7, 2018 at 4:30:00 PM UTC+5:30Resource Details:Instance Name : PROD-SPHQ-SOPHOS-VPN01Instance:  i-b891e407Private IPs: 10.59.1.192Availability zone: us-east-1bSubnet ID:subnet-01596c2aVPC ID:vpc-76df7212",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001i5msW,Cloud Engineer Level 2,Closed,1110636,Incident,29-01-2019 07:18,,"Hello Matthew,As per the last comment from Praveen, we are marking this case closed in CMP.Please let us know if you have any queries related to it.###Matthew Watts <mwatts@spendhq.com>Today, 1:51 AMSorry, I’m working on some critical items. I will review and get back to you.###We failed at least 5 times to meet to discuss the below items. Review the below items and let us know if we can break each of these items into a separate change ticket and work with your team to fix them(start with Dev/Test and move to Prod). For now, we will close this case in CMP.###Rohit updated that the call is scheduled at tonight IST.###Hello Matthew, We have shared calendar invite with you for Monday 15:00 EST (1:30 AM IST). Please accept the invitation.###Hello Matthew,Thanks for providing us with your availability. We will be sharing the bridge with you and will join on Monday at 1500.###Matthew Watts <mwatts@spendhq.com>Today, 8:56 AMRean Support <support@reancloud.com>Let’s do Monday at 1500 EST###Hello Matthew, We haven't heard back from you. We would like to re-schedule the call to Friday or next Monday, as Praveen is not available on Thursday. Please let us know your availability on those days.###Hello Matthew, We haven't heard back from you.We would like to re-schedule the call to Friday or next Monday, as Praveen is not available on Thursday. Please let us know your availability on those days.###Hello Matthew,We would like to re-schedule the call to Friday or next Monday, as Praveen is not available on Thursday. Please let us know your availability on those days.###As per Praveen's update in Ops call, reducing the priority to P3###We tried to reach Matthew to re-schedule the call to next Monday or Friday as Praveen is not available on Thursday. but he is not answering the call. We left a voice message about the same.Please try to reach him and re-schedule the call for next Monday or  Friday.###Hello Team,Praveen last week mentioned that he will not be available Tuesday, Wednesday and Thursday.Therefore, he declined the meeting invite and Rohit will be sending communication to Matthew Please check with him###Hello Matthew,We have shared calendar invite with you for Thursday 13:00 EST (11:30 PM IST).Please accept the invitation.###From Matthew:Perfect, please send out an invite.###Hello Matthew, Thanks for providing us with your availability. We will be sharing the bridge with you and will join on Thursday at 1300.###[Email] From MatthewThursday I am free at 1300###[Email]Hi Matthew,We are available to have a call on either Monday or Friday next week. Is it fine with you to have a call on Monday 10:30 AM EST ?Thanks,Rohit Puri###@TeamCheck with Praveen for his availability to schedule the call  and reply back to Matthew with the call schedule###[On Email] Hello Matthew, We will get back to you after checking with Praveen and Rohit about their availability. Thanks###Matthew Watts <mwatts@spendhq.com>Today, 11:44 AMRean Support <support@reancloud.com>What availability do you have on Wednesday?###Hello Matthew,As you did not join the call at 10.30 AM EST yesterday, we are looking to setup another in order to discuss this issue in detail.Therefore, please let us know your availability so that we can schedule.Thanks###Hi Matthew, Please let us know your availability so that we can schedule the call to discuss about this issue. Thanks !###Hi Matthew, Please join the meeting Here:  https://zoom.us/j/9933445766 We are waiting for you. Thanks !###Matthew Watts <mwatts@spendhq.com>Tue 1/15, 9:05 PMRohit Puri <rohit.puri@hitachivantara.com>;Praveen Muppala;spendhq-support@reancloud.comCan we postpone to tomorrow?###Rohit Puri <rohit.puri@hitachivantara.com>Tue 1/15, 9:04 PMPraveen Muppala;spendhq - mwatts;spendhq-support@reancloud.comHi Matthew, We are waiting on the bridge. Please Join Zoom Meeting https://zoom.us/j/9933445766One tap mobile +14086380968,,9933445766# US (San Jose) +16465588656,,9933445766# US (New York)Dial by your location         +1 408 638 0968 US (San Jose)         +1 646 558 8656 US (New York) Meeting ID: 993 344 5766 Find your local number: https://zoom.us/u/hqrVODCa###@here Please check with Rohit and update this ticket.###[via email]Rohit Puri <rohit.puri@hitachivantara.com>12:10 PM (4 hours ago)to Praveen, spendhq, spendhq-support@reancloud.comHi All,I have re-scheduled the meeting for 10:30 AM EST and sent the updated invite. Thanks !###I am good with this time. @Rohit Puri – If the monthly meeting time matches the same time, let’s discuss this during that time. If the timeslot is different move the meeting to 10:30AM Est.Praveen MuppalaCloud Architect / Tech Lead, Managed ServicesHitachi Vantara###From Matthew.Are you free tomorrow from 1030 - 1100.###Hello Matt,This is a followup email.Please provide your availability so that we can schedule a call with you to discuss more on this issue and creation of an action plan to get rid of this SWEET32 attack.Thanks###Hello Matt,Please provide us your availability so that we can schedule a call with you to discuss more on this issue and action plan creation.Thanks###Hello Matt, The below mentioned vulnerable Cipher Suite needs to be addressed at 3 levels. 1. LoadBalancers  2. EC2 Instances OS Level Security patching 3. EC2 Instances Apache SSL Settings. Many of the SpendHQ load balancers are still supporting the old SSL/TLS protocols which indeed allows the exploited ssl cipher suites. The below load balancers SSL Config needs to upgraded to the latest SSL Cipher policy - ELBSecurityPolicy-TLS-1-2-2017-01NewPreview-ELB ELBSecurityPolicy-2016-08Preview-api-spendhq-com ELBSecurityPolicy-2016-08Secure-SpendHQ-ELB ELBSecurityPolicy-2015-05SpendHQ-CAT-MapD-iELB ELBSecurityPolicy-2016-08SpendHQ-CAT-MapD-xELB ELBSecurityPolicy-2016-08SpendHQ-Proxy-xELB ELBSecurityPolicy-2016-08api-spendhq-com ELBSecurityPolicy-2016-08capfiles-spendhq-ielb ELBSecurityPolicy-2016-08capfiles-spendhq-xelb ELBSecurityPolicy-2016-08l-spendhq-ELB ELBSecurityPolicy-2016-08lp-spendhq-ELB ELBSecurityPolicy-2016-08mapd ELBSecurityPolicy-2016-08mapdtest2 ELBSecurityPolicy-2016-08preview-spendhq-xelb ELBSecurityPolicy-2015-05preview-spendhq-xelb ELBSecurityPolicy-2016-08sandbox ELBSecurityPolicy-2016-08spendhq-patch-server ELBSecurityPolicy-2016-08www1-sandbox-spendhq-com ELBSecurityPolicy-2016-08The OS Level security patches has not been performed in your environment since many quarters, applying security patches will help us to get the latest CA certs, OpenSSL upgrades, and other OS Level security patches which will help in protecting from the attacks.The SpendHQ applications are configured to receive the SSL traffic from ELB to EC2 Level Apache also as part of your compliance. Hence, we need to apply the strong SSL encryption at Apache level. The below config will remove the older SSL versions support and ensure the strong ssl cipher policies.SSLProtocol         all -SSLv3 -TLSv1 -TLSv1.1SSLCipherSuite      ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:!ECDSA:!NULL:!MD5:!DSS:!3DESSSLHonorCipherOrder onSSLCompression      offSSLSessionTickets   off Our team is always sending the monthly reports with the security best practices and for every quarter we are following up on the OS Level patching with SpendHQ. To address this, we can get on a call, create an action plan and implement them phases wise in Pre-prod and production environments respectively. And after that, we mandatorily meet every month, review the monthly report and create action items, if anything needs to be addressed. Praveen Muppala###Hello Matthew,Thanks for bringing it our attention. We apologize that our system did not detect these vulnerabilities.Let us review the details you have shared and will get back to you with a solution for SWEET32 attack.","Rean,It appears that we have a vulnerability on one of the servers that funnels/redirects PRD traffic. Based on the findings below - 64-bit block cipher 3DES vulnerable to SWEET32 attack - we need to disable 3DES on the server that might be involved in routing. Please note the PRD EC2 Instances that serve live traffic – 10.59.100.122 and 10.59.100.207 – are not effected and have been patched appropriately.Please do not fix the issue, instead only advise of what can be done to resolve this issue. Can you also please advise why this was not detected by REAN. The SWEET32 Attack has been known about for a while. What can we do to proactively protect our Production Systems?| => nmap --script ssl-enum-ciphers -p 443 secure.spendhq.comStarting Nmap 7.40 ( https://nmap.org ) at 2019-01-11 16:01 ESTNmap scan report for secure.spendhq.com (52.55.206.187)Host is up (0.0025s latency).Other addresses for secure.spendhq.com (not scanned): 34.233.176.120rDNS record for 52.55.206.187: ec2-52-55-206-187.compute-1.amazonaws.comPORT    STATE SERVICE443/tcp open  https| ssl-enum-ciphers:|   TLSv1.0:|     ciphers:|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|   TLSv1.1:|     ciphers:|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|   TLSv1.2:|     ciphers:|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_RSA_WITH_AES_128_GCM_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_GCM_SHA384 (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_3DES_EDE_CBC_SHA (rsa 2048) - C|     compressors:|       NULL|     cipher preference: server|     warnings:|       64-bit block cipher 3DES vulnerable to SWEET32 attack|_  least strength: CNmap done: 1 IP address (1 host up) scanned in 2.64 seconds| => nmap --script ssl-enum-ciphers -p 443 10.59.100.207Starting Nmap 7.40 ( https://nmap.org ) at 2019-01-11 16:00 ESTNmap scan report for 10.59.100.207Host is up (0.024s latency).PORT    STATE SERVICE443/tcp open  https| ssl-enum-ciphers:|   TLSv1.0:|     ciphers:|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_DHE_RSA_WITH_AES_128_CBC_SHA (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_256_CBC_SHA (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_128_CBC_SHA (rsa 2048) - A|     compressors:|       NULL|     cipher preference: server|   TLSv1.1:|     ciphers:|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_DHE_RSA_WITH_AES_128_CBC_SHA (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_256_CBC_SHA (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_128_CBC_SHA (rsa 2048) - A|     compressors:|       NULL|     cipher preference: server|   TLSv1.2:|     ciphers:|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 (dh 2048) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_128_CBC_SHA (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_AES_128_GCM_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_256_GCM_SHA384 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA256 (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_256_CBC_SHA (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_128_CBC_SHA (rsa 2048) - A|     compressors:|       NULL|     cipher preference: server|_  least strength: ANmap done: 1 IP address (1 host up) scanned in 8.73 seconds| => nmap --script ssl-enum-ciphers -p 443 10.59.100.122Starting Nmap 7.40 ( https://nmap.org ) at 2019-01-11 15:55 ESTNmap scan report for 10.59.100.122Host is up (0.023s latency).PORT    STATE SERVICE443/tcp open  https| ssl-enum-ciphers:|   TLSv1.0:|     ciphers:|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_DHE_RSA_WITH_AES_128_CBC_SHA (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_256_CBC_SHA (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_128_CBC_SHA (rsa 2048) - A|     compressors:|       NULL|     cipher preference: server|   TLSv1.1:|     ciphers:|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_DHE_RSA_WITH_AES_128_CBC_SHA (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_256_CBC_SHA (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_128_CBC_SHA (rsa 2048) - A|     compressors:|       NULL|     cipher preference: server|   TLSv1.2:|     ciphers:|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (secp256r1) - A|       TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 (dh 2048) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (secp256r1) - A|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (secp256r1) - A|       TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_128_CBC_SHA (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 (dh 2048) - A|       TLS_DHE_RSA_WITH_AES_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_AES_128_GCM_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_256_GCM_SHA384 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA (rsa 2048) - A|       TLS_RSA_WITH_AES_256_CBC_SHA256 (rsa 2048) - A|       TLS_RSA_WITH_AES_128_CBC_SHA256 (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_256_CBC_SHA (rsa 2048) - A|       TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA (dh 2048) - A|       TLS_RSA_WITH_CAMELLIA_128_CBC_SHA (rsa 2048) - A|     compressors:|       NULL|     cipher preference: server|_  least strength: ANmap done: 1 IP address (1 host up) scanned in 8.52 secondsMatthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SWEET32,,12-01-2019 02:41,413,0,SpendHQ,"Hello Matthew,As per the last comment from Praveen, we are marking this case closed in CMP.Please let us know if you have any queries related to it.","Matthew Watts <mwatts@spendhq.com>Today, 1:51 AMSorry, I’m working on some critical items. I will review and get back to you.","We failed at least 5 times to meet to discuss the below items. Review the below items and let us know if we can break each of these items into a separate change ticket and work with your team to fix them(start with Dev/Test and move to Prod). For now, we will close this case in CMP.",Rohit updated that the call is scheduled at tonight IST.,"Hello Matthew, We have shared calendar invite with you for Monday 15:00 EST (1:30 AM IST). Please accept the invitation.","Hello Matthew,Thanks for providing us with your availability. We will be sharing the bridge with you and will join on Monday at 1500.","Matthew Watts <mwatts@spendhq.com>Today, 8:56 AMRean Support <support@reancloud.com>Let’s do Monday at 1500 EST","Hello Matthew, We haven't heard back from you. We would like to re-schedule the call to Friday or next Monday, as Praveen is not available on Thursday. Please let us know your availability on those days.","Hello Matthew, We haven't heard back from you.We would like to re-schedule the call to Friday or next Monday, as Praveen is not available on Thursday. Please let us know your availability on those days.","Hello Matthew,We would like to re-schedule the call to Friday or next Monday, as Praveen is not available on Thursday. Please let us know your availability on those days.","As per Praveen's update in Ops call, reducing the priority to P3",We tried to reach Matthew to re-schedule the call to next Monday or Friday as Praveen is not available on Thursday. but he is not answering the call. We left a voice message about the same.Please try to reach him and re-schedule the call for next Monday or  Friday.,"Hello Team,Praveen last week mentioned that he will not be available Tuesday, Wednesday and Thursday.Therefore, he declined the meeting invite and Rohit will be sending communication to Matthew Please check with him","Hello Matthew,We have shared calendar invite with you for Thursday 13:00 EST (11:30 PM IST).Please accept the invitation.","From Matthew:Perfect, please send out an invite.","Hello Matthew, Thanks for providing us with your availability. We will be sharing the bridge with you and will join on Thursday at 1300.",[Email] From MatthewThursday I am free at 1300,"[Email]Hi Matthew,We are available to have a call on either Monday or Friday next week. Is it fine with you to have a call on Monday 10:30 AM EST ?Thanks,Rohit Puri",@TeamCheck with Praveen for his availability to schedule the call  and reply back to Matthew with the call schedule,"[On Email] Hello Matthew, We will get back to you after checking with Praveen and Rohit about their availability. Thanks","Matthew Watts <mwatts@spendhq.com>Today, 11:44 AMRean Support <support@reancloud.com>What availability do you have on Wednesday?","Hello Matthew,As you did not join the call at 10.30 AM EST yesterday, we are looking to setup another in order to discuss this issue in detail.Therefore, please let us know your availability so that we can schedule.Thanks","Hi Matthew, Please let us know your availability so that we can schedule the call to discuss about this issue. Thanks !","Hi Matthew, Please join the meeting Here:  https://zoom.us/j/9933445766 We are waiting for you. Thanks !","Matthew Watts <mwatts@spendhq.com>Tue 1/15, 9:05 PMRohit Puri <rohit.puri@hitachivantara.com>;Praveen Muppala;spendhq-support@reancloud.comCan we postpone to tomorrow?","Rohit Puri <rohit.puri@hitachivantara.com>Tue 1/15, 9:04 PMPraveen Muppala;spendhq - mwatts;spendhq-support@reancloud.comHi Matthew, We are waiting on the bridge. Please Join Zoom Meeting https://zoom.us/j/9933445766One tap mobile +14086380968,,9933445766# US (San Jose) +16465588656,,9933445766# US (New York)Dial by your location         +1 408 638 0968 US (San Jose)         +1 646 558 8656 US (New York) Meeting ID: 993 344 5766 Find your local number: https://zoom.us/u/hqrVODCa",@here Please check with Rohit and update this ticket.,"[via email]Rohit Puri <rohit.puri@hitachivantara.com>12:10 PM (4 hours ago)to Praveen, spendhq, spendhq-support@reancloud.comHi All,I have re-scheduled the meeting for 10:30 AM EST and sent the updated invite. Thanks !","I am good with this time. @Rohit Puri – If the monthly meeting time matches the same time, let’s discuss this during that time. If the timeslot is different move the meeting to 10:30AM Est.Praveen MuppalaCloud Architect / Tech Lead, Managed ServicesHitachi Vantara",From Matthew.Are you free tomorrow from 1030 - 1100.,"Hello Matt,This is a followup email.Please provide your availability so that we can schedule a call with you to discuss more on this issue and creation of an action plan to get rid of this SWEET32 attack.Thanks","Hello Matt,Please provide us your availability so that we can schedule a call with you to discuss more on this issue and action plan creation.Thanks","Hello Matt, The below mentioned vulnerable Cipher Suite needs to be addressed at 3 levels. 1. LoadBalancers  2. EC2 Instances OS Level Security patching 3. EC2 Instances Apache SSL Settings. Many of the SpendHQ load balancers are still supporting the old SSL/TLS protocols which indeed allows the exploited ssl cipher suites. The below load balancers SSL Config needs to upgraded to the latest SSL Cipher policy - ELBSecurityPolicy-TLS-1-2-2017-01NewPreview-ELB ELBSecurityPolicy-2016-08Preview-api-spendhq-com ELBSecurityPolicy-2016-08Secure-SpendHQ-ELB ELBSecurityPolicy-2015-05SpendHQ-CAT-MapD-iELB ELBSecurityPolicy-2016-08SpendHQ-CAT-MapD-xELB ELBSecurityPolicy-2016-08SpendHQ-Proxy-xELB ELBSecurityPolicy-2016-08api-spendhq-com ELBSecurityPolicy-2016-08capfiles-spendhq-ielb ELBSecurityPolicy-2016-08capfiles-spendhq-xelb ELBSecurityPolicy-2016-08l-spendhq-ELB ELBSecurityPolicy-2016-08lp-spendhq-ELB ELBSecurityPolicy-2016-08mapd ELBSecurityPolicy-2016-08mapdtest2 ELBSecurityPolicy-2016-08preview-spendhq-xelb ELBSecurityPolicy-2015-05preview-spendhq-xelb ELBSecurityPolicy-2016-08sandbox ELBSecurityPolicy-2016-08spendhq-patch-server ELBSecurityPolicy-2016-08www1-sandbox-spendhq-com ELBSecurityPolicy-2016-08The OS Level security patches has not been performed in your environment since many quarters, applying security patches will help us to get the latest CA certs, OpenSSL upgrades, and other OS Level security patches which will help in protecting from the attacks.The SpendHQ applications are configured to receive the SSL traffic from ELB to EC2 Level Apache also as part of your compliance. Hence, we need to apply the strong SSL encryption at Apache level. The below config will remove the older SSL versions support and ensure the strong ssl cipher policies.SSLProtocol         all -SSLv3 -TLSv1 -TLSv1.1SSLCipherSuite      ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:!ECDSA:!NULL:!MD5:!DSS:!3DESSSLHonorCipherOrder onSSLCompression      offSSLSessionTickets   off Our team is always sending the monthly reports with the security best practices and for every quarter we are following up on the OS Level patching with SpendHQ. To address this, we can get on a call, create an action plan and implement them phases wise in Pre-prod and production environments respectively. And after that, we mandatorily meet every month, review the monthly report and create action items, if anything needs to be addressed. Praveen Muppala","Hello Matthew,Thanks for bringing it our attention. We apologize that our system did not detect these vulnerabilities.Let us review the details you have shared and will get back to you with a solution for SWEET32 attack.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013uxL6,Cloud Engineer Level 1,Closed,1030235,Incident,10-11-2016 03:57,,"Hello Team,Please ignore this alert because one of our Rean Team member was trying to login.","Failed WebAdmin login attempt from 71.59.78.232 at 2016-11-09 22:24:48 with username admin.        -- System Uptime      : 165 days 16 hours 51 minutesSystem Load        : 0.11System Version     : Sophos UTM 9.403-4Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][WARN-005] Failed WebAdmin login,,10-11-2016 03:55,0,0,SpendHQ,"Hello Team,Please ignore this alert because one of our Rean Team member was trying to login.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001J4CRt,Cloud Engineer Level 1,Closed,1082937,Incident,24-10-2017 23:39,,"Hello Allen,We have started the monitoring again.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM###Thank you, Allen, for the update. I have enabled the maintenance mode for the endpoint monitoring for https://preview.spendhq.com/login. Please let us know once you are done with the maintenance so we will start monitoring again.Thank You, Safuvan KM###Allen Herrera7:04 PM (0 minutes ago)to Rean, spendhq-support This is me again, please turn on maintenance mode for an hour Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.com###Hello SpendHQ-team, This is to notify you that we have received a site down alert for the URL https://preview.spendhq.com/login. Later the alert got resolved and the site is accessible now. The violation lasted for 5 minutes. We are investigating the alert and meanwhile please let us know if you are performing any activity from your end.Thank You,Safuvan KM","Tue, 24 Oct 2017 09:27:20 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: Atlanta-B USConfirmed by node(s): Dallas-B US, New Jersey US, Sydney-C AU, Frankfurt DE--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,24-10-2017 18:57,5,0,SpendHQ,"Hello Allen,We have started the monitoring again.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM","Thank you, Allen, for the update. I have enabled the maintenance mode for the endpoint monitoring for https://preview.spendhq.com/login. Please let us know once you are done with the maintenance so we will start monitoring again.Thank You, Safuvan KM","Allen Herrera7:04 PM (0 minutes ago)to Rean, spendhq-support This is me again, please turn on maintenance mode for an hour Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.com","Hello SpendHQ-team, This is to notify you that we have received a site down alert for the URL https://preview.spendhq.com/login. Later the alert got resolved and the site is accessible now. The violation lasted for 5 minutes. We are investigating the alert and meanwhile please let us know if you are performing any activity from your end.Thank You,Safuvan KM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001dfV6X,Cloud Engineer Level 1,Closed,1106916,Incident,01-11-2018 07:09,,"Hello Team,This is a gentle reminderPlease review the previous comments and get back to us.###Hello Team,This is to inform you of the recent notification from AWS team regarding the AWS Direct Connect service. They mentioned Between 11:31 PM and 11:42 PM PDT, there was elevated packet loss impacting Direct Connect locations accessing the US-EAST-1 Region. The issue later got resolved and the service is currently operating normally.We have checked from the personal health dashboard and everything looks good.Please reach out to us if you have any queries and/or concerns.Thanks.","Between 11:31 PM and 11:42 PM PDT, we experienced elevated packet loss impacting Direct Connect locations accessing the US-EAST-1 Region. The issue has been resolved and the service is operating normally. For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_CONNECTIVITY_ISSUE,,30-10-2018 14:08,42,0,SpendHQ,"Hello Team,This is a gentle reminderPlease review the previous comments and get back to us.","Hello Team,This is to inform you of the recent notification from AWS team regarding the AWS Direct Connect service. They mentioned Between 11:31 PM and 11:42 PM PDT, there was elevated packet loss impacting Direct Connect locations accessing the US-EAST-1 Region. The issue later got resolved and the service is currently operating normally.We have checked from the personal health dashboard and everything looks good.Please reach out to us if you have any queries and/or concerns.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001GHdEB,Cloud Engineer Level 1,Closed,1074106,Incident,23-08-2017 04:27,,"Hello Matthew,Since we haven't heard back from you regarding this case, we are marking this case as resolved. Please revert back to us if you have any queries.###Hello Matthew,We have pointed preview-spendhq-xelb load balancer to 10.59.100.170. We have also updated the Name tag on the NewPreview-ELB.Please verify from your end and let us know if you have any queries.###Can someone call me regarding this issue as that effected PRD traffic again.###Hello Matthew,We have pointed preview-spendhq-xelb load balancer to 10.59.100.170. Now we are having three instances PRD-WW, PRD-WW2, and PRD-WW1 behind preview-spend-xelb load balancer.Regarding changing of ELB name, please let us know whether we need to add name tag or change the load balancer name.We can add name tag for the ELB but we can't change the name of a load balancer, because that would break the sites that use the load balancer. ELBs have an associated DNS name, that looks like this:${balancer_name}-${opaque_identifier}.${region}.elb.amazonaws.comRenaming the load balancer, if it were allowed, would necessarily change this hostname, which is how sites are pointed to the balancer, using CNAME records or A-record aliases (in Route 53)... and that would break the sites, since they would then be pointing to a nonexistent hostname.The simplest solution is to create a new balancer with the name you want, using the same configuration.Please let us know how can  we proceed on this  and revert back to us if you have any queries###Hello Matthew,We will work on this request and will get back to you with updates.","Please point the preview-spendhq-xelb load balancer to 10.59.100.170.Please also change the name of the NewPreview-ELB to PRD-SECURE-INT-ELB.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Load balancer,,21-08-2017 21:29,31,0,SpendHQ,"Hello Matthew,Since we haven't heard back from you regarding this case, we are marking this case as resolved. Please revert back to us if you have any queries.","Hello Matthew,We have pointed preview-spendhq-xelb load balancer to 10.59.100.170. We have also updated the Name tag on the NewPreview-ELB.Please verify from your end and let us know if you have any queries.",Can someone call me regarding this issue as that effected PRD traffic again.,"Hello Matthew,We have pointed preview-spendhq-xelb load balancer to 10.59.100.170. Now we are having three instances PRD-WW, PRD-WW2, and PRD-WW1 behind preview-spend-xelb load balancer.Regarding changing of ELB name, please let us know whether we need to add name tag or change the load balancer name.We can add name tag for the ELB but we can't change the name of a load balancer, because that would break the sites that use the load balancer. ELBs have an associated DNS name, that looks like this:${balancer_name}-${opaque_identifier}.${region}.elb.amazonaws.comRenaming the load balancer, if it were allowed, would necessarily change this hostname, which is how sites are pointed to the balancer, using CNAME records or A-record aliases (in Route 53)... and that would break the sites, since they would then be pointing to a nonexistent hostname.The simplest solution is to create a new balancer with the name you want, using the same configuration.Please let us know how can  we proceed on this  and revert back to us if you have any queries","Hello Matthew,We will work on this request and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001QkWNB,Cloud Engineer Level 1,Closed,1091351,Incident,21-02-2018 20:38,,"Hello Andrew,Thank you for the confirmation. At this time, we are marking this case as resolved. Kindly revert back incase of any further queries.Regards,Sumod.K.Bose###Andrew Kim <Akim@spendhq.com>7:46 PM (0 minutes ago)to Rean, spendhq-support That you for the report. You may close this case. Andrew Kim | Director of Information Technology & Security | SpendHQ®###Hello SpendHQ TeamWe have completed the analysis and we could confirm that the site was not actually down at the time of the alert but the wormly triggered alert due to the high latency on the website. We can see there was high traffic at the time of alert in  PRD-WW2_6(10-59-101-6)  as well as the backend db instance prd-db1 - 10.59.10.190 - db. The Network IN and OUT value of the PRD-WW2_6(10-59-101-6)  instance reached to value of 5963.82 MB/min and 436.411 MB/min respectively.  Also,  prd-db1 - 10.59.10.190 - db instance was having a high Network IN traffic with a value of 9145.52 MB/min. From the attached ELB logs it is clear that there were many requests with high backend processing time. As this was not usual traffic please let us know if you were performing any activity from your end at the time of the alert.Also, let us know if you have any questions or we are good to close this case.###Hello SpendHQ-Team, We have further checked the details, the Secure-SpendHQ-ELB is pointed to the Sophos Instance and from there, it is pointed to NewPreview-ELB. PRD-WW1_122(10-59-100-122) and PRD-WW2_6(10-59-101-6) are the WebServer instances attached to the NewPeview-ELB. And the backend DB server is PRD-DB1(10.59.10.190). We have checked the ELB and instance metrics, form the ELB level we could see a high spike in latency that reached up to 230s and other metrics seems to be normal. On checking the instance level, we were able to see a high number of requests are in TIME_WAIT condition and also the network IN and OUT was high at the time. [centos@ip-10-59-101-6 ~]$ netstat -a | grep TIME | wc -l419From the backend DB server, we could see memory utilization was high and a sudden spike in Network IN and OUT.We were able to see that https://secure.spendhq.com/login was not down at the time of this alert. Because of high latency on the website, our monitoring tool was unable to access the site within the 30s of the timeout period. Hence it shows the site down alerts.Please find the attached latency logs, Network IN and OUT on the web server, and memory utilization and Network IN and OUT from DB server. Kindly validate the details from your end and let us know if you have further queries.###Hello Team, On further analysis, we were able to figure out that the URL https://secure.spendhq.com/login was not down at the time of this alert. The violation has lasted for 1 minute.We have verified the logs and we could see a sudden spike in the ELB latency graph where ELB was not able to respond to our monitoring request within the timeout period set in the monitoring tool (which is 30 seconds). Hence it has thrown the Site down alert. All of the requests within the timeframe of this issue has been served with 200 response code. As the URL https://secure.spendhq.com/login was not down, we are reducing the priority of this case from P1 to P2. We have attached the ELB access logs and latency graph during the time of this issue along with this ticket for reference. Kindly validate it for more details.###Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login. The alert got resolved within one minute and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Kindly validate these details and let us know if your team have any further queries regarding this case.","Tue, 20 Feb 2018 10:37:51 -0500Detected Error on SpendHQ SecureEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, California US, London UK, Atlanta-B US--  <https://www.reancloud.com/news/rean-cloud-awarded-cloud-contract-department-defense-worth-950-million/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,20-02-2018 21:07,24,0,SpendHQ,"Hello Andrew,Thank you for the confirmation. At this time, we are marking this case as resolved. Kindly revert back incase of any further queries.Regards,Sumod.K.Bose","Andrew Kim <Akim@spendhq.com>7:46 PM (0 minutes ago)to Rean, spendhq-support That you for the report. You may close this case. Andrew Kim | Director of Information Technology & Security | SpendHQ®","Hello SpendHQ TeamWe have completed the analysis and we could confirm that the site was not actually down at the time of the alert but the wormly triggered alert due to the high latency on the website. We can see there was high traffic at the time of alert in  PRD-WW2_6(10-59-101-6)  as well as the backend db instance prd-db1 - 10.59.10.190 - db. The Network IN and OUT value of the PRD-WW2_6(10-59-101-6)  instance reached to value of 5963.82 MB/min and 436.411 MB/min respectively.  Also,  prd-db1 - 10.59.10.190 - db instance was having a high Network IN traffic with a value of 9145.52 MB/min. From the attached ELB logs it is clear that there were many requests with high backend processing time. As this was not usual traffic please let us know if you were performing any activity from your end at the time of the alert.Also, let us know if you have any questions or we are good to close this case.","Hello SpendHQ-Team, We have further checked the details, the Secure-SpendHQ-ELB is pointed to the Sophos Instance and from there, it is pointed to NewPreview-ELB. PRD-WW1_122(10-59-100-122) and PRD-WW2_6(10-59-101-6) are the WebServer instances attached to the NewPeview-ELB. And the backend DB server is PRD-DB1(10.59.10.190). We have checked the ELB and instance metrics, form the ELB level we could see a high spike in latency that reached up to 230s and other metrics seems to be normal. On checking the instance level, we were able to see a high number of requests are in TIME_WAIT condition and also the network IN and OUT was high at the time. [centos@ip-10-59-101-6 ~]$ netstat -a | grep TIME | wc -l419From the backend DB server, we could see memory utilization was high and a sudden spike in Network IN and OUT.We were able to see that https://secure.spendhq.com/login was not down at the time of this alert. Because of high latency on the website, our monitoring tool was unable to access the site within the 30s of the timeout period. Hence it shows the site down alerts.Please find the attached latency logs, Network IN and OUT on the web server, and memory utilization and Network IN and OUT from DB server. Kindly validate the details from your end and let us know if you have further queries.","Hello Team, On further analysis, we were able to figure out that the URL https://secure.spendhq.com/login was not down at the time of this alert. The violation has lasted for 1 minute.We have verified the logs and we could see a sudden spike in the ELB latency graph where ELB was not able to respond to our monitoring request within the timeout period set in the monitoring tool (which is 30 seconds). Hence it has thrown the Site down alert. All of the requests within the timeframe of this issue has been served with 200 response code. As the URL https://secure.spendhq.com/login was not down, we are reducing the priority of this case from P1 to P2. We have attached the ELB access logs and latency graph during the time of this issue along with this ticket for reference. Kindly validate it for more details.","Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login. The alert got resolved within one minute and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Kindly validate these details and let us know if your team have any further queries regarding this case.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d2mJO,Cloud Engineer Level 1,Closed,1106264,Incident,15-10-2018 20:07,,"Hello Team,This is to inform you alert regarding High Network OUT on spendhq-memsql-server1-2018-04-01 (10.59.100.191) has recovered and reached a normal value 0.63G. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Hello Team,We have analyzed the issue and we can see a spike in a couple of metrics including Network in/out, networks packet in/out and CPU utilization. We have checked the CPU utilization and we could see the memsqld process consuming high CPU at about 46.7%. Memory usage for the service was high too.   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND122594 memsql    20   0  0.112t 0.095t  37756 S  46.7 40.4   2355:09 memsqld123289 memsql    20   0  9.988g 874520  36792 S  33.3  0.3 502:50.87 memsqld122409 memsql    20   0 12.546g 764048   5720 S  20.0  0.3   2922:21 memsql-opsAttached are the CloudWatch metrics for the same. Please review and let us know if you have any questions.Thanks.###Hello Team,This is to notify you that we have received an alert regarding High Network OUT on spendhq-memsql-server1-2018-04-01  (10.59.100.191).We are analyzing the issue and will get back to you with the updates.Resource Details:Name: SpendHQ-memsql-server1-2018-04-01Instance ID: i-073579ff33c73d3cdInstance Type: i3.8xlargeAZ: us-east-1bIP: 10.59.100.191VPC ID: vpc-76df7212Thanks.","[image: Datadog][Triggered] [SpendHQ] - High Network OUT on host -spendhq-memsql-server1-2018-04-01 - 10.59.100.191 -High Network OUT on the instance. Please check the list open TCPConnections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024199?to_ts=1539610649000&group=host%3Ai-073579ff33c73d3cd&from_ts=1539603449000>*aws.ec2.network_out* over *datadog_monitor:on,host:i-073579ff33c73d3cd*was *> 1100000000.0* at all times during the *last 30m*.The monitor was last triggered at Mon Oct 15 2018 13:37:39 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024199?group=host%3Ai-073579ff33c73d3cd>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024199/edit>] · [Viewi-073579ff33c73d3cd<https://app.datadoghq.com/infrastructure?filter=i-073579ff33c73d3cd>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1539610779000&tags=host%3Ai-073579ff33c73d3cd&from_ts=1539609759000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4619569460813546563>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Hosea B. Getusi,*Cloud Engineer,**REĀN Cloud | **Reach, Engage, Āctivate, Nurtur**Mobile*: +254713404220 | *Skype*: hoseagetusi*hosea.getusi@reancloud.com <hosea.getusi@reancloud.com>* |  *www.reancloud.com<http://www.reancloud.com>*--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - spendhq-memsql-server1-2018-04-01 - 10.59.100.191 -,,15-10-2018 19:13,1,0,SpendHQ,"Hello Team,This is to inform you alert regarding High Network OUT on spendhq-memsql-server1-2018-04-01 (10.59.100.191) has recovered and reached a normal value 0.63G. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Hello Team,We have analyzed the issue and we can see a spike in a couple of metrics including Network in/out, networks packet in/out and CPU utilization. We have checked the CPU utilization and we could see the memsqld process consuming high CPU at about 46.7%. Memory usage for the service was high too.   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND122594 memsql    20   0  0.112t 0.095t  37756 S  46.7 40.4   2355:09 memsqld123289 memsql    20   0  9.988g 874520  36792 S  33.3  0.3 502:50.87 memsqld122409 memsql    20   0 12.546g 764048   5720 S  20.0  0.3   2922:21 memsql-opsAttached are the CloudWatch metrics for the same. Please review and let us know if you have any questions.Thanks.","Hello Team,This is to notify you that we have received an alert regarding High Network OUT on spendhq-memsql-server1-2018-04-01  (10.59.100.191).We are analyzing the issue and will get back to you with the updates.Resource Details:Name: SpendHQ-memsql-server1-2018-04-01Instance ID: i-073579ff33c73d3cdInstance Type: i3.8xlargeAZ: us-east-1bIP: 10.59.100.191VPC ID: vpc-76df7212Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001dfaAB,Cloud Engineer Level 1,Closed,1106942,Incident,01-11-2018 07:49,,"Hello Team,Since the alert has recovered we are marking this case as resolved and closing the case.Please review our previous analysis and let us know your thoughts on the same.Thanks,###Hello Team,This is to notify you that the alert regarding  High Network Out on the host SpendHQ-memsql-server1-2018-04-01 in us-east-1 region recovered and the monitor is now on OK state with a value of 2.56M, the violation lasted for 1 hour.Please have a look at our shared analysis and let us know your thoughts on the same.###Hello Team,This is to notify you that we have received an alert regarding High Network Out on the host SpendHQ-memsql-server1-2018-04-01  in us-east-1 region.From checking we could see that the current number of open TCP Connections is at 447458. We have attached the details of the Open TCP connections on the ticket.Please let us know if you have any queries.Thanks.Resource Details:Instance ID:	i-073579ff33c73d3cd	Instance Name:  	SpendHQ-memsql-server1-2018-04-01	Availability Zone:	us-east-1b	Region:	us-east-1Subnet ID:	subnet-0d093d27	VPC:	vpc-76df7212Private IP Address: 	10.59.100.191","[image: Datadog][Triggered] [SpendHQ] - High Network OUT on host -spendhq-memsql-server1-2018-04-01 - 10.59.100.191 -High Network OUT on the instance. Please check the list open TCPConnections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024199?to_ts=1540912649000&group=host%3Ai-073579ff33c73d3cd&from_ts=1540905449000>*aws.ec2.network_out* over *datadog_monitor:on,host:i-073579ff33c73d3cd*was *> 1100000000.0* at all times during the *last 30m*.The monitor was last triggered at Tue Oct 30 2018 15:17:39 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024199?group=host%3Ai-073579ff33c73d3cd>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024199/edit>] · [Viewi-073579ff33c73d3cd<https://app.datadoghq.com/infrastructure?filter=i-073579ff33c73d3cd>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1540912779000&tags=host%3Ai-073579ff33c73d3cd&from_ts=1540911759000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4641413395290573374>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Paul MulonziaREĀN Cloud | Reach, Engage, Āctivate, Nurtur--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - spendhq-memsql-server1-2018-04-01 - 10.59.100.191 -,,30-10-2018 20:54,35,0,SpendHQ,"Hello Team,Since the alert has recovered we are marking this case as resolved and closing the case.Please review our previous analysis and let us know your thoughts on the same.Thanks,","Hello Team,This is to notify you that the alert regarding  High Network Out on the host SpendHQ-memsql-server1-2018-04-01 in us-east-1 region recovered and the monitor is now on OK state with a value of 2.56M, the violation lasted for 1 hour.Please have a look at our shared analysis and let us know your thoughts on the same.","Hello Team,This is to notify you that we have received an alert regarding High Network Out on the host SpendHQ-memsql-server1-2018-04-01  in us-east-1 region.From checking we could see that the current number of open TCP Connections is at 447458. We have attached the details of the Open TCP connections on the ticket.Please let us know if you have any queries.Thanks.Resource Details:Instance ID:	i-073579ff33c73d3cd	Instance Name:  	SpendHQ-memsql-server1-2018-04-01	Availability Zone:	us-east-1b	Region:	us-east-1Subnet ID:	subnet-0d093d27	VPC:	vpc-76df7212Private IP Address: 	10.59.100.191",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014KkXm,Cloud Engineer Level 1,Closed,1033067,Incident,22-11-2016 14:40,,Please ignore this alert as one of our Team member was trying to login.,"Failed WebAdmin login attempt from 183.82.110.76 at 2016-11-22 09:04:52 with username sumod.kurianbose.        -- System Uptime      : 10 days 1 hour 19 minutesSystem Load        : 0.10System Version     : Sophos UTM 9.408-4Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][WARN-005] Failed WebAdmin login,,22-11-2016 14:35,218,0,SpendHQ,Please ignore this alert as one of our Team member was trying to login.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001KodFE,Cloud Engineer Level 1,Closed,1085103,Incident,23-11-2017 08:17,,"Hello Allen,We haven't heard back from you.We have mounted the new volume to 10.59.10.243 server under /mnt/production_22112017. Please validate and let us know if you have any further queries regarding this.###Hello Chris,Thanks for providing the volume details.@Allen: We have mounted the new volume to 10.59.10.243 server under /mnt/production_22112017.Please validate and let us know if you have any further queries regarding this.###Ok - I need a name for the volume....Chris Veillette###OK Everyone,Here is the  500 GB volume and  name: Map-B-171122you should be able to see it....###Hello Allen,We will look into your request and will get back to you with the updates.@Chris: Could you please create a new ISCSI volume with 500 GB size and provide us with the volume details so that we will mount it to the 10.59.10.243 server.","Hey Rean,Can we get an iSCSI mount of 500GB on the server 10.59.10.243 for additional storage.Please mount at /mnt/{nameOfMount}Allen Herrera | Developer | SpendHQ(r)M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",New mnt volume of 500GB,,22-11-2017 19:55,27,0,SpendHQ,"Hello Allen,We haven't heard back from you.We have mounted the new volume to 10.59.10.243 server under /mnt/production_22112017. Please validate and let us know if you have any further queries regarding this.","Hello Chris,Thanks for providing the volume details.@Allen: We have mounted the new volume to 10.59.10.243 server under /mnt/production_22112017.Please validate and let us know if you have any further queries regarding this.",Ok - I need a name for the volume....Chris Veillette,"OK Everyone,Here is the  500 GB volume and  name: Map-B-171122you should be able to see it....","Hello Allen,We will look into your request and will get back to you with the updates.@Chris: Could you please create a new ISCSI volume with 500 GB size and provide us with the volume details so that we will mount it to the 10.59.10.243 server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bkHOc,Cloud Engineer Level 1,Closed,1104660,Incident,28-09-2018 12:33,,"Hi Andrew,As discussed during our monthly call, we will differ the usage of unused and underutilized EBS volumes post working on low utilization of EC2 machines. We will revisit this action item next month. Thank you!RegardsChirodeep###@Team,Since we have sent several followup on these cases, we have mentioned this in the morning call to Chirodeep. he will be checking this and will let us know whether we can close this case. Please check with him in the evening ops call if there is no update from him.###Hello Andrew/Mathew, We haven't received any response from you. Please review our previous comment and let us know if we can proceed with deletion of EBS volumes.###Hello Andrew/Mathew,We haven't received any response from you. Please review our previous comment and let us know if we can proceed with deletion of EBS volumes.###Hello Andrew/Mathew,This is a gentle reminder, Please review our previous communication and let us know if we can proceed to delete the unused EBS volumes. Resource Details: Resource ID: vol-08525b5a8797e3935 Volume Name: A3-DX-Failover-Test-Fix Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-05-10 Size: 500 GiB Age: 127 days Resource ID: vol-060c6db8b26f5244f Type: General Purpose SSD Owner: spendhq-support@reancloud.com Region: us-east-1 Creation Date: 2018-06-07 Size: 8 GiB Age: 99 days Resource ID: vol-0e921824fccece88c Volume Name: SpendHQ-Server1-2018-06-15clone Type: General Purpose SSD Owner: spendhq-support@reancloud.com Region: us-east-1 Creation Date: 2018-06-16 Size: 50 GiB Age: 90 days Resource ID: vol-78e4f4c5 Volume Name: CloudEndure Volume u978v Type: Standard Region: us-west-1 Creation Date: 2016-05-25 Size: 10 GiB Age: 841 days###Hello Andrew/MathewThis is a gentle reminderPlease review the volumes marked as unused and get back to us.###Hello Matthew/Andrew, Please review our previous communication and let us know if we can proceed to delete the unused EBS volumes. Resource Details: Resource ID: vol-08525b5a8797e3935 Volume Name: A3-DX-Failover-Test-Fix Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-05-10 Size: 500 GiB Age: 127 days Resource ID: vol-060c6db8b26f5244f Type: General Purpose SSD Owner: spendhq-support@reancloud.com Region: us-east-1 Creation Date: 2018-06-07 Size: 8 GiB Age: 99 days Resource ID: vol-0e921824fccece88c Volume Name: SpendHQ-Server1-2018-06-15clone Type: General Purpose SSD Owner: spendhq-support@reancloud.com Region: us-east-1 Creation Date: 2018-06-16 Size: 50 GiB Age: 90 days Resource ID: vol-78e4f4c5 Volume Name: CloudEndure Volume u978v Type: Standard Region: us-west-1 Creation Date: 2016-05-25 Size: 10 GiB Age: 841 days###Hello Matthew/Andrew,Please review our previous communication and let us know if we can proceed to delete the unused EBS volumes.Resource Details:Resource ID: vol-08525b5a8797e3935 Volume Name: A3-DX-Failover-Test-Fix Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-05-10 Size: 500 GiB Age: 127 days Resource ID: vol-060c6db8b26f5244f Type: General Purpose SSD Owner: spendhq-support@reancloud.comRegion: us-east-1 Creation Date: 2018-06-07 Size: 8 GiB Age: 99 days Resource ID: vol-0e921824fccece88c Volume Name: SpendHQ-Server1-2018-06-15clone Type: General Purpose SSDOwner: spendhq-support@reancloud.comRegion: us-east-1 Creation Date: 2018-06-16 Size: 50 GiB Age: 90 days Resource ID: vol-78e4f4c5 Volume Name: CloudEndure Volume u978v Type: Standard Region: us-west-1 Creation Date: 2016-05-25 Size: 10 GiB Age: 841 days###waiting for customer response.","Hello Matt/Andrew, Let us know, if we can clean up these volumes. From: ms@reancloud.com <ms@reancloud.com> Sent: September 14, 2018 10:04 AMTo: spendhq-support@reancloud.comSubject: [Managed Cloud: spendhq] Ununsed Ebs Volume check REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud. The following AWS::EC2::Volume resources were affected:   _____  *	Violation: EBS volume is not attached any stopped or running EC2 instance.*	Recommendation: Review the use of the unattached EBS volume. Unattached EBS volume are chargeable.*	Action taken: None*	Resource details: Resource IDVolume NameTypeOwnerRegionCreation DateSizeAgevol-08525b5a8797e3935A3-DX-Failover-Test-FixGeneral Purpose SSD	us-east-12018-05-10500 GiB127 daysvol-060c6db8b26f5244f	General Purpose SSDspendhq-support@reancloud.com <mailto:spendhq-support@reancloud.com> us-east-12018-06-078 GiB99 daysvol-0e921824fccece88cSpendHQ-Server1-2018-06-15cloneGeneral Purpose SSDspendhq-support@reancloud.com <mailto:spendhq-support@reancloud.com> us-east-12018-06-1650 GiB90 daysvol-78e4f4c5CloudEndure Volume u978vStandard	us-west-12016-05-2510 GiB841 days  _____  Best Regards, REAN Cloud Team IMPORTANT: Please do not reply to this message or email address. --  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: [Managed Cloud: spendhq] Ununsed Ebs Volume check,,14-09-2018 20:05,328,0,SpendHQ,"Hi Andrew,As discussed during our monthly call, we will differ the usage of unused and underutilized EBS volumes post working on low utilization of EC2 machines. We will revisit this action item next month. Thank you!RegardsChirodeep","@Team,Since we have sent several followup on these cases, we have mentioned this in the morning call to Chirodeep. he will be checking this and will let us know whether we can close this case. Please check with him in the evening ops call if there is no update from him.","Hello Andrew/Mathew, We haven't received any response from you. Please review our previous comment and let us know if we can proceed with deletion of EBS volumes.","Hello Andrew/Mathew,We haven't received any response from you. Please review our previous comment and let us know if we can proceed with deletion of EBS volumes.","Hello Andrew/Mathew,This is a gentle reminder, Please review our previous communication and let us know if we can proceed to delete the unused EBS volumes. Resource Details: Resource ID: vol-08525b5a8797e3935 Volume Name: A3-DX-Failover-Test-Fix Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-05-10 Size: 500 GiB Age: 127 days Resource ID: vol-060c6db8b26f5244f Type: General Purpose SSD Owner: spendhq-support@reancloud.com Region: us-east-1 Creation Date: 2018-06-07 Size: 8 GiB Age: 99 days Resource ID: vol-0e921824fccece88c Volume Name: SpendHQ-Server1-2018-06-15clone Type: General Purpose SSD Owner: spendhq-support@reancloud.com Region: us-east-1 Creation Date: 2018-06-16 Size: 50 GiB Age: 90 days Resource ID: vol-78e4f4c5 Volume Name: CloudEndure Volume u978v Type: Standard Region: us-west-1 Creation Date: 2016-05-25 Size: 10 GiB Age: 841 days",Hello Andrew/MathewThis is a gentle reminderPlease review the volumes marked as unused and get back to us.,"Hello Matthew/Andrew, Please review our previous communication and let us know if we can proceed to delete the unused EBS volumes. Resource Details: Resource ID: vol-08525b5a8797e3935 Volume Name: A3-DX-Failover-Test-Fix Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-05-10 Size: 500 GiB Age: 127 days Resource ID: vol-060c6db8b26f5244f Type: General Purpose SSD Owner: spendhq-support@reancloud.com Region: us-east-1 Creation Date: 2018-06-07 Size: 8 GiB Age: 99 days Resource ID: vol-0e921824fccece88c Volume Name: SpendHQ-Server1-2018-06-15clone Type: General Purpose SSD Owner: spendhq-support@reancloud.com Region: us-east-1 Creation Date: 2018-06-16 Size: 50 GiB Age: 90 days Resource ID: vol-78e4f4c5 Volume Name: CloudEndure Volume u978v Type: Standard Region: us-west-1 Creation Date: 2016-05-25 Size: 10 GiB Age: 841 days","Hello Matthew/Andrew,Please review our previous communication and let us know if we can proceed to delete the unused EBS volumes.Resource Details:Resource ID: vol-08525b5a8797e3935 Volume Name: A3-DX-Failover-Test-Fix Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-05-10 Size: 500 GiB Age: 127 days Resource ID: vol-060c6db8b26f5244f Type: General Purpose SSD Owner: spendhq-support@reancloud.comRegion: us-east-1 Creation Date: 2018-06-07 Size: 8 GiB Age: 99 days Resource ID: vol-0e921824fccece88c Volume Name: SpendHQ-Server1-2018-06-15clone Type: General Purpose SSDOwner: spendhq-support@reancloud.comRegion: us-east-1 Creation Date: 2018-06-16 Size: 50 GiB Age: 90 days Resource ID: vol-78e4f4c5 Volume Name: CloudEndure Volume u978v Type: Standard Region: us-west-1 Creation Date: 2016-05-25 Size: 10 GiB Age: 841 days",waiting for customer response.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DHgpR,Cloud Engineer Level 1,Closed,1063749,Incident,20-06-2017 05:28,,"Hello Team,This is to notify you that we got an alert regarding volume usage alert for prod-sphq-db-server05 got resolved and returned to a normal value of 57%.###Hello Team, On further analysis, we could see /dev/xvda1 mounted on / is consuming high volume usage on this instance. Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 ext4 50G 47G 16M 100% / Please find the volume usage in / 7.5T total 5.2T mnt 2.3T var 21G tmp 13G usr Please delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.###Hello Team, This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% and reached to a value of 99%. We are analyzing the disk usage details and will share it with you shortly.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Tue, Jun 20, 2017 at 4:23 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjT0PgjAYhH8N3Wz6Qb-GDqZqTJwddDGlLwUSoAhl8N9bkhue3OXuwArTtGiwjFBFJDWMCc4llpIbjS_FZEY4rphzV8GrmkCGDoeEehsDl5ozGhrNJERVQyPqUGuqRBtLhEbb57xsFT9X7FbklwWDzx5S13_LxnR4IaR9zoWWNcVhbAvtJ_Im7vP4vZ70vqPVTls5Xls_hzHtcDRRtlOah5zWP_N2Obw>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj0luwzAMRU8jLwWJjAYutCic-hqBbMkDEEeurQQ5fhmjiwIEh0_w4TMFQ31ulgBKO2U1ARhEK61F8vLKIpBp0UHbfhsUF5VqmuRQmjlERTmhTyM5NfbWeD1iGnxWbgDvoW_uYa51OwR-Ceg44rbJFGtMZZp_mLGytpbHUst-CEBQgGRJYFfLrfLZVV_IkQbnSCklwE57eW6sp_xahizYKZMNdDyf9f1KUX-6di5HPfdaSUOSs0bDhHEv63-2Nie72cN68HN7jo_hXp7p466p4c_dLxXHUvA>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Mon Jun 19 2017 22:53:00 UTC (*35 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtTkGOwyAMfA0cEdgxCQcOq3TzD4ppEqkp2YRW-_x1q5Use2YszQxHCtei1wjW9da7AECI3niPYTAXESHQiD2M4zeh6iw3nk2ueolXzEOXiLkHzB1hwSH7VG5Chd-Kvseltf1U-KVgkkn7bji1xHVefsRjE22rj7XV41SAYAGDDwqn-ajPXeGFy2vNRUkjcSCYhH_u74uTe6NxqWf7_J01FIxsh6SPuJ1S9Sjpke_1ye8s3eJ_1h_uNUZQ>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjUEOwiAQRU8DSwIzMnQWLEzVe9AOtk1aqS3eX0xM_uol732JnoeslwjWBUuOATwiGSLkztwaBPY9Buj7u0d1sVJlMmPRc3RIyQZOwO45dE4yMWEgGnISGQX1Guda91PhVcGjLe27kVSTlGl-t8bW2FZeSy3HqQDBAjJxg1mWqo-4ne3vyOk1ruUjP0HX-Be-9hM2Uw>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVjUsOwyAQQ08DS8QnkMyCRZU095gE8pFKSGFy_1LJsqwn2Q7ewhL56bVUvXQKtLbGOOGcgUFMDWqwo-n1OL6tYZ0MFHaxZn542CSsGsBFjHHZFmXdIgdnMQyD7GTPP_4guiszL6bnJrxvEZAw5P34to3U2HltBSuVZ6WnRGbmI1e6MLU4KSksiObKWF58qu2-RLzWT37Cv8_Jp3ydlMsPbdI7Yg>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jc0OgyAQhJ9GjoZlWXAPHBqt74GCP4mKVdrnL700mWSSL_lmgiMeolidkmClAVaKEE1tDHJTdwUqphatatsnYaVlyGGuxyQWp8FHxdIWcxr0EK2msZkAvAX05FFsbsn5vCt8VKov8edZB599SPPyKht7YfETj_xv7NdQYYcMzEzGMJAGyWhIXG6_y_0V_TFu6R1-vshuT8ea0_UFyKM4_Q>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjcsOgyAURL9GloQ3smDR2PY_rlxQExWK-P_FZBaTk5MZ9NrNkWxeMG6Z4U4ILaWhxkg30neHwulJWjFNHy0HxbDhQkMmqwfHgoIgQI2JpQTAuY0OEqRZWQQku19bK9cgX4P49kApFKEB5mX99Y3jYSHk-2y9lRpTrPEM8SLVH1f_qhHOsOcbH5k0f-Rza7n-AdUrN8Q>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,20-06-2017 04:33,1,0,SpendHQ,"Hello Team,This is to notify you that we got an alert regarding volume usage alert for prod-sphq-db-server05 got resolved and returned to a normal value of 57%.","Hello Team, On further analysis, we could see /dev/xvda1 mounted on / is consuming high volume usage on this instance. Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 ext4 50G 47G 16M 100% / Please find the volume usage in / 7.5T total 5.2T mnt 2.3T var 21G tmp 13G usr Please delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.","Hello Team, This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% and reached to a value of 99%. We are analyzing the disk usage details and will share it with you shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DpJOb,Cloud Engineer Level 1,Closed,1066769,Incident,05-07-2017 20:18,,"Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 3.11.Later the alert got resolved automatically and return to a normal state with the value of 2.905.","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.11This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3942684977649987475 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,05-07-2017 20:03,0,0,SpendHQ,"Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 3.11.Later the alert got resolved automatically and return to a normal state with the value of 2.905.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Qi5rD,Cloud Engineer Level 1,Closed,1090695,Incident,13-02-2018 07:22,,"Hell Team,From, our initial analysis, we could see that httpd process is consuming high memory.Later the alert got resolved and return to normal state.At this time we are marking this case closed.###Hello Team, This is to inform you that we have revied alerts regarding the high CPU utilization and CPU Load on the instance  prd-ww2_6. The CPU utilization has exceeded the threshold value of 80%.We are currently analyzing more on this issue and will revert back to your team with further updates shortly.Refer the below resource details, Instance ID: i-01ac95c23ac66a40eInstance type: c4.2xlarge Availability zone: us-east-1c Private IP: 10.59.101.6VPC ID: vpc-76df7212 Subnet ID: subnet-29b09361","Regards,*Yogesh Maloo**Senior Cloud Engineer,**REĀN Cloud **Mobile*: +918003126272 | *Skype*: ykmalooyogesh.maloo@reancloud.com | www.reancloud.com<http://twitter.com/ykmaloo> <http://us.linkedin.com/in/ykmaloo><http://facebook.com/ykmaloo><http://github.com/ykmaloo>On Mon, Feb 12, 2018 at 11:21 PM, Datadog Alerting <alert@datadoghq.com>wrote:> [image: Datadog]>> [Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6> - 10.59.101.6 - web>> Detected High MEMORY utilization. Log in to the machine and verify which> process is consuming high MEMORY resources> @ms@reancloud.com> <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>>> [image: Metric Graph]> <https://app.datadoghq.com/monitors#2023977?to_ts=1518457907000&group=host%3Ai-01ac95c23ac66a40e&from_ts=1518457607000>>> avg(last_5m):( avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}> by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}> by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}> by {host} * 100 > 80>> The monitor was last triggered at Mon Feb 12 2018 17:51:57 UTC (*1 sec> ago*).> ------------------------------>> [Monitor Status> <https://app.datadoghq.com/monitors#2023977?group=host%3Ai-01ac95c23ac66a40e>]> · [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [View> i-01ac95c23ac66a40e> <https://app.datadoghq.com/infrastructure?hostname=i-01ac95c23ac66a40e>]> · [Show Processes> <https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1518457917000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1518457017000&live=false&showSummaryGraphs=true>> ]>> This alert was raised by account SpendHQ>> Comment in Datadog> <https://app.datadoghq.com/event/event?id=4264685307044590067>>> To manage your Datadog subscriptions, click here> <https://app.datadoghq.com/account/preferences>.>>--  <https://www.reancloud.com/news/rean-cloud-awarded-cloud-contract-department-defense-worth-950-million/>--  <https://www.reancloud.com/news/rean-cloud-awarded-cloud-contract-department-defense-worth-950-million/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 - 10.59.101.6 - web,,13-02-2018 00:49,7,0,SpendHQ,"Hell Team,From, our initial analysis, we could see that httpd process is consuming high memory.Later the alert got resolved and return to normal state.At this time we are marking this case closed.","Hello Team, This is to inform you that we have revied alerts regarding the high CPU utilization and CPU Load on the instance  prd-ww2_6. The CPU utilization has exceeded the threshold value of 80%.We are currently analyzing more on this issue and will revert back to your team with further updates shortly.Refer the below resource details, Instance ID: i-01ac95c23ac66a40eInstance type: c4.2xlarge Availability zone: us-east-1c Private IP: 10.59.101.6VPC ID: vpc-76df7212 Subnet ID: subnet-29b09361",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001jlpiC,Cloud Engineer Level 1,Closed,1112317,Incident,25-02-2019 06:49,,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved/Closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,###Hello Team, The version for poc-vendor-elasticsearch-box is 6.3. We look forward to serving you. Feel free to reach out to us in case you are facing any issues. Thanks###Hello Team,The version for poc-vendor-elasticsearch-box is 6.3.We look forward to serving you. Feel free to reach out to us in case you are facing any issues.Thanks###Hi David,The version for poc-vendor-elasticsearch-box is 6.3Please let us know if you have any issue. Thanks.Rohit Puri###Hi Nishad,  we were able to resolve the issue, could you however confirm the ElasticSearch version we are using? David###Rohit is checking on this issue.###@TeamI didn't get a chance to look into this case, Please check on this.###Hello David,We will check on this and will get back to you with an update.RegardsNishad Ali",***** EXTERNAL EMAIL *****Reanhttps://vpc-poc-vendor-elasticsearch-box-colduyv7t6efhtcsbeblktqfzu.us-east-1.es.amazonaws.comI’m receiving “No alive nodes found in your cluster” when trying to interact with this server.  Please investigate and let us know if there is something that needs to be fixed.Thank YouDavidDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/> | Schedule a Meeting<https://calendly.com/dmillershq>,ElasticSearch,,20-02-2019 02:04,125,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved/Closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,","Hello Team, The version for poc-vendor-elasticsearch-box is 6.3. We look forward to serving you. Feel free to reach out to us in case you are facing any issues. Thanks","Hello Team,The version for poc-vendor-elasticsearch-box is 6.3.We look forward to serving you. Feel free to reach out to us in case you are facing any issues.Thanks","Hi David,The version for poc-vendor-elasticsearch-box is 6.3Please let us know if you have any issue. Thanks.Rohit Puri","Hi Nishad,  we were able to resolve the issue, could you however confirm the ElasticSearch version we are using? David",Rohit is checking on this issue.,"@TeamI didn't get a chance to look into this case, Please check on this.","Hello David,We will check on this and will get back to you with an update.RegardsNishad Ali",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DDpCV,Cloud Engineer Level 1,Closed,1063073,Incident,16-06-2017 02:55,,"Hello SpendHQ Team, This is to inform you that the alert regarding volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume got resolved and has returned to normal with a value of 50.2%. The violation has lasted for 10 minutes.###Hello SpendHQ Team,This is to notify you that we have received an volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% to 99.8%. We are investigating the alert and let us know if you have any queries.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Fri, Jun 16, 2017 at 2:37 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjT0LwyAYhH9N3Cr6JhodHIK0FDp3aJdi1HxAEq0xQ_99Ddzw3MHdOcVk79GsgNCWcMqAkpYxTIHTusGy1lfREqaBE91JXjXEZTdiG9CkRG-9AApyoOCZcMV5DtI44a1seo4WNeUc96ruKrgVmRixM9m4ME7fsrGembXh2HKhmMIwL77QcSFvoj-P3-tJ7wdKat3LcfJms0s43NlEWa1hm3NIf1LBOnY>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj02OgzAMhU8TlpHjxAleZFExwzWqDEkBqTQU0qrHn4BmMZLln2f503P0xD-pmT2CcmAVoQJHJBVapY1k3X23DqhDC92FrTAQSxzlkJvJ26QGgyYyQctDdIZim4IGl27kbEjN3U-lrLvQF4F9jbCuMoYSYh6nZ2UsVVvyYy552wVqBNRsWei-5GupZ1_KsCMLrWIAEGjHLb_Wqsf0nockkA4yYV_ns37eMaij66a8l3OvQBLLmpWmSrhtefnHJrYnu9n8stfnthQewz2_4uGuKf7P3S8PVlLi>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Thu Jun 15 2017 21:07:00 UTC (*53 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtTsuOwyAM_Bo4IrAxhAOHKrv5DwjkITUlm9BqP7-kqjSyZ2xpZpInFzNfPUhlpVEESloiocAo1MJh_9tZST0Y2d-cYVqmmmYxFr74QN1krY1W2-wS6jjZEXTqcoxRTw753S-17ifDG4OhIey7SKGGVOblr3ls7baVx1rLcTJAkIDOOIbDfJTnzvAn5dc6ZgZ0ORAMTX_2_ysFdbF-KWf9_JUU5ESbCokffjtb1SOHx3gvz3Rl8eq_WW8gqkaM>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjcsKwyAQRb9Gl6IzUTMLFyG0_2Ed84Akpon9_1oo3NWBcy4HS68s1wDaeO2MBaO9tcqAM9gpwvHRe21HcHocyIlOc-VZpSKXAB45k6OEeiJMaeKUsJvIm456jyi3sNR63gIHAc-2eJ6KY41c5uXdGntjeznWWq5bAIIGbLkGM69VXmG_29-V45G28uGfIGv4C18AEjYr>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVjcEOhCAQQ79GjoQBATlwMO76H6PDqomKi-P_L5s0TfOSthRtmJLYolbglQOrQXlrJWgHppXBDO_OKztop4Y-uKZVxLTIOYs1Buy6gLOZIBmy5AAx-U45530bgJzY48p83Y3pGz1W4XVJQkbKy_qtG0dl2_kpeHN5Zn5Kasy45ptPPGp8gZI2yOpgrCjxuOt9SXjOe37o3xccj3xunMsPdPw7Vw>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jc0OgyAQhJ9GjmbZBXQPHIyt7wGCP4mKVdrnL700meRLJvlmgtXso1gtgmzASI0SGq1riUaSqpn6Z9uA7tFA37GpFIQc5npMYrGeSCmNZvJTEUeUnkZFjtvWtYwRxWaXnM-7oq7CocSdZx1cdiHNy6ts7KWLn3jkP2lYQ0UPYqmAJRjkBomBEMRl97vcX9Ed45be4eeLbPd0rDldX9YAOOg>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjc0OhCAQg59GjoQZBOTAwZjd90AYfxIVFvH9F5MemuZrG52yM7HdoQAjNCgEYZTigBpkz62cPoMRakItptHqrhexxpWHxDYXMIDxuvWElSSNBpo14eJReujtwA631ZrvTo4dfpt8zjz66mNat1_bON8shPRctblcaKFCV6CbFXfe7auQv8KRnvjCrLozXXtN5Q9GaTY9>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,16-06-2017 02:41,0,0,SpendHQ,"Hello SpendHQ Team, This is to inform you that the alert regarding volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume got resolved and has returned to normal with a value of 50.2%. The violation has lasted for 10 minutes.","Hello SpendHQ Team,This is to notify you that we have received an volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% to 99.8%. We are investigating the alert and let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001UK6zv,Cloud Engineer Level 1,Closed,1095562,Incident,09-04-2018 21:10,,"Hello Andrew,Thanks for the update.We are not blocking the IP for now.At this time we are marking this case closed.Kindly revert back to us in case of any queries.###Please do not block this IP address at this time.Thank you.###Hello Team, This is to inform you that we have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.192 which belongs to the Preview-api-spendhq-com We have analyzed the alert and below are the details. On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 186.139.68.226 which belongs to the organization - li331-182.members.linode.com was trying to execute the Oracle WebLogic Server Remote Code ExecutionELB log:2018-04-08T18:30:24.356320Z Secure-SpendHQ-ELB 96.126.98.182:56074 10.59.1.192:443 0.00004 0.17013 0.000044 302 302 0 0 HEAD https://secure.spendhq.com:443/ HTTP/1.1 Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.67 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Please review the details and let us know if you have any queries.","---------- Forwarded message ----------From: <ms@reancloud.com>Date: Mon, Apr 9, 2018 at 12:00 AMSubject: [SpendHQ] [10.59.1.192] [CRIT-852] Intrusion Prevention Alert(Packet dropped)To: spendhq-support@reancloud.comIntrusion Count: 3Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-ORACLE Oracle WebLogic Server remote commandexecution attemptDetails........: https://www.snort.org/search?query=45304Time...........: 2018-04-08 18:30:16Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.0.127Source port: 17667Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)Account Name - SpendHQAccount DL - spendhq-support@reancloud.comUTM Hostname - spendhq-utmPrivate IP - 10.59.1.192Public IP - 52.0.17.10Device URL - https://52.0.17.10:4444--System Uptime      : 104 days 11 hours 27 minutesSystem Load        : 0.08System Version     : Sophos UTM 9.506-2Please refer to the manual for detailed instructions.-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <https://signup.paloaltonetworks.com/ehome/321670>--  <https://signup.paloaltonetworks.com/ehome/321670>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [SpendHQ] [10.59.1.192] [CRIT-852] Intrusion Prevention Alert (Packet dropped),,09-04-2018 00:33,21,0,SpendHQ,"Hello Andrew,Thanks for the update.We are not blocking the IP for now.At this time we are marking this case closed.Kindly revert back to us in case of any queries.",Please do not block this IP address at this time.Thank you.,"Hello Team, This is to inform you that we have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.192 which belongs to the Preview-api-spendhq-com We have analyzed the alert and below are the details. On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 186.139.68.226 which belongs to the organization - li331-182.members.linode.com was trying to execute the Oracle WebLogic Server Remote Code ExecutionELB log:2018-04-08T18:30:24.356320Z Secure-SpendHQ-ELB 96.126.98.182:56074 10.59.1.192:443 0.00004 0.17013 0.000044 302 302 0 0 HEAD https://secure.spendhq.com:443/ HTTP/1.1 Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.67 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Please review the details and let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XDLy2,Cloud Engineer Level 1,Closed,1099907,Incident,11-06-2018 14:32,,"Hello Team, This is a gentle reminder. This Alarm is related to AWS Direct Connect. It is regarding the packet rate for inbound data to the AWS side of the connection. We have checked and verified that the alarm is resolved and is in OK state now. Please let us know if you have any other queries regarding this.###Hello Team,This is a gentle reminder.This Alarm is related to AWS Direct Connect. It is regarding the packet rate for inbound data to the AWS side of the connection. We have checked and verified that the alarm is resolved and is in OK state now. Please let us know if you have any other queries regarding this.###Hello SpendHQ Team,This Alarm is related to AWS Direct Connect. It is regarding the packet rate for inbound data to the AWS side of the connection. We have checked and verified that the alarm is resolved and is in OK state now.Please let us know if you have any other queries regarding this.","---------- Forwarded message ----------From: SPHQ-DXMon <no-reply@sns.amazonaws.com>Date: Thu, Jun 7, 2018 at 1:36 AMSubject: ALARM: DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb in US East(N. Virginia)To: spendhq-support@reancloud.comYou are receiving this email because your Amazon CloudWatch AlarmDX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb in the US East (N. Virginia)region has entered the ALARM state, because Threshold Crossed: 1 datapoint[127344.6 (06/06/18 20:01:00)] was greater than or equal to the threshold(120000.0). at Wednesday 06 June, 2018 20:06:02 UTC.View this alarm in the AWS Management Console:https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#s=Alarms&alarm=DX-ConnectionPpsIngress-SpendHQ-Equinix-10GbAlarm Details:- Name:                       DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb- Description:                The packet rate for inbound data to the AWSside of the connection.- State Change:               OK -> ALARM- Reason for State Change:    Threshold Crossed: 1 datapoint [127344.6(06/06/18 20:01:00)] was greater than or equal to the threshold (120000.0).- Timestamp:                  Wednesday 06 June, 2018 20:06:02 UTC- AWS Account:                261234435984Threshold:- The alarm is in the ALARM state when the metric isGreaterThanOrEqualToThreshold 120000.0 for 300 seconds.Monitored Metric:- MetricNamespace:                     AWS/DX- MetricName:                          ConnectionPpsIngress- Dimensions:                          [ConnectionId = dxcon-ffpmy711]- Period:                              300 seconds- Statistic:                           Average- Unit:                                not specifiedState Change Actions:- OK:- ALARM: [arn:aws:sns:us-east-1:261234435984:SpendHQ-DirectConnect-Cloudwatch-Monitoring]- INSUFFICIENT_DATA:--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQ-DirectConnect-Cloudwatch-Monitoring:24ff3fa5-5763-4bc5-b430-6ec72c0bae22&Endpoint=spendhq-support@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support-- Thanks & Regards,Kapil BokdiaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture4th Floor, 26, Tulsi Complex,100 Feet Road, New BhupalpuraUdaipur, Rajasthan 313001kapil.bokdia@reancloud.com |+917300421033| www.reancloud.com<http://www.reancloudsolutions.com/>Toll-Free Number: +12015828406-- ISSA Conference1st June - Cyber Security At Scale <https://www.fbcinc.com/e/ISSA-ISC/agendarow.aspx>Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- ISSA Conference1st June - Cyber Security At Scale <https://www.fbcinc.com/e/ISSA-ISC/agendarow.aspx>Get Security At Cloud Speed13th June - Palo Alto/AWS/REAN event <http://go.reancloud.com/secure-your-cloud>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 19th - 21th <http://go.reancloud.com/aws-public-sector-summit-2018>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: ALARM: DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb in US East (N. Virginia),,07-06-2018 03:08,118,0,SpendHQ,"Hello Team, This is a gentle reminder. This Alarm is related to AWS Direct Connect. It is regarding the packet rate for inbound data to the AWS side of the connection. We have checked and verified that the alarm is resolved and is in OK state now. Please let us know if you have any other queries regarding this.","Hello Team,This is a gentle reminder.This Alarm is related to AWS Direct Connect. It is regarding the packet rate for inbound data to the AWS side of the connection. We have checked and verified that the alarm is resolved and is in OK state now. Please let us know if you have any other queries regarding this.","Hello SpendHQ Team,This Alarm is related to AWS Direct Connect. It is regarding the packet rate for inbound data to the AWS side of the connection. We have checked and verified that the alarm is resolved and is in OK state now.Please let us know if you have any other queries regarding this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EqwNU,Cloud Engineer Level 1,Closed,1068525,Incident,18-07-2017 09:18,,"Hello Matthew,Thanks for the update.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Matthew Watts9:15 AM (0 minutes ago)￼￼￼to Rean￼This has since been resolved. Thank you.###Hello Matthew,We are looking into the issue and we could see that the PRD URL https://secure.spendhq.com/login loading and serving well. Please find the attached screenshot.We are looking into the instance level meanwhile could you please provide more information regarding the issue.","Our PRD server is returning a proxy error!!! Treat as  a SEV ONE-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SEV ONE - CRITICAL,,18-07-2017 09:07,0,0,SpendHQ,"Hello Matthew,Thanks for the update.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.",Matthew Watts9:15 AM (0 minutes ago)￼￼￼to Rean￼This has since been resolved. Thank you.,"Hello Matthew,We are looking into the issue and we could see that the PRD URL https://secure.spendhq.com/login loading and serving well. Please find the attached screenshot.We are looking into the instance level meanwhile could you please provide more information regarding the issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001f4NPR,Cloud Engineer Level 1,Closed,1107901,Incident,26-11-2018 17:00,,"Hello Mathew,Thank you for the update. we can also see from our monitoring tool that the alert is recovered and came back to the value of 53%. At this time, we're marking this case as closed. Please re-open this case for continued support. *******Regards,Rafi RameshPune, India###Revathy Kurup <revathy.kurup@reancloud.com>*****************************************************************************Hello Mattew,Thanks for your response. We have set the threshold value as 80%. And we are getting this alert from last week with disk usage 81.5%. Please zip or delete any unwanted files/folders to help resolve this. And please let us know if you have any queries regarding this.Thanks and Regards###Matthew Watts*******************************************************What’s the threshold on this alert and I will resolve.###Hello Team,We didn't hear back from you.The alert is still in the triggered state and current usage is 81.5%.Please zip or delete any unwanted files/folders to help resolve this. Thank you###Hello Team,This is to inform you that this alert is still in ALARM state with a reading of 81.5%.Please zip or delete any unwanted files/folders to help resolve this.Thank you.###The alert still in open state. The current usage is 81.5%.###The current disk usage is 81.5%.###The current value is 80.6%.###Hello Team,Please find the breakdown details below and kindly review this details and remove or clean up the unwanted files. Please revert back to us in case of any queries.[root@ip-10-59-10-50 mapd201803]# du -sch * | sort -hr | head -20151G    total94G     mapd58G     transferredCSVs16K     lost+found[root@ip-10-59-10-50 mapd]# du -sch * | sort -hr | head -2094G     total94G     data66M     mapd_export32K     mapd_catalogs16K     mapd_data4.0K    servers.json.good4.0K    servers.json4.0K    sds4.0K    mapd-sds.conf4.0K    mapd.conf4.0K    key.pem4.0K    favicon.ico4.0K    cert.pem[root@ip-10-59-10-50 data]# du -sch * | sort -hr | head -2094G     total53G     mapd_data36G     mapd_import5.4G    mapd_log11M     mapd_catalogs4.0K    mapd_server_pid.lck4.0K    mapd_export[root@ip-10-59-10-50 mapd_data]# du -sch * | sort -hr | head -2053G     total19G     table_3_12.9G    table_4_31.9G    table_7_21.4G    table_7_31.2G    table_4_1796M    table_11_13697M    DB_3_DICT_45687M    table_10_9626M    table_5_24604M    table_10_8488M    table_11_8469M    DB_3_DICT_44460M    table_11_10458M    table_11_11451M    table_11_9451M    table_11_7348M    table_10_7327M    table_10_4290M    table_3_34[root@ip-10-59-10-50 table_3_1]# du -sch * | sort -hr | head -2019G     total513M    9.2097152.mapd513M    8.2097152.mapd513M    7.2097152.mapd513M    6.2097152.mapd513M    5.2097152.mapd513M    4.2097152.mapd513M    36.2097152.mapd513M    35.2097152.mapd513M    34.2097152.mapd513M    33.2097152.mapd513M    32.2097152.mapd513M    3.2097152.mapd513M    31.2097152.mapd513M    30.2097152.mapd513M    29.2097152.mapd513M    28.2097152.mapd513M    27.2097152.mapd513M    26.2097152.mapd513M    25.2097152.mapd###Hello Team,This is to inform you that we have received an alert regarding  EBS High Disk Usage ( /dev/sdb ) on  prd-cat-mapd_13-03-2018 (10.59.10.50) Instance. The disk usage exceeded the threshold value of 80%.We are checking this alert and will get back to you with an update.","---------- Forwarded message ---------From: Datadog Alerting <alert@dtdg.co>Date: Wed, Nov 21, 2018 at 8:07 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/sdb ) - prd-cat-mapd_13-03-2018 - 10.59.10.50To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sdb ) -prd-cat-mapd_13-03-2018 - 10.59.10.50High Disk Usage detected on the device /dev/sdb@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1542767859000&group=device%3A%2Fdev%2Fsdb%2Chost%3Ai-04da5f97cbade5646&from_ts=1542764259000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc}by {host,device} * 100 > 80The monitor was last triggered at Wed Nov 21 2018 02:37:49 UTC (*4 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fsdb%2Chost%3Ai-04da5f97cbade5646>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [Viewi-04da5f97cbade5646<https://app.datadoghq.com/infrastructure?filter=i-04da5f97cbade5646>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1542767989000&tags=host%3Ai-04da5f97cbade5646&from_ts=1542766969000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4672538662510682534>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <https://hubs.ly/H0fzGbl0>--  <https://hubs.ly/H0fzGbl0>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sdb ) - prd-cat-mapd_13-03-2018 - 10.59.10.50,,21-11-2018 08:09,129,0,SpendHQ,"Hello Mathew,Thank you for the update. we can also see from our monitoring tool that the alert is recovered and came back to the value of 53%. At this time, we're marking this case as closed. Please re-open this case for continued support. *******Regards,Rafi RameshPune, India","Revathy Kurup <revathy.kurup@reancloud.com>*****************************************************************************Hello Mattew,Thanks for your response. We have set the threshold value as 80%. And we are getting this alert from last week with disk usage 81.5%. Please zip or delete any unwanted files/folders to help resolve this. And please let us know if you have any queries regarding this.Thanks and Regards",Matthew Watts*******************************************************What’s the threshold on this alert and I will resolve.,"Hello Team,We didn't hear back from you.The alert is still in the triggered state and current usage is 81.5%.Please zip or delete any unwanted files/folders to help resolve this. Thank you","Hello Team,This is to inform you that this alert is still in ALARM state with a reading of 81.5%.Please zip or delete any unwanted files/folders to help resolve this.Thank you.",The alert still in open state. The current usage is 81.5%.,The current disk usage is 81.5%.,The current value is 80.6%.,"Hello Team,Please find the breakdown details below and kindly review this details and remove or clean up the unwanted files. Please revert back to us in case of any queries.[root@ip-10-59-10-50 mapd201803]# du -sch * | sort -hr | head -20151G    total94G     mapd58G     transferredCSVs16K     lost+found[root@ip-10-59-10-50 mapd]# du -sch * | sort -hr | head -2094G     total94G     data66M     mapd_export32K     mapd_catalogs16K     mapd_data4.0K    servers.json.good4.0K    servers.json4.0K    sds4.0K    mapd-sds.conf4.0K    mapd.conf4.0K    key.pem4.0K    favicon.ico4.0K    cert.pem[root@ip-10-59-10-50 data]# du -sch * | sort -hr | head -2094G     total53G     mapd_data36G     mapd_import5.4G    mapd_log11M     mapd_catalogs4.0K    mapd_server_pid.lck4.0K    mapd_export[root@ip-10-59-10-50 mapd_data]# du -sch * | sort -hr | head -2053G     total19G     table_3_12.9G    table_4_31.9G    table_7_21.4G    table_7_31.2G    table_4_1796M    table_11_13697M    DB_3_DICT_45687M    table_10_9626M    table_5_24604M    table_10_8488M    table_11_8469M    DB_3_DICT_44460M    table_11_10458M    table_11_11451M    table_11_9451M    table_11_7348M    table_10_7327M    table_10_4290M    table_3_34[root@ip-10-59-10-50 table_3_1]# du -sch * | sort -hr | head -2019G     total513M    9.2097152.mapd513M    8.2097152.mapd513M    7.2097152.mapd513M    6.2097152.mapd513M    5.2097152.mapd513M    4.2097152.mapd513M    36.2097152.mapd513M    35.2097152.mapd513M    34.2097152.mapd513M    33.2097152.mapd513M    32.2097152.mapd513M    3.2097152.mapd513M    31.2097152.mapd513M    30.2097152.mapd513M    29.2097152.mapd513M    28.2097152.mapd513M    27.2097152.mapd513M    26.2097152.mapd513M    25.2097152.mapd","Hello Team,This is to inform you that we have received an alert regarding  EBS High Disk Usage ( /dev/sdb ) on  prd-cat-mapd_13-03-2018 (10.59.10.50) Instance. The disk usage exceeded the threshold value of 80%.We are checking this alert and will get back to you with an update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKpW,Cloud Engineer Level 1,Closed,1042233,Incident,,,,"Hello Matthew,Sure.We are proceeding with the patching of the instance.We will create abackup image of the instance and will update the security patches on theinstance.On Sat, Jan 14, 2017 at 8:32 AM, Matthew Watts <mwatts@spendhq.com> wrote:> Can we please just image the server and perform updates once done. Please> advise when the image is complete and the upgrade.>>>> *Matthew Watts* | Manager, Data Intelligence Systems | *Spend**HQ®*>> O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com>> *A SaaS Spend Visibility solution from Insight Sourcing Group*>> www.spendhq.com | www.insightsourcing.com>>>> *From:* Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]> *Sent:* Friday, January 13, 2017 9:37 PM>> *To:* Matthew Watts <mwatts@spendhq.com>> *Cc:* REAN Support <support@reancloud.com>> *Subject:* Re: Maintenance>>>> Hello Matthew,>>>> As mentioned earlier, Andromeda team is going to clone the volume before> we proceed with the patching of the instance.Please let us know if that is> done so that we can proceed with the security patching.>>>> On Sat, Jan 14, 2017 at 8:00 AM, Matthew Watts <mwatts@spendhq.com> wrote:>> Please update the 10.59.10.12 machine first and advise when complete.>>>> *Matthew Watts* | Manager, Data Intelligence Systems | *Spend**HQ®*>> O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com>> *A SaaS Spend Visibility solution from Insight Sourcing Group*>> www.spendhq.com | www.insightsourcing.com>>>> *From:* Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]> *Sent:* Friday, January 13, 2017 9:24 PM> *To:* Matthew Watts <mwatts@spendhq.com>> *Cc:* REAN Support <support@reancloud.com>> *Subject:* Re: Maintenance>>>> Hello Matthew,>>>> We are ready for the maintenance. Please let us know once you start making> the changes.>>>> On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com> wrote:>> Rean Team are you ready to commence the updates as planned on the> 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.>>>> *Matthew Watts* | Manager, Data Intelligence Systems | *Spend**HQ®*>> O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com>> *A SaaS Spend Visibility solution from Insight Sourcing Group*>> *www.spendhq.com <http://www.spendhq.com/>* | *www.insightsourcing.com> <http://www.insightsourcing.com/>*>>>>>>>> -->> Mrigank Saxena>> REĀN Cloud Solutions | Reach, Engage, Activate, Nurture>> 2201 Cooperative Way #250, Herndon, VA 20171>> Cloud Consulting | Secure Managed Services | AWS VAR>> [image: Image removed by sender.]>>>> [image: Image removed by sender.]> <https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>>>    - REAN Cloud Achieves AWS Financial Services Competency>    <https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>>    - REAN Cloud is Premier Consulting Partner 2017>    <https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>>    - REAN Cloud receives 8 AWS Service Designations>    <https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>>    - Accelerate the Application Life Cycle with REAN DevOpsNow>    <https://www.reancloud.com/devopsnow/>>>>>>>>> -->> Mrigank Saxena>> REĀN Cloud Solutions | Reach, Engage, Activate, Nurture>> 2201 Cooperative Way #250, Herndon, VA 20171>> Cloud Consulting | Secure Managed Services | AWS VAR>> [image: Image removed by sender.]>>>> [image: Image removed by sender.]> <https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>>>    - REAN Cloud Achieves AWS Financial Services Competency>    <https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>>    - REAN Cloud is Premier Consulting Partner 2017>    <https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>>    - REAN Cloud receives 8 AWS Service Designations>    <https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>>    - Accelerate the Application Life Cycle with REAN DevOpsNow>    <https://www.reancloud.com/devopsnow/>>>>-- Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Maintenance,,14-01-2017 08:35,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Doqzc,Cloud Engineer Level 1,Closed,1066466,Incident,03-07-2017 21:57,,"Hello SpendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 76%. The violation lasted for around 3 hours.As the alert got resolved, we are marking this case as closed. Kindly validate these details and let us know incase of any further queries.Regards,Sumod.K.Bose###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 99%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1     ext4    50G   46G  676M  99% / Files under root directory, 19G     usr15G     tmp12G     var474M    home285M    lib282M    optFiles under /tmp folder, 5.4G    liger_view_41abb8e65f688db087e5e76d16c36ac6.csv1.8G    liger_view_1a1784cff20ed80ad102e4266bbd6feb.csv641M    liger_view_f5c5dbd66b2f7c9eae941ce0b7f4e4a5.csv641M    liger_view_172378803024581fcd8fce8f7b56b8f9.csv604M    liger_view_8869c32bbcef55ee9af623dc15fddbae.csv583M    liger_view_fc2e6a440b94f64831840137698021e1.csv577M    liger_view_67ac61a6b8a7d5bb5b1e03402f9def89.csv577M    liger_view_4186b8943907012bd947930996fe9051.csv513M    liger_view_eaba129337280be02034b81c3cef9c3a.csv513M    liger_view_cf9f14ec811aabfbdc1dd92544967dd2.csv513M    liger_view_492a6be898c881b1868f4b3e459dd3ea.csv490M    liger_view_598fa1779fbcfaeb2e97a27a92b4620f.csv452M    liger_view_5352fd004a09d74e72d57891a66ea828.csv449M    liger_view_f9ac6e7f5788b2afce5989cc3ae584f5.csv449M    liger_view_f81715e198d92a9a71609762b7fb2640.csv385M    liger_view_1a904605387ef9d312e1b8b16a4e2cba.csv222M    liger_view_ad4bf54b69c664e169691d4cc5810df2.csvDelete/zip unwanted files or folders to reduce the current volume usage state on this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135 Regards, Sumod.K.Bose","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 90.186This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3939678698279054438 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,03-07-2017 18:16,4,0,SpendHQ,"Hello SpendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 76%. The violation lasted for around 3 hours.As the alert got resolved, we are marking this case as closed. Kindly validate these details and let us know incase of any further queries.Regards,Sumod.K.Bose","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 99%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1     ext4    50G   46G  676M  99% / Files under root directory, 19G     usr15G     tmp12G     var474M    home285M    lib282M    optFiles under /tmp folder, 5.4G    liger_view_41abb8e65f688db087e5e76d16c36ac6.csv1.8G    liger_view_1a1784cff20ed80ad102e4266bbd6feb.csv641M    liger_view_f5c5dbd66b2f7c9eae941ce0b7f4e4a5.csv641M    liger_view_172378803024581fcd8fce8f7b56b8f9.csv604M    liger_view_8869c32bbcef55ee9af623dc15fddbae.csv583M    liger_view_fc2e6a440b94f64831840137698021e1.csv577M    liger_view_67ac61a6b8a7d5bb5b1e03402f9def89.csv577M    liger_view_4186b8943907012bd947930996fe9051.csv513M    liger_view_eaba129337280be02034b81c3cef9c3a.csv513M    liger_view_cf9f14ec811aabfbdc1dd92544967dd2.csv513M    liger_view_492a6be898c881b1868f4b3e459dd3ea.csv490M    liger_view_598fa1779fbcfaeb2e97a27a92b4620f.csv452M    liger_view_5352fd004a09d74e72d57891a66ea828.csv449M    liger_view_f9ac6e7f5788b2afce5989cc3ae584f5.csv449M    liger_view_f81715e198d92a9a71609762b7fb2640.csv385M    liger_view_1a904605387ef9d312e1b8b16a4e2cba.csv222M    liger_view_ad4bf54b69c664e169691d4cc5810df2.csvDelete/zip unwanted files or folders to reduce the current volume usage state on this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135 Regards, Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001VrxYh,Cloud Engineer Level 2,Closed,1098375,Incident,10-05-2018 22:14,,"Hello Allen,Thanks for the confirmation.As the issue has been resolved we are marking the case as closed. Please revert back to us in case of further queries.###Allen Herrera10:04 PM (6 minutes ago)to Andrew, Rean Yeah it’s been 30 ish min and no broadcast messages. Supervisor is still up and the mounts are writable Thank you Rean.###Hello Andrew/Allen,We have stopped and disabled the ISCSI services from the machine.Please check and confirm from your end whether the issue has been resolved or not.###Hello Andrew,Thanks for the approval.We are working on it and will update you the status.###Andrew Kim6:25 PM (2 hours ago)to Rean, spendhq-support Approved. Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 |akim@spendhq.com###@Team: once we get approval stop the iscsi and iscsid service on this machine and disable on chkconfig too.###Hi Allen,,We looked into this issue. Yes we found the message when we logged in to the instance. This message is showing because the iscsi service is running in the instance and looking for iscsi volume which is not been used in this instance. Therefore, we are getting this message as a broadcast in few minutes. As we had the NFS mount issue 2 days back on these machines we did the reboot of the machines which lead to start the iscsi service. As the chkconfig enabled for this service which made to start this service. To stop these messages, we need your approval to stop the iscsi service as this is not been used in this instance. Please provide approval to stop this. Once you approve this we will go ahead stop this.###During morning ops call Rohit mentioned he will take a look at this case.Next Action: please check with Rohit for the update on this ticket.###I have checked the system logs and found following error from 6th onwards May  9 15:13:41 ip-10-59-100-193 iscsid: connection34:0 is operational after recovery (1 attempts)May  9 15:13:41 ip-10-59-100-193 iscsid: connection22:0 is operational after recovery (1 attempts)May  9 15:13:41 ip-10-59-100-193 iscsid: connection1:0 is operational after recovery (1 attempts)May  9 15:13:41 ip-10-59-100-193 iscsid: connection6:0 is operational after recovery (1 attempts)May  9 15:13:41 ip-10-59-100-193 iscsid: connection3:0 is operational after recovery (1 attempts)May  9 15:13:41 ip-10-59-100-193 iscsid: connection5:0 is operational after recovery (1 attempts)May  9 15:13:43 ip-10-59-100-193 kernel: connection22:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 kernel: connection34:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 kernel: connection1:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 kernel: connection6:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 kernel: connection5:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 kernel: connection3:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 22:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 34:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 1:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 6:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 5:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 3:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)The ISCSI services are running on the machine. Need to have a check with Rohit since I am not sure what exactly going on here.###Hello Allen,We will look into this and will let you know the updates.","Why am I seeing this message broadcast every 10 min or so on the server 10.59.100.193Message from syslogd@ip-10-59-100-193 at May  9 13:03:48 ...iscsid:Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Broadcast messages on 10.59.100.193,,09-05-2018 18:42,28,0,SpendHQ,"Hello Allen,Thanks for the confirmation.As the issue has been resolved we are marking the case as closed. Please revert back to us in case of further queries.","Allen Herrera10:04 PM (6 minutes ago)to Andrew, Rean Yeah it’s been 30 ish min and no broadcast messages. Supervisor is still up and the mounts are writable Thank you Rean.","Hello Andrew/Allen,We have stopped and disabled the ISCSI services from the machine.Please check and confirm from your end whether the issue has been resolved or not.","Hello Andrew,Thanks for the approval.We are working on it and will update you the status.","Andrew Kim6:25 PM (2 hours ago)to Rean, spendhq-support Approved. Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 |akim@spendhq.com",@Team: once we get approval stop the iscsi and iscsid service on this machine and disable on chkconfig too.,"Hi Allen,,We looked into this issue. Yes we found the message when we logged in to the instance. This message is showing because the iscsi service is running in the instance and looking for iscsi volume which is not been used in this instance. Therefore, we are getting this message as a broadcast in few minutes. As we had the NFS mount issue 2 days back on these machines we did the reboot of the machines which lead to start the iscsi service. As the chkconfig enabled for this service which made to start this service. To stop these messages, we need your approval to stop the iscsi service as this is not been used in this instance. Please provide approval to stop this. Once you approve this we will go ahead stop this.",During morning ops call Rohit mentioned he will take a look at this case.Next Action: please check with Rohit for the update on this ticket.,I have checked the system logs and found following error from 6th onwards May  9 15:13:41 ip-10-59-100-193 iscsid: connection34:0 is operational after recovery (1 attempts)May  9 15:13:41 ip-10-59-100-193 iscsid: connection22:0 is operational after recovery (1 attempts)May  9 15:13:41 ip-10-59-100-193 iscsid: connection1:0 is operational after recovery (1 attempts)May  9 15:13:41 ip-10-59-100-193 iscsid: connection6:0 is operational after recovery (1 attempts)May  9 15:13:41 ip-10-59-100-193 iscsid: connection3:0 is operational after recovery (1 attempts)May  9 15:13:41 ip-10-59-100-193 iscsid: connection5:0 is operational after recovery (1 attempts)May  9 15:13:43 ip-10-59-100-193 kernel: connection22:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 kernel: connection34:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 kernel: connection1:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 kernel: connection6:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 kernel: connection5:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 kernel: connection3:0: detected conn error (1020)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 22:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 34:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 1:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 6:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 5:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)May  9 15:13:43 ip-10-59-100-193 iscsid: Kernel reported iSCSI connection 3:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)The ISCSI services are running on the machine. Need to have a check with Rohit since I am not sure what exactly going on here.,"Hello Allen,We will look into this and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001f4ZRe,Cloud Engineer Level 1,Closed,1107961,Incident,22-11-2018 02:52,,"Closing this case and tracking it via I-01107953###Juneidi Abbas11:17 PM EATto meCan you call back. I had an issue with the mic###Hosea Getusi11:47 PM EATto jabbasHello Juneidi,So I've reset your password and re-toggled your MFA. Try logging in again and see if everything is working as expected.In case of any issues, I am here.Thanks,-Hosea###Hello Team,This is to inform you that we are receiving multiple alerts regarding too many failed logins from 159.100.161.41 for facility openvpn. From checking the logs, we can see that the new jabbas user is having issue:---------------------------------------------------------------------------------------------------------2018:11:21-19:59:00 spendhq aua[9587]: id=3005 severity=warn sys=System sub=auth name=Authentication failed srcip=159.100.161.41 host= user=jabbas caller=portal reason=DENIED2018:11:21-19:59:20 spendhq aua[3210]: id=3006 severity=info sys=System sub=auth name=Running _cleanup_up_children with max_run_time: 202018:11:21-19:59:20 spendhq aua[9693]: id=3006 severity=info sys=System sub=auth name=Trying 10.47.21.244 (adirectory)2018:11:21-19:59:20 spendhq aua[9693]: id=3005 severity=warn sys=System sub=auth name=Authentication failed srcip=159.100.161.41 host= user=jabbas caller=portal reason=DENIED---------------------------------------------------------------------------------------------------------If possible we'd like to get on call with the user and help them resolve the issue. @Juneidi please join this bridge to troubleshoot the issue:https://reancloud.zoom.us/my/mgse1;+16465588656,,,6709937998Thanks.","Too many failed logins from 159.100.161.41 for facility openvpn.Further logins will be blocked for 300 seconds.Account Name - SpendHQAccount DL - ms@reancloud.comUTM Hostname - spendhq-utmPrivate IP - 10.59.1.192Public IP - 52.0.17.10Device URL - https://52.0.17.10:4444-- System Uptime      : 179 days 14 hours 45 minutesSystem Load        : 0.15System Version     : Sophos UTM 9.509-3Please refer to the manual for detailed instructions.-- Hosea B. Getusi,*Cloud Engineer,**REĀN Cloud | **Reach, Engage, Āctivate, Nurtur**Mobile*: +254713404220 | *Skype*: hoseagetusi*hosea.getusi@reancloud.com <hosea.getusi@reancloud.com>* |  *www.reancloud.com<http://www.reancloud.com>*[image: Mailtrack]<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>Sendernotified byMailtrack<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>11/21/18,10:50:50 PM--  <https://hubs.ly/H0fzGbl0>--  <https://hubs.ly/H0fzGbl0>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[SpendHQ] [10.59.1.192] [WARN-070] Too many failed logins,,22-11-2018 01:21,2,0,SpendHQ,Closing this case and tracking it via I-01107953,Juneidi Abbas11:17 PM EATto meCan you call back. I had an issue with the mic,"Hosea Getusi11:47 PM EATto jabbasHello Juneidi,So I've reset your password and re-toggled your MFA. Try logging in again and see if everything is working as expected.In case of any issues, I am here.Thanks,-Hosea","Hello Team,This is to inform you that we are receiving multiple alerts regarding too many failed logins from 159.100.161.41 for facility openvpn. From checking the logs, we can see that the new jabbas user is having issue:---------------------------------------------------------------------------------------------------------2018:11:21-19:59:00 spendhq aua[9587]: id=3005 severity=warn sys=System sub=auth name=Authentication failed srcip=159.100.161.41 host= user=jabbas caller=portal reason=DENIED2018:11:21-19:59:20 spendhq aua[3210]: id=3006 severity=info sys=System sub=auth name=Running _cleanup_up_children with max_run_time: 202018:11:21-19:59:20 spendhq aua[9693]: id=3006 severity=info sys=System sub=auth name=Trying 10.47.21.244 (adirectory)2018:11:21-19:59:20 spendhq aua[9693]: id=3005 severity=warn sys=System sub=auth name=Authentication failed srcip=159.100.161.41 host= user=jabbas caller=portal reason=DENIED---------------------------------------------------------------------------------------------------------If possible we'd like to get on call with the user and help them resolve the issue. @Juneidi please join this bridge to troubleshoot the issue:https://reancloud.zoom.us/my/mgse1;+16465588656,,,6709937998Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001geOdN,Cloud Engineer Level 1,Closed,1109900,Incident,27-12-2018 06:22,,"Hello Team,As mentioned earlier we cleaned up the inactive IAM user akim and as such we are marking this case as resolved and proceeding to close it.Please reach out to us for continued support.Thanks.###Hello Team,This is to inform you that we have cleaned up the user akim and we could see that from the AWS console the user's access keys were disabled.Please have a look and let us know if you have any query/concern.Thanks,###Hello Team,Andrew left the company, please feel free to clean up his account completely.Praveen MuppalaCloud Architect / Tech Lead, Managed ServicesHitachi Vantara","REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::IAM::User resources were affected:________________________________  *   Violation: The user account is not enabled and Inactive since last 90 days.  *   Recommendation: To prevent your account from getting Deleted, please LogIn to your account or user your API Keys.  *   Action taken: None  *   Resource details:Resource IDUser NamePassword Last UsedAccess Keys Last UsedAIDAIU5MRGFMPG7HO2UIMakimNever2018-09-17________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Managed Cloud: spendhq] Inactive IAM Users Alert,,26-12-2018 17:20,13,0,SpendHQ,"Hello Team,As mentioned earlier we cleaned up the inactive IAM user akim and as such we are marking this case as resolved and proceeding to close it.Please reach out to us for continued support.Thanks.","Hello Team,This is to inform you that we have cleaned up the user akim and we could see that from the AWS console the user's access keys were disabled.Please have a look and let us know if you have any query/concern.Thanks,","Hello Team,Andrew left the company, please feel free to clean up his account completely.Praveen MuppalaCloud Architect / Tech Lead, Managed ServicesHitachi Vantara",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hQv7N,Cloud Engineer Level 1,Closed,1110169,Incident,03-01-2019 10:45,,"Hello Team,While checking We witnessed spikes in the load balancer latency with the value of 105573 milliseconds, the spike in HTTP 4XX and HTTP 5XX in Secure-spendhq-ELB which leads the site down. We are working on the RCA for the root cause of this issue on the case id: 01110144.We are closing this case and please revert back to us in the above case if you have any queries.###Hello Team,This is to inform you that we have received multiple sites down alert for the URL: https://secure.spendhq.com/login.We are checking the cause of this site down and will get back to you with an update.","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Thu, Jan 3, 2019 at 8:31 AMSubject: Detected Error on SpendHQ SecureTo: <ms@reancloud.com>Wed, 02 Jan 2019 22:01:12 -0500Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30002 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Atlanta-B US, California US, Dallas-B US, Frankfurt-BDE-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Secure,,03-01-2019 08:33,2,0,SpendHQ,"Hello Team,While checking We witnessed spikes in the load balancer latency with the value of 105573 milliseconds, the spike in HTTP 4XX and HTTP 5XX in Secure-spendhq-ELB which leads the site down. We are working on the RCA for the root cause of this issue on the case id: 01110144.We are closing this case and please revert back to us in the above case if you have any queries.","Hello Team,This is to inform you that we have received multiple sites down alert for the URL: https://secure.spendhq.com/login.We are checking the cause of this site down and will get back to you with an update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DCPTd,Cloud Engineer Level 1,Closed,1062844,Incident,14-06-2017 23:45,,"Hello Team,This is to inform you that the alert regarding high volume usage for sphq-db-server05 instance /dev/xvda1 volume got resolved and the usage has returned to normal with a value of 50%. The violation has lasted for 35 minutes.###Hello SpendHQ Team,This is to inform you that we got an alert regarding high volume usage for sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90 to 100%. We are investigating the alert.on our initial analysis, we could see that /tmp is consuming more space. Please find the below volume usage details and zip/delete unused files.7.4T    total5.1T    mnt2.3T    var22G     tmp8.2G    usr","[Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1   @ms@reancloud.comMetric Graphavg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90The monitor was last triggered at Wed Jun 14 2017 17:36:00 UTC (41 secs ago).",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,14-06-2017 23:33,0,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding high volume usage for sphq-db-server05 instance /dev/xvda1 volume got resolved and the usage has returned to normal with a value of 50%. The violation has lasted for 35 minutes.","Hello SpendHQ Team,This is to inform you that we got an alert regarding high volume usage for sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90 to 100%. We are investigating the alert.on our initial analysis, we could see that /tmp is consuming more space. Please find the below volume usage details and zip/delete unused files.7.4T    total5.1T    mnt2.3T    var22G     tmp8.2G    usr",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ET2fR,Cloud Engineer Level 1,Closed,1067137,Incident,10-07-2017 14:29,,"Hi SpendHq-Team,We have verified that SpendHq is not using Apache Struts in any applications. At this time, we are marking this case as resolved. Please let us know if you have any further queries.###SpendHQ is already updated that they are not using Apache Struts. Need to check internally for further proceeding on this.###Hello SpendHQ-Team, On further analysis, we have checked the ELB logs and we could see a number of requests with 403 & 504 response code. Please find the below details.34.195.230.118 => Reported two 403 responses and three 504 responses.93.76.208.204 => Reported nine 403 responsesIP details:IP Address: 93.76.208.204OrgName: AS25229 Kyivski Telekomunikatsiyni Merezhi LLCCountry: Ukraine, KharkivBlacklist Status: LowIP Address: 34.195.230.118OrgName: Amazon Technologies Inc.Country: United States, SeattleBlacklist Status: LowFrom the Sophos IPS logs, the details of the IPS alert are here: id=2101 severity=warn name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt  sid=41819 class=Attempted Administrator Privilege Gain Please review the above IP addresses, if they are not valid we can block them at NACL level, find the attachment section for log details and let us know if you need any further details.###Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 & 10.59.1.127 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",">> Intrusion Prevention Alert>> An intrusion has been detected. The packet has been dropped automatically.> You can toggle this rule between drop and alert only in WebAdmin.>> Details about the intrusion alert:>> Message........: SERVER-APACHE Apache Struts remote code execution attempt> Details........: https://www.snort.org/search?query=41819> Time...........: 2017-07-08 05:21:29> Packet dropped.: yes> Priority.......: high> Classification.: Attempted Administrator Privilege Gain> IP protocol....: 6 (TCP)>> Source IP address: 10.59.1.127> Source port: 21228> Destination IP address: 10.59.1.192 (spendhq)> Destination port: 8080 (http-alt)>> --> System Uptime      : 27 days 19 hours 59 minutes> System Load        : 0.09> System Version     : Sophos UTM 9.413-4>> Please refer to the manual for detailed instructions.>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,08-07-2017 10:54,52,0,SpendHQ,"Hi SpendHq-Team,We have verified that SpendHq is not using Apache Struts in any applications. At this time, we are marking this case as resolved. Please let us know if you have any further queries.",SpendHQ is already updated that they are not using Apache Struts. Need to check internally for further proceeding on this.,"Hello SpendHQ-Team, On further analysis, we have checked the ELB logs and we could see a number of requests with 403 & 504 response code. Please find the below details.34.195.230.118 => Reported two 403 responses and three 504 responses.93.76.208.204 => Reported nine 403 responsesIP details:IP Address: 93.76.208.204OrgName: AS25229 Kyivski Telekomunikatsiyni Merezhi LLCCountry: Ukraine, KharkivBlacklist Status: LowIP Address: 34.195.230.118OrgName: Amazon Technologies Inc.Country: United States, SeattleBlacklist Status: LowFrom the Sophos IPS logs, the details of the IPS alert are here: id=2101 severity=warn name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt  sid=41819 class=Attempted Administrator Privilege Gain Please review the above IP addresses, if they are not valid we can block them at NACL level, find the attachment section for log details and let us know if you need any further details.","Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 & 10.59.1.127 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TAFvQ,Cloud Engineer Level 1,Closed,1093765,Incident,29-03-2018 23:04,,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Thank You.###Hello Matthew,We haven't heard back from you regarding the case for a while. For continued support regarding the same issue, you can contact us anytime.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.###Hello Matthew,This is a gentle reminder.Please review our previous comment and let us know if you are still facing any issue.###Hello Matthew, We have implemented the permanent mount steps and performed a reboot to confirm the working. Everything seems to be good to me. Please confirm the same from your end and let us know if you are facing any issues. Once you confirm, please let us know if we have your approval to perform the same for 10.59.10.82 and 10.59.10.89 as well.###Hello Matthew,We have implemented the permanent mount steps and performed a reboot to confirm the working. Everything seems to be good to me. Please confirm the same from your end and let us know if you are facing any issues.Once you confirm, please let us know if we have your approval to perform the same for 10.59.10.82 and 10.59.10.89 as well.Thank You,Safuvan KM###Hello Matthew,Thanks for providing the approval. We are going to perform this now. Will keep you posted.Thanks,Safuvan KM###Matthew Watts12:29 AM (4 minutes ago)to Rean, spendhq-support Yes please resolve this issue. We need this machine to restart with reboots. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com###Hello Matthew, Did you get a chance to review this case and provide a response?When we set up, we did mount the volume temporarily and in order to mount permanently, the team has added the mount entry in the fstab file but that didn't work out as this is an iSCSI volume and we sometimes witness iSCSI volume drive name changes after reboots. And later when we had this reboot issue, we did some research on how to mount the iSCSI volumes to persist on reboots and prepared a plan to implement the same. As this instance is a new set up and does not have any application configured on it yet, we would like to implement it on this instance and do a reboot to see if it's working as expected. Once confirmed, we will be good to implement the same for other servers as per your approval and will consider including this in all new server requests going forward. Please let us know if you can give a go-ahead to the same. Please feel free to reach out to us for any queries. Thank You, Safuvan KM###Hello Matthew,When we set up, we did mount the volume temporarily and in order to mount permanently, the team has added the mount entry in the fstab file but that didn't work out as this is an iSCSI volume and we sometimes witness iSCSI volume drive name changes after reboots.And later when we had this reboot issue, we did some research on how to mount the iSCSI volumes to persist on reboots and prepared a plan to implement the same.As this instance is a new set up and does not have any application configured on it yet, we would like to implement it on this instance and do a reboot to see if it's working as expected. Once confirmed, we will be good to implement the same for other servers as per your approval and will consider including this in all new server requests going forward.Please let us know if you can give a go-ahead to the same. Please feel free to reach out to us for any queries.Thank You,Safuvan KM###Matthew Watts7:57 PM (26 minutes ago)to Rean Why was this not completed when you setup the machine?###Hello Matthew, The issue was with the mount entry that we gave in the fstab file. In order to implement permanent mount, we have to perform the below steps so that the mounts will not be lost on reboots. Step1: Install the iSCSI Initiator Software.		# yum install iscsi-initiator-utils		Step1: Edit and configure iSCSI via /etc/iscsi/iscsid.conf file. 	Add a new entry or edit the existing to set node.startup = automatic Step2: Discover targets. 	These steps are already completed as a part of temporary mount we currently have. 		# iscsiadm --mode discovery --type sendtargets --portal < TARGET IP >:3260  		# iscsiadm --mode node --targetname < TARGET IQN > --portal < TARGET IP >:3260,1 --login		# mount < DEVICE NAME > < ABSOLUTE PATH TO MOUNT DIRECTORY > Step3: Configure permanent mount using fstab. 	Open /etc/fstab file and append config directive: 		< DEVICE NAME > < ABSOLUTE PATH TO MOUNT DIRECTORY > < FILE FORMAT > _netdev 0 0 Step4: Perform a reboot to confirm the permanent mount is working fine. 		# reboot Please let us know if we have your approval to perform this. If you think this has to be planned for another time, please suggest. Thank You, Safuvan KM###Matthew Watts10:16 PM (8 minutes ago)to Rean, spendhq-support It was a reboot.###Hi Mathew,We investigated on this issue, we found that volumes were not getting mounted as per the /etc/fstab entry when booting up.To resolve it for now we had to mount the root volume to another server and commented the /etc/fstab entries on the filesystem.Later the server came up fine and we were able to mount the volumes manually.Please verify the access to the machine now till we further investigate the issue on why this happened.Just want to know did you perform a reboot and then it was not reachable? Or it automatically stopped responding?###Hello Matthew,We could see that the instance status check was failed for this instance.We are checking on it and will get back to you with an update.###Hello Matthew, We will check on this and will let you know the updates. Thanks,###The server is not coming up again. Can you investigate and add the volume to the FSTAB. Why are we unable to restart the machine?###Hello Matthew,The iscsi mount was missing after the reboot. I have mounted the volume now. Please let me know if you are facing any issues.Thank You,Safuvan KM###[via mail from Matthew]Can we also verify that the volumes are attached###Hello Matthew,This is to notify that issue got resolved after the stop and start actions, Please check from your end now whether you are able to ssh and Please let us know the update.###[via Matthew]Yes please do as we need this box working.###Hello Matthew,In order to troubleshoot this issue, I tried to SSH into the instance but couldn't connect. Please let me know if you can approve to perform a reboot from the AWS console that should resolve the issue.Thank You,Safuvan KM###Hello Matthew,We will look into this issue and will get back to you.Thanks","Can we see why 10.59.10.180 is  down?-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",10.59.10.180,,21-03-2018 02:50,212,0,SpendHQ,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Thank You.","Hello Matthew,We haven't heard back from you regarding the case for a while. For continued support regarding the same issue, you can contact us anytime.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.","Hello Matthew,This is a gentle reminder.Please review our previous comment and let us know if you are still facing any issue.","Hello Matthew, We have implemented the permanent mount steps and performed a reboot to confirm the working. Everything seems to be good to me. Please confirm the same from your end and let us know if you are facing any issues. Once you confirm, please let us know if we have your approval to perform the same for 10.59.10.82 and 10.59.10.89 as well.","Hello Matthew,We have implemented the permanent mount steps and performed a reboot to confirm the working. Everything seems to be good to me. Please confirm the same from your end and let us know if you are facing any issues.Once you confirm, please let us know if we have your approval to perform the same for 10.59.10.82 and 10.59.10.89 as well.Thank You,Safuvan KM","Hello Matthew,Thanks for providing the approval. We are going to perform this now. Will keep you posted.Thanks,Safuvan KM","Matthew Watts12:29 AM (4 minutes ago)to Rean, spendhq-support Yes please resolve this issue. We need this machine to restart with reboots. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com","Hello Matthew, Did you get a chance to review this case and provide a response?When we set up, we did mount the volume temporarily and in order to mount permanently, the team has added the mount entry in the fstab file but that didn't work out as this is an iSCSI volume and we sometimes witness iSCSI volume drive name changes after reboots. And later when we had this reboot issue, we did some research on how to mount the iSCSI volumes to persist on reboots and prepared a plan to implement the same. As this instance is a new set up and does not have any application configured on it yet, we would like to implement it on this instance and do a reboot to see if it's working as expected. Once confirmed, we will be good to implement the same for other servers as per your approval and will consider including this in all new server requests going forward. Please let us know if you can give a go-ahead to the same. Please feel free to reach out to us for any queries. Thank You, Safuvan KM","Hello Matthew,When we set up, we did mount the volume temporarily and in order to mount permanently, the team has added the mount entry in the fstab file but that didn't work out as this is an iSCSI volume and we sometimes witness iSCSI volume drive name changes after reboots.And later when we had this reboot issue, we did some research on how to mount the iSCSI volumes to persist on reboots and prepared a plan to implement the same.As this instance is a new set up and does not have any application configured on it yet, we would like to implement it on this instance and do a reboot to see if it's working as expected. Once confirmed, we will be good to implement the same for other servers as per your approval and will consider including this in all new server requests going forward.Please let us know if you can give a go-ahead to the same. Please feel free to reach out to us for any queries.Thank You,Safuvan KM",Matthew Watts7:57 PM (26 minutes ago)to Rean Why was this not completed when you setup the machine?,"Hello Matthew, The issue was with the mount entry that we gave in the fstab file. In order to implement permanent mount, we have to perform the below steps so that the mounts will not be lost on reboots. Step1: Install the iSCSI Initiator Software.		# yum install iscsi-initiator-utils		Step1: Edit and configure iSCSI via /etc/iscsi/iscsid.conf file. 	Add a new entry or edit the existing to set node.startup = automatic Step2: Discover targets. 	These steps are already completed as a part of temporary mount we currently have. 		# iscsiadm --mode discovery --type sendtargets --portal < TARGET IP >:3260  		# iscsiadm --mode node --targetname < TARGET IQN > --portal < TARGET IP >:3260,1 --login		# mount < DEVICE NAME > < ABSOLUTE PATH TO MOUNT DIRECTORY > Step3: Configure permanent mount using fstab. 	Open /etc/fstab file and append config directive: 		< DEVICE NAME > < ABSOLUTE PATH TO MOUNT DIRECTORY > < FILE FORMAT > _netdev 0 0 Step4: Perform a reboot to confirm the permanent mount is working fine. 		# reboot Please let us know if we have your approval to perform this. If you think this has to be planned for another time, please suggest. Thank You, Safuvan KM","Matthew Watts10:16 PM (8 minutes ago)to Rean, spendhq-support It was a reboot.","Hi Mathew,We investigated on this issue, we found that volumes were not getting mounted as per the /etc/fstab entry when booting up.To resolve it for now we had to mount the root volume to another server and commented the /etc/fstab entries on the filesystem.Later the server came up fine and we were able to mount the volumes manually.Please verify the access to the machine now till we further investigate the issue on why this happened.Just want to know did you perform a reboot and then it was not reachable? Or it automatically stopped responding?","Hello Matthew,We could see that the instance status check was failed for this instance.We are checking on it and will get back to you with an update.","Hello Matthew, We will check on this and will let you know the updates. Thanks,",The server is not coming up again. Can you investigate and add the volume to the FSTAB. Why are we unable to restart the machine?,"Hello Matthew,The iscsi mount was missing after the reboot. I have mounted the volume now. Please let me know if you are facing any issues.Thank You,Safuvan KM",[via mail from Matthew]Can we also verify that the volumes are attached,"Hello Matthew,This is to notify that issue got resolved after the stop and start actions, Please check from your end now whether you are able to ssh and Please let us know the update.",[via Matthew]Yes please do as we need this box working.,"Hello Matthew,In order to troubleshoot this issue, I tried to SSH into the instance but couldn't connect. Please let me know if you can approve to perform a reboot from the AWS console that should resolve the issue.Thank You,Safuvan KM","Hello Matthew,We will look into this issue and will get back to you.Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Zj07W,Cloud Engineer Level 1,Closed,1102362,Incident,05-08-2018 15:12,,"Hello Team,The site down alert for the URL:https://secure.spendhq.com/login got resolved and Estimated Downtime was 1 minute. As mentioned in the previous comment we checked all the metrics from AWS and instance level but there is no suspicious activity during the time of the alert. As this alert was triggered because of latency and the backend server was unable to handle the request within time with 500 response code. And after a minute backend server started working fine and the site got recovered.As the alert is in the resolved state we are marking this case as resolved and closing this case. Please let us know if you have any further queries.###Hello Team,The site down alert for the URL:https://secure.spendhq.com/login got resolved and Estimated Downtime was 1 minute.While checking the backend ELB, instance and DB servers, we found the below details. 1. From the NewPreview-ELB load balancer, we could see Latency was around 8037.0 NewPreview-ELB From the Backend Instance PRD-WW1_122 and PRD-WW2_6, we could see all the metrics are looking normal.From the Backend DB server PRD-DB1, we could see all the cloudwatch metrics are looking normal Please find the ELB latency logs in the attachments section. Kindly validate these details and let us know if you have performed any activity from your end.###Hello Spendhq-Team, This is to notify you that we received an alert site down on the URL: https://secure.spendhq.com/login .and recovered within a minute. we are analyzing more on this issue and will get back to you with updates.Please let us know if you are performing any activity from your end.","---------- Forwarded message ----------From: <ms@reancloud.com>Date: Sun, Aug 5, 2018 at 12:42 PMSubject: Detected Error on SpendHQ SecureTo: ms@reancloud.comSun, 05 Aug 2018 03:12:09 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): London UK, California US, Sydney-C AU, Frankfurt DE-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Secure,,05-08-2018 12:44,2,0,SpendHQ,"Hello Team,The site down alert for the URL:https://secure.spendhq.com/login got resolved and Estimated Downtime was 1 minute. As mentioned in the previous comment we checked all the metrics from AWS and instance level but there is no suspicious activity during the time of the alert. As this alert was triggered because of latency and the backend server was unable to handle the request within time with 500 response code. And after a minute backend server started working fine and the site got recovered.As the alert is in the resolved state we are marking this case as resolved and closing this case. Please let us know if you have any further queries.","Hello Team,The site down alert for the URL:https://secure.spendhq.com/login got resolved and Estimated Downtime was 1 minute.While checking the backend ELB, instance and DB servers, we found the below details. 1. From the NewPreview-ELB load balancer, we could see Latency was around 8037.0 NewPreview-ELB From the Backend Instance PRD-WW1_122 and PRD-WW2_6, we could see all the metrics are looking normal.From the Backend DB server PRD-DB1, we could see all the cloudwatch metrics are looking normal Please find the ELB latency logs in the attachments section. Kindly validate these details and let us know if you have performed any activity from your end.","Hello Spendhq-Team, This is to notify you that we received an alert site down on the URL: https://secure.spendhq.com/login .and recovered within a minute. we are analyzing more on this issue and will get back to you with updates.Please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EUYjr,Cloud Engineer Level 2,Closed,1067796,Incident,14-07-2017 12:10,,"We are closing this case and will follow up on ticket 01067648.###Hello Team, We have escalated this issue to our senior engineering team and will keep you posted on the progress. We are having 3 tickets for this one case. So we are closing these two cases 01067808 and 01067796 and will follow up on main ticket 01067648.###Hello Team,We have escalated this issue to our senior engineering team and will keep you posted on the progress.###Hello Team,We will look into this issue and will get back to you with the updates.","We are noticing sporadic timeouts when accessing patch.spendhq.com (10.59.100.79) and l.spendhq.com (10.59.10.107).  These timeouts occur somewhat randomly. From just trying to access the initial page within our browser, to even once we have been on the site for a while and are navigating to a new page within our application.  Was curious if you could take a look to see if you could help diagnose why this is happening.Thanks!Dusty Fowler | Developer | SpendHQ(r)O: 770.628.0026 | dfowler@spendhq.com<mailto:dfowler@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sporadic timeout issues,,13-07-2017 19:08,17,0,SpendHQ,We are closing this case and will follow up on ticket 01067648.,"Hello Team, We have escalated this issue to our senior engineering team and will keep you posted on the progress. We are having 3 tickets for this one case. So we are closing these two cases 01067808 and 01067796 and will follow up on main ticket 01067648.","Hello Team,We have escalated this issue to our senior engineering team and will keep you posted on the progress.","Hello Team,We will look into this issue and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Dn5pa,Cloud Engineer Level 1,Closed,1065105,Incident,27-06-2017 10:57,,"Hello Team,This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0. The alert got resolved automatically and return to a normal state with the value of 2.998.###Hello Team,This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of  3.o on average with the value of 3.044.","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.044This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3930341612147710897 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,27-06-2017 07:41,3,0,SpendHQ,"Hello Team,This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0. The alert got resolved automatically and return to a normal state with the value of 2.998.","Hello Team,This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of  3.o on average with the value of 3.044.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001GI2Yh,Cloud Engineer Level 1,Closed,1074333,Incident,23-08-2017 04:30,,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Matthew updated,Acknowledged. Thank you.###Hello Team,The alert got resolved automatically and the site is up now. The violation lasted for 15 mins.On further analysis, we could see that for web instance there was a spike in CPU utilization and the Network IN at the time of the alert. The database instance also experienced a high CPU usage. The Network IN/OUT was high at the time of the alert.On checking the application log from the instance level we could see the below error[Tue Aug 22 20:44:36 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:37 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:37 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:37 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:38 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:38 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:38 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:39 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:39 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:39 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:40 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499Please review the application code from your end and let us know if you have any queries.###Hello SpendHQ-team,This is to notify you that we have received a site down alert for the URL: https://preview.spendhq.com/login. The site is not accessible now. We are investigating the alert and meanwhile let us know if you are performing any activity from your end.","Tue, 22 Aug 2017 16:45:23 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Dallas-B US, London UK, Sydney-C AU, Frankfurt DE-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,23-08-2017 02:15,2,0,SpendHQ,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Matthew updated,Acknowledged. Thank you.","Hello Team,The alert got resolved automatically and the site is up now. The violation lasted for 15 mins.On further analysis, we could see that for web instance there was a spike in CPU utilization and the Network IN at the time of the alert. The database instance also experienced a high CPU usage. The Network IN/OUT was high at the time of the alert.On checking the application log from the instance level we could see the below error[Tue Aug 22 20:44:36 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:37 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:37 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:37 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:38 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:38 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:38 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:39 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:39 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:39 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499[Tue Aug 22 20:44:40 2017] [error] [client 10.59.1.192] PHP Parse error:  syntax error, unexpected ';' in /var/www/vhosts/secure.spendhq.com/public/app/controllers/users_controller.php on line 1499Please review the application code from your end and let us know if you have any queries.","Hello SpendHQ-team,This is to notify you that we have received a site down alert for the URL: https://preview.spendhq.com/login. The site is not accessible now. We are investigating the alert and meanwhile let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001NRAPr,Cloud Engineer Level 1,Closed,1088252,Incident,10-01-2018 10:46,,"Hello Team,High CPU Load prd-db1 - 10.59.10.190. is recovered and came down to 2.45.At this time we are marking this case as closed.Please let us know if you have any further queries.###Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.25. The MySQL process was consuming the usage. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1 We are analyzing more on this and get back to you with details.","[Triggered] [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over datadog_monitor:on,host:i-03ccfddd9f02cacb9 was > 3.0 on average during the last 5m.Metric value: 3.036This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=4215956563738237497 · Show Processes: https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=None&tags=datadog_monitor%3Aon&from_ts=None&live=false&groups=host&showSummaryGraphs=true · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9--  <https://www.reancloud.com/news/rean-cloud-named-partner-newly-launched-aws-alexa-business/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db,,10-01-2018 08:34,2,0,SpendHQ,"Hello Team,High CPU Load prd-db1 - 10.59.10.190. is recovered and came down to 2.45.At this time we are marking this case as closed.Please let us know if you have any further queries.","Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.25. The MySQL process was consuming the usage. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1 We are analyzing more on this and get back to you with details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001cKV0r,Cloud Engineer Level 1,Closed,1105920,Incident,12-10-2018 14:17,,"As per Rohit's update, we are closing this case###Hello Matthew, This is a gentle reminder. We completed your request. Please find the attachment of the server list including users with access details. Please let us know if you have any queries about the same and kindly confirm that whether we are good to close this case.Thanks.###Hello Matthew, This is a gentle reminder. We have done with your request. Please let us know if you have any queries about the same###Hello Matthew,This is a gentle reminder.We completed your request. Please find the attachment of the server list including users with access details. Please let us know if you have any queries about the same. Thanks.###Revathy KurupAttachments1:48 PM (0 minutes ago)to REAN, Matthew, spendhq-supportHello Matthew,We have done with your request. Please find the attachment of the server list including users with access details. Please let us know if you have any queries about the same. Thanks.###@RohitI have added the instance names and instance id's for the instances mentioned in the sheet. Please review the same and let us know if we need to do any modification.https://docs.google.com/spreadsheets/d/1V2TEB0xcuaH-BSEg6fV8pycCZB4OZ32skJaLI5Fc-YU/edit#gid=0###@Team:Please review the comment on the sheet and reply to the same.###There are 14 instances which are under monitoring. created the sheet based on the customer requirements.https://docs.google.com/spreadsheets/d/1V2TEB0xcuaH-BSEg6fV8pycCZB4OZ32skJaLI5Fc-YU/edit#gid=0Need to review this sheet with Rohit and share with the customer###Hello Matthew,We will follow the format provided by you and will provide a detail list.###Perfect, thank you. Can we please request the findings to come back in the following format: Server IPCurrent UsersMissing UsersUsers with Sudo AccessUsers permitted to login to server10.59.10.190mwattsakimmwattsmwatts10.59.10.125mwatts, akimdmillermwattsmwatts Please note the “Users permitted to login to server” field is governed by the following entry in the /etc/ssh/sshd_config configuration###Hello Matthew,Thanks for the listWe will work on this request and will let you know the update.###Matthew Watts2:24 AM (3 minutes ago)to Rean, spendhq-support@reancloud.comNamePositionSudo on all machinesLinux AliasMatthew WattsManagerYesmwattsJason BrayCTONojbrayAndrew KimManagerNoakimDavid MillerEngineerNodmillerAllen HerreraEngineerNoaherreraDaniel MackayDBANodmackayRobert LittleDBANorlittleChris MinEngineerNocminKristen StretchEngineerNokstretchKenya HarrisQANokharrisMatthew KieferBANomkieferDusty FowlerSMNodfowler###Hello Matthew,Please provide the list of users.","REAN,Can you ensure that all servers that are created have ALL usernames added to them and just limit these users via the SSHD Limit Configuration. Can we check what users are on which servers that we have on PRD and then send that over so we can see where we are.If you need a list of users, please let me know and I will be more than happy to supply this.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Server Requests & User Accounts,,07-10-2018 01:45,133,0,SpendHQ,"As per Rohit's update, we are closing this case","Hello Matthew, This is a gentle reminder. We completed your request. Please find the attachment of the server list including users with access details. Please let us know if you have any queries about the same and kindly confirm that whether we are good to close this case.Thanks.","Hello Matthew, This is a gentle reminder. We have done with your request. Please let us know if you have any queries about the same","Hello Matthew,This is a gentle reminder.We completed your request. Please find the attachment of the server list including users with access details. Please let us know if you have any queries about the same. Thanks.","Revathy KurupAttachments1:48 PM (0 minutes ago)to REAN, Matthew, spendhq-supportHello Matthew,We have done with your request. Please find the attachment of the server list including users with access details. Please let us know if you have any queries about the same. Thanks.",@RohitI have added the instance names and instance id's for the instances mentioned in the sheet. Please review the same and let us know if we need to do any modification.https://docs.google.com/spreadsheets/d/1V2TEB0xcuaH-BSEg6fV8pycCZB4OZ32skJaLI5Fc-YU/edit#gid=0,@Team:Please review the comment on the sheet and reply to the same.,There are 14 instances which are under monitoring. created the sheet based on the customer requirements.https://docs.google.com/spreadsheets/d/1V2TEB0xcuaH-BSEg6fV8pycCZB4OZ32skJaLI5Fc-YU/edit#gid=0Need to review this sheet with Rohit and share with the customer,"Hello Matthew,We will follow the format provided by you and will provide a detail list.","Perfect, thank you. Can we please request the findings to come back in the following format: Server IPCurrent UsersMissing UsersUsers with Sudo AccessUsers permitted to login to server10.59.10.190mwattsakimmwattsmwatts10.59.10.125mwatts, akimdmillermwattsmwatts Please note the “Users permitted to login to server” field is governed by the following entry in the /etc/ssh/sshd_config configuration","Hello Matthew,Thanks for the listWe will work on this request and will let you know the update.","Matthew Watts2:24 AM (3 minutes ago)to Rean, spendhq-support@reancloud.comNamePositionSudo on all machinesLinux AliasMatthew WattsManagerYesmwattsJason BrayCTONojbrayAndrew KimManagerNoakimDavid MillerEngineerNodmillerAllen HerreraEngineerNoaherreraDaniel MackayDBANodmackayRobert LittleDBANorlittleChris MinEngineerNocminKristen StretchEngineerNokstretchKenya HarrisQANokharrisMatthew KieferBANomkieferDusty FowlerSMNodfowler","Hello Matthew,Please provide the list of users.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001fmcrw,Cloud Engineer Level 1,Closed,1108698,Incident,18-12-2018 10:41,,"Hello Mathew,We haven't heard back from you.As already mentioned in the previous command the issue is already resolved by the stop/start performed on 14/12/2018. So there is no pending action on this case and we are making this case as closed.Thanks###@Night shift Team,we have checked this case with cc and as per his update, please close this case in your shift if yo don't here anything from client's end yet. Thank you.###Hello Matthew,There will be no restart today.After performing the stop/start on 14/12/2018,  the instance was migrated to a new healthy hardware/host.Therefore, this issue has already been resolved. Please let us know whether we can proceed to close the case.Thanks###Matthew Watts3:29 PM (2 minutes ago)to Rean, spendhq-support@reancloud.comPlease confirm a restart won’t happen###Hello Matthew,This is to notify you that we had already performed a stop/start on the instance after your approval. The instance is now running and passing both status checks (2/2). As such, it has now been migrated new hardware and the issue is resolved. This activity was scheduled to be done by AWS today at 11:00 UTC if there was no action from our side. Basically, they would just stop and we would have to start it by ourselves###Hello Matthew,At the time of your last email, we had already performed a stop/start on the instance once you provided the go ahead.The instance is now running and passing both status checks (2/2). As such, it has now been migrated new hardware and the issue is resolved. This activity was scheduled to be done by AWS today at 11:00 UTC if there was no action from our side. Basically, they would just stop and we would have to start it by ourselves.###Matthew Watts3:56 AM (1 minute ago)to Rean, spendhq-support@reancloud.comPlease disregard my last message. Do not restart the instance###Matthew Watts3:49 AM (4 minutes ago)to Rean, spendhq-support@reancloud.comYes, please start and stop the machine and advise when it’s done###We are not getting any reply from SpendHQ team regarding this. This EC2 retirement scheduled on today 4:30 PM IST. Please check with CC for further action item and also this instance is not under REAN monitoring. Instance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.10.235 CreationDate: 2018-08-30 Monitoring: Off Name: SPHQ-DB3-20180830 Owner: SpendHQ###Hello Matthew,We haven't heard back from you regarding this case for a while.The instance SPHQ-DB3-20180830(i-0e76e98abf08a1b70) will retire today at 11 AM UTC/6 AM EST.Due to this degradation, your instance could already be unreachable. After 2018-12-14 11:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will perform the action Instance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.10.235 CreationDate: 2018-08-30 Monitoring: Off Name: SPHQ-DB3-20180830 Owner: SpendHQ###Hello Team,we haven't received a reply from your end.Please review our analysis from the previous comment and please provide approval to perform stop and start###Hello TeamThis is a quick followup regarding the AAWS_EC2_PERSISTENT_INSTANCE_RETIREMENT_SCHEDULED notification that we have received for the instance SPHQ-DB3-20180830.Kindly check on the same and provide us an approval to perform stop and start. Thanks###Hello Matthew, This is a quick followup. We already shared the details of the affected resource on the previous comment. Please review and provide your approval to perform a stop/start. Thanks.###Hello Matthew,This is a quick followup.We already shared the details of the affected resource on the previous comment. Please review and provide your approval to perform a stop/start.Thanks.###Hello Matthew,Below are the resource details of the affected instance:Instance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.10.235###Matthew Watts6:00 PM (0 minutes ago)to Rean, spendhq-support@reancloud.comWhat IP is this?###Hello Team,This is a follow up regarding the scheduled changes regarding EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance in the us-east-1 region. Instance: SPHQ-DB3-20180830.A stop and start activity can resolve the issue. Please review our previous comment and please let us know if we can perform the action or you will perform the action###Hello Team, This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2018-12-14 11:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will perform the action Resource details Instance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.10.235###Hello Team,This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2018-12-14 11:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will perform the actionResource detailsInstance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.10.235","EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2018-12-14 11:00 UTC your instance, which has an EBS volume as the root device, will be stopped.\\n \\nYou can see more information on your instances that are scheduled for retirement in the AWS Management Console (https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Events)\\n \\n* How does this affect you?\\n \\nYour instance will be stopped after the specified retirement date, but you can start it again at any time. Note that if you have EC2 instance store volumes attached to the instance, any data on these volumes will be lost when the instance is stopped or terminated as these volumes are physically attached to the host computer\\n \\n* What do you need to do?\\n \\nYou can wait for the scheduled retirement date - when the instance is stopped - or stop the instance yourself any time before then. Once the instances has been stopped, you can start the instance again at any time. For more information about stopping and starting your instance, and what to expect when your instance is stopped, such as the effect on public, private and Elastic IP addresses associated with your instance, see Stop and Start Your Instance in the EC2 User Guide (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html).\\n \\n* Why retirement?\\n \\nAWS may schedule instances for retirement in cases where there is an unrecoverable issue with the underlying hardware. For more information about scheduled retirement events please see the EC2 user guide (http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-retirement.html).\\n \\nIf you have any questions or concerns, you can contact the AWS Support Team on the community forums and via AWS Premium Support at: http://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <https://hubs.ly/H0fzGbl0>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_EC2_PERSISTENT_INSTANCE_RETIREMENT_SCHEDULED,,30-11-2018 17:18,425,0,SpendHQ,"Hello Mathew,We haven't heard back from you.As already mentioned in the previous command the issue is already resolved by the stop/start performed on 14/12/2018. So there is no pending action on this case and we are making this case as closed.Thanks","@Night shift Team,we have checked this case with cc and as per his update, please close this case in your shift if yo don't here anything from client's end yet. Thank you.","Hello Matthew,There will be no restart today.After performing the stop/start on 14/12/2018,  the instance was migrated to a new healthy hardware/host.Therefore, this issue has already been resolved. Please let us know whether we can proceed to close the case.Thanks","Matthew Watts3:29 PM (2 minutes ago)to Rean, spendhq-support@reancloud.comPlease confirm a restart won’t happen","Hello Matthew,This is to notify you that we had already performed a stop/start on the instance after your approval. The instance is now running and passing both status checks (2/2). As such, it has now been migrated new hardware and the issue is resolved. This activity was scheduled to be done by AWS today at 11:00 UTC if there was no action from our side. Basically, they would just stop and we would have to start it by ourselves","Hello Matthew,At the time of your last email, we had already performed a stop/start on the instance once you provided the go ahead.The instance is now running and passing both status checks (2/2). As such, it has now been migrated new hardware and the issue is resolved. This activity was scheduled to be done by AWS today at 11:00 UTC if there was no action from our side. Basically, they would just stop and we would have to start it by ourselves.","Matthew Watts3:56 AM (1 minute ago)to Rean, spendhq-support@reancloud.comPlease disregard my last message. Do not restart the instance","Matthew Watts3:49 AM (4 minutes ago)to Rean, spendhq-support@reancloud.comYes, please start and stop the machine and advise when it’s done","We are not getting any reply from SpendHQ team regarding this. This EC2 retirement scheduled on today 4:30 PM IST. Please check with CC for further action item and also this instance is not under REAN monitoring. Instance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.10.235 CreationDate: 2018-08-30 Monitoring: Off Name: SPHQ-DB3-20180830 Owner: SpendHQ","Hello Matthew,We haven't heard back from you regarding this case for a while.The instance SPHQ-DB3-20180830(i-0e76e98abf08a1b70) will retire today at 11 AM UTC/6 AM EST.Due to this degradation, your instance could already be unreachable. After 2018-12-14 11:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will perform the action Instance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.10.235 CreationDate: 2018-08-30 Monitoring: Off Name: SPHQ-DB3-20180830 Owner: SpendHQ","Hello Team,we haven't received a reply from your end.Please review our analysis from the previous comment and please provide approval to perform stop and start",Hello TeamThis is a quick followup regarding the AAWS_EC2_PERSISTENT_INSTANCE_RETIREMENT_SCHEDULED notification that we have received for the instance SPHQ-DB3-20180830.Kindly check on the same and provide us an approval to perform stop and start. Thanks,"Hello Matthew, This is a quick followup. We already shared the details of the affected resource on the previous comment. Please review and provide your approval to perform a stop/start. Thanks.","Hello Matthew,This is a quick followup.We already shared the details of the affected resource on the previous comment. Please review and provide your approval to perform a stop/start.Thanks.","Hello Matthew,Below are the resource details of the affected instance:Instance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.10.235","Matthew Watts6:00 PM (0 minutes ago)to Rean, spendhq-support@reancloud.comWhat IP is this?","Hello Team,This is a follow up regarding the scheduled changes regarding EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance in the us-east-1 region. Instance: SPHQ-DB3-20180830.A stop and start activity can resolve the issue. Please review our previous comment and please let us know if we can perform the action or you will perform the action","Hello Team, This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2018-12-14 11:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will perform the action Resource details Instance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.10.235","Hello Team,This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2018-12-14 11:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will perform the actionResource detailsInstance ID	i-0e76e98abf08a1b70	Instance Name or ID	SPHQ-DB3-20180830	Instance Type	r5.4xlarge	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.10.235",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Doqyt,Cloud Engineer Level 1,Closed,1066465,Incident,03-07-2017 19:07,,"Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0. The alert got resolved automatically and return to a normal state with the value of 2.901.###Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0 on average with the value of 3.275.","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.275This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3939678166927846487 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,03-07-2017 18:16,1,0,SpendHQ,"Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0. The alert got resolved automatically and return to a normal state with the value of 2.901.","Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0 on average with the value of 3.275.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001i9MeS,Cloud Engineer Level 1,Closed,1111119,Incident,06-02-2019 22:44,,"Hello Mathew,As the alert is still in open state for a while and the disk has a capacity of 8TB and only 6.2 TB is in use, we have just changed the Alert threshold to 90% to resolve the alert.The current Disk utilization is 87%. Kindly check with that from your side.As of now, we don't have any action item pending on this case We are marking this case as closed. Let us know if you have any queries.Thanks###Hello Team This is a quick followup, The alert is still in open state with the value of 87% of Disk usage. kindly check with the detailed analysis shared with you on the previous comment and delete or zip the unused files to resolve this alert. Let us know if you have any queries.###Hello Team This is a quick followup, The alert is still in open state with the value of 85.9% of Disk usage. kindly check with the detailed analysis shared with you on the previous comment and delete or zip the unused files to resolve this alert. Let us know if you have any queries.###Hello Team The alert is triggered by the ISCSI volumes and is still open state. Kindly look into this on priority and delete and/or zip files to free up space. Let us know if you have any queries.###Hello TeamThis is a quick followup,The alert is still in open state with the value of 82.9% of Disk usage.kindly check with the detailed analysis shared with you on the previous comment and delete or zip the unused files to resolve this alert.Let us know if you have any queries.Thanks###Hello Team The alert is triggered by the ISCSI volumes and is still open state. Kindly look into this on priority and delete and/or zip files to free up space.Let us know if you have any queries.Thanks###@Team: Its iSCSI Volume and taken care by SpendHQ team only. Ask them to take care of this.###Hello Team, This is a gentle reminder that the alert is still in open state with the value of 86.6%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage. Thanks###Hello Team, This is a gentle reminder that the alert is still in open state with the value of 85.4%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage. Thanks###Hello Team, This is a gentle reminder that the alert is still in open state with the value of 83.2%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage.Thanks###Hello Team,This is a quick follow up. The alerts regarding EBS High Disk usage for /usr/local/mariadb is still open state with value 82.9%.please check the usage details we shared in the previous mail. and let us know you update.Regards.###The alert is still open with 81.7%###Hello Team,This is to inform you that we received an alert for  EBS High Disk Usage for the host in production.On checking the details we can see that /usr/local/MariaDB Consuming the high usage.below are the details [root@ip-10-59-10-45 ~]# df -hFilesystem      Size  Used Avail Use% Mounted on/dev/nvme0n1p1  100G  2.6G   98G   3% /devtmpfs         63G     0   63G   0% /devtmpfs            63G  131M   63G   1% /dev/shmtmpfs            63G  185M   62G   1% /runtmpfs            63G     0   63G   0% /sys/fs/cgroup/dev/sda        8.0T  6.1T  1.5T  81% /usr/local/mariadbtmpfs            13G     0   13G   0% /run/user/0tmpfs            13G     0   13G   0% /run/user/1000** dev/sda        8.0T  6.1T  1.5T  81% /usr/local/mariadb **6.1T	/usr/local/mariadb/columnstore/data2/000.dir6.1T	/usr/local/mariadb/columnstore/data26.1T	/usr/local/mariadb/columnstore6.1T	/usr/local/mariadb6.1T	total1.4T	/usr/local/mariadb/columnstore/data2/000.dir/009.dir1.3T	/usr/local/mariadb/columnstore/data2/000.dir/006.dir1.2T	/usr/local/mariadb/columnstore/data2/000.dir/010.dir1.2T	/usr/local/mariadb/columnstore/data2/000.dir/007.dir978G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir283G	/usr/local/mariadb/columnstore/data2/000.dir/011.dir64G	/usr/local/mariadb/columnstore/data2/000.dir/006.dir/035.dir27G	/usr/local/mariadb/columnstore/data2/000.dir/006.dir/034.dir22G	/usr/local/mariadb/columnstore/data2/000.dir/006.dir/032.dir14G	/usr/local/mariadb/columnstore/data2/000.dir/011.dir/059.dir13G	/usr/local/mariadb/columnstore/data2/000.dir/011.dir/057.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/228.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/209.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/104.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/055.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/046.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/040.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/036.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/249.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/244.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/224.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/175.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/173.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/168.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/148.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/146.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/104.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/088.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/007.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir/242.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir/221.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir/209.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir/179.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir/082.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/007.dir/255.dirPlease Check these details and let us know your updateResouce DetailsIp: 10.59.10.45Nmae: SPHQ-DB2-20180830nstance ID: i-0105d8ab19d508dd6","[image: Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sda ) -sphq-db2-20180830 - 10.59.10.45High Disk Usage detected on the device /dev/sda@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1548339879000&group=device%3A%2Fdev%2Fsda%2Chost%3Ai-0105d8ab19d508dd6&from_ts=1548336279000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc}by {host,device} * 100 > 80The monitor was last triggered at Thu Jan 24 2019 14:24:49 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fsda%2Chost%3Ai-0105d8ab19d508dd6>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [Viewi-0105d8ab19d508dd6<https://app.datadoghq.com/infrastructure?filter=i-0105d8ab19d508dd6>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1548340009000&tags=host%3Ai-0105d8ab19d508dd6&from_ts=1548338989000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4766021625320097364>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db2-20180830 - 10.59.10.45,,24-01-2019 20:46,314,0,SpendHQ,"Hello Mathew,As the alert is still in open state for a while and the disk has a capacity of 8TB and only 6.2 TB is in use, we have just changed the Alert threshold to 90% to resolve the alert.The current Disk utilization is 87%. Kindly check with that from your side.As of now, we don't have any action item pending on this case We are marking this case as closed. Let us know if you have any queries.Thanks","Hello Team This is a quick followup, The alert is still in open state with the value of 87% of Disk usage. kindly check with the detailed analysis shared with you on the previous comment and delete or zip the unused files to resolve this alert. Let us know if you have any queries.","Hello Team This is a quick followup, The alert is still in open state with the value of 85.9% of Disk usage. kindly check with the detailed analysis shared with you on the previous comment and delete or zip the unused files to resolve this alert. Let us know if you have any queries.",Hello Team The alert is triggered by the ISCSI volumes and is still open state. Kindly look into this on priority and delete and/or zip files to free up space. Let us know if you have any queries.,"Hello TeamThis is a quick followup,The alert is still in open state with the value of 82.9% of Disk usage.kindly check with the detailed analysis shared with you on the previous comment and delete or zip the unused files to resolve this alert.Let us know if you have any queries.Thanks",Hello Team The alert is triggered by the ISCSI volumes and is still open state. Kindly look into this on priority and delete and/or zip files to free up space.Let us know if you have any queries.Thanks,@Team: Its iSCSI Volume and taken care by SpendHQ team only. Ask them to take care of this.,"Hello Team, This is a gentle reminder that the alert is still in open state with the value of 86.6%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage. Thanks","Hello Team, This is a gentle reminder that the alert is still in open state with the value of 85.4%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage. Thanks","Hello Team, This is a gentle reminder that the alert is still in open state with the value of 83.2%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage.Thanks","Hello Team,This is a quick follow up. The alerts regarding EBS High Disk usage for /usr/local/mariadb is still open state with value 82.9%.please check the usage details we shared in the previous mail. and let us know you update.Regards.",The alert is still open with 81.7%,"Hello Team,This is to inform you that we received an alert for  EBS High Disk Usage for the host in production.On checking the details we can see that /usr/local/MariaDB Consuming the high usage.below are the details [root@ip-10-59-10-45 ~]# df -hFilesystem      Size  Used Avail Use% Mounted on/dev/nvme0n1p1  100G  2.6G   98G   3% /devtmpfs         63G     0   63G   0% /devtmpfs            63G  131M   63G   1% /dev/shmtmpfs            63G  185M   62G   1% /runtmpfs            63G     0   63G   0% /sys/fs/cgroup/dev/sda        8.0T  6.1T  1.5T  81% /usr/local/mariadbtmpfs            13G     0   13G   0% /run/user/0tmpfs            13G     0   13G   0% /run/user/1000** dev/sda        8.0T  6.1T  1.5T  81% /usr/local/mariadb **6.1T	/usr/local/mariadb/columnstore/data2/000.dir6.1T	/usr/local/mariadb/columnstore/data26.1T	/usr/local/mariadb/columnstore6.1T	/usr/local/mariadb6.1T	total1.4T	/usr/local/mariadb/columnstore/data2/000.dir/009.dir1.3T	/usr/local/mariadb/columnstore/data2/000.dir/006.dir1.2T	/usr/local/mariadb/columnstore/data2/000.dir/010.dir1.2T	/usr/local/mariadb/columnstore/data2/000.dir/007.dir978G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir283G	/usr/local/mariadb/columnstore/data2/000.dir/011.dir64G	/usr/local/mariadb/columnstore/data2/000.dir/006.dir/035.dir27G	/usr/local/mariadb/columnstore/data2/000.dir/006.dir/034.dir22G	/usr/local/mariadb/columnstore/data2/000.dir/006.dir/032.dir14G	/usr/local/mariadb/columnstore/data2/000.dir/011.dir/059.dir13G	/usr/local/mariadb/columnstore/data2/000.dir/011.dir/057.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/228.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/209.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/104.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/055.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/046.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/040.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/010.dir/036.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/249.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/244.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/224.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/175.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/173.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/168.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/148.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/146.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/104.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/088.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/009.dir/007.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir/242.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir/221.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir/209.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir/179.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/008.dir/082.dir12G	/usr/local/mariadb/columnstore/data2/000.dir/007.dir/255.dirPlease Check these details and let us know your updateResouce DetailsIp: 10.59.10.45Nmae: SPHQ-DB2-20180830nstance ID: i-0105d8ab19d508dd6",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001jilus,Cloud Engineer Level 1,Closed,1111882,Incident,10-02-2019 17:47,,"Hello Matthew,As discussed on the call we will be marking this case as closed and will schedule wormly to resume the monitoring at Monday 7 PM EST(5:30 AM IST Tuesday).RegardsNishad Ali###Hello Matthew,Thanks for the update,We will keep this URL on maintenance until we hear back from you on Monday.RegardsNishad Ali###Perfect. Please leave maintenance on until MondayGet Outlook for iOS###Hello Matthew,We are getting multiple Site down alerts for the URL https://preview.spendhq.com/login, we have analyzed the case and could see that the site is loading fine with some amount of latency and wormly throws the alert due to the Endpoint check timeout.-------------------C02XH05GJG5M:TMT niali$ for X in `seq 3`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://preview.spendhq.com/login -so /dev/null; doneHTTPCode=200 TotalTime=121.945129HTTPCode=200 TotalTime=122.023927HTTPCode=200 TotalTime=123.624051--------------------------As of now to avoid multiple alerts, we are enabling the maintenance in Wormly until we hear back from you.Kindly check from your end let us know the updatesAwaiting for an update from you to proceed further on this.RegardsNishad Ali###Hello Team,There is a small correction in the available memory details of the web server right now 10Gb is available.[root@ip-10-59-100-170 ~]# free -m             total       used       free     shared    buffers     cachedMem:         14938       4619      10319          0         74       1344-/+ buffers/cache:       3200      11738Swap:        10239         58      10181###Hello Team, On further Checking, we can see the Load balancer  preview-spendhq-xelb  has a sudden spike in latency with 70027.925.  Before the site is going down we noticed that high request count of 653 and there was a spike in 2xx Count of 638. The total time consumed the web site provide the response during the time of the alert is 120 seconds.[centos@ip-10-59-100-170 ~]$ for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://preview.spendhq.com/login -so /dev/null; doneHTTPCode=200 TotalTime=120.618HTTPCode=200 TotalTime=120.610HTTPCode=200 TotalTime=120.573HTTPCode=200 TotalTime=120.520HTTPCode=200 TotalTime=120.535Other than we checked the backend instance we couldn't find any error logs. The time wait and established at the connection backend web server is  64 and 132. [root@ip-10-59-100-170 ~]# netstat | grep TIME_WAIT | wc -l64[root@ip-10-59-100-170 ~]# netstat | grep ESTABLISHED | wc -l132the memory of web server is 937 available [root@ip-10-59-100-170 ~]# free -m             total       used       free     shared    buffers     cachedMem:         14938       5300       9638          0         66       1344-/+ buffers/cache:       3889      11049Swap:        10239         58      10181--- Also, we checked the backend Database and we could find  error logs Feb  9 02:04:48 ip-10-59-10-135 dhclient[1664]: DHCPREQUEST on eth0 to 10.59.10.1 port 67 (xid=0x27dfc9f9)Feb  9 02:04:48 ip-10-59-10-135 dhclient[1664]: DHCPACK from 10.59.10.1 (xid=0x27dfc9f9)Feb  9 02:04:50 ip-10-59-10-135 dhclient[1664]: bound to 10.59.10.135 -- renewal in 1477 seconds.Feb  9 02:04:51 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Feb  9 02:04:51 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Feb  9 02:04:51 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)The Cpu utilization on the preview web server and preview DB are normal and N/w out on preview web, preview DB are normal. We are attaching the Screenshot of the Details in the attachment section. Note: Currently the site is passing the wormly health check. ELB Details: ----------- Name: preview-spendhq-xelb DNS Name: preview-spendhq-xelb-520312558.us-east-1.elb.amazonaws.com Type: Classic Scheme: internet-facing Availability Zones: subnet-01596c2a - us-east-1b, subnet-acbb09e7 - us-east-1c VPC: vpc-76df7212 ----------- Backend Instance Details: ------------------------- Name: Preview DB Instance ID: i-008d43ad00357e47a Availability Zone: us-east-1b Private IP: 10.59.10.135 VPC ID: vpc-76df7212 ------------------------- Name: Preview WEb Instance ID:i-0f36027c388e7a563 Availability Zone: us-east-1b Private IP: 10.59.100.170 VPC ID: vpc-76df7212 We have analyzed the ELB Access logs and found there were high number of requests came from two Ip's mentioned below.We have attached the cloud watch metrics and ELB logs in the attachments section.###Matthew Watts <mwatts@spendhq.com>Sat 2/9/2019 8:12 AMPerfect. Thank you###Hello Team, The site is still accessible but it taking a long time to load the page. From Wormly, we could see requests timing out after Operation timed out after 9000 milliseconds with 0 bytes being received at the time. And from the preview-spendhq-xelb load balancer, we can see high latency of 700027.925We are further checking on this and update you.###Hello Team, This is to inform we received a site down alert for URL: https://preview.spendhq.com/login On further Checking, we can the site is accessible at the time but it taking a long time to load the desired page. We are checking further on this and we will let you know the update.","Subject: Detected Error on SpendHQ PreviewFri, 08 Feb 2019 21:03:28 -0500Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30002 milliseconds with 0 bytes receivedSensor parameters:url: https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fpreview.spendhq.com%2Flogin&amp;data=01%7C01%7Cmanideep.gunda%40hitachivantara.com%7Cd107bb767e464b0056ee08d68e32c93c%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=GvyGw3D%2B8XWZ7CAiD47034UxYsgLH%2FVxjbZJQyeqwmg%3D&amp;reserved=0expect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): California US, Frankfurt DE, New Jersey US, Sydney-C AU",Detected Error on SpendHQ Preview,,09-02-2019 07:35,34,0,SpendHQ,"Hello Matthew,As discussed on the call we will be marking this case as closed and will schedule wormly to resume the monitoring at Monday 7 PM EST(5:30 AM IST Tuesday).RegardsNishad Ali","Hello Matthew,Thanks for the update,We will keep this URL on maintenance until we hear back from you on Monday.RegardsNishad Ali",Perfect. Please leave maintenance on until MondayGet Outlook for iOS,"Hello Matthew,We are getting multiple Site down alerts for the URL https://preview.spendhq.com/login, we have analyzed the case and could see that the site is loading fine with some amount of latency and wormly throws the alert due to the Endpoint check timeout.-------------------C02XH05GJG5M:TMT niali$ for X in `seq 3`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://preview.spendhq.com/login -so /dev/null; doneHTTPCode=200 TotalTime=121.945129HTTPCode=200 TotalTime=122.023927HTTPCode=200 TotalTime=123.624051--------------------------As of now to avoid multiple alerts, we are enabling the maintenance in Wormly until we hear back from you.Kindly check from your end let us know the updatesAwaiting for an update from you to proceed further on this.RegardsNishad Ali","Hello Team,There is a small correction in the available memory details of the web server right now 10Gb is available.[root@ip-10-59-100-170 ~]# free -m             total       used       free     shared    buffers     cachedMem:         14938       4619      10319          0         74       1344-/+ buffers/cache:       3200      11738Swap:        10239         58      10181","Hello Team, On further Checking, we can see the Load balancer  preview-spendhq-xelb  has a sudden spike in latency with 70027.925.  Before the site is going down we noticed that high request count of 653 and there was a spike in 2xx Count of 638. The total time consumed the web site provide the response during the time of the alert is 120 seconds.[centos@ip-10-59-100-170 ~]$ for X in `seq 6`; do curl -Ik -w HTTPCode=%{http_code} TotalTime=%{time_total}\\n https://preview.spendhq.com/login -so /dev/null; doneHTTPCode=200 TotalTime=120.618HTTPCode=200 TotalTime=120.610HTTPCode=200 TotalTime=120.573HTTPCode=200 TotalTime=120.520HTTPCode=200 TotalTime=120.535Other than we checked the backend instance we couldn't find any error logs. The time wait and established at the connection backend web server is  64 and 132. [root@ip-10-59-100-170 ~]# netstat | grep TIME_WAIT | wc -l64[root@ip-10-59-100-170 ~]# netstat | grep ESTABLISHED | wc -l132the memory of web server is 937 available [root@ip-10-59-100-170 ~]# free -m             total       used       free     shared    buffers     cachedMem:         14938       5300       9638          0         66       1344-/+ buffers/cache:       3889      11049Swap:        10239         58      10181--- Also, we checked the backend Database and we could find  error logs Feb  9 02:04:48 ip-10-59-10-135 dhclient[1664]: DHCPREQUEST on eth0 to 10.59.10.1 port 67 (xid=0x27dfc9f9)Feb  9 02:04:48 ip-10-59-10-135 dhclient[1664]: DHCPACK from 10.59.10.1 (xid=0x27dfc9f9)Feb  9 02:04:50 ip-10-59-10-135 dhclient[1664]: bound to 10.59.10.135 -- renewal in 1477 seconds.Feb  9 02:04:51 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Feb  9 02:04:51 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Feb  9 02:04:51 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)The Cpu utilization on the preview web server and preview DB are normal and N/w out on preview web, preview DB are normal. We are attaching the Screenshot of the Details in the attachment section. Note: Currently the site is passing the wormly health check. ELB Details: ----------- Name: preview-spendhq-xelb DNS Name: preview-spendhq-xelb-520312558.us-east-1.elb.amazonaws.com Type: Classic Scheme: internet-facing Availability Zones: subnet-01596c2a - us-east-1b, subnet-acbb09e7 - us-east-1c VPC: vpc-76df7212 ----------- Backend Instance Details: ------------------------- Name: Preview DB Instance ID: i-008d43ad00357e47a Availability Zone: us-east-1b Private IP: 10.59.10.135 VPC ID: vpc-76df7212 ------------------------- Name: Preview WEb Instance ID:i-0f36027c388e7a563 Availability Zone: us-east-1b Private IP: 10.59.100.170 VPC ID: vpc-76df7212 We have analyzed the ELB Access logs and found there were high number of requests came from two Ip's mentioned below.We have attached the cloud watch metrics and ELB logs in the attachments section.",Matthew Watts <mwatts@spendhq.com>Sat 2/9/2019 8:12 AMPerfect. Thank you,"Hello Team, The site is still accessible but it taking a long time to load the page. From Wormly, we could see requests timing out after Operation timed out after 9000 milliseconds with 0 bytes being received at the time. And from the preview-spendhq-xelb load balancer, we can see high latency of 700027.925We are further checking on this and update you.","Hello Team, This is to inform we received a site down alert for URL: https://preview.spendhq.com/login On further Checking, we can the site is accessible at the time but it taking a long time to load the desired page. We are checking further on this and we will let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Ukorw,Cloud Engineer Level 1,Closed,1095894,Incident,20-04-2018 12:32,,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello Allen,We haven't heard from you,Please let us know if you facing any issues.###Manideep Gunda <manideep.gunda@reancloud.com>7:09 PM (6 hours ago)to Rohit, Allen, Rean, spendhq-support Hello Allen,Thanks for Joining the call,We have we resolved the issue and kindly confirm the same.###Hi Allen,We have stopped copying the data. We will be available at 900hrs EST. We will share the meeting invite with you to join the call. Thanks !Regards,Rohit Puri###Hello Allen,Please join the bridge, We have joined the call.https://reancloud.zoom.us/my/mgse1###Allen Herrera5:48 PM (0 minutes ago)to Rean, spendhq-support Rean,we do not need the data copied over. Can we please schedule a call so I can be clear with you about the requirements. 9:30am my time (in about an hour)###Moved 154GB data. Next action: Please run the command rsync -r /usr/local/mariadb /usr/local/mariadb-2018-04-17 -v and check the status.once the data moved to /usr/local/mariadb-2018-04-17. Unmount both and mount the /dev/sdr to /usr/local/mariadb mount point###I have used rsync -r /usr/local/mariadb /usr/local/mariadb-2018-04-17 -v used for copy dataonce the data moved to  /usr/local/mariadb-2018-04-17. Unmount both and mount the /dev/sdr to  /usr/local/mariadb mount point###Hello Team,We are  copying the data from /usr/local/mariadb to /usr/local/mariadb-2018-04-17 mount point. Currently, we have moved  149G of data, once the whole data moved we will change the mount point to /usr/local/mariadb. Please let us know if you have any queries.###Hello Matthew,Thanks for the approval.We will work on this request and will let you know the updates.###Matthew WattsApproved. REAN please turn this around asap.###If /usr/local/mariadb can’t be resized, then blow all that data away. Let’s just make the 4TB mount (usr/local/mariadb-2018-04-17 ) actually named /usr/local/mariadb and drop the 600+GB of data currently in usr/local/mariadb.Thanks for the continued support.Matthew please approveAllen Herrera###[sent through the mail]Hello Matthew,We have mounted the new volume under /usr/local/mariadb-2018-04-17 directory on the instance. Please find the screenshot below and let us know if you have any concerns.###Matthew Watts11:15 PM (1 hour ago)to Manideep, Chris, Rean, spendhq-support, David What is the status of this REAN?###Hello Chris,Thanks for the update,@Mattew we will work on this request and will get back to you with updates.###Ok - This is complete on my end...ready to go IE. build filesystem....you should see something like:iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend3Let me know if you have further questions...Chris###Matt, ET AL,Unfortunately we cannot increase the size of the volume easily since it is raw disk and has no native filesystem. Thus, while can increase on the storage side, it will not access the extra allocated disk since the filesystem (ext 4) is not formatted for it.We have two options to resolve this:The first would be to use the command resize2fs.  After  some research, this has a pretty good track-record of success; but we'd still need to backup the data as insurance.This would require a un-mount, run fdisk, make note of partition, node numbers, etc..and then run resize2fs....sounds a bit risky and not sure how long all this would take...The second option is - I have built another 2TB volume called JS2-Spend3 on the JetStor. This can be simply mounted and is ready to be formatted and used.I like this path since we need to back up the original volume anyway...might as well just put it there and be done with it.Thoughts?Chris###Sure....I will let everyone know when it is ready for mounting...###Chris, Let’s do option 2 please. Thank you. Can we shoot for a 4TB instance size.###Do we have an update on this team. We need to migrate data and this is holding us up.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com###After a remount  we are still seeing the following Chris; Can you please advise. Filesystem      Size  Used Avail Use% Mounted on/dev/xvda1       50G  2.2G   48G   5% /devtmpfs        121G     0  121G   0% /devtmpfs           121G  2.8M  121G   1% /dev/shmtmpfs           121G   73M  120G   1% /runtmpfs           121G     0  121G   0% /sys/fs/cgroup/dev/sde        689G  654G  6.5M 100% /usr/local/mariadb/dev/sdf        689G   82G  573G  13% /var/log/mariadbtmpfs            25G     0   25G   0% /run/user/1001/dev/sdq        4.0T  3.5T  287G  93% /mnt/mysqldumpstmpfs            25G     0   25G   0% /run/user/1000tmpfs            25G     0   25G   0% /run/user/1007###Chris VeilletteAllen - we would need to unmount the vol in order to grow it.... I know you don't what to do this - can I build you another vol on the same box ?###Hello Allen,We checked from the instance level the volume is completely occupied we could see that the volume is 100% used please see the below volume utilization details./dev/sde       ext4      689G  654G     0 100% /usr/local/mariadb654G    total654G    columnstore###From Chris,Hi Allen,I am checking on this....get back to you shortly...###Hi Allen/Chris,Yes we received the mail from Chris. We will check internally about this email issue and update you.For Volume Size, Chris we were planning to re-mount the volume but when we checked the volume, it was being used by multiple process. Therefore, we did not do that.Allen: Will you please stop all the services which are using this volume /usr/local/mariadb ? So that we can go ahead and re-mount the volume.Regards,Rohit Puri###Chris Veillette6:24 PM (2 minutes ago)to Rohit, Allen, Matthew, Andrew, spendhq-support Hi Rohit,I double-checked and I am at 1.95TB on this volume on the JetStor.I would suggest un-mount and re-mounting the volume if you haven't already.Let me know - if this doesn't work I will ping JetStor....Chris###Hi Chris,When we checked the size of the volume, it doesn't change. It still shows the same size. Please find the screenshot in the attachment section./dev/sde is the same volume which we asked for increasing the size of ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend2:dev7.ctr1-lun-0.Please iscsi screenshot in the attachment sectionPlease let us know if anything needs to be done from our end to reflect the size change. Thanks!###Next Action: Check with Rohit whether we are good to share the details with the customer.###Chris VeilletteAttachments12:50 AM (7 hours ago)to Allen, Rohit, Matthew, Andrew, spendhq-support, REAN Hours agoChris Veillette###Allen Herrera12:13 AM (7 hours ago)to Matthew, Rohit, Chris, Andrew, spendhq-support, REAN Has this been accomplished?###Hello Team,Please let us know once you are done to increase the Volume to 2TB.Kindly revert back to us in case of any queries.###Chris Veillette <cveillette@andromeda3.com>8:04 PM (0 minutes ago)to Rohit, Andrew, Rean Done - will take just about 10 mins or so to complete the initialization.###Chris Veillette <cveillette@andromeda3.com>8:02 PM (1 minute ago)to Andrew, Rean, spendhq-support Ok  doing it now -will take just a bit to do ... 10 mins or so....###Andrew Kim7:50 PM (12 minutes ago)to Rean, spendhq-support Approved.###Hi Chris,Please increase the size of ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend2:dev7.ctr1-lun-0 ISCSI Volume to 2TB.@Andrew: Please approve the same. Regards,Rohit Puri###Hello Allen,We will work on this and will let you know the update.","df -h/dev/sde        689G  6.9G  651G   1% /usr/local/mariadbHey ReanI need this mount increased from the current 650G to at least 2 terabytes (2TB) on that server 10.59.10.180.I need this done asap!--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Mount size increase,,11-04-2018 19:10,209,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello Allen,We haven't heard from you,Please let us know if you facing any issues.","Manideep Gunda <manideep.gunda@reancloud.com>7:09 PM (6 hours ago)to Rohit, Allen, Rean, spendhq-support Hello Allen,Thanks for Joining the call,We have we resolved the issue and kindly confirm the same.","Hi Allen,We have stopped copying the data. We will be available at 900hrs EST. We will share the meeting invite with you to join the call. Thanks !Regards,Rohit Puri","Hello Allen,Please join the bridge, We have joined the call.https://reancloud.zoom.us/my/mgse1","Allen Herrera5:48 PM (0 minutes ago)to Rean, spendhq-support Rean,we do not need the data copied over. Can we please schedule a call so I can be clear with you about the requirements. 9:30am my time (in about an hour)",Moved 154GB data. Next action: Please run the command rsync -r /usr/local/mariadb /usr/local/mariadb-2018-04-17 -v and check the status.once the data moved to /usr/local/mariadb-2018-04-17. Unmount both and mount the /dev/sdr to /usr/local/mariadb mount point,I have used rsync -r /usr/local/mariadb /usr/local/mariadb-2018-04-17 -v used for copy dataonce the data moved to  /usr/local/mariadb-2018-04-17. Unmount both and mount the /dev/sdr to  /usr/local/mariadb mount point,"Hello Team,We are  copying the data from /usr/local/mariadb to /usr/local/mariadb-2018-04-17 mount point. Currently, we have moved  149G of data, once the whole data moved we will change the mount point to /usr/local/mariadb. Please let us know if you have any queries.","Hello Matthew,Thanks for the approval.We will work on this request and will let you know the updates.",Matthew WattsApproved. REAN please turn this around asap.,"If /usr/local/mariadb can’t be resized, then blow all that data away. Let’s just make the 4TB mount (usr/local/mariadb-2018-04-17 ) actually named /usr/local/mariadb and drop the 600+GB of data currently in usr/local/mariadb.Thanks for the continued support.Matthew please approveAllen Herrera","[sent through the mail]Hello Matthew,We have mounted the new volume under /usr/local/mariadb-2018-04-17 directory on the instance. Please find the screenshot below and let us know if you have any concerns.","Matthew Watts11:15 PM (1 hour ago)to Manideep, Chris, Rean, spendhq-support, David What is the status of this REAN?","Hello Chris,Thanks for the update,@Mattew we will work on this request and will get back to you with updates.",Ok - This is complete on my end...ready to go IE. build filesystem....you should see something like:iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend3Let me know if you have further questions...Chris,"Matt, ET AL,Unfortunately we cannot increase the size of the volume easily since it is raw disk and has no native filesystem. Thus, while can increase on the storage side, it will not access the extra allocated disk since the filesystem (ext 4) is not formatted for it.We have two options to resolve this:The first would be to use the command resize2fs.  After  some research, this has a pretty good track-record of success; but we'd still need to backup the data as insurance.This would require a un-mount, run fdisk, make note of partition, node numbers, etc..and then run resize2fs....sounds a bit risky and not sure how long all this would take...The second option is - I have built another 2TB volume called JS2-Spend3 on the JetStor. This can be simply mounted and is ready to be formatted and used.I like this path since we need to back up the original volume anyway...might as well just put it there and be done with it.Thoughts?Chris",Sure....I will let everyone know when it is ready for mounting...,"Chris, Let’s do option 2 please. Thank you. Can we shoot for a 4TB instance size.","Do we have an update on this team. We need to migrate data and this is holding us up.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com",After a remount  we are still seeing the following Chris; Can you please advise. Filesystem      Size  Used Avail Use% Mounted on/dev/xvda1       50G  2.2G   48G   5% /devtmpfs        121G     0  121G   0% /devtmpfs           121G  2.8M  121G   1% /dev/shmtmpfs           121G   73M  120G   1% /runtmpfs           121G     0  121G   0% /sys/fs/cgroup/dev/sde        689G  654G  6.5M 100% /usr/local/mariadb/dev/sdf        689G   82G  573G  13% /var/log/mariadbtmpfs            25G     0   25G   0% /run/user/1001/dev/sdq        4.0T  3.5T  287G  93% /mnt/mysqldumpstmpfs            25G     0   25G   0% /run/user/1000tmpfs            25G     0   25G   0% /run/user/1007,Chris VeilletteAllen - we would need to unmount the vol in order to grow it.... I know you don't what to do this - can I build you another vol on the same box ?,"Hello Allen,We checked from the instance level the volume is completely occupied we could see that the volume is 100% used please see the below volume utilization details./dev/sde       ext4      689G  654G     0 100% /usr/local/mariadb654G    total654G    columnstore","From Chris,Hi Allen,I am checking on this....get back to you shortly...","Hi Allen/Chris,Yes we received the mail from Chris. We will check internally about this email issue and update you.For Volume Size, Chris we were planning to re-mount the volume but when we checked the volume, it was being used by multiple process. Therefore, we did not do that.Allen: Will you please stop all the services which are using this volume /usr/local/mariadb ? So that we can go ahead and re-mount the volume.Regards,Rohit Puri","Chris Veillette6:24 PM (2 minutes ago)to Rohit, Allen, Matthew, Andrew, spendhq-support Hi Rohit,I double-checked and I am at 1.95TB on this volume on the JetStor.I would suggest un-mount and re-mounting the volume if you haven't already.Let me know - if this doesn't work I will ping JetStor....Chris","Hi Chris,When we checked the size of the volume, it doesn't change. It still shows the same size. Please find the screenshot in the attachment section./dev/sde is the same volume which we asked for increasing the size of ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend2:dev7.ctr1-lun-0.Please iscsi screenshot in the attachment sectionPlease let us know if anything needs to be done from our end to reflect the size change. Thanks!",Next Action: Check with Rohit whether we are good to share the details with the customer.,"Chris VeilletteAttachments12:50 AM (7 hours ago)to Allen, Rohit, Matthew, Andrew, spendhq-support, REAN Hours agoChris Veillette","Allen Herrera12:13 AM (7 hours ago)to Matthew, Rohit, Chris, Andrew, spendhq-support, REAN Has this been accomplished?","Hello Team,Please let us know once you are done to increase the Volume to 2TB.Kindly revert back to us in case of any queries.","Chris Veillette <cveillette@andromeda3.com>8:04 PM (0 minutes ago)to Rohit, Andrew, Rean Done - will take just about 10 mins or so to complete the initialization.","Chris Veillette <cveillette@andromeda3.com>8:02 PM (1 minute ago)to Andrew, Rean, spendhq-support Ok  doing it now -will take just a bit to do ... 10 mins or so....","Andrew Kim7:50 PM (12 minutes ago)to Rean, spendhq-support Approved.","Hi Chris,Please increase the size of ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend2:dev7.ctr1-lun-0 ISCSI Volume to 2TB.@Andrew: Please approve the same. Regards,Rohit Puri","Hello Allen,We will work on this and will let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001kqOxB,Cloud Engineer Level 1,Closed,1112742,Incident,05-03-2019 17:50,,"In ops call, Praveen mentioned to close this case. As the latency issue is common###Hello Team,We haven't heard back from you regarding this case the URL  secure.spendhq.com  went down.At this time, we're marking this case as Resolved/closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,-Rafi###Hello Team,Please see the analysis we shared for the site down of secure.spendhq.com.---------------On analyzing the issue below are the finding regarding the case: Secure ELB Details: =============== 1) There was spike in average latency with the value of 55247. 2) Request was reached to the value of 96. NewPreview-ELB Details: =================== 1) On checking the last 24 hour metrics of average latency there is continous spikes in it. 2) Request count was 90. We also checked in wormly and found that it was giving connection timed out below are the logs for the same: HTTP Request 16:16:20 Operation timed out after 9000 milliseconds with 0 bytes received London UK HTTP Request 16:16:20 Operation timed out after 9001 milliseconds with 0 bytes received Frankfurt DE HTTP Request 16:16:20 Operation timed out after 9000 milliseconds with 0 bytes received California US HTTP Request 16:16:20 Operation timed out after 60001 milliseconds with 0 bytes received New Jersey US HTTP Request 16:16:20 Operation timed out after 9001 milliseconds with 0 bytes received Sydney-C AU HTTP Request 16:10:21 Operation timed out after 9001 milliseconds with 0 bytes received Frankfurt-B DE HTTP Request 16:10:21 Operation timed out after 9000 milliseconds with 0 bytes received Dallas-B US HTTP Request 16:10:21 Operation timed out after 9001 milliseconds with 0 bytes received Atlanta-B US HTTP Request 16:10:21 Operation timed out after 60001 milliseconds with 0 bytes received New Jersey US HTTP Request 16:10:21 Operation timed out after 9001 milliseconds with 0 bytes received Sydney-C AU HTTP Request 16:06:21 Operation timed out after 9001 milliseconds with 0 bytes received Frankfurt DE HTTP Request 16:06:21 Operation timed out after 60000 milliseconds with 0 bytes received New Jersey US HTTP Request 16:06:21 Operation timed out after 9000 milliseconds with 0 bytes received Sydney-C AU HTTP Request 16:06:21 Operation timed out after 9000 milliseconds with 0 bytes received Dallas-C US HTTP Request 16:06:21 Operation timed out after 9000 milliseconds with 0 bytes received Dallas-B US HTTP Request 16:04:21 Operation timed out after 9001 milliseconds with 0 bytes received Frankfurt-B DE HTTP Request 16:04:21 Operation timed out after 9000 milliseconds with 0 bytes received Dallas-B US HTTP Request 16:04:21 Operation timed out after 9000 milliseconds with 0 bytes received Frankfurt DE Everything seems to be normal from backend instance. On checking the ELB logs for both the Load Balancers there were 4XX response code for Secure-SpendHQ-ELB, below are the IPs having 4XX response code: 1) IP: 89.248.167.131 Country: Netherlands ISP: Incrediserve Ltd 2) IP: 179.98.156.83 Country: Brazil ISP: Vivo S.A. 3) IP: 197.255.189.25 Country: Congo ISP: Ofis Brazzaville We have attached the all relevant screenshot and logs in the attachment section please have a look at it and let us know if you have any queries. -----------------Regards-Rafi###Hello Team,On analyzing the issue below are the finding regarding the case:Secure ELB Details:===============1) There was spike in average latency with the value of 55247.2) Request was reached to the value of 96.NewPreview-ELB Details:===================1) On checking the last 24 hour metrics of average latency there is continous spikes in it.2) Request count was 90.We also checked in wormly and found that it was giving connection timed out below are the logs for the same:HTTP Request    16:16:20    Operation timed out after 9000 milliseconds with 0 bytes received        London UKHTTP Request    16:16:20    Operation timed out after 9001 milliseconds with 0 bytes received        Frankfurt DEHTTP Request    16:16:20    Operation timed out after 9000 milliseconds with 0 bytes received        California USHTTP Request    16:16:20    Operation timed out after 60001 milliseconds with 0 bytes received        New Jersey USHTTP Request    16:16:20    Operation timed out after 9001 milliseconds with 0 bytes received        Sydney-C AUHTTP Request    16:10:21    Operation timed out after 9001 milliseconds with 0 bytes received        Frankfurt-B DEHTTP Request    16:10:21    Operation timed out after 9000 milliseconds with 0 bytes received        Dallas-B USHTTP Request    16:10:21    Operation timed out after 9001 milliseconds with 0 bytes received        Atlanta-B USHTTP Request    16:10:21    Operation timed out after 60001 milliseconds with 0 bytes received        New Jersey USHTTP Request    16:10:21    Operation timed out after 9001 milliseconds with 0 bytes received        Sydney-C AUHTTP Request    16:06:21    Operation timed out after 9001 milliseconds with 0 bytes received        Frankfurt DEHTTP Request    16:06:21    Operation timed out after 60000 milliseconds with 0 bytes received        New Jersey USHTTP Request    16:06:21    Operation timed out after 9000 milliseconds with 0 bytes received        Sydney-C AUHTTP Request    16:06:21    Operation timed out after 9000 milliseconds with 0 bytes received        Dallas-C USHTTP Request    16:06:21    Operation timed out after 9000 milliseconds with 0 bytes received        Dallas-B USHTTP Request    16:04:21    Operation timed out after 9001 milliseconds with 0 bytes received        Frankfurt-B DEHTTP Request    16:04:21    Operation timed out after 9000 milliseconds with 0 bytes received        Dallas-B USHTTP Request    16:04:21    Operation timed out after 9000 milliseconds with 0 bytes received        Frankfurt DEEverything seems to be normal from backend instance. On checking the ELB logs for both the Load Balancers there were 4XX response code for Secure-SpendHQ-ELB, below are the IPs having 4XX response code:1) IP: 89.248.167.131   Country: Netherlands   ISP: Incrediserve Ltd2) IP: 179.98.156.83   Country: Brazil   ISP: Vivo S.A.3) IP: 197.255.189.25   Country: Congo   ISP: Ofis BrazzavilleWe have attached the all relevant screenshot and logs in the attachment section please have a look at it and let us know if you have any queries.Thanks###Hello Team,We have again received site down alert for url: https://secure.spendhq.com/login which got recovered automatically within 1 minute. We are analyzing the issue and will be sharing the details with you.###Hello Team, This is to inform you that at the time when we received site down alert, the site was loading fine from our end. We analyzed the issue and found the following on the external load balancer Secure-SpendHQ-ELB : 1. Spike in latency graph with a maximum value of 89756.97 ms 2. We can see a sudden spike in Request Count and value has been reached to 163 3. We also found a sudden spike in active connection count and value was 154 On internal load balancer NewPreview-ELB also we noticed the same patterns of graphs, here are the details : 1. Sudden Spike in latency during the same time of site down alert 2. Spike in request count with a value of 170 requests We have also verified the CPU, Network IN/OUT metrics of the backend instances for the time and all looks normal.From the instance, We didn't find any suspicious activity from the logs.Please check all screenshot of metrics from the attachment section.Kindly validates the details and let us know if you have any queries related to it.###Hello Team, This is to inform you that we received a site down alert for the following URL: https://secure.spendhq.com/login which later on recovered automatically after a minute. We are analyzing this and will be sharing more info. Thanks.","________________________________From: rean_ms@hitachivantara.com <rean_ms@hitachivantara.com>Sent: Saturday, March 2, 2019 10:59 AMTo: REAN Managed ServicesSubject: Detected Error on SpendHQ SecureSat, 02 Mar 2019 00:29:58 -0500Detected Error on SpendHQ SecureEstimated Downtime: 2 minuteshttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 60000 milliseconds with 0 bytes receivedSensor parameters:url: https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsecure.spendhq.com%2Flogin&amp;data=01%7C01%7Cgourav.pokhra%40hitachivantara.com%7Cbbd4806531c742ba2f7208d69ed01d01%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=1gJDDoyeyoTN8a%2Fo3ebenyfFuZH3M9eZBgQbKzsDifA%3D&amp;reserved=0expect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Frankfurt-B DE, Dallas-C US, Dallas-B US, Sydney-C AU",Detected Error on SpendHQ Secure,,02-03-2019 11:00,79,0,SpendHQ,"In ops call, Praveen mentioned to close this case. As the latency issue is common","Hello Team,We haven't heard back from you regarding this case the URL  secure.spendhq.com  went down.At this time, we're marking this case as Resolved/closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,-Rafi","Hello Team,Please see the analysis we shared for the site down of secure.spendhq.com.---------------On analyzing the issue below are the finding regarding the case: Secure ELB Details: =============== 1) There was spike in average latency with the value of 55247. 2) Request was reached to the value of 96. NewPreview-ELB Details: =================== 1) On checking the last 24 hour metrics of average latency there is continous spikes in it. 2) Request count was 90. We also checked in wormly and found that it was giving connection timed out below are the logs for the same: HTTP Request 16:16:20 Operation timed out after 9000 milliseconds with 0 bytes received London UK HTTP Request 16:16:20 Operation timed out after 9001 milliseconds with 0 bytes received Frankfurt DE HTTP Request 16:16:20 Operation timed out after 9000 milliseconds with 0 bytes received California US HTTP Request 16:16:20 Operation timed out after 60001 milliseconds with 0 bytes received New Jersey US HTTP Request 16:16:20 Operation timed out after 9001 milliseconds with 0 bytes received Sydney-C AU HTTP Request 16:10:21 Operation timed out after 9001 milliseconds with 0 bytes received Frankfurt-B DE HTTP Request 16:10:21 Operation timed out after 9000 milliseconds with 0 bytes received Dallas-B US HTTP Request 16:10:21 Operation timed out after 9001 milliseconds with 0 bytes received Atlanta-B US HTTP Request 16:10:21 Operation timed out after 60001 milliseconds with 0 bytes received New Jersey US HTTP Request 16:10:21 Operation timed out after 9001 milliseconds with 0 bytes received Sydney-C AU HTTP Request 16:06:21 Operation timed out after 9001 milliseconds with 0 bytes received Frankfurt DE HTTP Request 16:06:21 Operation timed out after 60000 milliseconds with 0 bytes received New Jersey US HTTP Request 16:06:21 Operation timed out after 9000 milliseconds with 0 bytes received Sydney-C AU HTTP Request 16:06:21 Operation timed out after 9000 milliseconds with 0 bytes received Dallas-C US HTTP Request 16:06:21 Operation timed out after 9000 milliseconds with 0 bytes received Dallas-B US HTTP Request 16:04:21 Operation timed out after 9001 milliseconds with 0 bytes received Frankfurt-B DE HTTP Request 16:04:21 Operation timed out after 9000 milliseconds with 0 bytes received Dallas-B US HTTP Request 16:04:21 Operation timed out after 9000 milliseconds with 0 bytes received Frankfurt DE Everything seems to be normal from backend instance. On checking the ELB logs for both the Load Balancers there were 4XX response code for Secure-SpendHQ-ELB, below are the IPs having 4XX response code: 1) IP: 89.248.167.131 Country: Netherlands ISP: Incrediserve Ltd 2) IP: 179.98.156.83 Country: Brazil ISP: Vivo S.A. 3) IP: 197.255.189.25 Country: Congo ISP: Ofis Brazzaville We have attached the all relevant screenshot and logs in the attachment section please have a look at it and let us know if you have any queries. -----------------Regards-Rafi","Hello Team,On analyzing the issue below are the finding regarding the case:Secure ELB Details:===============1) There was spike in average latency with the value of 55247.2) Request was reached to the value of 96.NewPreview-ELB Details:===================1) On checking the last 24 hour metrics of average latency there is continous spikes in it.2) Request count was 90.We also checked in wormly and found that it was giving connection timed out below are the logs for the same:HTTP Request    16:16:20    Operation timed out after 9000 milliseconds with 0 bytes received        London UKHTTP Request    16:16:20    Operation timed out after 9001 milliseconds with 0 bytes received        Frankfurt DEHTTP Request    16:16:20    Operation timed out after 9000 milliseconds with 0 bytes received        California USHTTP Request    16:16:20    Operation timed out after 60001 milliseconds with 0 bytes received        New Jersey USHTTP Request    16:16:20    Operation timed out after 9001 milliseconds with 0 bytes received        Sydney-C AUHTTP Request    16:10:21    Operation timed out after 9001 milliseconds with 0 bytes received        Frankfurt-B DEHTTP Request    16:10:21    Operation timed out after 9000 milliseconds with 0 bytes received        Dallas-B USHTTP Request    16:10:21    Operation timed out after 9001 milliseconds with 0 bytes received        Atlanta-B USHTTP Request    16:10:21    Operation timed out after 60001 milliseconds with 0 bytes received        New Jersey USHTTP Request    16:10:21    Operation timed out after 9001 milliseconds with 0 bytes received        Sydney-C AUHTTP Request    16:06:21    Operation timed out after 9001 milliseconds with 0 bytes received        Frankfurt DEHTTP Request    16:06:21    Operation timed out after 60000 milliseconds with 0 bytes received        New Jersey USHTTP Request    16:06:21    Operation timed out after 9000 milliseconds with 0 bytes received        Sydney-C AUHTTP Request    16:06:21    Operation timed out after 9000 milliseconds with 0 bytes received        Dallas-C USHTTP Request    16:06:21    Operation timed out after 9000 milliseconds with 0 bytes received        Dallas-B USHTTP Request    16:04:21    Operation timed out after 9001 milliseconds with 0 bytes received        Frankfurt-B DEHTTP Request    16:04:21    Operation timed out after 9000 milliseconds with 0 bytes received        Dallas-B USHTTP Request    16:04:21    Operation timed out after 9000 milliseconds with 0 bytes received        Frankfurt DEEverything seems to be normal from backend instance. On checking the ELB logs for both the Load Balancers there were 4XX response code for Secure-SpendHQ-ELB, below are the IPs having 4XX response code:1) IP: 89.248.167.131   Country: Netherlands   ISP: Incrediserve Ltd2) IP: 179.98.156.83   Country: Brazil   ISP: Vivo S.A.3) IP: 197.255.189.25   Country: Congo   ISP: Ofis BrazzavilleWe have attached the all relevant screenshot and logs in the attachment section please have a look at it and let us know if you have any queries.Thanks","Hello Team,We have again received site down alert for url: https://secure.spendhq.com/login which got recovered automatically within 1 minute. We are analyzing the issue and will be sharing the details with you.","Hello Team, This is to inform you that at the time when we received site down alert, the site was loading fine from our end. We analyzed the issue and found the following on the external load balancer Secure-SpendHQ-ELB : 1. Spike in latency graph with a maximum value of 89756.97 ms 2. We can see a sudden spike in Request Count and value has been reached to 163 3. We also found a sudden spike in active connection count and value was 154 On internal load balancer NewPreview-ELB also we noticed the same patterns of graphs, here are the details : 1. Sudden Spike in latency during the same time of site down alert 2. Spike in request count with a value of 170 requests We have also verified the CPU, Network IN/OUT metrics of the backend instances for the time and all looks normal.From the instance, We didn't find any suspicious activity from the logs.Please check all screenshot of metrics from the attachment section.Kindly validates the details and let us know if you have any queries related to it.","Hello Team, This is to inform you that we received a site down alert for the following URL: https://secure.spendhq.com/login which later on recovered automatically after a minute. We are analyzing this and will be sharing more info. Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000019CKbk,Cloud Engineer Level 1,Closed,1044413,Incident,25-03-2017 00:29,,"Hello SpendHQ Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello SpendHQ Team, This is a friendly reminder.Please review the RCA and let us know if you have any queries.###Hello SpendHQ Team,We have prepared the RCA for the outage happened on 12/03/2017. Please find the RCA in the attachment section and let us know if you have any queries.###We have shared the RCA with the Sudheer for review and he asked to perform some changes. We have made the changes and he asked to share with the client.###Hello Chris,Following are the list of instances and its ISCSI IQN names. Kindly, validate it from your end.1.PROD-SPHQ-WEB-SERVER02 (10.59.100.118) : InitiatorName=iqn.1994-05.com.redhat:a7565668c72a2. PROD-SPHQ-DB-SERVER02 (10.59.10.12) : InitiatorName=iqn.1994-05.com.redhat:573c3f4764b3. PROD-SPHQ-DB-SERVER03 (10.59.10.148) : InitiatorName=iqn.1994-05.com.redhat:2017011401484. PROD-SPHQ-DB-SERVER04 (10.59.10.91) : InitiatorName=iqn.1994-05.com.redhat:64d02cf6d2ce5. PROD-SPHQ-DB-SERVER05 (10.59.10.135) : InitiatorName=iqn.1994-05.com.redhat:64d02cf7e3df6. PROD-SPHQ-WEB-SERVER03 (10.59.100.94) : InitiatorName=iqn.1994-05.com.redhat:2017011100947. PROD-SPHQ-WEB-SERVER04 (10.59.100.104) : InitiatorName=iqn.1994-05.com.redhat:2017011001048. TEST-SPHQ-WEB-SERVER01 (10.59.100.125) : InitiatorName=iqn.1994-05.com.redhat:201701140125###Hello Chris,Thanks for the update. We will check the information provided by you for preparing the RCA and we will reach out to you if we need any further information from your end.###Could you please provide some details about the below-mentioned points.1) What analysis have we performed? - There were two issues resulting in the outage.  The first occurred when A3 tried to make changes to the network configuration in order to complete a Nimble OS upgrade.  One particular config caused the mgmt port which serves as a fail-over port to shutdown the B-node and fail to the A-node. This was a result of a bug in the Nimble OS version. This caused the volumes to go off-line.  Once the config was changed back, the volumes came back on-line - with the exception of shq1files01. This volume remained off-line due to the fact the IQN number  (iqn.1994-05.com.redhat:a7565668c72a) was different from the one that was configured on the ISCS initiator group on the Nimble.Once changed to the correct IQN of the AWS instance (iqn.1994-05.com.redhat:201701140125), the volume shq1file01 came back online.  Unknown how the IQN number changed - nothing A3 did would have changed it.2) What resolution procedure have been followed on this issue?3) What could be the long-term resolution to avoid this in future?The long term solution is upgrade the OS on the Nimble (to 3.6.x) in which A3 is currently in process of.  As far as the IQN number change, it is unclear to A3 as to how this happened.We are currently waiting for this updates from your part to create a consolidated RCA regarding the outage recently happened so that we can share it with SpendHq team.###Hello SpendHQ-Team,We are marking this case as resolved for now. Will get back to you with proper RCA once we have an update from Chris, Andromeda Team. Please note that the action is pending from Andromeda team. Once they provide a root cause regarding this outage, we will reopen this case and will share the consolidated RCA.Please let us know if you have any further queries.Thanks & Regards,Sumod.K.Bose###Hello Chris,This a gentle reminder since we haven't heard back from you regarding this issue.Please provide us with the updates for the earlier mentioned queries so that we can create a consolidated RCA regarding the outage recently happened and share with the SpendHQ Team.###Hi Chris,Could you please provide some details about the below-mentioned points.1) What analysis have we performed?2) What resolution procedure have been followed on this issue?3) What could be the long-term resolution to avoid this in future?We are currently waiting for this updates from your part to create a consolidated RCA regarding the outage recently happened so that we can share it with SpendHq team.###Sanket asked us to check with Sudheer for whether the info provided by Chris is enough to prepare the RCA from our side. We were expecting an RCA document from the nimple team, instead Chris sent a note. Sudheer is looking into it and will give an update.###Hello Chris,Thanks for your update.Please let us know once you got an update from the Nimble team.###Made changes to Nimble to accommodate near term OS upgrade.After, the controller B failed over to the A controller and volumes were off-line for some unknown reason.Failed-back to controller B and the volumes were visible - Except sphq1file01After investigation on the Nimble, it was determined that the IQN name was different from the IQN name of the AWS machine.  Unsure how this happened.Made change to the Nimble IQN to reflect the correct AWS IQN and volume came back on-line.Opened ticket with Nimble to figure out why the failover caused volumes to go off line.###t###Hello Chris,Thanks for your update.@SpendHQ-Team: Chris updated that he will provide the RCA by this pm and once we got that we will share the consolidated RCA document with you.Thanks&Regards,Anjali G Nair###Hi - I will shortly get it to you this pm -on vacation Chris Veillette###Hello Chris,As discussed on the troubleshooting session, could you please share the RCA with us.@SpendHQ-Team: Once we got the RCA from Andromeda team, we will share the consolidated RCA document with you.Thanks&Regards,Anjali G Nair###Hello SpendHQ Team, As discussed with you in call post snapshot restoration, we were able to mount the volumes and the service got up and running. Andromeda team will share the RCA by Monday evening and post that REAN will share the consolidated RCA document with SpendHQ Team. Please let us know if you have any queries regarding this.###We went on a call with the SpendHQ team to troubleshoot this issue.So we found out that we were not able to discover the ISCSI devices using the discovery command.We reached out to Andromeda team and they worked on the issue and asked us to check again.Later the connection with Nimble got restored.The volumes are mounted back on all instances except prod webserver and fileserver. The file storage volumes are not visible on fileserver and Andromeda team is troubleshooting that Hence we are still working with the Andromeda team and SpendHQ Team.###Hello SpendHQ-Team,We have tried to reaching out to Matthew, Andrew, Chris (Andromeda) and David (Andromeda) but we got no response.  Please respond back to us as soon as possible.###Hello SpendHQ-Team,On further analysis, from the system logs, we found following errors which are related to ISCSI connections.Mar 11 19:22:37 ip-10-59-100-118 kernel: connection3:0: ping timeout of 10 secs expired, recv timeout 5, last rx 11816749078, last ping 11816754078, now 11816764078Mar 11 19:22:37 ip-10-59-100-118 kernel: connection3:0: detected conn error (1011)Mar 11 19:22:38 ip-10-59-100-118 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)We are troubleshooting the issue currently and will let you know the updates shortly.###Hello SpendHQ-Team,This is to notify you that we have received site down alert for the URLs https://preview.spendhq.com/login and  https://secure.spendhq.com/login.  We are looking into it and will let you know the updates. Meanwhile, please let us know if you are performing any activities from your end.","Sat, 11 Mar 2017 16:24:17 -0500Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 403, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Frankfurt DE, London UK, Atlanta-B US, Dallas-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,12-03-2017 02:54,310,0,SpendHQ,"Hello SpendHQ Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello SpendHQ Team, This is a friendly reminder.Please review the RCA and let us know if you have any queries.","Hello SpendHQ Team,We have prepared the RCA for the outage happened on 12/03/2017. Please find the RCA in the attachment section and let us know if you have any queries.",We have shared the RCA with the Sudheer for review and he asked to perform some changes. We have made the changes and he asked to share with the client.,"Hello Chris,Following are the list of instances and its ISCSI IQN names. Kindly, validate it from your end.1.PROD-SPHQ-WEB-SERVER02 (10.59.100.118) : InitiatorName=iqn.1994-05.com.redhat:a7565668c72a2. PROD-SPHQ-DB-SERVER02 (10.59.10.12) : InitiatorName=iqn.1994-05.com.redhat:573c3f4764b3. PROD-SPHQ-DB-SERVER03 (10.59.10.148) : InitiatorName=iqn.1994-05.com.redhat:2017011401484. PROD-SPHQ-DB-SERVER04 (10.59.10.91) : InitiatorName=iqn.1994-05.com.redhat:64d02cf6d2ce5. PROD-SPHQ-DB-SERVER05 (10.59.10.135) : InitiatorName=iqn.1994-05.com.redhat:64d02cf7e3df6. PROD-SPHQ-WEB-SERVER03 (10.59.100.94) : InitiatorName=iqn.1994-05.com.redhat:2017011100947. PROD-SPHQ-WEB-SERVER04 (10.59.100.104) : InitiatorName=iqn.1994-05.com.redhat:2017011001048. TEST-SPHQ-WEB-SERVER01 (10.59.100.125) : InitiatorName=iqn.1994-05.com.redhat:201701140125","Hello Chris,Thanks for the update. We will check the information provided by you for preparing the RCA and we will reach out to you if we need any further information from your end.","Could you please provide some details about the below-mentioned points.1) What analysis have we performed? - There were two issues resulting in the outage.  The first occurred when A3 tried to make changes to the network configuration in order to complete a Nimble OS upgrade.  One particular config caused the mgmt port which serves as a fail-over port to shutdown the B-node and fail to the A-node. This was a result of a bug in the Nimble OS version. This caused the volumes to go off-line.  Once the config was changed back, the volumes came back on-line - with the exception of shq1files01. This volume remained off-line due to the fact the IQN number  (iqn.1994-05.com.redhat:a7565668c72a) was different from the one that was configured on the ISCS initiator group on the Nimble.Once changed to the correct IQN of the AWS instance (iqn.1994-05.com.redhat:201701140125), the volume shq1file01 came back online.  Unknown how the IQN number changed - nothing A3 did would have changed it.2) What resolution procedure have been followed on this issue?3) What could be the long-term resolution to avoid this in future?The long term solution is upgrade the OS on the Nimble (to 3.6.x) in which A3 is currently in process of.  As far as the IQN number change, it is unclear to A3 as to how this happened.We are currently waiting for this updates from your part to create a consolidated RCA regarding the outage recently happened so that we can share it with SpendHq team.","Hello SpendHQ-Team,We are marking this case as resolved for now. Will get back to you with proper RCA once we have an update from Chris, Andromeda Team. Please note that the action is pending from Andromeda team. Once they provide a root cause regarding this outage, we will reopen this case and will share the consolidated RCA.Please let us know if you have any further queries.Thanks & Regards,Sumod.K.Bose","Hello Chris,This a gentle reminder since we haven't heard back from you regarding this issue.Please provide us with the updates for the earlier mentioned queries so that we can create a consolidated RCA regarding the outage recently happened and share with the SpendHQ Team.","Hi Chris,Could you please provide some details about the below-mentioned points.1) What analysis have we performed?2) What resolution procedure have been followed on this issue?3) What could be the long-term resolution to avoid this in future?We are currently waiting for this updates from your part to create a consolidated RCA regarding the outage recently happened so that we can share it with SpendHq team.","Sanket asked us to check with Sudheer for whether the info provided by Chris is enough to prepare the RCA from our side. We were expecting an RCA document from the nimple team, instead Chris sent a note. Sudheer is looking into it and will give an update.","Hello Chris,Thanks for your update.Please let us know once you got an update from the Nimble team.","Made changes to Nimble to accommodate near term OS upgrade.After, the controller B failed over to the A controller and volumes were off-line for some unknown reason.Failed-back to controller B and the volumes were visible - Except sphq1file01After investigation on the Nimble, it was determined that the IQN name was different from the IQN name of the AWS machine.  Unsure how this happened.Made change to the Nimble IQN to reflect the correct AWS IQN and volume came back on-line.Opened ticket with Nimble to figure out why the failover caused volumes to go off line.",t,"Hello Chris,Thanks for your update.@SpendHQ-Team: Chris updated that he will provide the RCA by this pm and once we got that we will share the consolidated RCA document with you.Thanks&Regards,Anjali G Nair",Hi - I will shortly get it to you this pm -on vacation Chris Veillette,"Hello Chris,As discussed on the troubleshooting session, could you please share the RCA with us.@SpendHQ-Team: Once we got the RCA from Andromeda team, we will share the consolidated RCA document with you.Thanks&Regards,Anjali G Nair","Hello SpendHQ Team, As discussed with you in call post snapshot restoration, we were able to mount the volumes and the service got up and running. Andromeda team will share the RCA by Monday evening and post that REAN will share the consolidated RCA document with SpendHQ Team. Please let us know if you have any queries regarding this.",We went on a call with the SpendHQ team to troubleshoot this issue.So we found out that we were not able to discover the ISCSI devices using the discovery command.We reached out to Andromeda team and they worked on the issue and asked us to check again.Later the connection with Nimble got restored.The volumes are mounted back on all instances except prod webserver and fileserver. The file storage volumes are not visible on fileserver and Andromeda team is troubleshooting that Hence we are still working with the Andromeda team and SpendHQ Team.,"Hello SpendHQ-Team,We have tried to reaching out to Matthew, Andrew, Chris (Andromeda) and David (Andromeda) but we got no response.  Please respond back to us as soon as possible.","Hello SpendHQ-Team,On further analysis, from the system logs, we found following errors which are related to ISCSI connections.Mar 11 19:22:37 ip-10-59-100-118 kernel: connection3:0: ping timeout of 10 secs expired, recv timeout 5, last rx 11816749078, last ping 11816754078, now 11816764078Mar 11 19:22:37 ip-10-59-100-118 kernel: connection3:0: detected conn error (1011)Mar 11 19:22:38 ip-10-59-100-118 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)We are troubleshooting the issue currently and will let you know the updates shortly.","Hello SpendHQ-Team,This is to notify you that we have received site down alert for the URLs https://preview.spendhq.com/login and  https://secure.spendhq.com/login.  We are looking into it and will let you know the updates. Meanwhile, please let us know if you are performing any activities from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C3Q0P,Cloud Engineer Level 1,Closed,1055155,Incident,21-05-2017 10:20,,"Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 which belongs to the Preview ELB. We analyzed the ELB logs at the time of the alert, We were able to find the IP's 139.162.79.87.The IP 139.162.79.87 belongs to Ohio region in United States . This IP was trying to execute the SERVER-APACHE Apache Struts remote code and this IP was reported as abused IP.As a fix, we have blocked the IP's at NACL level. Please find the logs details below, ELB Logs: 2017-05-21T02:25:09.158339Z preview-spendhq-xelb 139.162.79.87:35046 10.59.1.192:8080 0.000036 0.001676 0.00002 403 403 0 209 GET http://52.6.177.194:8080/ HTTP/1.1 Mozilla/5.0 - -2017-05-21T02:25:09.158339Z preview-spendhq-xelb 139.162.79.87:35046 10.59.1.192:8080 0.000036 0.001676 0.00002 403 403 0 209 GET http://52.6.177.194:8080/ HTTP/1.1 Mozilla/5.0 - -Let us know if your team have any further queries regarding this case.###Hello SpendHQ Team,We have checked both the Secure and Preview ELB logs and we found that the IPs 139.162.114.70, 40.77.167.4, 217.71.221.26, 52.10.143.253, 34.250.66.237 and 188.166.8.122 were having 4xx/5xx response codes at the time of alert. As per https://www.abuseipdb.com, we found that the IPs 139.162.114.70, 40.77.167.4 were reported for attack. Hence we have blocked those IPs in NACL level.We haven't yet blocked the IPs  217.71.221.26, 52.10.143.253, 34.250.66.237 and 188.166.8.122. Please validate the IPs and let us know if you want to block these IPs.Please find the below IPS logs2017:05:20-20:20:02 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=33231 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:20:02 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=33231 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:20:43 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.111 dstip=10.59.1.192 proto=6 srcport=50842 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:20:43 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.111 dstip=10.59.1.192 proto=6 srcport=50842 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:21:25 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=49030 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:21:25 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=49030 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:33:02 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.123 dstip=10.59.1.192 proto=6 srcport=30999 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:33:02 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.123 dstip=10.59.1.192 proto=6 srcport=30999 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0###Hi SpendHQ Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address 10.59.1.20 and 10.59.1.167 belongs to the secure and preview ELB respectively. We are investigating the alert and will get back to you with updates.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-20 20:33:02Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.123 Source port: 30999Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)        -- System Uptime : 189 days 12 hours 47 minutes System Load : 0.14 System Version : Sophos UTM 9.408-4 Please refer to the manual for detailed instructions.,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,21-05-2017 02:10,17,0,SpendHQ,"Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 which belongs to the Preview ELB. We analyzed the ELB logs at the time of the alert, We were able to find the IP's 139.162.79.87.The IP 139.162.79.87 belongs to Ohio region in United States . This IP was trying to execute the SERVER-APACHE Apache Struts remote code and this IP was reported as abused IP.As a fix, we have blocked the IP's at NACL level. Please find the logs details below, ELB Logs: 2017-05-21T02:25:09.158339Z preview-spendhq-xelb 139.162.79.87:35046 10.59.1.192:8080 0.000036 0.001676 0.00002 403 403 0 209 GET http://52.6.177.194:8080/ HTTP/1.1 Mozilla/5.0 - -2017-05-21T02:25:09.158339Z preview-spendhq-xelb 139.162.79.87:35046 10.59.1.192:8080 0.000036 0.001676 0.00002 403 403 0 209 GET http://52.6.177.194:8080/ HTTP/1.1 Mozilla/5.0 - -Let us know if your team have any further queries regarding this case.","Hello SpendHQ Team,We have checked both the Secure and Preview ELB logs and we found that the IPs 139.162.114.70, 40.77.167.4, 217.71.221.26, 52.10.143.253, 34.250.66.237 and 188.166.8.122 were having 4xx/5xx response codes at the time of alert. As per https://www.abuseipdb.com, we found that the IPs 139.162.114.70, 40.77.167.4 were reported for attack. Hence we have blocked those IPs in NACL level.We haven't yet blocked the IPs  217.71.221.26, 52.10.143.253, 34.250.66.237 and 188.166.8.122. Please validate the IPs and let us know if you want to block these IPs.Please find the below IPS logs2017:05:20-20:20:02 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=33231 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:20:02 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=33231 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:20:43 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.111 dstip=10.59.1.192 proto=6 srcport=50842 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:20:43 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.111 dstip=10.59.1.192 proto=6 srcport=50842 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:21:25 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=49030 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:21:25 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=49030 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:33:02 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.123 dstip=10.59.1.192 proto=6 srcport=30999 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:20-20:33:02 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.123 dstip=10.59.1.192 proto=6 srcport=30999 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0","Hi SpendHQ Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address 10.59.1.20 and 10.59.1.167 belongs to the secure and preview ELB respectively. We are investigating the alert and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gcgF7,Cloud Engineer Level 2,Closed,1109625,Incident,23-12-2018 02:27,,"Hello Matthew,Thanks for the confirmation,At this time we are marking this case as closed.###Matthew Watts <mwatts@spendhq.com>Today, 2:16 AMRean Support <support@reancloud.com>;spendhq-support@reancloud.comPerfect. We can close this off.###Hello Team,the alert High Network OUT on the host for SPHQ-DB4-20180830  still in the alert state.Please find our analysis below and please let us know if you have any questions regarding the same,###@morning team: Please check with Rohit whether we can change the threshold value to 30 G and make the changes accordingly in DD###@Team,while checking i could see that the alert regarding High Network OUT on host is in alert state for last few months. The current threshold value is 1.1G . The average value of alert is 20 - 30 G. So please check with Rohit whether we can change the threshold value to 30 G  and make the changes accordingly in DD. thank you.###Hello Team,We haven't heard from you on this case.The monitor is still in alert state with the current average Network Out value standing at 29.56GB/min.Please review the previously shared analysis and let us know if you have any concerns.Thanks.###Hello Team,This is a quick followup.Please review our shared analysis and let us know if you have any query/concern.Thanks,###Hello Team,We have analyzed the issue and from the instance level we can see a relatively small number of active connections with most of the ESTABLISHED and CONNECTED connections coming from IP 10.59.100.193 which is PRD-SV1 server.netstat -a | grep ESTABLISHED | wc -l175netstat -a | grep CONNECTED | wc -l44From the CloudWatch level we could see a considerable spike in Network Packets Out over the last couple of hours.============Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    tcp        0      0 0.0.0.0:8601            0.0.0.0:*               LISTEN      121344/             tcp        0      0 0.0.0.0:8700            0.0.0.0:*               LISTEN      121312/workernode   tcp        0      0 0.0.0.0:42109           0.0.0.0:*               LISTEN      -                   tcp        0      0 127.0.0.1:8126          0.0.0.0:*               LISTEN      5934/trace-agent    tcp        0      0 0.0.0.0:8800            0.0.0.0:*               LISTEN      1924/ProcMon        tcp        0      0 0.0.0.0:43459           0.0.0.0:*               LISTEN      1352/rpc.statd      tcp        0      0 0.0.0.0:8612            0.0.0.0:*               LISTEN      121417/             tcp        0      0 0.0.0.0:8614            0.0.0.0:*               LISTEN      121498/             tcp        0      0 127.0.0.1:5000          0.0.0.0:*               LISTEN      5933/agent          tcp        0      0 127.0.0.1:5001          0.0.0.0:*               LISTEN      5933/agent          tcp        0      0 0.0.0.0:8622            0.0.0.0:*               LISTEN      121249/ServerMonito tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      871/rpcbind         tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1301/sshd           tcp6       0      0 :::45607                :::*                    LISTEN      1352/rpc.statd      tcp6       0      0 :::3306                 :::*                    LISTEN      21412/mysqld        tcp6       0      0 :::37324                :::*                    LISTEN      -                   tcp6       0      0 :::111                  :::*                    LISTEN      871/rpcbind         tcp6       0      0 :::22                   :::*                    LISTEN      1301/sshd           udp        0      0 0.0.0.0:55427           0.0.0.0:*                           -                   udp        0      0 0.0.0.0:58607           0.0.0.0:*                           1352/rpc.statd      udp        0      0 0.0.0.0:68              0.0.0.0:*                           1125/dhclient       udp        0      0 0.0.0.0:111             0.0.0.0:*                           871/rpcbind         udp        0      0 127.0.0.1:323           0.0.0.0:*                           870/chronyd         udp        0      0 0.0.0.0:617             0.0.0.0:*                           871/rpcbind         udp        0      0 127.0.0.1:703           0.0.0.0:*                           1352/rpc.statd      udp        0      0 127.0.0.1:8125          0.0.0.0:*                           5933/agent          udp6       0      0 :::45643                :::*                                -                   udp6       0      0 :::47239                :::*                                1352/rpc.statd      udp6       0      0 :::111                  :::*                                871/rpcbind         udp6       0      0 ::1:323                 :::*                                870/chronyd         udp6       0      0 :::617                  :::*                                871/rpcbind  ================We have attached the full netstat logs and other CloudWatch metrics for your reference.Please go through them and let us know if you have any questions.###Hello Team,This is to notify that we have received an alert regarding High Network OUT on host - sphq-db4-20180830 - 10.59.10.210. The average connection count has been above 1100000000 over the last 30 minutes.We are analyzing the issue and will get back to you with an update.Resource Details:---Instance Name: SPHQ-DB4-20180830Instance ID: i-082d412700b276f44Instance Type: r4.8xlargePrivate IP: 10.59.10.210AZ: us-east-1bVPC ID: vpc-76df7212Subnet ID: subnet-0fdde924Account: spendhq (261234435984)---","---------- Forwarded message ---------From: Datadog Alerting <alert@dtdg.co>Date: Tue, Dec 18, 2018 at 9:04 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host -sphq-db4-20180830 - 10.59.10.210 -To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Network OUT on host - sphq-db4-20180830 -10.59.10.210 -High Network OUT on the instance. Please check the list open TCPConnections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024199?to_ts=1545156269000&group=host%3Ai-082d412700b276f44&from_ts=1545149069000>*aws.ec2.network_out* over *datadog_monitor:on,host:i-082d412700b276f44*was *> 1100000000.0* at all times during the *last 30m*.The monitor was last triggered at Tue Dec 18 2018 18:04:39 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024199?group=host%3Ai-082d412700b276f44>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024199/edit>] · [Viewi-082d412700b276f44<https://app.datadoghq.com/infrastructure?filter=i-082d412700b276f44>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1545156399000&tags=host%3Ai-082d412700b276f44&from_ts=1545155379000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4712609487827544913>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - sphq-db4-20180830 - 10.59.10.210 -,,18-12-2018 23:38,99,0,SpendHQ,"Hello Matthew,Thanks for the confirmation,At this time we are marking this case as closed.","Matthew Watts <mwatts@spendhq.com>Today, 2:16 AMRean Support <support@reancloud.com>;spendhq-support@reancloud.comPerfect. We can close this off.","Hello Team,the alert High Network OUT on the host for SPHQ-DB4-20180830  still in the alert state.Please find our analysis below and please let us know if you have any questions regarding the same,",@morning team: Please check with Rohit whether we can change the threshold value to 30 G and make the changes accordingly in DD,"@Team,while checking i could see that the alert regarding High Network OUT on host is in alert state for last few months. The current threshold value is 1.1G . The average value of alert is 20 - 30 G. So please check with Rohit whether we can change the threshold value to 30 G  and make the changes accordingly in DD. thank you.","Hello Team,We haven't heard from you on this case.The monitor is still in alert state with the current average Network Out value standing at 29.56GB/min.Please review the previously shared analysis and let us know if you have any concerns.Thanks.","Hello Team,This is a quick followup.Please review our shared analysis and let us know if you have any query/concern.Thanks,","Hello Team,We have analyzed the issue and from the instance level we can see a relatively small number of active connections with most of the ESTABLISHED and CONNECTED connections coming from IP 10.59.100.193 which is PRD-SV1 server.netstat -a | grep ESTABLISHED | wc -l175netstat -a | grep CONNECTED | wc -l44From the CloudWatch level we could see a considerable spike in Network Packets Out over the last couple of hours.============Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    tcp        0      0 0.0.0.0:8601            0.0.0.0:*               LISTEN      121344/             tcp        0      0 0.0.0.0:8700            0.0.0.0:*               LISTEN      121312/workernode   tcp        0      0 0.0.0.0:42109           0.0.0.0:*               LISTEN      -                   tcp        0      0 127.0.0.1:8126          0.0.0.0:*               LISTEN      5934/trace-agent    tcp        0      0 0.0.0.0:8800            0.0.0.0:*               LISTEN      1924/ProcMon        tcp        0      0 0.0.0.0:43459           0.0.0.0:*               LISTEN      1352/rpc.statd      tcp        0      0 0.0.0.0:8612            0.0.0.0:*               LISTEN      121417/             tcp        0      0 0.0.0.0:8614            0.0.0.0:*               LISTEN      121498/             tcp        0      0 127.0.0.1:5000          0.0.0.0:*               LISTEN      5933/agent          tcp        0      0 127.0.0.1:5001          0.0.0.0:*               LISTEN      5933/agent          tcp        0      0 0.0.0.0:8622            0.0.0.0:*               LISTEN      121249/ServerMonito tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      871/rpcbind         tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1301/sshd           tcp6       0      0 :::45607                :::*                    LISTEN      1352/rpc.statd      tcp6       0      0 :::3306                 :::*                    LISTEN      21412/mysqld        tcp6       0      0 :::37324                :::*                    LISTEN      -                   tcp6       0      0 :::111                  :::*                    LISTEN      871/rpcbind         tcp6       0      0 :::22                   :::*                    LISTEN      1301/sshd           udp        0      0 0.0.0.0:55427           0.0.0.0:*                           -                   udp        0      0 0.0.0.0:58607           0.0.0.0:*                           1352/rpc.statd      udp        0      0 0.0.0.0:68              0.0.0.0:*                           1125/dhclient       udp        0      0 0.0.0.0:111             0.0.0.0:*                           871/rpcbind         udp        0      0 127.0.0.1:323           0.0.0.0:*                           870/chronyd         udp        0      0 0.0.0.0:617             0.0.0.0:*                           871/rpcbind         udp        0      0 127.0.0.1:703           0.0.0.0:*                           1352/rpc.statd      udp        0      0 127.0.0.1:8125          0.0.0.0:*                           5933/agent          udp6       0      0 :::45643                :::*                                -                   udp6       0      0 :::47239                :::*                                1352/rpc.statd      udp6       0      0 :::111                  :::*                                871/rpcbind         udp6       0      0 ::1:323                 :::*                                870/chronyd         udp6       0      0 :::617                  :::*                                871/rpcbind  ================We have attached the full netstat logs and other CloudWatch metrics for your reference.Please go through them and let us know if you have any questions.","Hello Team,This is to notify that we have received an alert regarding High Network OUT on host - sphq-db4-20180830 - 10.59.10.210. The average connection count has been above 1100000000 over the last 30 minutes.We are analyzing the issue and will get back to you with an update.Resource Details:---Instance Name: SPHQ-DB4-20180830Instance ID: i-082d412700b276f44Instance Type: r4.8xlargePrivate IP: 10.59.10.210AZ: us-east-1bVPC ID: vpc-76df7212Subnet ID: subnet-0fdde924Account: spendhq (261234435984)---",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001i6csz,Cloud Engineer Level 2,Closed,1110749,Incident,28-01-2019 23:37,,"Hello Matthew, Just a quick email to see if there is an update on this case. Please review the analysis shared on this case and please let us know if you have any questions.In the mean time we will mark this case as closed. Please feel free to reopen it if you have any concerns.Thanks.###@Team:Do a final follow up and close this.###@TeamSince we have done several followups already, please check with CC if we can close this case.###Hello Matthew, Just a quick email to see if there is an update on this case. Please review the analysis shared on this case and please let us know if you have any questions. Thank you.###Hello Matthew, We haven't heard back from you. The issue seems to be resolved, the Production DB went offline because of the ISCSI volume store MariaDB data went into read-only mode. Later a reboot performed by you resolved the issue.For now, we are reducing the priority of this ticket from P2 to P4. We will be looking forward to your response, please review the complete analysis shared here and let us know if you have any queries regarding it.###Hello Matthew,Just a quick email to see if there is an update on this case. Please review the analysis shared on this case and please let us know if you have any questions.Thank you.###Hello Matthew, We haven't heard back from you. Kindly review the shared analysis and let us know if you have any questions or concerns.As the issue is resolved we are downgrading the priority to P2###As per ops call update, we are downgrading the priority###Hello Matthew, We haven't heard back from you.Kindly review the shared analysis and let us know if you have any questions or concerns.###Hello Matthew, This is a quick followupKindly review the shared analysis and let us know if you have any questions or concerns. Thanks###Hello Matthew, We haven't heard back from you regarding this case. Kindly review the shared analysis and let us know if you have any questions or concerns. Thanks###Hello Matthew,We have further looked into this issue.Looking at the system logs before the issue has been reported we were able to figure out that the iscsi volume on which the MariaDB data is stored went to read only mode.Upon checking the mysqlmariadb-error.log, we could see that from 10 AM UTC we started receiving Errcode: 30 Read-only file system  error and it continued till the time a reboot has been performed on this instance. [root@ip-10-59-10-210 mysql]# cat mysqlmariadb-error.log | grep -i 2019-01-15 10:00:02019-01-15 10:00:00 140348329977984 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins2019-01-15 10:00:00 140348329977984 [Note] InnoDB: Uses event mutexes2019-01-15 10:00:00 140348329977984 [Note] InnoDB: Compressed tables use zlib 1.2.72019-01-15 10:00:00 140348329977984 [Note] InnoDB: Using Linux native AIO2019-01-15 10:00:00 140348329977984 [Note] InnoDB: Number of pools: 12019-01-15 10:00:00 140348329977984 [Note] InnoDB: Using SSE2 crc32 instructions2019-01-15 10:00:00 140348329977984 [ERROR] mysqld: Can't create/write to file '/usr/local/mariadb/columnstore/mysql/tmp/ibSNYxzD' (Errcode: 30 Read-only file system)2019-01-15 10:00:00 140348329977984 [ERROR] InnoDB: Unable to create temporary file; errno: 302019-01-15 10:00:00 140348329977984 [ERROR] mysqld: Can't create/write to file '/usr/local/mariadb/columnstore/mysql/tmp/ibHzCN73' (Errcode: 30 Read-only file system)2019-01-15 10:00:00 140348329977984 [ERROR] InnoDB: Unable to create temporary file; errno: 302019-01-15 10:00:00 140348329977984 [ERROR] InnoDB: Plugin initialization aborted with error Generic error2019-01-15 10:00:00 140348329977984 [Note] InnoDB: Starting shutdown...2019-01-15 10:00:00 140348329977984 [ERROR] Plugin 'InnoDB' init function returned error.2019-01-15 10:00:00 140348329977984 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed.2019-01-15 10:00:00 140348329977984 [ERROR] mysqld: File '/usr/local/mariadb/columnstore/mysql/db/aria_log_control' not found (Errcode: 30 Read-only file system)2019-01-15 10:00:00 140348329977984 [ERROR] mysqld: Got error 'Can't open file' when trying to use aria control file '/usr/local/mariadb/columnstore/mysql/db/aria_log_control'2019-01-15 10:00:00 140348329977984 [ERROR] Plugin 'Aria' init function returned error.2019-01-15 10:00:00 140348329977984 [ERROR] Plugin 'Aria' registration as a STORAGE ENGINE failed.[root@ip-10-59-10-210 mysql]# last reboot | less reboot system boot 3.10.0-862.11.6. Tue Jan 15 11:13 - 21:12 (09:58) reboot system boot 3.10.0-862.11.6. Tue Jan 15 11:02 - 21:12 (10:09) reboot system boot 3.10.0-862.11.6. Tue Jan 15 10:50 - 21:12 (10:21) As we could see that on 15th Jan, 3 times reboot was performed on this instance. The reboot which was performed at 10:50 UTC, then after the read-only mode error were gone and Mysql daemon got ready for connections after recovering from the crash which transaction changed 1 row. Later they performed another reboot while the buffer pool was getting loaded. Also, we have checked with AWS team and confirmed there was no network related issues during that time. We did not find any suspicious logs which can lead us to any networking issue on the connectivity between both the machines 10.59.10.210 and 10.59.10.26. Since this volume is managing by SpendHQ team, we are requesting you to check it on your end. Kindly verify the details and let us know if you have any queries.###@Team:We checked on this issue. We did not find any suspicious logs which can lead us to any networking issue on the connectivity between both the machines 10.59.10.210 and 10.59.10.26When we checked the mariadb error logs for the machine 10.59.10.210, we do can see that there was Errcode: 30 Read-only file system errors. There was no unusual on the other machine. The volume on which the mariadb data is stored is an iSCSI volume. But we have not notice any RO mode issue on the volume. This volume is taken care by SpendHQ team itself. They need to check at their end if there was any connectivity issue for this.  Please share the error logs for mariadb with the customer. Thanks !###Hello TeamWe are still working on the RCA. We will share RCA with you once it's completed.Thanks###@Rohit I had gone on chat with the AWS and checked if there any issue with the AWS side regarding the connectivity. they mentioned there is no downtime at their part.They mentioned that the Error that we find in logs is after the reboot as the network interface was initializing.As per CP comment, we could see that the customer was trying to connect using the wrong username and later they had logged in using the centos user and the key.kindly review the CP comment for more details and provide an update.###@here I created a format for the RCA, please ask Rohit to review the analysis and based on that update the RCA.https://docs.google.com/document/d/1LWHBHsfX_rbue5vk0B24JweoViN2p5zAoTculJ-c1Tg/edit?usp=sharing###@Rohit, I further checked on this issue and here are findings:Dusty Fowler reports us issue at 10:22 am UTC. While checking the secure logs we can see that earlier they were trying with the incorrect user but during the same time they switched to centos user and logged into the server. Means there was not issue with the connectivity.https://docs.google.com/document/d/1Ii7whRukO8c9zI76BlT1g0XtFs3YTfIIO5XIWihKFvE/edit?usp=sharingUpon checking the mysqlmariadb-error.log, we could see that from 10 AM UTC we started receiving Errcode: 30 Read-only file system  error and it continued till the time a reboot has been performed on this instance.[root@ip-10-59-10-210 mysql]# last reboot | lessreboot   system boot  3.10.0-862.11.6. Tue Jan 15 11:13 - 21:12  (09:58)    reboot   system boot  3.10.0-862.11.6. Tue Jan 15 11:02 - 21:12  (10:09)    reboot   system boot  3.10.0-862.11.6. Tue Jan 15 10:50 - 21:12  (10:21)As we could see that on 15th Jan, 3 times reboot was performed on this instance. The reboot which was performed at 10:50 UTC, then after the read-only mode error were gone and Mysql daemon got ready for connections after recovering from the crash which transaction changed 1 row.2019-01-15 10:54:43 140219123579008 [Note] Starting crash recovery...2019-01-15 10:54:43 140219123579008 [Note] InnoDB: Starting recovery for XA transactions...2019-01-15 10:54:43 140219123579008 [Note] InnoDB: Transaction 378840786 in prepared state after recovery2019-01-15 10:54:43 140219123579008 [Note] InnoDB: Transaction contains changes to 1 rows2019-01-15 10:54:43 140219123579008 [Note] InnoDB: 1 transactions in prepared state after recovery2019-01-15 10:54:43 140219123579008 [Note] Found 1 prepared transaction(s) in InnoDB2019-01-15 10:54:43 140219123579008 [Note] Crash recovery finished.2019-01-15 10:54:43 140219035903744 [Warning] InnoDB: Table mysql/innodb_table_stats has length mismatch in the column name table_name.  Please run mysql_upgrade2019-01-15 10:54:43 140219035903744 [Warning] InnoDB: Table mysql/innodb_index_stats has length mismatch in the column name table_name.  Please run mysql_upgrade2019-01-15 10:54:43 140219123579008 [Note] Server socket created on IP: '::'.2019-01-15 10:54:43 140219123579008 [ERROR] mysqld: Incorrect information in file: '/usr/local/mariadb/columnstore/mysql/tmp/#sqlaa5c_441b67_3.frm'2019-01-15 10:54:43 140219123579008 [Note] Reading of all Master_info entries succeded2019-01-15 10:54:43 140219123579008 [Note] Added new Master_info '' to hash table2019-01-15 10:54:43 140219123579008 [Note] /usr/local/mariadb/columnstore/mysql//bin/mysqld: ready for connections.Later they performed another reboot while the buffer pool was getting loaded. 2019-01-15 10:55:33 140129009088256 [Warning] InnoDB: Table mysql/innodb_index_stats has length mismatch in the column name table_name.  Please run mysql_upgrade2019-01-15 10:58:52 140130144741120 [Note] InnoDB: Buffer pool(s) load completed at 190115 10:58:522019-01-15 10:59:40 140130088302336 [Note] /usr/local/mariadb/columnstore/mysql//bin/mysqld (initiated by: unknown): Normal shutdown2019-01-15 10:59:45 140130088302336 [Note] InnoDB: Shutdown completed; log sequence number 83058018504962019-01-15 10:59:45 140130088302336 [Note] /usr/local/mariadb/columnstore/mysql//bin/mysqld: Shutdown complete2019-01-15 10:59:47 140387927427200 [Note] InnoDB: Initializing buffer pool, total size = 79G, instances = 8, chunk size = 128MPlease find the complete logs with the description in the sheet and let us know the next action :https://docs.google.com/document/d/1r6S39gxbxnoTUIrKiXWVdVRlp66vDvQ2B558QigtXmk/edit?usp=sharing###Team,Please work on RCA###Hello Matthew,On further checking, from the system logs, we could see there was an issue with the network service during that time.Refer the system logs at the time of the issue below.Jan 15 11:12:40 ip-10-59-10-26 network: Bringing up interface eth0: ERROR : [/etc/sysconfig/network-scripts/ifup-eth] Device eth0 does not seem to be present, delaying initialization. Jan 15 11:12:40 ip-10-59-10-26 /etc/sysconfig/network-scripts/ifup-eth: Device eth0 does not seem to be present, delaying initialization. Jan 15 11:12:40 ip-10-59-10-26 network: [FAILED] Jan 15 11:12:40 ip-10-59-10-26 systemd: network.service: control process exited, code=exited status=1 Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed to start LSB: Bring up/down networking. Jan 15 11:12:40 ip-10-59-10-26 systemd: Unit network.service entered failed state. Jan 15 11:12:40 ip-10-59-10-26 systemd: network.service failed. Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Initial cloud-init job (metadata service crawler)... Jan 15 11:12:40 ip-10-59-10-26 systemd: Reached target Network. Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Network. Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Logout off all iSCSI sessions on shutdown... Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting /etc/rc.d/rc.local Compatibility... Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Login and scanning of iSCSI devices... Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting MariaDB Columnstore... Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed at step EXEC spawning /usr/local/mariadb/columnstore/bin/columnstore: No such file or directory Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Dynamic System Tuning Daemon... Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Agent. Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Agent... Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Process Agent. Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Process Agent... Jan 15 11:12:40 ip-10-59-10-26 iscsi-mark-root-nodes: iscsiadm: No active sessions. Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Trace Agent (APM). Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Trace Agent (APM)... Jan 15 11:12:40 ip-10-59-10-26 rc.local: % Total % Received % Xferd Average Speed Time Time Time Current Jan 15 11:12:40 ip-10-59-10-26 rc.local: Dload Upload Total Spent Left Speed Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Logout off all iSCSI sessions on shutdown. Jan 15 11:12:40 ip-10-59-10-26 systemd: columnstore.service: control process exited, code=exited status=203 Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed to start MariaDB Columnstore. Jan 15 11:12:40 ip-10-59-10-26 systemd: Unit columnstore.service entered failed state. Jan 15 11:12:40 ip-10-59-10-26 systemd: columnstore.service failed.Also, we have witnessed high network In in both of the machines during the time.After you have performed reboot on the machines, we could see the issue has been resolved.Kindly verify the details and let us know your thoughts regarding this.We will work on the RCA and will get back to you with an update.###System Logs at the time of the issue.Jan 15 11:12:40 ip-10-59-10-26 network: Bringing up interface eth0:  ERROR     : [/etc/sysconfig/network-scripts/ifup-eth] Device eth0 does not seem to be present, delaying initialization.Jan 15 11:12:40 ip-10-59-10-26 /etc/sysconfig/network-scripts/ifup-eth: Device eth0 does not seem to be present, delaying initialization.Jan 15 11:12:40 ip-10-59-10-26 network: [FAILED]Jan 15 11:12:40 ip-10-59-10-26 systemd: network.service: control process exited, code=exited status=1Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed to start LSB: Bring up/down networking.Jan 15 11:12:40 ip-10-59-10-26 systemd: Unit network.service entered failed state.Jan 15 11:12:40 ip-10-59-10-26 systemd: network.service failed.Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Initial cloud-init job (metadata service crawler)...Jan 15 11:12:40 ip-10-59-10-26 systemd: Reached target Network.Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Network.Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Logout off all iSCSI sessions on shutdown...Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting /etc/rc.d/rc.local Compatibility...Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Login and scanning of iSCSI devices...Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting MariaDB Columnstore...Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed at step EXEC spawning /usr/local/mariadb/columnstore/bin/columnstore: No such file or directoryJan 15 11:12:40 ip-10-59-10-26 systemd: Starting Dynamic System Tuning Daemon...Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Agent.Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Agent...Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Process Agent.Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Process Agent...Jan 15 11:12:40 ip-10-59-10-26 iscsi-mark-root-nodes: iscsiadm: No active sessions.Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Trace Agent (APM).Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Trace Agent (APM)...Jan 15 11:12:40 ip-10-59-10-26 rc.local: % Total    % Received % Xferd  Average Speed   Time    Time     Time  CurrentJan 15 11:12:40 ip-10-59-10-26 rc.local: Dload  Upload   Total   Spent    Left  SpeedJan 15 11:12:40 ip-10-59-10-26 systemd: Started Logout off all iSCSI sessions on shutdown.Jan 15 11:12:40 ip-10-59-10-26 systemd: columnstore.service: control process exited, code=exited status=203Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed to start MariaDB Columnstore.Jan 15 11:12:40 ip-10-59-10-26 systemd: Unit columnstore.service entered failed state.Jan 15 11:12:40 ip-10-59-10-26 systemd: columnstore.service failed.###Jan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=warning msg=unable to use upstart error=fork/exec /sbin/initctl: no such file or directoryJan 15 11:12:47 ip-10-59-10-26 systemd: Got automount request for /proc/sys/fs/binfmt_misc, triggered by 727 (newrelic-infra)Jan 15 11:12:47 ip-10-59-10-26 systemd: Mounting Arbitrary Executable File Formats File System...Jan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=warning msg=enabling 'semodule' may report performance issues in RedHat-based distributions plugin name=selinuxJan 15 11:12:47 ip-10-59-10-26 systemd: Mounted Arbitrary Executable File Formats File System.Jan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/all/stable_secret, skipping: read /proc/sys/net/ipv6/conf/all/stable_secret: input/output errorJan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/default/stable_secret, skipping: read /proc/sys/net/ipv6/conf/default/stable_secret: input/output errorJan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/ens5/stable_secret, skipping: read /proc/sys/net/ipv6/conf/ens5/stable_secret: input/output errorJan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/lo/stable_secret, skipping: read /proc/sys/net/ipv6/conf/lo/stable_secret: input/output errorJan 15 11:12:47 ip-10-59-10-26 kernel: ICMPv6: process `newrelic-infra' is using deprecated sysctl (syscall) net.ipv6.neigh.default.retrans_time - use net.ipv6.neigh.default.retrans_time_ms insteadan 15 11:02:50 ip-10-59-10-210 rc.local: % Total    % Received % Xferd  Average Speed   Time    Time     Time  CurrentJan 15 11:02:50 ip-10-59-10-210 rc.local: Dload  Upload   Total   Spent    Left  SpeedJan 15 11:02:50 ip-10-59-10-210 systemd: Started Logout off all iSCSI sessions on shutdown.Jan 15 11:02:50 ip-10-59-10-210 systemd: columnstore.service: control process exited, code=exited status=203Jan 15 11:02:50 ip-10-59-10-210 systemd: Failed to start MariaDB Columnstore.Jan 15 11:02:50 ip-10-59-10-210 systemd: Unit columnstore.service entered failed state.Jan 15 11:02:50 ip-10-59-10-210 systemd: columnstore.service failed.Jan 15 11:02:57 ip-10-59-10-210 newrelic-infra: time=2019-01-15T11:02:57Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/all/stable_secret, skipping: read /proc/sys/net/ipv6/conf/all/stable_secret: input/output errorJan 15 11:02:57 ip-10-59-10-210 newrelic-infra: time=2019-01-15T11:02:57Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/default/stable_secret, skipping: read /proc/sys/net/ipv6/conf/default/stable_secret: input/output errorJan 15 11:02:57 ip-10-59-10-210 newrelic-infra: time=2019-01-15T11:02:57Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/ens5/stable_secret, skipping: read /proc/sys/net/ipv6/conf/ens5/stable_secret: input/output errorJan 15 11:02:57 ip-10-59-10-210 newrelic-infra: time=2019-01-15T11:02:57Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/lo/stable_secret, skipping: read /proc/sys/net/ipv6/conf/lo/stable_secret: input/output errorJan 15 11:02:57 ip-10-59-10-210 kernel: ICMPv6: process `newrelic-infra' is using deprecated sysctl (syscall) net.ipv6.neigh.default.retrans_time - use net.ipv6.neigh.default.retrans_time_ms insteadRohit updated that he will reveiw the details and will update.###Sure.Let us look into it. We will update you the status.###It appeared to be a networking issue. Are you able to see why it happened? If not I can look into it. It was resolved through brute force by shutting down the machine.Matthew Watts | Manager, Application Development | SpendHQ®###Hello Matthew,Thanks for the update.We can see the port 8616 is listening on the machine.Could you please brief us what was the issue.###Matthew Watts <mwatts@spendhq.com>Today, 5:11 PMRean Support <support@reancloud.com>;spendhq - dfowlerI have resolved the issue. We are back up.###Hello Matthew,Let us know if we need to get on call to discuss this.###Hello Matthew,We have checked and from our side we are able to connect from 10.59.10.210 to 10.59.10.26.See the below ping output from 10.59.10.210:PING 10.59.10.26 (10.59.10.26) 56(84) bytes of data.64 bytes from 10.59.10.26: icmp_seq=1 ttl=64 time=0.194 ms64 bytes from 10.59.10.26: icmp_seq=2 ttl=64 time=0.193 ms64 bytes from 10.59.10.26: icmp_seq=3 ttl=64 time=0.163 ms64 bytes from 10.59.10.26: icmp_seq=4 ttl=64 time=0.156 ms64 bytes from 10.59.10.26: icmp_seq=5 ttl=64 time=0.146 ms--- 10.59.10.26 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4000msrtt min/avg/max/mdev = 0.146/0.170/0.194/0.022 msPlease let us know if you are still having the same issue.Thanks###[Matthew]Rean we are having connection issues from 10.59.10.210 to 10.59.10.26. Can you resolve asap.Matthew###Hello Matthew,The server is accessible. Please let us know if you need any assistance from our end for the DB access issue.###Matthew Watts <mwatts@spendhq.com>Today, 4:21 PMThe 10.59.10.210 server won’t start. Please reboot asap.###Matthew Watts <mwatts@spendhq.com>Today, 4:21 PMRean Support <support@reancloud.com>;spendhq-support@reancloud.comIgnore message. Took a while but it came back up###Hello Matthew,Thanks for the update.Please let us know if you need any assistance from our end.###﻿Please stand down. I will deal with this. Matthew Watts | Manager, Application Development | SpendHQ®###Hello Dusty,The instance is accessible and we are able to login to the machine.Also, we have checked the MySQL service is running on the machine.Could you please let us know the commands used for starting the DB service. Let us know if we can get on a call to check this further.###Thank you, what is the current status?###Hello Dusty,We are looking into this with urgency and will get back to you shortly.Thanks","Hello Rean,This is an urgent issue.  It seems the database located at 10.59.10.210 is offline.  Is somebody able to access the server and start the db service again?Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com<mailto:dfowler@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sev One - Production DB Offline,,15-01-2019 15:52,320,0,SpendHQ,"Hello Matthew, Just a quick email to see if there is an update on this case. Please review the analysis shared on this case and please let us know if you have any questions.In the mean time we will mark this case as closed. Please feel free to reopen it if you have any concerns.Thanks.",@Team:Do a final follow up and close this.,"@TeamSince we have done several followups already, please check with CC if we can close this case.","Hello Matthew, Just a quick email to see if there is an update on this case. Please review the analysis shared on this case and please let us know if you have any questions. Thank you.","Hello Matthew, We haven't heard back from you. The issue seems to be resolved, the Production DB went offline because of the ISCSI volume store MariaDB data went into read-only mode. Later a reboot performed by you resolved the issue.For now, we are reducing the priority of this ticket from P2 to P4. We will be looking forward to your response, please review the complete analysis shared here and let us know if you have any queries regarding it.","Hello Matthew,Just a quick email to see if there is an update on this case. Please review the analysis shared on this case and please let us know if you have any questions.Thank you.","Hello Matthew, We haven't heard back from you. Kindly review the shared analysis and let us know if you have any questions or concerns.As the issue is resolved we are downgrading the priority to P2","As per ops call update, we are downgrading the priority","Hello Matthew, We haven't heard back from you.Kindly review the shared analysis and let us know if you have any questions or concerns.","Hello Matthew, This is a quick followupKindly review the shared analysis and let us know if you have any questions or concerns. Thanks","Hello Matthew, We haven't heard back from you regarding this case. Kindly review the shared analysis and let us know if you have any questions or concerns. Thanks","Hello Matthew,We have further looked into this issue.Looking at the system logs before the issue has been reported we were able to figure out that the iscsi volume on which the MariaDB data is stored went to read only mode.Upon checking the mysqlmariadb-error.log, we could see that from 10 AM UTC we started receiving Errcode: 30 Read-only file system  error and it continued till the time a reboot has been performed on this instance. [root@ip-10-59-10-210 mysql]# cat mysqlmariadb-error.log | grep -i 2019-01-15 10:00:02019-01-15 10:00:00 140348329977984 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins2019-01-15 10:00:00 140348329977984 [Note] InnoDB: Uses event mutexes2019-01-15 10:00:00 140348329977984 [Note] InnoDB: Compressed tables use zlib 1.2.72019-01-15 10:00:00 140348329977984 [Note] InnoDB: Using Linux native AIO2019-01-15 10:00:00 140348329977984 [Note] InnoDB: Number of pools: 12019-01-15 10:00:00 140348329977984 [Note] InnoDB: Using SSE2 crc32 instructions2019-01-15 10:00:00 140348329977984 [ERROR] mysqld: Can't create/write to file '/usr/local/mariadb/columnstore/mysql/tmp/ibSNYxzD' (Errcode: 30 Read-only file system)2019-01-15 10:00:00 140348329977984 [ERROR] InnoDB: Unable to create temporary file; errno: 302019-01-15 10:00:00 140348329977984 [ERROR] mysqld: Can't create/write to file '/usr/local/mariadb/columnstore/mysql/tmp/ibHzCN73' (Errcode: 30 Read-only file system)2019-01-15 10:00:00 140348329977984 [ERROR] InnoDB: Unable to create temporary file; errno: 302019-01-15 10:00:00 140348329977984 [ERROR] InnoDB: Plugin initialization aborted with error Generic error2019-01-15 10:00:00 140348329977984 [Note] InnoDB: Starting shutdown...2019-01-15 10:00:00 140348329977984 [ERROR] Plugin 'InnoDB' init function returned error.2019-01-15 10:00:00 140348329977984 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed.2019-01-15 10:00:00 140348329977984 [ERROR] mysqld: File '/usr/local/mariadb/columnstore/mysql/db/aria_log_control' not found (Errcode: 30 Read-only file system)2019-01-15 10:00:00 140348329977984 [ERROR] mysqld: Got error 'Can't open file' when trying to use aria control file '/usr/local/mariadb/columnstore/mysql/db/aria_log_control'2019-01-15 10:00:00 140348329977984 [ERROR] Plugin 'Aria' init function returned error.2019-01-15 10:00:00 140348329977984 [ERROR] Plugin 'Aria' registration as a STORAGE ENGINE failed.[root@ip-10-59-10-210 mysql]# last reboot | less reboot system boot 3.10.0-862.11.6. Tue Jan 15 11:13 - 21:12 (09:58) reboot system boot 3.10.0-862.11.6. Tue Jan 15 11:02 - 21:12 (10:09) reboot system boot 3.10.0-862.11.6. Tue Jan 15 10:50 - 21:12 (10:21) As we could see that on 15th Jan, 3 times reboot was performed on this instance. The reboot which was performed at 10:50 UTC, then after the read-only mode error were gone and Mysql daemon got ready for connections after recovering from the crash which transaction changed 1 row. Later they performed another reboot while the buffer pool was getting loaded. Also, we have checked with AWS team and confirmed there was no network related issues during that time. We did not find any suspicious logs which can lead us to any networking issue on the connectivity between both the machines 10.59.10.210 and 10.59.10.26. Since this volume is managing by SpendHQ team, we are requesting you to check it on your end. Kindly verify the details and let us know if you have any queries.","@Team:We checked on this issue. We did not find any suspicious logs which can lead us to any networking issue on the connectivity between both the machines 10.59.10.210 and 10.59.10.26When we checked the mariadb error logs for the machine 10.59.10.210, we do can see that there was Errcode: 30 Read-only file system errors. There was no unusual on the other machine. The volume on which the mariadb data is stored is an iSCSI volume. But we have not notice any RO mode issue on the volume. This volume is taken care by SpendHQ team itself. They need to check at their end if there was any connectivity issue for this.  Please share the error logs for mariadb with the customer. Thanks !",Hello TeamWe are still working on the RCA. We will share RCA with you once it's completed.Thanks,"@Rohit I had gone on chat with the AWS and checked if there any issue with the AWS side regarding the connectivity. they mentioned there is no downtime at their part.They mentioned that the Error that we find in logs is after the reboot as the network interface was initializing.As per CP comment, we could see that the customer was trying to connect using the wrong username and later they had logged in using the centos user and the key.kindly review the CP comment for more details and provide an update.","@here I created a format for the RCA, please ask Rohit to review the analysis and based on that update the RCA.https://docs.google.com/document/d/1LWHBHsfX_rbue5vk0B24JweoViN2p5zAoTculJ-c1Tg/edit?usp=sharing","@Rohit, I further checked on this issue and here are findings:Dusty Fowler reports us issue at 10:22 am UTC. While checking the secure logs we can see that earlier they were trying with the incorrect user but during the same time they switched to centos user and logged into the server. Means there was not issue with the connectivity.https://docs.google.com/document/d/1Ii7whRukO8c9zI76BlT1g0XtFs3YTfIIO5XIWihKFvE/edit?usp=sharingUpon checking the mysqlmariadb-error.log, we could see that from 10 AM UTC we started receiving Errcode: 30 Read-only file system  error and it continued till the time a reboot has been performed on this instance.[root@ip-10-59-10-210 mysql]# last reboot | lessreboot   system boot  3.10.0-862.11.6. Tue Jan 15 11:13 - 21:12  (09:58)    reboot   system boot  3.10.0-862.11.6. Tue Jan 15 11:02 - 21:12  (10:09)    reboot   system boot  3.10.0-862.11.6. Tue Jan 15 10:50 - 21:12  (10:21)As we could see that on 15th Jan, 3 times reboot was performed on this instance. The reboot which was performed at 10:50 UTC, then after the read-only mode error were gone and Mysql daemon got ready for connections after recovering from the crash which transaction changed 1 row.2019-01-15 10:54:43 140219123579008 [Note] Starting crash recovery...2019-01-15 10:54:43 140219123579008 [Note] InnoDB: Starting recovery for XA transactions...2019-01-15 10:54:43 140219123579008 [Note] InnoDB: Transaction 378840786 in prepared state after recovery2019-01-15 10:54:43 140219123579008 [Note] InnoDB: Transaction contains changes to 1 rows2019-01-15 10:54:43 140219123579008 [Note] InnoDB: 1 transactions in prepared state after recovery2019-01-15 10:54:43 140219123579008 [Note] Found 1 prepared transaction(s) in InnoDB2019-01-15 10:54:43 140219123579008 [Note] Crash recovery finished.2019-01-15 10:54:43 140219035903744 [Warning] InnoDB: Table mysql/innodb_table_stats has length mismatch in the column name table_name.  Please run mysql_upgrade2019-01-15 10:54:43 140219035903744 [Warning] InnoDB: Table mysql/innodb_index_stats has length mismatch in the column name table_name.  Please run mysql_upgrade2019-01-15 10:54:43 140219123579008 [Note] Server socket created on IP: '::'.2019-01-15 10:54:43 140219123579008 [ERROR] mysqld: Incorrect information in file: '/usr/local/mariadb/columnstore/mysql/tmp/#sqlaa5c_441b67_3.frm'2019-01-15 10:54:43 140219123579008 [Note] Reading of all Master_info entries succeded2019-01-15 10:54:43 140219123579008 [Note] Added new Master_info '' to hash table2019-01-15 10:54:43 140219123579008 [Note] /usr/local/mariadb/columnstore/mysql//bin/mysqld: ready for connections.Later they performed another reboot while the buffer pool was getting loaded. 2019-01-15 10:55:33 140129009088256 [Warning] InnoDB: Table mysql/innodb_index_stats has length mismatch in the column name table_name.  Please run mysql_upgrade2019-01-15 10:58:52 140130144741120 [Note] InnoDB: Buffer pool(s) load completed at 190115 10:58:522019-01-15 10:59:40 140130088302336 [Note] /usr/local/mariadb/columnstore/mysql//bin/mysqld (initiated by: unknown): Normal shutdown2019-01-15 10:59:45 140130088302336 [Note] InnoDB: Shutdown completed; log sequence number 83058018504962019-01-15 10:59:45 140130088302336 [Note] /usr/local/mariadb/columnstore/mysql//bin/mysqld: Shutdown complete2019-01-15 10:59:47 140387927427200 [Note] InnoDB: Initializing buffer pool, total size = 79G, instances = 8, chunk size = 128MPlease find the complete logs with the description in the sheet and let us know the next action :https://docs.google.com/document/d/1r6S39gxbxnoTUIrKiXWVdVRlp66vDvQ2B558QigtXmk/edit?usp=sharing","Team,Please work on RCA","Hello Matthew,On further checking, from the system logs, we could see there was an issue with the network service during that time.Refer the system logs at the time of the issue below.Jan 15 11:12:40 ip-10-59-10-26 network: Bringing up interface eth0: ERROR : [/etc/sysconfig/network-scripts/ifup-eth] Device eth0 does not seem to be present, delaying initialization. Jan 15 11:12:40 ip-10-59-10-26 /etc/sysconfig/network-scripts/ifup-eth: Device eth0 does not seem to be present, delaying initialization. Jan 15 11:12:40 ip-10-59-10-26 network: [FAILED] Jan 15 11:12:40 ip-10-59-10-26 systemd: network.service: control process exited, code=exited status=1 Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed to start LSB: Bring up/down networking. Jan 15 11:12:40 ip-10-59-10-26 systemd: Unit network.service entered failed state. Jan 15 11:12:40 ip-10-59-10-26 systemd: network.service failed. Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Initial cloud-init job (metadata service crawler)... Jan 15 11:12:40 ip-10-59-10-26 systemd: Reached target Network. Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Network. Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Logout off all iSCSI sessions on shutdown... Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting /etc/rc.d/rc.local Compatibility... Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Login and scanning of iSCSI devices... Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting MariaDB Columnstore... Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed at step EXEC spawning /usr/local/mariadb/columnstore/bin/columnstore: No such file or directory Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Dynamic System Tuning Daemon... Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Agent. Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Agent... Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Process Agent. Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Process Agent... Jan 15 11:12:40 ip-10-59-10-26 iscsi-mark-root-nodes: iscsiadm: No active sessions. Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Trace Agent (APM). Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Trace Agent (APM)... Jan 15 11:12:40 ip-10-59-10-26 rc.local: % Total % Received % Xferd Average Speed Time Time Time Current Jan 15 11:12:40 ip-10-59-10-26 rc.local: Dload Upload Total Spent Left Speed Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Logout off all iSCSI sessions on shutdown. Jan 15 11:12:40 ip-10-59-10-26 systemd: columnstore.service: control process exited, code=exited status=203 Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed to start MariaDB Columnstore. Jan 15 11:12:40 ip-10-59-10-26 systemd: Unit columnstore.service entered failed state. Jan 15 11:12:40 ip-10-59-10-26 systemd: columnstore.service failed.Also, we have witnessed high network In in both of the machines during the time.After you have performed reboot on the machines, we could see the issue has been resolved.Kindly verify the details and let us know your thoughts regarding this.We will work on the RCA and will get back to you with an update.","System Logs at the time of the issue.Jan 15 11:12:40 ip-10-59-10-26 network: Bringing up interface eth0:  ERROR     : [/etc/sysconfig/network-scripts/ifup-eth] Device eth0 does not seem to be present, delaying initialization.Jan 15 11:12:40 ip-10-59-10-26 /etc/sysconfig/network-scripts/ifup-eth: Device eth0 does not seem to be present, delaying initialization.Jan 15 11:12:40 ip-10-59-10-26 network: [FAILED]Jan 15 11:12:40 ip-10-59-10-26 systemd: network.service: control process exited, code=exited status=1Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed to start LSB: Bring up/down networking.Jan 15 11:12:40 ip-10-59-10-26 systemd: Unit network.service entered failed state.Jan 15 11:12:40 ip-10-59-10-26 systemd: network.service failed.Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Initial cloud-init job (metadata service crawler)...Jan 15 11:12:40 ip-10-59-10-26 systemd: Reached target Network.Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Network.Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Logout off all iSCSI sessions on shutdown...Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting /etc/rc.d/rc.local Compatibility...Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Login and scanning of iSCSI devices...Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting MariaDB Columnstore...Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed at step EXEC spawning /usr/local/mariadb/columnstore/bin/columnstore: No such file or directoryJan 15 11:12:40 ip-10-59-10-26 systemd: Starting Dynamic System Tuning Daemon...Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Agent.Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Agent...Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Process Agent.Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Process Agent...Jan 15 11:12:40 ip-10-59-10-26 iscsi-mark-root-nodes: iscsiadm: No active sessions.Jan 15 11:12:40 ip-10-59-10-26 systemd: Started Datadog Trace Agent (APM).Jan 15 11:12:40 ip-10-59-10-26 systemd: Starting Datadog Trace Agent (APM)...Jan 15 11:12:40 ip-10-59-10-26 rc.local: % Total    % Received % Xferd  Average Speed   Time    Time     Time  CurrentJan 15 11:12:40 ip-10-59-10-26 rc.local: Dload  Upload   Total   Spent    Left  SpeedJan 15 11:12:40 ip-10-59-10-26 systemd: Started Logout off all iSCSI sessions on shutdown.Jan 15 11:12:40 ip-10-59-10-26 systemd: columnstore.service: control process exited, code=exited status=203Jan 15 11:12:40 ip-10-59-10-26 systemd: Failed to start MariaDB Columnstore.Jan 15 11:12:40 ip-10-59-10-26 systemd: Unit columnstore.service entered failed state.Jan 15 11:12:40 ip-10-59-10-26 systemd: columnstore.service failed.","Jan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=warning msg=unable to use upstart error=fork/exec /sbin/initctl: no such file or directoryJan 15 11:12:47 ip-10-59-10-26 systemd: Got automount request for /proc/sys/fs/binfmt_misc, triggered by 727 (newrelic-infra)Jan 15 11:12:47 ip-10-59-10-26 systemd: Mounting Arbitrary Executable File Formats File System...Jan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=warning msg=enabling 'semodule' may report performance issues in RedHat-based distributions plugin name=selinuxJan 15 11:12:47 ip-10-59-10-26 systemd: Mounted Arbitrary Executable File Formats File System.Jan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/all/stable_secret, skipping: read /proc/sys/net/ipv6/conf/all/stable_secret: input/output errorJan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/default/stable_secret, skipping: read /proc/sys/net/ipv6/conf/default/stable_secret: input/output errorJan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/ens5/stable_secret, skipping: read /proc/sys/net/ipv6/conf/ens5/stable_secret: input/output errorJan 15 11:12:47 ip-10-59-10-26 newrelic-infra: time=2019-01-15T11:12:47Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/lo/stable_secret, skipping: read /proc/sys/net/ipv6/conf/lo/stable_secret: input/output errorJan 15 11:12:47 ip-10-59-10-26 kernel: ICMPv6: process `newrelic-infra' is using deprecated sysctl (syscall) net.ipv6.neigh.default.retrans_time - use net.ipv6.neigh.default.retrans_time_ms insteadan 15 11:02:50 ip-10-59-10-210 rc.local: % Total    % Received % Xferd  Average Speed   Time    Time     Time  CurrentJan 15 11:02:50 ip-10-59-10-210 rc.local: Dload  Upload   Total   Spent    Left  SpeedJan 15 11:02:50 ip-10-59-10-210 systemd: Started Logout off all iSCSI sessions on shutdown.Jan 15 11:02:50 ip-10-59-10-210 systemd: columnstore.service: control process exited, code=exited status=203Jan 15 11:02:50 ip-10-59-10-210 systemd: Failed to start MariaDB Columnstore.Jan 15 11:02:50 ip-10-59-10-210 systemd: Unit columnstore.service entered failed state.Jan 15 11:02:50 ip-10-59-10-210 systemd: columnstore.service failed.Jan 15 11:02:57 ip-10-59-10-210 newrelic-infra: time=2019-01-15T11:02:57Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/all/stable_secret, skipping: read /proc/sys/net/ipv6/conf/all/stable_secret: input/output errorJan 15 11:02:57 ip-10-59-10-210 newrelic-infra: time=2019-01-15T11:02:57Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/default/stable_secret, skipping: read /proc/sys/net/ipv6/conf/default/stable_secret: input/output errorJan 15 11:02:57 ip-10-59-10-210 newrelic-infra: time=2019-01-15T11:02:57Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/ens5/stable_secret, skipping: read /proc/sys/net/ipv6/conf/ens5/stable_secret: input/output errorJan 15 11:02:57 ip-10-59-10-210 newrelic-infra: time=2019-01-15T11:02:57Z level=error msg=Unable to read sysctl from /proc/sys/net/ipv6/conf/lo/stable_secret, skipping: read /proc/sys/net/ipv6/conf/lo/stable_secret: input/output errorJan 15 11:02:57 ip-10-59-10-210 kernel: ICMPv6: process `newrelic-infra' is using deprecated sysctl (syscall) net.ipv6.neigh.default.retrans_time - use net.ipv6.neigh.default.retrans_time_ms insteadRohit updated that he will reveiw the details and will update.",Sure.Let us look into it. We will update you the status.,"It appeared to be a networking issue. Are you able to see why it happened? If not I can look into it. It was resolved through brute force by shutting down the machine.Matthew Watts | Manager, Application Development | SpendHQ®","Hello Matthew,Thanks for the update.We can see the port 8616 is listening on the machine.Could you please brief us what was the issue.","Matthew Watts <mwatts@spendhq.com>Today, 5:11 PMRean Support <support@reancloud.com>;spendhq - dfowlerI have resolved the issue. We are back up.","Hello Matthew,Let us know if we need to get on call to discuss this.","Hello Matthew,We have checked and from our side we are able to connect from 10.59.10.210 to 10.59.10.26.See the below ping output from 10.59.10.210:PING 10.59.10.26 (10.59.10.26) 56(84) bytes of data.64 bytes from 10.59.10.26: icmp_seq=1 ttl=64 time=0.194 ms64 bytes from 10.59.10.26: icmp_seq=2 ttl=64 time=0.193 ms64 bytes from 10.59.10.26: icmp_seq=3 ttl=64 time=0.163 ms64 bytes from 10.59.10.26: icmp_seq=4 ttl=64 time=0.156 ms64 bytes from 10.59.10.26: icmp_seq=5 ttl=64 time=0.146 ms--- 10.59.10.26 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4000msrtt min/avg/max/mdev = 0.146/0.170/0.194/0.022 msPlease let us know if you are still having the same issue.Thanks",[Matthew]Rean we are having connection issues from 10.59.10.210 to 10.59.10.26. Can you resolve asap.Matthew,"Hello Matthew,The server is accessible. Please let us know if you need any assistance from our end for the DB access issue.","Matthew Watts <mwatts@spendhq.com>Today, 4:21 PMThe 10.59.10.210 server won’t start. Please reboot asap.","Matthew Watts <mwatts@spendhq.com>Today, 4:21 PMRean Support <support@reancloud.com>;spendhq-support@reancloud.comIgnore message. Took a while but it came back up","Hello Matthew,Thanks for the update.Please let us know if you need any assistance from our end.","﻿Please stand down. I will deal with this. Matthew Watts | Manager, Application Development | SpendHQ®","Hello Dusty,The instance is accessible and we are able to login to the machine.Also, we have checked the MySQL service is running on the machine.Could you please let us know the commands used for starting the DB service. Let us know if we can get on a call to check this further.","Thank you, what is the current status?","Hello Dusty,We are looking into this with urgency and will get back to you shortly.Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016qL6H,Cloud Engineer Level 1,Closed,1042528,Incident,,,,"Can you guys set that up and send it over please.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]Sent: Monday, January 23, 2017 2:37 PMTo: Matthew Watts <mwatts@spendhq.com>Cc: REAN Support <support@reancloud.com>Subject: Re: MeetingHello Matthew,We will be available today at 1600 hours EST for the discussion.Please let us know the Bridge details before the meeting.On Fri, Jan 20, 2017 at 1:55 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Rean Team,Can we please meet for 30 minutes on Monday 22nd January at 1600 Hours to go over the Load Balancing Solution for the upcoming release.Thank you.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Meeting,,24-01-2017 01:07,0,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FdJWz,Cloud Engineer Level 1,Closed,1072839,Incident,11-08-2017 07:14,,"Hello SpendHQ-Team,This is to inform you that we have received a site down alert for the URL: https://secure.spendhq.com/login. The alert got resolved within 3 minutes and the site is up and loading fine.At the time of the alert, we could see a high spike in Network inbound traffic on the DB server. As per the call with Andrew, we are making this case as resolved since this network traffic was caused by internal processes. Please let us know if you have any queries.","Thu, 10 Aug 2017 21:12:25 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30003 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): London UK, California US, Atlanta-B US, Dallas-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,11-08-2017 06:42,1,0,SpendHQ,"Hello SpendHQ-Team,This is to inform you that we have received a site down alert for the URL: https://secure.spendhq.com/login. The alert got resolved within 3 minutes and the site is up and loading fine.At the time of the alert, we could see a high spike in Network inbound traffic on the DB server. As per the call with Andrew, we are making this case as resolved since this network traffic was caused by internal processes. Please let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TmYtu,Cloud Engineer Level 1,Closed,1094642,Incident,04-04-2018 01:02,,"Hello Andrew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###We believe this may be from a monitoring service. Please do not block. Thank you.###Hello Team,We haven't heard back from you.Please validate the intrusion Prevention Alert (Packet dropped) details and let us know if we have your approval to block this IP address from the subnet NACL.Revert back to us for any queries.###Hello Team,Please validate the intrusion Prevention Alert (Packet dropped) details and let us know if we have your approval to block this IP address from the subnet NACL. Revert back to us for any queries.###Hello SpendHQ-Team,This is to inform you that we have received an Intrusion Prevention Alert (Packet dropped), we have analyzed the same and below are the findings.Name: Intrusion protection alertAction: drop,Reason: SERVER-ORACLE Oracle WebLogic Server remote command execution attempt,Class: Attempted Administrator Privilege Gain,Source IP Destination IP Port Mapping:10.59.0.218:36547 ==> 10.59.1.192:8010.59.1.97:44191 ==> 10.59.1.192:8010.59.0.77:45762 ==> 10.59.1.192:8010.59.1.246:8348 ==> 10.59.1.192:80Please find the source IP to ELB mapping here which includes non monitoring resources as well.10.59.0.218 - capfiles-spendhq-xelb - Access Logs not enabled. - Not Under Contract.10.59.1.97 - SpendHQ-CAT-MapD-xELB - Access Logs not enabled. - Not Under Contract.10.59.0.77 - Preview-api-spendhq-com - Access Logs enabled. - Not Under Contract.10.59.1.246 - Secure-SpendHQ-ELB - Access Logs enabled. - Under Contract.Please find the associated logs below:2018:03:30-02:30:22 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.218 dstip=10.59.1.192 proto=6 srcport=36547 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02018:03:30-04:15:06 spendhq snort[23832]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.97 dstip=10.59.1.192 proto=6 srcport=44191 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02018:03:30-07:04:18 spendhq snort[23832]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.77 dstip=10.59.1.192 proto=6 srcport=45762 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02018:03:30-08:13:30 spendhq snort[23832]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.246 dstip=10.59.1.192 proto=6 srcport=8348 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0By analyzing the ELB Secure-SpendHQ-ELB access logs, we were able to track down the requester public IP. Please find the details below.IP Address: 54.228.16.35Country: IrelandRegion: DublinPlease find these details and let us know if we have your approval to block this IP address from the subnet NACL. Feel free to reach us for any queries.Thank You,Safuvan KM","Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-ORACLE Oracle WebLogic Server remote commandexecution attemptDetails........: https://www.snort.org/search?query=45304Time...........: 2018-03-30 02:30:22Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.0.218Source port: 36547Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 94 days 19 hours 27 minutesSystem Load        : 0.15System Version     : Sophos UTM 9.506-2Please refer to the manual for detailed instructions.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,30-03-2018 14:40,106,0,SpendHQ,"Hello Andrew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.",We believe this may be from a monitoring service. Please do not block. Thank you.,"Hello Team,We haven't heard back from you.Please validate the intrusion Prevention Alert (Packet dropped) details and let us know if we have your approval to block this IP address from the subnet NACL.Revert back to us for any queries.","Hello Team,Please validate the intrusion Prevention Alert (Packet dropped) details and let us know if we have your approval to block this IP address from the subnet NACL. Revert back to us for any queries.","Hello SpendHQ-Team,This is to inform you that we have received an Intrusion Prevention Alert (Packet dropped), we have analyzed the same and below are the findings.Name: Intrusion protection alertAction: drop,Reason: SERVER-ORACLE Oracle WebLogic Server remote command execution attempt,Class: Attempted Administrator Privilege Gain,Source IP Destination IP Port Mapping:10.59.0.218:36547 ==> 10.59.1.192:8010.59.1.97:44191 ==> 10.59.1.192:8010.59.0.77:45762 ==> 10.59.1.192:8010.59.1.246:8348 ==> 10.59.1.192:80Please find the source IP to ELB mapping here which includes non monitoring resources as well.10.59.0.218 - capfiles-spendhq-xelb - Access Logs not enabled. - Not Under Contract.10.59.1.97 - SpendHQ-CAT-MapD-xELB - Access Logs not enabled. - Not Under Contract.10.59.0.77 - Preview-api-spendhq-com - Access Logs enabled. - Not Under Contract.10.59.1.246 - Secure-SpendHQ-ELB - Access Logs enabled. - Under Contract.Please find the associated logs below:2018:03:30-02:30:22 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.218 dstip=10.59.1.192 proto=6 srcport=36547 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02018:03:30-04:15:06 spendhq snort[23832]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.97 dstip=10.59.1.192 proto=6 srcport=44191 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02018:03:30-07:04:18 spendhq snort[23832]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.77 dstip=10.59.1.192 proto=6 srcport=45762 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02018:03:30-08:13:30 spendhq snort[23832]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.246 dstip=10.59.1.192 proto=6 srcport=8348 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0By analyzing the ELB Secure-SpendHQ-ELB access logs, we were able to track down the requester public IP. Please find the details below.IP Address: 54.228.16.35Country: IrelandRegion: DublinPlease find these details and let us know if we have your approval to block this IP address from the subnet NACL. Feel free to reach us for any queries.Thank You,Safuvan KM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001U9OKS,IT Management,Closed,1094932,Incident,11-04-2018 15:13,,"No response from the customer. Hence closing this case###As updated by Vinod I have assigned the ticket with him###Hello Matthew, We haven't heard back from you, Please review the previous comment and let us know if you are still facing the issues.###Hello Matthew, We haven't heard back from you,Please review the previous comment and let us know if you are still facing the issues.###Hello Matthew,Yes it is not giving 200 Response. See the below screenshot for your reference.Regards,-Praveen###Hello Matthew,We have checked URL: https://api.spendhq.com and it returned a response code 500. Please verify this from your end and let us know if you have any further queries.###Let me review and get back to you on that. Does the endpoint not return a 200 statusMatthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com###Hello Matt, Kindly review the below comments. We have done a quick analysis and see that app is working fine for your API calls as per file: /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-api.spendhq.com-access.log log file on both the servers. But the homepage URL throwing an Error. Is there any full URL where we can use to get the health of the api.spendhq.com Portal.###﻿Hello Matt, Kindly review the below comments.We have done a quick analysis and see that app is working fine for your API calls as per file: /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-api.spendhq.com-access.log log file on both the servers. But the homepage URL throwing an Error. Is there any full URL where we can use to get the health of the api.spendhq.com Portal.###As updated by Rohit reducing teh priority of the ticket to P2.###﻿Hello Matt, We have done a quick analysis and see that app is working fine for your API calls as per file: /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-api.spendhq.com-access.log log file on both the servers. But the homepage URL throwing an Error. Is there any full URL where we can use to get the health of the api.spendhq.com Portal. Regards,-Praveen###Matthew Watts2:14 AM (0 minutes ago)to Praveen, spendhq-support We have two servers behind that. Can you identify what server###Hell Matt,But right now, api.spendhq.com is throwing an Error. Is this an expected behavior as you are doing something with it.Regards,-Praveen###Matthew Watts1:23 AM (0 minutes ago)to Praveen, spendhq-support I was trying to log in with the password you gave me however it didn’t work. Can you validate the password and then send me it once done###Hello Matthew,We didn't understand your comment. Are you doing some activity where you want us to ignore this issue for now. Or do you want us to rectify this.Regards,-Praveen###Matthew Watts12:13 AM (3 minutes ago)to Rean, spendhq-support This was me trying to access the serverMatthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Group###Hello Team,From our initial analysis, we found that there is some issue with the ISCSI. Please find the below mentioned system logs error.Apr  3 18:01:45 ip-10-59-100-78 iscsid: Kernel reported iSCSI connection 20:0 er                                                         ror (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Apr  3 18:01:48 ip-10-59-100-78 kernel: connection20:0: detected conn error (102                                                         0)Apr  3 18:01:48 ip-10-59-100-78 iscsid: Kernel reported iSCSI connection 20:0 er                                                         ror (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Apr  3 18:01:52 ip-10-59-100-78 kernel: connection20:0: detected conn error (102                                                         0)Apr  3 18:01:52 ip-10-59-100-78 iscsid: Kernel reported iSCSI connection 20:0 er                                                         ror (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Apr  3 18:01:55 ip-10-59-100-78 kernel: connection20:0: detected conn error (102                                                         0)Apr  3 18:01:55 ip-10-59-100-78 iscsid: Kernel reported iSCSI connection 20:0 er                                                         ror (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Apr  3 18:01:59 ip-10-59-100-78 kernel: connection20:0: detected conn error (102                                                         0)We are analyzing more on this issue meanwhile please let us know if it is a known activity performing on your end###Hello Team,This is to notify that we have received a site-down alert for the URL:- https://api.spendhq.comWe are analyzing the issue, Meanwhile please let us know if it is a known activity performing on your end","Tue, 03 Apr 2018 12:32:56 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 59 seconds https://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Sensor parameters:url: https://api.spendhq.comexpect: 200wantedstring: unwantedstring: Reported by node: Atlanta-B USConfirmed by node(s): London UK, New Jersey US, California US, Frankfurt DE--  <http://go.reancloud.com/public-sector-events>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,03-04-2018 22:03,185,0,SpendHQ,No response from the customer. Hence closing this case,As updated by Vinod I have assigned the ticket with him,"Hello Matthew, We haven't heard back from you, Please review the previous comment and let us know if you are still facing the issues.","Hello Matthew, We haven't heard back from you,Please review the previous comment and let us know if you are still facing the issues.","Hello Matthew,Yes it is not giving 200 Response. See the below screenshot for your reference.Regards,-Praveen","Hello Matthew,We have checked URL: https://api.spendhq.com and it returned a response code 500. Please verify this from your end and let us know if you have any further queries.","Let me review and get back to you on that. Does the endpoint not return a 200 statusMatthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com","Hello Matt, Kindly review the below comments. We have done a quick analysis and see that app is working fine for your API calls as per file: /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-api.spendhq.com-access.log log file on both the servers. But the homepage URL throwing an Error. Is there any full URL where we can use to get the health of the api.spendhq.com Portal.","﻿Hello Matt, Kindly review the below comments.We have done a quick analysis and see that app is working fine for your API calls as per file: /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-api.spendhq.com-access.log log file on both the servers. But the homepage URL throwing an Error. Is there any full URL where we can use to get the health of the api.spendhq.com Portal.",As updated by Rohit reducing teh priority of the ticket to P2.,"﻿Hello Matt, We have done a quick analysis and see that app is working fine for your API calls as per file: /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-api.spendhq.com-access.log log file on both the servers. But the homepage URL throwing an Error. Is there any full URL where we can use to get the health of the api.spendhq.com Portal. Regards,-Praveen","Matthew Watts2:14 AM (0 minutes ago)to Praveen, spendhq-support We have two servers behind that. Can you identify what server","Hell Matt,But right now, api.spendhq.com is throwing an Error. Is this an expected behavior as you are doing something with it.Regards,-Praveen","Matthew Watts1:23 AM (0 minutes ago)to Praveen, spendhq-support I was trying to log in with the password you gave me however it didn’t work. Can you validate the password and then send me it once done","Hello Matthew,We didn't understand your comment. Are you doing some activity where you want us to ignore this issue for now. Or do you want us to rectify this.Regards,-Praveen","Matthew Watts12:13 AM (3 minutes ago)to Rean, spendhq-support This was me trying to access the serverMatthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Group","Hello Team,From our initial analysis, we found that there is some issue with the ISCSI. Please find the below mentioned system logs error.Apr  3 18:01:45 ip-10-59-100-78 iscsid: Kernel reported iSCSI connection 20:0 er                                                         ror (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Apr  3 18:01:48 ip-10-59-100-78 kernel: connection20:0: detected conn error (102                                                         0)Apr  3 18:01:48 ip-10-59-100-78 iscsid: Kernel reported iSCSI connection 20:0 er                                                         ror (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Apr  3 18:01:52 ip-10-59-100-78 kernel: connection20:0: detected conn error (102                                                         0)Apr  3 18:01:52 ip-10-59-100-78 iscsid: Kernel reported iSCSI connection 20:0 er                                                         ror (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Apr  3 18:01:55 ip-10-59-100-78 kernel: connection20:0: detected conn error (102                                                         0)Apr  3 18:01:55 ip-10-59-100-78 iscsid: Kernel reported iSCSI connection 20:0 er                                                         ror (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Apr  3 18:01:59 ip-10-59-100-78 kernel: connection20:0: detected conn error (102                                                         0)We are analyzing more on this issue meanwhile please let us know if it is a known activity performing on your end","Hello Team,This is to notify that we have received a site-down alert for the URL:- https://api.spendhq.comWe are analyzing the issue, Meanwhile please let us know if it is a known activity performing on your end",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ErS6x,Cloud Engineer Level 1,Closed,1068844,Incident,19-07-2017 23:38,,"Hello SpendHQ-Team,This is to inform you that we have received multiple alerts regarding the  MySQL Process is down - prod-sphq-db-server05 - 10.59.10.135 - db. The number of processes was found less than 5 for prod-sphq-db-server05. Later the alert got resolved and returned to normal and violation lasted for 2 minutes. Please let us know if you are performing any activities from your end.Resource Details:name:prod-sphq-db-server05Instance ID : i-008d43ad00357e47aPrivate IP:10.59.10.135Instance Availability Zone : us-east-1bInstance Type : r3.8xlargeVPC ID : vpc-76df7212Subnet ID : subnet-0fdde924","[Triggered on {host:10.59.10.135,process:mysql}] [SpendHQ] MySQL Process is down - prod-sphq-db-server05  - 10.59.10.135 - db  MySQL Process is down @support@reancloud.com     @support@reancloud.comPROCS CRITICAL: 0 processes found for mysqlThis alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2014430?group=host%3A10.59.10.135%2Cprocess%3Amysql · Edit Monitor: https://app.datadoghq.com/monitors#2014430/edit · Event URL: https://app.datadoghq.com/event/event?id=3963181058945956255 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","[Monitor Alert] Triggered: [SpendHQ] MySQL Process is down - prod-sphq-db-server05 - 10.59.10.135 - db on process:mysql,host:10.59.10.135",,19-07-2017 23:24,4,0,SpendHQ,"Hello SpendHQ-Team,This is to inform you that we have received multiple alerts regarding the  MySQL Process is down - prod-sphq-db-server05 - 10.59.10.135 - db. The number of processes was found less than 5 for prod-sphq-db-server05. Later the alert got resolved and returned to normal and violation lasted for 2 minutes. Please let us know if you are performing any activities from your end.Resource Details:name:prod-sphq-db-server05Instance ID : i-008d43ad00357e47aPrivate IP:10.59.10.135Instance Availability Zone : us-east-1bInstance Type : r3.8xlargeVPC ID : vpc-76df7212Subnet ID : subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d4VdB,Cloud Engineer Level 1,Closed,1106426,Incident,18-10-2018 19:27,,"Hello Allen,Thanks for the update.As you confirmed it's due to expired license on Database.At this time we are marking this case as closed and let us know if you have any queries.###Allen Herrera <aherrera@spendhq.com>7:23 PM (2 minutes ago)to Rean, spendhq-support@reancloud.comWe have confirmed that the issue is with expired licenses on our database. We are handling everything on our end.###Allen Herrera7:23 PM (2 minutes ago)to Rean, spendhq-support We have confirmed that the issue is with expired licenses on our database. We are handling everything on our end. Allen Herrera | Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###We have encountered a P1 issue. Below are the details of the issueCustomer Name: SpendhqOpen date/time: 06:54 PM ISTIssue summary/Details: https://secure.spendhq.com/loginOwner: Anu PappachanStatus: In ProgressAction/s Taken: Currently checking the instance level logs###Hi Team,This is to notify that we have received site down alert on URL: https://secure.spendhq.com/login.We are working on the issue and let you know the updates.","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Thu, Oct 18, 2018 at 6:54 PMSubject: Detected Error on SpendHQ SecureTo: <ms@reancloud.com>Thu, 18 Oct 2018 09:24:49 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, Frankfurt DE, London UK, Dallas-B US--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Secure,,18-10-2018 18:55,1,0,SpendHQ,"Hello Allen,Thanks for the update.As you confirmed it's due to expired license on Database.At this time we are marking this case as closed and let us know if you have any queries.","Allen Herrera <aherrera@spendhq.com>7:23 PM (2 minutes ago)to Rean, spendhq-support@reancloud.comWe have confirmed that the issue is with expired licenses on our database. We are handling everything on our end.","Allen Herrera7:23 PM (2 minutes ago)to Rean, spendhq-support We have confirmed that the issue is with expired licenses on our database. We are handling everything on our end. Allen Herrera | Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com",We have encountered a P1 issue. Below are the details of the issueCustomer Name: SpendhqOpen date/time: 06:54 PM ISTIssue summary/Details: https://secure.spendhq.com/loginOwner: Anu PappachanStatus: In ProgressAction/s Taken: Currently checking the instance level logs,"Hi Team,This is to notify that we have received site down alert on URL: https://secure.spendhq.com/login.We are working on the issue and let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001lSozM,Cloud Engineer Level 1,Closed,1113352,Incident,15-03-2019 05:22,,"Hello Team,This is to inform you that the alert regarding the EBS High Disk Usage on /dev/xvda1 volume on prd-sv1 (10.59.100.193 )  got resolved and the current value reached to 55.2% and the violation lasted for  13 hours. At this time we are marking the case as resolved. Please revert back to us if you have any concerns.###Hello Team,The alert is still in open statePlease zip or remove the unwanted files to resolve this issue and let us know if you need any assistance on this case. Thanks###Hello Team,Please find the breakdown details on the instance prd-sv1(10.59.100.193). Please zip or remove the unwanted files to resolve this issue and let us know if you need any assistance on this case.##=======##======####=======##======###Disk usage as per Directories in /var==>>2.9G    www534M    log527M    lib377M    tmp130M    cache15M     spool880K    db116K    run16K     lock8.0K    empty##=======##======####=======##======####You are in the /var/cache directory==>>128M    yum2.0M    man24K     ldconfig12K     rpcbind8.0K    fontconfig4.0K    php-pear4.0K    mod_ssl4.0K    mod_proxy##=======##======####=======##======####You are in the /var/crash directory==>>Seems like /var/crash is empty!##=======##======####=======##======####You are in the /var/db directory==>>548K    newrelic-infra328K    sudo##=======##======####=======##======####You are in the /var/empty directory==>>4.0K    sshd##=======##======####=======##======####You are in the /var/games directory==>>Seems like /var/games is empty!##=======##======####=======##======####You are in the /var/lib directory==>>405M    clamav67M     rpm45M     amazon8.0M    yum868K    cloud676K    pear624K    iscsi140K    alternatives40K     sepolgen28K     nfs##=======##======####=======##======####You are in the /var/local directory==>>Seems like /var/local is empty!##=======##======####=======##======####You are in the /var/lock directory==>>4.0K    subsys4.0K    iscsi4.0K    iptraf0       kdump##=======##======####=======##======####You are in the /var/log directory==>>200M    file_monitor.log152M    datadog94M     amazon26M     audit20M     sa20M     newrelic5.3M    messages-20180513.gz2.4M    cron-201903102.4M    cron-201903032.4M    cron-20190224##=======##======####=======##======####You are in the /var/nis directory==>>Seems like /var/nis is empty!##=======##======####=======##======####You are in the /var/opt directory==>>Seems like /var/opt is empty!##=======##======####=======##======####You are in the /var/preserve directory==>>Seems like /var/preserve is empty!##=======##======####=======##======####You are in the /var/run directory==>>8.0K    screen8.0K    newrelic8.0K    httpd8.0K    clamav4.0K    utmp4.0K    syslogd.pid4.0K    sshd.pid4.0K    sm-notify.pid4.0K    setrans4.0K    sepermit##=======##======####=======##======####You are in the /var/spool directory==>>15M     mail200K    postfix16K     anacron8.0K    plymouth8.0K    cron4.0K    lpd##=======##======####=======##======####You are in the /var/tmp directory==>>91M     yum-sng-_8DLIG78M     yum-reanro-991xMl72M     shq-logs66M     yum-aherrera-9Eg3N560M     yum-mwatts-PnLKnb13M     yum-root-VWvI4w12K     monitor.php4.0K    yum-dmiller-EXt6n64.0K    yum-dfowler-MRADio4.0K    yum-centos-2EtZMg##=======##======####=======##======####You are in the /var/www directory==>>2.9G    vhosts948K    icons216K    error4.0K    html4.0K    cgi-bin##=======##======####=======##======####Thanks###Hello Team, This is to inform you that we have received an alert regarding EBS High Disk Usage  /dev/xvda1 ) - prd-sv1 - 10.59.100.193The EBS disk usage exceeded the threshold value of  90%. The current EBS disk utilization is 98.8%. We will analyze the details and will get back to you with an update. Regards,","From: Datadog Alerting <alert@dtdg.co>Sent: Thursday, March 14, 2019 1:05 PMTo: REAN Managed ServicesSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-sv1 - 10.59.100.193***** EXTERNAL EMAIL *****[Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-sv1 - 10.59.100.193High Disk Usage detected on the device /dev/xvda1   @rean_ms@hitachivantara.com[Metric Graph]<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUo3P8lwfZQEFo-2FY0kI1aGqRRAWulwlF9iUluzdUZOiGH60osg3QL9qacaqBiqMNJWSFFAR9D8CEhQe2kjO5Lz905Rbh3EVsFCbL5vKvd2E4ZxBtN8O443dhK0oGDMPraPqO6KKr-2BG29sLFWoKcJ1Vedw-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij32x4Rx0nCpXbz-2BLj0-2BtW4WfeZ1vMzbiGPgRPyjc39jwb1ZL4gYUNTO2p21UHoOueD5JxnFVsufo-2FQBHk8RB3WfmQsPI8jsaNTJvlJxvf4sNvFK51r13Vs9RvZ2JSlvxLQF4-2B-2FcdGy-2BvvNepPl17dP8CGNBxuNQxmE-2FnPh7fn6ioAQqCWNIrVlYwux2TPeS0IhFXbdtr1b9A3rXEWKgQ1Kpp&data=01%7C01%7Cthenmozhy.durairaj%40hitachivantara.com%7Cc58a56924b2b43f05b2f08d6a84fb096%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=wDarIQlWetgC4Pm3rvtWUJc7bdbadifF6PnauIR%2BTs4%3D&reserved=0>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 90The monitor was last triggered at Thu Mar 14 2019 07:35:49 UTC (3 secs ago).________________________________[Monitor Status<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUoKvcGnAzkyStJKdzb6NVcA-2FAP7bPLe2VSvjF-2Ffhnfwgpdq59Rq-2BtJSSwEdnWTnUwhEH2vYhahtv-2Bpl09p8a-2FcFA-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij32x4Rx0nCpXbz-2BLj0-2BtW4WfeZ1vMzbiGPgRPyjc39jwb8B8oAlb0RSe2GwCNUEjFDOKJbTIVZ36EQCtX7uSL5KxYp-2FDbsMyi1s46dF9Mp7S1BhJFaFAiyZ4wHTjWttOk6p94EepBZFlGQsjw6rZJo2C8SlhntSTz-2FCLdgE9NwTkHdA2idk7cU6ul7F3AyR0gYy7ZMngofeMFsazmwJXvqYT&data=01%7C01%7Cthenmozhy.durairaj%40hitachivantara.com%7Cc58a56924b2b43f05b2f08d6a84fb096%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=4Nix68tdXfPMcijxVbPFkrLXi4bAhbgFbRzERw4YqBI%3D&reserved=0>] · [Edit Monitor<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUo3IM-2FbEP-2FJM89epazZbNBUA-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij32x4Rx0nCpXbz-2BLj0-2BtW4WfeZ1vMzbiGPgRPyjc39jwb-2FGCTSJBMDaRbS5EQHwvFFrSS6ks-2BMjYP-2FwT3GbLxSqqzIM9P54uVgLZE-2FXy0iWTxupPu-2F6kMUvshK2ZPHBuorQ6YR76mQojXIHqyI5-2F146UDJJQOPPfjY33hQpzBhAN3-2F67FIiRtL83YY9A2VtfMo4rj8Dwp7phI7CQ0SLT0I5K&data=01%7C01%7Cthenmozhy.durairaj%40hitachivantara.com%7Cc58a56924b2b43f05b2f08d6a84fb096%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=0OfdjTReKUhZC2fHZSqAgcWrQHKir0oWZREqjTt405c%3D&reserved=0>] · [View i-048e66836110e8d7b<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEDKT1NZt0tnkwEaAxSQZgju6UUoUiOTstx-2FCQvbfJ9ZJk-2FSquGogVhkOJD5C0pteqQ-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij32x4Rx0nCpXbz-2BLj0-2BtW4WfeZ1vMzbiGPgRPyjc39jwb4yPrfPEZa5mle2BLB2cxwxaxmyrZkJJGjCnb4nj0dA6h-2F4dwrHNN-2Bifl77bdAJ3O-2FC5YWmh-2B-2FQAxntTjFXheDvJP6kxY0k9xi1BeGPgX0PqFCmsF5r3t7cvsMFheX1K64I1vaizh-2FtcDNmMyyU2Waw8xbU5jVAdXwAVZJ-2B97AVQ&data=01%7C01%7Cthenmozhy.durairaj%40hitachivantara.com%7Cc58a56924b2b43f05b2f08d6a84fb096%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=OU9o%2F2S6neHzFyrCbG4tEqWuXmPEgWROn7bWV%2BbBGAU%3D&reserved=0>] · [Show Processes<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQED-2FFPDBbKPsalSo1i1ufo6S-2FX4pKstbDP3BrKs5ghv718AfEv-2F1RcPw-2F3o3ujevY048yvG5h21fHUCtBIt497DMpFD1BD2WuH79SqhI3ds0FDnw3zl966FRCbyxEC7y-2FxiRmK6nPzeOm15z7PGdNobGVNjrzJPX0XthE9-2BI-2Fie3wEagzdLFnfDkMlw4bPiPaZ8-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij32x4Rx0nCpXbz-2BLj0-2BtW4WfeZ1vMzbiGPgRPyjc39jwb1z-2B7ANZn-2FwH81-2BI3yIvljQkI4-2FySpkHunYkm76wFjkdAHSoRdyXw7vOw-2Ft6CupfxUI9ZIQUCSQKl4BRDyq0iRl1oqwv5g5cyjnk3GVRpPx2YyN4fGdqAGCZdTts6VW5wrBmMxQgQcogIq7FVhqyZ15wKIIl-2FbljHciO4ck3bIdd&data=01%7C01%7Cthenmozhy.durairaj%40hitachivantara.com%7Cc58a56924b2b43f05b2f08d6a84fb096%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=DQfT0xEVw8jz5VEpFtfOIton7wzgEI%2FEAkcarnaNI1o%3D&reserved=0>]This alert was raised by account SpendHQComment in Datadog<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAYJwPp8omKJuncXDFvQtomFxO9k2tPqJnx0ZviOGcqmsWEWo1kJ7Il6AEGkTG-2B8X8-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij32x4Rx0nCpXbz-2BLj0-2BtW4WfeZ1vMzbiGPgRPyjc39jwbzUmBQ3-2FZP0q0k6kKfo5h0DELE0LiAdT-2FJ3bZQHJBsLwAJJFgmknx9Fb-2BwZl1SSuyrKYBUjIwzWhpM50AdsEX6MkXdyYde-2BfxuELO5JkuBxR488aBOXLuE7lp4qOl6hF-2F-2BLky1jPjWEmpn0ycMQdd1JCVHbX9O6y2vEkje18ahqB&data=01%7C01%7Cthenmozhy.durairaj%40hitachivantara.com%7Cc58a56924b2b43f05b2f08d6a84fb096%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=hy19HEoxvuhe9SlTiOnlsuLKpXxhne8U4g1j2x4Sep4%3D&reserved=0>To manage your Datadog subscriptions, click here<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECkg7AnUPKGn51plZlHct1NB9fwJzgmRoiq4UZtJ-2F9d6Q-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij32x4Rx0nCpXbz-2BLj0-2BtW4WfeZ1vMzbiGPgRPyjc39jwb2XjtOMijXGCGYBCqlKrnXzKc-2B9nbLcNgZrUoI8m4RlZpkJV-2Fh19uDPl4HLC1vhtPAhZIkK1cUoTwV64fCtIFeu3gr0qJ-2Bmr1ngVaXwkLpxUDIL1d8SnOL1KlycJulBSVbYvepeYQWbtEoOrF0iyApKZmkXfC9NlJwLu0lfuNr3y&data=01%7C01%7Cthenmozhy.durairaj%40hitachivantara.com%7Cc58a56924b2b43f05b2f08d6a84fb096%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=l9JdjHsHH6d88JakPbjQ%2B3LlRXOpWYOHdRIrYnu8Tkk%3D&reserved=0>.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-sv1 - 10.59.100.193,,14-03-2019 13:07,16,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding the EBS High Disk Usage on /dev/xvda1 volume on prd-sv1 (10.59.100.193 )  got resolved and the current value reached to 55.2% and the violation lasted for  13 hours. At this time we are marking the case as resolved. Please revert back to us if you have any concerns.","Hello Team,The alert is still in open statePlease zip or remove the unwanted files to resolve this issue and let us know if you need any assistance on this case. Thanks","Hello Team,Please find the breakdown details on the instance prd-sv1(10.59.100.193). Please zip or remove the unwanted files to resolve this issue and let us know if you need any assistance on this case.##=======##======",#=======##======,Disk usage as per Directories in /var==>>2.9G    www534M    log527M    lib377M    tmp130M    cache15M     spool880K    db116K    run16K     lock8.0K    empty##=======##======,#=======##======,#You are in the /var/cache directory==>>128M    yum2.0M    man24K     ldconfig12K     rpcbind8.0K    fontconfig4.0K    php-pear4.0K    mod_ssl4.0K    mod_proxy##=======##======,#=======##======,#You are in the /var/crash directory==>>Seems like /var/crash is empty!##=======##======,#=======##======,#You are in the /var/db directory==>>548K    newrelic-infra328K    sudo##=======##======,#=======##======,#You are in the /var/empty directory==>>4.0K    sshd##=======##======,#=======##======,#You are in the /var/games directory==>>Seems like /var/games is empty!##=======##======,#=======##======,#You are in the /var/lib directory==>>405M    clamav67M     rpm45M     amazon8.0M    yum868K    cloud676K    pear624K    iscsi140K    alternatives40K     sepolgen28K     nfs##=======##======,#=======##======,#You are in the /var/local directory==>>Seems like /var/local is empty!##=======##======,#=======##======,#You are in the /var/lock directory==>>4.0K    subsys4.0K    iscsi4.0K    iptraf0       kdump##=======##======,#=======##======,#You are in the /var/log directory==>>200M    file_monitor.log152M    datadog94M     amazon26M     audit20M     sa20M     newrelic5.3M    messages-20180513.gz2.4M    cron-201903102.4M    cron-201903032.4M    cron-20190224##=======##======,#=======##======,#You are in the /var/nis directory==>>Seems like /var/nis is empty!##=======##======,#=======##======,#You are in the /var/opt directory==>>Seems like /var/opt is empty!##=======##======,#=======##======,#You are in the /var/preserve directory==>>Seems like /var/preserve is empty!##=======##======,#=======##======,#You are in the /var/run directory==>>8.0K    screen8.0K    newrelic8.0K    httpd8.0K    clamav4.0K    utmp4.0K    syslogd.pid4.0K    sshd.pid4.0K    sm-notify.pid4.0K    setrans4.0K    sepermit##=======##======,#=======##======,#You are in the /var/spool directory==>>15M     mail200K    postfix16K     anacron8.0K    plymouth8.0K    cron4.0K    lpd##=======##======,#=======##======,#You are in the /var/tmp directory==>>91M     yum-sng-_8DLIG78M     yum-reanro-991xMl72M     shq-logs66M     yum-aherrera-9Eg3N560M     yum-mwatts-PnLKnb13M     yum-root-VWvI4w12K     monitor.php4.0K    yum-dmiller-EXt6n64.0K    yum-dfowler-MRADio4.0K    yum-centos-2EtZMg##=======##======,#=======##======,#You are in the /var/www directory==>>2.9G    vhosts948K    icons216K    error4.0K    html4.0K    cgi-bin##=======##======,#=======##======,#Thanks,"Hello Team, This is to inform you that we have received an alert regarding EBS High Disk Usage  /dev/xvda1 ) - prd-sv1 - 10.59.100.193The EBS disk usage exceeded the threshold value of  90%. The current EBS disk utilization is 98.8%. We will analyze the details and will get back to you with an update. Regards,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ESUjT,Cloud Engineer Level 1,Closed,1066962,Incident,07-07-2017 14:23,,"Hello SpendHQ Team,The alert related to volume usage for PROD-SPHQ-DB-SERVER05 got resolved and volume usage is now at a value of  57%.###Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 92.248This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3944219209526455559 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,06-07-2017 21:27,17,0,SpendHQ,"Hello SpendHQ Team,The alert related to volume usage for PROD-SPHQ-DB-SERVER05 got resolved and volume usage is now at a value of  57%.","Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hS5Fe,Cloud Engineer Level 1,Closed,1110364,Incident,10-01-2019 07:35,,"Hello Matthew,We have not yet heard back from you regarding this case.As this issue was already resolved and the site is accessible, we will be closing this case.However, if you have any questions feel free to get in touch with us.Thanks###Hello Mathew,This is a gentle reminder,Kindly check with the analysis shared with you regarding the site down alert that we have received for the URL https://secure.spendhq.com/login and Let us know if you have any queries.Thanks###Hello Matthew,This is quick follow up.At the time this alert triggered, we noticed there was a sudden spike in the Estimated ALB New Connection Count which hit 194 at around 11:45 AM UTC (kindly see the attached graph).Please let us know if you have performed any activity at the time of the alert.###Hello Rohit,We have checked and verified that the OOM issue happened after the alert recovered and we have also checked and verified all the logs but didn't find any suspicious activity.###@Team:We need to verify with customer if they made any changes. Please reach out to the customer.First re-verify if the below messages logs are of  the time of alert, if yes then please check the logs of /var/www/vhosts/files.spendhq.com/logs/production at the time of alert. Please post your finding here. Thanks !###Hello Rohit,Kindly review and let us know the next action on this###Hello Team,Other than a spike in new connections to the load balancer, I also checked dmesg and could see quite a number of oom errors even after the alert recovered.The following are filters from messages:Jan  7 16:11:38 ip-10-59-100-122 kernel: Out of memory: Kill process 3187 (httpd) score 82 or sacrifice childJan  7 16:11:38 ip-10-59-100-122 kernel: Killed process 3187, UID 48, (httpd) total-vm:5537016kB, anon-rss:5163276kB, file-rss:948kBJan  7 16:11:38 ip-10-59-100-122 kernel: httpd: page allocation failure. order:0, mode:0x201daJan  7 16:11:38 ip-10-59-100-122 kernel: Pid: 3187, comm: httpd Not tainted 2.6.32-696.3.1.el6.x86_64 #1Jan  7 16:11:46 ip-10-59-100-122 kernel: httpd invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0Jan  7 16:11:46 ip-10-59-100-122 kernel: httpd cpuset=/ mems_allowed=0Jan  7 16:11:46 ip-10-59-100-122 kernel: Pid: 16331, comm: httpd Not tainted 2.6.32-696.3.1.el6.x86_64 #1Jan  7 16:11:47 ip-10-59-100-122 kernel: Out of memory: Kill process 23802 (httpd) score 90 or sacrifice childJan  7 16:11:47 ip-10-59-100-122 kernel: Killed process 23802, UID 48, (httpd) total-vm:6054420kB, anon-rss:5679848kB, file-rss:992kBJan  7 16:12:10 ip-10-59-100-122 kernel: httpd invoked oom-killer: gfp_mask=0x280da, order=0, oom_adj=0, oom_score_adj=0Jan  7 16:12:10 ip-10-59-100-122 kernel: httpd cpuset=/ mems_allowed=0Jan  7 16:12:10 ip-10-59-100-122 kernel: Pid: 30187, comm: httpd Not tainted 2.6.32-696.3.1.el6.x86_64 #1Jan  7 17:00:24 ip-10-59-100-122 kernel: Out of memory: Kill process 20115 (httpd) score 74 or sacrifice childJan  7 17:00:24 ip-10-59-100-122 kernel: Killed process 20115, UID 48, (httpd) total-vm:5028108kB, anon-rss:4654088kB, file-rss:928kB###Hello Matthew,We have not heard back from you again regarding this case.At the time this alert triggered, we noticed there was a sudden spike in the Estimated ALB New Connection Count which hit 194 at around 11:45 AM UTC (kindly see the attached graph).As updated initially, there was some considerable amount of latency over time experienced on the load balancer yesterday and has been the case for sometime now.Kindly review these and let us know if you have any questions.Thanks###Hi team,We also checked the instance level(/var/log/messages & httpd/error.logs ), we couldn't see any error. other than Shubhankar analysis to the customer.###Hello Team, As the issue got resolved hence we are downgrading the priority of the case.###Hello Matthew,Please let us know if you have made any changes or performed any activity at the time of alert or before. As from the console, we can see that there were some spikes over time in the latency graph, below is the screenshot for the same in the attachment section.Kindly let us know your views on this.###Hello Matthew, We are analyzing the issue and will let you know the updates.###Mail sent to leads.###Matthew Watts5:30 PM (1 minute ago)to Rean, spendhq-support@reancloud.comWe’re working to recover now.###Hello Team,We have received an alert regarding site down for URL: https://secure.spendhq.com/login. We are getting Http error code 500 while browsing the site. Please let us know if you are performing any activity at your end meanwhile we are checking the issue from our side.","Mon, 07 Jan 2019 06:43:23 -0500Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): California US, Atlanta-B US, Frankfurt DE, Dallas-C US-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,07-01-2019 17:15,62,0,SpendHQ,"Hello Matthew,We have not yet heard back from you regarding this case.As this issue was already resolved and the site is accessible, we will be closing this case.However, if you have any questions feel free to get in touch with us.Thanks","Hello Mathew,This is a gentle reminder,Kindly check with the analysis shared with you regarding the site down alert that we have received for the URL https://secure.spendhq.com/login and Let us know if you have any queries.Thanks","Hello Matthew,This is quick follow up.At the time this alert triggered, we noticed there was a sudden spike in the Estimated ALB New Connection Count which hit 194 at around 11:45 AM UTC (kindly see the attached graph).Please let us know if you have performed any activity at the time of the alert.","Hello Rohit,We have checked and verified that the OOM issue happened after the alert recovered and we have also checked and verified all the logs but didn't find any suspicious activity.","@Team:We need to verify with customer if they made any changes. Please reach out to the customer.First re-verify if the below messages logs are of  the time of alert, if yes then please check the logs of /var/www/vhosts/files.spendhq.com/logs/production at the time of alert. Please post your finding here. Thanks !","Hello Rohit,Kindly review and let us know the next action on this","Hello Team,Other than a spike in new connections to the load balancer, I also checked dmesg and could see quite a number of oom errors even after the alert recovered.The following are filters from messages:Jan  7 16:11:38 ip-10-59-100-122 kernel: Out of memory: Kill process 3187 (httpd) score 82 or sacrifice childJan  7 16:11:38 ip-10-59-100-122 kernel: Killed process 3187, UID 48, (httpd) total-vm:5537016kB, anon-rss:5163276kB, file-rss:948kBJan  7 16:11:38 ip-10-59-100-122 kernel: httpd: page allocation failure. order:0, mode:0x201daJan  7 16:11:38 ip-10-59-100-122 kernel: Pid: 3187, comm: httpd Not tainted 2.6.32-696.3.1.el6.x86_64 #1Jan  7 16:11:46 ip-10-59-100-122 kernel: httpd invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0Jan  7 16:11:46 ip-10-59-100-122 kernel: httpd cpuset=/ mems_allowed=0Jan  7 16:11:46 ip-10-59-100-122 kernel: Pid: 16331, comm: httpd Not tainted 2.6.32-696.3.1.el6.x86_64 #1Jan  7 16:11:47 ip-10-59-100-122 kernel: Out of memory: Kill process 23802 (httpd) score 90 or sacrifice childJan  7 16:11:47 ip-10-59-100-122 kernel: Killed process 23802, UID 48, (httpd) total-vm:6054420kB, anon-rss:5679848kB, file-rss:992kBJan  7 16:12:10 ip-10-59-100-122 kernel: httpd invoked oom-killer: gfp_mask=0x280da, order=0, oom_adj=0, oom_score_adj=0Jan  7 16:12:10 ip-10-59-100-122 kernel: httpd cpuset=/ mems_allowed=0Jan  7 16:12:10 ip-10-59-100-122 kernel: Pid: 30187, comm: httpd Not tainted 2.6.32-696.3.1.el6.x86_64 #1Jan  7 17:00:24 ip-10-59-100-122 kernel: Out of memory: Kill process 20115 (httpd) score 74 or sacrifice childJan  7 17:00:24 ip-10-59-100-122 kernel: Killed process 20115, UID 48, (httpd) total-vm:5028108kB, anon-rss:4654088kB, file-rss:928kB","Hello Matthew,We have not heard back from you again regarding this case.At the time this alert triggered, we noticed there was a sudden spike in the Estimated ALB New Connection Count which hit 194 at around 11:45 AM UTC (kindly see the attached graph).As updated initially, there was some considerable amount of latency over time experienced on the load balancer yesterday and has been the case for sometime now.Kindly review these and let us know if you have any questions.Thanks","Hi team,We also checked the instance level(/var/log/messages & httpd/error.logs ), we couldn't see any error. other than Shubhankar analysis to the customer.","Hello Team, As the issue got resolved hence we are downgrading the priority of the case.","Hello Matthew,Please let us know if you have made any changes or performed any activity at the time of alert or before. As from the console, we can see that there were some spikes over time in the latency graph, below is the screenshot for the same in the attachment section.Kindly let us know your views on this.","Hello Matthew, We are analyzing the issue and will let you know the updates.",Mail sent to leads.,"Matthew Watts5:30 PM (1 minute ago)to Rean, spendhq-support@reancloud.comWe’re working to recover now.","Hello Team,We have received an alert regarding site down for URL: https://secure.spendhq.com/login. We are getting Http error code 500 while browsing the site. Please let us know if you are performing any activity at your end meanwhile we are checking the issue from our side.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000018I43x,Cloud Engineer Level 1,Closed,1043214,Incident,21-02-2017 06:23,,"Hello SpendHq Team,At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Hello Steven,We are monitoring all the matrices for the PROD-SPHQ-DB-SERVER02.We are monitoring mysql process also for all the DB servers.The alert for mysql get triggered when the Process count matching mysql is below the threshold of 4.Please let us know if you have any more queries.###Are you only monitoring if the machine goes down or the load goes high? You are not monitoring the actual mysql service on that machine?###Hello Steven,Thanks for the update.We will mark this case as resolved for now.Regarding the prod database instance (PROD-SPHQ-DB-SERVER02) , We are actively monitoring it through our monitoring tool.###You can make this case resolved. We believe we know the cause for the sudden spike. I had to do a repair table which caused a critical table to lock up. Do you have monitoring on the 10.59.10.12 server (houses the PROD database)?###Hello Steven,Please let us know if you have any further queries on this.###Hello Steven,We have verified the logs and found the site was not down but there was a sudden spike in the ELB latency which caused due to the high number of requests. The ELBs were not able to respond to our monitoring request within the timeout period set in the monitoring tool  (which is 30 seconds). Hence it has thrown the Site down alert.From the logs, we couldn't find any suspicious URLs and also there was a spike in network inbound and open TCP connections. But it was not much in order to consider this as an attack.Please let us know if you have any further queries on this.###Was there a DDOS of some sorts?###The RCA was informative it doesn't address the real root cause. Why was the latency so high? I get that the wormly pings came back eventually but we still don't know why it was so slow.###Hello SpendHQ-Team,We haven't heard back from you.At this time we are marking this case as resolved however if you have any further queries on this we can reopen the case at any time.###Hello Team,Please review the RCA and let us know if you have any queries on this.###Hi Team,Please find the attached RCA document and let us know if you have any further queries.###Hello SpendHQ Team, We have analyzed the secure and preview logs and found that the sites were actually not down at the time of alert. We have seen a sudden increase in ELB latency graph. Also Sum of requests was high for both of the ELBs. Due to this our monitoring tool was not able to process the request since its timeout is set to 30 seconds.We have checked the ELB logs and found that there are some entries which have high backend processing time.While analyzing backend DB server metrics, we found that there was a spike in open tcp connections graph.Please find the attachment section for screenshots of graphs and ELB logs at the time of alert and let us know if you have queries regarding this. We are analyzing more on this issue and will get back to you with the RCA Document.###Hello SpendHQ Team, We again received a site down alert for the urls: https://preview.spendhq.com/login and https://secure.spendhq.com/loginThe site was accessible at the time of alert. We are analyzing this issue from our part and will get back to you with the updates.###Hello SpendHQ  Team,We have analysed the backend db server host metrics and we could see a spike in Network Inbound  at the time of the alert as well as there is a sudden spike in open tcp connection which went to a value of 389 at the time of the alert.From elb logs we could see that all request with high backend processing time to preview are from wormly and the requests to secure  also show high processing time so the sites were not  actually down it took more time to process the request.###We have also verified the backend host metrics and we could see a spike in Network  Inbound and Outbound traffic at the time of the alert.  And also the db server PROD-SPHQ-DB-SERVER02, the network inbound and outbound traffic were high at the time of the alert.###Hello SpendHQ-Team,We have verified the logs and found the sites were not down but there was a sudden spike in the ELB latency where ELBs was not able to respond to our monitoring request within the timeout period set in the monitoring tool(which is 30 seconds). Hence it has thrown the Site down alert.We have also analysed the Secure and Preview ELB access logs, we were able to figure out that the requests were serving with high latency.  Sum of requests was high for both of the ELBs, Secure ELB was having a count of 401 sum requests and 124 for Preview at the point of this alert. Hence, the sudden spike in the sum of requests leads to high latency.Also, there was no suspicious activity seen from incoming IP addresses shown in the log files.We have checked instance level access logs, error logs, message logs and didn't found anything abnormal. Please refer the attached documents consisting of the ELB access logs, latency and sum requests graphs at the time of the alert. Kindly validate the details and let us know if you have any queries regarding this.Our team is analysing more on this issue and will get back to you with further updates shortly.###Hello SpendHQ-Team,This is to notify you that we got the site down alert for the URLs  https://preview.spendhq.com/login and https://secure.spendhq.com/login. The alert got resolved automatically within 1 mInute. We have checked and confirmed that the site was accessible at the time of the alert.We are analysing on it and will keep you with updates.","Wed, 15 Feb 2017 17:16:19 -0500Detected Error on SpendHQEstimated Downtime: 2 minutes https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: --------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Frankfurt DE, Dallas-B US, California US, Sydney-C AU-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,16-02-2017 03:46,123,0,SpendHQ,"Hello SpendHq Team,At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Hello Steven,We are monitoring all the matrices for the PROD-SPHQ-DB-SERVER02.We are monitoring mysql process also for all the DB servers.The alert for mysql get triggered when the Process count matching mysql is below the threshold of 4.Please let us know if you have any more queries.",Are you only monitoring if the machine goes down or the load goes high? You are not monitoring the actual mysql service on that machine?,"Hello Steven,Thanks for the update.We will mark this case as resolved for now.Regarding the prod database instance (PROD-SPHQ-DB-SERVER02) , We are actively monitoring it through our monitoring tool.",You can make this case resolved. We believe we know the cause for the sudden spike. I had to do a repair table which caused a critical table to lock up. Do you have monitoring on the 10.59.10.12 server (houses the PROD database)?,"Hello Steven,Please let us know if you have any further queries on this.","Hello Steven,We have verified the logs and found the site was not down but there was a sudden spike in the ELB latency which caused due to the high number of requests. The ELBs were not able to respond to our monitoring request within the timeout period set in the monitoring tool  (which is 30 seconds). Hence it has thrown the Site down alert.From the logs, we couldn't find any suspicious URLs and also there was a spike in network inbound and open TCP connections. But it was not much in order to consider this as an attack.Please let us know if you have any further queries on this.",Was there a DDOS of some sorts?,The RCA was informative it doesn't address the real root cause. Why was the latency so high? I get that the wormly pings came back eventually but we still don't know why it was so slow.,"Hello SpendHQ-Team,We haven't heard back from you.At this time we are marking this case as resolved however if you have any further queries on this we can reopen the case at any time.","Hello Team,Please review the RCA and let us know if you have any queries on this.","Hi Team,Please find the attached RCA document and let us know if you have any further queries.","Hello SpendHQ Team, We have analyzed the secure and preview logs and found that the sites were actually not down at the time of alert. We have seen a sudden increase in ELB latency graph. Also Sum of requests was high for both of the ELBs. Due to this our monitoring tool was not able to process the request since its timeout is set to 30 seconds.We have checked the ELB logs and found that there are some entries which have high backend processing time.While analyzing backend DB server metrics, we found that there was a spike in open tcp connections graph.Please find the attachment section for screenshots of graphs and ELB logs at the time of alert and let us know if you have queries regarding this. We are analyzing more on this issue and will get back to you with the RCA Document.","Hello SpendHQ Team, We again received a site down alert for the urls: https://preview.spendhq.com/login and https://secure.spendhq.com/loginThe site was accessible at the time of alert. We are analyzing this issue from our part and will get back to you with the updates.","Hello SpendHQ  Team,We have analysed the backend db server host metrics and we could see a spike in Network Inbound  at the time of the alert as well as there is a sudden spike in open tcp connection which went to a value of 389 at the time of the alert.From elb logs we could see that all request with high backend processing time to preview are from wormly and the requests to secure  also show high processing time so the sites were not  actually down it took more time to process the request.","We have also verified the backend host metrics and we could see a spike in Network  Inbound and Outbound traffic at the time of the alert.  And also the db server PROD-SPHQ-DB-SERVER02, the network inbound and outbound traffic were high at the time of the alert.","Hello SpendHQ-Team,We have verified the logs and found the sites were not down but there was a sudden spike in the ELB latency where ELBs was not able to respond to our monitoring request within the timeout period set in the monitoring tool(which is 30 seconds). Hence it has thrown the Site down alert.We have also analysed the Secure and Preview ELB access logs, we were able to figure out that the requests were serving with high latency.  Sum of requests was high for both of the ELBs, Secure ELB was having a count of 401 sum requests and 124 for Preview at the point of this alert. Hence, the sudden spike in the sum of requests leads to high latency.Also, there was no suspicious activity seen from incoming IP addresses shown in the log files.We have checked instance level access logs, error logs, message logs and didn't found anything abnormal. Please refer the attached documents consisting of the ELB access logs, latency and sum requests graphs at the time of the alert. Kindly validate the details and let us know if you have any queries regarding this.Our team is analysing more on this issue and will get back to you with further updates shortly.","Hello SpendHQ-Team,This is to notify you that we got the site down alert for the URLs  https://preview.spendhq.com/login and https://secure.spendhq.com/login. The alert got resolved automatically within 1 mInute. We have checked and confirmed that the site was accessible at the time of the alert.We are analysing on it and will keep you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FjiTn,Cloud Engineer Level 1,Closed,1077173,Incident,06-09-2017 12:52,,"As discussed in Morning Ops call, we are closing this case since Yogesh will create a Jira ticket for following up with Client.###Follow up with the customer in case of no response.###Hello SpendHQ-Team,Do we have any updates regarding this case?Kindly review this list of IAM Server Certificates that have been shared previously and let us know whether we can clean the unwanted ones. Revert back in case of any further queries.###Sent an email to the customer with the details of IAM server certificates we can cleanup. Will wait for their reply or follow up.###I talked with Yogesh and he updated that he is working on priority ticket.Need to check with Yogesh for the updates. Next action: Check with Yogesh for the further updates.###I talked with Yogesh and he will update.Next Action: Check With Yogesh for the updates.###Informed this to Yogesh. We will have to check for the update from Yogesh in the evening shift.",Below are resource details that cross limitsREGION       RESOURCE   LIMIT          USAGE          SERVICE-               IAM               20              16              Server certificates,REAN CLOUD AWS limit checker ALERT for spendhq - WARNING,,30-08-2017 14:28,166,0,SpendHQ,"As discussed in Morning Ops call, we are closing this case since Yogesh will create a Jira ticket for following up with Client.",Follow up with the customer in case of no response.,"Hello SpendHQ-Team,Do we have any updates regarding this case?Kindly review this list of IAM Server Certificates that have been shared previously and let us know whether we can clean the unwanted ones. Revert back in case of any further queries.",Sent an email to the customer with the details of IAM server certificates we can cleanup. Will wait for their reply or follow up.,I talked with Yogesh and he updated that he is working on priority ticket.Need to check with Yogesh for the updates. Next action: Check with Yogesh for the further updates.,I talked with Yogesh and he will update.Next Action: Check With Yogesh for the updates.,Informed this to Yogesh. We will have to check for the update from Yogesh in the evening shift.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001LwtA4,Cloud Engineer Level 1,Closed,1087333,Incident,26-12-2017 08:11,,"Hello SpendHQ-Team,There was a temp entry added for port 22 on 0.0.0.0/0 to the Sophos instance security group as a part of the maintenance activity which has been performed yesterday. This was the reason why we were receiving multiple failed SSH login attempts from different locations.We have removed the entry from the Security Group and now this issue has been resolved. Kindly validate these details and let us know if your team have any further queries regarding the same.Regards,Sumod.K.Bose###Hello SpendHQ Team, We have received couple more SSH failed login attempts and below are the details. 218.65.30.40, 182.243.121.140 & 218.65.30.40- ChinaWe have blocked these IPs from the NACL level. We are monitoring the environment. Please let us know if you have any queries.###27.114.166.196###182.243.121.140###218.65.30.40###Hello SpendHQ Team, We have received couple more SSH failed login attempts and below are the details.219.151.22.59 - 	ChinaWe have blocked these IPs from the NACL level. We are monitoring the environment. Please let us know if you have any queries. Thank You, Safuvan KM###219.151.22.59###Hello SpendHQ Team,We have received couple more SSH failed login attempts and below are the details.39.118.158.229 - Korea109.169.142.203 - Russian FederationWe have blocked these IPs from the NACL level. We are monitoring the environment. Please let us know if you have any queries.Thank You,Safuvan KM###109.169.142.203###39.118.158.229###Hello SpendHQ Team,This is to inform you that we were receiving multiple failed SSH login attempt alerts for the SpendHQ Sophos. On further checking, we have sorted out the source IP addresses and corresponding geo location from which the login attempts are coming.218.84.173.202 - China190.178.88.251 - Argentina5.138.49.24 - Russian Federation123.150.200.121 - China112.81.199.128 - China103.207.37.110 - Viet Nam186.130.192.70 - ArgentinaWe have blocked these IP addresses from the NACL level. Since then, no new attempts have reported. We will keep monitoring this and let you know if we have any new updates. Please let us know if you have any queries.Thank You,Safuvan KM",">> Failed SSH login attempt from 218.84.173.202 at 2017-12-25 05:47:12 with> username root.>> --> System Uptime      : 0 days 0 hours 10 minutes> System Load        : 1.16> System Version     : Sophos UTM 9.506-2>> Please refer to the manual for detailed instructions.>--  <https://www.reancloud.com/news/rean-cloud-named-partner-newly-launched-aws-alexa-business/>--  <https://www.reancloud.com/news/rean-cloud-named-partner-newly-launched-aws-alexa-business/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][WARN-006] Failed SSH login,,25-12-2017 19:10,13,0,SpendHQ,"Hello SpendHQ-Team,There was a temp entry added for port 22 on 0.0.0.0/0 to the Sophos instance security group as a part of the maintenance activity which has been performed yesterday. This was the reason why we were receiving multiple failed SSH login attempts from different locations.We have removed the entry from the Security Group and now this issue has been resolved. Kindly validate these details and let us know if your team have any further queries regarding the same.Regards,Sumod.K.Bose","Hello SpendHQ Team, We have received couple more SSH failed login attempts and below are the details. 218.65.30.40, 182.243.121.140 & 218.65.30.40- ChinaWe have blocked these IPs from the NACL level. We are monitoring the environment. Please let us know if you have any queries.",27.114.166.196,182.243.121.140,218.65.30.40,"Hello SpendHQ Team, We have received couple more SSH failed login attempts and below are the details.219.151.22.59 - 	ChinaWe have blocked these IPs from the NACL level. We are monitoring the environment. Please let us know if you have any queries. Thank You, Safuvan KM",219.151.22.59,"Hello SpendHQ Team,We have received couple more SSH failed login attempts and below are the details.39.118.158.229 - Korea109.169.142.203 - Russian FederationWe have blocked these IPs from the NACL level. We are monitoring the environment. Please let us know if you have any queries.Thank You,Safuvan KM",109.169.142.203,39.118.158.229,"Hello SpendHQ Team,This is to inform you that we were receiving multiple failed SSH login attempt alerts for the SpendHQ Sophos. On further checking, we have sorted out the source IP addresses and corresponding geo location from which the login attempts are coming.218.84.173.202 - China190.178.88.251 - Argentina5.138.49.24 - Russian Federation123.150.200.121 - China112.81.199.128 - China103.207.37.110 - Viet Nam186.130.192.70 - ArgentinaWe have blocked these IP addresses from the NACL level. Since then, no new attempts have reported. We will keep monitoring this and let you know if we have any new updates. Please let us know if you have any queries.Thank You,Safuvan KM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Tlq1k,Cloud Engineer Level 3,Closed,1094507,Incident,06-04-2018 16:56,,"Hello Matthew,Did you get a chance to review the RCA and revert back to us?We have created the preventive action tasks internally and will be keeping you posted on the progress. Hence, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM###Hello Matthew,Please find the RCA in the attachment section.Kindly review this details and revert back to us in case of any queries.###Hello Matthew,We are currently working on the RCA and will share with you once it is done.###What is the case status here?###Praveen and Rohit will be having a call on this at 5:30 AM EST Tomorrow.###In ops call praveen updated that he review it###As mentioned bt Yogesh please get the RCA reviewed by Praveen.###As per the update by Yogesh, I have corrected the RCA and he is currently reviewing it. Yogesh will update the status in an hour.###Hello Team,We are currently working on the RCA and we will update you the status ASAP.###I have completed the RCA. https://docs.google.com/document/d/1EBYHWkIzI3MUYdcuhGXKeoltdWc39DLtVMsytOL6gBI/edit#I have called Rohit and he updated that he will review it today.###I have worked on the RCA and only preventive action is pending in this case.  Need help from CC regarding the preventive actionshttps://docs.google.com/document/d/1EBYHWkIzI3MUYdcuhGXKeoltdWc39DLtVMsytOL6gBI/edit####Updated the RCA with the info that we got and shared it with Rohit Check with him for completing it https://docs.google.com/document/d/1EBYHWkIzI3MUYdcuhGXKeoltdWc39DLtVMsytOL6gBI/edit####Hello Team, We terminated New NFS server ( i-051117f01b8e6b51c). Please check and let us know if you have any concerns. For now, we are closing this change ticket and will be following up on case 01094507.###@here What's the progress on SpendHQ RCA ?Please make sure we delete the new FS1 server we created in night(ip may be 10.59.100.226)cc: @rohit.puri###I had a word with Vinod on this and as per the communication escalating the ticket to Yogesh for creating the RCA.@Yogesh: Please find the RCA doc in there: https://docs.google.com/document/d/1EBYHWkIzI3MUYdcuhGXKeoltdWc39DLtVMsytOL6gBI/edit####We have fixed the NFS server issue by rebooting the server.later we have  Verified the services are came properly. and also checked the  mount point is all client-server and also in /etc/fstab and informed the customer regarding the status. Started working on the RCA. Need to work on the RCA: https://docs.google.com/document/d/1EBYHWkIzI3MUYdcuhGXKeoltdWc39DLtVMsytOL6gBI/edit####Perfect, thank you. I will verify on this end. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com###Hello Matthew,We have completed updating the /etc/fstab entries changes and make sure the required NFS mounts are coming up properly on the below servers, Please verify the servers mentioned below:10.59.100.12210.59.100.17010.59.100.19310.59.100.21010.59.100.24010.59.100.7810.59.101.6Below servers are currently in the stopped state, Hence we did not perform the changes there. Let us know if you want us to start and finish changes on these:10.59.100.11810.59.100.7910.59.100.94Also let us know if there are any additional server where we need to update /etc/fstab entries and perform reboot.Regards,###Matthew WattsHow are we looking?###Almost done. Team is doing final check. Regards,-Praveen###Matthew WattsWhat is the update here? When can we expect systems to be operational again?###Hello Mattew,We are rebooting the NFS server.###Hello Matthew,We are actively working on it and will get back to with updates shortly.###We went on a call with SPendhq team on this issue, at that time they have reported that they are facing an issue on NFS server and raised another ticket with Name: SEV ONECan you please confirm that you understand that we are having a SEV ONE and confirm receipt. The files.spendhq.com has been unmounted on all production machines and needs to be resolved ASAP Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###Hello Matthew,We are currently working on this issue to remount them back and will let you know the updates.###Matthew Watts8:31 PM (9 minutes ago)to REAN Can you please confirm that you understand that we are having a SEV ONE and confirm receipt. The files.spendhq.com has been unmounted on all production machines and needs to be resolved ASAP Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###Hello Matthew,Please join the call here https://reancloud.zoom.us/my/mgse1To mount the volumes.###Hello Matthew,We are checking on this issue will get back to you shortly.###Matthew Watts7:08 PM (14 minutes ago)to Praveen, spendhq-support None of the mounts are functional on this machine, neither are they on 10.59.100.170 Please look into this asap.###Hello Matthew,We will check on this issue and will get back to you with details.###Hello Matthew,We have performed stop and start on the instance. Both instance and system status check passed on the instance.  But the instance is currently outofservice under the sandbox ELB. On further checking on this, we could see that the health check port listens to port 80 in ELB and from the instance level, the port 80 is not opened. Also, from instance level the httpd service in the stopped state.In order to fix this issue, restart the httpd service from the instance level. Kindly validate the details and let us know if your team need further assistance from our end.###Hello Matt, The instances health check failed at AWS Level. It’s because of the underlying hardware and our team is on it. Regards,-Praveen###Hello Matthew,We acknowledge the delivery of your request. We will check on this and will let you know the updates.","Rean,Can you please investigate why 10.59.100.240 is inaccessible.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",10.59.100.240 Inaccessible,,29-03-2018 03:22,206,0,SpendHQ,"Hello Matthew,Did you get a chance to review the RCA and revert back to us?We have created the preventive action tasks internally and will be keeping you posted on the progress. Hence, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM","Hello Matthew,Please find the RCA in the attachment section.Kindly review this details and revert back to us in case of any queries.","Hello Matthew,We are currently working on the RCA and will share with you once it is done.",What is the case status here?,Praveen and Rohit will be having a call on this at 5:30 AM EST Tomorrow.,In ops call praveen updated that he review it,As mentioned bt Yogesh please get the RCA reviewed by Praveen.,"As per the update by Yogesh, I have corrected the RCA and he is currently reviewing it. Yogesh will update the status in an hour.","Hello Team,We are currently working on the RCA and we will update you the status ASAP.",I have completed the RCA. https://docs.google.com/document/d/1EBYHWkIzI3MUYdcuhGXKeoltdWc39DLtVMsytOL6gBI/edit#I have called Rohit and he updated that he will review it today.,I have worked on the RCA and only preventive action is pending in this case.  Need help from CC regarding the preventive actionshttps://docs.google.com/document/d/1EBYHWkIzI3MUYdcuhGXKeoltdWc39DLtVMsytOL6gBI/edit,#Updated the RCA with the info that we got and shared it with Rohit Check with him for completing it https://docs.google.com/document/d/1EBYHWkIzI3MUYdcuhGXKeoltdWc39DLtVMsytOL6gBI/edit,"#Hello Team, We terminated New NFS server ( i-051117f01b8e6b51c). Please check and let us know if you have any concerns. For now, we are closing this change ticket and will be following up on case 01094507.",@here What's the progress on SpendHQ RCA ?Please make sure we delete the new FS1 server we created in night(ip may be 10.59.100.226)cc: @rohit.puri,I had a word with Vinod on this and as per the communication escalating the ticket to Yogesh for creating the RCA.@Yogesh: Please find the RCA doc in there: https://docs.google.com/document/d/1EBYHWkIzI3MUYdcuhGXKeoltdWc39DLtVMsytOL6gBI/edit,#We have fixed the NFS server issue by rebooting the server.later we have  Verified the services are came properly. and also checked the  mount point is all client-server and also in /etc/fstab and informed the customer regarding the status. Started working on the RCA. Need to work on the RCA: https://docs.google.com/document/d/1EBYHWkIzI3MUYdcuhGXKeoltdWc39DLtVMsytOL6gBI/edit,"#Perfect, thank you. I will verify on this end. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com","Hello Matthew,We have completed updating the /etc/fstab entries changes and make sure the required NFS mounts are coming up properly on the below servers, Please verify the servers mentioned below:10.59.100.12210.59.100.17010.59.100.19310.59.100.21010.59.100.24010.59.100.7810.59.101.6Below servers are currently in the stopped state, Hence we did not perform the changes there. Let us know if you want us to start and finish changes on these:10.59.100.11810.59.100.7910.59.100.94Also let us know if there are any additional server where we need to update /etc/fstab entries and perform reboot.Regards,",Matthew WattsHow are we looking?,"Almost done. Team is doing final check. Regards,-Praveen",Matthew WattsWhat is the update here? When can we expect systems to be operational again?,"Hello Mattew,We are rebooting the NFS server.","Hello Matthew,We are actively working on it and will get back to with updates shortly.","We went on a call with SPendhq team on this issue, at that time they have reported that they are facing an issue on NFS server and raised another ticket with Name: SEV ONECan you please confirm that you understand that we are having a SEV ONE and confirm receipt. The files.spendhq.com has been unmounted on all production machines and needs to be resolved ASAP Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com","Hello Matthew,We are currently working on this issue to remount them back and will let you know the updates.","Matthew Watts8:31 PM (9 minutes ago)to REAN Can you please confirm that you understand that we are having a SEV ONE and confirm receipt. The files.spendhq.com has been unmounted on all production machines and needs to be resolved ASAP Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com","Hello Matthew,Please join the call here https://reancloud.zoom.us/my/mgse1To mount the volumes.","Hello Matthew,We are checking on this issue will get back to you shortly.","Matthew Watts7:08 PM (14 minutes ago)to Praveen, spendhq-support None of the mounts are functional on this machine, neither are they on 10.59.100.170 Please look into this asap.","Hello Matthew,We will check on this issue and will get back to you with details.","Hello Matthew,We have performed stop and start on the instance. Both instance and system status check passed on the instance.  But the instance is currently outofservice under the sandbox ELB. On further checking on this, we could see that the health check port listens to port 80 in ELB and from the instance level, the port 80 is not opened. Also, from instance level the httpd service in the stopped state.In order to fix this issue, restart the httpd service from the instance level. Kindly validate the details and let us know if your team need further assistance from our end.","Hello Matt, The instances health check failed at AWS Level. It’s because of the underlying hardware and our team is on it. Regards,-Praveen","Hello Matthew,We acknowledge the delivery of your request. We will check on this and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G000016oKx7,Cloud Engineer Level 1,Closed,1042241,Incident,,,,"Fri, 13 Jan 2017 22:26:58 -0500SpendHQ has RecoveredEstimated Downtime: 11 minutes 59 seconds https://www.wormly.com/edithost/hostid/50743----------HTTP is UP----------Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: ----------HTTP is UP----------Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SpendHQ has Recovered,,14-01-2017 08:57,0,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000017Qgiu,Cloud Engineer Level 3,Closed,1042841,Incident,08-02-2017 22:07,,"As per the discussion on evening OPS call, we are closing this case.###Sanket provided following details to Darren.Our idea behind adding high availability at every layer of the architecture aligns with the recommendation that rather than vertical scaling, we design our architecture for horizontal scaling. So, if we are using c4.xlarge instance at our web layer, we should break it into two c4.large instances which span across multiple availability zones. It will ensure our cost remains the same while we achieve high availability for our architecture. Also, the high availability architecture will be in active-active mode rather than the active-passive mode, so your end-users are not impacted.We can further improve by adding auto-scaling capabilities. Auto-scaling ensures your number of nodes scale up during peak hours and come down to the minimum during off hours. It turns out to a cheaper option rather than running a high compute underutilised node during off hours. Rest assured, our architecture design with high availability does factor in the cost part, and we will do our best to minimise your cost. The only thing we need to figure out is your network bandwidth requirement and whether chosen instance type supports it or not.Lastly, we do understand the sensitivity of these hardware failures. As of now, AWS doesn't have a mechanism to alert us ahead of time to prevent this issue. During previous hardware failure, we did reach out to AWS team and got a response that they work hard to minimise these hardware failures, but it is not immune from these failures.Unfortunately, it is very hard to write down all thoughts in an email, but we do understand your concern and will do best to help you. We do have our bi-weekly call scheduled for next week. However, we can certainly have a call this week to get into a deeper discussion and finalise the design which can help us to mitigate any such issues keeping your cost intact.###Assigning ticket to Sanket.###Darren replied that Thank you, Sanket for taking the time to respond over the weekend. I understand your comment, and we are already designing some failure recovery points, but I would like us to discuss the general comment a bit more. In short, if I understand, you are stating that because hardware fails, we should spend more money to protect ourselves from the hardware failure. In the cloud world, that seems incomplete logic. To us, one of the benefits of using AWS is so that we don’t have to worry about hardware failure. In reality, we have had many more hardware failures in the past year than we did in the history of the company prior to the move. If AWS hardware is likely to fail, there should be some protection provided to us other than just constantly spending more money. If we go to a full failover environment, do we need to have a fully redundant system in case our DR hardware fails? What if that fails? I have confident that if we would have bought all of these machines and put them in our DC that we would not have experience four hardware failures in 12 months. If I need to rent 20 machines to ensure that I have 15 fully operational, that deteriorates the cloud value proposition considerably. Please understand – not trying to be overly critical – just trying to make sure we are synchronized in our expectations. I will have Andrew Kim follow up on this thread to discuss next steps.###Hello Matthew,We have received an email from your out of office mail box that you are not available till 13th Feb.Hence we are marking this case as resolved as of now.Once you are back and if there are any comments, let us know.We will re-open the case.###Sanket has updated that he has received an email from Matthew out of office mail box that he is not available till Feb 13th###Sanket replied  that,Hi Matthew,There is no way that we can get alerted for hardware degradation ahead of the time. This is beyond of our control as it happens at AWS level. Whenever due to hardware degradation the instance goes out of the service, we have instance status check alerts configured. However, this becomes too late in your case as your production or staging site goes down because of all dependency on the single node. The only way to bring the environment back up and running is to perform a stop and start of the instance. Internally, AWS moves the instance from the degraded hardware to the healthy hardware, and your instance is up and running.The best way to mitigate this situation is to design for failure, i.e., high availability at every layer of the architecture and de-coupling between the layers. I believe we are on right track as we plan to add multiple web instances behind ELB/WAF layer. This will ensure whenever an instance goes down, the WAF/ELB layer will stop sending any request to the unhealthy node, and all requests will be directed to the healthy one.Also, I believe we are also considering the use of elasticache or redis. This will take away the session management dependency from the web layer providing the seamless experience to your users.We are already working on a plan for your design to not only achieve high availability at every layer but also enable complete segregation between the environment. I'll review the document and share with you by Tuesday.###For the hardware degradation, we will be getting the alerts as status check failure so we can inform the same to the customer as we do. But to avoid this from impacting downtime in production, we need to use ELB and auto scaling groups so that in the case of a single instance status check failure, the clones will be available to serve the data so the application will not be affected.In the case of SpendHQ, the servers are mounted with ISCSI volumes and also the application is enabled WAF protection, the above suggestion may not be implemented. So to be clear, we need to discuss this with CE2/CE3 and act accordingly.###Hello Matthew,We will look into this query and will come up with recommendations.","Due to the recent failures that we have had with the PRD Servers, I would like to see if you are able to notify us when hardware degradation is noticed to help mitigate downtime to our end users? What can we do to mitigate these failures from affecting live traffic in the future and what do you recommend are the next steps for us to take in this respect.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS Hardware Failures,,04-02-2017 02:01,1506,0,SpendHQ,"As per the discussion on evening OPS call, we are closing this case.","Sanket provided following details to Darren.Our idea behind adding high availability at every layer of the architecture aligns with the recommendation that rather than vertical scaling, we design our architecture for horizontal scaling. So, if we are using c4.xlarge instance at our web layer, we should break it into two c4.large instances which span across multiple availability zones. It will ensure our cost remains the same while we achieve high availability for our architecture. Also, the high availability architecture will be in active-active mode rather than the active-passive mode, so your end-users are not impacted.We can further improve by adding auto-scaling capabilities. Auto-scaling ensures your number of nodes scale up during peak hours and come down to the minimum during off hours. It turns out to a cheaper option rather than running a high compute underutilised node during off hours. Rest assured, our architecture design with high availability does factor in the cost part, and we will do our best to minimise your cost. The only thing we need to figure out is your network bandwidth requirement and whether chosen instance type supports it or not.Lastly, we do understand the sensitivity of these hardware failures. As of now, AWS doesn't have a mechanism to alert us ahead of time to prevent this issue. During previous hardware failure, we did reach out to AWS team and got a response that they work hard to minimise these hardware failures, but it is not immune from these failures.Unfortunately, it is very hard to write down all thoughts in an email, but we do understand your concern and will do best to help you. We do have our bi-weekly call scheduled for next week. However, we can certainly have a call this week to get into a deeper discussion and finalise the design which can help us to mitigate any such issues keeping your cost intact.",Assigning ticket to Sanket.,"Darren replied that Thank you, Sanket for taking the time to respond over the weekend. I understand your comment, and we are already designing some failure recovery points, but I would like us to discuss the general comment a bit more. In short, if I understand, you are stating that because hardware fails, we should spend more money to protect ourselves from the hardware failure. In the cloud world, that seems incomplete logic. To us, one of the benefits of using AWS is so that we don’t have to worry about hardware failure. In reality, we have had many more hardware failures in the past year than we did in the history of the company prior to the move. If AWS hardware is likely to fail, there should be some protection provided to us other than just constantly spending more money. If we go to a full failover environment, do we need to have a fully redundant system in case our DR hardware fails? What if that fails? I have confident that if we would have bought all of these machines and put them in our DC that we would not have experience four hardware failures in 12 months. If I need to rent 20 machines to ensure that I have 15 fully operational, that deteriorates the cloud value proposition considerably. Please understand – not trying to be overly critical – just trying to make sure we are synchronized in our expectations. I will have Andrew Kim follow up on this thread to discuss next steps.","Hello Matthew,We have received an email from your out of office mail box that you are not available till 13th Feb.Hence we are marking this case as resolved as of now.Once you are back and if there are any comments, let us know.We will re-open the case.",Sanket has updated that he has received an email from Matthew out of office mail box that he is not available till Feb 13th,"Sanket replied  that,Hi Matthew,There is no way that we can get alerted for hardware degradation ahead of the time. This is beyond of our control as it happens at AWS level. Whenever due to hardware degradation the instance goes out of the service, we have instance status check alerts configured. However, this becomes too late in your case as your production or staging site goes down because of all dependency on the single node. The only way to bring the environment back up and running is to perform a stop and start of the instance. Internally, AWS moves the instance from the degraded hardware to the healthy hardware, and your instance is up and running.The best way to mitigate this situation is to design for failure, i.e., high availability at every layer of the architecture and de-coupling between the layers. I believe we are on right track as we plan to add multiple web instances behind ELB/WAF layer. This will ensure whenever an instance goes down, the WAF/ELB layer will stop sending any request to the unhealthy node, and all requests will be directed to the healthy one.Also, I believe we are also considering the use of elasticache or redis. This will take away the session management dependency from the web layer providing the seamless experience to your users.We are already working on a plan for your design to not only achieve high availability at every layer but also enable complete segregation between the environment. I'll review the document and share with you by Tuesday.","For the hardware degradation, we will be getting the alerts as status check failure so we can inform the same to the customer as we do. But to avoid this from impacting downtime in production, we need to use ELB and auto scaling groups so that in the case of a single instance status check failure, the clones will be available to serve the data so the application will not be affected.In the case of SpendHQ, the servers are mounted with ISCSI volumes and also the application is enabled WAF protection, the above suggestion may not be implemented. So to be clear, we need to discuss this with CE2/CE3 and act accordingly.","Hello Matthew,We will look into this query and will come up with recommendations.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BX23D,Cloud Engineer Level 1,Closed,1049811,Incident,27-04-2017 02:31,,"Hello SpendHQ Team,This is to inform you that the site down alert for the url  https://preview.spendhq.com/login is resolved and the page is loading fine now. This issue happened due to the change made in preview.spendhq.com load balancer. As per the request from David, we pointed preview.spendhq.com load balancer to 10.59.100.94. We have rectified the configuration issue and the page is now loading fine. Matthew has already confirmed that the site is up and running.As of now we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Hello SpendHQ Team,This is to inform you that we received an alert regarding site is down for the URL https://preview.spendhq.com/login . We are investigating the alert and will get back to you with updates.","Wed, 26 Apr 2017 15:32:02 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Sydney-C AU, Atlanta-B US, Dallas-B US, Frankfurt DE-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,27-04-2017 01:02,2,0,SpendHQ,"Hello SpendHQ Team,This is to inform you that the site down alert for the url  https://preview.spendhq.com/login is resolved and the page is loading fine now. This issue happened due to the change made in preview.spendhq.com load balancer. As per the request from David, we pointed preview.spendhq.com load balancer to 10.59.100.94. We have rectified the configuration issue and the page is now loading fine. Matthew has already confirmed that the site is up and running.As of now we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Hello SpendHQ Team,This is to inform you that we received an alert regarding site is down for the URL https://preview.spendhq.com/login . We are investigating the alert and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bkHNP,Cloud Engineer Level 2,Closed,1104658,Incident,20-09-2018 12:09,,"As per the discussion with Chirodeep we are marking this case as closed.###Hello Team,During ops call, we discussed this case with Rohit team. As per the discussion, we figured out that the alert is triggering even the SG are in use. So Chirodeep mentioned he will check with DevOps team on this.###from Kapil: All defaults are deleted which are not in use or attached.Next action : check with Rohit###@team updated the sheet.###@Team,I have created a sheet below is the link for that, associated resource details are mentioned in that please proceed to complete it.https://docs.google.com/spreadsheets/d/11JvL1rX8mgadpgVTNYSC0ynXJBnTgD6ywN3sbaKjg-o/edit#gid=0###@Team,The above mentioned SG's cannot be deleted as either they are associated with running instances or referenced to other security groups and others are default security groups for specific regions. See below a document with all the details:https://docs.google.com/spreadsheets/d/1RN-KsZpY5wbfka2_EWdYfGpOdNPMMAyAB6gr5teQ0lY/edit?usp=sharing###praveen.muppala@reancloud.comFri, Sep 14, 5:35 PM (4 days ago)to Rean, spendhq-supportHello Team, Please clean up all this SG’s","Hello Team, Please clean up all this SG’s From: ms@reancloud.com <ms@reancloud.com> Sent: September 14, 2018 10:07 AMTo: spendhq-support@reancloud.comSubject: [Managed Cloud: spendhq] Unused Security Groups Alert REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud. The following AWS::EC2::SecurityGroup resources were affected:   _____  *	Violation: Security group is not in use.*	Recommendation: None*	Action taken: None*	Resource details: Resource IDNameRegionVPC IDsg-04f3d661	ap-northeast-1vpc-9df273f8sg-055fbd6c	ap-northeast-2vpc-647a9c0dsg-39c82750	ap-south-1vpc-4337d72asg-d33676b6	ap-southeast-1vpc-4aac132fsg-595e093c	ap-southeast-2vpc-bfbf06dasg-f150b998	ca-central-1vpc-78876a11sg-b00369d9	eu-central-1vpc-5245c33bsg-f575d591	eu-west-1vpc-46fa8823sg-cbaf40a2	eu-west-2vpc-751bfb1csg-ccad79a5	eu-west-3vpc-3c2bd455sg-f491f291	sa-east-1vpc-927c38f7sg-0ce80c7c	us-east-1vpc-76df7212sg-161a8170	us-east-1vpc-76df7212sg-1a79b968	us-east-1vpc-76df7212sg-23e35e68	us-east-1vpc-7837d002sg-3732f349	us-east-1vpc-76df7212sg-3e849776	us-east-1vpc-76df7212sg-47f94b30	us-east-1vpc-76df7212sg-4d86243d	us-east-1vpc-76df7212sg-4efc4c38	us-east-1vpc-76df7212sg-51597223	us-east-1vpc-76df7212sg-559fe82fDB2-Clone Security Groupus-east-1vpc-76df7212sg-5a5c7728	us-east-1vpc-76df7212sg-5c63bd3aSPENDHQEastus-east-1vpc-76df7212sg-6663bd00	us-east-1vpc-76df7212sg-6723e02f	us-east-1vpc-76df7212sg-772cfe00	us-east-1vpc-76df7212sg-79b5760b	us-east-1vpc-76df7212sg-7d73ae0c	us-east-1vpc-76df7212sg-855a34e3	us-east-1vpc-76df7212sg-9e869fd5	us-east-1vpc-76df7212sg-b18c9ff9	us-east-1vpc-76df7212sg-b70469ce	us-east-1vpc-76df7212sg-b7775cc5	us-east-1vpc-76df7212sg-ba1f5dc4	us-east-1vpc-76df7212sg-be8093f6	us-east-1vpc-76df7212sg-c8baaeb8	us-east-1vpc-76df7212sg-c99f43b8	us-east-1vpc-76df7212sg-d24598aa	us-east-1vpc-76df7212sg-e79089ac	us-east-1vpc-76df7212sg-e9811f9f	us-east-1vpc-76df7212sg-ec30819a	us-east-1vpc-76df7212sg-f60d9f83PRD-New-Centos-7-ELB-SGus-east-1vpc-76df7212sg-fc00c68d	us-east-1vpc-76df7212sg-8d709ae4	us-east-2vpc-4939d520sg-43e8a626	us-west-1vpc-bf04b9dasg-c23b8da6	us-west-1vpc-e76a3982sg-c63b8da2	us-west-1vpc-e76a3982sg-abcfbdcf	us-west-2vpc-9c3965f9sg-e087ea84	us-west-2vpc-43cc9826  _____  Best Regards, REAN Cloud Team IMPORTANT: Please do not reply to this message or email address. --  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: [Managed Cloud: spendhq] Unused Security Groups Alert,,14-09-2018 20:05,136,0,SpendHQ,As per the discussion with Chirodeep we are marking this case as closed.,"Hello Team,During ops call, we discussed this case with Rohit team. As per the discussion, we figured out that the alert is triggering even the SG are in use. So Chirodeep mentioned he will check with DevOps team on this.",from Kapil: All defaults are deleted which are not in use or attached.Next action : check with Rohit,@team updated the sheet.,"@Team,I have created a sheet below is the link for that, associated resource details are mentioned in that please proceed to complete it.https://docs.google.com/spreadsheets/d/11JvL1rX8mgadpgVTNYSC0ynXJBnTgD6ywN3sbaKjg-o/edit#gid=0","@Team,The above mentioned SG's cannot be deleted as either they are associated with running instances or referenced to other security groups and others are default security groups for specific regions. See below a document with all the details:https://docs.google.com/spreadsheets/d/1RN-KsZpY5wbfka2_EWdYfGpOdNPMMAyAB6gr5teQ0lY/edit?usp=sharing","praveen.muppala@reancloud.comFri, Sep 14, 5:35 PM (4 days ago)to Rean, spendhq-supportHello Team, Please clean up all this SG’s",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DnvRg,Cloud Engineer Level 1,Closed,1065719,Incident,30-06-2017 05:31,,"Hi SpendHQ-Team,This is to inform you that the volume usage for PROD-SPHQ-DB-SERVER05 instance has resolved and returned to normal with a value 67.8%###Hi SpendHQ-Team, On further analysis, we could see that /dev/xvda1 mounted on / is consuming high volume. Please find the volume usage details[root@ip-10-59-10-135 centos]# df -hTFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   44G  2.6G  95% /Please find the volume usage in / 44G     total18G     usr13G     tmp12G     var474M    home285M    lib282M    opt44M     boot/tmp13G     total6.2G    liger_view_44a76ee08eb2d63d67d7d82d4a6c31e9.csv2.0G    liger_view_49a1f163738b393116cd8f14c6e67c4b.csv1.8G    liger_view_117338120d15765bbe94808db6f99d39.csv358M    liger_view_a54144ed50626138b74aa224e74e6c67.csv358M    liger_view_66f0212a4195cd09147cae24c81a61ee.csv308M    liger_view_ef447944146a6943ab7fd9a71b3ce51c.csv226M    liger_view_f752167fca2ecaf38964ffaff639b8d8.csv226M    liger_view_3db0c81b0a25ab06af83bde59115dd4b.csv221M    spark-2.1.0-bin-hadoop2.7192M    liger_view_8880c379fff9b9e04006847551f412f8.csv151M    liger_view_ac8831499783d6c81588ecdce5de17bc.csv151M    liger_view_2d921b4e03367502f3bd8700a8c38de7.csv78M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm68M     liger_view_adcbe9aa405106ec1a7895c8f2d3dac0.csv49M     reports38M     liger_view_c6902b33cfa4abf14dde5b6039064553.csv27M     spark-351c878d-7245-4f00-affa-34d5deff741412M     pgloader-3.3.212M     mysql-connector-java-5.1.415.0M    gases_report.csv4.9M    percona-toolkit-3.0.2-r462c006-el6-x86_64-bundle.tar4.9M    percona-toolkit-3.0.2-1.el6.x86_64.rpm4.2M    v3.3.2.zip4.0M    metastore_db2.1M    spark-0728cb94-5e6a-4745-97ee-df688c34ebde1.6M    monitor.json692K    postgresql-42.0.0.jar664K    postgresql-9.4.1211.jar660K    spark-10741b8c-0854-4a20-bc5a-30348146c02f192K    spark-89bf9420-3c54-4f70-840a-27220d2a3bac192K    spark-21a1c472-1e22-4c78-bd16-8e35340ca38760K     liblz4-java9216094424446269217.so28K     import_controller.rb24K     xlsx2csv.py24K     hive16K     doug-one.csv12K     spark-a9d9fd92-65ad-45ac-9cfb-a69080b9948512K     spark-73e49063-d6e7-4016-9c3f-35bed12e688012K     output.csv12K     newcars.csv12K     mwatts12K     blockmgr-939d915a-bf82-4039-89cc-ad8bceb86e2c8.0K    bhload-info-82696-1496866253-144.bhl_report4.0K    watts4.0K    tiger_test.csv4.0K    steven.txt4.0K    stackextractzTL4RI4.0K    spark4.0K    sbt_9ec560e94.0K    sbt2837550324044363793.log4.0K    psql.log4.0K    ib4.9.0-0-install.log4.0K    hsperfdata_memsql4.0K    fc9a61de-4471-4ffe-b5ea-6788f45aff56_resources4.0K    f239a42a-9007-4faa-ab9a-6a9de8c19ecd_resources4.0K    ef85da34-4288-4dd5-a38c-0193aff633f0_resources4.0K    e8b6dcd8-98a9-45e0-833f-1868792ff9bc_resources4.0K    derby.log4.0K    c25e60c2-e1ae-4e28-b260-0dfddfb4b0a6_resources4.0K    blockmgr-eacfdd52-cd30-42ad-8fa9-8eb9639c9c2c4.0K    blockmgr-e9d26ecc-5e06-4dc5-bdc5-c4f77ed248e84.0K    blockmgr-cdf6a61d-b9b2-4131-aaa4-6592f131d1014.0K    blockmgr-bff0afd8-7324-41d7-9c15-74f08174665e4.0K    blockmgr-88b0d845-7c3d-4129-99ba-87783bb12ffc4.0K    bhload-info-83480-1497095465-447.bhl_report4.0K    bhload-info-83480-1497095465-447/usr 18G     total17G     local882M    share813M    lib130M    lib6459M     bin16M     sbinPlease delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.###Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 93.571This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3934033303389644505 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,29-06-2017 20:48,9,0,SpendHQ,"Hi SpendHQ-Team,This is to inform you that the volume usage for PROD-SPHQ-DB-SERVER05 instance has resolved and returned to normal with a value 67.8%","Hi SpendHQ-Team, On further analysis, we could see that /dev/xvda1 mounted on / is consuming high volume. Please find the volume usage details[root@ip-10-59-10-135 centos]# df -hTFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   44G  2.6G  95% /Please find the volume usage in / 44G     total18G     usr13G     tmp12G     var474M    home285M    lib282M    opt44M     boot/tmp13G     total6.2G    liger_view_44a76ee08eb2d63d67d7d82d4a6c31e9.csv2.0G    liger_view_49a1f163738b393116cd8f14c6e67c4b.csv1.8G    liger_view_117338120d15765bbe94808db6f99d39.csv358M    liger_view_a54144ed50626138b74aa224e74e6c67.csv358M    liger_view_66f0212a4195cd09147cae24c81a61ee.csv308M    liger_view_ef447944146a6943ab7fd9a71b3ce51c.csv226M    liger_view_f752167fca2ecaf38964ffaff639b8d8.csv226M    liger_view_3db0c81b0a25ab06af83bde59115dd4b.csv221M    spark-2.1.0-bin-hadoop2.7192M    liger_view_8880c379fff9b9e04006847551f412f8.csv151M    liger_view_ac8831499783d6c81588ecdce5de17bc.csv151M    liger_view_2d921b4e03367502f3bd8700a8c38de7.csv78M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm68M     liger_view_adcbe9aa405106ec1a7895c8f2d3dac0.csv49M     reports38M     liger_view_c6902b33cfa4abf14dde5b6039064553.csv27M     spark-351c878d-7245-4f00-affa-34d5deff741412M     pgloader-3.3.212M     mysql-connector-java-5.1.415.0M    gases_report.csv4.9M    percona-toolkit-3.0.2-r462c006-el6-x86_64-bundle.tar4.9M    percona-toolkit-3.0.2-1.el6.x86_64.rpm4.2M    v3.3.2.zip4.0M    metastore_db2.1M    spark-0728cb94-5e6a-4745-97ee-df688c34ebde1.6M    monitor.json692K    postgresql-42.0.0.jar664K    postgresql-9.4.1211.jar660K    spark-10741b8c-0854-4a20-bc5a-30348146c02f192K    spark-89bf9420-3c54-4f70-840a-27220d2a3bac192K    spark-21a1c472-1e22-4c78-bd16-8e35340ca38760K     liblz4-java9216094424446269217.so28K     import_controller.rb24K     xlsx2csv.py24K     hive16K     doug-one.csv12K     spark-a9d9fd92-65ad-45ac-9cfb-a69080b9948512K     spark-73e49063-d6e7-4016-9c3f-35bed12e688012K     output.csv12K     newcars.csv12K     mwatts12K     blockmgr-939d915a-bf82-4039-89cc-ad8bceb86e2c8.0K    bhload-info-82696-1496866253-144.bhl_report4.0K    watts4.0K    tiger_test.csv4.0K    steven.txt4.0K    stackextractzTL4RI4.0K    spark4.0K    sbt_9ec560e94.0K    sbt2837550324044363793.log4.0K    psql.log4.0K    ib4.9.0-0-install.log4.0K    hsperfdata_memsql4.0K    fc9a61de-4471-4ffe-b5ea-6788f45aff56_resources4.0K    f239a42a-9007-4faa-ab9a-6a9de8c19ecd_resources4.0K    ef85da34-4288-4dd5-a38c-0193aff633f0_resources4.0K    e8b6dcd8-98a9-45e0-833f-1868792ff9bc_resources4.0K    derby.log4.0K    c25e60c2-e1ae-4e28-b260-0dfddfb4b0a6_resources4.0K    blockmgr-eacfdd52-cd30-42ad-8fa9-8eb9639c9c2c4.0K    blockmgr-e9d26ecc-5e06-4dc5-bdc5-c4f77ed248e84.0K    blockmgr-cdf6a61d-b9b2-4131-aaa4-6592f131d1014.0K    blockmgr-bff0afd8-7324-41d7-9c15-74f08174665e4.0K    blockmgr-88b0d845-7c3d-4129-99ba-87783bb12ffc4.0K    bhload-info-83480-1497095465-447.bhl_report4.0K    bhload-info-83480-1497095465-447/usr 18G     total17G     local882M    share813M    lib130M    lib6459M     bin16M     sbinPlease delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.","Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Kr0zg,Cloud Engineer Level 1,Closed,1085764,Incident,04-12-2017 10:04,,"Hello Team,The alert got resolved automatically and has reduced to a value of 1.91. Let us know if you have any further queries.###Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.25. The mysql process was consuming the usage. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1We are analyzing more on this and get back to you with details.","[Triggered] [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over datadog_monitor:on,host:i-03ccfddd9f02cacb9 was > 3.0 on average during the last 5m.Metric value: 3.322This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=4162381505402841287 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prd-db1 - 10.59.10.190 - db,,04-12-2017 09:32,1,0,SpendHQ,"Hello Team,The alert got resolved automatically and has reduced to a value of 1.91. Let us know if you have any further queries.","Hello Team, This is to notify you that we got an alert regarding High CPU Load prd-db1 - 10.59.10.190. The alert has crossed the threshold of 3 and has reached a value of 4.25. The mysql process was consuming the usage. Resource Details: Name:prd-db1 Instance-type:r4.8xlarge Region:us-east-1We are analyzing more on this and get back to you with details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013vuaK,Cloud Engineer Level 1,Closed,1030975,Incident,,,,"New Firmware Up2Dates have been installed. The current firmware versionis now 9.406003.        -- System Uptime      : 168 days 2 hours 7 minutesSystem Load        : 0.85System Version     : Sophos UTM 9.406-3Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][INFO-302] New Firmware Up2Date installed,,12-11-2016 13:10,0,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016qxVS,Cloud Engineer Level 1,Closed,1042599,Incident,30-01-2017 14:18,,"Step to change iSCSI Initiator names link: https://reancloud.atlassian.net/wiki/display/CUS/Step+to+change+iSCSI+Initiator+names###Hello SpendHQ Team,We have confirmed that the iscsi errors are not happening after the service restart.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM###Hi Team,We have performed the restart of iscsi service and let us know if you are facing any issues.###Hi Team,We are going to perform the restart of  iscsi service and let you know the updates.###Hello Steven,Thanks for the confirmation.We will perform the restart on PROD-SPHQ-DB-SERVER05 and PROD-SPHQ-DB-SERVER03 on Sunday 9PM EST (Monday 7:30AM IST).Please let us know if you have any more queries regarding this.###Go ahead and do the restart for the .135 machine and PROD-SPHQ-DB-SERVER05 today (2017-01-29) at 9pmThank you.###Hello SpendHQ Team,This is a gentle reminder.Please let us know whether we can go ahead and restart the iscsi service.###Hello SpendHQ Team, We haven't heard back from you.Please provide us an approval for restarting the iscsi service.###Sudheer is verifying the initiator names and configuration on all instances.  He also updated that we have to restart the ISCSI service.###Hello SpendHQ Team,This is a gentle reminder since we haven't heard back from you regarding this issue.We are waiting for your approval to restart the iscsi service. Please let us know if you have any queries regarding this issue.###Hello SpendHQ Team,While investigating further on this issue, the initiator names seem unique across all machines and for PROD-SPHQ-DB-SERVER05 it's “iqn.1994-05.com.redhat:64d02cf7e3df”. But from the iscsi service status, the Iface Initiatorname seems different from what we saw in the initiator name file. i.e., “iqn.1994-05.com.redhat:64d02cf6d2ce”.The same issue is present in the PROD-SPHQ-DB-SERVER03 also.To resolve this issue, we have to perform an iscsi service restart on both of the machines. Please let us know if we have your approval to do the same and please suggest if you have any specific time frame.###The initiator name seems unique across all machines and for 10-135 it's as below[root@ip-10-59-10-135 ~]# cat /etc/iscsi/initiatorname.iscsiInitiatorName=iqn.1994-05.com.redhat:64d02cf7e3dfBut from the iscsi service configuration details, the Iface Initiatorname seems different from what we saw above.[root@ip-10-59-10-135 ~]# /etc/init.d/iscsi status | grep Iface Initiatorname                Iface Initiatorname: iqn.1994-05.com.redhat:64d02cf6d2ceAs we are aware of the initiator name change done by us recently, I checked the iscsi process uptime to verify the service restart was performed or not, we could see the uptime is more than 47 days.[root@ip-10-59-10-135 ~]# ps -eo pid,comm,lstart,etime,time,args | grep iscsi  1520 iscsid          Fri Dec  9 21:46:20 2016 47-08:07:15 00:01:46 iscsidThis indicates that the initiator name change performed didn’t got applied on the already running iscsi service and existing connections. To make the change applied, we should restart the iscsi and iscsi daemon so to resolve this error messages popping up.The error messages are indicating to the 10-91 node.[root@ip-10-59-10-135 ~]# tail /var/log/messagesJan 26 05:59:52 ip-10-59-10-91 iscsid: Kernel reported iSCSI connection 4:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Jan 26 05:59:55 ip-10-59-10-91 iscsid: connection4:0 is operational after recovery (1 attempts)As this node was the one we kept unchanged while fixing the initiator name conflict so there were no issues with the initiator name but we took a look into the /var/log/messages and found that the same error messages are popping up.[root@ip-10-59-10-91 ~]# tail /var/log/messagesJan 26 06:07:37 ip-10-59-10-148 iscsid: Kernel reported iSCSI connection 4:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Jan 26 06:07:38 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Jan 26 06:07:39 ip-10-59-10-148 iscsid: connection2:0 is operational after recovery (1 attempts)The errors indicating to the node 10-148. From 10-148, we could see the initiator name conflict.[root@ip-10-59-10-148 ~]# cat /etc/iscsi/initiatorname.iscsiInitiatorName=iqn.1994-05.com.redhat:201701140148[root@ip-10-59-10-148 ~]# /etc/init.d/iscsi status | grep Iface Initiatorname                Iface Initiatorname: iqn.1994-05.com.redhat:64d02cf6d2ceWe realise this was the one node which we did the initiator name change but didn’t perform a service restart at that time. We have verified this from the below output that the service is up and running since last 125 days.[root@ip-10-59-10-148 ~]# ps -eo pid,comm,lstart,etime,time,args | grep iscsi  2069 iscsid          Thu Sep 22 15:48:21 2016 125-14:20:26 00:02:19 iscsidThis indicates the iscsi connections are up and running for last 125 days or more. So the changes made from us does not applied as we haven’t restarted the /etc/init.d/iscsi service but instead of this we restarted /etc/init.d/iscsid service. So to resolve this issue, we have to restart the /etc/init.d/iscsi service on the instances which wherever we see the error messages. Specifically for the reported issue, we could resolve this by restarting the service in node 10-148 then in 10-135.Please get this reviewed by any CE2 and share with customer.###Hi Team,We have checked for all the instances and 10.59.10.135 instance is not having any same initiator with other still we are having this error.Since the iscsi is mounted there will be a need to restart the iscsi service. Please check with sudheer and update the client regarding the details.###Hello Andrew,We are currently verifying the iscsi initiator names. We will let you know the updates.","Hello, we’re seeing iscsi errors Jan 25 21:09:07 ip-10-59-10-91 iscsid: connection2:0 is operational after recovery (1 attempts)Jan 25 21:09:07 ip-10-59-10-91 iscsid: connection4:0 is operational after recovery (1 attempts)Jan 25 21:09:09 ip-10-59-10-91 kernel: connection4:0: detected conn error (1020)Jan 25 21:09:09 ip-10-59-10-91 kernel: connection2:0: detected conn error (1020)Jan 25 21:09:09 ip-10-59-10-91 iscsid: Kernel reported iSCSI connection 4:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Jan 25 21:09:09 ip-10-59-10-91 iscsid: Kernel reported iSCSI connection 2:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Please change the iqn names to resolve. You can also reference case I-01042179.",iscsid errors on 10.59.10.135,,26-01-2017 03:40,102,0,SpendHQ,Step to change iSCSI Initiator names link: https://reancloud.atlassian.net/wiki/display/CUS/Step+to+change+iSCSI+Initiator+names,"Hello SpendHQ Team,We have confirmed that the iscsi errors are not happening after the service restart.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM","Hi Team,We have performed the restart of iscsi service and let us know if you are facing any issues.","Hi Team,We are going to perform the restart of  iscsi service and let you know the updates.","Hello Steven,Thanks for the confirmation.We will perform the restart on PROD-SPHQ-DB-SERVER05 and PROD-SPHQ-DB-SERVER03 on Sunday 9PM EST (Monday 7:30AM IST).Please let us know if you have any more queries regarding this.",Go ahead and do the restart for the .135 machine and PROD-SPHQ-DB-SERVER05 today (2017-01-29) at 9pmThank you.,"Hello SpendHQ Team,This is a gentle reminder.Please let us know whether we can go ahead and restart the iscsi service.","Hello SpendHQ Team, We haven't heard back from you.Please provide us an approval for restarting the iscsi service.",Sudheer is verifying the initiator names and configuration on all instances.  He also updated that we have to restart the ISCSI service.,"Hello SpendHQ Team,This is a gentle reminder since we haven't heard back from you regarding this issue.We are waiting for your approval to restart the iscsi service. Please let us know if you have any queries regarding this issue.","Hello SpendHQ Team,While investigating further on this issue, the initiator names seem unique across all machines and for PROD-SPHQ-DB-SERVER05 it's “iqn.1994-05.com.redhat:64d02cf7e3df”. But from the iscsi service status, the Iface Initiatorname seems different from what we saw in the initiator name file. i.e., “iqn.1994-05.com.redhat:64d02cf6d2ce”.The same issue is present in the PROD-SPHQ-DB-SERVER03 also.To resolve this issue, we have to perform an iscsi service restart on both of the machines. Please let us know if we have your approval to do the same and please suggest if you have any specific time frame.","The initiator name seems unique across all machines and for 10-135 it's as below[root@ip-10-59-10-135 ~]# cat /etc/iscsi/initiatorname.iscsiInitiatorName=iqn.1994-05.com.redhat:64d02cf7e3dfBut from the iscsi service configuration details, the Iface Initiatorname seems different from what we saw above.[root@ip-10-59-10-135 ~]# /etc/init.d/iscsi status | grep Iface Initiatorname                Iface Initiatorname: iqn.1994-05.com.redhat:64d02cf6d2ceAs we are aware of the initiator name change done by us recently, I checked the iscsi process uptime to verify the service restart was performed or not, we could see the uptime is more than 47 days.[root@ip-10-59-10-135 ~]# ps -eo pid,comm,lstart,etime,time,args | grep iscsi  1520 iscsid          Fri Dec  9 21:46:20 2016 47-08:07:15 00:01:46 iscsidThis indicates that the initiator name change performed didn’t got applied on the already running iscsi service and existing connections. To make the change applied, we should restart the iscsi and iscsi daemon so to resolve this error messages popping up.The error messages are indicating to the 10-91 node.[root@ip-10-59-10-135 ~]# tail /var/log/messagesJan 26 05:59:52 ip-10-59-10-91 iscsid: Kernel reported iSCSI connection 4:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Jan 26 05:59:55 ip-10-59-10-91 iscsid: connection4:0 is operational after recovery (1 attempts)As this node was the one we kept unchanged while fixing the initiator name conflict so there were no issues with the initiator name but we took a look into the /var/log/messages and found that the same error messages are popping up.[root@ip-10-59-10-91 ~]# tail /var/log/messagesJan 26 06:07:37 ip-10-59-10-148 iscsid: Kernel reported iSCSI connection 4:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Jan 26 06:07:38 ip-10-59-10-148 iscsid: conn 0 login rejected: initiator error (02/04)Jan 26 06:07:39 ip-10-59-10-148 iscsid: connection2:0 is operational after recovery (1 attempts)The errors indicating to the node 10-148. From 10-148, we could see the initiator name conflict.[root@ip-10-59-10-148 ~]# cat /etc/iscsi/initiatorname.iscsiInitiatorName=iqn.1994-05.com.redhat:201701140148[root@ip-10-59-10-148 ~]# /etc/init.d/iscsi status | grep Iface Initiatorname                Iface Initiatorname: iqn.1994-05.com.redhat:64d02cf6d2ceWe realise this was the one node which we did the initiator name change but didn’t perform a service restart at that time. We have verified this from the below output that the service is up and running since last 125 days.[root@ip-10-59-10-148 ~]# ps -eo pid,comm,lstart,etime,time,args | grep iscsi  2069 iscsid          Thu Sep 22 15:48:21 2016 125-14:20:26 00:02:19 iscsidThis indicates the iscsi connections are up and running for last 125 days or more. So the changes made from us does not applied as we haven’t restarted the /etc/init.d/iscsi service but instead of this we restarted /etc/init.d/iscsid service. So to resolve this issue, we have to restart the /etc/init.d/iscsi service on the instances which wherever we see the error messages. Specifically for the reported issue, we could resolve this by restarting the service in node 10-148 then in 10-135.Please get this reviewed by any CE2 and share with customer.","Hi Team,We have checked for all the instances and 10.59.10.135 instance is not having any same initiator with other still we are having this error.Since the iscsi is mounted there will be a need to restart the iscsi service. Please check with sudheer and update the client regarding the details.","Hello Andrew,We are currently verifying the iscsi initiator names. We will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Tl9A1,Cloud Engineer Level 1,Closed,1094411,Incident,03-04-2018 23:49,,"Hello Andrew,Thanks for the update we have blocked the IP.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Yes, please block and and close this ticket. Thank you###Hello Team,This is a gentle reminder.Please review the previous comment and let us know if you have any queries.###Hello Team,We haven't heard back from you.We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.172 which belongs to the preview-spendhq-xelb Please find the Intrusion Prevention Logs: 2018:03:27-18:31:54 spendhq snort[18763]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.172 dstip=10.59.1.192 proto=6 srcport=41757 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0 On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 180.151.83.30 which belongs to the organization - Shyam Spectra Pvt Ltd was trying to execute the Oracle WebLogic Server Remote Code Execution. This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. Find the ELB logs details below, 2018-03-27T18:32:09.845836Z preview-spendhq-xelb 180.151.83.30:6269 10.59.1.192:80 0.000047 0.0015 0.000023 403 403 0 218 GET http://34.237.188.40:80/index.php HTTP/1.1 Mozilla/5.0 - - Please review the details and let us know if you want us to block this IP.###Hello SpendHQ Team,Did you get a chance to review the case comments and provide your feedback. We are waiting for your approval to block the reported IP in here. Please feel free to reach out to us for any queries.This is to inform you that we have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.172 which belongs to the preview-spendhq-xelb Please find the Intrusion Prevention Logs: 2018:03:27-18:31:54 spendhq snort[18763]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.172 dstip=10.59.1.192 proto=6 srcport=41757 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0 On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 180.151.83.30 which belongs to the organization - Shyam Spectra Pvt Ltd was trying to execute the Oracle WebLogic Server Remote Code Execution. This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. Find the ELB logs details below, 2018-03-27T18:32:09.845836Z preview-spendhq-xelb 180.151.83.30:6269 10.59.1.192:80 0.000047 0.0015 0.000023 403 403 0 218 GET http://34.237.188.40:80/index.php HTTP/1.1 Mozilla/5.0 - - Please review the details and let us know if you want us to block this IP.###Hello Team, This is to inform you that we have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.172 which belongs to the preview-spendhq-xelb Please find the Intrusion Prevention Logs: 2018:03:27-18:31:54 spendhq snort[18763]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.172 dstip=10.59.1.192 proto=6 srcport=41757 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP  180.151.83.30 which belongs to the organization - Shyam Spectra Pvt Ltd was trying to execute the Oracle WebLogic Server Remote Code Execution. This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. Find the ELB logs details below, 2018-03-27T18:32:09.845836Z preview-spendhq-xelb 180.151.83.30:6269 10.59.1.192:80 0.000047 0.0015 0.000023 403 403 0 218 GET http://34.237.188.40:80/index.php HTTP/1.1 Mozilla/5.0 - -Please review the details and let us know if you want us to block this IP.","Thanks & Regards,Anjali G NairHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>anjali.gopinadhan@reancloud.com <kriti@reancloud.com> | +91-7702500499 |www.reancloud.com <http://www.reancloudsolutions.com/>---------- Forwarded message ----------From: Firewall Notification System <manage-spendhq@reancloud.com>Date: Wed, Mar 28, 2018 at 12:01 AMSubject: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped)To: event-5domgd23@dtdg.co, spendhq-support@reancloud.com, ms@reancloud.comIntrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-ORACLE Oracle WebLogic Server remote commandexecution attemptDetails........: https://www.snort.org/search?query=45304Time...........: 2018-03-27 18:31:54Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.172Source port: 41757Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 92 days 11 hours 29 minutesSystem Load        : 0.11System Version     : Sophos UTM 9.506-2Please refer to the manual for detailed instructions.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,28-03-2018 00:03,168,0,SpendHQ,"Hello Andrew,Thanks for the update we have blocked the IP.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Yes, please block and and close this ticket. Thank you","Hello Team,This is a gentle reminder.Please review the previous comment and let us know if you have any queries.","Hello Team,We haven't heard back from you.We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.172 which belongs to the preview-spendhq-xelb Please find the Intrusion Prevention Logs: 2018:03:27-18:31:54 spendhq snort[18763]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.172 dstip=10.59.1.192 proto=6 srcport=41757 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0 On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 180.151.83.30 which belongs to the organization - Shyam Spectra Pvt Ltd was trying to execute the Oracle WebLogic Server Remote Code Execution. This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. Find the ELB logs details below, 2018-03-27T18:32:09.845836Z preview-spendhq-xelb 180.151.83.30:6269 10.59.1.192:80 0.000047 0.0015 0.000023 403 403 0 218 GET http://34.237.188.40:80/index.php HTTP/1.1 Mozilla/5.0 - - Please review the details and let us know if you want us to block this IP.","Hello SpendHQ Team,Did you get a chance to review the case comments and provide your feedback. We are waiting for your approval to block the reported IP in here. Please feel free to reach out to us for any queries.This is to inform you that we have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.172 which belongs to the preview-spendhq-xelb Please find the Intrusion Prevention Logs: 2018:03:27-18:31:54 spendhq snort[18763]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.172 dstip=10.59.1.192 proto=6 srcport=41757 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0 On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 180.151.83.30 which belongs to the organization - Shyam Spectra Pvt Ltd was trying to execute the Oracle WebLogic Server Remote Code Execution. This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. Find the ELB logs details below, 2018-03-27T18:32:09.845836Z preview-spendhq-xelb 180.151.83.30:6269 10.59.1.192:80 0.000047 0.0015 0.000023 403 403 0 218 GET http://34.237.188.40:80/index.php HTTP/1.1 Mozilla/5.0 - - Please review the details and let us know if you want us to block this IP.","Hello Team, This is to inform you that we have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.172 which belongs to the preview-spendhq-xelb Please find the Intrusion Prevention Logs: 2018:03:27-18:31:54 spendhq snort[18763]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.1.172 dstip=10.59.1.192 proto=6 srcport=41757 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP  180.151.83.30 which belongs to the organization - Shyam Spectra Pvt Ltd was trying to execute the Oracle WebLogic Server Remote Code Execution. This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. Find the ELB logs details below, 2018-03-27T18:32:09.845836Z preview-spendhq-xelb 180.151.83.30:6269 10.59.1.192:80 0.000047 0.0015 0.000023 403 403 0 218 GET http://34.237.188.40:80/index.php HTTP/1.1 Mozilla/5.0 - -Please review the details and let us know if you want us to block this IP.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d1924,Cloud Engineer Level 1,Closed,1106059,Incident,10-10-2018 00:19,,"Hello Matthew,Thank you for the update.Since the issue is resolved we are marking this case as closed.Thanks.","FYI we restored the process.On 10/9/18, 1:21 PM, alert=newrelic.com@alerts.newrelic.com<mailto:alert=newrelic.com@alerts.newrelic.com> on behalf of New Relic Alert <alert=newrelic.com@alerts.newrelic.com<mailto:alert=newrelic.com@alerts.newrelic.com> on behalf of alert@newrelic.com<mailto:alert@newrelic.com>> wrote:[New Relic]Incident 35652069 <https://alerts.newrelic.com/accounts/1173825/incidents/35652069> closed Oct 9, '18 05:21 PM UTC[Checkmark]Recovered 4 minute(s) after incident openip-10-59-100-122.ec2.internal <https://infrastructure.newrelic.com/accounts/1173825/alertLanding?violationId=b8342ce5-ba24-4622-b932-d563df7fdad6>[WEB] APACHE Process not running. <https://alerts.newrelic.com/accounts/1173825/policies/324194>[WEB] APACHE Process not running. : Critical on ip-10-59-100-122.ec2.internalView incident details <https://alerts.newrelic.com/accounts/1173825/incidents/35652069>Alert PolicyHTTPD Process WW1 <https://alerts.newrelic.com/accounts/1173825/policies/324194>Start/EndOct 9, '18 05:16 PM / Oct 9, '18 05:21 PMDuration4 minute(s)Critical violation0 open / 1 totalWarning violations0 open / totalAcknowledgedRunbook-2 channels notifiedEmailmwatts@spendhq.comPagerdutyON CALLManage who gets notified <https://alerts.newrelic.com/accounts/1173825/policies/324194/channels>Copyright 2008-2018 New Relic, Inc. All rights reserved. All trademarks, trade names, service marks and logos referenced herein belong to their respective companies.New Relic Inc. 111 SW 5th Ave #2700, Portland, OR 97204[Image removed by sender.]--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: Incident 35652069 CLOSED: 'ip-10-59-100-122.ec2.internal' '[WEB] APACHE Process not running. ',,09-10-2018 22:54,1,0,SpendHQ,"Hello Matthew,Thank you for the update.Since the issue is resolved we are marking this case as closed.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001jiMJc,Cloud Engineer Level 1,Closed,1111827,Incident,12-02-2019 06:50,,"Hello Team,The alert regarding EBS High Disk Usage is recovered with a current value of 71.6 . Hence we are closing this ticket from our end. Please don't hesitate to contact back in case of any issues. Thank you.###Hello Team,The alert regarding EBS High Disk Usage on SPHQ-DB1-20180830 still in open state with a value of 92%.Please validate our analysis and please let us know if you have any queries.###Alert is still in open state with a value of 90.6%###Hello Team,This is to inform you that we have received an alert regarding High EBS disk usage with a current value of 90.7. Resource details:Instance Name : SPHQ-DB1-20180830Instance ID : i-009c4b64628c39954Private IP : 10.59.10.26The top disk consuming details are as follows,```````````````````6.9T	/usr/local/mariadb/columnstore/data1/000.dir6.9T	/usr/local/mariadb/columnstore/data16.9T	/usr/local/mariadb/columnstore6.9T	/usr/local/mariadb6.9T	total1.3T	/usr/local/mariadb/columnstore/data1/000.dir/006.dir1.2T	/usr/local/mariadb/columnstore/data1/000.dir/009.dir1.2T	/usr/local/mariadb/columnstore/data1/000.dir/007.dir996G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir986G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir929G	/usr/local/mariadb/columnstore/data1/000.dir/008.dir457G	/usr/local/mariadb/columnstore/data1/000.dir/012.dir75G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/035.dir29G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/032.dir27G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/034.dir13G	/usr/local/mariadb/columnstore/data1/000.dir/007.dir/090.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/012.dir/133.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/012.dir/040.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/222.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/220.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/215.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/211.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/086.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/228.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/209.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/161.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/138.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/104.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/055.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/046.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/040.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/038.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/036.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/245.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/188.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/187.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/175.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/173.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/168.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/148.dir``````````````````````````````````````Please remove unwanted files and folders / zip files to reduce the disk space consumption. Thank you.","________________________________From: Datadog Alerting <alert@dtdg.co>Sent: 08 February 2019 03:47To: REANCloud SupportSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26[Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26High Disk Usage detected on the device /dev/sda   @ms@reancloud.com<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECa4ZPSFheKVV3Kgt6YrvAIS39UJGhw9KZnRJrltVbOTQ-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLx9z-2B0W6pZ4IikBJcOWQ7u-2FKolnYnTVYaaHM-2Fej4ELtV9iJdSnQYwW7D7CfLKwDpqBYL9yHcf-2BnUhdXlHu-2F4S9RPia2zwdqcNpExCnqIELaQZt4iEkfCFXgJsq-2B1UzdRZDqZuvK82xsc9zqrdhwuqPXGfQ8l-2BtXgO90Ct509LHJjsru9chPcfjtvjwxJ8mCjilDQG11L9cCoNNkasTbIPv3&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cdc80e44fca254523950a08d68d4a1cd9%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=Tf4R%2FLL2swbWjnHBhm%2B8L2%2Bzhlv0SMKCLotUH2E1Sn8%3D&reserved=0>[Metric Graph]<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUof2aD02VM5nmNa7-2FHDOXwjIzWeB48-2BCv6WYm4u9mIjrZ8Axeksaty86602hVfw-2BWYrPgh5Wv3EkuFXCMCrXSh9kw-2Fe8mt4VHyBYECG-2B5gq0K-2FwwuTf4G9tT-2F4brYw-2BekvA6Y1Vbr9vq-2FplpYSZE4zvQ-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLx9z-2B0W6pZ4IikBJcOWQ7u-2Fzyb0CCL-2Fa3njN1QnqZ3UCOp4I5Y80WXXJ0o7lmFSp8Lm5nlnmqxawT3wJ24masG3BwbjeschLEA0WktJSwFkup2r1ib4DjpJGpkjN6gex-2BcSkprrsa21Eq3sEpwDyGMXOgAUUVgqV2CldVllVl2kDi5BO3I1XWVmQhH-2F-2BUNUJC7N8vFruLiAKoykZwApRaxE&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cdc80e44fca254523950a08d68d4a1cd9%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=AL3NTsjiQUyVgZiyzfxwJM3gZvNE1AkHBZej81RqDMI%3D&reserved=0>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 90The monitor was last triggered at Thu Feb 07 2019 22:17:49 UTC (2 secs ago).________________________________[Monitor Status<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUoKvcGnAzkyStJKdzb6NVcA5t2M-2BrFxoMN2TmHLeZCbSa8AYoFnJPzhQsfotJyWIEOwpdY6qar2OvVL9gKeG85Rw-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLx9z-2B0W6pZ4IikBJcOWQ7u-2Fbh3iBULjq9IYulWHOzWdmrRkU00PmTtmYHP8v3-2FUxAhE3FmaWuPdiL84qhPbTZkrmn-2FxzA7uZz3JL01E1-2BQ2ZqajRXJ7iBtt8fdXRBRcnEwBnyGbgcEFyFZRffOxZz8v8TM5nNY875xDWfJndUk6HhIEK2GICR4HlRL-2BaZucQR5OG3T6Lfz1Q0-2FQPuh-2FG9pw&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cdc80e44fca254523950a08d68d4a1cd9%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=ZW%2BNm7Yis0qT%2Bbx%2BW7SX92sWkFwxg589oXZpDY9B%2Bsk%3D&reserved=0>] · [Edit Monitor<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUo3IM-2FbEP-2FJM89epazZbNBUA-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLx9z-2B0W6pZ4IikBJcOWQ7u-2FP2JQuJqlIRnudcb-2FJIe9mpqrHACn3WSH00-2B7Y9D8Hb1ASnla8hPvszLV0GrzhqRG5r2y6G-2BYY60l3uD0P9ctyOo6-2BgZ6IfvzA0HWOrMHxKKGxGPVa5yHn-2BGLuU5VCm-2BjSho8UIcMjXixl5dguhmV8A4Ezl7Wb-2F1QoDSyTNVNY2WSU40HejfS2vaIjyNkaFXh&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cdc80e44fca254523950a08d68d4a1cd9%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=isnKM3T%2FT5fPT33vT53DXUE2r64SJ95a0%2F1o9AuhRz4%3D&reserved=0>] · [View i-009c4b64628c39954<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEDKT1NZt0tnkwEaAxSQZgju0vyJXQkH1ijIgP0bgTjT4nZOqaAoOXNpNmNd2gLu9R8-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLx9z-2B0W6pZ4IikBJcOWQ7u-2F0aNkVfv-2BoSiLsfi6oRd1dhKM2-2FlPHlY30Hmrk1e8k6-2FROLJKMb0fEng2OhS4BgwNx7rmj47XtvQpHQF-2BkNYD1pFYmQcxsb8SyN1bU6ylW9n16bDUoXue7f-2F6I2BOnqa-2BhF7VGEM80nDBGMoeaSsdVS3I0ZYyPi0Aw9f4W4GMrDvD-2FgISnzKZNOSo5Hf6U0WR&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cdc80e44fca254523950a08d68d4a1cd9%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=xHshx1lheum34j3PMGprHCJ4aOT2t1%2FiTwBDIT4vyV0%3D&reserved=0>] · [Show Processes<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQED-2FFPDBbKPsalSo1i1ufo6S-2FX4pKstbDP3BrKs5ghv713zLsidUYWK4L5aR5oKPSXNnFYDhLhSm3fqqyDV0sJQ74xodRkuO15cSO48ERcT2UZ486IWQXhqcEK5k2PrvD1u83idiennJZfZuOOkw7SK3qw3bZWkFywMhZGcAfWjQLzFcNJYAP-2FXC-2BLH1Yutr15U-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLx9z-2B0W6pZ4IikBJcOWQ7u-2F5hlCg-2FvJBdxFxuUUSei63we2i9xy3JXPY1DutgtMF5tV76VxRBa15PhvsuGG1yga1ukrnyE4gAxfaViooVa47Fod8vOz9CKhLf3pXUFlZWuBlaHrASd2JCNIshzOifYKaHPU0Oq2BbXRCt9XvZPW7fGesIkZ0Hzml-2BZHt24SrYAWkghvy1LLGau5oXzfA0z3&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cdc80e44fca254523950a08d68d4a1cd9%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=5L3aHCxeyPMOrBurMUOe%2BIbYBd4ZDf8VuCvAcM9Au%2Fc%3D&reserved=0>]This alert was raised by account SpendHQComment in Datadog<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAYJwPp8omKJuncXDFvQtomz8MIWaD-2Fwrx8vxaq6JOMISzJHHoJ9I2MjfVjG4tqB2g-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLx9z-2B0W6pZ4IikBJcOWQ7u-2F9yhcflIMNffr7ARfliXqh-2Fd32z9JoHqujd4svwyitahRfunSxEEDgS2pLQS-2BtoeV8oJryDmdHX5FBmlo-2BSp9xfaCLfw3Bevn-2Bd1qIQ-2By09lUlVYsCbWPC5RsLqRR-2B9oGXc5iQsqSUTLbzDpb0Z8P-2FYH-2BK5Ek65G2CPO1F8hoEVTv7cs7VwAqFwRiOLaBiVzM&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cdc80e44fca254523950a08d68d4a1cd9%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=W0qReDvMG8sbD6w0LyuT0GmnWIRKolK20ZFApElRvjU%3D&reserved=0>To manage your Datadog subscriptions, click here<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECkg7AnUPKGn51plZlHct1NB9fwJzgmRoiq4UZtJ-2F9d6Q-3D-3D_GJLGb5R0v008OfUEomjlW7EzrdkbZ-2FpD93bKkrv1lLx9z-2B0W6pZ4IikBJcOWQ7u-2Fcoequ-2BX1v8wKBgW4Tlbx2vbIS3iuheWSWqqGkUKSBojKxmUmcE4cCpsCnx2MpGTjg-2BNRlmZk-2BN0ltmFqQA3SiuSrJ-2B9qvBmosfYUTtwCSJTtswHQKcBXMMMQi7Wrd3sZ3nvvskayPU0oiDqDlMRVHjTll6-2Fl1TbCiSI-2Fup7-2Bn1QHY-2FYGpCMBCRnkOFUyYjYR&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cdc80e44fca254523950a08d68d4a1cd9%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=grPGP%2BvO64%2BtcIdUwxY%2B7NWPbTghlYJuQusaGuPfew4%3D&reserved=0>.-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26,,08-02-2019 07:04,96,0,SpendHQ,"Hello Team,The alert regarding EBS High Disk Usage is recovered with a current value of 71.6 . Hence we are closing this ticket from our end. Please don't hesitate to contact back in case of any issues. Thank you.","Hello Team,The alert regarding EBS High Disk Usage on SPHQ-DB1-20180830 still in open state with a value of 92%.Please validate our analysis and please let us know if you have any queries.",Alert is still in open state with a value of 90.6%,"Hello Team,This is to inform you that we have received an alert regarding High EBS disk usage with a current value of 90.7. Resource details:Instance Name : SPHQ-DB1-20180830Instance ID : i-009c4b64628c39954Private IP : 10.59.10.26The top disk consuming details are as follows,```````````````````6.9T	/usr/local/mariadb/columnstore/data1/000.dir6.9T	/usr/local/mariadb/columnstore/data16.9T	/usr/local/mariadb/columnstore6.9T	/usr/local/mariadb6.9T	total1.3T	/usr/local/mariadb/columnstore/data1/000.dir/006.dir1.2T	/usr/local/mariadb/columnstore/data1/000.dir/009.dir1.2T	/usr/local/mariadb/columnstore/data1/000.dir/007.dir996G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir986G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir929G	/usr/local/mariadb/columnstore/data1/000.dir/008.dir457G	/usr/local/mariadb/columnstore/data1/000.dir/012.dir75G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/035.dir29G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/032.dir27G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/034.dir13G	/usr/local/mariadb/columnstore/data1/000.dir/007.dir/090.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/012.dir/133.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/012.dir/040.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/222.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/220.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/215.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/211.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/086.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/228.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/209.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/161.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/138.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/104.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/055.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/046.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/040.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/038.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/036.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/245.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/188.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/187.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/175.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/173.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/168.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/148.dir``````````````````````````````````````Please remove unwanted files and folders / zip files to reduce the disk space consumption. Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C2Syy,Cloud Engineer Level 1,Closed,1054703,Incident,18-05-2017 17:43,,"Hello SpendHQ-Team, On further analyzing the ELB logs at the time of the alert, We are able to find the IP 120.24.79.205 which belongs to Zhejiang region in China which is trying to execute the SERVER-APACHE Apache Struts remote code.As a fix we have blocked the IP at NACL level. Please refer the below ELB and IPS logs during the time of this alerts:ELB Logs:-2017-05-18T10:03:23.358495Z preview-spendhq-xelb 120.24.79.205:60885 - -1 -1 -1 504 0 0 0 GET http://52.6.177.194:80/ HTTP/1.1 Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1) - -IPS Logs:-2017:05:18-10:03:23 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.111 dstip=10.59.1.192 proto=6 srcport=31856 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0Let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello SpendHQ-Team,This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.111 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.Regards,Sumod.K.Bose",1.Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41819Time...........: 2017-05-18 10:03:23Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.111Source port: 31856Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)2.Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-18 10:03:23Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.111Source port: 31856Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 187 days 2 hours 18 minutesSystem Load        : 0.09System Version     : Sophos UTM 9.408-4,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,18-05-2017 15:35,5,0,SpendHQ,"Hello SpendHQ-Team, On further analyzing the ELB logs at the time of the alert, We are able to find the IP 120.24.79.205 which belongs to Zhejiang region in China which is trying to execute the SERVER-APACHE Apache Struts remote code.As a fix we have blocked the IP at NACL level. Please refer the below ELB and IPS logs during the time of this alerts:ELB Logs:-2017-05-18T10:03:23.358495Z preview-spendhq-xelb 120.24.79.205:60885 - -1 -1 -1 504 0 0 0 GET http://52.6.177.194:80/ HTTP/1.1 Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1) - -IPS Logs:-2017:05:18-10:03:23 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.111 dstip=10.59.1.192 proto=6 srcport=31856 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0Let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello SpendHQ-Team,This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.111 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DHnRj,Cloud Engineer Level 1,Closed,1063860,Incident,20-06-2017 21:50,,"Hello SpendHQ-Team,This volume usage alert on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) has been resolved and returned to a normal state with a value of 67%.The violation lasted for around 2 hours.We are monitoring on it and will keep your team updated. Let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello SpendHQ-Team,This is to remind you that the volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) is still in the open state. The volume usage has reached a value of 100%. /tmp folder is consuming high volume usage on this instance.Kindly delete/zip unwanted files or folders to reduce the current volume usage state on this since and let us know if your team need any further assistance from our end to resolve this issue at the earliest.Regards,Sumod.K.Bose###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 95%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1     ext4    50G   45G  2.4G  95% / Files under root directory, 19G     tmp14G     usr12G     var 510M    home285M    lib282M    optFiles under /tmp folder, 6.9G    liger_view_44be0c51d9aa33652c6123b8a2341455.csv1.3G    liger_view_caa16490a6f4c23258e135e31655eacd.csv1.3G    liger_view_75711df91b1c04b9ebb0c798d1db1924.csv1.2G    liger_view_ca94360e9066d0795046db0cdedb63a0.csv1.2G    liger_view_c3da8d154944aa663d2278f459dde888.csv1.2G    liger_view_a702c89696d224eb4616d1ff17c3cff8.csv1.2G    liger_view_3981fa6ba16ae364f9043c3007514a9a.csv1.2G    liger_view_304b3103c7b7b3a51526b509a772f5ca.csv1.2G    liger_view_20e3b27c33ea26e70d7177648ce52e27.csv Delete/zip unwanted files or folders to reduce the current volume usage state on this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135 Regards, Sumod.K.Bose","[Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,20-06-2017 19:27,2,0,SpendHQ,"Hello SpendHQ-Team,This volume usage alert on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) has been resolved and returned to a normal state with a value of 67%.The violation lasted for around 2 hours.We are monitoring on it and will keep your team updated. Let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello SpendHQ-Team,This is to remind you that the volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) is still in the open state. The volume usage has reached a value of 100%. /tmp folder is consuming high volume usage on this instance.Kindly delete/zip unwanted files or folders to reduce the current volume usage state on this since and let us know if your team need any further assistance from our end to resolve this issue at the earliest.Regards,Sumod.K.Bose","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 95%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1     ext4    50G   45G  2.4G  95% / Files under root directory, 19G     tmp14G     usr12G     var 510M    home285M    lib282M    optFiles under /tmp folder, 6.9G    liger_view_44be0c51d9aa33652c6123b8a2341455.csv1.3G    liger_view_caa16490a6f4c23258e135e31655eacd.csv1.3G    liger_view_75711df91b1c04b9ebb0c798d1db1924.csv1.2G    liger_view_ca94360e9066d0795046db0cdedb63a0.csv1.2G    liger_view_c3da8d154944aa663d2278f459dde888.csv1.2G    liger_view_a702c89696d224eb4616d1ff17c3cff8.csv1.2G    liger_view_3981fa6ba16ae364f9043c3007514a9a.csv1.2G    liger_view_304b3103c7b7b3a51526b509a772f5ca.csv1.2G    liger_view_20e3b27c33ea26e70d7177648ce52e27.csv Delete/zip unwanted files or folders to reduce the current volume usage state on this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135 Regards, Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d2sfk,Cloud Engineer Level 1,Closed,1106280,Incident,16-10-2018 06:50,,"Hello Team,This is to inform you that the alert regarding High CPU Load on spendhq-memsql-server2-2018-04-01 (10.59.100.171) recovered and the monitor is now on okay state with a value of 0.13%.Since we don't have any other action item from our end we are marking this case as resolved and closing the case.Please reach out to us in case of any query or concern.Thanks,###Hello Team,We have analyzed the issue and could see the CPU load was 0.02, 3.58, 23.28 over 1, 5 and 15 minutes respectively.Additionally the process memsql is consuming the highest CPU on average at 37.5%.top - 16:50:58 up 196 days, 19:50,  0 users,  load average: 0.02, 3.58, 23.28Tasks: 312 total,   1 running, 311 sleeping,   0 stopped,   0 zombie%Cpu(s):  1.0 us,  0.2 sy,  0.0 ni, 98.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total, 27549216 free, 15417368+used, 69852128 buff/cacheKiB Swap:        0 total,        0 free,        0 used. 87950312 avail Mem    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND 10048 memsql    20   0 11.845g 251040   5260 S  37.5  0.1   4:24.81 memsql-ops 23049 root      20   0  354776   7596   5416 S   6.2  0.0   0:00.01 ssm-docum+     1 root      20   0  195564   7940   3176 S   0.0  0.0   6:37.65 systemdPlease see the attachment section for clear breakdown and let us know if you have any queries.Thanks.###Hello Team,This is to notify you that we have received an alert regarding High CPU Load on spendhq-memsql-server2-2018-04-01 (10.59.100.171).We are analyzing the issue and will get back to you with the updates.Resource Details-------------------------------------------------------------------------------------------------------------Instance ID: i-0382b753fdc5a21bdInstance Name: SpendHQ-memsql-server2-2018-04-01Private IP: 10.59.100.171Instance Type: i3.8xlargeAvailability zone: us-east-1bVPC ID: vpc-76df7212Subnet ID: subnet-0d093d27-------------------------------------------------------------------------------------------------------------Thanks.","*Mr. Stephen Oduor Otieno**Junior Cloud Engineer**REĀN Cloud. **stephen.oduor@reancloud.com <stephen.oduor@reancloud.com> |www.reancloud.com <http://www.reancloud.com>**AWS SysOps-Admin Associate Certified*---------- Forwarded message ---------From: Datadog Alerting <alert@dtdg.co>Date: Mon, Oct 15, 2018 at 7:48 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on hostspendhq-memsql-server2-2018-04-01 - 10.59.100.171 -To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High CPU Load on hostspendhq-memsql-server2-2018-04-01 - 10.59.100.171 -Detected High CPU load. Log in to the machine and verify which process isconsuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023975?to_ts=1539622065000&group=host%3Ai-0382b753fdc5a21bd&from_ts=1539614865000>*system.load.15* over *datadog_monitor:on,host:i-0382b753fdc5a21bd* was *>40.0* on average during the *last 1h*.The monitor was last triggered at Mon Oct 15 2018 16:47:55 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023975?group=host%3Ai-0382b753fdc5a21bd>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023975/edit>] · [Viewi-0382b753fdc5a21bd<https://app.datadoghq.com/infrastructure?filter=i-0382b753fdc5a21bd>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1539622195000&tags=host%3Ai-0382b753fdc5a21bd&from_ts=1539621175000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4619760962550416940>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on host spendhq-memsql-server2-2018-04-01 - 10.59.100.171 -,,15-10-2018 22:22,8,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding High CPU Load on spendhq-memsql-server2-2018-04-01 (10.59.100.171) recovered and the monitor is now on okay state with a value of 0.13%.Since we don't have any other action item from our end we are marking this case as resolved and closing the case.Please reach out to us in case of any query or concern.Thanks,","Hello Team,We have analyzed the issue and could see the CPU load was 0.02, 3.58, 23.28 over 1, 5 and 15 minutes respectively.Additionally the process memsql is consuming the highest CPU on average at 37.5%.top - 16:50:58 up 196 days, 19:50,  0 users,  load average: 0.02, 3.58, 23.28Tasks: 312 total,   1 running, 311 sleeping,   0 stopped,   0 zombie%Cpu(s):  1.0 us,  0.2 sy,  0.0 ni, 98.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total, 27549216 free, 15417368+used, 69852128 buff/cacheKiB Swap:        0 total,        0 free,        0 used. 87950312 avail Mem    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND 10048 memsql    20   0 11.845g 251040   5260 S  37.5  0.1   4:24.81 memsql-ops 23049 root      20   0  354776   7596   5416 S   6.2  0.0   0:00.01 ssm-docum+     1 root      20   0  195564   7940   3176 S   0.0  0.0   6:37.65 systemdPlease see the attachment section for clear breakdown and let us know if you have any queries.Thanks.","Hello Team,This is to notify you that we have received an alert regarding High CPU Load on spendhq-memsql-server2-2018-04-01 (10.59.100.171).We are analyzing the issue and will get back to you with the updates.Resource Details-------------------------------------------------------------------------------------------------------------Instance ID: i-0382b753fdc5a21bdInstance Name: SpendHQ-memsql-server2-2018-04-01Private IP: 10.59.100.171Instance Type: i3.8xlargeAvailability zone: us-east-1bVPC ID: vpc-76df7212Subnet ID: subnet-0d093d27-------------------------------------------------------------------------------------------------------------Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gco0d,Cloud Engineer Level 1,Closed,1109636,Incident,20-12-2018 17:00,,"Hello TeamAs already informed via the last comment that the action that we have to be performed on this case is already completed as a part of the stop and start of the instances according to the schedule.As there is no pending action on this. So we will be marking this case as closed.Let us know if you have any queries.Thanks###@Team:Send a closure mail on this if it has been already taken care by scheduled start/stop. Thanks###Hello TeamThis is to inform you that we have received we have received a notification from the AWs that one of the EC2 instance which is running in your AWS account has detected degradation of the underlying hardware.As the instance is scheduled for the auto start and stops based on the tags attached, the issue is already taken care when the instance is stopped on yesterday night. The instance will be starting over new underlying hardware at the time it starts based on the tag attached. So we have no pending action from our end on this.Instance Name: matt_m5.large_03Instance ID:i-08ba7660add5681aeLet us know if you have any queries.Thanks###@Team:We need to inform to customer with an addition that we are not monitoring this instance. Ask them if they want us to take care of it or not.###Hello Team,This instance is not having monitoring on tag. Please check with CC whether we can inform this to the customer or not.","EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-01 22:00 UTC your instance, which has an EBS volume as the root device, will be stopped.\\n \\nYou can see more information on your instances that are scheduled for retirement in the AWS Management Console (https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Events)\\n \\n* How does this affect you?\\n \\nYour instance will be stopped after the specified retirement date, but you can start it again at any time. Note that if you have EC2 instance store volumes attached to the instance, any data on these volumes will be lost when the instance is stopped or terminated as these volumes are physically attached to the host computer\\n \\n* What do you need to do?\\n \\nYou can wait for the scheduled retirement date - when the instance is stopped - or stop the instance yourself any time before then. Once the instances has been stopped, you can start the instance again at any time. For more information about stopping and starting your instance, and what to expect when your instance is stopped, such as the effect on public, private and Elastic IP addresses associated with your instance, see Stop and Start Your Instance in the EC2 User Guide (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html).\\n \\n* Why retirement?\\n \\nAWS may schedule instances for retirement in cases where there is an unrecoverable issue with the underlying hardware. For more information about scheduled retirement events please see the EC2 user guide (http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-retirement.html).\\n \\nIf you have any questions or concerns, you can contact the AWS Support Team on the community forums and via AWS Premium Support at: http://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_EC2_PERSISTENT_INSTANCE_RETIREMENT_SCHEDULED,,19-12-2018 03:49,37,0,SpendHQ,Hello TeamAs already informed via the last comment that the action that we have to be performed on this case is already completed as a part of the stop and start of the instances according to the schedule.As there is no pending action on this. So we will be marking this case as closed.Let us know if you have any queries.Thanks,@Team:Send a closure mail on this if it has been already taken care by scheduled start/stop. Thanks,"Hello TeamThis is to inform you that we have received we have received a notification from the AWs that one of the EC2 instance which is running in your AWS account has detected degradation of the underlying hardware.As the instance is scheduled for the auto start and stops based on the tags attached, the issue is already taken care when the instance is stopped on yesterday night. The instance will be starting over new underlying hardware at the time it starts based on the tag attached. So we have no pending action from our end on this.Instance Name: matt_m5.large_03Instance ID:i-08ba7660add5681aeLet us know if you have any queries.Thanks",@Team:We need to inform to customer with an addition that we are not monitoring this instance. Ask them if they want us to take care of it or not.,"Hello Team,This instance is not having monitoring on tag. Please check with CC whether we can inform this to the customer or not.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EUE5N,Cloud Engineer Level 1,Closed,1067627,Incident,14-07-2017 23:09,,"Matthew replied:Thank you###Hello SpendHQ Team,Please find the RCA for the site down issue occurred on 12th of July for secure.spendhq.com URL in the attachments.Kindly review it and let us know if you have any more queries.###I have created the RCA.Need to get it reviewed by CE2/CE3.Link - https://docs.google.com/document/d/1SA4hVJJfh6_3gamXaZuZ7pXJrxzPSpY1T7DdEYvsgq8/edit####Hello Team, This is a quick follow-up.Could you please let us know if you have any queries regarding the issue.###Hello Team,This is a gentle reminder.Please let us know if you got a chance to review the analysis shared. Please revert back to us if you have any queries.###We tried to reach ANdrew and Matthew over phone but unable to reach out to them###Hello Team,On further analysis, we found that one of the several running httpd process with PID 9755 got killed by the  “Out Of Memory killer” of Kernel.Please find the logs for the same below:/var/log/messagesJul 12 13:41:15 ip-10-59-100-94 kernel: Out of memory: Kill process 9755 (httpd) score 279 or sacrifice childJul 12 13:41:15 ip-10-59-100-94 kernel: Killed process 9755, UID 48, (httpd) total-vm:4634728kB, anon-rss:4263168kB, file-rss:932kBBy default, Linux kernels allow processes to request more memory than currently available in the system. But this can lead to extremely low memory conditions, where no pages can be allocated to process.To prevent such situations, the out of memory killer activates and identifies the process to be the killed.Hence, The HTTP process that was trying to allocate more memory got killed and a new HTTP child process was created by the parent process. Please let us know if yo have any further queries regarding this issue.###Hello SpendHQ-Team,This is to notify you that we got a site down alert for the url https://secure.spendhq.com/login. While accessing the page at the time of the alert, we could see that page is loading but there was an internal error message in the page. The alert got resolved and the page is accessible now. We are investigating the alert and meanwhile let us know if your team is performing any activity from your end.","Wed, 12 Jul 2017 09:30:53 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Frankfurt DE, Dallas-B US, Sydney-C AU, California US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,12-07-2017 19:00,53,0,SpendHQ,Matthew replied:Thank you,"Hello SpendHQ Team,Please find the RCA for the site down issue occurred on 12th of July for secure.spendhq.com URL in the attachments.Kindly review it and let us know if you have any more queries.",I have created the RCA.Need to get it reviewed by CE2/CE3.Link - https://docs.google.com/document/d/1SA4hVJJfh6_3gamXaZuZ7pXJrxzPSpY1T7DdEYvsgq8/edit,"#Hello Team, This is a quick follow-up.Could you please let us know if you have any queries regarding the issue.","Hello Team,This is a gentle reminder.Please let us know if you got a chance to review the analysis shared. Please revert back to us if you have any queries.",We tried to reach ANdrew and Matthew over phone but unable to reach out to them,"Hello Team,On further analysis, we found that one of the several running httpd process with PID 9755 got killed by the  “Out Of Memory killer” of Kernel.Please find the logs for the same below:/var/log/messagesJul 12 13:41:15 ip-10-59-100-94 kernel: Out of memory: Kill process 9755 (httpd) score 279 or sacrifice childJul 12 13:41:15 ip-10-59-100-94 kernel: Killed process 9755, UID 48, (httpd) total-vm:4634728kB, anon-rss:4263168kB, file-rss:932kBBy default, Linux kernels allow processes to request more memory than currently available in the system. But this can lead to extremely low memory conditions, where no pages can be allocated to process.To prevent such situations, the out of memory killer activates and identifies the process to be the killed.Hence, The HTTP process that was trying to allocate more memory got killed and a new HTTP child process was created by the parent process. Please let us know if yo have any further queries regarding this issue.","Hello SpendHQ-Team,This is to notify you that we got a site down alert for the url https://secure.spendhq.com/login. While accessing the page at the time of the alert, we could see that page is loading but there was an internal error message in the page. The alert got resolved and the page is accessible now. We are investigating the alert and meanwhile let us know if your team is performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EVUm4,Cloud Engineer Level 1,Closed,1068274,Incident,16-07-2017 21:54,,"Hello SpendHQ Team, This is to notify you that we have received an alert that the network outbound for prod-sphq-db-server05 is above the threshold of 2220000000.0.The alert got resolved within few minutes and returned to normal. Resource details: Instance Name - prod-sphq-db-server05 Instance ID - i-008d43ad00357e47a VPC ID - vpc-76df7212 Instance type - r3.8xlarge","[Triggered] [SpendHQ] - High Network OUT on host - prod-sphq-db-server05 - 10.59.10.135 - db Status  High Network OUT on the instance. Please check the list open TCP Connections    @support@reancloud.comaws.ec2.network_out over host:10.59.10.135,monitoring:on was > 2220000000.0 at all times during the last 5m.Metric value: 8501253632.0This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024199?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2024199/edit · Event URL: https://app.datadoghq.com/event/event?id=3958509263551769454 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - prod-sphq-db-server05 - 10.59.10.135 - db Status,,16-07-2017 18:03,4,0,SpendHQ,"Hello SpendHQ Team, This is to notify you that we have received an alert that the network outbound for prod-sphq-db-server05 is above the threshold of 2220000000.0.The alert got resolved within few minutes and returned to normal. Resource details: Instance Name - prod-sphq-db-server05 Instance ID - i-008d43ad00357e47a VPC ID - vpc-76df7212 Instance type - r3.8xlarge",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014o5LN,Cloud Engineer Level 1,Closed,1035739,Incident,02-12-2016 04:07,,"Andrew asked to kill the session tomorrow night that is  7pm eastern on Friday 12/2, which is 5:30 AM IST Saturday and he also mentioned certain other action items that we need to perform like database back up, fix mount point and remove session. So we are closing this ticket and opening new change ticket.###Hi Andrew,We are getting the login error messages as it is not able to connect to the volume spend2-v777bb21358661922. From the target session list, we can see that it is trying to connect to spend2-v777bb21358661922 but it is not able to connect(Screenshot attached). As a part of Nimble volume management, this volume is listed to delete as we are not using.Given below are the volumes that were planned to remove.·         092016-sphge2var-clone·         Rean1·         Spend2 ·         10-15-16-spendhq-testWe can kill the session to stop trying to connect to that volume. Please let us know if you would like to know any further information.###Hello Andrew,We are working on this request and will update you the progress.","We’re investigating the sudden increase in disk usage on Web2 (10.59.100.118), and noticed the following error in /var/log/messages. Please advise.",Error in messages on Web2 (10.59.100.118),,02-12-2016 02:02,2,0,SpendHQ,"Andrew asked to kill the session tomorrow night that is  7pm eastern on Friday 12/2, which is 5:30 AM IST Saturday and he also mentioned certain other action items that we need to perform like database back up, fix mount point and remove session. So we are closing this ticket and opening new change ticket.","Hi Andrew,We are getting the login error messages as it is not able to connect to the volume spend2-v777bb21358661922. From the target session list, we can see that it is trying to connect to spend2-v777bb21358661922 but it is not able to connect(Screenshot attached). As a part of Nimble volume management, this volume is listed to delete as we are not using.Given below are the volumes that were planned to remove.·         092016-sphge2var-clone·         Rean1·         Spend2 ·         10-15-16-spendhq-testWe can kill the session to stop trying to connect to that volume. Please let us know if you would like to know any further information.","Hello Andrew,We are working on this request and will update you the progress.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001KpTRu,Cloud Engineer Level 1,Closed,1085317,Incident,27-11-2017 21:22,,"Hello Matthew,This request has been completed.Kindly check and let us know if you have any queries.Regards,Sumod.K.Bose","Rean,Can you disable my multi authentication on my account.--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",VPN Multi Auth,,27-11-2017 21:06,25,0,SpendHQ,"Hello Matthew,This request has been completed.Kindly check and let us know if you have any queries.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bkHNo,Cloud Engineer Level 1,Closed,1104659,Incident,19-09-2018 19:53,,"Hi Team,We have performed cleaned up for following Volumes. Please verify and let us know if you have any queries. Resource Details: Resource ID: vol-06e018ec5373c46a0 Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-03-13 Size: 8 GiB Age: 185 days Resource ID: vol-0d52f3dfd2bd0bdbf Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-03-08 Size: 8 GiB Age: 190 days Resource ID: vol-06949a7c5b2ee5952 Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-03-08 Size: 8 GiB Age: 189 days###Hello Team,This is to inform you that we have cleaned up the below volumes. Please let us know if you have any query.Resource Details:Resource ID: vol-06e018ec5373c46a0Type: General Purpose SSDRegion: us-east-1Creation Date: 2018-03-13Size: 8 GiBAge: 185 daysResource ID: vol-0d52f3dfd2bd0bdbfType: General Purpose SSDRegion: us-east-1Creation Date: 2018-03-08Size: 8 GiBAge: 190 days Resource ID: vol-06949a7c5b2ee5952Type: General Purpose SSDRegion: us-east-1Creation Date: 2018-03-08Size: 8 GiBAge: 189 days###praveen.muppala@reancloud.comSep 14, 2018, 5:35 PM (4 days ago)to Rean, spendhq-supportHello Team, please cleanup these volumes","Hello Team, please cleanup these volumes From: ms@reancloud.com <ms@reancloud.com> Sent: September 14, 2018 10:04 AMTo: spendhq-support@reancloud.comSubject: [Managed Cloud: spendhq] Ununsed Ebs Volume check REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud. The following AWS::EC2::Volume resources were affected:   _____  *	Violation: EBS volume is not attached any stopped or running EC2 instance.*	Recommendation: Review the use of the unattached EBS volume. Unattached EBS volume are chargeable.*	Action taken: None*	Resource details: Resource IDVolume NameTypeOwnerRegionCreation DateSizeAgevol-06e018ec5373c46a0	General Purpose SSD	us-east-12018-03-138 GiB185 daysvol-0d52f3dfd2bd0bdbf	General Purpose SSD	us-east-12018-03-088 GiB190 daysvol-06949a7c5b2ee5952	General Purpose SSD	us-east-12018-03-088 GiB189 days  _____  Best Regards, REAN Cloud Team IMPORTANT: Please do not reply to this message or email address. --  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: [Managed Cloud: spendhq] Ununsed Ebs Volume check,,14-09-2018 20:05,122,0,SpendHQ,"Hi Team,We have performed cleaned up for following Volumes. Please verify and let us know if you have any queries. Resource Details: Resource ID: vol-06e018ec5373c46a0 Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-03-13 Size: 8 GiB Age: 185 days Resource ID: vol-0d52f3dfd2bd0bdbf Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-03-08 Size: 8 GiB Age: 190 days Resource ID: vol-06949a7c5b2ee5952 Type: General Purpose SSD Region: us-east-1 Creation Date: 2018-03-08 Size: 8 GiB Age: 189 days","Hello Team,This is to inform you that we have cleaned up the below volumes. Please let us know if you have any query.Resource Details:Resource ID: vol-06e018ec5373c46a0Type: General Purpose SSDRegion: us-east-1Creation Date: 2018-03-13Size: 8 GiBAge: 185 daysResource ID: vol-0d52f3dfd2bd0bdbfType: General Purpose SSDRegion: us-east-1Creation Date: 2018-03-08Size: 8 GiBAge: 190 days Resource ID: vol-06949a7c5b2ee5952Type: General Purpose SSDRegion: us-east-1Creation Date: 2018-03-08Size: 8 GiBAge: 189 days","praveen.muppala@reancloud.comSep 14, 2018, 5:35 PM (4 days ago)to Rean, spendhq-supportHello Team, please cleanup these volumes",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C2uVL,Cloud Engineer Level 1,Closed,1054818,Incident,19-05-2017 05:50,,We are following in 01054804.,"Thu, 18 May 2017 18:32:09 -0400Detected Error on SpendHQEstimated Downtime: 59 seconds https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Atlanta-B US, California US, Sydney-C AU, London UK-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,19-05-2017 04:02,2,0,SpendHQ,We are following in 01054804.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C4G7s,Cloud Engineer Level 1,Closed,1055736,Incident,25-05-2017 05:40,,"I have completed the deployment plan for performing the firmware update for the SpendHQ Sophos. Here is the link https://drive.google.com/open?id=16jdH8dDyeUGI7VCVypZiRpZe8ZEmyl1tmTE0srU_YBg Please create change ticket before we start the maintenance on June 10th and attach the Deployment plan over there.###Hello Andrew,Thanks for the confirmation.We can schedule the Sophos update on June 10th at 1am eastern. We will work on the deployment plan and share it with you.###Hello, Can we schedule the Sophos update on June 10th at 1am eastern? Thank you,###Hello Andrew,I have analyzed this issue further and the findings are as below.From the Sophos IPS logs, the details of the IPS alert are here:id=2101severity=warnname=Intrusion protection alertaction=dropreason=SERVER-APACHE Apache Struts remote code execution attemptgroup=212srcip=10.59.5.123dstip=10.59.1.192srcport=37428dstport=80sid=41819class=Attempted Administrator Privilege Gainpriority=1I have looked into the IPS rule ID 2101 used to filter this request and the rule description is here.A buffer overflow exists in the SMB (Server Message Block) Protocol implementation in Microsfot Windows NT, Windows 2000, and Windows XP that allows attackers to cause a denial of service via a NetShareEnum request.We found a request from the ELB logs which may match the IPS rule ID 2101 condition. Please find the log here.2017-05-23T21:06:38.512574Z Secure-SpendHQ-ELB 216.53.140.3:47071 10.59.1.192:443 0.000056 43.884324 0.000044 500 500 0 0 GET https://secure.spendhq.com:443/spend-visibility/spend_detail/category_detail/vendors/location:QWxsIExvY2F0aW9ucw/?_=1495573545546 HTTP/1.1 Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko ECDHE-RSA-AES128-SHA256 TLSv1.2From the log, we could see the client user is having Windows NT as the device and that can be the reason for which the Sophos IPS protection is reporting this. But, the IP address is not reported for any kind of abuse reports and there was only one request with this behavior. We can consider this as a false positive.In order to reduce the false positives, we recommend to performing a Sophos firmware update in the SpendHQ Sophos(currently, we have 4 Updates available for installation). Please find the below details for more information.Firmware version:		9.408-44 Update(s) available for installationPattern version:		126363Please let us know if we have your approval to perform Sophos firmware update in the SpendHQ Sophos.--Thanks & Regards,Safuvan KM###Hello Andrew,We have unblocked the IP 24.5.67.101 from NACL level.We are analyzing the issue further and will revert back to you with more details.###Andrew Kim4:33 AM (6 minutes ago)￼￼￼to Rean, spendhq-support￼This should be a legitimate url. Can you provide more information on what Intrusion Prevention detected? Please unblock the 24.5.67.101 IP address. Thank you,###Hello SpendHQ-Team, On further analysis, we have checked the ELB logs and we could see a number of requests with 403 response code. There were 42 requests from IP 24.5.67.101 having a 403 error code.ELB Logs:2017-05-23T21:24:22.722500Z Secure-SpendHQ-ELB 24.5.67.101:54717 10.59.1.192:443 0.000047 0.105798 0.00005 403 403 0 0 GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1495529835120 HTTP/1.1 Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2IP trace details:IP: 24.5.67.101 Country: United States ISP: Comcast Cable Communications LLC We have blocked the IP in NACL level. Please let us know if you have any queries regarding this.###Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.123 which belongs to the Secure ELB.We are analyzing the ELB logs and IPS logs will let you know the further updates.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-23 21:24:55Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.123 Source port: 37428Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http),[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,24-05-2017 03:19,39,0,SpendHQ,I have completed the deployment plan for performing the firmware update for the SpendHQ Sophos. Here is the link https://drive.google.com/open?id=16jdH8dDyeUGI7VCVypZiRpZe8ZEmyl1tmTE0srU_YBg Please create change ticket before we start the maintenance on June 10th and attach the Deployment plan over there.,"Hello Andrew,Thanks for the confirmation.We can schedule the Sophos update on June 10th at 1am eastern. We will work on the deployment plan and share it with you.","Hello, Can we schedule the Sophos update on June 10th at 1am eastern? Thank you,","Hello Andrew,I have analyzed this issue further and the findings are as below.From the Sophos IPS logs, the details of the IPS alert are here:id=2101severity=warnname=Intrusion protection alertaction=dropreason=SERVER-APACHE Apache Struts remote code execution attemptgroup=212srcip=10.59.5.123dstip=10.59.1.192srcport=37428dstport=80sid=41819class=Attempted Administrator Privilege Gainpriority=1I have looked into the IPS rule ID 2101 used to filter this request and the rule description is here.A buffer overflow exists in the SMB (Server Message Block) Protocol implementation in Microsfot Windows NT, Windows 2000, and Windows XP that allows attackers to cause a denial of service via a NetShareEnum request.We found a request from the ELB logs which may match the IPS rule ID 2101 condition. Please find the log here.2017-05-23T21:06:38.512574Z Secure-SpendHQ-ELB 216.53.140.3:47071 10.59.1.192:443 0.000056 43.884324 0.000044 500 500 0 0 GET https://secure.spendhq.com:443/spend-visibility/spend_detail/category_detail/vendors/location:QWxsIExvY2F0aW9ucw/?_=1495573545546 HTTP/1.1 Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko ECDHE-RSA-AES128-SHA256 TLSv1.2From the log, we could see the client user is having Windows NT as the device and that can be the reason for which the Sophos IPS protection is reporting this. But, the IP address is not reported for any kind of abuse reports and there was only one request with this behavior. We can consider this as a false positive.In order to reduce the false positives, we recommend to performing a Sophos firmware update in the SpendHQ Sophos(currently, we have 4 Updates available for installation). Please find the below details for more information.Firmware version:		9.408-44 Update(s) available for installationPattern version:		126363Please let us know if we have your approval to perform Sophos firmware update in the SpendHQ Sophos.--Thanks & Regards,Safuvan KM","Hello Andrew,We have unblocked the IP 24.5.67.101 from NACL level.We are analyzing the issue further and will revert back to you with more details.","Andrew Kim4:33 AM (6 minutes ago)￼￼￼to Rean, spendhq-support￼This should be a legitimate url. Can you provide more information on what Intrusion Prevention detected? Please unblock the 24.5.67.101 IP address. Thank you,","Hello SpendHQ-Team, On further analysis, we have checked the ELB logs and we could see a number of requests with 403 response code. There were 42 requests from IP 24.5.67.101 having a 403 error code.ELB Logs:2017-05-23T21:24:22.722500Z Secure-SpendHQ-ELB 24.5.67.101:54717 10.59.1.192:443 0.000047 0.105798 0.00005 403 403 0 0 GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1495529835120 HTTP/1.1 Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2IP trace details:IP: 24.5.67.101 Country: United States ISP: Comcast Cable Communications LLC We have blocked the IP in NACL level. Please let us know if you have any queries regarding this.","Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.123 which belongs to the Secure ELB.We are analyzing the ELB logs and IPS logs will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BXMkn,Cloud Engineer Level 1,Closed,1050060,Incident,28-04-2017 04:57,,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Matthew Watts4:43 AM (11 minutes ago)￼￼￼to Rean￼Yes this is the desired outcome. Much thanks of your work on this.###Hello Matthew,We have added the Network definition for PROD-SPHQ-WEB-SERVER04 in Sophos and also enabled access over port 8080 and 8443 for the same.We have allowed the access over port 8080 as plain HTTP Text while we have used Encrypted SSL communication for port 8443 using the same wildcard_spendhq_com_09_02_2017 certificate like port 443.We have tested the accessibility by hitting the preview.spendhq.com:8080 and it is working fine.But preview.spendhq.com:8443 was not accessible.To check the configuration further we tried hitting the port directly on the instance using its IP but it was not accessible.Hence, we can conclude that this is due to the application side configuration issue.Please verify it from your end and let us know if there are any more changes required from our side.###Matthew Watts3:14 AM (30 minutes ago)￼￼￼to Rean￼That is correct providing the DO NOT effect PRD traffic. My understanding is that these are two new definitions.###Matthew Watts3:23 AM (21 minutes ago)￼￼￼to Praveen, Rean￼Confirmed. Thank you.###Praveen Kumar Muppala3:19 AM (25 minutes ago)￼￼￼to Matthew, Rean￼Time Window is wrongly mentioned it is 6:30PM EST###Hello Matthew,As per our understanding, in order to complete the request, we need to perform the below steps.1 - Create a Host definiton for PROD-SPHQ-WEB-SERVER04 - 10.59.100.104 IP Address2 - Create 2 WAF definitions(Virtual Web Server Definition)  - 8080 - Mimic the definition of preview 80    - Add 10.59.100.104 Web Server - Real Web Server  - 8443 0 Mimic the definition of preview 443    - Add 10.59.100.104 Web Server - Real Web Server3 - Allow 8080 / 8443 from public world in preview ELB Security Group Inbound/Outbound4 - Allow 8080 / 8443 traffic on PROD-SPHQ-WEB-SERVER04 SG (sg-855a34e3) from Sophos Security GroupPlease provide an approval to perform those steps.###Matthew Watts2:11 AM (48 minutes ago)￼￼￼to Rean￼Can we get a status update on the ETA?###Hello Matthew,We will work on this request and will get back to you with updates.","We have enabled tomcat on our preview environment. Can we please open (transfer) traffic coming from 8080 and 8443 to 8080 and 8443 on 10.59.100.104.Matthew Watts | Manager, Application Development | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Tomcat,,28-04-2017 01:02,4,0,SpendHQ,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.",Matthew Watts4:43 AM (11 minutes ago)￼￼￼to Rean￼Yes this is the desired outcome. Much thanks of your work on this.,"Hello Matthew,We have added the Network definition for PROD-SPHQ-WEB-SERVER04 in Sophos and also enabled access over port 8080 and 8443 for the same.We have allowed the access over port 8080 as plain HTTP Text while we have used Encrypted SSL communication for port 8443 using the same wildcard_spendhq_com_09_02_2017 certificate like port 443.We have tested the accessibility by hitting the preview.spendhq.com:8080 and it is working fine.But preview.spendhq.com:8443 was not accessible.To check the configuration further we tried hitting the port directly on the instance using its IP but it was not accessible.Hence, we can conclude that this is due to the application side configuration issue.Please verify it from your end and let us know if there are any more changes required from our side.",Matthew Watts3:14 AM (30 minutes ago)￼￼￼to Rean￼That is correct providing the DO NOT effect PRD traffic. My understanding is that these are two new definitions.,"Matthew Watts3:23 AM (21 minutes ago)￼￼￼to Praveen, Rean￼Confirmed. Thank you.","Praveen Kumar Muppala3:19 AM (25 minutes ago)￼￼￼to Matthew, Rean￼Time Window is wrongly mentioned it is 6:30PM EST","Hello Matthew,As per our understanding, in order to complete the request, we need to perform the below steps.1 - Create a Host definiton for PROD-SPHQ-WEB-SERVER04 - 10.59.100.104 IP Address2 - Create 2 WAF definitions(Virtual Web Server Definition)  - 8080 - Mimic the definition of preview 80    - Add 10.59.100.104 Web Server - Real Web Server  - 8443 0 Mimic the definition of preview 443    - Add 10.59.100.104 Web Server - Real Web Server3 - Allow 8080 / 8443 from public world in preview ELB Security Group Inbound/Outbound4 - Allow 8080 / 8443 traffic on PROD-SPHQ-WEB-SERVER04 SG (sg-855a34e3) from Sophos Security GroupPlease provide an approval to perform those steps.",Matthew Watts2:11 AM (48 minutes ago)￼￼￼to Rean￼Can we get a status update on the ETA?,"Hello Matthew,We will work on this request and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001KoQlu,Cloud Engineer Level 1,Closed,1085017,Incident,28-11-2017 23:50,,"Hello Matthew,Thanks for the update. We have decommissioned the 10.59.10.85 server. At this time, we are marking this case as resolved.###Matthew Watts11:17 PM (14 minutes ago)￼￼￼to Rean, spendhq-support￼Yes, please decommission this box.###Hello Matthew,Do you have any updates regarding this case?As mentioned by David Miller, please check and confirm if we are good to decommission the 10.59.10.85 server. If we haven't heard back from you regarding this case within the next 24 hours, we will be marking this case as resolved.Let us know if you have any queries regarding this case.Regards,Sumod.K.Bose###Followup with the customer during morning EST hours.###Hello Matthew, We haven't heard back from you. Could you please check and confirm whether we are good to decommission the server 10.59.10.85 as mentioned by David. Refer the instance resource details below, Resource Details:- Instance ID: i-01310ab6c76e88df9 Instance Name: PRD-DB-CLONE Instance type: r3.8xlarge Availability zone: us-east-1b Private IP: 10.59.10.85 VPC ID: vpc-76df7212 AMI ID: PRD-DB image (ami-08ce4d72) Subnet ID: subnet-0fdde924 Please review these details and let us know if you have any further queries.###Hello Matthew, We haven't heard back from you.Could you please check and confirm whether we are good to decommission the server 10.59.10.85 as mentioned by David. Refer the instance resource details below, Resource Details:- Instance ID: i-01310ab6c76e88df9 Instance Name: PRD-DB-CLONE Instance type: r3.8xlarge Availability zone: us-east-1b Private IP: 10.59.10.85 VPC ID: vpc-76df7212 AMI ID: PRD-DB image (ami-08ce4d72) Subnet ID: subnet-0fdde924 Please review these details and let us know if you have any further queries.###Hello Matthew,Could you please check and confirm whether we are good to decommission the server 10.59.10.85 as mentioned by David. Refer the instance resource details below,Resource Details:-Instance ID: i-01310ab6c76e88df9Instance Name: PRD-DB-CLONEInstance type: r3.8xlargeAvailability zone: us-east-1bPrivate IP: 10.59.10.85VPC ID: vpc-76df7212AMI ID: PRD-DB image (ami-08ce4d72)Subnet ID: subnet-0fdde924Kindly review these details and let us know if you have any further queries.Regards,Sumod.K.Bose###Waiting for approval.","Hello,We need to go ahead and decommission server 10.59.10.85.  Matthew can you confirm please that the ip is correct.Thank YouDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/>--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Decomission Server,,22-11-2017 00:39,167,0,SpendHQ,"Hello Matthew,Thanks for the update. We have decommissioned the 10.59.10.85 server. At this time, we are marking this case as resolved.","Matthew Watts11:17 PM (14 minutes ago)￼￼￼to Rean, spendhq-support￼Yes, please decommission this box.","Hello Matthew,Do you have any updates regarding this case?As mentioned by David Miller, please check and confirm if we are good to decommission the 10.59.10.85 server. If we haven't heard back from you regarding this case within the next 24 hours, we will be marking this case as resolved.Let us know if you have any queries regarding this case.Regards,Sumod.K.Bose",Followup with the customer during morning EST hours.,"Hello Matthew, We haven't heard back from you. Could you please check and confirm whether we are good to decommission the server 10.59.10.85 as mentioned by David. Refer the instance resource details below, Resource Details:- Instance ID: i-01310ab6c76e88df9 Instance Name: PRD-DB-CLONE Instance type: r3.8xlarge Availability zone: us-east-1b Private IP: 10.59.10.85 VPC ID: vpc-76df7212 AMI ID: PRD-DB image (ami-08ce4d72) Subnet ID: subnet-0fdde924 Please review these details and let us know if you have any further queries.","Hello Matthew, We haven't heard back from you.Could you please check and confirm whether we are good to decommission the server 10.59.10.85 as mentioned by David. Refer the instance resource details below, Resource Details:- Instance ID: i-01310ab6c76e88df9 Instance Name: PRD-DB-CLONE Instance type: r3.8xlarge Availability zone: us-east-1b Private IP: 10.59.10.85 VPC ID: vpc-76df7212 AMI ID: PRD-DB image (ami-08ce4d72) Subnet ID: subnet-0fdde924 Please review these details and let us know if you have any further queries.","Hello Matthew,Could you please check and confirm whether we are good to decommission the server 10.59.10.85 as mentioned by David. Refer the instance resource details below,Resource Details:-Instance ID: i-01310ab6c76e88df9Instance Name: PRD-DB-CLONEInstance type: r3.8xlargeAvailability zone: us-east-1bPrivate IP: 10.59.10.85VPC ID: vpc-76df7212AMI ID: PRD-DB image (ami-08ce4d72)Subnet ID: subnet-0fdde924Kindly review these details and let us know if you have any further queries.Regards,Sumod.K.Bose",Waiting for approval.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001T9xRI,Cloud Engineer Level 1,Closed,1093729,Incident,21-03-2018 02:17,,"Hello Team,This is to inform you that the alert got recovered and the violation lasted for 1hr. The current memory utilization is 57%As the alert is in the resolved state, we are marking this case as resolved. Kindly validate these details and revert back in case of any further queries.###Hello SpendHQ-Team, This is to inform you that we have received an alert regarding high memory Utilization on prd-ww1_122 (10.59.100.122) has exceeded the threshold value of 85 to 93.26%. Please find the resources details and memory utilization below. Resource Details:- Instance ID: i-0ace70ce06368e4a7 Instance Name: prd-ww1_122 Private IP: 10.59.100.122 USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDapache   28120  0.2  5.1 1148308 782628 ?      S    06:30   1:00 /usr/sbin/httpdapache   25372  1.8  3.7 936984 571788 ?       S    12:35   0:35 /usr/sbin/httpdapache   20308  0.3  3.6 930716 565588 ?       S    04:53   1:28 /usr/sbin/httpdapache   15109  1.3  3.6 918716 553136 ?       S    10:28   2:11 /usr/sbin/httpdclam      1635  0.0  3.6 714764 552684 ?       Ssl  Mar06   2:00 clamdapache   22560  1.1  3.5 919548 548564 ?       S    12:00   0:46 /usr/sbin/httpdapache   32652  0.5  3.5 912548 547192 ?       S    07:26   1:55 /usr/sbin/httpdapache   21089  1.0  3.4 899104 533756 ?       S    11:42   0:53 /usr/sbin/httpdapache   22600  0.3  3.4 898472 533016 ?       S    05:21   1:27 /usr/sbin/httpdapache   23009  0.7  3.4 891776 526624 ?       S    12:06   0:28 /usr/sbin/httpdKindly review this details and revert back to us if you gave any queries.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Tue, Mar 20, 2018 at 6:20 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Memory UtilizationAlert on host - prd-ww1_122 - 10.59.100.122 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww1_122- 10.59.100.122 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1521550187000&group=host%3Ai-0ace70ce06368e4a7&from_ts=1521549887000>avg(last_5m):( avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 85The monitor was last triggered at Tue Mar 20 2018 12:49:57 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-0ace70ce06368e4a7>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?hostname=i-0ace70ce06368e4a7>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1521550197000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1521549297000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4316565165545159756>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww1_122 - 10.59.100.122 - web,,20-03-2018 18:45,8,0,SpendHQ,"Hello Team,This is to inform you that the alert got recovered and the violation lasted for 1hr. The current memory utilization is 57%As the alert is in the resolved state, we are marking this case as resolved. Kindly validate these details and revert back in case of any further queries.","Hello SpendHQ-Team, This is to inform you that we have received an alert regarding high memory Utilization on prd-ww1_122 (10.59.100.122) has exceeded the threshold value of 85 to 93.26%. Please find the resources details and memory utilization below. Resource Details:- Instance ID: i-0ace70ce06368e4a7 Instance Name: prd-ww1_122 Private IP: 10.59.100.122 USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDapache   28120  0.2  5.1 1148308 782628 ?      S    06:30   1:00 /usr/sbin/httpdapache   25372  1.8  3.7 936984 571788 ?       S    12:35   0:35 /usr/sbin/httpdapache   20308  0.3  3.6 930716 565588 ?       S    04:53   1:28 /usr/sbin/httpdapache   15109  1.3  3.6 918716 553136 ?       S    10:28   2:11 /usr/sbin/httpdclam      1635  0.0  3.6 714764 552684 ?       Ssl  Mar06   2:00 clamdapache   22560  1.1  3.5 919548 548564 ?       S    12:00   0:46 /usr/sbin/httpdapache   32652  0.5  3.5 912548 547192 ?       S    07:26   1:55 /usr/sbin/httpdapache   21089  1.0  3.4 899104 533756 ?       S    11:42   0:53 /usr/sbin/httpdapache   22600  0.3  3.4 898472 533016 ?       S    05:21   1:27 /usr/sbin/httpdapache   23009  0.7  3.4 891776 526624 ?       S    12:06   0:28 /usr/sbin/httpdKindly review this details and revert back to us if you gave any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eNez5,Cloud Engineer Level 1,Closed,1107232,Incident,07-11-2018 10:31,,"Hello TeamThis is to notify you that the high memory utilization alert on the prd-ww2_6 - 10.59.101.6 instance ha got recovered and is in the Ok state now.The violation lasted for 40 minutes. The current memory utilization is 89.08%.As the alert is in the recovered state, we are marking this case as closed. Let us know if you have any queries###Hello Team,This is to inform you that we've received an alert regarding high memory utilization on the prd-ww2_6 - 10.59.101.6 instance.Current utilization is at 95.65% which is above the set threshold of 95%.We've analyzed the issue and can see that the httpd process is consuming majority of the memory plus CPU.Below is a breakdown of the same:-----------------------------------------top - 19:01:42 up 182 days, 48 min,  0 users,  load average: 3.27, 7.33, 13.08Tasks: 541 total,  10 running, 531 sleeping,   0 stopped,   0 zombieCpu(s):  4.3%us,  0.6%sy,  0.0%ni, 94.2%id,  0.7%wa,  0.0%hi,  0.1%si,  0.0%stMem:  32877480k total, 31932748k used,   944732k free,    20452k buffersSwap:        0k total,        0k used,        0k free,   153304k cached  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND            13100 apache    20   0  796m 439m 7544 R 100.0  1.4   0:17.52 httpd              9308 apache    20   0  601m 244m 7592 R 99.3  0.8   0:24.49 httpd              12970 apache    20   0  580m 222m 6332 R 83.7  0.7   0:52.22 httpd               9254 apache    20   0  583m 226m 7572 R 75.9  0.7   0:15.23 httpd              14877 apache    20   0  535m 180m 9268 R 68.1  0.6   0:04.19 httpd              14749 apache    20   0  527m 171m 7528 R 66.2  0.5   0:08.48 httpd              14670 apache    20   0  740m 355m 6952 R 64.3  1.1   0:29.48 httpd              13270 apache    20   0  427m  69m 6068 R 56.5  0.2   0:34.75 httpd              14876 apache    20   0  393m  36m 8148 R 48.7  0.1   0:00.48 httpd              10588 apache    20   0  864m 507m 7384 S 42.8  1.6   1:11.60 httpd              12230 apache    20   0  421m  63m 6820 S  3.9  0.2   0:28.65 httpd              15123 root      20   0 15288 1556  884 R  3.9  0.0   0:00.02 top                    1 root      20   0 19372 1448 1120 S  0.0  0.0  23:06.33 init                   2 root      20   0     0    0    0 S  0.0  0.0   0:00.14 kthreadd               3 root      RT   0     0    0    0 S  0.0  0.0  10:18.06 migration/0            4 root      20   0     0    0    0 S  0.0  0.0  12:00.77 ksoftirqd/0            5 root      RT   0     0    0    0 S  0.0  0.0   0:00.00 stopper/0              6 root      RT   0     0    0    0 S  0.0  0.0   0:24.83 watchdog/0         -----------------------------------------553.65 Mb /usr/sbin/httpd        498.68 Mb /usr/sbin/httpd        494.74 Mb /usr/sbin/httpd        474.11 Mb /usr/sbin/httpd        471.55 Mb /usr/sbin/httpd        468.86 Mb /usr/sbin/httpd        457.37 Mb /usr/sbin/httpd        456.99 Mb /usr/sbin/httpd        455.96 Mb /usr/sbin/httpd        431.00 Mb /usr/sbin/httpd        430.75 Mb /usr/sbin/httpd        429.40 Mb /usr/sbin/httpd        427.20 Mb /usr/sbin/httpd        426.19 Mb /usr/sbin/httpd        425.57 Mb /usr/sbin/httpd        418.57 Mb /usr/sbin/httpd        415.70 Mb /usr/bin/ssm-document-worker 54f9732a-3ab3-4ecb-88fd-b3194b59979b        412.35 Mb /usr/sbin/httpd        401.70 Mb /usr/sbin/httpd -----------------------------------------Thank you.","[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 -10.59.101.6 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1541530067000&group=host%3Ai-01ac95c23ac66a40e&from_ts=1541522867000>avg(last_30m):(avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by {host}- avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by{host} ) /avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by{host} * 100 > 95The monitor was last triggered at Tue Nov 06 2018 18:47:57 UTC (*5 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-01ac95c23ac66a40e>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-01ac95c23ac66a40e<https://app.datadoghq.com/infrastructure?filter=i-01ac95c23ac66a40e>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1541530197000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1541529177000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4651771975756721083>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Hosea B. Getusi,*Cloud Engineer,**REĀN Cloud | **Reach, Engage, Āctivate, Nurtur**Mobile*: +254713404220 | *Skype*: hoseagetusi*hosea.getusi@reancloud.com <hosea.getusi@reancloud.com>* |  *www.reancloud.com<http://www.reancloud.com>*--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 - 10.59.101.6 - web,,07-11-2018 00:33,10,0,SpendHQ,"Hello TeamThis is to notify you that the high memory utilization alert on the prd-ww2_6 - 10.59.101.6 instance ha got recovered and is in the Ok state now.The violation lasted for 40 minutes. The current memory utilization is 89.08%.As the alert is in the recovered state, we are marking this case as closed. Let us know if you have any queries","Hello Team,This is to inform you that we've received an alert regarding high memory utilization on the prd-ww2_6 - 10.59.101.6 instance.Current utilization is at 95.65% which is above the set threshold of 95%.We've analyzed the issue and can see that the httpd process is consuming majority of the memory plus CPU.Below is a breakdown of the same:-----------------------------------------top - 19:01:42 up 182 days, 48 min,  0 users,  load average: 3.27, 7.33, 13.08Tasks: 541 total,  10 running, 531 sleeping,   0 stopped,   0 zombieCpu(s):  4.3%us,  0.6%sy,  0.0%ni, 94.2%id,  0.7%wa,  0.0%hi,  0.1%si,  0.0%stMem:  32877480k total, 31932748k used,   944732k free,    20452k buffersSwap:        0k total,        0k used,        0k free,   153304k cached  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND            13100 apache    20   0  796m 439m 7544 R 100.0  1.4   0:17.52 httpd              9308 apache    20   0  601m 244m 7592 R 99.3  0.8   0:24.49 httpd              12970 apache    20   0  580m 222m 6332 R 83.7  0.7   0:52.22 httpd               9254 apache    20   0  583m 226m 7572 R 75.9  0.7   0:15.23 httpd              14877 apache    20   0  535m 180m 9268 R 68.1  0.6   0:04.19 httpd              14749 apache    20   0  527m 171m 7528 R 66.2  0.5   0:08.48 httpd              14670 apache    20   0  740m 355m 6952 R 64.3  1.1   0:29.48 httpd              13270 apache    20   0  427m  69m 6068 R 56.5  0.2   0:34.75 httpd              14876 apache    20   0  393m  36m 8148 R 48.7  0.1   0:00.48 httpd              10588 apache    20   0  864m 507m 7384 S 42.8  1.6   1:11.60 httpd              12230 apache    20   0  421m  63m 6820 S  3.9  0.2   0:28.65 httpd              15123 root      20   0 15288 1556  884 R  3.9  0.0   0:00.02 top                    1 root      20   0 19372 1448 1120 S  0.0  0.0  23:06.33 init                   2 root      20   0     0    0    0 S  0.0  0.0   0:00.14 kthreadd               3 root      RT   0     0    0    0 S  0.0  0.0  10:18.06 migration/0            4 root      20   0     0    0    0 S  0.0  0.0  12:00.77 ksoftirqd/0            5 root      RT   0     0    0    0 S  0.0  0.0   0:00.00 stopper/0              6 root      RT   0     0    0    0 S  0.0  0.0   0:24.83 watchdog/0         -----------------------------------------553.65 Mb /usr/sbin/httpd        498.68 Mb /usr/sbin/httpd        494.74 Mb /usr/sbin/httpd        474.11 Mb /usr/sbin/httpd        471.55 Mb /usr/sbin/httpd        468.86 Mb /usr/sbin/httpd        457.37 Mb /usr/sbin/httpd        456.99 Mb /usr/sbin/httpd        455.96 Mb /usr/sbin/httpd        431.00 Mb /usr/sbin/httpd        430.75 Mb /usr/sbin/httpd        429.40 Mb /usr/sbin/httpd        427.20 Mb /usr/sbin/httpd        426.19 Mb /usr/sbin/httpd        425.57 Mb /usr/sbin/httpd        418.57 Mb /usr/sbin/httpd        415.70 Mb /usr/bin/ssm-document-worker 54f9732a-3ab3-4ecb-88fd-b3194b59979b        412.35 Mb /usr/sbin/httpd        401.70 Mb /usr/sbin/httpd -----------------------------------------Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013uydp,Cloud Engineer Level 1,Closed,1030238,Incident,,,,"Failed WebAdmin login attempt from 10.242.2.4 at 2016-11-09 22:48:06 with username admin.        -- System Uptime      : 165 days 17 hours 15 minutesSystem Load        : 0.18System Version     : Sophos UTM 9.403-4Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][WARN-005] Failed WebAdmin login,,10-11-2016 04:18,2,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Baoq1,Cloud Engineer Level 1,Closed,1052713,Incident,11-05-2017 18:10,,"Hello SpendHQ Team, We haven't heard back from you regarding this case. At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue. Best Regards, Safuvan KM###Hello Team,On further analysing the ELB logs at the time of the alert, We are able to find the IP 199.46.250.154 which belongs to located in North Carolina region in United States is trying to execute the SERVER-APACHE Apache Struts remote code.As a fix we have blocked the IP at NACL level.Please find the logs details below Intrusion Prevention logs:2017:05:10-12:46:32 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.62 dstip=10.59.1.192 proto=6 srcport=58799 dstport=80 sid=41922 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:10-12:47:03 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.62 dstip=10.59.1.192 proto=6 srcport=58843 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0ELB Logs:2017-05-10T12:52:53.560612Z Secure-SpendHQ-ELB 199.46.250.154:31236 10.59.1.192:443 0.000044 0.116255 0.000037 404 404 0 6761 GET https://secure.spendhq.com:443/css/images/ui-icons_888888_256x240.png HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko ECDHE-RSA-AES128-GCM-SHA256 TLSv1.22017-05-10T12:52:53.560612Z Secure-SpendHQ-ELB 199.46.250.154:31236 10.59.1.192:443 0.000044 0.116255 0.000037 404 404 0 6761 GET https://secure.spendhq.com:443/css/images/ui-icons_888888_256x240.png HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Please get back to us if you have any queries.###Hello Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.62 which belongs to the secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",An intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-10 12:47:03Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.62Source port: 58843Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http),[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,10-05-2017 18:22,24,0,SpendHQ,"Hello SpendHQ Team, We haven't heard back from you regarding this case. At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue. Best Regards, Safuvan KM","Hello Team,On further analysing the ELB logs at the time of the alert, We are able to find the IP 199.46.250.154 which belongs to located in North Carolina region in United States is trying to execute the SERVER-APACHE Apache Struts remote code.As a fix we have blocked the IP at NACL level.Please find the logs details below Intrusion Prevention logs:2017:05:10-12:46:32 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.62 dstip=10.59.1.192 proto=6 srcport=58799 dstport=80 sid=41922 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:10-12:47:03 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.62 dstip=10.59.1.192 proto=6 srcport=58843 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0ELB Logs:2017-05-10T12:52:53.560612Z Secure-SpendHQ-ELB 199.46.250.154:31236 10.59.1.192:443 0.000044 0.116255 0.000037 404 404 0 6761 GET https://secure.spendhq.com:443/css/images/ui-icons_888888_256x240.png HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko ECDHE-RSA-AES128-GCM-SHA256 TLSv1.22017-05-10T12:52:53.560612Z Secure-SpendHQ-ELB 199.46.250.154:31236 10.59.1.192:443 0.000044 0.116255 0.000037 404 404 0 6761 GET https://secure.spendhq.com:443/css/images/ui-icons_888888_256x240.png HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Please get back to us if you have any queries.","Hello Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.62 which belongs to the secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ETl7K,Cloud Engineer Level 1,Closed,1067438,Incident,11-07-2017 20:34,,"Hello Steven,Thanks for the update.At this time, we are marking this case as resolved. Please let us k now if you have any queries.###Steven updated that,The stopped process was by us. We had to force a reboot for the service. Steven Ng | Full Stack Developer | SpendHQ®O: 770-628-0692 | sng@spendhq.com###Hello SpendHQ Team,This is to notify you that we have received a MySQL Process Down alert for prod-sphq-db-server05 instance. Later the alert got resolved and the violation has lasted for only 2 minutes.We are investigating the alert and meanwhile let us know if your team is performing any activity from your end.","[Triggered on {host:10.59.10.135,process:mysql}] [SpendHQ] MySQL Process is down - prod-sphq-db-server05  - 10.59.10.135 - db  MySQL Process is down @support@reancloud.com     @support@reancloud.comPROCS CRITICAL: 0 processes found for mysqlThis alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2014430?group=host%3A10.59.10.135%2Cprocess%3Amysql · Edit Monitor: https://app.datadoghq.com/monitors#2014430/edit · Event URL: https://app.datadoghq.com/event/event?id=3951399367558541427 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","[Monitor Alert] Triggered: [SpendHQ] MySQL Process is down - prod-sphq-db-server05 - 10.59.10.135 - db on process:mysql,host:10.59.10.135",,11-07-2017 20:20,0,0,SpendHQ,"Hello Steven,Thanks for the update.At this time, we are marking this case as resolved. Please let us k now if you have any queries.","Steven updated that,The stopped process was by us. We had to force a reboot for the service. Steven Ng | Full Stack Developer | SpendHQ®O: 770-628-0692 | sng@spendhq.com","Hello SpendHQ Team,This is to notify you that we have received a MySQL Process Down alert for prod-sphq-db-server05 instance. Later the alert got resolved and the violation has lasted for only 2 minutes.We are investigating the alert and meanwhile let us know if your team is performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Fcppp,Cloud Engineer Level 1,Closed,1072556,Incident,11-08-2017 01:50,,"Hi Team,Thanks for your confirmation over the call.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Hello Allen&Dusty,We can have a call to discuss this issue in details. We are available for the call at 2:30 PM EST today and shared the calendar invite already. Please let us know if this time works for you.Thank You,REAN Support###Dusty Fowler11:19 PM (0 minutes ago)to me, Allen, Sumod, Matthew, Spendhq Just to clarify, we were given an RPM file to setup the database and have been having difficulties getting it working. Dusty Fowler | Developer | SpendHQ®###Hello Allen,We will discuss this internally and will get back to you.Thank You,REAN Support###Allen Herrera10:20 PM (46 minutes ago)to Sumod, Matthew, Dusty, Spendhq Can you add it to monitoring and help me install infobright postgres. This is critical Allen Herrera | Developer | SpendHQ®###Allen Herrera10:37 PM (29 minutes ago)to Sumod, Matthew, Dusty, Spendhq As in , can we get on a call TODAY and figure this out Allen Herrera | Developer | SpendHQ®###Followed with Allen through email since she is not part of CMP###Next Action: Evening Shift: In the case of no response, send a reminder to the customer.###Hi Allen,This instance is not under REAN monitoring list. As per the request from Matthew, REAN team has lauched this instance from scratch and provided the Access to SpendHq Team.At the time of instance creation, we have created user accounts for Andrew and Matthew. Please find the below user credentials.UserNames: akim, mwattsPassword : <username>@shqPlease let us know whether we need to On-board this instance into our monitoring list.###Hello Allen,We are looking into this issue and will let you know the updates","Whats going on here rean? The ip is 10.59.10.190Sudo systemctl start infobright-iee-postgres.service[cid:image005.jpg@01D31119.A8D56BD0][cid:image006.jpg@01D31119.A8D56BD0]Allen Herrera | Developer | SpendHQ(r)M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Password to start postgres ?!?!?!,,09-08-2017 23:43,26,0,SpendHQ,"Hi Team,Thanks for your confirmation over the call.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Hello Allen&Dusty,We can have a call to discuss this issue in details. We are available for the call at 2:30 PM EST today and shared the calendar invite already. Please let us know if this time works for you.Thank You,REAN Support","Dusty Fowler11:19 PM (0 minutes ago)to me, Allen, Sumod, Matthew, Spendhq Just to clarify, we were given an RPM file to setup the database and have been having difficulties getting it working. Dusty Fowler | Developer | SpendHQ®","Hello Allen,We will discuss this internally and will get back to you.Thank You,REAN Support","Allen Herrera10:20 PM (46 minutes ago)to Sumod, Matthew, Dusty, Spendhq Can you add it to monitoring and help me install infobright postgres. This is critical Allen Herrera | Developer | SpendHQ®","Allen Herrera10:37 PM (29 minutes ago)to Sumod, Matthew, Dusty, Spendhq As in , can we get on a call TODAY and figure this out Allen Herrera | Developer | SpendHQ®",Followed with Allen through email since she is not part of CMP,"Next Action: Evening Shift: In the case of no response, send a reminder to the customer.","Hi Allen,This instance is not under REAN monitoring list. As per the request from Matthew, REAN team has lauched this instance from scratch and provided the Access to SpendHq Team.At the time of instance creation, we have created user accounts for Andrew and Matthew. Please find the below user credentials.UserNames: akim, mwattsPassword : <username>@shqPlease let us know whether we need to On-board this instance into our monitoring list.","Hello Allen,We are looking into this issue and will let you know the updates",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VrXQO,Cloud Engineer Level 2,Closed,1098242,Incident,17-05-2018 20:24,,"Rohit and Praveen went on a call with spendhq today for discussing the RCA, So we are closing this case###Hi Team,Please join the below bridge:https://reancloud.zoom.us/my/mgse2###Hello Team,Because of certain emergency reasons we have to reschedule the call that we have planned for today at 10:30 AM EST. We are rescheduling the call to tomorrow that is 17th May 2018 9:30 AM EST on the same bridge.  Please let us know if you have any concerns.Apologies for the inconvenience caused.###Hello Team,This is the gentle reminder. Please find the RCA attached to the ticket in the attachment section. We have scheduled a call for tomorrow 16th May 2018 10:30 AM EST Please join the below bridge for discussion tomorrow: https://reancloud.zoom.us/my/mgse1###Hi Team,Please find the RCA attached to the ticket in the attachment section. We have scheduled a call for tomorrow 16th May 2018 10:30 AM ESTPlease join the below bridge for discussion tomorrow:https://reancloud.zoom.us/my/mgse1###Hello Team,I have added the Corrective actions and sequence of events.Please update time details in the RCA. After that get it reviewed by Rohit.###Need to work on the RCA###Started working on the RCAhttps://docs.google.com/document/d/1JdBD_-xGYUU2SSeZUZAeORJJZYo66c7Oxjl1qdadY90/edit#please update the rest of the things.###Hello Team,Thanks for the response,We are working on the RCA and will get back to you with the update once it is done.###We have talked with Rohit regarding RCA and he updated that he will create an RCA for this.###Hello Andrew,Thanks for the update.We will prepare the document and will update you on the status.###Andrew Kim9:39 PM (6 minutes ago)to Matthew, Allen, Rean, spendhq-support Hello – we have tested and appears to be working now. We will use the current dataset to move forward – no additional data recovery is needed. Please provide documentation on steps taken to perform this and an action plan to prevent this from happening in the future. Thank you,###Hi Andrew,We were successful to mount the old volume 05--05-test-db on the folder /usr/local/infobright-products/iee/postgres. We have restarted the postgres service too. Please verify the data and let us know your thoughts on this. In meanwhile we will be working on the recovering the latest data.###Hello Andrew,We are working on this issue and will get back to you in an hour.###Any updates? 5 hours without an update for a sev1 is not acceptable, especially after a 4 day outage...Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 |akim@spendhq.com###Hello Andrew,We have fetched the latest data from volume recovery.We are currently working on the further case to resolve the issue regarding the mounting the volume.###Andrew Kim1:48 AM (27 minutes ago)to Rean, spendhq-support, Matthew, Allen Any update?###Just one quick point of clarification - the parent volume called , test-DB-170814, has data up to 03-14-18.  At which point this volume was cloned and labeled  03-14-18-recover, which was then mounted and used as the primary volume henceforth.It is this vol, 03-14-18-recover, which has suffered a corrupt system.Chris Veillette###Andrew Kim9:59 PM (1 hour ago)to Matthew, Allen, Rean, spendhq-support Thank you for the update. Please keep us updated. Thank you,###Hi Andrew,We had a discussion with Chris. We try to mount different time interval volume. But we were only able to mount the parent volume clone. This parent volume clone has data of 2017 end. With this data we were not able to restart the postgres service on the DB instance.For now, the team is working on fetching the latest data from recovery volume  which we were not able to mount as the FS type issue was occurring and all the data went to lost+found folder. We will try to start the postgres service once we will have the data build from recover volume. We will update you once we make progress on this.###Thanks Rohit. Unfortunately, the SHQ team will be unavailable until 12pm eastern. Please work with A3 at 10am, and provide and update. If the problem is still not resolved by 12, let me know and I will join the conference call. I am open to going back further than 24 hours for the restore point. @Chris - would there be any difference trying to restore from the backup Nimble? Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 |akim@spendhq.com###Hi Andrew,We have used fsck.ext4 too before that. But we were facing the same issue.###Andrew Kim3:06 PM (1 minute ago)to Rean, spendhq-support Thank you for the update. Was “e2fsck” the only tool tried or were others also tried?###Hi All,The meeting has been scheduled for 10 AM EST for today and invite has been sent. Please join the below bridge to troubleshoot the issue at 10 AM EST today.https://reancloud.zoom.us/my/mgse1;Regards,Rohit Puri###Thank you Andrew!@rohit.puri@reancloud.com - Schedule a call with Andromeda team at 10:00AM let's work on the bridge call until we resolve the issue.Regards,-Praveen###Hi Andrew,Sorry for delay response on this. We were analyzing the issue it took time. We used e2fsck this time. We try to fix it but the FS fixed but we ended up with the Lost+Found only in the volume provided. We were facing everytime this issue when we try to fix the FS type. Please find the screenshot in the attachment section for the same.###Please escalate. The last action update was from Chris at 11:53am. This is considered a sev1 and has been active for 72 hours. Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###I have tried to reach out to Praveen via Call and Slack many time but he was not available.###Hell Andrew,We are actively working on this issue and will get back to you shortly.###Andrew Kim5:23 AM (23 minutes ago)to Matthew, Rean, spendhq-support Can we get an update? This is approaching 72 hours and is still affecting clients.###Hello Andrew,We currently checking on this and will let you know the update.###Andrew Kim12:53 AM (7 minutes ago)to Matthew, Rean, spendhq-support What’s the status on the fs check? Thanks,###Hi Praveen,I mounted the new backup provided by Chris. It through the same error:mount: mount /dev/sdu on /usr/local/infobright-products/iee/postgres failed: Stale file handleWhen i gone through the https://www.cyberciti.biz/tips/surviving-a-linux-filesystem-failures.html article as shared by Andrew, this I don't think will help as I ran this command e2fsck -f but with no option I can see it was asking the same options and giving the same details as we ran the command for fsck.ext4Please have a look to this.###Rohit updated that he will work on this after 11PM###Hello Chris,Thanks for the update.We will check on this and will update you###OK -I built and mounted the volume, 03-10-18-recover-fs-check for testing purposes -lets see how it responds...###Chris Veillette7:37 PM (28 minutes ago)to Andrew, Rean, spendhq-support Good idea - you want me to mount a snapshot and try it out on it??###It sounds like we’ve tried to restore from points over 24 hours ago. I know we ran into this problem the last time as well, so I’m not confident that going back further will find a mountable volume. Have we tried running an e2fsck commend? https://www.cyberciti.biz/tips/surviving-a-linux-filesystem-failures.html Thanks, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Andrew Kim7:38 PM (26 minutes ago)to Chris, Rean, spendhq-support Yes please. Thanks Chris. Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hi Chris,Thanks for providing the new volume 05-09-18-PostGres (500GB).@Andrew: As the step you mentioned, mounting the old and new volume and copy the data to new. The old volume 03-14-18-recover has the issue of FS type as Chris mentioned. We tried to mount that volume again but we faced the Wrorng FS Type error. We need to use the volume older than this volume. If you agree with this then we can ask Chris to provide the backup older than this and we will do the steps as asked by you or we can simply mount the backup older than 03-14-18-recover this to the /usr/local/infobright-products/iee/postgres folderLet us know your thoughts on this. Thanks !###After received the volume details I have called and pinged to Praveen but he was not available and I also tried to call Rohit in morning but not reachable.@morning: Please check with Rohit and work.###Hi Everyone,I created a new 500GB vol called  05-09-18-PostGres- we can change the name later if so desired.Chris Veillette###Andrew Kim2:40 AM (3 minutes ago)to Chris, praveen.muppala, Matthew, spendhq-support Chris – when you get home, can you set up another 500GB volume? Please let REAN know the volume name. REAN – Once Chris provides the volume name, please mount both the old mount and the new volume, copy the data to the new volume, and have the new volume mounted to the PostGres directory. Then start the PostGres service. Do not restart the server or any other services aside from PostGres. Please keep us updated on the status as this is approaching 48 hours of unavailability. Thank you,###[Andrew Replied]I am available now. I believe the volume was readable – can we copy the data to a new volume and mount the new volume to the same location?###Chris Veillette2:34 AM (9 minutes ago)to Andrew, praveen.muppala, Matthew, spendhq-support Hi - if it is readable can build a empty volume - you could then mount it and copy data overI am my kids' soccer game - will be home around 730 Edt###Chris, I am sure we should get on a call along with SpendHQ team to get this addressed ASAP. @Andrew and @Matthew Watts – Let us know your availability to work on this. Regards,-Praveen###praveen.muppala@reancloud.com12:12 AM (7 minutes ago)to Chris, spendhq-support Hello Chris, Does the new volume is having the data that it supposed to have it. Regards,-Praveen###Chris Veillette11:18 PM (2 minutes ago)to Rean Ok - how about we try the parent volume since this was a clone...Chris Veillette###Hi Praveen,We are not able to start the postgres service on PRD-DB1 instanace as the service has the dependency on the data in the folder /usr/local/infobright-products/iee/postgres . For mounting the ISCSI volume to this folder we are failing to do so. As whenever we try to mount the volume it is giving error of wrong FS type. When we try to fix the error with fsck.ext4 we were able to fix the issue. But when we mounted the volume. There is only one folder is present with name Lost+Found which has number of unique number folder. When we try to move the recent folder data. Even though we are not able to start the service. Please have a look on this. We have asked Chris to provide the recovery volumes to mount.###Hi Chris,Please delete 03-14-18-recover24 as we tried to fix the FS type issue on this but we were not able to. Please provide the volume backup of 1day older and 2 days older. Please share the volumes details with us ASAP. Thanks !###Hello Chris,We are scheduling a call at 11:00 PM IST.Please join the bridge to troubleshoot the issue.https://reancloud.zoom.us/my/mgse2###Had a call with Rohit and he updated that he will schedule a call and fix this issue.###Hello Andrew,We are checking on this internally and will get back to you with an update.###Can we get a status update on getting the PostGres database server working on 10.59.10.190?At this time, our clients have not had access to related parts of our application for 36 hours.As a reminder, DO NOT restart any services or reboot the server without permission from Matthew Watts or myself (Andrew Kim).###Hello Chris,Thanks for the update.We are checking on this and will update you if any assistance needed from your end.###Chris Veillette5:25 PM (0 minutes ago)to Rean, spendhq-support done -called:     03-14-18-recover24Chris VeilletteCIO###Praveen updated that he needs an RCA for this case and set up a call with him on Thursday 2:30 PM IST hours.###Hi Chris, We haven't heard back from you, Please delete the volumes 03-14-18-recover1 and 03-14-18-recover2. Please provide the backup older than 24 hours.###Hi Chris, We haven't heard back from you,Please delete the volumes 03-14-18-recover1 and 03-14-18-recover2. Please provide the backup older than 24 hours.###Hi Chris,Please delete the volumes  03-14-18-recover1 and 03-14-18-recover2. Please provide the backup older than 24 hours.###Hi Chris,Please join this bridge for resolving the volume issue:https://zoom.us/j/900434392###Chris Veillette <cveillette@andromeda3.com>Attachments10:36 PM (16 minutes ago)to Rohit, Rean, spendhq-support 03-14-18-recover2###Rohit Puri10:15 PM (35 minutes ago)to Chris, Rean, spendhq-support Hi Chris,Volume details please.Regards,Rohit Puri###Chris Veillette <cveillette@andromeda3.com>10:07 PM (43 minutes ago)to Rean, spendhq-support done###Hi Chris,Please provide the volume backup older than 12 hours of ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:03-14-18-recover-v777bb21358661922.00000032.2f1dab31-lun-0. As the volume provided  03-14-18-recover1 is of no use.###Hi Andrew,The volume provided by Chris does not have the backup except lost+found folder. But in meanwhile, we were able to mount the original volume. If you want us to mount the newly created backup then we need to ask Chris to provide us again the backup.For restarting the services, while starting the postgres service we did not restart the mysql only once we did in the starting when Mathew was on call. Please let us know if we need to takecare of anything else to restart the postgres. Thanks !###Hi Team,We are able to mount the ISCSI Volume ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:03-14-18-recover-v777bb21358661922.00000032.2f1dab31-lun-0 .We are able to restart the mysql service but not able to start the postgres service on PRD-DB1 (10.59.10.190). Please have a look on this.###Hi Chris,This ISCSI Volume ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:03-14-18-recover-v777bb21358661922.00000032.2f1dab31-lun-0 got corrupted. Please provide pointing time snapshot from 5 hours back.###Hi Andrew,We have remounted the volumes on Production Database Server. Please restart the services or join the call here https://zoom.us/j/8795388904###Hi Team,We have mounted the ISCSI Volume back to NFS Server and NFS Client is also showing the right size on the mounted folder. We have remounted the volumes on PRD-DB and PRD-DB1. But facing the wrong FS on the PRD-DB1 when we try to remount the volume on the folder /usr/local/infobright-products/iee/postgresWe are working on resolving that. We will update you once we fix this.###Matthew Watts1:35 PM (8 minutes ago)to Rean, spendhq-support Can we setup aBridge to get an update please###Hello Team,We still haven't heard back from Andromeda Team Chris and David both.###Hi Andrew,The Primary Connection is up now. We are working on mounting the NFS volumes again. We will update you on this once done.###Matthew Watts12:59 PM (11 minutes ago)to Rean, spendhq-support, Chris, David What is the status here?###Hi Team,We reached out to the Andromeda Team  Chris and David both. We have left voice message too but we did not get any response yet. We need them to switchover to Secondary Connection.  We are keep on trying to get on a call with the Andromeda Team.###Hi Team,The NFS Server does not have connection with ISCSI Volumes attached to it as the switchover does not happen to the Secondary Connection. We need to wait till the Primary Connection is up again. Till then there will be downtime on the site.###Hello Mattew,Thanks for joining the call We are actively working on this issue and we are trying to reach out Chris.###Hi Team,When we are trying to start the httpd service we found that the files it is using has went to read only mode. Need to remount the volumes on NFS Server. We are trying to reach out to Andromeda Team on phone but we did not get any response.We need Andromeda team for resolving the issue as we will unmount and mount the ISCSI volumes on the NFS server.###Hello Chris,Could you please join the bridge https://reancloud.zoom.us/my/mgse2###Hello SpendHQ-Team,There is an on-going activity for scheduled maintenance for direct connect 10 Gbps and secure.spendhq.com has a permission issue due to httpd service is not starting up. We suspect that has caused this issue. Please join the bridge to further troubleshoot the issue:https://reancloud.zoom.us/my/mgse2###Hello Spendhq-Team,This is to notify you that we received an alert site down on the URL:  https://secure.spendhq.com/login .The site is not accessible.Please let us know if you are perfroming any changes on your end.","Mon, 07 May 2018 23:08:42 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30016 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Dallas-B US, London UK, Frankfurt DE, Atlanta-B US--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,08-05-2018 08:38,228,0,SpendHQ,"Rohit and Praveen went on a call with spendhq today for discussing the RCA, So we are closing this case","Hi Team,Please join the below bridge:https://reancloud.zoom.us/my/mgse2","Hello Team,Because of certain emergency reasons we have to reschedule the call that we have planned for today at 10:30 AM EST. We are rescheduling the call to tomorrow that is 17th May 2018 9:30 AM EST on the same bridge.  Please let us know if you have any concerns.Apologies for the inconvenience caused.","Hello Team,This is the gentle reminder. Please find the RCA attached to the ticket in the attachment section. We have scheduled a call for tomorrow 16th May 2018 10:30 AM EST Please join the below bridge for discussion tomorrow: https://reancloud.zoom.us/my/mgse1","Hi Team,Please find the RCA attached to the ticket in the attachment section. We have scheduled a call for tomorrow 16th May 2018 10:30 AM ESTPlease join the below bridge for discussion tomorrow:https://reancloud.zoom.us/my/mgse1","Hello Team,I have added the Corrective actions and sequence of events.Please update time details in the RCA. After that get it reviewed by Rohit.",Need to work on the RCA,Started working on the RCAhttps://docs.google.com/document/d/1JdBD_-xGYUU2SSeZUZAeORJJZYo66c7Oxjl1qdadY90/edit#please update the rest of the things.,"Hello Team,Thanks for the response,We are working on the RCA and will get back to you with the update once it is done.",We have talked with Rohit regarding RCA and he updated that he will create an RCA for this.,"Hello Andrew,Thanks for the update.We will prepare the document and will update you on the status.","Andrew Kim9:39 PM (6 minutes ago)to Matthew, Allen, Rean, spendhq-support Hello – we have tested and appears to be working now. We will use the current dataset to move forward – no additional data recovery is needed. Please provide documentation on steps taken to perform this and an action plan to prevent this from happening in the future. Thank you,","Hi Andrew,We were successful to mount the old volume 05--05-test-db on the folder /usr/local/infobright-products/iee/postgres. We have restarted the postgres service too. Please verify the data and let us know your thoughts on this. In meanwhile we will be working on the recovering the latest data.","Hello Andrew,We are working on this issue and will get back to you in an hour.","Any updates? 5 hours without an update for a sev1 is not acceptable, especially after a 4 day outage...Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 |akim@spendhq.com","Hello Andrew,We have fetched the latest data from volume recovery.We are currently working on the further case to resolve the issue regarding the mounting the volume.","Andrew Kim1:48 AM (27 minutes ago)to Rean, spendhq-support, Matthew, Allen Any update?","Just one quick point of clarification - the parent volume called , test-DB-170814, has data up to 03-14-18.  At which point this volume was cloned and labeled  03-14-18-recover, which was then mounted and used as the primary volume henceforth.It is this vol, 03-14-18-recover, which has suffered a corrupt system.Chris Veillette","Andrew Kim9:59 PM (1 hour ago)to Matthew, Allen, Rean, spendhq-support Thank you for the update. Please keep us updated. Thank you,","Hi Andrew,We had a discussion with Chris. We try to mount different time interval volume. But we were only able to mount the parent volume clone. This parent volume clone has data of 2017 end. With this data we were not able to restart the postgres service on the DB instance.For now, the team is working on fetching the latest data from recovery volume  which we were not able to mount as the FS type issue was occurring and all the data went to lost+found folder. We will try to start the postgres service once we will have the data build from recover volume. We will update you once we make progress on this.","Thanks Rohit. Unfortunately, the SHQ team will be unavailable until 12pm eastern. Please work with A3 at 10am, and provide and update. If the problem is still not resolved by 12, let me know and I will join the conference call. I am open to going back further than 24 hours for the restore point. @Chris - would there be any difference trying to restore from the backup Nimble? Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 |akim@spendhq.com","Hi Andrew,We have used fsck.ext4 too before that. But we were facing the same issue.","Andrew Kim3:06 PM (1 minute ago)to Rean, spendhq-support Thank you for the update. Was “e2fsck” the only tool tried or were others also tried?","Hi All,The meeting has been scheduled for 10 AM EST for today and invite has been sent. Please join the below bridge to troubleshoot the issue at 10 AM EST today.https://reancloud.zoom.us/my/mgse1;Regards,Rohit Puri","Thank you Andrew!@rohit.puri@reancloud.com - Schedule a call with Andromeda team at 10:00AM let's work on the bridge call until we resolve the issue.Regards,-Praveen","Hi Andrew,Sorry for delay response on this. We were analyzing the issue it took time. We used e2fsck this time. We try to fix it but the FS fixed but we ended up with the Lost+Found only in the volume provided. We were facing everytime this issue when we try to fix the FS type. Please find the screenshot in the attachment section for the same.",Please escalate. The last action update was from Chris at 11:53am. This is considered a sev1 and has been active for 72 hours. Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com,I have tried to reach out to Praveen via Call and Slack many time but he was not available.,"Hell Andrew,We are actively working on this issue and will get back to you shortly.","Andrew Kim5:23 AM (23 minutes ago)to Matthew, Rean, spendhq-support Can we get an update? This is approaching 72 hours and is still affecting clients.","Hello Andrew,We currently checking on this and will let you know the update.","Andrew Kim12:53 AM (7 minutes ago)to Matthew, Rean, spendhq-support What’s the status on the fs check? Thanks,","Hi Praveen,I mounted the new backup provided by Chris. It through the same error:mount: mount /dev/sdu on /usr/local/infobright-products/iee/postgres failed: Stale file handleWhen i gone through the https://www.cyberciti.biz/tips/surviving-a-linux-filesystem-failures.html article as shared by Andrew, this I don't think will help as I ran this command e2fsck -f but with no option I can see it was asking the same options and giving the same details as we ran the command for fsck.ext4Please have a look to this.",Rohit updated that he will work on this after 11PM,"Hello Chris,Thanks for the update.We will check on this and will update you","OK -I built and mounted the volume, 03-10-18-recover-fs-check for testing purposes -lets see how it responds...","Chris Veillette7:37 PM (28 minutes ago)to Andrew, Rean, spendhq-support Good idea - you want me to mount a snapshot and try it out on it??","It sounds like we’ve tried to restore from points over 24 hours ago. I know we ran into this problem the last time as well, so I’m not confident that going back further will find a mountable volume. Have we tried running an e2fsck commend? https://www.cyberciti.biz/tips/surviving-a-linux-filesystem-failures.html Thanks, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Andrew Kim7:38 PM (26 minutes ago)to Chris, Rean, spendhq-support Yes please. Thanks Chris. Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Hi Chris,Thanks for providing the new volume 05-09-18-PostGres (500GB).@Andrew: As the step you mentioned, mounting the old and new volume and copy the data to new. The old volume 03-14-18-recover has the issue of FS type as Chris mentioned. We tried to mount that volume again but we faced the Wrorng FS Type error. We need to use the volume older than this volume. If you agree with this then we can ask Chris to provide the backup older than this and we will do the steps as asked by you or we can simply mount the backup older than 03-14-18-recover this to the /usr/local/infobright-products/iee/postgres folderLet us know your thoughts on this. Thanks !",After received the volume details I have called and pinged to Praveen but he was not available and I also tried to call Rohit in morning but not reachable.@morning: Please check with Rohit and work.,"Hi Everyone,I created a new 500GB vol called  05-09-18-PostGres- we can change the name later if so desired.Chris Veillette","Andrew Kim2:40 AM (3 minutes ago)to Chris, praveen.muppala, Matthew, spendhq-support Chris – when you get home, can you set up another 500GB volume? Please let REAN know the volume name. REAN – Once Chris provides the volume name, please mount both the old mount and the new volume, copy the data to the new volume, and have the new volume mounted to the PostGres directory. Then start the PostGres service. Do not restart the server or any other services aside from PostGres. Please keep us updated on the status as this is approaching 48 hours of unavailability. Thank you,",[Andrew Replied]I am available now. I believe the volume was readable – can we copy the data to a new volume and mount the new volume to the same location?,"Chris Veillette2:34 AM (9 minutes ago)to Andrew, praveen.muppala, Matthew, spendhq-support Hi - if it is readable can build a empty volume - you could then mount it and copy data overI am my kids' soccer game - will be home around 730 Edt","Chris, I am sure we should get on a call along with SpendHQ team to get this addressed ASAP. @Andrew and @Matthew Watts – Let us know your availability to work on this. Regards,-Praveen","praveen.muppala@reancloud.com12:12 AM (7 minutes ago)to Chris, spendhq-support Hello Chris, Does the new volume is having the data that it supposed to have it. Regards,-Praveen",Chris Veillette11:18 PM (2 minutes ago)to Rean Ok - how about we try the parent volume since this was a clone...Chris Veillette,"Hi Praveen,We are not able to start the postgres service on PRD-DB1 instanace as the service has the dependency on the data in the folder /usr/local/infobright-products/iee/postgres . For mounting the ISCSI volume to this folder we are failing to do so. As whenever we try to mount the volume it is giving error of wrong FS type. When we try to fix the error with fsck.ext4 we were able to fix the issue. But when we mounted the volume. There is only one folder is present with name Lost+Found which has number of unique number folder. When we try to move the recent folder data. Even though we are not able to start the service. Please have a look on this. We have asked Chris to provide the recovery volumes to mount.","Hi Chris,Please delete 03-14-18-recover24 as we tried to fix the FS type issue on this but we were not able to. Please provide the volume backup of 1day older and 2 days older. Please share the volumes details with us ASAP. Thanks !","Hello Chris,We are scheduling a call at 11:00 PM IST.Please join the bridge to troubleshoot the issue.https://reancloud.zoom.us/my/mgse2",Had a call with Rohit and he updated that he will schedule a call and fix this issue.,"Hello Andrew,We are checking on this internally and will get back to you with an update.","Can we get a status update on getting the PostGres database server working on 10.59.10.190?At this time, our clients have not had access to related parts of our application for 36 hours.As a reminder, DO NOT restart any services or reboot the server without permission from Matthew Watts or myself (Andrew Kim).","Hello Chris,Thanks for the update.We are checking on this and will update you if any assistance needed from your end.","Chris Veillette5:25 PM (0 minutes ago)to Rean, spendhq-support done -called:     03-14-18-recover24Chris VeilletteCIO",Praveen updated that he needs an RCA for this case and set up a call with him on Thursday 2:30 PM IST hours.,"Hi Chris, We haven't heard back from you, Please delete the volumes 03-14-18-recover1 and 03-14-18-recover2. Please provide the backup older than 24 hours.","Hi Chris, We haven't heard back from you,Please delete the volumes 03-14-18-recover1 and 03-14-18-recover2. Please provide the backup older than 24 hours.","Hi Chris,Please delete the volumes  03-14-18-recover1 and 03-14-18-recover2. Please provide the backup older than 24 hours.","Hi Chris,Please join this bridge for resolving the volume issue:https://zoom.us/j/900434392","Chris Veillette <cveillette@andromeda3.com>Attachments10:36 PM (16 minutes ago)to Rohit, Rean, spendhq-support 03-14-18-recover2","Rohit Puri10:15 PM (35 minutes ago)to Chris, Rean, spendhq-support Hi Chris,Volume details please.Regards,Rohit Puri","Chris Veillette <cveillette@andromeda3.com>10:07 PM (43 minutes ago)to Rean, spendhq-support done","Hi Chris,Please provide the volume backup older than 12 hours of ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:03-14-18-recover-v777bb21358661922.00000032.2f1dab31-lun-0. As the volume provided  03-14-18-recover1 is of no use.","Hi Andrew,The volume provided by Chris does not have the backup except lost+found folder. But in meanwhile, we were able to mount the original volume. If you want us to mount the newly created backup then we need to ask Chris to provide us again the backup.For restarting the services, while starting the postgres service we did not restart the mysql only once we did in the starting when Mathew was on call. Please let us know if we need to takecare of anything else to restart the postgres. Thanks !","Hi Team,We are able to mount the ISCSI Volume ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:03-14-18-recover-v777bb21358661922.00000032.2f1dab31-lun-0 .We are able to restart the mysql service but not able to start the postgres service on PRD-DB1 (10.59.10.190). Please have a look on this.","Hi Chris,This ISCSI Volume ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:03-14-18-recover-v777bb21358661922.00000032.2f1dab31-lun-0 got corrupted. Please provide pointing time snapshot from 5 hours back.","Hi Andrew,We have remounted the volumes on Production Database Server. Please restart the services or join the call here https://zoom.us/j/8795388904","Hi Team,We have mounted the ISCSI Volume back to NFS Server and NFS Client is also showing the right size on the mounted folder. We have remounted the volumes on PRD-DB and PRD-DB1. But facing the wrong FS on the PRD-DB1 when we try to remount the volume on the folder /usr/local/infobright-products/iee/postgresWe are working on resolving that. We will update you once we fix this.","Matthew Watts1:35 PM (8 minutes ago)to Rean, spendhq-support Can we setup aBridge to get an update please","Hello Team,We still haven't heard back from Andromeda Team Chris and David both.","Hi Andrew,The Primary Connection is up now. We are working on mounting the NFS volumes again. We will update you on this once done.","Matthew Watts12:59 PM (11 minutes ago)to Rean, spendhq-support, Chris, David What is the status here?","Hi Team,We reached out to the Andromeda Team  Chris and David both. We have left voice message too but we did not get any response yet. We need them to switchover to Secondary Connection.  We are keep on trying to get on a call with the Andromeda Team.","Hi Team,The NFS Server does not have connection with ISCSI Volumes attached to it as the switchover does not happen to the Secondary Connection. We need to wait till the Primary Connection is up again. Till then there will be downtime on the site.","Hello Mattew,Thanks for joining the call We are actively working on this issue and we are trying to reach out Chris.","Hi Team,When we are trying to start the httpd service we found that the files it is using has went to read only mode. Need to remount the volumes on NFS Server. We are trying to reach out to Andromeda Team on phone but we did not get any response.We need Andromeda team for resolving the issue as we will unmount and mount the ISCSI volumes on the NFS server.","Hello Chris,Could you please join the bridge https://reancloud.zoom.us/my/mgse2","Hello SpendHQ-Team,There is an on-going activity for scheduled maintenance for direct connect 10 Gbps and secure.spendhq.com has a permission issue due to httpd service is not starting up. We suspect that has caused this issue. Please join the bridge to further troubleshoot the issue:https://reancloud.zoom.us/my/mgse2","Hello Spendhq-Team,This is to notify you that we received an alert site down on the URL:  https://secure.spendhq.com/login .The site is not accessible.Please let us know if you are perfroming any changes on your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001cJJSw,Cloud Engineer Level 1,Closed,1105487,Incident,04-10-2018 22:19,,"Hello Chris,Thanks for the update, at this point we are marking this case as resolved and proceeding to close the case.Please reach out to us for continued support.Thanks.###Leonel Atencio <latencio@number8.com>7:24 PM (4 minutes ago)to Chris, Rohit, Paul, isaac.muteti@reancloud.com, chandrapratap.singh@reancloud.com, Andrew, Matthew, REANI also got it###Chris Min <cmin@spendhq.com>7:18 PM (6 minutes ago)to Rohit, Paul, isaac.muteti@reancloud.com, latencio@number8.com, chandrapratap.singh@reancloud.com, Andrew, Matthew, REANThank you guys.I just received the password from Paul and verified that I could perform sudo actions without password. Thanks,###Paul Mulonzia3:37 PM (0 minutes ago)to Chris, Isaac, latencio, Chandrapratap, Akim, Matthew, REANHello Chris,We have verified that you already have sudo permissions across all three servers, please share with us the exact error you are getting.Thanks.###Paul Mulonzia <paul.mulonzia@reancloud.com>2:31 PM (10 minutes ago)to REAN, Chris, Isaac, latencio, Chandrapratap, Akim, MatthewHello Chris,We are checking on your user permissions and we will be updating you in a short while.Regards,###Chris Min:Hi Isaac,I (cmin) still can’t sudo anything. Is there an extra I need to take to run commands as a sudoer?Thanks,###Isaac Mwania1:21 AM (0 minutes ago)to latencio, Chandrapratap, cmin, REAN, Akim, MatthewHello Chris, LeonelWe have provided sudo permission to latencio, cmin, and rlittle on all the instances.Please check and let us know if you have any questions.###From : Leonel AtencioI will also need to be able to run sudo su to run commands as root.###Hello Chris,Sure, we will work and provide sudo access to the following users latencio, cmin, and rlittle on all three instances.###REAN, Could you give latencio, cmin, and rlittle sudo permission on those instances?10.59.100.2510.59.100.6110.59.100.248Thank you,Chris Min | Senior Data Engineer | SpendHQ®O: 470.204.0862 | C: 770.688.5695 | cmin@spendhq.com###Isaac Mwania12:34 AM (1 minute ago)to cmin, REAN, Akim, Matthew, latencioHello Chris,Thank you reaching out to us.###Chris Min12:18 AM (16 minutes ago)to me, REAN, Andrew, Matthew, latencio@number8.comI see. I guess the problem is elsewhere. Thank you for checking.###Isaac Mwania <isaac.muteti@reancloud.com>11:00 PM (0 minutes ago)to cmin, REAN, Akim, Matthew, latencioHello Chris,We have not revoked any access.We have also checked from all the machines and the user (Leonel) and his keys are still there.Please check and let us know if you have any further questions.###Below are the users in the three servers:centos  cmin  latencio  mwatts  rlittle###Team,I tried checking on all three servers (these were recently created in this ticket 01105019). In the request we only created one user - mwatts. On further checking on the failed logins, I could see some failed logins from an unknown user, please check with the customer the user they are trying to log in with.below are the logs to the failed login attempts:https://docs.google.com/document/d/1tDtBQd-kWnTrTEcrZ-oBNejjNrb2Pnmo_5I-VgTS58I/edit?usp=sharing###Hello Chris,We are checking on this issue and we will get back to you with more details.Thank you.","REAN,We have a contractor (Leonel) who has been working with10.59.100.2510.59.100.6110.59.100.248His access got revoked all of a sudden. Did you remove his access by any chance? If so, please restore his access.Thanks,Chris Min | Senior Data Engineer | SpendHQ®O: 470.204.0862 | C: 770.688.5695 | cmin@spendhq.com<mailto:cmin@spenhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","SSH public keys disappeared from 10.59.100.{25, 61, 248} all of a sudden",,03-10-2018 21:05,25,0,SpendHQ,"Hello Chris,Thanks for the update, at this point we are marking this case as resolved and proceeding to close the case.Please reach out to us for continued support.Thanks.","Leonel Atencio <latencio@number8.com>7:24 PM (4 minutes ago)to Chris, Rohit, Paul, isaac.muteti@reancloud.com, chandrapratap.singh@reancloud.com, Andrew, Matthew, REANI also got it","Chris Min <cmin@spendhq.com>7:18 PM (6 minutes ago)to Rohit, Paul, isaac.muteti@reancloud.com, latencio@number8.com, chandrapratap.singh@reancloud.com, Andrew, Matthew, REANThank you guys.I just received the password from Paul and verified that I could perform sudo actions without password. Thanks,","Paul Mulonzia3:37 PM (0 minutes ago)to Chris, Isaac, latencio, Chandrapratap, Akim, Matthew, REANHello Chris,We have verified that you already have sudo permissions across all three servers, please share with us the exact error you are getting.Thanks.","Paul Mulonzia <paul.mulonzia@reancloud.com>2:31 PM (10 minutes ago)to REAN, Chris, Isaac, latencio, Chandrapratap, Akim, MatthewHello Chris,We are checking on your user permissions and we will be updating you in a short while.Regards,","Chris Min:Hi Isaac,I (cmin) still can’t sudo anything. Is there an extra I need to take to run commands as a sudoer?Thanks,","Isaac Mwania1:21 AM (0 minutes ago)to latencio, Chandrapratap, cmin, REAN, Akim, MatthewHello Chris, LeonelWe have provided sudo permission to latencio, cmin, and rlittle on all the instances.Please check and let us know if you have any questions.",From : Leonel AtencioI will also need to be able to run sudo su to run commands as root.,"Hello Chris,Sure, we will work and provide sudo access to the following users latencio, cmin, and rlittle on all three instances.","REAN, Could you give latencio, cmin, and rlittle sudo permission on those instances?10.59.100.2510.59.100.6110.59.100.248Thank you,Chris Min | Senior Data Engineer | SpendHQ®O: 470.204.0862 | C: 770.688.5695 | cmin@spendhq.com","Isaac Mwania12:34 AM (1 minute ago)to cmin, REAN, Akim, Matthew, latencioHello Chris,Thank you reaching out to us.","Chris Min12:18 AM (16 minutes ago)to me, REAN, Andrew, Matthew, latencio@number8.comI see. I guess the problem is elsewhere. Thank you for checking.","Isaac Mwania <isaac.muteti@reancloud.com>11:00 PM (0 minutes ago)to cmin, REAN, Akim, Matthew, latencioHello Chris,We have not revoked any access.We have also checked from all the machines and the user (Leonel) and his keys are still there.Please check and let us know if you have any further questions.",Below are the users in the three servers:centos  cmin  latencio  mwatts  rlittle,"Team,I tried checking on all three servers (these were recently created in this ticket 01105019). In the request we only created one user - mwatts. On further checking on the failed logins, I could see some failed logins from an unknown user, please check with the customer the user they are trying to log in with.below are the logs to the failed login attempts:https://docs.google.com/document/d/1tDtBQd-kWnTrTEcrZ-oBNejjNrb2Pnmo_5I-VgTS58I/edit?usp=sharing","Hello Chris,We are checking on this issue and we will get back to you with more details.Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hQxmw,Cloud Engineer Level 2,Closed,1110180,Incident,08-01-2019 19:36,,"Hello SpendHQ-Team, We are closing the current case as the issue got fixed on 10-59-10-50  instance and created another case to track the initiator issue from the instance 10.59.10.135. Please find the case ID: 01110431 to the new case.  We will continue work on the issue and will share the details over the there. Let us know if you have any concerns.###@Praveen:Initially we got an alert for RO mode issue on 10-59-10-50 by our Jenkins Job. We worked on it with the help of Chris to resolve as we were not able to mount that volume. Some issue at Anderomeda side. We were able to resolve this once changes made by Chris. Then we got an update from Chris (A3 Team) the logs were flooding with “login was rejected due to initiator error” at his end for initiator issue from the instance 10.59.10.135This created an confusion between all three of us (SpendHQ Team, REAN Team and A3 Team) As sometime it was asked to get close the ticket from SpendHQ Team and A3 was also saying the same that issue got resolved. But when we verified from our end the messages logs were flooding with the error login rejected: initiator errorI have verified now also the logs are still flooding with this error. For this we need to work with A3 Team to get on a call to understand the same. We tried to reach him but could not get him on call.###Hello Chris,The issue still persist on the server 10.59.10.135 and we can see the messages logs are still flooding with an error of iscsid: conn 0 login rejected: initiator error (02/04).Can we have a call to understand and resolve the same?Please let me know your availability. Thanks !###The errors are still getting. Please check with Rohit for further actions.###[ Internal Slack Communication on Mgs Group ]Praveen Kumar Muppala [Today at 20:45]@rohit.puri and team what is the status of this ticket - ISCSI Device Details which are in RO mode7 repliesRafi.Ramesh [2 hours ago]@praveen.muppala we asked them provide their availability to schedule a call.Praveen Kumar Muppala [2 hours ago]You mean Chris from Andromeda3.Rafi.Ramesh [2 hours ago]yesPraveen Kumar Muppala [2 hours ago]Ok. Did anyone called them or not?Rafi.Ramesh [2 hours ago]yes we called chris. but he is not reachable.we will try again him in half an hourPraveen Kumar Muppala [2 hours ago]@chirodeep.roy and @rohit.puri - There is a different note from Chris. Can you guys review and address it ASAP. I am not sure what's going on here.Chirodeep Roy [1 hour ago]@praveen.muppala I will speak to Rohit and ask him to add if anything else is required on this issue.###[ Below response, we received from Chris before Nishad mail.]Chris Veillette9:07 PM (1 hour ago)to Jason, Matthew, Nishad, Will, spendhq-support@reancloud.comConfused- this was resolved last Friday AM###Hello Matthew,We have again checked from our end on this and still we could see that the /var/log/messages are get flooded with the below log entries. Kindly check with the same from your end . [root@ip-10-59-10-135 log]# tailf  messagesJan  7 15:51:32 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:51:32 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:51:46 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:51:46 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:51:47 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:51:47 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:52:01 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:52:01 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:52:01 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:52:01 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)We are waiting for your update to proceed further to closing this case.Thanks###[Via Email]Then let’s close it off team.Matthew Watts | Manager, Application Development |SpendHQ®###[Via Mail]Jason Bray <jbray@spendhq.com>6:09 PM (23 minutes ago)to Matthew, Nishad, Will, Chris, spendhq-support@reancloud.com﻿Agreed! This needs immediate attention to resolve.###[Via Mail]Matthew Watts12:45 PM (5 hours ago)to Nishad, Will, Chris, spendhq-support@reancloud.comTeam. This needs immediate elevation. It’s unacceptable for this to be in this state for so long. Please get with Will and resolve ASAP. Treat as SEV ONE.###@TeamTried to Get Chris on call but he is not accepting the call.  please try to get in touch with him to get on a call to look on this issue ASAP###Hi Matthew,We are re-opening this ticket. We will work along with Chris from A3 Team to resolve this ASAP.Chris:Please let us know your availability as we need to jump on a call to resolve this ASAP. We already shared with you the logs for error on login rejected.###@Team:Please re-open this ticket. Why we close this ticket without customer confirmation?Schedule a call with Chris from A3 Team###Hello Chris,We have further checked with logs and could not see the errors are getting generated today.So as per the Wills confirmation on the last comment by him, we are marking this case closed as we could see that the issue is got fixed from our end also. Feel free to reopen the case if you have any queries.Thanks###Hello Chris, We had disconnected the call as you had not joined the call. Can you please verify once again regarding the error as we can see that it still flooding the /var/log/messages  logs Awaiting your reply to proceed further on this case. Thanks###Hello Chris From our end, we could see that the bellow error still flooding the /var/log/messages =========== [root@ip-10-59-10-135 production_25_08_2018]# tail -10f /var/log/messages Jan 4 18:05:29 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:30 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:44 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:44 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:44 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:44 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:58 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:59 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:59 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:59 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) ========== Can you Join on the below same bridge to look into this issue?###I think we are good now...errors stoppedChris Veillette###Hello Chris We had checked on this issue from our end also ands could see the same error that you mentioned flooding the logs.==============Jan  4 17:32:35 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/00)Jan  4 17:32:35 ip-10-59-10-135 iscsid: Kernel reported iSCSI connection 23:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (1)Jan  4 17:32:35 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/00)Jan  4 17:32:35 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/00)Jan  4 17:32:35 ip-10-59-10-135 iscsid: Kernel reported iSCSI connection 29:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (1)Jan  4 17:32:35 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error - target not found (02/03)Jan  4 17:32:35 ip-10-59-10-135 kernel: connection33:0: detected conn error (1020)Jan  4 17:32:36 ip-10-59-10-135 kernel: connection28:0: detected conn error (1020)Jan  4 17:32:36 ip-10-59-10-135 kernel: connection23:0: detected conn error (1020)====== We also tried to logout from the volumes at the IPs with the 172.24.5.3 and 172.24.5.3 which are not used by the instance and we are getting the but we are getting the below error. [root@ip-10-59-10-135 production_25_08_2018]# iscsiadm --mode node --targetname ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0scsi-test:dev9.ctr2-lun-9 --portal 172.24.5.3:3260,1 --logoutiscsiadm: No matching sessions found[root@ip-10-59-10-135 production_25_08_2018]# iscsiadm --mode node --targetname  ip-172.24.5.2:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev0.ctr1-lun-3 --portal 172.24.5.3:3260,1 --logoutiscsiadm: No matching sessions found[root@ip-10-59-10-135 production_25_08_2018]# iscsiadm --mode node --targetname  ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:clone-db-v777bb21358661922.0000001d.2f1dab31-lun-0 --portal 172.23.104.77:3260,1 --logoutiscsiadm: No matching sessions found  Kindly Join the below bridge to fix the issue https://reancloud.zoom.us/my/mgse1###Hello Chris, We will check on this and get back to you ASAP. Regards###I have been able to restart the services on the server and so far it does not appear to show any issues. After issue with 64d02cf7e3df - ip 10.59.10.135 is troubleshooted I believe the ticket can be closed. Thanks, Will Will Webb###Hello Chris Thanks for the update. Will  let you know if still facing any issues. Regards###Great - one thing : can you check instance 64d02cf7e3df - ip 10.59.10.135I am getting an error in my end complaining that “login was rejected due to initiator error”......  it is filling up my error log file ....Chris Veillette###Ok - good - let me ASAP if there are further issues 😄Chris Veillette###Hello Will We could see that the volume is mounted and accessible. Please see the below output. [root@ip-10-59-10-50 centos]# df -Th | grep /dev/sdb/dev/sdb       ext4      197G  101G   87G  54% /mnt/mapd201803 [root@ip-10-59-10-50 mapd201803]# ls -ltrhtotal 32Kdrwxrwxrwx. 2 root     root      16K Mar 12  2018 lost+founddrwxrwxrwx. 7 mapd     mapd     4.0K Aug 16 21:15 mapddrwxrwxr-x. 2 wwebb    wwebb    4.0K Dec 17 17:29 upgradeProofdrwxrwxr-x. 2 wwebb    wwebb    4.0K Dec 28 18:57 schemadrwxrwxrwx. 2 aherrera aherrera 4.0K Dec 28 20:15 transferredCSVs[root@ip-10-59-10-50 mapd201803]# Let us know you availability to get on the call the discuss further on you queries @Chris we could see that the volume is currently accessible and mounted top the instance. Thanks###[Via Mail]Confused - is this volume accessible ?  --Chris Veillette###[Via Email]An update was provided to Matthew stating the services were back online. We can confirm as of this morning the server is still down. @spendhq-support@reancloud.com Can you ensure I’m included on updates related to this ticket?@athira.pk@hitachivantara.com Should we jump on a call to better understand the issue?Thanks, Will Webb###Hello Matthew,Kindly disregard the previous mail.As already mentioned it was a mistake that we have updated the reply for the P1 Case with subject Detected Error on SpendHQ Secure on this ticket.We have reopened this case and we will be waiting for your reply on this case to proceed further.Thanks###Hello Matthew,Thanks for the confirmation. As the issue is fixed and we don’t have any pending action from you, So we will be marking this case as closed.Let us know if you have any queries.Thanks###Reply From Matthew=========Perfect###Hello Mathew,Thanks for the update. Kindly get back to us after verifying the ISCSI mount. Let us know if you have any queries.Regards###Reply from Matthew===========Understood. We will verify###Hello Matthew,Thank you for the update.###From Matthew:-Understood. We will verify###Hello Matthew and Will,We have remounted the ISCSI volume on the instance. We have verified also that we are able to touch a file in the /mnt/mapd201803 folder. Please check from your end and let us know if you have any queries.###Hello Will,We are actively working on this issue of  jetstor volume and will let back to you with an update as soon as possible. Kindly await for the same. Thank you for your patience for the mean time. Athira P K###Chris and Kapil, This is our production server, do you have an update you can provide? If at all possible can we increase the frequency in updates? Best Regards, Will Webb###i will look into itChris Veillette###Hello Chris,We had an issue on the jetstor volume. It went in RO mode. We tried to remount the volume but we are facing the below error.mount: /dev/sdb: can't read superblockWe tried to logout from the ISCSI target but getting the below errors.[root@ip-10-59-10-50 ~]# iscsiadm --mode node --targetname ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12  --portal 172.24.5.3:3260,1 --logoutiscsiadm: No matching sessions found when we discovered the device, we are getting timed out error.[root@ip-10-59-10-50 ~]# iscsiadm --mode discovery --type sendtargets --portal 172.24.5.3:3260iscsiadm: Discovery session to 172.24.5.3:3260 timed out.iscsiadm: Connection to Discovery Address 172.24.5.3 failediscsiadm: Login I/O error, failed to receive a PDUiscsiadm: retrying discovery login to 172.24.5.3 AWS server IP: 10.59.10.5IQN: ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12 Kindly check once from your end. We are available for call now, let us know if we can have a call session to troubleshoot the issue.###Hello Matthew,We are working to resolve this and will be back with an update soon.Thanks.###[Via Email]Matthew Watts5:26 PM (8 minutes ago)to Will, Rean, spendhq-support@reancloud.comWhat’s the status here?###Hello Matthew,Thank you for the approval. We are working on it and will keep you posted.###Matthew Watts6:35 PM (2 minutes ago)to Rean, spendhq-support@reancloud.comYes let’s kill and restart.###Hello Spendhq-Team, We are not able to unmount the volume because of the below processes are running.COMMAND     PID USER   FD   TYPE DEVICE  SIZE/OFF    NODE NAMEmapd_web_ 16193 mapd    3w   REG   8,16         0 3408386 /mnt/mapd201803/mapd/data/mapd_log/mapd_web_server.ip-10-59-10-50.ec2.internal.mapd.log.ALL.20181210-171407.16193mapd_web_ 16193 mapd    5w   REG   8,16   2540811 3408387 /mnt/mapd201803/mapd/data/mapd_log/mapd_web_server.ip-10-59-10-50.ec2.internal.mapd.log.ACCESS.20181210-171407.16193mapd_serv 30763 mapd  mem    REG   8,16   4194304 7865147 /mnt/mapd201803/mapd/data/mapd_data/DB_5_DICT_647/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 7865146 /mnt/mapd201803/mapd/data/mapd_data/DB_5_DICT_647/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 7865139 /mnt/mapd201803/mapd/data/mapd_data/DB_5_DICT_643/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 7865138 /mnt/mapd201803/mapd/data/mapd_data/DB_5_DICT_643/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801117 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1137/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801116 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1137/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801115 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1136/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801114 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1136/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801113 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1135/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801112 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1135/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801111 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1134/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801110 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1134/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801109 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1133/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801108 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1133/DictPayloadKindly request you to kill the processes or provide us approval to kill the process so that we can unmount and remount the volume.###Hello Spendhq Team,This is to inform you that we received a notification stating that ISCSI volume ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12 went into read-only mode on the instance i-04da5f97cbade5646. We are checking from our end and will let you know the update.","Please check on this.From: ms@reancloud.com <ms@reancloud.com>Sent: 03 January 2019 18:01To: ms@reancloud.comSubject: ISCSI Device Details which are in RO modeThe daily report of ISCSI devices which are in RO modeInstance_IDInstance_NameISCSI_NameMachine_Level_Disk_NameMount_DirectoryMount_Propertiesi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12sdb/mnt/mapd201803ro-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",ISCSI Device Details which are in RO mode,,03-01-2019 18:05,122,0,SpendHQ,"Hello SpendHQ-Team, We are closing the current case as the issue got fixed on 10-59-10-50  instance and created another case to track the initiator issue from the instance 10.59.10.135. Please find the case ID: 01110431 to the new case.  We will continue work on the issue and will share the details over the there. Let us know if you have any concerns.","@Praveen:Initially we got an alert for RO mode issue on 10-59-10-50 by our Jenkins Job. We worked on it with the help of Chris to resolve as we were not able to mount that volume. Some issue at Anderomeda side. We were able to resolve this once changes made by Chris. Then we got an update from Chris (A3 Team) the logs were flooding with “login was rejected due to initiator error” at his end for initiator issue from the instance 10.59.10.135This created an confusion between all three of us (SpendHQ Team, REAN Team and A3 Team) As sometime it was asked to get close the ticket from SpendHQ Team and A3 was also saying the same that issue got resolved. But when we verified from our end the messages logs were flooding with the error login rejected: initiator errorI have verified now also the logs are still flooding with this error. For this we need to work with A3 Team to get on a call to understand the same. We tried to reach him but could not get him on call.","Hello Chris,The issue still persist on the server 10.59.10.135 and we can see the messages logs are still flooding with an error of iscsid: conn 0 login rejected: initiator error (02/04).Can we have a call to understand and resolve the same?Please let me know your availability. Thanks !",The errors are still getting. Please check with Rohit for further actions.,[ Internal Slack Communication on Mgs Group ]Praveen Kumar Muppala [Today at 20:45]@rohit.puri and team what is the status of this ticket - ISCSI Device Details which are in RO mode7 repliesRafi.Ramesh [2 hours ago]@praveen.muppala we asked them provide their availability to schedule a call.Praveen Kumar Muppala [2 hours ago]You mean Chris from Andromeda3.Rafi.Ramesh [2 hours ago]yesPraveen Kumar Muppala [2 hours ago]Ok. Did anyone called them or not?Rafi.Ramesh [2 hours ago]yes we called chris. but he is not reachable.we will try again him in half an hourPraveen Kumar Muppala [2 hours ago]@chirodeep.roy and @rohit.puri - There is a different note from Chris. Can you guys review and address it ASAP. I am not sure what's going on here.Chirodeep Roy [1 hour ago]@praveen.muppala I will speak to Rohit and ask him to add if anything else is required on this issue.,"[ Below response, we received from Chris before Nishad mail.]Chris Veillette9:07 PM (1 hour ago)to Jason, Matthew, Nishad, Will, spendhq-support@reancloud.comConfused- this was resolved last Friday AM","Hello Matthew,We have again checked from our end on this and still we could see that the /var/log/messages are get flooded with the below log entries. Kindly check with the same from your end . [root@ip-10-59-10-135 log]# tailf  messagesJan  7 15:51:32 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:51:32 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:51:46 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:51:46 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:51:47 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:51:47 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:52:01 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:52:01 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:52:01 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)Jan  7 15:52:01 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04)We are waiting for your update to proceed further to closing this case.Thanks","[Via Email]Then let’s close it off team.Matthew Watts | Manager, Application Development |SpendHQ®","[Via Mail]Jason Bray <jbray@spendhq.com>6:09 PM (23 minutes ago)to Matthew, Nishad, Will, Chris, spendhq-support@reancloud.com﻿Agreed! This needs immediate attention to resolve.","[Via Mail]Matthew Watts12:45 PM (5 hours ago)to Nishad, Will, Chris, spendhq-support@reancloud.comTeam. This needs immediate elevation. It’s unacceptable for this to be in this state for so long. Please get with Will and resolve ASAP. Treat as SEV ONE.",@TeamTried to Get Chris on call but he is not accepting the call.  please try to get in touch with him to get on a call to look on this issue ASAP,"Hi Matthew,We are re-opening this ticket. We will work along with Chris from A3 Team to resolve this ASAP.Chris:Please let us know your availability as we need to jump on a call to resolve this ASAP. We already shared with you the logs for error on login rejected.",@Team:Please re-open this ticket. Why we close this ticket without customer confirmation?Schedule a call with Chris from A3 Team,"Hello Chris,We have further checked with logs and could not see the errors are getting generated today.So as per the Wills confirmation on the last comment by him, we are marking this case closed as we could see that the issue is got fixed from our end also. Feel free to reopen the case if you have any queries.Thanks","Hello Chris, We had disconnected the call as you had not joined the call. Can you please verify once again regarding the error as we can see that it still flooding the /var/log/messages  logs Awaiting your reply to proceed further on this case. Thanks","Hello Chris From our end, we could see that the bellow error still flooding the /var/log/messages =========== [root@ip-10-59-10-135 production_25_08_2018]# tail -10f /var/log/messages Jan 4 18:05:29 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:30 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:44 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:44 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:44 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:44 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:58 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:59 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:59 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) Jan 4 18:05:59 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/04) ========== Can you Join on the below same bridge to look into this issue?",I think we are good now...errors stoppedChris Veillette,"Hello Chris We had checked on this issue from our end also ands could see the same error that you mentioned flooding the logs.==============Jan  4 17:32:35 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/00)Jan  4 17:32:35 ip-10-59-10-135 iscsid: Kernel reported iSCSI connection 23:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (1)Jan  4 17:32:35 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/00)Jan  4 17:32:35 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error (02/00)Jan  4 17:32:35 ip-10-59-10-135 iscsid: Kernel reported iSCSI connection 29:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (1)Jan  4 17:32:35 ip-10-59-10-135 iscsid: conn 0 login rejected: initiator error - target not found (02/03)Jan  4 17:32:35 ip-10-59-10-135 kernel: connection33:0: detected conn error (1020)Jan  4 17:32:36 ip-10-59-10-135 kernel: connection28:0: detected conn error (1020)Jan  4 17:32:36 ip-10-59-10-135 kernel: connection23:0: detected conn error (1020)====== We also tried to logout from the volumes at the IPs with the 172.24.5.3 and 172.24.5.3 which are not used by the instance and we are getting the but we are getting the below error. [root@ip-10-59-10-135 production_25_08_2018]# iscsiadm --mode node --targetname ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0scsi-test:dev9.ctr2-lun-9 --portal 172.24.5.3:3260,1 --logoutiscsiadm: No matching sessions found[root@ip-10-59-10-135 production_25_08_2018]# iscsiadm --mode node --targetname  ip-172.24.5.2:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev0.ctr1-lun-3 --portal 172.24.5.3:3260,1 --logoutiscsiadm: No matching sessions found[root@ip-10-59-10-135 production_25_08_2018]# iscsiadm --mode node --targetname  ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:clone-db-v777bb21358661922.0000001d.2f1dab31-lun-0 --portal 172.23.104.77:3260,1 --logoutiscsiadm: No matching sessions found  Kindly Join the below bridge to fix the issue https://reancloud.zoom.us/my/mgse1","Hello Chris, We will check on this and get back to you ASAP. Regards","I have been able to restart the services on the server and so far it does not appear to show any issues. After issue with 64d02cf7e3df - ip 10.59.10.135 is troubleshooted I believe the ticket can be closed. Thanks, Will Will Webb",Hello Chris Thanks for the update. Will  let you know if still facing any issues. Regards,Great - one thing : can you check instance 64d02cf7e3df - ip 10.59.10.135I am getting an error in my end complaining that “login was rejected due to initiator error”......  it is filling up my error log file ....Chris Veillette,Ok - good - let me ASAP if there are further issues 😄Chris Veillette,Hello Will We could see that the volume is mounted and accessible. Please see the below output. [root@ip-10-59-10-50 centos]# df -Th | grep /dev/sdb/dev/sdb       ext4      197G  101G   87G  54% /mnt/mapd201803 [root@ip-10-59-10-50 mapd201803]# ls -ltrhtotal 32Kdrwxrwxrwx. 2 root     root      16K Mar 12  2018 lost+founddrwxrwxrwx. 7 mapd     mapd     4.0K Aug 16 21:15 mapddrwxrwxr-x. 2 wwebb    wwebb    4.0K Dec 17 17:29 upgradeProofdrwxrwxr-x. 2 wwebb    wwebb    4.0K Dec 28 18:57 schemadrwxrwxrwx. 2 aherrera aherrera 4.0K Dec 28 20:15 transferredCSVs[root@ip-10-59-10-50 mapd201803]# Let us know you availability to get on the call the discuss further on you queries @Chris we could see that the volume is currently accessible and mounted top the instance. Thanks,[Via Mail]Confused - is this volume accessible ?  --Chris Veillette,"[Via Email]An update was provided to Matthew stating the services were back online. We can confirm as of this morning the server is still down. @spendhq-support@reancloud.com Can you ensure I’m included on updates related to this ticket?@athira.pk@hitachivantara.com Should we jump on a call to better understand the issue?Thanks, Will Webb","Hello Matthew,Kindly disregard the previous mail.As already mentioned it was a mistake that we have updated the reply for the P1 Case with subject Detected Error on SpendHQ Secure on this ticket.We have reopened this case and we will be waiting for your reply on this case to proceed further.Thanks","Hello Matthew,Thanks for the confirmation. As the issue is fixed and we don’t have any pending action from you, So we will be marking this case as closed.Let us know if you have any queries.Thanks",Reply From Matthew=========Perfect,"Hello Mathew,Thanks for the update. Kindly get back to us after verifying the ISCSI mount. Let us know if you have any queries.Regards",Reply from Matthew===========Understood. We will verify,"Hello Matthew,Thank you for the update.",From Matthew:-Understood. We will verify,"Hello Matthew and Will,We have remounted the ISCSI volume on the instance. We have verified also that we are able to touch a file in the /mnt/mapd201803 folder. Please check from your end and let us know if you have any queries.","Hello Will,We are actively working on this issue of  jetstor volume and will let back to you with an update as soon as possible. Kindly await for the same. Thank you for your patience for the mean time. Athira P K","Chris and Kapil, This is our production server, do you have an update you can provide? If at all possible can we increase the frequency in updates? Best Regards, Will Webb",i will look into itChris Veillette,"Hello Chris,We had an issue on the jetstor volume. It went in RO mode. We tried to remount the volume but we are facing the below error.mount: /dev/sdb: can't read superblockWe tried to logout from the ISCSI target but getting the below errors.[root@ip-10-59-10-50 ~]# iscsiadm --mode node --targetname ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12  --portal 172.24.5.3:3260,1 --logoutiscsiadm: No matching sessions found when we discovered the device, we are getting timed out error.[root@ip-10-59-10-50 ~]# iscsiadm --mode discovery --type sendtargets --portal 172.24.5.3:3260iscsiadm: Discovery session to 172.24.5.3:3260 timed out.iscsiadm: Connection to Discovery Address 172.24.5.3 failediscsiadm: Login I/O error, failed to receive a PDUiscsiadm: retrying discovery login to 172.24.5.3 AWS server IP: 10.59.10.5IQN: ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12 Kindly check once from your end. We are available for call now, let us know if we can have a call session to troubleshoot the issue.","Hello Matthew,We are working to resolve this and will be back with an update soon.Thanks.","[Via Email]Matthew Watts5:26 PM (8 minutes ago)to Will, Rean, spendhq-support@reancloud.comWhat’s the status here?","Hello Matthew,Thank you for the approval. We are working on it and will keep you posted.","Matthew Watts6:35 PM (2 minutes ago)to Rean, spendhq-support@reancloud.comYes let’s kill and restart.","Hello Spendhq-Team, We are not able to unmount the volume because of the below processes are running.COMMAND     PID USER   FD   TYPE DEVICE  SIZE/OFF    NODE NAMEmapd_web_ 16193 mapd    3w   REG   8,16         0 3408386 /mnt/mapd201803/mapd/data/mapd_log/mapd_web_server.ip-10-59-10-50.ec2.internal.mapd.log.ALL.20181210-171407.16193mapd_web_ 16193 mapd    5w   REG   8,16   2540811 3408387 /mnt/mapd201803/mapd/data/mapd_log/mapd_web_server.ip-10-59-10-50.ec2.internal.mapd.log.ACCESS.20181210-171407.16193mapd_serv 30763 mapd  mem    REG   8,16   4194304 7865147 /mnt/mapd201803/mapd/data/mapd_data/DB_5_DICT_647/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 7865146 /mnt/mapd201803/mapd/data/mapd_data/DB_5_DICT_647/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 7865139 /mnt/mapd201803/mapd/data/mapd_data/DB_5_DICT_643/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 7865138 /mnt/mapd201803/mapd/data/mapd_data/DB_5_DICT_643/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801117 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1137/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801116 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1137/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801115 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1136/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801114 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1136/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801113 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1135/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801112 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1135/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801111 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1134/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801110 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1134/DictPayloadmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801109 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1133/DictOffsetsmapd_serv 30763 mapd  mem    REG   8,16   4194304 3801108 /mnt/mapd201803/mapd/data/mapd_data/DB_3_DICT_1133/DictPayloadKindly request you to kill the processes or provide us approval to kill the process so that we can unmount and remount the volume.","Hello Spendhq Team,This is to inform you that we received a notification stating that ISCSI volume ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12 went into read-only mode on the instance i-04da5f97cbade5646. We are checking from our end and will let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5002I00001jjd6H,Cloud Engineer Level 1,Closed,1112020,Incident,13-02-2019 00:01,,"Send mail to MGS leads###Hello David, Thanks for the update. We will be marking this case as closed. RegardsNishad Ali###Hello David Can we jump on a screen share section to look further on this issue. https://hitachivantara.zoom.us/my/safuvankm Nishad Ali###Don’t worry, matthew was able to get this working for me, we are all set!  thanks###Still receiving permission denied.  Try again###Hello David As per your request we have further checked on this and could see that the “dmiller” user was not listed under the AllowedUsers List in the sshd_config file and we have added the user :”dmiller” to fix this issue. Kindly check from you end and let us know the updates. @spendhq - mwattsFYI###Please check the access to the server, matthew typically disables our account outside of our ssh keys, please check that and let me know once fixed###I am still waiting on access, this is a SEV1 and effecting customers.  Please copy my ssh key from 10.59.100.78, please also check sshd_config and make sure my user has access. We are approaching 1 hour and this should only take 5 minutes as we do this dozens of times a week.  Please advise thanks###It’s not working, please copy my ssh key from 10.59.100.78 and I will try again###Hello David, We have copied the key from the mentioned instance and we could see that there was change in the keys in the instance “10.59.101.78” compared to “10.59.100.78”.  We have fixed this issue. Kindly check from your and let us know the update. If you are still facing the issue kindly  join with us on https://hitachivantara.zoom.us/my/safuvankm. RegardsNishad Ali###Thank you, this has now become a sev1 issue.  Please advise###Hello David, We are working on this to provide the access for your user “dmiller” to the instance “ 10.59.101.178”. Wil update you once it is done. RegardsNishad Ali###Hello David As we could see that “dmiller” user is already the on this server and the .ssh folder have some permission issue and we have fixed that and provide the user “dmiller” with the password less sudo user access on the server “10.59.101.178”. kindly check from your end also. If you are still facing any issues we can jump on screen sharing session  for fixing this issue. RegardsNishad Ali","Rean,I need immediate ssh access to 10.59.101.78, username: 10.59.101.78 and sudoless password please.DavidFrom: Yogeeraj Kulkarni <yogeeraj.kulkarni@reancloud.com>Date: Friday, February 8, 2019 at 9:12 AMTo: David Miller <dmiller@spendhq.com>Cc: Rean Support <support@reancloud.com>Subject: Re: On call AccessHello David/Matthew,We understand your emergency.@mathew Please approve this request to complete this  ASAPThanks.On Fri, Feb 8, 2019 at 7:24 PM David Miller <dmiller@spendhq.com<mailto:dmiller@spendhq.com>> wrote:Hi REAN,I need to be able to access the following servers for on call purpose:  *   10.59.100.125 (ssh key already setup)  *   10.59.10.210 (ssh key already setup)  *   10.59.10.26  *   10.59.10.45  *   10.59.10.235  *   10.59.100.193  (ssh key already setup)My username is dmiller, please use the public key on the servers already setup.  Please also make my user have password-less sudo on ALL these machines as well.Thank YouDavid Miller | Developer | SpendHQdmiller@spendhq.com<mailto:dmiller@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | Schedule a Meeting<https://calendly.com/dmillershq>--­­Yogeeraj Milind Kulkarni.Jr. Cloud Engineer, Cloud Operation, Global ServicesHitachi VantaraError! Filename not specified.m: +917057033088e: yogeeraj.kulkarni@hitachivantara.com<mailto:yogeeraj.kulkarni@HitachiVantara.com>Suyog Platinum Tower,7th Floor, Naylor Rd Platinum,Sangamvadi - Pune Maharashtra 411001 IndiaFollow Hitachi Vantarawww.HitachiVantara.com<https://www.hitachivantara.com/en-us/home.html> | community.HitachiVantara.com<https://community.hitachivantara.com/>[Image removed by sender. twitter]<https://twitter.com/HitachiVantara> [Image removed by sender. facebook] <https://www.facebook.com/HitachiVantara>  [Image removed by sender. linkedin] <https://www.linkedin.com/company/11257500>  [Image removed by sender. youtube] <https://www.youtube.com/c/HitachiVantara>[Image removed by sender.]<http://htchivantara.is/2RAornF>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: On call Access,,12-02-2019 22:14,2,0,SpendHQ,Send mail to MGS leads,"Hello David, Thanks for the update. We will be marking this case as closed. RegardsNishad Ali",Hello David Can we jump on a screen share section to look further on this issue. https://hitachivantara.zoom.us/my/safuvankm Nishad Ali,"Don’t worry, matthew was able to get this working for me, we are all set!  thanks",Still receiving permission denied.  Try again,Hello David As per your request we have further checked on this and could see that the “dmiller” user was not listed under the AllowedUsers List in the sshd_config file and we have added the user :”dmiller” to fix this issue. Kindly check from you end and let us know the updates. @spendhq - mwattsFYI,"Please check the access to the server, matthew typically disables our account outside of our ssh keys, please check that and let me know once fixed","I am still waiting on access, this is a SEV1 and effecting customers.  Please copy my ssh key from 10.59.100.78, please also check sshd_config and make sure my user has access. We are approaching 1 hour and this should only take 5 minutes as we do this dozens of times a week.  Please advise thanks","It’s not working, please copy my ssh key from 10.59.100.78 and I will try again","Hello David, We have copied the key from the mentioned instance and we could see that there was change in the keys in the instance “10.59.101.78” compared to “10.59.100.78”.  We have fixed this issue. Kindly check from your and let us know the update. If you are still facing the issue kindly  join with us on https://hitachivantara.zoom.us/my/safuvankm. RegardsNishad Ali","Thank you, this has now become a sev1 issue.  Please advise","Hello David, We are working on this to provide the access for your user “dmiller” to the instance “ 10.59.101.178”. Wil update you once it is done. RegardsNishad Ali",Hello David As we could see that “dmiller” user is already the on this server and the .ssh folder have some permission issue and we have fixed that and provide the user “dmiller” with the password less sudo user access on the server “10.59.101.178”. kindly check from your end also. If you are still facing any issues we can jump on screen sharing session  for fixing this issue. RegardsNishad Ali,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C0sTM,Cloud Engineer Level 1,Closed,1053099,Incident,13-05-2017 02:52,,"Hello SpendHQ-Team,Based on the analysis performed regarding the intrusion prevention alert on preview.spendhq ELB, we were able to figure out one IP 54.159.78.53, with 403 response code during the time of this issue. Refer the below log details for more information,2017-05-12T19:19:09.853266Z preview-spendhq-xelb 54.159.78.53:42609 10.59.1.192:80 0.000033 0.002107 0.000023 403 403 0 0 HEAD http://52.6.177.194:80/ HTTP/1.1 Cloud mapping experiment. Contact research@pdrlabs.net - -The IP belongs to Amazon Technologies and the count was normal with a value of 1. Hence, we haven't blocked this IP. Refer the details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello SpendHQ-Team,We again received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates. Meanwhile kindly validate the below information shared and let us know if your team have any further queries regarding it.Regards, Sumod.K.Bose###Hello SpendHQ-Team,On further analysis, we were able to figure out one IP, 144.160.98.95 with 403 response code during the time of this alert. The IP belongs to United States, North Carolina region and the ISP provider is AT&T Services Inc. When we analyzed the overall count of this IP address, we were able to see a total count of 785 requests made from this IP address where all are served with 403 error response code. Hence, we have blocked this IP from the NACL level.We have attached the ELB logs for the IP 144.160.98.95 during the time of this alert. Kindly refer the attachment section for more details. Kindly validate these details from your end and let us know if this IP belongs to any of your know resources. Revert back to us if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello SpendHQ-Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.123 which belongs to the secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.Regards,Sumod.K.Bose",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-12 18:05:35Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.123Source port: 52363Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http),[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,12-05-2017 23:42,3,0,SpendHQ,"Hello SpendHQ-Team,Based on the analysis performed regarding the intrusion prevention alert on preview.spendhq ELB, we were able to figure out one IP 54.159.78.53, with 403 response code during the time of this issue. Refer the below log details for more information,2017-05-12T19:19:09.853266Z preview-spendhq-xelb 54.159.78.53:42609 10.59.1.192:80 0.000033 0.002107 0.000023 403 403 0 0 HEAD http://52.6.177.194:80/ HTTP/1.1 Cloud mapping experiment. Contact research@pdrlabs.net - -The IP belongs to Amazon Technologies and the count was normal with a value of 1. Hence, we haven't blocked this IP. Refer the details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello SpendHQ-Team,We again received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates. Meanwhile kindly validate the below information shared and let us know if your team have any further queries regarding it.Regards, Sumod.K.Bose","Hello SpendHQ-Team,On further analysis, we were able to figure out one IP, 144.160.98.95 with 403 response code during the time of this alert. The IP belongs to United States, North Carolina region and the ISP provider is AT&T Services Inc. When we analyzed the overall count of this IP address, we were able to see a total count of 785 requests made from this IP address where all are served with 403 error response code. Hence, we have blocked this IP from the NACL level.We have attached the ELB logs for the IP 144.160.98.95 during the time of this alert. Kindly refer the attachment section for more details. Kindly validate these details from your end and let us know if this IP belongs to any of your know resources. Revert back to us if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello SpendHQ-Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.123 which belongs to the secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001J6ZKr,Cloud Engineer Level 1,Closed,1083724,Incident,09-11-2017 17:45,,"Abhi updated that we are good to close this ticket.###Hi Andrew,I invited the user to CloudHealth. He should have received an email from CloudHealth.Regards,Abhinag Naidu###[Abhinag Naidu updated the case via Email]Hi Andrew,Going through the instructions provided to provision the access to CloudCostOut, I noticed that they have been asking us to provide billing bucket access. We cannot do this since SpendHQ is linked to REAN Master account along with 130 other accounts. The tool that CloudCostOut has been using to do the analysis is CloudHealth. Since REAN uses CloudHealth, we can create users for CloudCostOut to access SpendHQ billing information. Please let us know the users for whom the account needs to be created in CloudHealth. Regards,Abhinag Naidu###Hi Andrew,I am trying to create a new account for jonathan.manuzak@codeguard.com in SpendHQ CloudHealth account and I am not able to do it. Can you please let me know if there is any SpendHQ domain email address for Jonathan?###Check with Abhi for more updates.###I have talked with Abhi he updated that he will work on this today evening. Next Action: Please check with Abhi in Afternoon Shift###Yes, I have received the email from CloudHealth.I am still waiting on confirmation on setting up an account for my 3rd party partner, CloudCostOut. Thank you.###Hello Andrew, We haven't heard back from you.We have provisioned accounts in SpendHQ for you. You should have received an email from CloudHealth about it. Please let me know if you have any questions.###Hi Andrew,I have provisioned accounts in SpendHQ for you. You should have received an email from CloudHealth about it. Please let me know if you have any questions. Regards,Abhinag Naidu###Thank you Praveen. Yes, we would like to utilize both CloudHealth and CloudCostOut. Please enable the integration. Thank you.###Thank you Praveen. Yes, we would like to utilize both CloudHealth and CloudCostOut. Please enable the integration. Thank you. Andrew Kim###Hello Andrew, REAN has a Cloud Cost Management tool called : CloudHealth which is a free of cost for all of our Managed Service Customers. If you don’t have access to the system, we can create one for you and you can start utilizing it for your cost management. If you still see a need for CloudCostOut, we would be happy to enable the integration. @Abhi Naidu – Can you do the needful. Please provide access to Andrew and Matthew. Post that, we can schedule a call to walk through the CloudHealth capabilities and advantages of it. Regards,-Praveen","Hello – we’ve engaged with a partner to perform a utilization and costoptimization for our Amazon account. Please grant them access.Attached are instructions.Please let me know if there are any questions, or if we should haveconference call with the partner.Thank you,*Andrew Kim* | Director of Information Technology & Security | *Spend**HQ®*O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com*From:* Jonathan Manuzak [mailto:jonathan.manuzak@codeguard.com]*Sent:* Thursday, November 2, 2017 2:48 PM*To:* Andrew Kim <Akim@spendhq.com>*Cc:* Charles Brian Quinn <me@seebq.com>*Subject:* CloudCostOut Setup InstructionsHi Andrew,Thank you again for your time yesterday. As discussed, I've attached theinstructions for configuring automated detailed billing reports within yourAWS account and granting CloudCostOut access to this billing data.After completing the steps in the document, we will need the followinginformation to finalize the setup on our side:   - AWS Account ID (ex. 709659176911)   - IAM Role ARN (ex. arn:aws:iam::1234567890:role/CloudCostOut-ReadOnly)   - S3 Billing Bucket Name (ex. testdotorg-CloudCostOut)   - Cost & Usage Report Bucket Name and Prefix (ex.   testdotorg-CloudCostOut/CloudCostOut-cur)Creating and collecting all of this information is outlined in thedocumentation. In addition to these instructions, you will also need yourunique External ID to complete the setup process. That ID is:56ac2d81ad6489d444944fbd68dc42If you or your vendor need any additional information, please feel free toshare our contact information. We would be happy to work with them directlyso you don't have to relay messages.Best,Jonathan-- Jonathan ManuzakCTOCodeGuard | 1000 Marietta St | Suite 120 | Atlanta, GA 30318C: 404.987.3185 | Skype: jmanuzakjonathan.manuzak@codeguard.com-- Regards,Akhil K MREĀN Cloud Solutions | Reach, Engage, Āctivate, Nurture2201 Cooperative Way #250, Herndon, Va 20171akhil.kurumath@reancloud.com | www.reancloud.com<http://www.reancloudsolutions.com/>--  <https://www.reancloud.com/aws-reinvent/>--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Grant access to 3rd party partner CloudCostOut,,03-11-2017 00:42,161,0,SpendHQ,Abhi updated that we are good to close this ticket.,"Hi Andrew,I invited the user to CloudHealth. He should have received an email from CloudHealth.Regards,Abhinag Naidu","[Abhinag Naidu updated the case via Email]Hi Andrew,Going through the instructions provided to provision the access to CloudCostOut, I noticed that they have been asking us to provide billing bucket access. We cannot do this since SpendHQ is linked to REAN Master account along with 130 other accounts. The tool that CloudCostOut has been using to do the analysis is CloudHealth. Since REAN uses CloudHealth, we can create users for CloudCostOut to access SpendHQ billing information. Please let us know the users for whom the account needs to be created in CloudHealth. Regards,Abhinag Naidu","Hi Andrew,I am trying to create a new account for jonathan.manuzak@codeguard.com in SpendHQ CloudHealth account and I am not able to do it. Can you please let me know if there is any SpendHQ domain email address for Jonathan?",Check with Abhi for more updates.,I have talked with Abhi he updated that he will work on this today evening. Next Action: Please check with Abhi in Afternoon Shift,"Yes, I have received the email from CloudHealth.I am still waiting on confirmation on setting up an account for my 3rd party partner, CloudCostOut. Thank you.","Hello Andrew, We haven't heard back from you.We have provisioned accounts in SpendHQ for you. You should have received an email from CloudHealth about it. Please let me know if you have any questions.","Hi Andrew,I have provisioned accounts in SpendHQ for you. You should have received an email from CloudHealth about it. Please let me know if you have any questions. Regards,Abhinag Naidu","Thank you Praveen. Yes, we would like to utilize both CloudHealth and CloudCostOut. Please enable the integration. Thank you.","Thank you Praveen. Yes, we would like to utilize both CloudHealth and CloudCostOut. Please enable the integration. Thank you. Andrew Kim","Hello Andrew, REAN has a Cloud Cost Management tool called : CloudHealth which is a free of cost for all of our Managed Service Customers. If you don’t have access to the system, we can create one for you and you can start utilizing it for your cost management. If you still see a need for CloudCostOut, we would be happy to enable the integration. @Abhi Naidu – Can you do the needful. Please provide access to Andrew and Matthew. Post that, we can schedule a call to walk through the CloudHealth capabilities and advantages of it. Regards,-Praveen",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G0000159t3e,Cloud Engineer Level 1,Closed,1038424,Incident,13-12-2016 00:40,,"Hello Team,We have provided the details on both tickets and so we are closing this ticket here.###01037260 and 01037994.###Hello Matthew,The URLs you provided leads to the customer portal that we can't access. Could you please provided the ticket numbers so that we can look on that and provide you with the details.","We need a response for the following tickets;https://reancloud.force.com/customers/5000G00001596zVhttps://reancloud.force.com/customers/5000G0000157FKnMatthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Responses Needed,,12-12-2016 20:46,4,0,SpendHQ,"Hello Team,We have provided the details on both tickets and so we are closing this ticket here.",01037260 and 01037994.,"Hello Matthew,The URLs you provided leads to the customer portal that we can't access. Could you please provided the ticket numbers so that we can look on that and provide you with the details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015VjEA,Cloud Engineer Level 1,Closed,1038897,Incident,14-12-2016 23:29,,This alert triggered as part of the issue on outage in secure site and rean team is on call with the client they have rebooted the instance.,"Wed, 14 Dec 2016 12:54:10 -0500Detected Error on SpendHQEstimated Downtime: 59 seconds https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Dallas-B US, Atlanta-B US, Frankfurt DE, California US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,14-12-2016 23:24,0,0,SpendHQ,This alert triggered as part of the issue on outage in secure site and rean team is on call with the client they have rebooted the instance.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DBHP5,Cloud Engineer Level 1,Closed,1061926,Incident,11-06-2017 05:18,,"Matthew Watts5:14 AM (2 minutes ago)to Rean, spendhq-support Yes I can confirm that I rebooted the server. Sent from my iPhone###We analyzed this issue further from the instance level and found that user mwatts performed a network service restart and HTTPS service restart at the same time of the alert and that was the reason behind the status check failure and also HTTPS process down.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM###This is to inform you that we received an instance status check failure for the instance PROD-SPHQ-WEB-SERVER03_Clone_June-04-2017(10.59.100.153) and it got resolved automatically within 1 minute.We also witnessed a HTTPS process down alert 5 minute ahead of the incident. We will investigate this further and update you with the status. Meanwhile, Please let us know if you are performing any changes from your side. Regards,Safuvan KM","[Triggered on {host:10.59.100.153}] [SpendHQ] - Status Check failed Any on prod-sphq-web-server03_clone_june-04-2017 - 10.59.100.153 - web Stop and start the instance and raise a support ticket if System status check is failing. Get approval from client and reboot the system if Instance status check is failing @ms@reancloud.comMetric Graphaws.ec2.status_check_failed over host:10.59.100.153,monitoring:on was > 0.0 on average during the last 5m.The monitor was last triggered at Sat Jun 10 2017 22:43:00 UTC (21 secs ago).[Monitor Status] · [Edit Monitor] · [View 10.59.100.153]This alert was raised by account SpendHQComment in Datadog To manage your Datadog subscriptions, click here.",[Monitor Alert] Triggered: [SpendHQ] - Status Check failed Any on prod-sphq-web-server03_clone_june-04-2017 - 10.59.100.153 - web,,11-06-2017 04:35,0,0,SpendHQ,"Matthew Watts5:14 AM (2 minutes ago)to Rean, spendhq-support Yes I can confirm that I rebooted the server. Sent from my iPhone","We analyzed this issue further from the instance level and found that user mwatts performed a network service restart and HTTPS service restart at the same time of the alert and that was the reason behind the status check failure and also HTTPS process down.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM","This is to inform you that we received an instance status check failure for the instance PROD-SPHQ-WEB-SERVER03_Clone_June-04-2017(10.59.100.153) and it got resolved automatically within 1 minute.We also witnessed a HTTPS process down alert 5 minute ahead of the incident. We will investigate this further and update you with the status. Meanwhile, Please let us know if you are performing any changes from your side. Regards,Safuvan KM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DdFV2,Cloud Engineer Level 1,Closed,1063223,Incident,16-06-2017 23:39,,"Hello Team,This is to inform you that the alert regarding volume usage for prod-sphq-db-server05 instance /dev/xvda1 volume got resolved and has returned to normal with a value of 53.1%. The violation has lasted for 16 minutes.###Hello SpendHQ Team,This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% to 96.6%. We are analyzing the issue and meanwhile let us know if you have any queries regarding this.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Fri, Jun 16, 2017 at 11:20 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjTsLwyAYRX9N3Co-oiaDgw2EQucO7VKsfnlAEq0xQ_99DZzhcOHe67VoP4BmzQhVRFJJlSA1wUwxLrCh_CqNNKI3naS8q2risx-xC2jSdGgAbFPwDhyzqpUcGgaKUKil8mjRU85xr7ipWF-wMWJvs_VhnL5lYz0z58Kx5WIxhWFeoNhxIS_Sve-_54PeDpT0upfjBHZzSzj82URZr2Gbc0h_Wo06iw>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj8tugzAQRb_GLK15eEy88IJS8RuVgx2IFGIKTtTPr0FdVBrN447m6E704q6puXsCbMGixVbAgKaWWHSH_GE728nQ9Ra5VwZiiZMeczN7MC5AMA4oXDgxCslNwhVTvLQUg2sefi5l3RV3ioYaYV11DCXEPM3flbFUbcnPe8nbrogJiJ11ioeSv0o9-0TjWsvCzgGAIjtt-bVWPab3fUyK5CALDXU-6887Bjy6fs57OfcIWpyuGVkq4bbl5T_b4MluNr_s9bkthef4yK94uGuK_3P3C7GbUoQ>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Fri Jun 16 2017 17:50:00 UTC (*36 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtTsuOwyAM_Bo4ImwHsxw4ZLPKf1AgD6kp2YRW-_kl1Uoje8aWZiZ5425Zrh41WM3AYI3utEKLZFQP9M0992bsBwYaRKdTTbOKRS4-xTx9GUsIcYLJ8hR06IAdI1Lmzsq7X2rdT0G9wLEh7LtKoYZU5uW3eWzttpXHWstxCiTUSI6doHE-ynMX9JPya41ZoLkcDI5Nf_bfKwW42LCUs37-oJVxqk0gIw-_na3qkcMj3sszXVmy-v-sN6keRdQ>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjUEOgyAQRU8jS8LMyBAWLKiJ90ABNVGxSu9fmjT5q5e896PTdkpic6jAKAYGo1WvJBokLT3Qiz17PfqBgYauV7HGRc5FrC5AUJwzGLIhB2SmNJGdiHWGPqIWu1trvZ6OfIdjW7guGUMNsSzruzWOxo5ybrXcT4eECsmybTDFrYrbHU_7u1M457184k8Q1f2FL_IDNiY>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVjc0OhCAQg59GjmQYYNQDB9aN74GCP8kqLo7vv2zSNM2XtI3O9lMSu0NQLZAi1VowILFFbaVX-kWevB39QEoPjYHIcZVzFpsLCIBk-q5HAupwSWmOerIpamgNofi4jfm6G-0bHKvCdckYOMS8bt-6cVS2n0sJN5dn5qekRo9bvvkMR41vBdL2srrSVhR33PW-pHDOn_zEf1-wO_K5cy4_Huw60g>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jc0OgyAQhJ8GjmaXBdQDB2rje6CLP4mKVdrnL700mWSSSb5v2Jl2iHJ1CrAGixZrAxoqVSsylUd6WG-96X1nkTqhgTPP1Zjk4uLAQZthQg0t8oRNAEVTiwSB6tFMcnNLzuctyAvVl4TzrDjkwGleXsWxly1-4pH_Tf3Kgp7UoiGtQBkqcrSNauTl9rvcXzEc45be_ONldns61pyuLwQVOVA>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjUkOhCAURE8jS_KZ2wUL2sR7AB-HRIVGvH9jUovKS-UVWjWGRHbLgRnQTDOjQALlhgtFHRNf7bRTs5s0E9MgARuuNGayWQDDgxcSExvBLJKDVkvgCOGDDL0mh91aK_cg3MDnHl8KRd885nX7dcf5shjzc7XeSk1LqumK6SbVnnf_qslf8cgPvmPS7JmvveX6B08ANnw>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,16-06-2017 23:23,4,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding volume usage for prod-sphq-db-server05 instance /dev/xvda1 volume got resolved and has returned to normal with a value of 53.1%. The violation has lasted for 16 minutes.","Hello SpendHQ Team,This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90% to 96.6%. We are analyzing the issue and meanwhile let us know if you have any queries regarding this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FnEli,Cloud Engineer Level 3,Closed,1078646,Incident,18-09-2017 14:33,,"Discussed with Praveen, He is good with the report. Hence Closing this ticket.###I have reviewed the Instance resource utilization from Coudwatch, Datadog and Sophos WebAdmin. After reviewing the utilization and considering any peak happened in the last year, I can see the maximum utilization for the Sophos UTM is as below:##For Last Year:1. Maximum CPU Usage: 12.20%2. Maximum Memory Usage: 30.01%3. Maximum Network Usage: Inbound = 161.46 Mbps ; Outbound = 154.20 MbpsAs per these details, we can see that a maximum of 30% of the resources was utilized for the Sophos UTM. Still, to keep some buffer capacity we consider the keeping the 50% of the current resource capacity in case any peak traffic arises.So we recommend downgrading the current instance(m3.2xlarge) to a lesser size(m3.xlarge) which is having exactly half of the current capacity.m3.2xlarge is having 8 vCPU and 30 GiB of Memory, Where m3.xlarge will have 4 vCPU and 15 GiB of the Memory, Which is more than sufficient in this case.Switching to m4.xlarge is not possible at this time as UTM is running on PV virtualization. Praveen, Please review and let me know your thoughts on the above..###As discussed during the morning OPS Call, Yogesh mentioned that he will look on this request and will provide an update. Check with Yogesh for more updates.###Hello Team,I have analyzed the CPU, network in and out and memory of prod VPN instance.As per my analysis m3.large is suitable for this instance.Next Action: please check with Yogesh on this request.","Hello Yogesh/Team,Please review the SpendHQ Sophos UTM Instance Utilization (Cloud Watch + Datadog) – CPU, Memory and Network and come up with the recommended instance type. Treat this as a high priority and get the details before 4:30PM IST MGS Ops call.Regards,-Praveen-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SpendHQ : Sophos UTM Instance Type Recommnedation,,14-09-2017 02:14,108,0,SpendHQ,"Discussed with Praveen, He is good with the report. Hence Closing this ticket.","I have reviewed the Instance resource utilization from Coudwatch, Datadog and Sophos WebAdmin. After reviewing the utilization and considering any peak happened in the last year, I can see the maximum utilization for the Sophos UTM is as below:##For Last Year:1. Maximum CPU Usage: 12.20%2. Maximum Memory Usage: 30.01%3. Maximum Network Usage: Inbound = 161.46 Mbps ; Outbound = 154.20 MbpsAs per these details, we can see that a maximum of 30% of the resources was utilized for the Sophos UTM. Still, to keep some buffer capacity we consider the keeping the 50% of the current resource capacity in case any peak traffic arises.So we recommend downgrading the current instance(m3.2xlarge) to a lesser size(m3.xlarge) which is having exactly half of the current capacity.m3.2xlarge is having 8 vCPU and 30 GiB of Memory, Where m3.xlarge will have 4 vCPU and 15 GiB of the Memory, Which is more than sufficient in this case.Switching to m4.xlarge is not possible at this time as UTM is running on PV virtualization. Praveen, Please review and let me know your thoughts on the above..","As discussed during the morning OPS Call, Yogesh mentioned that he will look on this request and will provide an update. Check with Yogesh for more updates.","Hello Team,I have analyzed the CPU, network in and out and memory of prod VPN instance.As per my analysis m3.large is suitable for this instance.Next Action: please check with Yogesh on this request.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DDbxJ,Cloud Engineer Level 1,Closed,1063014,Incident,15-06-2017 19:29,,"Hello SpendHQ-Team,This is to notify you that we have received an alert regarding ngpds process down for the instance prod-sphq-web-server03_clone_june-04-2017b. The alert got recovered after 4 minutes. Please let us know if you have performed any activity from your end.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Thu, Jun 15, 2017 at 7:13 PMSubject: [Monitor Alert] Triggered: [SpendHQ] ngpds Process is down -prod-sphq-web-server03_clone_june-04-2017 - 10.59.100.153 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {host:10.59.100.153,process:ngpds}] [SpendHQ] ngpds Processis down - prod-sphq-web-server03_clone_june-04-2017 - 10.59.100.153 - webngpds Process is down @ms@reancloud.com<http://email.dtdg.co/c/eJwVjT0PgyAURX-NbCUPeUIZGKyJadK5Q7s0CPiRqFiFof--mNzh5CbnXqcr1Xky6RKYBMEqxpFzSbkEjpTfGPJrraBWssGWFQguuoHaQEbtmRFGYoWm77wrO5DSKBQoZAm-t4LMeoxxOwpeF2WbY7aNOhONC8P4zRvL2Vkb0hozbXvop9lnShd4Q_N5_F5Pdk9k18uRj3dvVjuH5E6TRL2EdYph_wMM9jn5>PROCS CRITICAL: 0 processes found for ngpdsThe monitor was last triggered at Thu Jun 15 2017 13:43:28 UTC (*8 secs ago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtjkGOwyAQBF8DRwQME-DAwfHK_8AeYkeKDQvk_yGrlfpULVU3BfRr4s-gpbLyplCBAbACrAQj4K4MuMnLydvZLIoZSZ12sWV-BO1W7TAmpIg-GcAHrVYjuAQUHUn-CkfvpTGYmF5GYimCYo-U9-N3OM7Bznw9e66NadDKIWrDYNlrfhcGP0dunQ3jpKRAL5SUQiEMoudS85Za-2uvvVDjNZxt_KspXtsrv-k7wHv4H_gA3dFDvg>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjUEKwyAQRU-jS1FnzOjCRVrIPaxjk0BS08TevxYKf_Xgvc_RhUeRa7TakB6MM4AApIA0oIKbQfBj0GOgO05GoObGs8pVLjGQ9pSJCqLJ7AIHSzazB7Z68OUpt7i0dlwCRmGnvnQcilNLXOfl3Rt7Z3t9ra2el7BgjXfOYoeF1ybPuF_97yzplbf64Z8gW_wLX7oeNcE>]· [View 10.59.100.153<http://email.dtdg.co/c/eJwVjUsOhCAQBU8jS9LYILJg4czEeyCNn0TFwfb-wyRvUalFPfLGTUlsvgVloVNGoUa0Ei2glvhSGvvBweDsW4-q0UBMi4xZrB51Z3uM0E9AxrU9RYIZkaIhSGiS2P3KfN0NDk071oXrkhQ4UF7Wb20c1W3nXMLN5Yn8lNTguOabz3BU_CiQxkkFIJVBUfxx1_-Swhn3_NA_INgf-dw4lx-Btjtw>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jcsKwyAURL9Gl6LeGx8LF2lL_sN6zQOSmCa231-7KQwMDJw5FDr_zHwJWiorjeoUIIAVYCWggJtCcL2Xvbd3HBRDSZUmkQqfg5PR54Q6Ja1yTFZnOyY_ZiIH1njga5hrPS4GPdNDSzwOQbFGKtP8ah9b2_In7_XfMCzE4AFegWlilBbRO2eM4mfYrqY_c9zTWt7043kNW9mXWs4vLJc5yA>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjUEOhCAQBF8DRwIOiBw4uJv4D4RBTRRYxP8vJn3oVDrVwSqzIj3swIXmo1ACJIBmoDlIBh8hYZoNn43-ykUQyUMLG_OZ7lZrIaNzCkdlxAiIPso4IVdgNE5hpafdWys3gZkMS48rhQXXXMjb_uuO62Xe5ye13krFiBWTx5tWe939q6JL_sxPeMe02Suno-X6B2O7NrY>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] ngpds Process is down - prod-sphq-web-server03_clone_june-04-2017 - 10.59.100.153 - web,,15-06-2017 19:22,2,0,SpendHQ,"Hello SpendHQ-Team,This is to notify you that we have received an alert regarding ngpds process down for the instance prod-sphq-web-server03_clone_june-04-2017b. The alert got recovered after 4 minutes. Please let us know if you have performed any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XxbHB,Cloud Engineer Level 1,Closed,1100465,Incident,22-06-2018 07:25,,"Hello Matthew,Thanks for the update.At this time, We are marking this case as resolved hence closing this case. Kindly revert back to us in case of any queries.###Matthew Watts10:26 PM (1 hour ago)to Rean, spendhq-support Yes we are. I am now working on 10.59.100.122. 10.59.101.6 is back on the load balancer.###Hello Matthew,Thanks for the update.Please let us know if you are still performing any activity.###Matthew Watts10:03 PM (5 minutes ago)to Rean, spendhq-support I have removed this from the load balancer for maintenance.###Hello Team,We have received an alert regarding Httpd Process is down on  prd-ww2_6 - 10.59.101.6 - web on process:httpd,host:i-01ac95c23ac66a40e, the alert got resolved  with in 4 mins. We are analysing the issue and will back to you with the update.Resource details:Instance Id: i-01ac95c23ac66a40e IP: 10-59-101-6Region: us-east-1Instance-type: m4.2xlargeMeanwhile please let us know if you have performed any activity at your end.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Thu, Jun 21, 2018 at 9:43 PMSubject: [Monitor Alert] Triggered: [SpendHQ] Httpd Process is down -prd-ww2_6 - 10.59.101.6 - web on process:httpd,host:i-01ac95c23ac66a40eTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {host:i-01ac95c23ac66a40e,process:httpd}] [SpendHQ] HttpdProcess is down - prd-ww2_6 - 10.59.101.6 - webHttpd Process is down @ms@reancloud.com<https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>PROCS CRITICAL: 0 processes found for httpdThe monitor was last triggered at Thu Jun 21 2018 16:13:46 UTC (*4 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2014428?group=host%3Ai-01ac95c23ac66a40e%2Cprocess%3Ahttpd>]· [Edit Monitor <https://app.datadoghq.com/monitors#2014428/edit>] · [Viewi-01ac95c23ac66a40e<https://app.datadoghq.com/infrastructure?filter=i-01ac95c23ac66a40e>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CASC&to_ts=1529597626000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1529596726000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4451578652906014599>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Thanks & Regards,Kapil BokdiaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture4th Floor, 26, Tulsi Complex,100 Feet Road, New BhupalpuraUdaipur, Rajasthan 313001kapil.bokdia@reancloud.com |+917300421033| www.reancloud.com<http://www.reancloudsolutions.com/>Toll-Free Number: +12015828406-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","Fwd: [Monitor Alert] Triggered: [SpendHQ] Httpd Process is down - prd-ww2_6 - 10.59.101.6 - web on process:httpd,host:i-01ac95c23ac66a40e",,21-06-2018 21:44,10,0,SpendHQ,"Hello Matthew,Thanks for the update.At this time, We are marking this case as resolved hence closing this case. Kindly revert back to us in case of any queries.","Matthew Watts10:26 PM (1 hour ago)to Rean, spendhq-support Yes we are. I am now working on 10.59.100.122. 10.59.101.6 is back on the load balancer.","Hello Matthew,Thanks for the update.Please let us know if you are still performing any activity.","Matthew Watts10:03 PM (5 minutes ago)to Rean, spendhq-support I have removed this from the load balancer for maintenance.","Hello Team,We have received an alert regarding Httpd Process is down on  prd-ww2_6 - 10.59.101.6 - web on process:httpd,host:i-01ac95c23ac66a40e, the alert got resolved  with in 4 mins. We are analysing the issue and will back to you with the update.Resource details:Instance Id: i-01ac95c23ac66a40e IP: 10-59-101-6Region: us-east-1Instance-type: m4.2xlargeMeanwhile please let us know if you have performed any activity at your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKji,Cloud Engineer Level 1,Closed,1042231,Incident,,,,"Chris,Did you manage to image the machine?Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]Sent: Friday, January 13, 2017 9:37 PMTo: Matthew Watts <mwatts@spendhq.com>Cc: REAN Support <support@reancloud.com>Subject: Re: MaintenanceHello Matthew,As mentioned earlier, Andromeda team is going to clone the volume before we proceed with the patching of the instance.Please let us know if that is done so that we can proceed with the security patching.On Sat, Jan 14, 2017 at 8:00 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Please update the 10.59.10.12 machine first and advise when complete.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com<mailto:mrigank.saxena@reancloud.com>]Sent: Friday, January 13, 2017 9:24 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,We are ready for the maintenance. Please let us know once you start making the changes.On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Rean Team are you ready to commence the updates as planned on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Maintenance,,14-01-2017 08:22,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001J5xIq,Cloud Engineer Level 1,Closed,1083569,Incident,03-11-2017 18:41,,"Hello Andrew,Thanks for the update.At this time we are marking this case as resolved. Please revert back to us if you have any queries.###Thank you for your recommendation. At this time, we are currently building towards autoscaling, but our application does not support this currently.You may close this case. Thank you.###The analysis has been shared already and sent 2 reminders for the customer response. Please sent a final reminder in today evening shift and close it in tomorrow evening shift.###Hello SpendHQ-Team, Did you get a chance to review the recommendations provided regarding this case? Kindly validate the details shared and let us know if your team have any further queries regarding this case.###Hello SpendHQ-Team,Did you get a chance to review the recommendations provided regarding this case?Kindly validate the details shared and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello SpendHQ Team,As we already mentioned, the website wasn't down and all the requests were served with 200 response code. The issue was the latency which reached around 194 seconds. While analyzing the reason behind the latency, below are the findings:1. Public Load Balancer Secure-SpendHQ-ELB was having high request count with a maximum value of 361 per minute.2. Public Load Balancer Secure-SpendHQ-ELB  witnessed a spike in the Estimated Processed Bytes with a maximum value of 106186612 bytes(106 MB) per minute.3. Sophos UTM Network In was high with a value of 796 MB per minute.4. Sophos UTM Network Out was high with a value of 533 MB per minute.5. Internal Load Balancer NewPreview-ELB Latency went high with a value of 29 seconds.6. Internal Load Balancer NewPreview-ELB witnessed a spike in the Estimated Processed Bytes with a maximum value of 106186612 bytes(106 MB) per minute.7. The back-end Instances, as well as the DB instances, was witnessing high network traffic.This indicated that the application was hitting a high traffic which leads to a high data processign in the back-end instances as well as the DB. There were a high number of TIME_WAIT connections on both the backend instances even after the incident was resolved that indicates the same. In order to prevent this in future, we recommend configuring autoscaling for your application that will prevent these type resource bottleneck issues.Please review these details and let us know if you have any concerns about these details and also your thoughts on the recommendation.Thank You,Safuvan KM###+++Internal Comment+++As we know, Secure-SpendHQ-ELB is pointed to the Sophos Instance and from WAF, it is pointed to NewPreview-ELB. PRD-WW1(10-59-100-122) and PRD-WW2(10-59-101-6) are the WebServer instances attached to the NewPeview-ELB. The backend database configured for these web servers is PRD-DB1(10.59.10.190).We have analyzed the WebServer Instance metrics where it usage looks fine and from Instance level, we have analyzed the system messages, httpd logs, and tomcat logs which is also good at the time of this issue. But we were able to witness a spike in the total number of TIME_WAIT connections on both of the WebServers. Refer the details below,[root@ip-10-59-101-6 logs]# netstat | grep TIME_WAIT | wc -l374[root@ip-10-59-100-122 logs]# netstat | grep TIME_WAIT | wc -l389The site down issue lasted only for a short time period and the above details were collected after the alert got resolved and we believe that there was a high number of TIME_WAIT connections during the time of the issue. Soon later the TIME_WAIT value reduced to a range between 100-150 for both of the instances. TIME_WAIT is actually a state that some sockets can enter and remain in for a relatively long length of time if we have high socket's in TIME_WAIT then the ability to create new socket connections may be affected and this can affect the scalability of the system. As all of the other metrics look normal, we suspect the high latency was caused due to a high number of TIME_WAIT connections. And we are unable to further analyze more on the backend DB as we don't have access to the DB. Verify these details with CC and check if we are good to share the TIME_WAIT details with the customer or not.###Hello SpendHQ-Team,On further analysis, we were able to figure out that the URL https://secure.spendhq.com/login was not down at the time of this alert and was serving well as expected. The site down alert was triggered at 19:03 UTC and it got resolved at 19:04 UTC. We have verified the logs and found the issue was caused due to a sudden spike in the ELB latency where ELB was not able to respond to our monitoring request within the timeout period set in the monitoring tool (which is 30 seconds). Hence it has thrown the Site down alert. But users wouldn’t experience any downtime because the ELB timeout is set to 1000 seconds and the latency was rounded up to 194 seconds. All of the requests within the timeframe of this issue has been served with 200 response code. As the URL https://secure.spendhq.com/login was not down, we are reducing the priority of this case from P1 to P2.During the time of this issue, we could see high CPU Load and Network Out for the backed Database instance PRD-DB1(10.59.10.190). All other web servers and ELB metrics are normal. We have attached the ELB access logs during the time of this issue along with this ticket for reference. Kindly validate it for more details.We are further performing more analysis from the WebServer Instances and will keep your team updated regarding the progress. Validate these details and revert back in case of any further queries.Regards,Sumod.K.Bose###Hello SpendHQ-Team,This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login. The alert got resolved within one minute and the website is now serving well as expected.We are further performing more analysis on this issue and will get back to you with the updates shortly. Kindly validate these details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Tue, 31 Oct 2017 15:05:15 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): London UK, Atlanta-B US, California US, Sydney-C AU--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,01-11-2017 00:35,66,0,SpendHQ,"Hello Andrew,Thanks for the update.At this time we are marking this case as resolved. Please revert back to us if you have any queries.","Thank you for your recommendation. At this time, we are currently building towards autoscaling, but our application does not support this currently.You may close this case. Thank you.",The analysis has been shared already and sent 2 reminders for the customer response. Please sent a final reminder in today evening shift and close it in tomorrow evening shift.,"Hello SpendHQ-Team, Did you get a chance to review the recommendations provided regarding this case? Kindly validate the details shared and let us know if your team have any further queries regarding this case.","Hello SpendHQ-Team,Did you get a chance to review the recommendations provided regarding this case?Kindly validate the details shared and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello SpendHQ Team,As we already mentioned, the website wasn't down and all the requests were served with 200 response code. The issue was the latency which reached around 194 seconds. While analyzing the reason behind the latency, below are the findings:1. Public Load Balancer Secure-SpendHQ-ELB was having high request count with a maximum value of 361 per minute.2. Public Load Balancer Secure-SpendHQ-ELB  witnessed a spike in the Estimated Processed Bytes with a maximum value of 106186612 bytes(106 MB) per minute.3. Sophos UTM Network In was high with a value of 796 MB per minute.4. Sophos UTM Network Out was high with a value of 533 MB per minute.5. Internal Load Balancer NewPreview-ELB Latency went high with a value of 29 seconds.6. Internal Load Balancer NewPreview-ELB witnessed a spike in the Estimated Processed Bytes with a maximum value of 106186612 bytes(106 MB) per minute.7. The back-end Instances, as well as the DB instances, was witnessing high network traffic.This indicated that the application was hitting a high traffic which leads to a high data processign in the back-end instances as well as the DB. There were a high number of TIME_WAIT connections on both the backend instances even after the incident was resolved that indicates the same. In order to prevent this in future, we recommend configuring autoscaling for your application that will prevent these type resource bottleneck issues.Please review these details and let us know if you have any concerns about these details and also your thoughts on the recommendation.Thank You,Safuvan KM","+++Internal Comment+++As we know, Secure-SpendHQ-ELB is pointed to the Sophos Instance and from WAF, it is pointed to NewPreview-ELB. PRD-WW1(10-59-100-122) and PRD-WW2(10-59-101-6) are the WebServer instances attached to the NewPeview-ELB. The backend database configured for these web servers is PRD-DB1(10.59.10.190).We have analyzed the WebServer Instance metrics where it usage looks fine and from Instance level, we have analyzed the system messages, httpd logs, and tomcat logs which is also good at the time of this issue. But we were able to witness a spike in the total number of TIME_WAIT connections on both of the WebServers. Refer the details below,[root@ip-10-59-101-6 logs]# netstat | grep TIME_WAIT | wc -l374[root@ip-10-59-100-122 logs]# netstat | grep TIME_WAIT | wc -l389The site down issue lasted only for a short time period and the above details were collected after the alert got resolved and we believe that there was a high number of TIME_WAIT connections during the time of the issue. Soon later the TIME_WAIT value reduced to a range between 100-150 for both of the instances. TIME_WAIT is actually a state that some sockets can enter and remain in for a relatively long length of time if we have high socket's in TIME_WAIT then the ability to create new socket connections may be affected and this can affect the scalability of the system. As all of the other metrics look normal, we suspect the high latency was caused due to a high number of TIME_WAIT connections. And we are unable to further analyze more on the backend DB as we don't have access to the DB. Verify these details with CC and check if we are good to share the TIME_WAIT details with the customer or not.","Hello SpendHQ-Team,On further analysis, we were able to figure out that the URL https://secure.spendhq.com/login was not down at the time of this alert and was serving well as expected. The site down alert was triggered at 19:03 UTC and it got resolved at 19:04 UTC. We have verified the logs and found the issue was caused due to a sudden spike in the ELB latency where ELB was not able to respond to our monitoring request within the timeout period set in the monitoring tool (which is 30 seconds). Hence it has thrown the Site down alert. But users wouldn’t experience any downtime because the ELB timeout is set to 1000 seconds and the latency was rounded up to 194 seconds. All of the requests within the timeframe of this issue has been served with 200 response code. As the URL https://secure.spendhq.com/login was not down, we are reducing the priority of this case from P1 to P2.During the time of this issue, we could see high CPU Load and Network Out for the backed Database instance PRD-DB1(10.59.10.190). All other web servers and ELB metrics are normal. We have attached the ELB access logs during the time of this issue along with this ticket for reference. Kindly validate it for more details.We are further performing more analysis from the WebServer Instances and will keep your team updated regarding the progress. Validate these details and revert back in case of any further queries.Regards,Sumod.K.Bose","Hello SpendHQ-Team,This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login. The alert got resolved within one minute and the website is now serving well as expected.We are further performing more analysis on this issue and will get back to you with the updates shortly. Kindly validate these details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XxChj,Cloud Engineer Level 1,Closed,1100385,Incident,20-06-2018 14:40,,"Hello Matthew,Thanks for the confirmation,At this time we are marking this case as resolved and closing this case. Please let us know if you have any further queries.###Matthew Watts2:36 PM (1 minute ago)to Rean, spendhq-support ConfirmedSent from a mobile device.###Hello Team,Further analyzing on this issue we could see that there was a high latency and request count on the ELB preview-spendhq-xelb uring the period of the error. Please review the Cloudwatch graph for latency and latency logs from the attachments section. Please let us know if you have any further queries.###Hello SpendHQ Team, This is to inform you that we've received a site down alert on URL: https://preview.spendhq.com/login. The downtime lasted for 1 minutes We are analyzing this and will get back to you with further details on the issue.","---------- Forwarded message ----------From: <ms@reancloud.com>Date: Wed, Jun 20, 2018 at 2:08 PMSubject: Detected Error on SpendHQ PreviewTo: ms@reancloud.comWed, 20 Jun 2018 04:38:22 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30026 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): London UK, California US, New Jersey US, Sydney-C AU-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Sprint to Cloud | AWS Public Sector SummitBooth #304 | June 20th - 21th, 2018 <http://go.reancloud.com/aws-public-sector-summit-2018>Moving to the cloud, securelyJune 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Preview,,20-06-2018 14:10,0,0,SpendHQ,"Hello Matthew,Thanks for the confirmation,At this time we are marking this case as resolved and closing this case. Please let us know if you have any further queries.","Matthew Watts2:36 PM (1 minute ago)to Rean, spendhq-support ConfirmedSent from a mobile device.","Hello Team,Further analyzing on this issue we could see that there was a high latency and request count on the ELB preview-spendhq-xelb uring the period of the error. Please review the Cloudwatch graph for latency and latency logs from the attachments section. Please let us know if you have any further queries.","Hello SpendHQ Team, This is to inform you that we've received a site down alert on URL: https://preview.spendhq.com/login. The downtime lasted for 1 minutes We are analyzing this and will get back to you with further details on the issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bk7IB,Cloud Engineer Level 1,Closed,1104504,Incident,14-09-2018 02:30,,This was tracked under I-01104501Hence closing the case.,"Disregard, seems to be working now.Dan Mackay | Spend Solutions DBA | SpendHQO: 770-741-0157 | dmackay@spendhq.com<mailto:dmackay@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing GroupFrom: Daniel MackaySent: Thursday, September 13, 2018 4:51 PMTo: 'Rean Support' <support@reancloud.com>Cc: Technology Group <TechnologyGroup@insightsourcing.com>Subject: SEV ONE - Cannot Connect to the VPNRean,We are unable to connect to the VPN. Please investigate and fix ASAP.Best Regards,Dan Mackay | Spend Solutions DBA | SpendHQO: 770-741-0157 | dmackay@spendhq.com<mailto:dmackay@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: SEV ONE - Cannot Connect to the VPN,,14-09-2018 02:24,0,0,SpendHQ,This was tracked under I-01104501Hence closing the case.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gdkxX,Cloud Engineer Level 1,Closed,1109813,Incident,24-12-2018 22:05,,"Matthew Watts10:03 PM (1 minute ago)to Rean, spendhq-support@reancloud.comPerfect. Yes please close this case.###Hello Spendhq-Team, We still haven't heard back from you regarding this case.As mentioned earlier, this issue was resolved after 1 minute. Therefore, at this point we are proceeding to close this case.However, if you have any questions or concerns, please let us know.Regards,REAN TEAM###Hello Team,We haven't heard back from you.Please review our shared analysis and let us know your thoughts on the same.Thanks,###Hello Spendhq-Team,This is a gentle reminderPlease review the analysis shared and let us know if you have queries.###Hello SpendHQ-Team,We have investigated on the site down and found that the URL https://secure.spendhq.com/login was not down and was serving well during the time of site down. We have verified the logs and found the issue was caused due to a sudden spike in the ELB latency. We got the site down alert because of the timeout period set in our monitoring tool as 30 seconds.The latency was 58017.45 milliseconds and other metrics seems to be normal. From the instance level, we could see a high number of requests are in TIME_WAIT condition with the value of 582 and also the network IN and OUT was high at the time of the site down. Please review the analysis and let us know in case of any queires.###Sent an email to MGS leads###Hello SpendHQ-Team, On further analysis, we were able to figure out that the URL https://secure.spendhq.com/login was not down at the time of this alert and was serving well as expected. The site down alert was triggered at 20:05 UTC and it got resolved at 20:06 UTC. We have verified the logs and found the issue was caused due to a sudden spike in the ELB latency where ELB was not able to respond to our monitoring request within the timeout period set in the monitoring tool (which is 30 seconds). Hence it has thrown the Site down alert. But users wouldn’t experience any downtime because the ELB timeout is set to 3600 seconds and the latency was rounded up to 58017.45 milliseconds. All of the requests within the timeframe of this issue has been served with 200 response code. We have checked the ELB and instance metrics, form the ELB level we could see a high spike in latency that reached up to 58017.45ms and other metrics seems to be normal. On checking the instance level, we were able to see a high number of requests are in TIME_WAIT condition and also the network IN and OUT was high at the time. [root@ip-10-59-100-122 ~]# netstat | grep TIME_WAIT | wc -l582Please find the attached latency logs, Network IN and OUT on the web server.Kindly validate the details from your end and let us know if you have further queries.###Hello Team,We received the 4 times site down alert for https://secure.spendhq.com/login and resolved within one minute.Currently, we are analyzing the issue and keep you posted the updates. Meanwhile please let us know if you are performing any activity or not.###Hello Team, This is to notify that we have received an alert regarding Detected Error on SpendHQ Secure for the URL https://secure.spendhq.com/login.The alert got recovered. Violation is 1 minute. The site is accessible now. Currently, we are analyzing the issue and keep you posted the updates.","Fri, 21 Dec 2018 15:35:38 -0500Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsecure.spendhq.com%2Flogin&amp;data=01%7C01%7Cgourav.pokhra%40hitachivantara.com%7C03a9c3c0ce7c4b95f7ee08d66783e01a%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=N2QsJFkLAcvkW684aO1wEbcWOImGN4Jl5%2BgUPL9AxLU%3D&amp;reserved=0expect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, Dallas-B US, Frankfurt DE, California US-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,22-12-2018 02:07,68,0,SpendHQ,"Matthew Watts10:03 PM (1 minute ago)to Rean, spendhq-support@reancloud.comPerfect. Yes please close this case.","Hello Spendhq-Team, We still haven't heard back from you regarding this case.As mentioned earlier, this issue was resolved after 1 minute. Therefore, at this point we are proceeding to close this case.However, if you have any questions or concerns, please let us know.Regards,REAN TEAM","Hello Team,We haven't heard back from you.Please review our shared analysis and let us know your thoughts on the same.Thanks,","Hello Spendhq-Team,This is a gentle reminderPlease review the analysis shared and let us know if you have queries.","Hello SpendHQ-Team,We have investigated on the site down and found that the URL https://secure.spendhq.com/login was not down and was serving well during the time of site down. We have verified the logs and found the issue was caused due to a sudden spike in the ELB latency. We got the site down alert because of the timeout period set in our monitoring tool as 30 seconds.The latency was 58017.45 milliseconds and other metrics seems to be normal. From the instance level, we could see a high number of requests are in TIME_WAIT condition with the value of 582 and also the network IN and OUT was high at the time of the site down. Please review the analysis and let us know in case of any queires.",Sent an email to MGS leads,"Hello SpendHQ-Team, On further analysis, we were able to figure out that the URL https://secure.spendhq.com/login was not down at the time of this alert and was serving well as expected. The site down alert was triggered at 20:05 UTC and it got resolved at 20:06 UTC. We have verified the logs and found the issue was caused due to a sudden spike in the ELB latency where ELB was not able to respond to our monitoring request within the timeout period set in the monitoring tool (which is 30 seconds). Hence it has thrown the Site down alert. But users wouldn’t experience any downtime because the ELB timeout is set to 3600 seconds and the latency was rounded up to 58017.45 milliseconds. All of the requests within the timeframe of this issue has been served with 200 response code. We have checked the ELB and instance metrics, form the ELB level we could see a high spike in latency that reached up to 58017.45ms and other metrics seems to be normal. On checking the instance level, we were able to see a high number of requests are in TIME_WAIT condition and also the network IN and OUT was high at the time. [root@ip-10-59-100-122 ~]# netstat | grep TIME_WAIT | wc -l582Please find the attached latency logs, Network IN and OUT on the web server.Kindly validate the details from your end and let us know if you have further queries.","Hello Team,We received the 4 times site down alert for https://secure.spendhq.com/login and resolved within one minute.Currently, we are analyzing the issue and keep you posted the updates. Meanwhile please let us know if you are performing any activity or not.","Hello Team, This is to notify that we have received an alert regarding Detected Error on SpendHQ Secure for the URL https://secure.spendhq.com/login.The alert got recovered. Violation is 1 minute. The site is accessible now. Currently, we are analyzing the issue and keep you posted the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001geOdc,Cloud Engineer Level 1,Closed,1109901,Incident,26-12-2018 18:54,,"Hello Matthew,Thanks for the update. Currently, we are marking this case as closed.Thanks and regardsRevathy Kurup###Perfect. Please close the caseMatthew Watts###Hello Team,This is to inform you that we have cleaned up the IAM user paul.mulonzia since the account has not been used over the past 96 days.Please check on the same and let us know if you have any query/concern.Thanks,###Hello Team, Paul shouldn’t be having an user in SpendHQ, I am not sure who/why/when created this account. Please clean it up ASAP. Praveen Muppala Cloud Architect / Tech Lead, Managed Services","REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::IAM::User resources were affected:________________________________  *   Violation: The user account is not enabled and Inactive since last 90 days.  *   Recommendation: To prevent your account from getting Deleted, please LogIn to your account or user your API Keys.  *   Action taken: None  *   Resource details:Resource IDUser NamePassword Last UsedAccess Keys Last UsedAIDAJHL6YNDQRLY4NKHP2paul.mulonziaNever2018-09-21________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Managed Cloud: spendhq] Inactive IAM Users Alert,,26-12-2018 17:21,2,0,SpendHQ,"Hello Matthew,Thanks for the update. Currently, we are marking this case as closed.Thanks and regardsRevathy Kurup",Perfect. Please close the caseMatthew Watts,"Hello Team,This is to inform you that we have cleaned up the IAM user paul.mulonzia since the account has not been used over the past 96 days.Please check on the same and let us know if you have any query/concern.Thanks,","Hello Team, Paul shouldn’t be having an user in SpendHQ, I am not sure who/why/when created this account. Please clean it up ASAP. Praveen Muppala Cloud Architect / Tech Lead, Managed Services",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001aNOt1,Cloud Engineer Level 1,Closed,1102747,Incident,15-08-2018 00:39,,"Hello Team,The alert regarding high memory Utilization on sandbox.spendhq.com_11th_Oct_2017  has recovered and the current utilization is at 22.94%. At this time we are marking this case as closed and let us know if you have queries.###Hello Team,This is to notify you that the alert regarding high memory Utilization on sandbox.spendhq.com_11th_Oct_2017   has recovered and the current utilization is at 22.94%.Thanks###Hello Team,This is to inform you that we have received an alert regarding high memory Utilization on sandbox.spendhq.com_11th_Oct_2017 has exceeded the threshold value of 95 to 97.8Resource Details:-Instance ID: i-0627929bed380b8daInstance Name: sandbox.spendhq.com_11th_Oct_2017Private IP: 10.59.100.240Please check the below-mentioned details for High Memory Utilization.USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDapache   21114  0.1  7.9 1588320 1220164 ?     S    Aug13   2:09 /usr/sbin/httpdapache   20937  0.1  7.9 1576880 1208652 ?     S    Aug13   2:11 /usr/sbin/httpdapache   20939  0.1  7.8 1576148 1208012 ?     S    Aug13   2:08 /usr/sbin/httpdapache   21109  0.1  7.8 1562056 1193864 ?     S    Aug13   2:06 /usr/sbin/httpdapache   21083  0.1  7.7 1555380 1187160 ?     S    Aug13   2:05 /usr/sbin/httpdapache   31332  0.0  7.7 1552460 1184524 ?     S    Aug12   2:05 /usr/sbin/httpdapache   30877  0.1  7.7 1551828 1183768 ?     S    Aug13   2:06 /usr/sbin/httpdapache   23794  0.0  7.7 1551664 1183548 ?     S    Aug11   2:06 /usr/sbin/httpdapache   19990  0.0  7.7 1547700 1179664 ?     S    Aug13   2:09 /usr/sbin/httpdapache   20901  0.1  7.7 1547716 1179648 ?     S    Aug13   2:05 /usr/sbin/httpdPlease let us know if you have any queries.","[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host -sandbox.spendhq.com_11th_oct_2017 - 10.59.100.240 -Detected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1534252967000&group=host%3Ai-0627929bed380b8da&from_ts=1534245767000>avg(last_30m):(avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 95The monitor was last triggered at Tue Aug 14 2018 13:22:57 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-0627929bed380b8da>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-0627929bed380b8da<https://app.datadoghq.com/infrastructure?filter=i-0627929bed380b8da>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1534253097000&tags=host%3Ai-0627929bed380b8da&from_ts=1534252077000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4529682434038470867>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - sandbox.spendhq.com_11th_oct_2017 - 10.59.100.240 -,,14-08-2018 19:04,6,0,SpendHQ,"Hello Team,The alert regarding high memory Utilization on sandbox.spendhq.com_11th_Oct_2017  has recovered and the current utilization is at 22.94%. At this time we are marking this case as closed and let us know if you have queries.","Hello Team,This is to notify you that the alert regarding high memory Utilization on sandbox.spendhq.com_11th_Oct_2017   has recovered and the current utilization is at 22.94%.Thanks","Hello Team,This is to inform you that we have received an alert regarding high memory Utilization on sandbox.spendhq.com_11th_Oct_2017 has exceeded the threshold value of 95 to 97.8Resource Details:-Instance ID: i-0627929bed380b8daInstance Name: sandbox.spendhq.com_11th_Oct_2017Private IP: 10.59.100.240Please check the below-mentioned details for High Memory Utilization.USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDapache   21114  0.1  7.9 1588320 1220164 ?     S    Aug13   2:09 /usr/sbin/httpdapache   20937  0.1  7.9 1576880 1208652 ?     S    Aug13   2:11 /usr/sbin/httpdapache   20939  0.1  7.8 1576148 1208012 ?     S    Aug13   2:08 /usr/sbin/httpdapache   21109  0.1  7.8 1562056 1193864 ?     S    Aug13   2:06 /usr/sbin/httpdapache   21083  0.1  7.7 1555380 1187160 ?     S    Aug13   2:05 /usr/sbin/httpdapache   31332  0.0  7.7 1552460 1184524 ?     S    Aug12   2:05 /usr/sbin/httpdapache   30877  0.1  7.7 1551828 1183768 ?     S    Aug13   2:06 /usr/sbin/httpdapache   23794  0.0  7.7 1551664 1183548 ?     S    Aug11   2:06 /usr/sbin/httpdapache   19990  0.0  7.7 1547700 1179664 ?     S    Aug13   2:09 /usr/sbin/httpdapache   20901  0.1  7.7 1547716 1179648 ?     S    Aug13   2:05 /usr/sbin/httpdPlease let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5002I00001i5mUU,Cloud Engineer Level 1,Closed,1110635,Incident,12-01-2019 02:46,,"Hello Matthew,Thanks for the update.As of now, the alert is in the recovered state, therefore, we are marking this case resolved and closing this case. Please get back to us if you come across any issue.Thanks###We were conducting maintenance at this time. It was not on the load balancer.Matthew Watts | Manager, Application Development | SpendHQ®###Hello Team,This is to inform you that we have received an alert regarding Httpd process is down on prd-ww1_122 (10.59.100.122) server.The alert got recovered within 2 minutes. We are analyzing the issue, meanwhile please update us if you were performing any activity.","From: Datadog Alerting <alert@dtdg.co>Sent: 12 January 2019 02:26To: REANCloud SupportSubject: [Monitor Alert] Triggered: [SpendHQ] Httpd Process is down - prd-ww1_122 - 10.59.100.122 - web on host:i-0ace70ce06368e4a7,process:httpd[Datadog][Triggered on {host:i-0ace70ce06368e4a7,process:httpd}] [SpendHQ] Httpd Process is down - prd-ww1_122 - 10.59.100.122 - webHttpd Process is down    @ms@reancloud.com<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Faccount%2Fprofile%2Fu-0Z0C_KyYU1Hu&data=01%7C01%7Cchandrapratap.singh%40hitachivantara.com%7C764f8f64a43c44718f2008d6780738f7%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=foGhp679FSST5zpX9h51J1xhYW5TpbFWltnwdeoc3cg%3D&reserved=0>PROCS CRITICAL: 0 processes found for httpdThe monitor was last triggered at Fri Jan 11 2019 20:56:00 UTC (8 secs ago).________________________________[Monitor Status<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Fmonitors%232014428%3Fgroup%3Dhost%253Ai-0ace70ce06368e4a7%252Cprocess%253Ahttpd&data=01%7C01%7Cchandrapratap.singh%40hitachivantara.com%7C764f8f64a43c44718f2008d6780738f7%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=cl%2BlWGLrDTTMvaEcafx7SJc1ydQLKLDzcAxvrU%2FZIE0%3D&reserved=0>] · [Edit Monitor<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Fmonitors%232014428%2Fedit&data=01%7C01%7Cchandrapratap.singh%40hitachivantara.com%7C764f8f64a43c44718f2008d6780738f7%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=heP7q4eWJlryhScyc%2B85ieu8q1er6wG0YgNuW%2F2hqb0%3D&reserved=0>] · [View i-0ace70ce06368e4a7<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Finfrastructure%3Ffilter%3Di-0ace70ce06368e4a7&data=01%7C01%7Cchandrapratap.singh%40hitachivantara.com%7C764f8f64a43c44718f2008d6780738f7%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=2OCy33DIQNXAC9KRt85GQNBmwOIR2gVA%2F7xAELNDXFY%3D&reserved=0>] · [Show Processes<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Fprocess%3Fsort%3Dmemory%252CASC%26to_ts%3D1547240280000%26tags%3Dhost%253Ai-0ace70ce06368e4a7%26from_ts%3D1547239260000%26live%3Dfalse%26showSummaryGraphs%3Dtrue&data=01%7C01%7Cchandrapratap.singh%40hitachivantara.com%7C764f8f64a43c44718f2008d6780738f7%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=Eh7PhuqwOqK%2BlE58slXE6hUms78Smk6EcVosKWySSy8%3D&reserved=0>]This alert was raised by account SpendHQComment in Datadog<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Fevent%2Fevent%3Fid%3D4747571331285426289&data=01%7C01%7Cchandrapratap.singh%40hitachivantara.com%7C764f8f64a43c44718f2008d6780738f7%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=tF%2B%2FLY%2F%2B4t%2FryW1gOrdMXNu3PNZcWMWnQoLy3wNohD8%3D&reserved=0>To manage your Datadog subscriptions, click here<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fapp.datadoghq.com%2Faccount%2Fpreferences&data=01%7C01%7Cchandrapratap.singh%40hitachivantara.com%7C764f8f64a43c44718f2008d6780738f7%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=JrPLQpuVhI8VC5GFfrub%2BRmE8dqgR7bUuMaIYxbsFZQ%3D&reserved=0>.-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","Fw: [Monitor Alert] Triggered: [SpendHQ] Httpd Process is down - prd-ww1_122  - 10.59.100.122 - web on host:i-0ace70ce06368e4a7,process:httpd",,12-01-2019 02:30,0,0,SpendHQ,"Hello Matthew,Thanks for the update.As of now, the alert is in the recovered state, therefore, we are marking this case resolved and closing this case. Please get back to us if you come across any issue.Thanks","We were conducting maintenance at this time. It was not on the load balancer.Matthew Watts | Manager, Application Development | SpendHQ®","Hello Team,This is to inform you that we have received an alert regarding Httpd process is down on prd-ww1_122 (10.59.100.122) server.The alert got recovered within 2 minutes. We are analyzing the issue, meanwhile please update us if you were performing any activity.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001kndqP,Cloud Engineer Level 1,Closed,1112553,Incident,04-03-2019 09:09,,"Hello Team,We have deleted the IAM user Beca. Please let us know when you want us to recreate the user. For now, we are closing this case. Please revert back to us in case of any query.###Hi Matthew,As our team mentioned that IAM User beca has no activity from the day the user been created. As a security measure, we are going to delete this user in next 24 hours if we do not get any response from you on this. Thanks.###Hello team, This is a quick follow up! We have received an alert regarding Inactive IAM Users for beca user. As per alert, Your account will be deleted on 2019-02-27. So we recommend you to LogIn your account in every 10 days, to prevent your account from getting deleted in the future. If you need any help, feel free to contact us at any time. Regards.###Hello team,This is a quick follow up!We have received an alert regarding Inactive IAM Users for beca user. As per alert, Your account will be deleted on 2019-02-27. So we recommend you to LogIn your account in every 10 days, to prevent your account from getting deleted in the future. If you need any help, feel free to contact us at any time. Regards.###Hello team,We have received an alert regarding Inactive IAM Users for beca user. As per alert, Your account will be deleted on 2019-02-27.So we recommend you to LogIn your account in every 10 days, to prevent your account from getting deleted in future.If you need any help, feel free to contact us at any time.Regards.","________________________________From: notifications@mnc-notify.com <notifications@mnc-notify.com>Sent: Tuesday, February 26, 2019 4:10 PMTo: Spendhq SupportSubject: [Managed Cloud: spendhq] Inactive IAM Users Alert***** EXTERNAL EMAIL *****REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::IAM::User resources were affected:________________________________  *   Violation: The user has reached maximum number of Inactive days allowed 90  *   Recommendation: Please LogIn to your account in every 10 days, to prevent your account from getting deleted in future  *   Action taken: None  *   Resource details:Resource ID     User Name       Password Last Used      Access Keys Last Used   Delete OnAIDAJA3T5BQYVN5I6LAOO   beca    Never   Never   2019-02-27________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.",[Managed Cloud: spendhq] Inactive IAM Users Alert,,26-02-2019 16:20,137,0,SpendHQ,"Hello Team,We have deleted the IAM user Beca. Please let us know when you want us to recreate the user. For now, we are closing this case. Please revert back to us in case of any query.","Hi Matthew,As our team mentioned that IAM User beca has no activity from the day the user been created. As a security measure, we are going to delete this user in next 24 hours if we do not get any response from you on this. Thanks.","Hello team, This is a quick follow up! We have received an alert regarding Inactive IAM Users for beca user. As per alert, Your account will be deleted on 2019-02-27. So we recommend you to LogIn your account in every 10 days, to prevent your account from getting deleted in the future. If you need any help, feel free to contact us at any time. Regards.","Hello team,This is a quick follow up!We have received an alert regarding Inactive IAM Users for beca user. As per alert, Your account will be deleted on 2019-02-27. So we recommend you to LogIn your account in every 10 days, to prevent your account from getting deleted in the future. If you need any help, feel free to contact us at any time. Regards.","Hello team,We have received an alert regarding Inactive IAM Users for beca user. As per alert, Your account will be deleted on 2019-02-27.So we recommend you to LogIn your account in every 10 days, to prevent your account from getting deleted in future.If you need any help, feel free to contact us at any time.Regards.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001lRcGd,Cloud Engineer Level 1,Closed,1113098,Incident,12-03-2019 01:38,,"Hello Balam,Thanks for your updated response. At this time we are marking this case as closed.###***** EXTERNAL EMAIL *****That will be all regarding this question.You may close the ticket.Thank you,Balam MendozaCISO OfficeSpendHQ###Hello Balam,The instances which have spendhq-office-hours Policy will stop the instance at 1 AM EST and will start at 7 AM EST.Let us know if you have any queries regarding this.","Hi,We need to know if the instances with the spendhq-office-hours Shutdown Policy are turn down after 8PM or so. And if you could give us the timeframe where they are up.Best,Balam MendozaCISO OfficeSpendHQ-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",spendhq-office-hours Policy,,11-03-2019 21:38,4,0,SpendHQ,"Hello Balam,Thanks for your updated response. At this time we are marking this case as closed.","***** EXTERNAL EMAIL *****That will be all regarding this question.You may close the ticket.Thank you,Balam MendozaCISO OfficeSpendHQ","Hello Balam,The instances which have spendhq-office-hours Policy will stop the instance at 1 AM EST and will start at 7 AM EST.Let us know if you have any queries regarding this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Dnl0H,Cloud Engineer Level 2,Closed,1065595,Incident,04-07-2017 21:00,,"Hello Matthew,We haven't heard back from you regarding this case. At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Regards,Sumod.K.Bose###Next Action: Evening shift: Check whether we are getting any response from the customer, else send a reminder.###Hello Matthew,We haven't heard back from you regarding this case. Kindly validate these details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Next Action: Check whether we are getting any response from the customer, else send a reminder on Evening shift.###Hello Matthew,We haven't heard back from you.Please validate our findings and let us know if you have any queries.###Next Action: Check whether we are getting any response from customer, else send a reminder on afternoon shift.###Hi Matthew/ Steven,On further analysis, we could see that the server went into unresponsive mode 30 minutes before the restart happen. Memory leak caused by java process fills the heap space, which resulted in Java OutOfMemoryError.The issue got resolved after Matthew restarted the application.From logs, we could see that the web application [InfoGo] appears to have started a thread named [Thread-10] but has failed to stop it. This is very likely to create a memory leak.Please find the below logs.Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread http-nio-8080-ClientPoller-1Exception in thread https-jsse-nio-443-exec-1         at java.util.Collections$UnmodifiableCollection.iterator(Unknown Source)Exception in thread http-nio-80-Acceptor-0 Exception in thread https-jsse-nio-443-exec-3 Exception in thread https-jsse-nio-443-ClientPoller-0 Exception in thread http-nio-80-ClientPoller-1 Exception in thread https-jsse-nio-443-exec-9   at org.apache.tomcat.util.net.NioEndpoint$Poller.timeout(NioEndpoint.java:1005)        at org.apache.tomcat.util.net.NioEndpoint$Poller.run(NioEndpoint.java:825)        at java.lang.Thread.run(Unknown Source)java.lang.OutOfMemoryError: Java heap spacejava.lang.OutOfMemoryError: Java heap spacejava.lang.OutOfMemoryError: Java heap spacejava.lang.OutOfMemoryError: Java heap spacejava.lang.OutOfMemoryError: Java heap spacejava.lang.OutOfMemoryError: Java heap space28-Jun-2017 21:56:05.008 WARNING [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase.clearReferencesThreads The web application [InfoGo] appears to have started a thread named [Thread-10] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: java.lang.Object.wait(Native Method) vmw.common.SynchUtils.wait(SynchUtils.java:19) system.Threading.ThreadPool$WorkerThread.run(ThreadPool.jvm.cs:259) It seems to be related with application side, please check with your application team to figure out this issue. Let us know if you need any further details.Since you haven't previously asked to monitor this  l.spendhq.com. URL specifically we didn't enable that. Now the URL is under monitoring.Also please find the list of resources that are currently under monitoring from attachment section.###Matthew WattsWhy was this not being monitored? This is a PRD box that is managed by REAN. Can you please provide me with a list of all boxes and URL’s that are monitored.###Hello Team,We will check more on this and will get back to you with details.Also, we have enabled monitoring for the URL l.spendhq.com in our URL monitoring tool so that we will be notified when it goes down.###Steven Updated that.That restart issued by mwatts was the answer to correcting the issue. We need to know why the process wasn't behaving properly, which resulted in a 504 response frim l.spendhq.com even though it appeared to be running prior to being restarted by mwatts.###Sanket updated to enable url monitoring in wormly. And apart from that, we are good. Next action: we need to work on this.###Next action: Evening shift. Please discuss this issue on call and check if any further analysis is pending on this part. Also, need to check whether this URL needs to be get monitored through Wormly. Summary: /* As per the initial analysis, we were able to figure out that Tomcat service has been stopped and started during the time of this incident. Initially, when Matthew informed that the URL l.spendhq.com was down and we tried to load the URL but it was not accessible at that time. Later when the Tomcat service got started, we were able to witness Tomcat default web page while accessing this URL. Basically, we are not aware of the content that this particular URL needs to serve. Hence we contacted Praveen and passed the same information to him. Based on his suggestion, we are informing all these details to the customer. We have analysed the system logs and was not able to find any error related at the time of this incident.*/###Next action: Morning shift team: Need to discuss this issue with Sanket and check if any further analysis is pending on this part. Also, need to check whether this URL needs to be get monitored through Wormly.###Hello SpendHQ-Team,Initially, when this incident was reported, we were not able to access the URL l.spendhq.com. Later after a short period of time, the URL was serving with the default web page of Tomcat service. After performing more analysis on the instance level, we were able to witness that the Tomcat service was in the stopped state and later the service was restarted. Kindly refer the below logs for more details.Logs :- Stopping Service Catalina 28-Jun-2017 21:56:04.938 INFO [main] org.apache.catalina.core.StandardService.stopInternal Stopping service Catalina28-Jun-2017 21:56:05.008 WARNING [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase.clearReferencesThreads The web application [InfoGo] appears to have started a thread named [Thread-10] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:28-Jun-2017 21:56:05.028 INFO [main] org.apache.coyote.AbstractProtocol.stop Stopping ProtocolHandler [http-nio-8080]28-Jun-2017 21:56:06.130 INFO [main] org.apache.coyote.AbstractProtocol.stop Stopping ProtocolHandler [http-nio-80]28-Jun-2017 21:56:08.234 INFO [main] org.apache.coyote.AbstractProtocol.stop Stopping ProtocolHandler [https-jsse-nio-443]28-Jun-2017 21:56:10.339 INFO [main] org.apache.coyote.AbstractProtocol.stop Stopping ProtocolHandler [ajp-nio-8009]Starting Service Catalina 28-Jun-2017 21:56:45.113 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [http-nio-8080]28-Jun-2017 21:56:45.123 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [http-nio-80]28-Jun-2017 21:56:45.126 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [https-jsse-nio-443]28-Jun-2017 21:56:45.130 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [ajp-nio-8009]28-Jun-2017 21:56:45.135 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 32465 msThe tomcat service was stopped at 21:56:04 UTC, later it got started at 21:56:45 UTC. We were able to see that below users have logged in to the instance during the time of this incident.[root@10 centos]# w 22:01:08 up 17 days, 23:24,  5 users,  load average: 0.02, 0.17, 0.09USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHATdfowler  pts/1    10.59.1.192      20:22    1:11m  0.01s  0.00s sshd: dfowler [priv]mwatts   pts/2    10.59.1.192      21:37    4:52   0.02s  0.02s -bashmwatts   pts/3    10.59.1.192      21:39    5:08  60.76s  0.01s -bashaherrera pts/4    10.59.1.192      21:55    2:08   0.00s  0.00s -bashcentos   pts/5    10.59.1.192      21:59    0.00s  0.00s  0.00s sshd: centos [priv]From analysing the bash history details, we were able to see that the tomcat service restart command (sudo /etc/init.d/tomcat restart) has been initiated by the user mwatts.As of now, the URL l.spendhq.com is serving the default tomcat web page. Please let us know whether this is the expected outcome of this URL.  We have analysed the system logs and was not able to find any error related at the time of this incident. Kindly validate all these details and let us know if your team have any further queries regarding this case.###+++ Internal Comment +++We had a call with Praveen for addressing this issue. As per the initial analysis, we were able to figure out that Tomcat service has been stopped and started during the time of this incident. Initially, when Matthew informed that the URL l.spendhq.com was down and we tried to load the URL but it was not accessible at that time. Later when the Tomcat service got started, we were able to witness Tomcat default web page while accessing this URL.Basically, we are not aware of the content that this particular URL needs to serve. Hence we contacted Praveen and passed the same information to him. Based on his suggestion, we are informing all these details to the customer.###Assigning to On call CE2###Hello Matthew,While checking we could see that the default web page of apache tomcat. Please find the attached snapshot from the attachment section.###Hello Matthew,We are looking into this and will get back to you with updates.","We have l.spendhq.com down. This is a SEV ONE. Please review.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",CRITICAL,,29-06-2017 03:13,138,0,SpendHQ,"Hello Matthew,We haven't heard back from you regarding this case. At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Regards,Sumod.K.Bose","Next Action: Evening shift: Check whether we are getting any response from the customer, else send a reminder.","Hello Matthew,We haven't heard back from you regarding this case. Kindly validate these details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Next Action: Check whether we are getting any response from the customer, else send a reminder on Evening shift.","Hello Matthew,We haven't heard back from you.Please validate our findings and let us know if you have any queries.","Next Action: Check whether we are getting any response from customer, else send a reminder on afternoon shift.","Hi Matthew/ Steven,On further analysis, we could see that the server went into unresponsive mode 30 minutes before the restart happen. Memory leak caused by java process fills the heap space, which resulted in Java OutOfMemoryError.The issue got resolved after Matthew restarted the application.From logs, we could see that the web application [InfoGo] appears to have started a thread named [Thread-10] but has failed to stop it. This is very likely to create a memory leak.Please find the below logs.Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread http-nio-8080-ClientPoller-1Exception in thread https-jsse-nio-443-exec-1         at java.util.Collections$UnmodifiableCollection.iterator(Unknown Source)Exception in thread http-nio-80-Acceptor-0 Exception in thread https-jsse-nio-443-exec-3 Exception in thread https-jsse-nio-443-ClientPoller-0 Exception in thread http-nio-80-ClientPoller-1 Exception in thread https-jsse-nio-443-exec-9   at org.apache.tomcat.util.net.NioEndpoint$Poller.timeout(NioEndpoint.java:1005)        at org.apache.tomcat.util.net.NioEndpoint$Poller.run(NioEndpoint.java:825)        at java.lang.Thread.run(Unknown Source)java.lang.OutOfMemoryError: Java heap spacejava.lang.OutOfMemoryError: Java heap spacejava.lang.OutOfMemoryError: Java heap spacejava.lang.OutOfMemoryError: Java heap spacejava.lang.OutOfMemoryError: Java heap spacejava.lang.OutOfMemoryError: Java heap space28-Jun-2017 21:56:05.008 WARNING [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase.clearReferencesThreads The web application [InfoGo] appears to have started a thread named [Thread-10] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread: java.lang.Object.wait(Native Method) vmw.common.SynchUtils.wait(SynchUtils.java:19) system.Threading.ThreadPool$WorkerThread.run(ThreadPool.jvm.cs:259) It seems to be related with application side, please check with your application team to figure out this issue. Let us know if you need any further details.Since you haven't previously asked to monitor this  l.spendhq.com. URL specifically we didn't enable that. Now the URL is under monitoring.Also please find the list of resources that are currently under monitoring from attachment section.",Matthew WattsWhy was this not being monitored? This is a PRD box that is managed by REAN. Can you please provide me with a list of all boxes and URL’s that are monitored.,"Hello Team,We will check more on this and will get back to you with details.Also, we have enabled monitoring for the URL l.spendhq.com in our URL monitoring tool so that we will be notified when it goes down.","Steven Updated that.That restart issued by mwatts was the answer to correcting the issue. We need to know why the process wasn't behaving properly, which resulted in a 504 response frim l.spendhq.com even though it appeared to be running prior to being restarted by mwatts.","Sanket updated to enable url monitoring in wormly. And apart from that, we are good. Next action: we need to work on this.","Next action: Evening shift. Please discuss this issue on call and check if any further analysis is pending on this part. Also, need to check whether this URL needs to be get monitored through Wormly. Summary: /* As per the initial analysis, we were able to figure out that Tomcat service has been stopped and started during the time of this incident. Initially, when Matthew informed that the URL l.spendhq.com was down and we tried to load the URL but it was not accessible at that time. Later when the Tomcat service got started, we were able to witness Tomcat default web page while accessing this URL. Basically, we are not aware of the content that this particular URL needs to serve. Hence we contacted Praveen and passed the same information to him. Based on his suggestion, we are informing all these details to the customer. We have analysed the system logs and was not able to find any error related at the time of this incident.*/","Next action: Morning shift team: Need to discuss this issue with Sanket and check if any further analysis is pending on this part. Also, need to check whether this URL needs to be get monitored through Wormly.","Hello SpendHQ-Team,Initially, when this incident was reported, we were not able to access the URL l.spendhq.com. Later after a short period of time, the URL was serving with the default web page of Tomcat service. After performing more analysis on the instance level, we were able to witness that the Tomcat service was in the stopped state and later the service was restarted. Kindly refer the below logs for more details.Logs :- Stopping Service Catalina 28-Jun-2017 21:56:04.938 INFO [main] org.apache.catalina.core.StandardService.stopInternal Stopping service Catalina28-Jun-2017 21:56:05.008 WARNING [localhost-startStop-2] org.apache.catalina.loader.WebappClassLoaderBase.clearReferencesThreads The web application [InfoGo] appears to have started a thread named [Thread-10] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:28-Jun-2017 21:56:05.028 INFO [main] org.apache.coyote.AbstractProtocol.stop Stopping ProtocolHandler [http-nio-8080]28-Jun-2017 21:56:06.130 INFO [main] org.apache.coyote.AbstractProtocol.stop Stopping ProtocolHandler [http-nio-80]28-Jun-2017 21:56:08.234 INFO [main] org.apache.coyote.AbstractProtocol.stop Stopping ProtocolHandler [https-jsse-nio-443]28-Jun-2017 21:56:10.339 INFO [main] org.apache.coyote.AbstractProtocol.stop Stopping ProtocolHandler [ajp-nio-8009]Starting Service Catalina 28-Jun-2017 21:56:45.113 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [http-nio-8080]28-Jun-2017 21:56:45.123 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [http-nio-80]28-Jun-2017 21:56:45.126 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [https-jsse-nio-443]28-Jun-2017 21:56:45.130 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [ajp-nio-8009]28-Jun-2017 21:56:45.135 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 32465 msThe tomcat service was stopped at 21:56:04 UTC, later it got started at 21:56:45 UTC. We were able to see that below users have logged in to the instance during the time of this incident.[root@10 centos]# w 22:01:08 up 17 days, 23:24,  5 users,  load average: 0.02, 0.17, 0.09USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHATdfowler  pts/1    10.59.1.192      20:22    1:11m  0.01s  0.00s sshd: dfowler [priv]mwatts   pts/2    10.59.1.192      21:37    4:52   0.02s  0.02s -bashmwatts   pts/3    10.59.1.192      21:39    5:08  60.76s  0.01s -bashaherrera pts/4    10.59.1.192      21:55    2:08   0.00s  0.00s -bashcentos   pts/5    10.59.1.192      21:59    0.00s  0.00s  0.00s sshd: centos [priv]From analysing the bash history details, we were able to see that the tomcat service restart command (sudo /etc/init.d/tomcat restart) has been initiated by the user mwatts.As of now, the URL l.spendhq.com is serving the default tomcat web page. Please let us know whether this is the expected outcome of this URL.  We have analysed the system logs and was not able to find any error related at the time of this incident. Kindly validate all these details and let us know if your team have any further queries regarding this case.",#NAME?,Assigning to On call CE2,"Hello Matthew,While checking we could see that the default web page of apache tomcat. Please find the attached snapshot from the attachment section.","Hello Matthew,We are looking into this and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Etexq,Cloud Engineer Level 1,Closed,1070368,Incident,28-07-2017 18:27,,"Hello SpendHQ-Team,We have contacted AWS Support Team regarding this instance status check failure alert. AWS Support team updated that everything was fine from their end at the time of this alert.We have also analyzed the instance level logs such as /var/log/messages, boot.log and dmesg logs but was not able to figure out any errors during the timeframe of this issue. Also from AWS instance level metrics, everything is fine at that point.Hence, as of now we are marking this case as resolved. Will investigate more if this issue happens again. Kindly validate these details from your end and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###++++ For Internal Only +++++++Jul 28 00:04:18 ip-10-59-100-94 iscsid: Kernel reported iSCSI connection 10:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)Jul 28 00:04:20 ip-10-59-100-94 dd.dogstatsd[9025]: ERROR (dogstatsd.py:325): Unable to post payload.#012Traceback (most recent call last):#012  File /opt/datadog-agent/agent/dogstatsd.py, line 315, in submit_http#012    r = requests.post(url, data=data, timeout=5, headers=headers)#012  File /opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/api.py, line 110, in post#012    return request('post', url, data=data, json=json, **kwargs)#012  File /opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/api.py, line 56, in request#012    return session.request(method=method, url=url, **kwargs)#012  File /opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/sessions.py, line 475, in request#012    resp = self.send(prep, **send_kwargs)#012  File /opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/sessions.py, line 596, in send#012    r = adapter.send(request, **kwargs)#012  File /opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/adapters.py, line 499, in send#012    raise ReadTimeout(e, request=request)#012ReadTimeout: HTTPConnectionPool(host='localhost', port=17123): Read timed out. (read timeout=5)###I have checked the instance level metrics 1)CPU load , CPU usage all were normal 2)Checked uptime which was 24 days3)Service was not restarted4) Checked messages logs and no errors were found5) No users were logged in around that period6)Checked cloudtrail logs there is no event logged7)Checked sar output and was not able to find any loadRaising support with AWS also escalating to oncall CE2###Hello Team,This is to notify you that we have received an alert for Status Check failed on prod-sphq-web-server03_4th_july_2017  (10.59.100.79).The instance status check got failed.The alert got resolved automatically within 3 minutes.We are analysing more on this issue and will get back to you with the updates.","[Triggered] [SpendHQ] - Status Check failed Any on prod-sphq-web-server03_4th_july_2017 - 10.59.100.79 - web  Stop and start the instance and raise a support ticket if System status check is failing. Get approval from client and reboot the system if Instance status check is failing   @support@reancloud.comaws.ec2.status_check_failed over host:i-0590f342fdc9965bb,monitoring:on was > 0.0 on average during the last 5m.Metric value: 0.4This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2044546?group=host%3Ai-0590f342fdc9965bb · Edit Monitor: https://app.datadoghq.com/monitors#2044546/edit · Event URL: https://app.datadoghq.com/event/event?id=3975148955336486665 · View i-0590f342fdc9965bb: https://app.datadoghq.com/infrastructure?hostname=i-0590f342fdc9965bb-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - Status Check failed Any on prod-sphq-web-server03_4th_july_2017 - 10.59.100.79 - web,,28-07-2017 05:33,10,0,SpendHQ,"Hello SpendHQ-Team,We have contacted AWS Support Team regarding this instance status check failure alert. AWS Support team updated that everything was fine from their end at the time of this alert.We have also analyzed the instance level logs such as /var/log/messages, boot.log and dmesg logs but was not able to figure out any errors during the timeframe of this issue. Also from AWS instance level metrics, everything is fine at that point.Hence, as of now we are marking this case as resolved. Will investigate more if this issue happens again. Kindly validate these details from your end and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","++++ For Internal Only +++++++Jul 28 00:04:18 ip-10-59-100-94 iscsid: Kernel reported iSCSI connection 10:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)Jul 28 00:04:20 ip-10-59-100-94 dd.dogstatsd[9025]: ERROR (dogstatsd.py:325): Unable to post payload.#012Traceback (most recent call last):#012  File /opt/datadog-agent/agent/dogstatsd.py, line 315, in submit_http#012    r = requests.post(url, data=data, timeout=5, headers=headers)#012  File /opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/api.py, line 110, in post#012    return request('post', url, data=data, json=json, **kwargs)#012  File /opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/api.py, line 56, in request#012    return session.request(method=method, url=url, **kwargs)#012  File /opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/sessions.py, line 475, in request#012    resp = self.send(prep, **send_kwargs)#012  File /opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/sessions.py, line 596, in send#012    r = adapter.send(request, **kwargs)#012  File /opt/datadog-agent/embedded/lib/python2.7/site-packages/requests/adapters.py, line 499, in send#012    raise ReadTimeout(e, request=request)#012ReadTimeout: HTTPConnectionPool(host='localhost', port=17123): Read timed out. (read timeout=5)","I have checked the instance level metrics 1)CPU load , CPU usage all were normal 2)Checked uptime which was 24 days3)Service was not restarted4) Checked messages logs and no errors were found5) No users were logged in around that period6)Checked cloudtrail logs there is no event logged7)Checked sar output and was not able to find any loadRaising support with AWS also escalating to oncall CE2","Hello Team,This is to notify you that we have received an alert for Status Check failed on prod-sphq-web-server03_4th_july_2017  (10.59.100.79).The instance status check got failed.The alert got resolved automatically within 3 minutes.We are analysing more on this issue and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Vrlyi,Cloud Engineer Level 1,Closed,1098323,Incident,09-05-2018 00:26,,"Yogesh Maloo12:23 AM (2 minutes ago)to REAN, Matthew, Technology This one is resolved. Regards,Yogesh MalooSenior Cloud Engineer, REĀN Cloud","Rean,The database volume contains ns no data. Please investigate immediately;drwxr-xr-x 2 root root 6 Jul 27  2017 db_backup_07_20_2017drwxr-xr-x 2 root root 6 Aug 19  2017 production_19082017[mwatts@ip-10-59-10-190 ~]$ cd /mnt/production_19082017/[mwatts@ip-10-59-10-190 production_19082017]$ lltotal 0--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SEV ONE,,09-05-2018 00:13,0,0,SpendHQ,"Yogesh Maloo12:23 AM (2 minutes ago)to REAN, Matthew, Technology This one is resolved. Regards,Yogesh MalooSenior Cloud Engineer, REĀN Cloud",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gcEuR,Cloud Engineer Level 1,Closed,1109570,Incident,20-12-2018 22:10,,"Hello Matthew, We hope that you are doing fine. We still haven't heard back from you regarding this case. On 17/12/2018 we received a request from you to look into and resolve this issue regarding a read only file system. REAN team duly worked on and resolved the issue, then later prepared and shared the RCA with you and can still be found from the attachments section.We would also like to let you know that we have opened a Jira ticket to look into this further.Therefore, at this point, since the issue was resolved, we will be closing this case. However, if you have any questions and/or concerns, please let us know. We appreciate your patience while we worked to resolve the issue.Thanks.###Hello Team, We didn't hear back from you.Please review the RCA available in attachment section and let us know if you have any queries related to it.###Hello Team,This is quick follow up.Please review the RCA and let us know if you have any queries related to it.###Hello Team,We have completed the RCA and please find the RCA document in the attachment section.Kindly review the RCA and let us know if you have any queries.###Created Jira ticket for Rohit MSI-16848 and updated the preventive actions in the RCA.Had a discussion with Rohit and sharing the RCA with the customer.###Reviewed and put the comments in the RCA.###Hello Team,We are actively working on the RCA and will share with you shortly.###Praveen will review the RCA today###Chirodeep Roy [1:24 AM]@anu.pappachan SpendHQ RCA was discussed in Ops call and this is not the update I had. Anyway @rohit.puri Please look into the preventive action piece, we can mention that instead of weekly script running to identify this issue, we can run it daily or more frequently which can notify us well in advance.Rohit Puri [1:27 AM]@chirodeep.roy  script is running every hour. We got the notification at 9:31pm IST and customer raised the issue at 9:34pm istChirodeep Roy [1:40 AM]@rohit.puri alright then do we have any preventive action from our end or from customer end?Praveen Kumar Muppala [1:41 AM]I will review this tonight###Chirodeep Roy [1:24 AM]@anu.pappachan SpendHQ RCA was discussed in Ops call and this is not the update I had. Anyway @rohit.puri Please look into the preventive action piece, we can mention that instead of weekly script running to identify this issue, we can run it daily or more frequently which can notify us well in advance.###@praveen.muppala Please review the RCA for the SpendHQ SEV ONE issue https://reancloud.cloudforce.com/5002I00001gcEuR###@Praveen:Please review once the RCA so that we share with the customer:https://docs.google.com/document/d/1Ynl2wo86W17jtdfzY5O1ZoMB0Zhljze00IvoO0xcQEM/edit#For Preventive Action:We do not have such any action from our end as the issue was not our end. We verified the logs. We have taken the preventive action in past as to get the notification whenever RO mode issue happen and we do got the update. Please let us know if we are good to share the RCA. Thanks###Hello Rohit,I have reviewed the message buffer of the kernel (looking for sda).[root@ip-10-59-100-125 centos]# dmesg | grep sdasd 13:0:0:0: [sda] 4294967296 512-byte logical blocks: (2.19 TB/2.00 TiB)sd 13:0:0:0: [sda] Write Protect is offsd 13:0:0:0: [sda] Mode Sense: 9b 00 00 08sd 13:0:0:0: [sda] Write cache: disabled, read cache: enabled, doesn't support DPO or FUA sda: unknown partition tablesd 13:0:0:0: [sda] Attached SCSI diskEXT4-fs (sda): warning: mounting fs with errors, running e2fsck is recommendedEXT4-fs (sda): recovery completeEXT4-fs (sda): mounted filesystem with ordered data mode. Opts:I also checked the messages and noticed that there were I/O errors on device sda at around 14:36 UTC (before the issue occured).[root@ip-10-59-100-125 centos]# cat /var/log/messages | grep `date --date=yesterday +%b\\ %e` | grep sda | head -100Dec 17 14:36:08 ip-10-59-100-125 kernel: Buffer I/O error on device sda, logical block 215032111Dec 17 14:36:08 ip-10-59-100-125 kernel: lost page write due to I/O error on sdaDec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda]  Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OKDec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda] CDB: Write(10): 2a 00 34 81 a2 80 00 00 08 00Dec 17 14:36:08 ip-10-59-100-125 kernel: end_request: I/O error, dev sda, sector 880910976Dec 17 14:36:08 ip-10-59-100-125 kernel: Buffer I/O error on device sda, logical block 110113872Dec 17 14:36:08 ip-10-59-100-125 kernel: lost page write due to I/O error on sdaDec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda]  Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OKDec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda] CDB: Write(10): 2a 00 66 88 84 60 00 00 08 00Dec 17 14:36:08 ip-10-59-100-125 kernel: end_request: I/O error, dev sda, sector 1720222816Dec 17 14:36:08 ip-10-59-100-125 kernel: Buffer I/O error on device sda, logical block 215027852Dec 17 14:36:08 ip-10-59-100-125 kernel: lost page write due to I/O error on sdaDec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda]  Dec 17 14:36:08 ip-10-59-100-125 kernel: JBD2: Detected IO errors while flushing file data on sda-8Dec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda] CDB: Write(10): 2a 00 80 07 d1 18 00 00 08 00Dec 17 14:36:08 ip-10-59-100-125 kernel: end_request: I/O error, dev sda, sector 2147995928Dec 17 14:36:08 ip-10-59-100-125 kernel: Aborting journal on device sda-8.Dec 17 14:36:08 ip-10-59-100-125 kernel: JBD2: I/O error detected when updating journal superblock for sda-8.Dec 17 14:36:08 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_journal_start_sb: Detected aborted journalDec 17 14:36:08 ip-10-59-100-125 kernel: EXT4-fs (sda): Remounting filesystem read-onlyPlease check###Hello Team,We are analyzing the root cause of this issue. We will update you ASAP.###@Team,Please check syslogs of nfs server for the time we received NFS readonly mode alert###steps performed:1. We have received the notification from Spendhq team that they facing RO issue on 10-59-100-122 server for the files.spendhq.com file system.2. As there are lots process running which are using /var/www/vhosts/files.spendhq.com path we are unable to mount and remount the volume. 3. We went on a call with the customer and killed the process and mount the volume again. 4. But the volume again back to RO mode. We have faced the login issue on the server due to high CPU utilization, so performed a reboot on the server.5. After reboot, the mount got unmount and we have again bind mount volume and restart all NFS services.6. Verify the Client NFS mount and confirmed everything back normal.Please check the log from the NFS server and check we have an issue based on Rohit review reached out to A3 team if required.###Prepared the RCA: https://docs.google.com/document/d/1Ynl2wo86W17jtdfzY5O1ZoMB0Zhljze00IvoO0xcQEM/edit#The issue started around  9:31 PM IST (4:01 pm UTC )and we have checked the Network IN and OUT on the server around, could see spike around 14:10 PM UTC.  Other than I haven't found anything.###Hello Team,I have reviewed the messages logs from nfs server 10.59.100.125I could see the below logs as part of troubleshooting timeDec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:36 ip-10-59-100-125 iscsid: Connection14:0 to [target: iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is shutdown.Dec 17 17:14:36 ip-10-59-100-125 iscsid: conn 0 login rejected: initiator error (02/04)Dec 17 17:14:36 ip-10-59-100-125 kernel: EXT4-fs error (device sda): __ext4_get_inode_loc: unable to read inode block - inode=91488320, block=365953059Dec 17 17:14:36 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:36 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:36 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0---------------------------------------------------------------We have recived the ISCSI Device Details which are in RO mode alert at Mon, Dec 17, 8:31 PM  IST and we have checked the logs during these time and couldn't  see find any error###Email sent to MGS Leads----Subject: Critical - P1 | Case # 01109570 | SEV ONE read only file systemHi Leads,We have encountered a P1 issue. Below are the details of the issueCustomer Name: SpendHQOpen date/time: 17th December 2018 / 21:34 ISTIssue Summary/Details: We received a P1 case from SpendHQ team, we went on call with the team for troubleshooting and fixing the issue. Volume mounted on the folder /var/www/vhosts/files.spendhq.com on the server 10.59.100.125 went into Read Only mode.Owner : Rohit PuriStatus : ResolvedAction/s Taken: Went on call with customer to resolve the issue.Stephen OduorCloud Engineer, Cloud Operations, Global Services###Hi Matthew/Dusty, Thanks for joining the call. For now the folders are accessible and the RO mode issue has been resolved on NFS server and NFS client. Dusty has verified the same on call itself. We will work on the RCA and share with you.###Matthew Watts	7:58 PM (2 minutes ago)	to Rohit, ReanLet’s kill the process and move forward.###Rohit Puri <rohit.puri@hitachivantara.com>	7:58 PM (0 minutes ago)	to Matthew, ReanHi Mattew, The volume went into RO mode mounted on the folder /var/www/vhosts/files.spendhq.com For resolving this, we need to unmount and re-mount the iSCSI volume. But we are not able to as there lots process running which are using /var/www/vhosts/files.spendhq.com path. Please join the call on https://reancloud.zoom.us/my/mgse1 or give an approval to kill the process consuming the volume mounted on /var/www/vhosts/files.spendhq.com###Hello Mathew,We acknowledge your request, we work to resolve the issue as soon as possible","Rean,We have a read only file system that need to be resolved ASAP.[mwatts@ip-10-59-100-122 files.spendhq.com]$ sudo mkdir testyertwmkdir: cannot create directory `testyertw': Read-only file systemMatthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SEV ONE,,17-12-2018 21:34,73,0,SpendHQ,"Hello Matthew, We hope that you are doing fine. We still haven't heard back from you regarding this case. On 17/12/2018 we received a request from you to look into and resolve this issue regarding a read only file system. REAN team duly worked on and resolved the issue, then later prepared and shared the RCA with you and can still be found from the attachments section.We would also like to let you know that we have opened a Jira ticket to look into this further.Therefore, at this point, since the issue was resolved, we will be closing this case. However, if you have any questions and/or concerns, please let us know. We appreciate your patience while we worked to resolve the issue.Thanks.","Hello Team, We didn't hear back from you.Please review the RCA available in attachment section and let us know if you have any queries related to it.","Hello Team,This is quick follow up.Please review the RCA and let us know if you have any queries related to it.","Hello Team,We have completed the RCA and please find the RCA document in the attachment section.Kindly review the RCA and let us know if you have any queries.",Created Jira ticket for Rohit MSI-16848 and updated the preventive actions in the RCA.Had a discussion with Rohit and sharing the RCA with the customer.,Reviewed and put the comments in the RCA.,"Hello Team,We are actively working on the RCA and will share with you shortly.",Praveen will review the RCA today,"Chirodeep Roy [1:24 AM]@anu.pappachan SpendHQ RCA was discussed in Ops call and this is not the update I had. Anyway @rohit.puri Please look into the preventive action piece, we can mention that instead of weekly script running to identify this issue, we can run it daily or more frequently which can notify us well in advance.Rohit Puri [1:27 AM]@chirodeep.roy  script is running every hour. We got the notification at 9:31pm IST and customer raised the issue at 9:34pm istChirodeep Roy [1:40 AM]@rohit.puri alright then do we have any preventive action from our end or from customer end?Praveen Kumar Muppala [1:41 AM]I will review this tonight","Chirodeep Roy [1:24 AM]@anu.pappachan SpendHQ RCA was discussed in Ops call and this is not the update I had. Anyway @rohit.puri Please look into the preventive action piece, we can mention that instead of weekly script running to identify this issue, we can run it daily or more frequently which can notify us well in advance.",@praveen.muppala Please review the RCA for the SpendHQ SEV ONE issue https://reancloud.cloudforce.com/5002I00001gcEuR,@Praveen:Please review once the RCA so that we share with the customer:https://docs.google.com/document/d/1Ynl2wo86W17jtdfzY5O1ZoMB0Zhljze00IvoO0xcQEM/edit#For Preventive Action:We do not have such any action from our end as the issue was not our end. We verified the logs. We have taken the preventive action in past as to get the notification whenever RO mode issue happen and we do got the update. Please let us know if we are good to share the RCA. Thanks,"Hello Rohit,I have reviewed the message buffer of the kernel (looking for sda).[root@ip-10-59-100-125 centos]# dmesg | grep sdasd 13:0:0:0: [sda] 4294967296 512-byte logical blocks: (2.19 TB/2.00 TiB)sd 13:0:0:0: [sda] Write Protect is offsd 13:0:0:0: [sda] Mode Sense: 9b 00 00 08sd 13:0:0:0: [sda] Write cache: disabled, read cache: enabled, doesn't support DPO or FUA sda: unknown partition tablesd 13:0:0:0: [sda] Attached SCSI diskEXT4-fs (sda): warning: mounting fs with errors, running e2fsck is recommendedEXT4-fs (sda): recovery completeEXT4-fs (sda): mounted filesystem with ordered data mode. Opts:I also checked the messages and noticed that there were I/O errors on device sda at around 14:36 UTC (before the issue occured).[root@ip-10-59-100-125 centos]# cat /var/log/messages | grep `date --date=yesterday +%b\\ %e` | grep sda | head -100Dec 17 14:36:08 ip-10-59-100-125 kernel: Buffer I/O error on device sda, logical block 215032111Dec 17 14:36:08 ip-10-59-100-125 kernel: lost page write due to I/O error on sdaDec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda]  Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OKDec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda] CDB: Write(10): 2a 00 34 81 a2 80 00 00 08 00Dec 17 14:36:08 ip-10-59-100-125 kernel: end_request: I/O error, dev sda, sector 880910976Dec 17 14:36:08 ip-10-59-100-125 kernel: Buffer I/O error on device sda, logical block 110113872Dec 17 14:36:08 ip-10-59-100-125 kernel: lost page write due to I/O error on sdaDec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda]  Result: hostbyte=DID_NO_CONNECT driverbyte=DRIVER_OKDec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda] CDB: Write(10): 2a 00 66 88 84 60 00 00 08 00Dec 17 14:36:08 ip-10-59-100-125 kernel: end_request: I/O error, dev sda, sector 1720222816Dec 17 14:36:08 ip-10-59-100-125 kernel: Buffer I/O error on device sda, logical block 215027852Dec 17 14:36:08 ip-10-59-100-125 kernel: lost page write due to I/O error on sdaDec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda]  Dec 17 14:36:08 ip-10-59-100-125 kernel: JBD2: Detected IO errors while flushing file data on sda-8Dec 17 14:36:08 ip-10-59-100-125 kernel: sd 15:0:0:0: [sda] CDB: Write(10): 2a 00 80 07 d1 18 00 00 08 00Dec 17 14:36:08 ip-10-59-100-125 kernel: end_request: I/O error, dev sda, sector 2147995928Dec 17 14:36:08 ip-10-59-100-125 kernel: Aborting journal on device sda-8.Dec 17 14:36:08 ip-10-59-100-125 kernel: JBD2: I/O error detected when updating journal superblock for sda-8.Dec 17 14:36:08 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_journal_start_sb: Detected aborted journalDec 17 14:36:08 ip-10-59-100-125 kernel: EXT4-fs (sda): Remounting filesystem read-onlyPlease check","Hello Team,We are analyzing the root cause of this issue. We will update you ASAP.","@Team,Please check syslogs of nfs server for the time we received NFS readonly mode alert","steps performed:1. We have received the notification from Spendhq team that they facing RO issue on 10-59-100-122 server for the files.spendhq.com file system.2. As there are lots process running which are using /var/www/vhosts/files.spendhq.com path we are unable to mount and remount the volume. 3. We went on a call with the customer and killed the process and mount the volume again. 4. But the volume again back to RO mode. We have faced the login issue on the server due to high CPU utilization, so performed a reboot on the server.5. After reboot, the mount got unmount and we have again bind mount volume and restart all NFS services.6. Verify the Client NFS mount and confirmed everything back normal.Please check the log from the NFS server and check we have an issue based on Rohit review reached out to A3 team if required.","Prepared the RCA: https://docs.google.com/document/d/1Ynl2wo86W17jtdfzY5O1ZoMB0Zhljze00IvoO0xcQEM/edit#The issue started around  9:31 PM IST (4:01 pm UTC )and we have checked the Network IN and OUT on the server around, could see spike around 14:10 PM UTC.  Other than I haven't found anything.","Hello Team,I have reviewed the messages logs from nfs server 10.59.100.125I could see the below logs as part of troubleshooting timeDec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:35 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:36 ip-10-59-100-125 iscsid: Connection14:0 to [target: iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31, portal: 172.23.104.77,3260] through [iface: iSCSI1] is shutdown.Dec 17 17:14:36 ip-10-59-100-125 iscsid: conn 0 login rejected: initiator error (02/04)Dec 17 17:14:36 ip-10-59-100-125 kernel: EXT4-fs error (device sda): __ext4_get_inode_loc: unable to read inode block - inode=91488320, block=365953059Dec 17 17:14:36 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:36 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0Dec 17 17:14:36 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_find_entry: reading directory #41287688 offset 0---------------------------------------------------------------We have recived the ISCSI Device Details which are in RO mode alert at Mon, Dec 17, 8:31 PM  IST and we have checked the logs during these time and couldn't  see find any error","Email sent to MGS Leads----Subject: Critical - P1 | Case # 01109570 | SEV ONE read only file systemHi Leads,We have encountered a P1 issue. Below are the details of the issueCustomer Name: SpendHQOpen date/time: 17th December 2018 / 21:34 ISTIssue Summary/Details: We received a P1 case from SpendHQ team, we went on call with the team for troubleshooting and fixing the issue. Volume mounted on the folder /var/www/vhosts/files.spendhq.com on the server 10.59.100.125 went into Read Only mode.Owner : Rohit PuriStatus : ResolvedAction/s Taken: Went on call with customer to resolve the issue.Stephen OduorCloud Engineer, Cloud Operations, Global Services","Hi Matthew/Dusty, Thanks for joining the call. For now the folders are accessible and the RO mode issue has been resolved on NFS server and NFS client. Dusty has verified the same on call itself. We will work on the RCA and share with you.","Matthew Watts	7:58 PM (2 minutes ago)	to Rohit, ReanLet’s kill the process and move forward.","Rohit Puri <rohit.puri@hitachivantara.com>	7:58 PM (0 minutes ago)	to Matthew, ReanHi Mattew, The volume went into RO mode mounted on the folder /var/www/vhosts/files.spendhq.com For resolving this, we need to unmount and re-mount the iSCSI volume. But we are not able to as there lots process running which are using /var/www/vhosts/files.spendhq.com path. Please join the call on https://reancloud.zoom.us/my/mgse1 or give an approval to kill the process consuming the volume mounted on /var/www/vhosts/files.spendhq.com","Hello Mathew,We acknowledge your request, we work to resolve the issue as soon as possible",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001aNGpL,Cloud Engineer Level 1,Closed,1102717,Incident,14-08-2018 04:21,,"Hello Team,This is to inform you that the alert regarding High CPU load on  spendhq-memsql-server1-2018-04-01, spendhq-memsql-server2-2018-04-01 and spendhq-memsql-server3-2018-04-01 got recovered and back to its normal state with the value of 1.02, 3.2 and 2.86 respectively.###For Instance Id:  i-093eff6fae479397c################## CPU Utilization details ################## top - 22:02:48 up 134 days,  1:02,  0 users,  load average: 0.91, 2.61, 6.03Tasks: 311 total,   1 running, 310 sleeping,   0 stopped,   0 zombie%Cpu(s):  1.7 us,  0.4 sy,  0.0 ni, 97.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total,  7869488 free, 23396680+used,  9738740 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  8592100 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND14050 memsql    20   0  0.124t 0.108t  13816 S  50.0 45.9  14910:48 memsqld96752 memsql    20   0 12.289g 332456   2608 S  12.5  0.1  21565:50 memsql-ops44738 root      20   0  419416   8092   5636 S   6.2  0.0   0:00.01 ssm-docum+    1 root      20   0  195564   8568   3804 S   0.0  0.0   6:05.45 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:01.47 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:15.98 ksoftirqd+    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.30 migration+    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0  56:25.38 rcu_sched   10 root      rt   0       0      0      0 S   0.0  0.0   0:55.94 watchdog/0   11 root      rt   0       0      0      0 S   0.0  0.0   0:50.03 watchdog/1   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.14 migration+   13 root      20   0       0      0      0 S   0.0  0.0   0:04.83 ksoftirqd+   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1+   16 root      rt   0       0      0      0 S   0.0  0.0   0:49.35 watchdog/2   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.32 migration+   18 root      20   0       0      0      0 S   0.0  0.0   0:02.17 ksoftirqd+   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2+   21 root      rt   0       0      0      0 S   0.0  0.0   0:50.34 watchdog/3   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.06 migration+   23 root      20   0       0      0      0 S   0.0  0.0   0:01.42 ksoftirqd+   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/3+   26 root      rt   0       0      0      0 S   0.0  0.0   0:49.14 watchdog/4   27 root      rt   0       0      0      0 S   0.0  0.0   0:00.29 migration+   28 root      20   0       0############### Connection Details: ############### 1) netstat | wc -l 1000 2) netstat | grep TIME_WAIT | wc -l 0 3) netstat | grep ESTABLISHED | wc -l 869###For Instance Id:  i-0382b753fdc5a21bd ################## CPU Utilization details ################## top - 22:02:48 up 133 days, 22:37,  0 users,  load average: 0.14, 1.12, 5.13Tasks: 311 total,   1 running, 310 sleeping,   0 stopped,   0 zombie%Cpu(s):  0.2 us,  0.2 sy,  0.0 ni, 99.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total,  5647852 free, 23685889+used,  9068284 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  5682792 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND14443 memsql    20   0  0.125t 0.109t  13512 S   6.2 46.4  14625:09 memsqld    1 root      20   0  195696   8060   3292 S   0.0  0.0   8:36.23 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:01.49 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:13.75 ksoftirqd+    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.36 migration+    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0  58:35.93 rcu_sched   10 root      rt   0       0      0      0 S   0.0  0.0   0:56.86 watchdog/0   11 root      rt   0       0      0      0 S   0.0  0.0   0:50.76 watchdog/1   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.41 migration+   13 root      20   0       0      0      0 S   0.0  0.0   0:03.65 ksoftirqd+   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1+   16 root      rt   0       0      0      0 S   0.0  0.0   0:50.35 watchdog/2   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.35 migration+   18 root      20   0       0      0      0 S   0.0  0.0   0:02.81 ksoftirqd+   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2+   21 root      rt   0       0      0      0 S   0.0  0.0   0:51.28 watchdog/3   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.18 migration+   23 root      20   0       0      0      0 S   0.0  0.0   0:01.56 ksoftirqd+   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/3+   26 root      rt   0       0      0      0 S   0.0  0.0   0:49.84 watchdog/4   27 root      rt   0       0      0      0 S   0.0  0.0   0:00.30 migration+   28 root      20   0       0      0      0 S   0.0  0.0   0:02.43 ksoftirqd+   29 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kworker/4+   30 root       0 -20       0 ############### Connection Details: ############### 1) netstat | wc -l 10002) netstat | grep TIME_WAIT | wc -l 0 3) netstat | grep ESTABLISHED | wc -l 869###Hello Team,We analyzed the issue and below are the details:For Instance Id: i-073579ff33c73d3cd:##################CPU Utilization details##################top - 21:59:45 up 97 days,  5:54,  0 users,  load average: 0.19, 1.15, 2.07Tasks: 364 total,   1 running, 363 sleeping,   0 stopped,   0 zombie%Cpu(s):  0.2 us,  0.0 sy,  0.0 ni, 99.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total, 82011424 free, 12151025+used, 48053352 buff/cacheKiB Swap:        0 total,        0 free,        0 used. 11973328+avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND63778 memsql    20   0  0.125t 0.109t  40232 S   6.7 46.6  14078:52 memsqld64267 memsql    20   0 7366764 601288  35776 S   6.7  0.2   1277:00 memsqld    1 root      20   0  195696   8860   4080 S   0.0  0.0   5:53.98 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:02.02 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:25.13 ksoftirqd+    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.79 migration+    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0  72:35.56 rcu_sched   10 root      rt   0       0      0      0 S   0.0  0.0   0:41.50 watchdog/0   11 root      rt   0       0      0      0 S   0.0  0.0   0:37.48 watchdog/1   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.07 migration+   13 root      20   0       0      0      0 S   0.0  0.0   0:11.81 ksoftirqd+   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1+   16 root      rt   0       0      0      0 S   0.0  0.0   0:36.83 watchdog/2   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.19 migration+   18 root      20   0       0      0      0 S   0.0  0.0   0:04.32 ksoftirqd+   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2+   21 root      rt   0       0      0      0 S   0.0  0.0   0:36.94 watchdog/3   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.20 migration+   23 root      20   0       0      0      0 S   0.0  0.0   0:01.94 ksoftirqd+   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/3+   26 root      rt   0       0      0      0 S   0.0  0.0   0:36.80 watchdog/4   27 root      rt   0       0      0      0 S   0.0  0.0   0:00.21 migration+   28 root      20   0       0      0      0 S   0.0  0.0   0:01.58 ksoftirqd+###############Connection Details:###############1) netstat | wc -l     11692) netstat | grep TIME_WAIT | wc -l     03) netstat | grep ESTABLISHED | wc -l   1030###Hello Team, We have received an alert regarding High CPU Load on hostspendhq-memsql-server1-2018-04-01 - 10.59.100.191 which has crossed the threshold and reached to the value of 4.65. We are analyzing the issue and will back to you with the update. Resource Details: Instance Id: i-073579ff33c73d3cdIP: 10-59-100-191 Name: spendhq-memsql-server1-2018-04-01Region: us-east-1 Meanwhile please let us know if you are performing any activity at your end.###Hello Team,We have received an alert regarding High CPU Load on  host spendhq-memsql-server3-2018-04-01 - 10.59.100.230 and spendhq-memsql-server2-2018-04-01 - 10.59.100.171 which has crossed the threshold and reached to the value of 10 and 9.63 respectivley. We are analyzing the issue and will back to you with the update.Resource Details:Instance Id: i-093eff6fae479397cIP: 10-59-100-230Name: spendhq-memsql-server3-2018-04-01Region: us-east-1Instance Id: i-0382b753fdc5a21bdIP: 10-59-100-171Name: spendhq-memsql-server2-2018-04-01Region: us-east-1","[image: Datadog][Triggered] [SpendHQ] - High CPU Load on host spendhq-memsql-server3-2018-04-01- 10.59.100.230 -Detected High CPU load. Log in to the machine and verify which process isconsuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023975?to_ts=1534195005000&group=host%3Ai-093eff6fae479397c&from_ts=1534187805000>*system.load.15* over *datadog_monitor:on,host:i-093eff6fae479397c* was *>4.0* on average during the *last 1h*.The monitor was last triggered at Mon Aug 13 2018 21:16:55 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023975?group=host%3Ai-093eff6fae479397c>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023975/edit>] · [Viewi-093eff6fae479397c<https://app.datadoghq.com/infrastructure?filter=i-093eff6fae479397c>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1534195135000&tags=host%3Ai-093eff6fae479397c&from_ts=1534194115000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4528709992841959783>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Load on host spendhq-memsql-server3-2018-04-01 - 10.59.100.230 -,,14-08-2018 02:49,30,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding High CPU load on  spendhq-memsql-server1-2018-04-01, spendhq-memsql-server2-2018-04-01 and spendhq-memsql-server3-2018-04-01 got recovered and back to its normal state with the value of 1.02, 3.2 and 2.86 respectively.",For Instance Id:  i-093eff6fae479397c,,,,,,CPU Utilization details,,,,,,"top - 22:02:48 up 134 days,  1:02,  0 users,  load average: 0.91, 2.61, 6.03Tasks: 311 total,   1 running, 310 sleeping,   0 stopped,   0 zombie%Cpu(s):  1.7 us,  0.4 sy,  0.0 ni, 97.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total,  7869488 free, 23396680+used,  9738740 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  8592100 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND14050 memsql    20   0  0.124t 0.108t  13816 S  50.0 45.9  14910:48 memsqld96752 memsql    20   0 12.289g 332456   2608 S  12.5  0.1  21565:50 memsql-ops44738 root      20   0  419416   8092   5636 S   6.2  0.0   0:00.01 ssm-docum+    1 root      20   0  195564   8568   3804 S   0.0  0.0   6:05.45 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:01.47 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:15.98 ksoftirqd+    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.30 migration+    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0  56:25.38 rcu_sched   10 root      rt   0       0      0      0 S   0.0  0.0   0:55.94 watchdog/0   11 root      rt   0       0      0      0 S   0.0  0.0   0:50.03 watchdog/1   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.14 migration+   13 root      20   0       0      0      0 S   0.0  0.0   0:04.83 ksoftirqd+   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1+   16 root      rt   0       0      0      0 S   0.0  0.0   0:49.35 watchdog/2   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.32 migration+   18 root      20   0       0      0      0 S   0.0  0.0   0:02.17 ksoftirqd+   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2+   21 root      rt   0       0      0      0 S   0.0  0.0   0:50.34 watchdog/3   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.06 migration+   23 root      20   0       0      0      0 S   0.0  0.0   0:01.42 ksoftirqd+   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/3+   26 root      rt   0       0      0      0 S   0.0  0.0   0:49.14 watchdog/4   27 root      rt   0       0      0      0 S   0.0  0.0   0:00.29 migration+   28 root      20   0       0",,,,,Connection Details:,,,,,1) netstat | wc -l 1000 2) netstat | grep TIME_WAIT | wc -l 0 3) netstat | grep ESTABLISHED | wc -l 869,For Instance Id:  i-0382b753fdc5a21bd,,,,,,CPU Utilization details,,,,,,"top - 22:02:48 up 133 days, 22:37,  0 users,  load average: 0.14, 1.12, 5.13Tasks: 311 total,   1 running, 310 sleeping,   0 stopped,   0 zombie%Cpu(s):  0.2 us,  0.2 sy,  0.0 ni, 99.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total,  5647852 free, 23685889+used,  9068284 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  5682792 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND14443 memsql    20   0  0.125t 0.109t  13512 S   6.2 46.4  14625:09 memsqld    1 root      20   0  195696   8060   3292 S   0.0  0.0   8:36.23 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:01.49 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:13.75 ksoftirqd+    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.36 migration+    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0  58:35.93 rcu_sched   10 root      rt   0       0      0      0 S   0.0  0.0   0:56.86 watchdog/0   11 root      rt   0       0      0      0 S   0.0  0.0   0:50.76 watchdog/1   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.41 migration+   13 root      20   0       0      0      0 S   0.0  0.0   0:03.65 ksoftirqd+   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1+   16 root      rt   0       0      0      0 S   0.0  0.0   0:50.35 watchdog/2   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.35 migration+   18 root      20   0       0      0      0 S   0.0  0.0   0:02.81 ksoftirqd+   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2+   21 root      rt   0       0      0      0 S   0.0  0.0   0:51.28 watchdog/3   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.18 migration+   23 root      20   0       0      0      0 S   0.0  0.0   0:01.56 ksoftirqd+   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/3+   26 root      rt   0       0      0      0 S   0.0  0.0   0:49.84 watchdog/4   27 root      rt   0       0      0      0 S   0.0  0.0   0:00.30 migration+   28 root      20   0       0      0      0 S   0.0  0.0   0:02.43 ksoftirqd+   29 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kworker/4+   30 root       0 -20       0",,,,,Connection Details:,,,,,1) netstat | wc -l 10002) netstat | grep TIME_WAIT | wc -l 0 3) netstat | grep ESTABLISHED | wc -l 869,"Hello Team,We analyzed the issue and below are the details:For Instance Id: i-073579ff33c73d3cd:",,,,,,CPU Utilization details,,,,,,"top - 21:59:45 up 97 days,  5:54,  0 users,  load average: 0.19, 1.15, 2.07Tasks: 364 total,   1 running, 363 sleeping,   0 stopped,   0 zombie%Cpu(s):  0.2 us,  0.0 sy,  0.0 ni, 99.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stKiB Mem : 25157502+total, 82011424 free, 12151025+used, 48053352 buff/cacheKiB Swap:        0 total,        0 free,        0 used. 11973328+avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND63778 memsql    20   0  0.125t 0.109t  40232 S   6.7 46.6  14078:52 memsqld64267 memsql    20   0 7366764 601288  35776 S   6.7  0.2   1277:00 memsqld    1 root      20   0  195696   8860   4080 S   0.0  0.0   5:53.98 systemd    2 root      20   0       0      0      0 S   0.0  0.0   0:02.02 kthreadd    3 root      20   0       0      0      0 S   0.0  0.0   0:25.13 ksoftirqd+    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0+    7 root      rt   0       0      0      0 S   0.0  0.0   0:00.79 migration+    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh    9 root      20   0       0      0      0 S   0.0  0.0  72:35.56 rcu_sched   10 root      rt   0       0      0      0 S   0.0  0.0   0:41.50 watchdog/0   11 root      rt   0       0      0      0 S   0.0  0.0   0:37.48 watchdog/1   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.07 migration+   13 root      20   0       0      0      0 S   0.0  0.0   0:11.81 ksoftirqd+   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1+   16 root      rt   0       0      0      0 S   0.0  0.0   0:36.83 watchdog/2   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.19 migration+   18 root      20   0       0      0      0 S   0.0  0.0   0:04.32 ksoftirqd+   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/2+   21 root      rt   0       0      0      0 S   0.0  0.0   0:36.94 watchdog/3   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.20 migration+   23 root      20   0       0      0      0 S   0.0  0.0   0:01.94 ksoftirqd+   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/3+   26 root      rt   0       0      0      0 S   0.0  0.0   0:36.80 watchdog/4   27 root      rt   0       0      0      0 S   0.0  0.0   0:00.21 migration+   28 root      20   0       0      0      0 S   0.0  0.0   0:01.58 ksoftirqd+",,,,,Connection Details:,,,,,1) netstat | wc -l     11692) netstat | grep TIME_WAIT | wc -l     03) netstat | grep ESTABLISHED | wc -l   1030,"Hello Team, We have received an alert regarding High CPU Load on hostspendhq-memsql-server1-2018-04-01 - 10.59.100.191 which has crossed the threshold and reached to the value of 4.65. We are analyzing the issue and will back to you with the update. Resource Details: Instance Id: i-073579ff33c73d3cdIP: 10-59-100-191 Name: spendhq-memsql-server1-2018-04-01Region: us-east-1 Meanwhile please let us know if you are performing any activity at your end.","Hello Team,We have received an alert regarding High CPU Load on  host spendhq-memsql-server3-2018-04-01 - 10.59.100.230 and spendhq-memsql-server2-2018-04-01 - 10.59.100.171 which has crossed the threshold and reached to the value of 10 and 9.63 respectivley. We are analyzing the issue and will back to you with the update.Resource Details:Instance Id: i-093eff6fae479397cIP: 10-59-100-230Name: spendhq-memsql-server3-2018-04-01Region: us-east-1Instance Id: i-0382b753fdc5a21bdIP: 10-59-100-171Name: spendhq-memsql-server2-2018-04-01Region: us-east-1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bk7Be,Cloud Engineer Level 1,Closed,1104501,Incident,14-09-2018 02:29,,"Hi Dan,Thanks for the update, please reach out to us if you face any further difficulties.At the moment we are marking this case as resolved and closing the case.Thanks.###From Daniel:	Disregard, seems to be working now.###Hello Dan,We are working to resolve this issue and we will keep you informed.Thanks.","Rean,We are unable to connect to the VPN. Please investigate and fix ASAP.Best Regards,Dan Mackay | Spend Solutions DBA | SpendHQO: 770-741-0157 | dmackay@spendhq.com<mailto:dmackay@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SEV ONE - Cannot Connect to the VPN,,14-09-2018 02:21,0,0,SpendHQ,"Hi Dan,Thanks for the update, please reach out to us if you face any further difficulties.At the moment we are marking this case as resolved and closing the case.Thanks.","From Daniel:	Disregard, seems to be working now.","Hello Dan,We are working to resolve this issue and we will keep you informed.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eP6kA,Cloud Engineer Level 1,Closed,1107416,Incident,12-11-2018 03:25,,"Hello Team,The alert regarding high memory utilization alert on the host PRD-WW2_6 has recovered and returned to the normal.We are marking this case as resolved and closing this case. Please let us know if you have any query.###Hello Team, This is to notify you that we received a high memory utilization alert on the host PRD-WW2_6 in us-east-1 region which has crossed the set threshold of 95%. The alert recovered within 13 minutes and currently has a reading of 94.76% with the httpd process showing most activity. ---------------------------------------------------------------------------------------             total       used       free     shared    buffers     cachedMem:           31G        28G       2.7G       872K        21M       400MLow:           31G        28G       2.7GHigh:           0B         0B         0B-/+ buffers/cache:        28G       3.1GSwap:           0B         0B         0B-----------------------------------------------------------------------------------------------------------------USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDapache   23759  0.5  2.3 1142676 770916 ?      S    Nov07  16:12 /usr/sbin/httpdapache   28218  0.6  2.1 1073436 707124 ?      S    Nov07  25:21 /usr/sbin/httpdapache   28743  0.4  2.0 1024232 657960 ?      R    17:53   0:29 /usr/sbin/httpdapache    7727  0.6  1.7 945288 578892 ?       S    Nov08   9:45 /usr/sbin/httpdapache    7717  0.5  1.7 944132 572240 ?       S    Nov08   8:36 /usr/sbin/httpdapache   25335  0.4  1.7 939932 568032 ?       S    Nov08   6:40 /usr/sbin/httpdapache   18820  0.5  1.7 938688 567576 ?       S    Nov08   9:06 /usr/sbin/httpdapache    4427  1.0  1.7 932408 560580 ?       S    14:38   3:12 /usr/sbin/httpdapache   26941  1.5  1.6 921728 550748 ?       S    17:39   1:43 /usr/sbin/httpdapache   25195  0.6  1.6 920156 548800 ?       S    Nov08  15:23 /usr/sbin/httpd-----------------------------------------------------------------------------------------------------------------As this is recovered, we are marking this case as resolved and closing it as well. Feel free to get in touch with us if you have any other queries.Thank you.","[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 -10.59.101.6 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1541791247000&group=host%3Ai-01ac95c23ac66a40e&from_ts=1541784047000>avg(last_30m):(avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by {host}- avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by{host} ) /avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by{host} * 100 > 95The monitor was last triggered at Fri Nov 09 2018 19:20:57 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-01ac95c23ac66a40e>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-01ac95c23ac66a40e<https://app.datadoghq.com/infrastructure?filter=i-01ac95c23ac66a40e>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1541791377000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1541790357000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4656153826769763542>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Hosea B. Getusi,*Cloud Engineer,**REĀN Cloud | **Reach, Engage, Āctivate, Nurtur**Mobile*: +254713404220 | *Skype*: hoseagetusi*hosea.getusi@reancloud.com <hosea.getusi@reancloud.com>* |  *www.reancloud.com<http://www.reancloud.com>*--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 - 10.59.101.6 - web,,10-11-2018 01:01,50,0,SpendHQ,"Hello Team,The alert regarding high memory utilization alert on the host PRD-WW2_6 has recovered and returned to the normal.We are marking this case as resolved and closing this case. Please let us know if you have any query.","Hello Team, This is to notify you that we received a high memory utilization alert on the host PRD-WW2_6 in us-east-1 region which has crossed the set threshold of 95%. The alert recovered within 13 minutes and currently has a reading of 94.76% with the httpd process showing most activity. ---------------------------------------------------------------------------------------             total       used       free     shared    buffers     cachedMem:           31G        28G       2.7G       872K        21M       400MLow:           31G        28G       2.7GHigh:           0B         0B         0B-/+ buffers/cache:        28G       3.1GSwap:           0B         0B         0B-----------------------------------------------------------------------------------------------------------------USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDapache   23759  0.5  2.3 1142676 770916 ?      S    Nov07  16:12 /usr/sbin/httpdapache   28218  0.6  2.1 1073436 707124 ?      S    Nov07  25:21 /usr/sbin/httpdapache   28743  0.4  2.0 1024232 657960 ?      R    17:53   0:29 /usr/sbin/httpdapache    7727  0.6  1.7 945288 578892 ?       S    Nov08   9:45 /usr/sbin/httpdapache    7717  0.5  1.7 944132 572240 ?       S    Nov08   8:36 /usr/sbin/httpdapache   25335  0.4  1.7 939932 568032 ?       S    Nov08   6:40 /usr/sbin/httpdapache   18820  0.5  1.7 938688 567576 ?       S    Nov08   9:06 /usr/sbin/httpdapache    4427  1.0  1.7 932408 560580 ?       S    14:38   3:12 /usr/sbin/httpdapache   26941  1.5  1.6 921728 550748 ?       S    17:39   1:43 /usr/sbin/httpdapache   25195  0.6  1.6 920156 548800 ?       S    Nov08  15:23 /usr/sbin/httpd-----------------------------------------------------------------------------------------------------------------As this is recovered, we are marking this case as resolved and closing it as well. Feel free to get in touch with us if you have any other queries.Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Bag0o,Cloud Engineer Level 1,Closed,1052559,Incident,11-05-2017 18:56,,"You can mark this as resolved.###Hello SpendHQ Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM###Hello Team,Please let us know if you are still facing any issues.###Hello Team,We could see that processors which are in  TIME_WAIT state are now reduced to 163. [root@ip-10-59-100-118 ~]# netstat -e | grep TIME_WAIT | wc -l163Connections which are in  TIME_WAIT to the PROD-SPHQ-DB-SERVER02. [root@ip-10-59-100-118 ~]# netstat -e | grep TIME_WAIT | grep 10.59.10.12 |wc -l135Also, we witnessed high CPU Usage, CPU Load, Memory usage, Disk Read operation and Network In/Out for this instance at that particular time.  Please refer the attached graphs for reference. As of now, everything seems to be normal and it might be an issue with any long queries running on the database.Please let us know if you are facing any issues###From: MatthewIt looks like the networking interface isn’t releasing the packets in a timely fashion. Yes, we can log in and this is not effecting clients just yet.###Hello Steven,We could see that there are 317 processes are in TIME_WAIT state and most of the connections make to DB server PROD-SPHQ-DB-SERVER02. Total connections:[centos@ip-10-59-100-118 log]$ netstat -e | grep TIME_WAIT | wc -l317Connections to the PROD-SPHQ-DB-SERVER02.[centos@ip-10-59-100-118 log]$ netstat -e | grep TIME_WAIT | grep 10.59.10.12 |wc -l159Also, we could see there are 32 connections established for apache.[centos@ip-10-59-100-118 log]$ netstat -e | grep ESTABLISHED | grep apache | wc -l32Please let us know if your team performed any deployment today and also let us know if you are able to log into the application.We could see that the connection made to the DB are in the time-wait state. We are further analysing on this issue and will get back to you with the updates.","REAN,Can you advise and tell if we are experiencing high volume in traffic to one of our web servers at 10.59.10.118? We are getting reports of long response times and high CPU utilization.When we view the affected client's data it appears just fine and in a timely fashion. I want to know if there is something making repeated requests.Steven Ng | Full Stack Developer | SpendHQ(r)O: 770-628-0692 | sng@spendhq.com<mailto:sng@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Firewall and ELB High Load,,10-05-2017 01:43,40,0,SpendHQ,You can mark this as resolved.,"Hello SpendHQ Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM","Hello Team,Please let us know if you are still facing any issues.","Hello Team,We could see that processors which are in  TIME_WAIT state are now reduced to 163. [root@ip-10-59-100-118 ~]# netstat -e | grep TIME_WAIT | wc -l163Connections which are in  TIME_WAIT to the PROD-SPHQ-DB-SERVER02. [root@ip-10-59-100-118 ~]# netstat -e | grep TIME_WAIT | grep 10.59.10.12 |wc -l135Also, we witnessed high CPU Usage, CPU Load, Memory usage, Disk Read operation and Network In/Out for this instance at that particular time.  Please refer the attached graphs for reference. As of now, everything seems to be normal and it might be an issue with any long queries running on the database.Please let us know if you are facing any issues","From: MatthewIt looks like the networking interface isn’t releasing the packets in a timely fashion. Yes, we can log in and this is not effecting clients just yet.","Hello Steven,We could see that there are 317 processes are in TIME_WAIT state and most of the connections make to DB server PROD-SPHQ-DB-SERVER02. Total connections:[centos@ip-10-59-100-118 log]$ netstat -e | grep TIME_WAIT | wc -l317Connections to the PROD-SPHQ-DB-SERVER02.[centos@ip-10-59-100-118 log]$ netstat -e | grep TIME_WAIT | grep 10.59.10.12 |wc -l159Also, we could see there are 32 connections established for apache.[centos@ip-10-59-100-118 log]$ netstat -e | grep ESTABLISHED | grep apache | wc -l32Please let us know if your team performed any deployment today and also let us know if you are able to log into the application.We could see that the connection made to the DB are in the time-wait state. We are further analysing on this issue and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013U4xx,Cloud Engineer Level 1,Closed,1025315,Incident,28-10-2016 11:36,,"Hello Team,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.###Hello SpendHQ Team,,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.###Hi Team,Gentle reminder,Did you get a chance to look into this issue, please let us know whether the specified Ip is a valid one or not.###Hello Team,As this was a critical issue, we have blocked the IP  195.62.53.168 in NACL. Please let us know whether this IP was a valid one or not.###Hi Team,Since this is a critical issue and we got it multiple times we have blocked the IP 195.62.53.168  in NACL. Please inform us if it is a valid one and let us know if you have any queries on this.###Hi SpendHQ Team,On analyzing the logs, we have found that at the time of alert a GET request has been made to the http://lock.bz:80/ URL. The source IP of this request is 195.62.53.168. We have found that 195.62.53.168 IP address belongs to Saint Petersburg state, Russia. Please let us know if we can block this IP address for future.Let us know if you would like to know for any further information.###Sudheer Chamarthi·4:35 AMHi SpendHQ Team,We want to inform you that we have received threat notification from Sophos in your environment. The source IP/host 10.59.1.194 was found to communicate with a potentially malicious site outside your company. We are looking into it and will update you with details shortly.",Advanced Threat ProtectionA threat has been detected in your networkThe source IP/host listed below was found to communicate with a potentially malicious site outside your company.Details about the alert:Threat name....: C2/Generic-ADetails........: http://www.sophos.com/en-us/threat-center/threat-analyses/viruses-and-spyware/C2~Generic-A.aspxTime...........: 2016-10-25 22:59:45Traffic blocked: noSource IP address or host: 10.59.1.194,[spendhq][CRIT-861] Advanced Threat Protection Alert,,26-10-2016 04:33,55,0,SpendHQ,"Hello Team,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.","Hello SpendHQ Team,,We haven't heard back from you regarding case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.","Hi Team,Gentle reminder,Did you get a chance to look into this issue, please let us know whether the specified Ip is a valid one or not.","Hello Team,As this was a critical issue, we have blocked the IP  195.62.53.168 in NACL. Please let us know whether this IP was a valid one or not.","Hi Team,Since this is a critical issue and we got it multiple times we have blocked the IP 195.62.53.168  in NACL. Please inform us if it is a valid one and let us know if you have any queries on this.","Hi SpendHQ Team,On analyzing the logs, we have found that at the time of alert a GET request has been made to the http://lock.bz:80/ URL. The source IP of this request is 195.62.53.168. We have found that 195.62.53.168 IP address belongs to Saint Petersburg state, Russia. Please let us know if we can block this IP address for future.Let us know if you would like to know for any further information.","Sudheer Chamarthi·4:35 AMHi SpendHQ Team,We want to inform you that we have received threat notification from Sophos in your environment. The source IP/host 10.59.1.194 was found to communicate with a potentially malicious site outside your company. We are looking into it and will update you with details shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C30Tu,Cloud Engineer Level 1,Closed,1054888,Incident,26-05-2017 05:39,,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM###Hello Matthew,We have whitelisted the IP 207.230.146.148.Please review the below ELB log entry we have found at the time of the alert and let us know if you need any further information.ELB log:2017-05-19T09:54:13.418124Z Secure-SpendHQ-ELB 207.230.146.148:59717 10.59.1.192:443 0.000051 0.104895 0.000045 403 403 0 0 GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1495055354284 HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2###This IP Address belongs to one of our customers. Please whitelist this ip address immediately.###In addition to Matthew’s request, can you provide any log information for this IP address (207.230.146.148) so that we can diagnose the alert if it is legitimate?###Hello SpendHQ-Team, On further analyzing the ELB logs at the time of the alert, We are able to figure out one IP 207.230.146.148 which belongs to Texas region in the United States was trying to execute the SERVER-APACHE Apache Struts remote code.As a fix, we have blocked the IP at NACL level. Please find the logs details below,Intrusion Prevention logs: 2017:05:19-09:54:11 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=21157 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0ELB Logs:2017-05-19T09:54:13.418124Z Secure-SpendHQ-ELB 207.230.146.148:59717 10.59.1.192:443 0.000051 0.104895 0.000045 403 403 0 0 GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1495055354284 HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Please refer these details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.20 which belongs to the Secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-19 09:54:11Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.20Source port: 21157Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 188 days 2 hours 8 minutesSystem Load        : 0.13,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,19-05-2017 15:27,158,0,SpendHQ,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM","Hello Matthew,We have whitelisted the IP 207.230.146.148.Please review the below ELB log entry we have found at the time of the alert and let us know if you need any further information.ELB log:2017-05-19T09:54:13.418124Z Secure-SpendHQ-ELB 207.230.146.148:59717 10.59.1.192:443 0.000051 0.104895 0.000045 403 403 0 0 GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1495055354284 HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2",This IP Address belongs to one of our customers. Please whitelist this ip address immediately.,"In addition to Matthew’s request, can you provide any log information for this IP address (207.230.146.148) so that we can diagnose the alert if it is legitimate?","Hello SpendHQ-Team, On further analyzing the ELB logs at the time of the alert, We are able to figure out one IP 207.230.146.148 which belongs to Texas region in the United States was trying to execute the SERVER-APACHE Apache Struts remote code.As a fix, we have blocked the IP at NACL level. Please find the logs details below,Intrusion Prevention logs: 2017:05:19-09:54:11 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=21157 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0ELB Logs:2017-05-19T09:54:13.418124Z Secure-SpendHQ-ELB 207.230.146.148:59717 10.59.1.192:443 0.000051 0.104895 0.000045 403 403 0 0 GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1495055354284 HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Please refer these details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.20 which belongs to the Secure ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ETmFK,Cloud Engineer Level 1,Closed,1067442,Incident,11-07-2017 22:51,,"Hello Dusty,Thanks for the update.At this time we are marking this case as resolved. However, if you have any further queries we want to hear back from you. Please reach out to us in case of further queries.###Thank you.  Looks good.###Next action: Evening shift: Send a reminder in case of no response.###Hello Dusty,The patch.spendhq.com is accessible over the internet without VPN connection. Please let us know if you have any further queries.","Hello,Can you ensure that the patch.spendhq.com server (10.59.100.79) is accessible without a VPN connection?Thanks!Dusty Fowler | Developer | SpendHQ(r)O: 770.628.0026 | dfowler@spendhq.com<mailto:dfowler@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Open server to outside world,,11-07-2017 20:57,2,0,SpendHQ,"Hello Dusty,Thanks for the update.At this time we are marking this case as resolved. However, if you have any further queries we want to hear back from you. Please reach out to us in case of further queries.",Thank you.  Looks good.,Next action: Evening shift: Send a reminder in case of no response.,"Hello Dusty,The patch.spendhq.com is accessible over the internet without VPN connection. Please let us know if you have any further queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001EVUt0,Cloud Engineer Level 1,Closed,1068276,Incident,17-07-2017 02:36,,"Hello SpendHQ Team,We have disabled maintenance for both preview.spendhq.com and secure.spendhq.com. We have checked and verified that both sites are up and running. At this time we are marking this case as resolved.Please revert back to us if you have any queries.###Next action: Andrew has updated that they are performing some database rebuilding activity for next 4 hours.So we have enabled maintenance mode for preview as well as secure website.Follow up with the customer on the status after 12:30 AM IST.###Hello Team,Thanks for quick talk over the phone.As discussed we have enabled maintenance for both preview.spendhq.com and secure.spendhq.com for next 4 hours.Please let us know once you are done with the maintenance so that we can enable the monitoring again.###Hello Team, This is to notify you that we got an alert regarding site down for URL: https://preview.spendhq.com/login or https://secure.spendhq.com/login.The alert got resolved automatically within a minute. The site is accessible now. We are analyzing the issue from our end. Please let us know if you are performing any activity from your end.###Hello Team,In our analysis, We have found that the issue was related to latency.While analysing the ELB logs we found that the site was not actually down.The alert got triggered as the Womly bot check got timed out due to high latency.Please find the logs from the ELB below:2017-07-16T13:06:49.201465Z preview-spendhq-xelb 66.246.75.38:36786 10.59.1.192:443 0.000047 39.549187 0.00005 200 200 0 9584 GET https://preview.spendhq.com:443/login HTTP/1.1 Mozilla/5.0 (compatible; WormlyBot; +http://wormly.com) ECDHE-RSA-AES128-GCM-SHA256 TLSv1.22017-07-16T13:07:19.413679Z preview-spendhq-xelb 69.164.195.159:52912 10.59.1.192:443 0.000052 9.418694 0.000047 200 200 0 9579 GET https://preview.spendhq.com:443/login HTTP/1.1 Mozilla/5.0 (compatible; WormlyBot; +http://wormly.com) ECDHE-RSA-AES128-GCM-SHA256 TLSv1.22017-07-16T13:07:49.034224Z preview-spendhq-xelb 66.246.75.38:39896 10.59.1.192:443 0.000042 3.005071 0.000049 200 200 0 9581 GET https://preview.spendhq.com:443/login HTTP/1.1 Mozilla/5.0 (compatible; WormlyBot; +http://wormly.com) ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Kindly verify the logs and let us know if you have any more queries regarding this.###Hello Team, This is to notify you that we got an alert regarding site down for URL: https://preview.spendhq.com/login.The alert got resolved automatically within a minute. The site is accessible now. We are analyzing the issue from our end. Please let us know if you are performing any activity from your end.","Sun, 16 Jul 2017 09:07:32 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): London UK, California US, Dallas-B US, Frankfurt DE-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,16-07-2017 18:37,8,0,SpendHQ,"Hello SpendHQ Team,We have disabled maintenance for both preview.spendhq.com and secure.spendhq.com. We have checked and verified that both sites are up and running. At this time we are marking this case as resolved.Please revert back to us if you have any queries.",Next action: Andrew has updated that they are performing some database rebuilding activity for next 4 hours.So we have enabled maintenance mode for preview as well as secure website.Follow up with the customer on the status after 12:30 AM IST.,"Hello Team,Thanks for quick talk over the phone.As discussed we have enabled maintenance for both preview.spendhq.com and secure.spendhq.com for next 4 hours.Please let us know once you are done with the maintenance so that we can enable the monitoring again.","Hello Team, This is to notify you that we got an alert regarding site down for URL: https://preview.spendhq.com/login or https://secure.spendhq.com/login.The alert got resolved automatically within a minute. The site is accessible now. We are analyzing the issue from our end. Please let us know if you are performing any activity from your end.","Hello Team,In our analysis, We have found that the issue was related to latency.While analysing the ELB logs we found that the site was not actually down.The alert got triggered as the Womly bot check got timed out due to high latency.Please find the logs from the ELB below:2017-07-16T13:06:49.201465Z preview-spendhq-xelb 66.246.75.38:36786 10.59.1.192:443 0.000047 39.549187 0.00005 200 200 0 9584 GET https://preview.spendhq.com:443/login HTTP/1.1 Mozilla/5.0 (compatible; WormlyBot; +http://wormly.com) ECDHE-RSA-AES128-GCM-SHA256 TLSv1.22017-07-16T13:07:19.413679Z preview-spendhq-xelb 69.164.195.159:52912 10.59.1.192:443 0.000052 9.418694 0.000047 200 200 0 9579 GET https://preview.spendhq.com:443/login HTTP/1.1 Mozilla/5.0 (compatible; WormlyBot; +http://wormly.com) ECDHE-RSA-AES128-GCM-SHA256 TLSv1.22017-07-16T13:07:49.034224Z preview-spendhq-xelb 66.246.75.38:39896 10.59.1.192:443 0.000042 3.005071 0.000049 200 200 0 9581 GET https://preview.spendhq.com:443/login HTTP/1.1 Mozilla/5.0 (compatible; WormlyBot; +http://wormly.com) ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2Kindly verify the logs and let us know if you have any more queries regarding this.","Hello Team, This is to notify you that we got an alert regarding site down for URL: https://preview.spendhq.com/login.The alert got resolved automatically within a minute. The site is accessible now. We are analyzing the issue from our end. Please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gdiMj,Cloud Engineer Level 1,Closed,1109806,Incident,23-12-2018 04:43,,"Hello Matthew,Thanks for the update.At this time we are marking this case closed.We look forward to serving you. Feel free to reach out to us at support@reancloud.com for any additional queries.###Matthew Watts <mwatts@spendhq.com>Today, 4:41 AMLet’s close it off. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting###Hello Matthew,We didn't see any downtime at the time of the alert, everything was normal.Please let us know if you have any queries related to it or we are good to close this case or not.###Matthew Watts <mwatts@spendhq.com>Today, 4:07 AMRean Support <support@reancloud.com>;spendhq-support@reancloud.comCan you advise if this caused any downtime?###Hello Team,This is to inform that the alert DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb in US East (N. Virginia) got recovered and returned to normal state.At this time we are marking this case closed and let us know if you have any queries related to it.###Hello Team,From checking the history data for the alert, we could see that at the time Threshold Crossed: 1 datapoint [2105.5 (13/11/18 20:54:00)] was not greater than or equal to the threshold (120000.0).{  version: 1.0,  oldState: {    stateValue: OK,    stateReason: Threshold Crossed: 1 datapoint [2105.5 (13/11/18 20:54:00)] was not greater than or equal to the threshold (120000.0).,    stateReasonData: {      version: 1.0,      queryDate: 2018-11-13T20:59:02.117+0000,      startDate: 2018-11-13T20:54:00.000+0000,      statistic: Average,      period: 300,      recentDatapoints: [        2105.5      ],      threshold: 120000    }  },  newState: {    stateValue: ALARM,    stateReason: Threshold Crossed: 1 datapoint [126458.0 (21/12/18 18:45:00)] was greater than or equal to the threshold (120000.0).,    stateReasonData: {      version: 1.0,      queryDate: 2018-12-21T18:50:02.576+0000,      startDate: 2018-12-21T18:45:00.000+0000,      statistic: Average,      period: 300,      recentDatapoints: [        126458      ],      threshold: 120000    }  }}The alert has however since then recovered and is now in OK state. Thanks.###Hello Team,We acknowledge receipt of this alert. We are working on it and will be getting back to you with more details regarding the same.Thanks.","You are receiving this email because your Amazon CloudWatch AlarmDX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb in the US East (N. Virginia)region has entered the ALARM state, because Threshold Crossed: 1 datapoint[126458.0 (21/12/18 18:45:00)] was greater than or equal to the threshold(120000.0). at Friday 21 December, 2018 18:50:02 UTC.View this alarm in the AWS Management Console:https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#s=Alarms&alarm=DX-ConnectionPpsIngress-SpendHQ-Equinix-10GbAlarm Details:- Name:                       DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb- Description:                The packet rate for inbound data to the AWSside of the connection.- State Change:               OK -> ALARM- Reason for State Change:    Threshold Crossed: 1 datapoint [126458.0(21/12/18 18:45:00)] was greater than or equal to the threshold (120000.0).- Timestamp:                  Friday 21 December, 2018 18:50:02 UTC- AWS Account:                261234435984Threshold:- The alarm is in the ALARM state when the metric isGreaterThanOrEqualToThreshold 120000.0 for 300 seconds.Monitored Metric:- MetricNamespace:                     AWS/DX- MetricName:                          ConnectionPpsIngress- Dimensions:                          [ConnectionId = dxcon-ffpmy711]- Period:                              300 seconds- Statistic:                           Average- Unit:                                not specifiedState Change Actions:- OK:- ALARM:[arn:aws:sns:us-east-1:261234435984:SpendHQ-DirectConnect-Cloudwatch-Monitoring]- INSUFFICIENT_DATA:--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQ-DirectConnect-Cloudwatch-Monitoring:24ff3fa5-5763-4bc5-b430-6ec72c0bae22&Endpoint=spendhq-support@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",ALARM: DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb in US East (N. Virginia),,22-12-2018 00:32,28,0,SpendHQ,"Hello Matthew,Thanks for the update.At this time we are marking this case closed.We look forward to serving you. Feel free to reach out to us at support@reancloud.com for any additional queries.","Matthew Watts <mwatts@spendhq.com>Today, 4:41 AMLet’s close it off. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting","Hello Matthew,We didn't see any downtime at the time of the alert, everything was normal.Please let us know if you have any queries related to it or we are good to close this case or not.","Matthew Watts <mwatts@spendhq.com>Today, 4:07 AMRean Support <support@reancloud.com>;spendhq-support@reancloud.comCan you advise if this caused any downtime?","Hello Team,This is to inform that the alert DX-ConnectionPpsIngress-SpendHQ-Equinix-10Gb in US East (N. Virginia) got recovered and returned to normal state.At this time we are marking this case closed and let us know if you have any queries related to it.","Hello Team,From checking the history data for the alert, we could see that at the time Threshold Crossed: 1 datapoint [2105.5 (13/11/18 20:54:00)] was not greater than or equal to the threshold (120000.0).{  version: 1.0,  oldState: {    stateValue: OK,    stateReason: Threshold Crossed: 1 datapoint [2105.5 (13/11/18 20:54:00)] was not greater than or equal to the threshold (120000.0).,    stateReasonData: {      version: 1.0,      queryDate: 2018-11-13T20:59:02.117+0000,      startDate: 2018-11-13T20:54:00.000+0000,      statistic: Average,      period: 300,      recentDatapoints: [        2105.5      ],      threshold: 120000    }  },  newState: {    stateValue: ALARM,    stateReason: Threshold Crossed: 1 datapoint [126458.0 (21/12/18 18:45:00)] was greater than or equal to the threshold (120000.0).,    stateReasonData: {      version: 1.0,      queryDate: 2018-12-21T18:50:02.576+0000,      startDate: 2018-12-21T18:45:00.000+0000,      statistic: Average,      period: 300,      recentDatapoints: [        126458      ],      threshold: 120000    }  }}The alert has however since then recovered and is now in OK state. Thanks.","Hello Team,We acknowledge receipt of this alert. We are working on it and will be getting back to you with more details regarding the same.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001YNIN0,Cloud Engineer Level 1,Closed,1101101,Incident,12-07-2018 16:27,,"Hello Team,We haven't heard back from you regarding this case for a while. For continued support regarding the same issue, you can contact us any time. At this time we are marking this case as resolved and closing this case. Kindly validate these details and let us know if you have any further queries.###@Morning_shift team should close this case if there's no response from Matthew by end of their shift.###Hello Matthew, We haven't heard back from you regarding this case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.Best Regards,Hosea Getusi.###Hello Mathew, This is a gentle reminder. Kindly review the previous comment and let us know if you have any issue.###Hello Mathew,This is a gentle reminder.We have updated the idle timeout value for the www1-sandbox-spendhq-com Loadbalancer. Please check and verify from your end everything is working fine and let us know if you're still facing any challenges.###Hello Mathew,We have updated the idle timeout value for the www1-sandbox-spendhq-com Loadbalancer.Please check and verify from your end everything is working fine and let us know if you're still facing any challenges.###Hello Matthew,We will look into this and will get back to you with an update.","REAN,We are currently getting a timeout with our ww1.soendhq.com Load Balancer. Can you please ensure that the values match the PRD Load Balancer.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Ww1 Load Balancer Timeout,,06-07-2018 02:28,158,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case for a while. For continued support regarding the same issue, you can contact us any time. At this time we are marking this case as resolved and closing this case. Kindly validate these details and let us know if you have any further queries.",@Morning_shift team should close this case if there's no response from Matthew by end of their shift.,"Hello Matthew, We haven't heard back from you regarding this case for a while. For continued support regarding the same issue, you can contact us any time.Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case anytime by sending an email back to us.Best Regards,Hosea Getusi.","Hello Mathew, This is a gentle reminder. Kindly review the previous comment and let us know if you have any issue.","Hello Mathew,This is a gentle reminder.We have updated the idle timeout value for the www1-sandbox-spendhq-com Loadbalancer. Please check and verify from your end everything is working fine and let us know if you're still facing any challenges.","Hello Mathew,We have updated the idle timeout value for the www1-sandbox-spendhq-com Loadbalancer.Please check and verify from your end everything is working fine and let us know if you're still facing any challenges.","Hello Matthew,We will look into this and will get back to you with an update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bjMm5,Cloud Engineer Level 2,Closed,1104385,Incident,18-09-2018 10:34,,"Hello Team,We haven't heard back from you.The status check was failed from 3:30 PM to 4:04 PM EST. When we looked at the metrics, during this period we see a sudden spike in Network IN and Network OUT. Also, this network spike is an expected behavior for DB machines. When System didn’t respond to the Amazon health checks because of any busy operation(in this case, network out) amazon mark it as health checks failure. If that status stays a long time and if the machine is not reachable then it will be a real problem. Once resources were free, the incoming request was processed and the health checks were passed. In this case, we can conclude it is a false positive because we witness there is a network spike during that time. We have confirmed that the system is functioning normally and resources utilization is as expected so that it is an underlying hardware issue and now the instance is running in a new healthy hardware as we have performed stop and start on this server. This instance is not under monitoring as of now.Please find the metrics screenshot in the attachment section, as the issue is resolved hence we are marking this case as closed please reach us out in case of any query.###Hello Team, This is a gentle reminder. Please review our previous comment and let us know in case of any queries.###Hello Team, This is a gentle reminder. Please review our previous comment and let us know in case of any queries.###Hello Team,This is a gentle reminder.Please review our previous comment and let us know in case of any queries.###Hello SpendHQ-Team,The status check was failed from 3:30 PM to 4:04 PM EST. When we looked at the metrics, during this period we see a sudden spike in Network IN and Network OUT. Also, this network spike is an expected behavior for DB machines. When System didn’t respond to the Amazon health checks because of any busy operation(in this case, network out) amazon mark it as health checks failure. If that status stays long time and if the machine is not reachable then it will be a real problem. Once resources were free, the incoming request was processed and the health checks were passed.  In this case, we can conclude it is a false positive because we witness there is a network spike during that time. We have confirmed that the system is functioning normally and resources utilization is as expected so that it is an underlying hardware issue and now the instance is running in a new healthy hardware as we have performed stop and start on this server.This instance is not under monitoring so that we are downgrading the priority.Please find the metrics screenshot in the attachment section and Kindly review this details and let us know in case of any queries.Regards,Thenmozhy D.###Hello Rohit,I have checked the Cloudwatch matrices of the instance 10.59.10.180 and did not found any kind of spikes at the time of status check failed. Also checked the instance level logs but not able to find any related issue. It might be an underlying hardware issue. Please let us know if we should get assistance from AWS support to find the root cause.###Allen Herrera1:41 AM (1 minute ago)to Rean, MatthewIts back online. Thank you. Yes please have an RCA.###Hello Allen,We checked from the console and found that Instance was not passing both status checks(system and instance). We went ahead and performed stop and start. Now the instance is running fine with both status check passed and we are able to login to the instance also. Please verify from your end and let us know if you are still facing the issue. Meanwhile, we are checking for the cause of this issue and will let you know the update.###Hello Matthew/Allen,We are checking on this and keep you posted.","REAN, can we treat this like a SEV ONE. Please work on restoring service ASAPSent from a mobile device.________________________________From: Allen Herrera <aherrera@spendhq.com>Sent: Tuesday, September 11, 2018 1:39:47 PMTo: spendhq-support@reancloud.comSubject: 10.59.10.180 Server OfflineHey Rean,10.59.10.180 is offline, it’s a part of our mariadb testing environment cluster.Please get this machine back online asap because our QA team can’t work without itAllen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--You received this message because you are subscribed to the Google Groups Spendhq Support group.To unsubscribe from this group and stop receiving emails from it, send an email to spendhq-support+unsubscribe@reancloud.com<mailto:spendhq-support+unsubscribe@reancloud.com>.--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: 10.59.10.180 Server Offline,,12-09-2018 01:14,153,0,SpendHQ,"Hello Team,We haven't heard back from you.The status check was failed from 3:30 PM to 4:04 PM EST. When we looked at the metrics, during this period we see a sudden spike in Network IN and Network OUT. Also, this network spike is an expected behavior for DB machines. When System didn’t respond to the Amazon health checks because of any busy operation(in this case, network out) amazon mark it as health checks failure. If that status stays a long time and if the machine is not reachable then it will be a real problem. Once resources were free, the incoming request was processed and the health checks were passed. In this case, we can conclude it is a false positive because we witness there is a network spike during that time. We have confirmed that the system is functioning normally and resources utilization is as expected so that it is an underlying hardware issue and now the instance is running in a new healthy hardware as we have performed stop and start on this server. This instance is not under monitoring as of now.Please find the metrics screenshot in the attachment section, as the issue is resolved hence we are marking this case as closed please reach us out in case of any query.","Hello Team, This is a gentle reminder. Please review our previous comment and let us know in case of any queries.","Hello Team, This is a gentle reminder. Please review our previous comment and let us know in case of any queries.","Hello Team,This is a gentle reminder.Please review our previous comment and let us know in case of any queries.","Hello SpendHQ-Team,The status check was failed from 3:30 PM to 4:04 PM EST. When we looked at the metrics, during this period we see a sudden spike in Network IN and Network OUT. Also, this network spike is an expected behavior for DB machines. When System didn’t respond to the Amazon health checks because of any busy operation(in this case, network out) amazon mark it as health checks failure. If that status stays long time and if the machine is not reachable then it will be a real problem. Once resources were free, the incoming request was processed and the health checks were passed.  In this case, we can conclude it is a false positive because we witness there is a network spike during that time. We have confirmed that the system is functioning normally and resources utilization is as expected so that it is an underlying hardware issue and now the instance is running in a new healthy hardware as we have performed stop and start on this server.This instance is not under monitoring so that we are downgrading the priority.Please find the metrics screenshot in the attachment section and Kindly review this details and let us know in case of any queries.Regards,Thenmozhy D.","Hello Rohit,I have checked the Cloudwatch matrices of the instance 10.59.10.180 and did not found any kind of spikes at the time of status check failed. Also checked the instance level logs but not able to find any related issue. It might be an underlying hardware issue. Please let us know if we should get assistance from AWS support to find the root cause.","Allen Herrera1:41 AM (1 minute ago)to Rean, MatthewIts back online. Thank you. Yes please have an RCA.","Hello Allen,We checked from the console and found that Instance was not passing both status checks(system and instance). We went ahead and performed stop and start. Now the instance is running fine with both status check passed and we are able to login to the instance also. Please verify from your end and let us know if you are still facing the issue. Meanwhile, we are checking for the cause of this issue and will let you know the update.","Hello Matthew/Allen,We are checking on this and keep you posted.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DHaqB,Cloud Engineer Level 1,Closed,1063722,Incident,20-06-2017 04:31,,"Hello Team, This is to notify you that volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume got resolved and violation lasted for 1 hour.###Hello Team,On further analysis, we could see /dev/xvda1 mounted on / is consuming high volume usage on this instance. Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G   16M 100% /Please find the volume usage in / 7.5T    total5.2T    mnt2.3T    var21G     tmp13G     usrPlease delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.###Hello Team,This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90%.We are analyzing the issue and meanwhile let us know if you have any queries regarding this.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Tue, Jun 20, 2017 at 12:34 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjb0OgyAYRZ9GtpoPBISBoTWaJp07tEuDgD-JClUY-vbF5A4nNzn3WsVk79CsCOAaOJZYAiW45KwiVdlQDm0HDItb1dSyLSjYaMfSeDQpx91AjKCYUAZSCNJbI5yRg5bSUELRoqYYw1FU14J0OTqE0uqorR-nb95Yz84Yn7aYKex-mBeXKV3gDc3n8Xs98T2hXa1HPt6d3szikz1NFNXqtzn6_Q8L3jn1>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj0uOwyAMhk9DlsiYGPCCxTTTXGNEQ15SUzIJrXr8kmgWI1t-_JY_2dET3_pq9gjKglGsGGpU0pBGLZvawLUFUu6iG8tXUUPMcZRdqibvMAZEMqiHUMwhmOiYA93AENVDdfdTzusu9JfAtnhYVxlDDjGN029hLEVb0mPOadsFagTUbFjoNqefXNa-Vc3WsWPLACDQjFt6rkWP_WvueoF0kAnb0p_5_YpBHVUzpT2fcwWSWJaoNBXCsKXlP9vak11tftnLc1sfHt09PeNxXZX933UfxnBSqA>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Mon Jun 19 2017 19:04:00 UTC (*16 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtTkGOwyAMfA0ckW1iCAcO22zzDxbYJFJTsgmt-vySaqWRPWNLM5M8u58sF0-AFgw6dNARKsOatBo6A9cRGPuLHqy7ig5STZOKRc6eeszQR6N_LXCy2Nto2QW2jigENPLm51q3Q-gvQWND2DaVQg2pTPNf81jbbS33pZb9EKQJSDvjhB6nvTw2ob9Tfi4xC-LTgWls-rNfzxTwZMNcjvr5Iyh2qk3ULHe_Hq3qnsM93sojnVmy-v-sNzolRT0>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjUEOgyAQRU8DS8LMCDgLFq3ReyAQNdFild6_NGnyVy957ydveM5y86jBaQsMrDsEZQ0hqaGzepy0gf5Jg-NRdDrVtKhY5Ood8sxAZDg4ihQ5szNIAA5dJOjl7tdaz1vQQ-DUFs5TpVBDKsv6bo2jsaO8tlquWyChRmLLDea0VXn5425_Vw6vuJdP-gmy-r_wBXcANQ8>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVjUsOwyAQQ08TlmiGCaQsWPSXe0wC-UhNSMnk_qWSZVlPsh2D9UNSazCAHTj06KE1qJ0lQ_rZOnj3YPH2oGfn300LUeKsx6yWMJLhwSKh72Aw7FOizg2tSZP1bByoT1hEjrOhe2P6Kj4OHVk45nn51o2tsnWfCp9SrlGukhrql3zKzluNLwRtva6OZFUJ21nvS-J9_OQr_vtKwpb3VXL5AUbYOx0>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jksOgzAQQ09Dligzkw9ZZNFSuEdgUkACQiHt-ZtuKlmyZOnZZq_dEMXiUYKVBhw4qRBqowmpbpWRXS81NHdqresqJTnzVI9JzB5pNBJtHDgOwQQAtkE_wVhtwSIOYvVzzsdV0a3CvigcR80hB07T_CodW8niJ-7579QvXNGDygtrVINOoW5cQ86J029XmT9j2Mc1vfnHi-y3tC85nV_sfTlG>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjUsOhCAQRE8jS9J8RFmwmDF6D6BBTVQYxPsPJrWovFReoem1C2Q3HNgAimmmQXJGVS-4oJNUMC_Qs_ErpkHPnQSsuFKfyGac0HxEF5SSADxiBO21A4zW8YFLIIfZas13Jz4dX1pszhRttZjW7dcc58u8T89VW8slxFDC5cNNijnv9lWCvfyRHnzHpJozXXtN5Q9oITat>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,20-06-2017 00:36,4,0,SpendHQ,"Hello Team, This is to notify you that volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume got resolved and violation lasted for 1 hour.","Hello Team,On further analysis, we could see /dev/xvda1 mounted on / is consuming high volume usage on this instance. Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G   16M 100% /Please find the volume usage in / 7.5T    total5.2T    mnt2.3T    var21G     tmp13G     usrPlease delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.","Hello Team,This is to notify you that we have received a volume usage alert for prod-sphq-db-server05 instance /dev/xvda1 volume has exceeded a threshold value of 90%.We are analyzing the issue and meanwhile let us know if you have any queries regarding this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001GHbUt,Cloud Engineer Level 1,Closed,1074094,Incident,21-08-2017 22:41,,"We had a call with Matthew and he updated that he needs to rename the loadbalancer. Following this on 01074106###Hello Matthew,We have tried to call you in this number 770-629-3158, but you were unreachable. We have reverted back the changes made in preview elb and page is loading fine now. Please verify and let us know if you have any queries.","Please revert the load balancer changes immediately.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",CRITICAL,,21-08-2017 20:25,2,0,SpendHQ,We had a call with Matthew and he updated that he needs to rename the loadbalancer. Following this on 01074106,"Hello Matthew,We have tried to call you in this number 770-629-3158, but you were unreachable. We have reverted back the changes made in preview elb and page is loading fine now. Please verify and let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ZkVub,Cloud Engineer Level 1,Closed,1102555,Incident,10-08-2018 07:28,,"Hello Team,This is to inform you that the alert regarding High CPU Utilization and High CPU Load on prd-ww1_122 got recovered and back to its normal state with the value of 1.38%. As the issue got resolved hence we are marking this as closed.###Hello Spendhq-Team, This is to inform you that we have received an alert regarding High CPU Utilization and High CPU Load on prd-ww1_122 (10.59.100.122) has exceeded the threshold value of 80 to 99.66%. Please find the resources details below. Resource Details:- Instance ID: i-0ace70ce06368e4a7 Instance Name: prd-ww1_122 Private IP: 10.59.100.122 Please find CPU utilization and Active Internet connections details below: Load Average of the System16.21, 14.50, 11.46################################################   Processes with highest CPU usage################################################ USER       PID  PPID CMD                         %CPUapache   13739 23078 /usr/sbin/httpd             48.7apache   13741 23078 /usr/sbin/httpd             32.8apache   13740 23078 /usr/sbin/httpd             32.3apache   18035 23078 /usr/sbin/httpd             32.0apache    3902 23078 /usr/sbin/httpd             27.4apache   11274 23078 /usr/sbin/httpd             26.1apache   20664 23078 /usr/sbin/httpd             25.9apache   29358 23078 /usr/sbin/httpd             18.8apache    6725 23078 /usr/sbin/httpd             13.3apache   21877 23078 /usr/sbin/httpd             10.8################################################ Below are netstat summary (network statistics) ################################################ Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program name   tcp        0      0 *:nfs                       *:*                         LISTEN      -                   tcp        0      0 *:43043                     *:*                         LISTEN      6081/rpc.mountd     tcp        0      0 *:37859                     *:*                         LISTEN      6081/rpc.mountd     tcp        0      0 localhost:commplex-main     *:*                         LISTEN      20283/agent         tcp        0      0 *:51720                     *:*                         LISTEN      6081/rpc.mountd     tcp        0      0 localhost:commplex-link     *:*                         LISTEN      20283/agent         tcp        0      0 localhost:dyna-access       *:*                         LISTEN      1831/clamd          tcp        0      0 *:sunrpc                    *:*                         LISTEN      1346/rpcbind        tcp        0      0 *:ssh                       *:*                         LISTEN      1731/sshd           tcp        0      0 *:41782                     *:*                         LISTEN      -                   tcp        0      0 *:hbci                      *:*                         LISTEN      2041/node           tcp        0      0 localhost:smtp              *:*                         LISTEN      1966/master         tcp        0      0 *:40508                     *:*                         LISTEN      1368/rKindly review this details and let us know your thoughts on this.","---------- Forwarded message ----------From: Datadog Alerting <alert@dtdg.co>Date: Fri, Aug 10, 2018 at 1:53 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on thehost prd-ww1_122 - 10.59.100.122 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High CPU Utilization on the host prd-ww1_122 -10.59.100.122 - webHigh CPU Utilization on the host. Log in to the machine and verify whichprocess is consuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024189?to_ts=1533846199000&group=host%3Ai-0ace70ce06368e4a7&from_ts=1533838999000>avg(last_30m):avg:system.cpu.stolen{datadog_monitor:on} by {host} +avg:system.cpu.user{datadog_monitor:on} by {host} > 80The monitor was last triggered at Thu Aug 09 2018 20:23:29 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024189?group=host%3Ai-0ace70ce06368e4a7>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024189/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?filter=i-0ace70ce06368e4a7>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1533846329000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1533845309000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4522858004188532817>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on the host prd-ww1_122 - 10.59.100.122 - web,,10-08-2018 01:58,6,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding High CPU Utilization and High CPU Load on prd-ww1_122 got recovered and back to its normal state with the value of 1.38%. As the issue got resolved hence we are marking this as closed.","Hello Spendhq-Team, This is to inform you that we have received an alert regarding High CPU Utilization and High CPU Load on prd-ww1_122 (10.59.100.122) has exceeded the threshold value of 80 to 99.66%. Please find the resources details below. Resource Details:- Instance ID: i-0ace70ce06368e4a7 Instance Name: prd-ww1_122 Private IP: 10.59.100.122 Please find CPU utilization and Active Internet connections details below: Load Average of the System16.21, 14.50, 11.46",,,,,,,,,,,,,,,,Processes with highest CPU usage,,,,,,,,,,,,,,,,USER       PID  PPID CMD                         %CPUapache   13739 23078 /usr/sbin/httpd             48.7apache   13741 23078 /usr/sbin/httpd             32.8apache   13740 23078 /usr/sbin/httpd             32.3apache   18035 23078 /usr/sbin/httpd             32.0apache    3902 23078 /usr/sbin/httpd             27.4apache   11274 23078 /usr/sbin/httpd             26.1apache   20664 23078 /usr/sbin/httpd             25.9apache   29358 23078 /usr/sbin/httpd             18.8apache    6725 23078 /usr/sbin/httpd             13.3apache   21877 23078 /usr/sbin/httpd             10.8,,,,,,,,,,,,,,,,Below are netstat summary (network statistics),,,,,,,,,,,,,,,,Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program name   tcp        0      0 *:nfs                       *:*                         LISTEN      -                   tcp        0      0 *:43043                     *:*                         LISTEN      6081/rpc.mountd     tcp        0      0 *:37859                     *:*                         LISTEN      6081/rpc.mountd     tcp        0      0 localhost:commplex-main     *:*                         LISTEN      20283/agent         tcp        0      0 *:51720                     *:*                         LISTEN      6081/rpc.mountd     tcp        0      0 localhost:commplex-link     *:*                         LISTEN      20283/agent         tcp        0      0 localhost:dyna-access       *:*                         LISTEN      1831/clamd          tcp        0      0 *:sunrpc                    *:*                         LISTEN      1346/rpcbind        tcp        0      0 *:ssh                       *:*                         LISTEN      1731/sshd           tcp        0      0 *:41782                     *:*                         LISTEN      -                   tcp        0      0 *:hbci                      *:*                         LISTEN      2041/node           tcp        0      0 localhost:smtp              *:*                         LISTEN      1966/master         tcp        0      0 *:40508                     *:*                         LISTEN      1368/rKindly review this details and let us know your thoughts on this.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bmgop,Cloud Engineer Level 2,Closed,1105048,Incident,26-09-2018 13:34,,"Hello Team,We haven't heard back from you regarding this case.At this time we are marking this case as closed and let us know if you have any queries related to it.###Hello Team, This is the gentle reminder. Please review the details mentioned in the previous comment and let us know if you have any queries related to it.###During OPs call Rohit said that we should close this case by tomorrow end of day###Rohit is working on it. Please follow up with him###Hello Team, This is the gentle reminder. Please review the details mentioned in the previous comment and let us know if you have any queries related to it.###Hello Team, This is the gentle reminder. Please review the details mentioned in the previous comment and let us know if you have any queries related to it.###Hello Team,The site was loading slowly during the downtime and by looking at the ELB graphs we could see there were high latency, request count and surge queue length at the time of the alert.The surge queue metric shows the requests being queued on the ELB. This happens when the backend instances are not accepting more requests and thus these requests get queued up at the ELB. This leads to latency. When we looked into the Apache error logs we could see the following error [error] server reached MaxClients setting, consider raising the MaxClients setting. This means the connections limit defined by MaxClients is reached(In our cases, it was set to 300). In such situations, the website will take too much time to load. Our monitoring tool tries to ping the URL and it didn't resolve teh site within 30 seconds consider as the site was down. So by analyzing these details, we can see the site was not actually down but it was running very slowly. Once the load was released the slowness issue got resolved.We have checked the disk usage details for the backend machine PRD-WW2_6(i-01ac95c23ac66a40e). By looking into the last one day graph we could see the maximum volume usage for the root device was 32% (Attached the graph for the reference).  Please confirm the instance which you have resolved the root partition storage reached to 100%. Please let verify the details and let us know if you have any queries.###We could also see from event logs during the time of alert log rotation was running: Sep 21 16:41:43 ip-10-59-101-6 kernel: [23855]     0 23855    91898     1960   0       0             0 httpdSep 21 16:41:43 ip-10-59-101-6 kernel: [23857]     0 23857     7961      182   0       0             0 rotatelogsSep 21 16:41:43 ip-10-59-101-6 kernel: [23858]     0 23858     7961      182   5       0             0 rotatelogsWe also didn't receive any datadog alert for high disk usage.The Host shows the root volume to have been below 32% the entire day:https://app.datadoghq.com/dash/host/324510931?live=true&from_ts=1537385227232&to_ts=1537558027232&page=0&is_auto=false&tile_size=m&fullscreen=e4da3bPlease do more analysis on this, if we could verify the root volume had hit 100%###Team,We have only one instance behind the ELB NewPreview-ELBCurrently the disk is on 27% utilization Filesystem            Size  Used Avail Use% Mounted on/dev/xvda1             50G   13G   35G  27% /tmpfs                  16G     0   16G   0% /dev/shm10.59.100.125:/exports_production/files.spendhq.com                     2.0T  853G  1.1T  45% /var/www/vhosts/files.spendhq.comWe also checked on the Log rotation and it was enabled.sudo cat /etc/cron.daily/logrotate#!/bin/sh/usr/sbin/logrotate /etc/logrotate.confEXITVALUE=$?if [ $EXITVALUE != 0 ]; then   /usr/bin/logger -t logrotate ALERT exited abnormally with [$EXITVALUE]fiexit 0###Hello Jason,We will check internally and will let you know the details.###Jason Bray <jbray@spendhq.com>10:24 PM (1 hour ago)to Allen, Rean, spendhq-support@reancloud.comWhat can be done to automate this so we don’t run into this issue as we move ahead?###Hello Allen,Thanks for the update.We also identified Spikes in Latency, Request Count and HTTP 4xx response code ELB metrics that lasted for 2 minutes, from 16:18 UTC to 16:20 UTC.At the time the Average Latency peaked to 125,389.189587 milliseconds while the request count had hit 1,134 requests.Checking on the backend Instance Cloudwatch metrics, everything looked normal. Please find the ELB Latency, Request Count Cloudwatch Metrics below:###Im fairly sure its because of the root partition storage reaching 100%. I resolved itAllen Herrera.###Sent Mail to Leads:Hi Leads,We have encountered a P1 issue. Below are the details of the issue,Customer Name: SpendHQOpen date/time:  Fri, 21 Sep 2018 12:16:03 -0400Issue Summary/Details:  We received a site down alert on the URL https://secure.spendhq.com/login which lasted for 4 minutesOwner : Rafi RameshStatus : In ProgressAction/s Taken : Informed customer of Site down alert.Regards,Paul MulonziaREĀN Cloud | Reach, Engage, Āctivate, Nurtur###Hello Team,This is to inform that you that we got a site down alert for URL https://secure.spendhq.com/login  and site up and serving well.total violation: 4 minuteswe are analyzing the issue and get back to you with an update.Thank you.","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Fri, Sep 21, 2018 at 9:46 PMSubject: Detected Error on SpendHQ SecureTo: <ms@reancloud.com>Fri, 21 Sep 2018 12:16:03 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30011 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Dallas-B US, Frankfurt DE, California US, Sydney-C AU-- *Thank You,**        Rafi R*--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Secure,,21-09-2018 21:47,112,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.At this time we are marking this case as closed and let us know if you have any queries related to it.","Hello Team, This is the gentle reminder. Please review the details mentioned in the previous comment and let us know if you have any queries related to it.",During OPs call Rohit said that we should close this case by tomorrow end of day,Rohit is working on it. Please follow up with him,"Hello Team, This is the gentle reminder. Please review the details mentioned in the previous comment and let us know if you have any queries related to it.","Hello Team, This is the gentle reminder. Please review the details mentioned in the previous comment and let us know if you have any queries related to it.","Hello Team,The site was loading slowly during the downtime and by looking at the ELB graphs we could see there were high latency, request count and surge queue length at the time of the alert.The surge queue metric shows the requests being queued on the ELB. This happens when the backend instances are not accepting more requests and thus these requests get queued up at the ELB. This leads to latency. When we looked into the Apache error logs we could see the following error [error] server reached MaxClients setting, consider raising the MaxClients setting. This means the connections limit defined by MaxClients is reached(In our cases, it was set to 300). In such situations, the website will take too much time to load. Our monitoring tool tries to ping the URL and it didn't resolve teh site within 30 seconds consider as the site was down. So by analyzing these details, we can see the site was not actually down but it was running very slowly. Once the load was released the slowness issue got resolved.We have checked the disk usage details for the backend machine PRD-WW2_6(i-01ac95c23ac66a40e). By looking into the last one day graph we could see the maximum volume usage for the root device was 32% (Attached the graph for the reference).  Please confirm the instance which you have resolved the root partition storage reached to 100%. Please let verify the details and let us know if you have any queries.","We could also see from event logs during the time of alert log rotation was running: Sep 21 16:41:43 ip-10-59-101-6 kernel: [23855]     0 23855    91898     1960   0       0             0 httpdSep 21 16:41:43 ip-10-59-101-6 kernel: [23857]     0 23857     7961      182   0       0             0 rotatelogsSep 21 16:41:43 ip-10-59-101-6 kernel: [23858]     0 23858     7961      182   5       0             0 rotatelogsWe also didn't receive any datadog alert for high disk usage.The Host shows the root volume to have been below 32% the entire day:https://app.datadoghq.com/dash/host/324510931?live=true&from_ts=1537385227232&to_ts=1537558027232&page=0&is_auto=false&tile_size=m&fullscreen=e4da3bPlease do more analysis on this, if we could verify the root volume had hit 100%","Team,We have only one instance behind the ELB NewPreview-ELBCurrently the disk is on 27% utilization Filesystem            Size  Used Avail Use% Mounted on/dev/xvda1             50G   13G   35G  27% /tmpfs                  16G     0   16G   0% /dev/shm10.59.100.125:/exports_production/files.spendhq.com                     2.0T  853G  1.1T  45% /var/www/vhosts/files.spendhq.comWe also checked on the Log rotation and it was enabled.sudo cat /etc/cron.daily/logrotate#!/bin/sh/usr/sbin/logrotate /etc/logrotate.confEXITVALUE=$?if [ $EXITVALUE != 0 ]; then   /usr/bin/logger -t logrotate ALERT exited abnormally with [$EXITVALUE]fiexit 0","Hello Jason,We will check internally and will let you know the details.","Jason Bray <jbray@spendhq.com>10:24 PM (1 hour ago)to Allen, Rean, spendhq-support@reancloud.comWhat can be done to automate this so we don’t run into this issue as we move ahead?","Hello Allen,Thanks for the update.We also identified Spikes in Latency, Request Count and HTTP 4xx response code ELB metrics that lasted for 2 minutes, from 16:18 UTC to 16:20 UTC.At the time the Average Latency peaked to 125,389.189587 milliseconds while the request count had hit 1,134 requests.Checking on the backend Instance Cloudwatch metrics, everything looked normal. Please find the ELB Latency, Request Count Cloudwatch Metrics below:",Im fairly sure its because of the root partition storage reaching 100%. I resolved itAllen Herrera.,"Sent Mail to Leads:Hi Leads,We have encountered a P1 issue. Below are the details of the issue,Customer Name: SpendHQOpen date/time:  Fri, 21 Sep 2018 12:16:03 -0400Issue Summary/Details:  We received a site down alert on the URL https://secure.spendhq.com/login which lasted for 4 minutesOwner : Rafi RameshStatus : In ProgressAction/s Taken : Informed customer of Site down alert.Regards,Paul MulonziaREĀN Cloud | Reach, Engage, Āctivate, Nurtur","Hello Team,This is to inform that you that we got a site down alert for URL https://secure.spendhq.com/login  and site up and serving well.total violation: 4 minuteswe are analyzing the issue and get back to you with an update.Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001deKSy,Cloud Engineer Level 1,Closed,1106771,Incident,29-10-2018 13:21,,"Hello Team,Greetings!!!We received an alert regarding Postfix Process is down - prd-ww1_122 - 10.59.100.122 and we have shared our analysis below.We have checked logs and found that the Postfix mail was stopped and restarted at 18:13:02 UTC leading to the alert. Oct 25 18:13:02 ip-10-59-100-122 postfix/master[1966]: terminating on signal 15 Oct 25 18:14:42 ip-10-59-100-122 postfix/postfix-script[1920]: starting the Postfix mail system Oct 25 18:14:42 ip-10-59-100-122 postfix/master[1921]: daemon started -- version 2.6.6, configuration /etc/postfix Except for Network IN spikes at the time of the alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors. And this led to status check failure of the instance PRD-WW1_122 .Please refer more details on Ticket no:01106769. We keep monitoring the alerts and keep you posted the updates.As of now, we are marking this case as closed###Hello Team, We haven't heard back from you regarding the alert of Postfix Process is down - prd-ww1_122 - 10.59.100.122 - web,From our analysis, we could see the Postfix mail system was stopped and restarted at 18:13:02 UTC leading to the alert. Oct 25 18:13:02 ip-10-59-100-122 postfix/master[1966]: terminating on signal 15 Oct 25 18:14:42 ip-10-59-100-122 postfix/postfix-script[1920]: starting the Postfix mail system Oct 25 18:14:42 ip-10-59-100-122 postfix/master[1921]: daemon started -- version 2.6.6, configuration /etc/postfix Except for Network IN spikes at the time of the alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors. You can also refer to the related Status Check Failed case 01106769 for additional info. Please review these details and let us know if you have any questions. Thanks.###Hello Team,From our analysis we could see the Postfix mail system was stopped and restarted at 18:13:02 UTC leading to the alert.Oct 25 18:13:02 ip-10-59-100-122 postfix/master[1966]: terminating on signal 15Oct 25 18:14:42 ip-10-59-100-122 postfix/postfix-script[1920]: starting the Postfix mail systemOct 25 18:14:42 ip-10-59-100-122 postfix/master[1921]: daemon started -- version 2.6.6, configuration /etc/postfixExcept for Network IN spikes at the time of alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors.You can also refer to the related Status Check Failed case 01106769 for additional info.Please review these details and let us know if you have any questions.Thanks.###Hello Team, This is to notify you that we received an alert regarding Postfix Process is down - prd-ww1_122 - 10.59.100.122. The alert is recovered and in OK state. The violation lasted 2 minutes.We are looking into this issue and will get back to you with the updates. Resource Details: ------------------------------------------------------------------------------------------- Instance Name: PRD-WW1_122 Instance ID: i-0ace70ce06368e4a7 Instance Type: r4.2xlarge Private IP: 10.59.100.122 VPC ID: vpc-76df7212 Subnet ID: subnet-0d093d27 Availability Zone: us-east-1b -------------------------------------------------------------------------------------------- Thanks.","*Mr. Stephen Oduor Otieno**Junior Cloud Engineer**REĀN Cloud. **stephen.oduor@reancloud.com <stephen.oduor@reancloud.com> |www.reancloud.com <http://www.reancloud.com>**AWS SysOps-Admin Associate Certified*---------- Forwarded message ---------From: Datadog Alerting <alert@dtdg.co>Date: Thu, Oct 25, 2018 at 9:16 PMSubject: [Monitor Alert] Triggered: [SpendHQ] Postfix Process is down -prd-ww1_122 - 10.59.100.122 - web onprocess:postfix,host:i-0ace70ce06368e4a7To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {host:i-0ace70ce06368e4a7,process:postfix}] [SpendHQ] PostfixProcess is down - prd-ww1_122 - 10.59.100.122 - webPostfix Process is down @ms@reancloud.com<https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>PROCS CRITICAL: 0 processes found for postfixThe monitor was last triggered at Thu Oct 25 2018 18:16:00 UTC (*6 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2014439?group=host%3Ai-0ace70ce06368e4a7%2Cprocess%3Apostfix>]· [Edit Monitor <https://app.datadoghq.com/monitors#2014439/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?filter=i-0ace70ce06368e4a7>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CASC&to_ts=1540491480000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1540490460000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4634345214186135714>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","[Monitor Alert] Triggered: [SpendHQ] Postfix Process is down - prd-ww1_122 - 10.59.100.122 - web on process:postfix,host:i-0ace70ce06368e4a7",,26-10-2018 00:00,85,0,SpendHQ,"Hello Team,Greetings!!!We received an alert regarding Postfix Process is down - prd-ww1_122 - 10.59.100.122 and we have shared our analysis below.We have checked logs and found that the Postfix mail was stopped and restarted at 18:13:02 UTC leading to the alert. Oct 25 18:13:02 ip-10-59-100-122 postfix/master[1966]: terminating on signal 15 Oct 25 18:14:42 ip-10-59-100-122 postfix/postfix-script[1920]: starting the Postfix mail system Oct 25 18:14:42 ip-10-59-100-122 postfix/master[1921]: daemon started -- version 2.6.6, configuration /etc/postfix Except for Network IN spikes at the time of the alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors. And this led to status check failure of the instance PRD-WW1_122 .Please refer more details on Ticket no:01106769. We keep monitoring the alerts and keep you posted the updates.As of now, we are marking this case as closed","Hello Team, We haven't heard back from you regarding the alert of Postfix Process is down - prd-ww1_122 - 10.59.100.122 - web,From our analysis, we could see the Postfix mail system was stopped and restarted at 18:13:02 UTC leading to the alert. Oct 25 18:13:02 ip-10-59-100-122 postfix/master[1966]: terminating on signal 15 Oct 25 18:14:42 ip-10-59-100-122 postfix/postfix-script[1920]: starting the Postfix mail system Oct 25 18:14:42 ip-10-59-100-122 postfix/master[1921]: daemon started -- version 2.6.6, configuration /etc/postfix Except for Network IN spikes at the time of the alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors. You can also refer to the related Status Check Failed case 01106769 for additional info. Please review these details and let us know if you have any questions. Thanks.","Hello Team,From our analysis we could see the Postfix mail system was stopped and restarted at 18:13:02 UTC leading to the alert.Oct 25 18:13:02 ip-10-59-100-122 postfix/master[1966]: terminating on signal 15Oct 25 18:14:42 ip-10-59-100-122 postfix/postfix-script[1920]: starting the Postfix mail systemOct 25 18:14:42 ip-10-59-100-122 postfix/master[1921]: daemon started -- version 2.6.6, configuration /etc/postfixExcept for Network IN spikes at the time of alert, all other CloudWatch metrics looked normal. We suspect this may be related to the Status check failed issue where multiple processes were killed by TERM signal. Please refer to the attachment for related Kernel errors.You can also refer to the related Status Check Failed case 01106769 for additional info.Please review these details and let us know if you have any questions.Thanks.","Hello Team, This is to notify you that we received an alert regarding Postfix Process is down - prd-ww1_122 - 10.59.100.122. The alert is recovered and in OK state. The violation lasted 2 minutes.We are looking into this issue and will get back to you with the updates. Resource Details: ------------------------------------------------------------------------------------------- Instance Name: PRD-WW1_122 Instance ID: i-0ace70ce06368e4a7 Instance Type: r4.2xlarge Private IP: 10.59.100.122 VPC ID: vpc-76df7212 Subnet ID: subnet-0d093d27 Availability Zone: us-east-1b -------------------------------------------------------------------------------------------- Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eOq2l,Cloud Engineer Level 1,Closed,1107375,Incident,09-11-2018 05:15,,"Hello Team, This is to notify you that we have received a high CPU Utilization alert on the host SpendHQ-memsql-server2-2018-04-01 in us-east-1 region. On checking, we identified the memsqld process to be consuming high CPU. Please refer to the screenshot attached below. The alert lasted for 8 minutes and the got recovered. Please let us know if you have any queries. Thanks. Resource Details: Instance ID:	i-0382b753fdc5a21bd		Instance Name:	SpendHQ-memsql-server2-2018-04-01	Instance Type: i3.8xlarge	Availability Zone:	us-east-1b	Region:	us-east-1 Subnet:	subnet-0d093d27	VPC:	vpc-76df7212 Private IP Address:   10.59.100.171","[image: Datadog][Triggered] [SpendHQ] - High CPU Utilization on the hostspendhq-memsql-server2-2018-04-01 - 10.59.100.171 -High CPU Utilization on the host. Log in to the machine and verify whichprocess is consuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024189?to_ts=1541718919000&group=host%3Ai-0382b753fdc5a21bd&from_ts=1541711719000>avg(last_30m):avg:system.cpu.stolen{datadog_monitor:on} by {host} +avg:system.cpu.user{datadog_monitor:on} by {host} +avg:system.cpu.system{datadog_monitor:on} by {host} > 85The monitor was last triggered at Thu Nov 08 2018 23:15:29 UTC (*4 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024189?group=host%3Ai-0382b753fdc5a21bd>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024189/edit>] · [Viewi-0382b753fdc5a21bd<https://app.datadoghq.com/infrastructure?filter=i-0382b753fdc5a21bd>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1541719049000&tags=host%3Ai-0382b753fdc5a21bd&from_ts=1541718029000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4654940368265588220>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Paul MulonziaREĀN Cloud | Reach, Engage, Āctivate, Nurtur--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on the host spendhq-memsql-server2-2018-04-01 - 10.59.100.171 -,,09-11-2018 05:12,1,0,SpendHQ,"Hello Team, This is to notify you that we have received a high CPU Utilization alert on the host SpendHQ-memsql-server2-2018-04-01 in us-east-1 region. On checking, we identified the memsqld process to be consuming high CPU. Please refer to the screenshot attached below. The alert lasted for 8 minutes and the got recovered. Please let us know if you have any queries. Thanks. Resource Details: Instance ID:	i-0382b753fdc5a21bd		Instance Name:	SpendHQ-memsql-server2-2018-04-01	Instance Type: i3.8xlarge	Availability Zone:	us-east-1b	Region:	us-east-1 Subnet:	subnet-0d093d27	VPC:	vpc-76df7212 Private IP Address:   10.59.100.171",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G0000159vCS,Cloud Engineer Level 1,Closed,1038428,Incident,13-12-2016 04:38,,"Hello Matthew,Thank you.At this time we are marking this case as resolved. However, if you are still facing any issues we want to hear back from you. Thanks.###Thank you.###Hello Matthew,We have changed the ISCSI initiator name on PRD-DB5 (10.59.10.135) Server.The old ISCSI initiator name on PRD-DB5 (10.59.10.135) is InitiatorName=iqn.1994-05.com.redhat:64d02cf6d2ce and it is changed to InitiatorName=iqn.1994-05.com.redhat:64d02cf7e3dfPlease let us know if you are facing any issues with it.###Yes please work on resolving this on this machine only.###Hello Matthew,The above issue is caused due to the identical name of  iscsi initiators. while we checked the logs we could find the below errorsDec 12 09:59:58 ip-10-59-10-91 iscsid: Kernel reported iSCSI connection 2:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Dec 12 09:59:58 ip-10-59-10-91 iscsid: Kernel reported iSCSI connection 4:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)This means that when the server which tried to access the iscsi device  it will look for the initiator name and so if two instances tried to access the iscsi device  the both will access using the initiator names at the same time. In that case, at a time one instance is able to connect the device and other will get the 1020 error means that the target disconnected from us (disconnected tcp/ip connection).To fix the issue, we need to modify the iSCSI initiator names so that each host has a unique initiator names. All hosts accessing iSCSI LUNs must have unique initiator names.Please let us know your thought regarding this.###Hello Matthew,We will look into this issue and will get back to you with updates.","We are getting the following output on the command line of the PRD-DB5 (10.59.10.135) Server;Message from syslogd@ip-10-59-10-91 at Dec 12 15:53:35 ...iscsid:Message from syslogd@ip-10-59-10-91 at Dec 12 16:07:30 ...iscsid:Message from syslogd@ip-10-59-10-91 at Dec 12 16:14:49 ...iscsid:Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",ISCSI Messages,,12-12-2016 21:53,7,0,SpendHQ,"Hello Matthew,Thank you.At this time we are marking this case as resolved. However, if you are still facing any issues we want to hear back from you. Thanks.",Thank you.,"Hello Matthew,We have changed the ISCSI initiator name on PRD-DB5 (10.59.10.135) Server.The old ISCSI initiator name on PRD-DB5 (10.59.10.135) is InitiatorName=iqn.1994-05.com.redhat:64d02cf6d2ce and it is changed to InitiatorName=iqn.1994-05.com.redhat:64d02cf7e3dfPlease let us know if you are facing any issues with it.",Yes please work on resolving this on this machine only.,"Hello Matthew,The above issue is caused due to the identical name of  iscsi initiators. while we checked the logs we could find the below errorsDec 12 09:59:58 ip-10-59-10-91 iscsid: Kernel reported iSCSI connection 2:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)Dec 12 09:59:58 ip-10-59-10-91 iscsid: Kernel reported iSCSI connection 4:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3)This means that when the server which tried to access the iscsi device  it will look for the initiator name and so if two instances tried to access the iscsi device  the both will access using the initiator names at the same time. In that case, at a time one instance is able to connect the device and other will get the 1020 error means that the target disconnected from us (disconnected tcp/ip connection).To fix the issue, we need to modify the iSCSI initiator names so that each host has a unique initiator names. All hosts accessing iSCSI LUNs must have unique initiator names.Please let us know your thought regarding this.","Hello Matthew,We will look into this issue and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EVVMM,Cloud Engineer Level 1,Closed,1068292,Incident,16-07-2017 21:49,,"Hello SpendHQ Team,Team as discussed over call since you are performing some activity from your end. As of know  we are marking this case as resolved###Hello SpendHQ Team, This is to notify you that we have received a MySQL Process Down alert for prod-sphq-db-server05 instance. Later the alert got resolved automatically within a minute. We are investigating the alert and meanwhile let us know if your team is performing any activity from your end.","[Triggered on {host:10.59.10.135,process:mysql}] [SpendHQ] MySQL Process is down - prod-sphq-db-server05  - 10.59.10.135 - db  MySQL Process is down @support@reancloud.com     @support@reancloud.comPROCS CRITICAL: 0 processes found for mysqlThis alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2014430?group=host%3A10.59.10.135%2Cprocess%3Amysql · Edit Monitor: https://app.datadoghq.com/monitors#2014430/edit · Event URL: https://app.datadoghq.com/event/event?id=3958628026929361956 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","[Monitor Alert] Triggered: [SpendHQ] MySQL Process is down - prod-sphq-db-server05 - 10.59.10.135 - db on process:mysql,host:10.59.10.135",,16-07-2017 20:01,2,0,SpendHQ,"Hello SpendHQ Team,Team as discussed over call since you are performing some activity from your end. As of know  we are marking this case as resolved","Hello SpendHQ Team, This is to notify you that we have received a MySQL Process Down alert for prod-sphq-db-server05 instance. Later the alert got resolved automatically within a minute. We are investigating the alert and meanwhile let us know if your team is performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001GHa0i,Cloud Engineer Level 1,Closed,1074087,Incident,21-08-2017 22:45,,"Matthew requested to revert back the changes and call him. We are following this on 01074094###Hello Allen,This request has been completed. However while checking, we could see a maintenance page. Please find the attached screenshot and let us know if this is the expected outcome.###Hello SpendHQ Team,We will work on this request and will get back to you with the updates.","Can we remove 10.59.100.122  and 10.59.101.6 from the preview ELB and add 10.59.100.170 to the preview.spendhq.com elb  ASAP.Allen Herrera | Developer | SpendHQ(r)M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Update Preview.spendhq.com ELB with 10.59.100.170,,21-08-2017 19:25,3,0,SpendHQ,Matthew requested to revert back the changes and call him. We are following this on 01074094,"Hello Allen,This request has been completed. However while checking, we could see a maintenance page. Please find the attached screenshot and let us know if this is the expected outcome.","Hello SpendHQ Team,We will work on this request and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EU9i3,Cloud Engineer Level 1,Closed,1067525,Incident,15-07-2017 00:25,,"Hello SpendHQ,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM###Hello SpendHQ Team,This is a gentle reminder.Please review the RCA shared by our team and let us know if you have any more queries.###Next action: send reminder in evening shift###Hello SpendHQ Team, We have prepared the RCA for the outage happened on 12/7/2017. Please find the RCA in the attachment section and let us know if you have any queries.###Shared the RCA with Praveen for review.###Yogesh has reviewed the RCA, Updated to check with Praveen once on recommendation part before sending to the customer.Next action: check with Praveen.###I have prepared the RCA document and shared with Yogesh for review and adding recommendation.https://reancloud.atlassian.net/browse/MSL1T-832Next Action: Afternoon shift, check with yogesh.###Hi Matthew,Thanks for the information.We will work on the RCA document and will share it with you shortly.###Matthew Updated.Of course. The cache in redis had to be flushed as PRD was reading inaccurate data Sent from my iPhone###Hi Matthew,Can you please provide a note of details which you have performed to resolve this issue, so that we can prepare an RCA document and will share with you shortly.###Matthew Updated,This has been resolved###Hi Matthew,Please join the below Bride for a quick discussion on this issue.https://zoom.us/j/9199305073###Hi Andrew/ Mattew,We tried to contact over a call but you were not available. The URL's https://secure.spendhq.com/login and https://preview.spendhq.com/login are loading but not showing a proper login page.Please find the below error while we trying to load the web page.Missing Database TableError: Database table view_template for model LigerView was not found.From webserver logs, we couldn't find any errors, it seems like an issue with database.Please let us know anyone from your team made this database change and find the attached screenshot for more details.###Matthew updated,We are not experiencing this error on Secure.###Hello Team,On checking we could see that change was made to database from error as shown below:Missing Database TableError: Database table view_template for model LigerView was not found.Please let us know if this change was performed from your end.###Hello Team,This is to inform you that we are getting the site down alert again and is getting resolved automatically.While accessing the URL https://secure.spendhq.com/login the site is loading fine but while accessing the URL https://preview.spendhq.com/login the page is loading fine but we could see some error in the page itself.Please find the error observed below:Warning (2): pg_connect(): Unable to connect to PostgreSQL server: server closed the connection unexpectedly	This probably means the server terminated abnormally	before or while processing the request. [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 119]Warning (2): pg_set_client_encoding() expects parameter 1 to be resource, boolean given [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 867]Warning (2): Cannot modify header information - headers already sent by (output started at /var/www/vhosts/secure.spendhq.com/public/cake/libs/debugger.php:686) [APP/views/layouts/v5.ctp, line 1]Warning (2): Cannot modify header information - headers already sent by (output started at /var/www/vhosts/secure.spendhq.com/public/cake/libs/debugger.php:686) [APP/views/layouts/v5.ctp, line 7]Please let us know if you have performed any activity on this. We are analyzing more on the issue.###Hello Team,This is to notify you that we have received site down alert for the URLs https://preview.spendhq.com/login and https://secure.spendhq.com/login. We are not able to access the sites. We are looking into this and will let you know the updates. Meanwhile, please let us know if your team is performing any activity from your end.","Tue, 11 Jul 2017 20:13:05 -0400Detected Error on SpendHQEstimated Downtime: 2 minutes https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: --------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): California US, Dallas-B US, Atlanta-B US, Frankfurt DE-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,12-07-2017 05:43,67,0,SpendHQ,"Hello SpendHQ,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Safuvan KM","Hello SpendHQ Team,This is a gentle reminder.Please review the RCA shared by our team and let us know if you have any more queries.",Next action: send reminder in evening shift,"Hello SpendHQ Team, We have prepared the RCA for the outage happened on 12/7/2017. Please find the RCA in the attachment section and let us know if you have any queries.",Shared the RCA with Praveen for review.,"Yogesh has reviewed the RCA, Updated to check with Praveen once on recommendation part before sending to the customer.Next action: check with Praveen.","I have prepared the RCA document and shared with Yogesh for review and adding recommendation.https://reancloud.atlassian.net/browse/MSL1T-832Next Action: Afternoon shift, check with yogesh.","Hi Matthew,Thanks for the information.We will work on the RCA document and will share it with you shortly.",Matthew Updated.Of course. The cache in redis had to be flushed as PRD was reading inaccurate data Sent from my iPhone,"Hi Matthew,Can you please provide a note of details which you have performed to resolve this issue, so that we can prepare an RCA document and will share with you shortly.","Matthew Updated,This has been resolved","Hi Matthew,Please join the below Bride for a quick discussion on this issue.https://zoom.us/j/9199305073","Hi Andrew/ Mattew,We tried to contact over a call but you were not available. The URL's https://secure.spendhq.com/login and https://preview.spendhq.com/login are loading but not showing a proper login page.Please find the below error while we trying to load the web page.Missing Database TableError: Database table view_template for model LigerView was not found.From webserver logs, we couldn't find any errors, it seems like an issue with database.Please let us know anyone from your team made this database change and find the attached screenshot for more details.","Matthew updated,We are not experiencing this error on Secure.","Hello Team,On checking we could see that change was made to database from error as shown below:Missing Database TableError: Database table view_template for model LigerView was not found.Please let us know if this change was performed from your end.","Hello Team,This is to inform you that we are getting the site down alert again and is getting resolved automatically.While accessing the URL https://secure.spendhq.com/login the site is loading fine but while accessing the URL https://preview.spendhq.com/login the page is loading fine but we could see some error in the page itself.Please find the error observed below:Warning (2): pg_connect(): Unable to connect to PostgreSQL server: server closed the connection unexpectedly	This probably means the server terminated abnormally	before or while processing the request. [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 119]Warning (2): pg_set_client_encoding() expects parameter 1 to be resource, boolean given [CORE/cake/libs/model/datasources/dbo/dbo_postgres.php, line 867]Warning (2): Cannot modify header information - headers already sent by (output started at /var/www/vhosts/secure.spendhq.com/public/cake/libs/debugger.php:686) [APP/views/layouts/v5.ctp, line 1]Warning (2): Cannot modify header information - headers already sent by (output started at /var/www/vhosts/secure.spendhq.com/public/cake/libs/debugger.php:686) [APP/views/layouts/v5.ctp, line 7]Please let us know if you have performed any activity on this. We are analyzing more on the issue.","Hello Team,This is to notify you that we have received site down alert for the URLs https://preview.spendhq.com/login and https://secure.spendhq.com/login. We are not able to access the sites. We are looking into this and will let you know the updates. Meanwhile, please let us know if your team is performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013vuai,Cloud Engineer Level 1,Closed,1030973,Incident,12-11-2016 13:10,,"Team,It was because of maintenance.","WebAdmin webserver not running - restarted-- System Uptime      : 0 days 0 hours 3 minutesSystem Load        : 0.87System Version     : Sophos UTM 9.403-4Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][INFO-107] WebAdmin webserver not running - restarted,,12-11-2016 13:05,0,0,SpendHQ,"Team,It was because of maintenance.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001J3uCh,Cloud Engineer Level 1,Closed,1082802,Incident,23-10-2017 23:44,,"Hello Allen,We have disabled the maintenance. At this time we are marking this case as resolved.###Hello Allen,Thanks for the update. We have enabled maintenance mode for preview.spendhq.com.###This was me doing internal testing. Can we put preview.spendhq.com on maintenance mode for the next hour. Allen Herrera | Developer | SpendHQ®###Hello SpendHQ-team, This is to notify you that we have received a site down alert for the URL: https://preview.spendhq.com/login. Later the alert got resolved and the site is accessible now. The violation lasted for  7 minutes 59 seconds. We are investigating the alert and meanwhile let us know if you are performing any activity from your end.","Mon, 23 Oct 2017 10:18:28 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: Atlanta-B USConfirmed by node(s): Frankfurt DE, Sydney-C AU, California US, London UK--  <https://www.reancloud.com/>   - REAN Cloud among CISPs mentioned in Gartner report on successful cloud    migration projects    <https://www.reancloud.com/blog/rean-cloud-gartner-report-run-successful-cloud-implementation-project-varying-scale-maturity/>   - Automate AWS account security assessment with REAN Cloud    <https://www.reancloud.com/consolidate-aws-account/>   - Boost business availability with REAN Enterprise Managed Services    <https://www.reancloud.com/managed-services-campaign/>   - Boost the speed of your research on cloud from day one    <https://www.reancloud.com/launch-science-on-cloud/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,23-10-2017 19:48,4,0,SpendHQ,"Hello Allen,We have disabled the maintenance. At this time we are marking this case as resolved.","Hello Allen,Thanks for the update. We have enabled maintenance mode for preview.spendhq.com.",This was me doing internal testing. Can we put preview.spendhq.com on maintenance mode for the next hour. Allen Herrera | Developer | SpendHQ®,"Hello SpendHQ-team, This is to notify you that we have received a site down alert for the URL: https://preview.spendhq.com/login. Later the alert got resolved and the site is accessible now. The violation lasted for  7 minutes 59 seconds. We are investigating the alert and meanwhile let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001b0pC5,Cloud Engineer Level 1,Closed,1103706,Incident,03-09-2018 07:26,,"Hello Team,We have verified the resources for which emergency maintenance is scheduled and found that the connection dxcon-fg8t61ol AWS Direct Connect router in Equinix DC2/DC11 was created for a testing purpose and we are not using this. The current state of this connection is already down. Therefore it will not affect the production environment hence closing this case.###Hello Team, This is to inform you that we received notification from AWS stating Emergency maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 10Gbps may become unavailable. Connection name: SpendHQ Connection ID:  dxcon-fg8t61olYour Peer IP: 169.254.255.50/30Amazon Peer IP: 169.254.255.49/30AWS Scheduled Maintenance Window:- Start time September 3, 2018 at 8:31:00 AM UTC+5:30 End time September 3, 2018 at 12:31:00 PM UTC+5:30AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same","Emergency maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. This maintenance will cause a disruption to your Direct Connect connections associated with this event.If you have configured your service to use redundant Direct Connect connections, then alternate connections will be available for the duration of the maintenance. For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Santa Clara Convention Center - Santa Clara, CA24th Oct, 2018 <http://go.reancloud.com/santa-clara-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_EMERGENCY_MAINTENANCE_SCHEDULED,,03-09-2018 05:39,2,0,SpendHQ,"Hello Team,We have verified the resources for which emergency maintenance is scheduled and found that the connection dxcon-fg8t61ol AWS Direct Connect router in Equinix DC2/DC11 was created for a testing purpose and we are not using this. The current state of this connection is already down. Therefore it will not affect the production environment hence closing this case.","Hello Team, This is to inform you that we received notification from AWS stating Emergency maintenance has been scheduled on an AWS Direct Connect router in Equinix DC2/DC11, Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 10Gbps may become unavailable. Connection name: SpendHQ Connection ID:  dxcon-fg8t61olYour Peer IP: 169.254.255.50/30Amazon Peer IP: 169.254.255.49/30AWS Scheduled Maintenance Window:- Start time September 3, 2018 at 8:31:00 AM UTC+5:30 End time September 3, 2018 at 12:31:00 PM UTC+5:30AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DBER8,Cloud Engineer Level 1,Closed,1061913,Incident,12-06-2017 20:00,,"Need to create a ticket for Yogesh and review last 2 weeks intrusion prevention alerts. As the team is not using Apache structs we can add skip rule entry in Sophos.###Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 which belongs to the Preview ELB. On further analysis, We have found the following details from the logs: Name: Intrusion protection alert Action: Drop Reason: SERVER-APACHE Apache Struts remote code execution attempt Class: Attempted Administrator Privilege Gain Source IP Destination IP Port Mapping: 10.59.5.111:17309 ==> 10.59.1.192: 8080Please find the ELB logs below for more details and let us know if you have any queriesIP: 93.174.93.136Location: VictoriaOrganisation: Novogara LTDIP Reputation Risk: medium2017-06-12T05:24:42.220486Z,preview-spendhq-xelb,93.174.93.136,42686,10.59.1.192,8080,0.000044,0.001416,0.000019,403,403,0,232,GET http://www.baidu.com:8080/cache/global/img/gs.gif HTTP/1.1,Mozilla,-,-IP: 60.191.38.77Location: HangzhouOrganisation: CHINANET-ZJ Hangzhou node networkIP Reputation Risk: medium2017-06-12T05:44:05.344032Z,preview-spendhq-xelb,60.191.38.77,37067,10.59.1.192,80,0.000036,0.00212,0.00002,403,403,0,209,GET http://52.6.177.194:80/ HTTP/1.1,Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:47.0) Gecko/20100101 Firefox/47.0,-,-2017-06-12T06:15:09.664586Z,preview-spendhq-IP: 81.35.179.245Location: 	TokyoOrganisation: Linode, LLCIP Reputation Risk: mediumxelb,139.162.106.181,42182,10.59.1.192,443,0.000054,0.001544,0.00002,403,403,0,209,GET https://52.6.177.194:443/ HTTP/1.1,Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36,TLSv1.2,ECDHE-RSA-AES128-GCM-SHA256IP: 81.35.179.245Location: 		Pilona(Spain)Organisation: Telefonica de Espana SauIP Reputation Risk: medium2017-06-12T06:38:55.989051Z,preview-spendhq-xelb,81.35.179.245,37970,10.59.1.192,80,0.000035,0.001964,0.000023,403,403,0,209,GET http://52.4.199.57:80/ HTTP/1.1,Mozilla/5.0 zgrab/0.x,-,-###As we don't see any elb logs related to this, we need to raise a support case with Sophos and figure out the root cause. if this is a false positive, we have to avoid this alerts and avoid sending unwanted noise to the customer. Please raise the support case.###Hello SpendHQ-Team,This is to inform you that we received another Intrusion Prevention Alert from Sophos and source IP address 10.59.1.167 which belong to the Preview ELB.Please find the IPS logs from Sophos2017:06:11-09:13:28 spendhq snort[4258]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=56768 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are analyzing the ELB logs and will let you know the further updates.###Hello Team,On further analysis, We have found the following details from the logs:Name:   Intrusion protection alertAction: DropReason:  SERVER-APACHE Apache Struts remote code execution attempt  Class:  Attempted Administrator Privilege Gain Source IP                          Destination IP Port Mapping:10.59.5.111:34437 ==> 10.59.1.192:802017:06:10-16:59:43 spendhq snort[4239]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.111 dstip=10.59.1.192 proto=6 srcport=34437 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0###Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-06-10 16:59:43Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.5.111Source port: 34437Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http),[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,10-06-2017 23:55,55,0,SpendHQ,Need to create a ticket for Yogesh and review last 2 weeks intrusion prevention alerts. As the team is not using Apache structs we can add skip rule entry in Sophos.,"Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 which belongs to the Preview ELB. On further analysis, We have found the following details from the logs: Name: Intrusion protection alert Action: Drop Reason: SERVER-APACHE Apache Struts remote code execution attempt Class: Attempted Administrator Privilege Gain Source IP Destination IP Port Mapping: 10.59.5.111:17309 ==> 10.59.1.192: 8080Please find the ELB logs below for more details and let us know if you have any queriesIP: 93.174.93.136Location: VictoriaOrganisation: Novogara LTDIP Reputation Risk: medium2017-06-12T05:24:42.220486Z,preview-spendhq-xelb,93.174.93.136,42686,10.59.1.192,8080,0.000044,0.001416,0.000019,403,403,0,232,GET http://www.baidu.com:8080/cache/global/img/gs.gif HTTP/1.1,Mozilla,-,-IP: 60.191.38.77Location: HangzhouOrganisation: CHINANET-ZJ Hangzhou node networkIP Reputation Risk: medium2017-06-12T05:44:05.344032Z,preview-spendhq-xelb,60.191.38.77,37067,10.59.1.192,80,0.000036,0.00212,0.00002,403,403,0,209,GET http://52.6.177.194:80/ HTTP/1.1,Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:47.0) Gecko/20100101 Firefox/47.0,-,-2017-06-12T06:15:09.664586Z,preview-spendhq-IP: 81.35.179.245Location: 	TokyoOrganisation: Linode, LLCIP Reputation Risk: mediumxelb,139.162.106.181,42182,10.59.1.192,443,0.000054,0.001544,0.00002,403,403,0,209,GET https://52.6.177.194:443/ HTTP/1.1,Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36,TLSv1.2,ECDHE-RSA-AES128-GCM-SHA256IP: 81.35.179.245Location: 		Pilona(Spain)Organisation: Telefonica de Espana SauIP Reputation Risk: medium2017-06-12T06:38:55.989051Z,preview-spendhq-xelb,81.35.179.245,37970,10.59.1.192,80,0.000035,0.001964,0.000023,403,403,0,209,GET http://52.4.199.57:80/ HTTP/1.1,Mozilla/5.0 zgrab/0.x,-,-","As we don't see any elb logs related to this, we need to raise a support case with Sophos and figure out the root cause. if this is a false positive, we have to avoid this alerts and avoid sending unwanted noise to the customer. Please raise the support case.","Hello SpendHQ-Team,This is to inform you that we received another Intrusion Prevention Alert from Sophos and source IP address 10.59.1.167 which belong to the Preview ELB.Please find the IPS logs from Sophos2017:06:11-09:13:28 spendhq snort[4258]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=56768 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are analyzing the ELB logs and will let you know the further updates.","Hello Team,On further analysis, We have found the following details from the logs:Name:   Intrusion protection alertAction: DropReason:  SERVER-APACHE Apache Struts remote code execution attempt  Class:  Attempted Administrator Privilege Gain Source IP                          Destination IP Port Mapping:10.59.5.111:34437 ==> 10.59.1.192:802017:06:10-16:59:43 spendhq snort[4239]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.5.111 dstip=10.59.1.192 proto=6 srcport=34437 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0","Hello SpendHQ-Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.5.111 which belongs to the Preview ELB. We are analyzing the ELB logs and IPS logs will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VrjAj,Cloud Engineer Level 1,Closed,1098318,Incident,09-05-2018 12:32,,The issue got resolved and hence closing this case###I am not sure about this case.Need to check with Yogesh.,"Regards,*Yogesh Maloo**Senior Cloud Engineer,**REĀN Cloud **Mobile*: +918003126272 | *Skype*: ykmalooyogesh.maloo@reancloud.com | www.reancloud.com<http://twitter.com/ykmaloo> <http://us.linkedin.com/in/ykmaloo><http://facebook.com/ykmaloo><http://github.com/ykmaloo>On Tue, May 8, 2018 at 7:36 PM, Andrew Kim <Akim@spendhq.com> wrote:> We’d like to get the PostGres DB working>>>> *Andrew Kim* | Director of Information Technology & Security | *Spend*> *HQ®*>> O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com>> *A SaaS Spend Visibility solution from Insight Sourcing Group*>> www.spendhq.com | www.insightsourcing.com>>>--  <http://go.reancloud.com/gartner-magic-quadrant>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Can you provide call in number?,,08-05-2018 23:29,13,0,SpendHQ,The issue got resolved and hence closing this case,I am not sure about this case.Need to check with Yogesh.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Dnk6D,Cloud Engineer Level 1,Closed,1065588,Incident,03-07-2017 17:40,,"Hello SpendHQ-Team,We haven't heard back from your team regarding this case.At this time, we are marking this case as resolved. Kindly validate these details and let us know incase f any further queries.Regards,Sumod.K.Bose###Next action: Evening shift: Check we got a reply from Team else send a reminder###Next action: Morning shift: Check we got a reply from Team else send a reminder###Hello Allen,We haven't heard back from you. We have changed the idle timeout configured at ELB level from 60s to 600s. Also ELB logs are not enabled for this ELB, it is recommended to enable ELB level logs so that we can easily figure out these kind of errors. Please let us know if you have any queries regarding this.###Next action: Evening shift: Check we got a reply from Team else send a reminder###Next action: morning shift: Check we got a reply from Team else send a reminder###Hi Allen/ Matthew,We have changed the idle timeout configured at ELB level from 60s to 600s. Please let us know if you are still getting any timeout errors.Note: ELB logs are not enabled for this ELB, it is recommended to enable ELB level logs so that we can easily figure out these kind of errors.Let us know if you need any further information.###Allen updated that.l.spendhq.com Once authenticated into the SpendHQ app, going into explore and build from navigator on a sizable client (mine had 9.2M records) , dragging over subcategory and category results in a 504 error every time exactly 60 seconds after being triggered. We know the postgres database is still running the query as we watched it finish on the database around 80 seconds after being triggered. These navigator explore and build requests are to l.spendhq.com:3000 which then queries our postgres database on 10.59.100.135:5029 Yesterday we confirmed that the Tomcat request/response timeout is greater than 60 seconds (1 hour) and that Logi’s command timeout is greater than 60 seconds.###Is there a request timeout setting that we could raise from 60 seconds to an hour. We keep getting a 504 gateway error on requests that take over 60 seconds. Allen Herrera###Allen – Can you describe what steps lead to the timeout? What (domain?) are you trying to access that’s giving you the 504 error? REAN – Can we globally increase the gateway timeout on the Sophos to 600 seconds? Thanks, Andrew Kim###We haven't received any update from the team. Next action: Please do a follow up in the evening shift.###Next action: Morning shift: Check if we receive any updates from SpendHQ team else send a reminder on Afternoon shift hours.###Hello Allen,We have analyzed last 3 hours of both Secure and Preview ELB logs, webserver logs & modsecurity logs and was not able to figure out any logs related to 504 response code. But we were able to figure out 500, 502 and 503 error logs from Secure ELB and modsecurity logs. Please refer the below attached logs for more details and let us know if you have any queries.###Hello Allen,We will check for 504 errors in the logs and will get back to you with details.","Can you please check all the logs, modsecurity, web server, ELB for 504 errors. Are there command timeouts of 60 seconds blocking requests that we need to come through.*Allen Herrera***| Developer |*Spend**HQ^® *^M: 360-888-3938 | aherrera@spendhq.com <mailto:aherrera@spendhq.com>www.spendhq.com <http://www.spendhq.com/>| /A SaaS Spend Visibility solution from Insight Sourcing Group/-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Please Check the Logs,,29-06-2017 02:31,111,0,SpendHQ,"Hello SpendHQ-Team,We haven't heard back from your team regarding this case.At this time, we are marking this case as resolved. Kindly validate these details and let us know incase f any further queries.Regards,Sumod.K.Bose",Next action: Evening shift: Check we got a reply from Team else send a reminder,Next action: Morning shift: Check we got a reply from Team else send a reminder,"Hello Allen,We haven't heard back from you. We have changed the idle timeout configured at ELB level from 60s to 600s. Also ELB logs are not enabled for this ELB, it is recommended to enable ELB level logs so that we can easily figure out these kind of errors. Please let us know if you have any queries regarding this.",Next action: Evening shift: Check we got a reply from Team else send a reminder,Next action: morning shift: Check we got a reply from Team else send a reminder,"Hi Allen/ Matthew,We have changed the idle timeout configured at ELB level from 60s to 600s. Please let us know if you are still getting any timeout errors.Note: ELB logs are not enabled for this ELB, it is recommended to enable ELB level logs so that we can easily figure out these kind of errors.Let us know if you need any further information.","Allen updated that.l.spendhq.com Once authenticated into the SpendHQ app, going into explore and build from navigator on a sizable client (mine had 9.2M records) , dragging over subcategory and category results in a 504 error every time exactly 60 seconds after being triggered. We know the postgres database is still running the query as we watched it finish on the database around 80 seconds after being triggered. These navigator explore and build requests are to l.spendhq.com:3000 which then queries our postgres database on 10.59.100.135:5029 Yesterday we confirmed that the Tomcat request/response timeout is greater than 60 seconds (1 hour) and that Logi’s command timeout is greater than 60 seconds.",Is there a request timeout setting that we could raise from 60 seconds to an hour. We keep getting a 504 gateway error on requests that take over 60 seconds. Allen Herrera,"Allen – Can you describe what steps lead to the timeout? What (domain?) are you trying to access that’s giving you the 504 error? REAN – Can we globally increase the gateway timeout on the Sophos to 600 seconds? Thanks, Andrew Kim",We haven't received any update from the team. Next action: Please do a follow up in the evening shift.,Next action: Morning shift: Check if we receive any updates from SpendHQ team else send a reminder on Afternoon shift hours.,"Hello Allen,We have analyzed last 3 hours of both Secure and Preview ELB logs, webserver logs & modsecurity logs and was not able to figure out any logs related to 504 response code. But we were able to figure out 500, 502 and 503 error logs from Secure ELB and modsecurity logs. Please refer the below attached logs for more details and let us know if you have any queries.","Hello Allen,We will check for 504 errors in the logs and will get back to you with details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ErUWn,Cloud Engineer Level 1,Closed,1068877,Incident,20-07-2017 01:13,,"Hi SpendHQ-Team,This is to notify you that we have received an alert that memory usage for 	PROD-SPHQ-NFS-SERVER01 instance has exceeded a threshold value of 90% to 95.92%.  Later the alert got resolved and returned to normal with a value of 11%. The violation lasted for 9 minutes.Resource DetailsInstance Name: PROD-SPHQ-NFS-SERVER01Instance ID : i-1426f28bInstance Private IP Address : 10.59.100.125Instance Availability Zone : us-east-1bInstance Type : c4.xlargeVPC ID : vpc-76df7212Subnet ID : subnet-0d093d27","[Triggered] [SpendHQ] - High Memory Utilization Alert on  prod-sphq-nfs-server01 - 10.59.100.125 - nfs  Detected High MEMORY utilization. Log in to the machine and verify which process is consuming high MEMORY resources      @support@reancloud.com`avg(last_5m):( avg:system.mem.used{monitoring:on} by {host} - avg:system.mem.cached{monitoring:on} by {host} ) / avg:system.mem.total{monitoring:on} by {host} * 100 > 90`Metric value: 90.766This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023977?group=host%3Ai-1426f28b · Edit Monitor: https://app.datadoghq.com/monitors#2023977/edit · Event URL: https://app.datadoghq.com/event/event?id=3963272360908860607 · View i-1426f28b: https://app.datadoghq.com/infrastructure?hostname=i-1426f28b-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on prod-sphq-nfs-server01 - 10.59.100.125 - nfs,,20-07-2017 00:55,0,0,SpendHQ,"Hi SpendHQ-Team,This is to notify you that we have received an alert that memory usage for 	PROD-SPHQ-NFS-SERVER01 instance has exceeded a threshold value of 90% to 95.92%.  Later the alert got resolved and returned to normal with a value of 11%. The violation lasted for 9 minutes.Resource DetailsInstance Name: PROD-SPHQ-NFS-SERVER01Instance ID : i-1426f28bInstance Private IP Address : 10.59.100.125Instance Availability Zone : us-east-1bInstance Type : c4.xlargeVPC ID : vpc-76df7212Subnet ID : subnet-0d093d27",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Etl7r,Cloud Engineer Level 2,Closed,1070487,Incident,08-08-2017 15:14,,"Hi SpendHQ Team,Please find the below response from AWS Internal service team where they confirms the degraded hardware was causing the status check failures on the instance:#################################################################################Hello,Sorry for the delay in providing you with an update. So I was able to get a feedback from our internal service team who took a deep dive in finding the health status of the underlying hardware and after a thorough analysis, its confirmed that underlying hardware had issues for which they have now marked it in degraded state so then no new instances will be launched using the same. Which means there is no possibility of having your instances to go on the same faulty hardware as its already marked degraded now. I truly hope that I was able to assist you and in future if you happen to experience similar issues, please feel free to open a case for us and we will be happy to assist you in best possible way.Best regards,Ankit j.Amazon Web Services#################################################################################I hope this answer our queries on why the issue did not happen on the other servers running on the same network driver version. As per the AWS recommendation, REAN MGS Team will submit a plan to update the network driver versions on the all SpendHQ instances.###Hi Team,As discussed in our last biweekly call, we will further work on the network driver update activity across all nodes as a result of this incident.Attaching the incident RCA for your review. let us know if you have any questions. Thank you!###As discussed in the ops call we can close this since AWS already mentioned there is hardware issue. So we are not sharing the RCA.  As a next step based on the SpenHQ biweekly MOM there is an action item to update network driver as shown below: Network Driver Updatea.      Get Inventory of all the resources and their network driver version(Instance Name, Instance ID, IP Address, Driver Version)b.      Andrew/Matthew will provide comments which one needs update because they are planning to terminate few resourcesJira tickets will be created to follow up on the tasks. So we are closing the ticket from here and will be following the action in JIRA ticket.###In the morning call, this was discussed and Yogesh will take care of this.He will follow up with AWS support, make the changes to the RCA and will keep the customer updated with the status every day.###Reply from AWS team.Hello,Thanks for reaching out to AWS Premium Support today.I am sorry for the delay in responding over the email. This is because we experienced a high volume of customer contacts within the period. Just wanted to summarize about our discussed that we had today over chat. You wanted to know what caused your instances to hook them off from the network on 28th of July. From the couple of correspondence happened on this case, the speculation was over the network drivers and could be because of the underlying hardware. For the same, I asked you to start your instance so I can go through the latest console logs in real time. After analyzing those logs I confirmed that the instance was able to pass the health checks after the network was loaded fine by kernel. There wasnt any error reported on the network device so I further looked over to the underlying hardware. From the health stats of your instance I did see the failure on health check happened during the below timings27th July 23:40 - 00:1128th July 14:26 - 15:1128th on 20:41 - 21:11Further, I checked at the underlying hardware that was hosting your instance on that particular date/time, I found there were issues seen at the hardware level. For the same I opened a ticket for my internal service team to investigate further. At this moment, I can not gurantee the expected time around when they will revert but as soon as I get a response from them, I will immediately provide you with the information.Since you already confirmed that at present you are not using that instance as you have launched a new instance that came online on another underlying hardware, you not seeing any issues at the moment. I also informed you about using the recommended and stable version of the network driver as advertised on our public documentation :###Last Worked: SumodLast Action: Support ticket reopened and asked the queries. The network driver instability in the other nodes is not making issues now. AWS conveyed the network driver version may not make issues in every case but it may cause network instability sometimes.Next Action: Convey the same info to the customer champion and wait for the response from AWS support.###+++Internal Comment+++We had a detailed discussion with the AWS Support Team regarding this issue. We have raised two main points related to this issues and they are,1, To check and confirm if there was any kind of underlying hardware issues on this during the time of these outages.AWS Support engineer initially mentioned that everything was fine at the time of these issues and after taking a deeper look, he was able to see that there were uplink issues with the underlying host and he has opened an internal ticket to get that issue fixed locally and will update us once they have any inputs on this case.2, If the issue is with the Network Enhancing Driver, why the clones created from these servers are not having any health check issues? AWS Team replied that, if we are not getting any issues on the other instances then its good but its always advisable to go with the recommendations as the versions are tested well with the kernel versions and tagged as stable. From their conversation, it was clear that they don't have a clear point of clarification.Next Action: Check for further updates from AWS Support Team regarding this case and also share all these updates with the CC. Can refer the chat details on the case for more details.Regards,Sumod.K.Bose###+++Internal Comment+++We have checked with Yogesh for the updates of this case. He mentioned that he needs to follow up with AWS Support team to get further clarification regarding this issue as it has been not been affected with the other clones of this instance.As per the updates from Yogesh, we will be getting in contact with AWS Support Team regarding the progress of this case.Regards,Sumod.K.Bose###The RCA has completed.The URL: https://docs.google.com/a/reansolutionsinc.com/document/d/1xXhYVm1dgPUpplwKo1ktq55cfv-ByTOopGQhn_K4x5c/edit?usp=sharingI have assigned this to Yogesh for review.Next Action: Evening shift: Sync up with Yogesh and get the RCA reviewed. Please send the RCA to the customer once it is reviewed.###Started working on the RCA document. The document is in progresshttps://docs.google.com/a/reansolutionsinc.com/document/d/1xXhYVm1dgPUpplwKo1ktq55cfv-ByTOopGQhn_K4x5c/edit?usp=sharing###Hello SpendHQ Team,We successfully installed the latest version of ixgbevf package which is 4.2.1 to the new node  created from the 10.59.100.79 (AMI ID: ami-a9c6e1d2) and enabled new virtual server configuration in sophos. Since Daniel performed the smoke test for the application and verified everything is working as expected, at this time, we're marking this case as Resolved. However, if you have any further queries on this please revert back to us.###Daniel Mackay7:39 AM (26 minutes ago)to Matthew, Rean, spendhq-support Rean, I am available if / when you need me. Feel free to reach out to me via email or phone – (404) 988-3100. Or I can call in if you provide a number.  Best regards, Dan Mackay | Spend Solutions DBA | SpendHQO: 770-741-0157 | dmackay@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group###Matthew has updated to perform this change on 2/8/2017 9 AM IST (11:30 PM EST) on another ticket.  (I-01071188).Need to call Yogesh and get the deployment plan updated with the steps required.###Hello Matthew,Thanks for the update.We will schedule the change on 10 PM EST hours on Friday and also will share with you the updated deployment plan.###Let us set this to 2200 Hours EST on Friday.Matthew###Hello SpendHQ-Team,We haven't heard back from you.As we have now successfully test installed the latest version of ixgbevf package which is 4.2.1. Please provide us a maintenance window again to perform the changes on the instance: i-0590f342fdc9965bb (PROD-SPHQ-WEB-SERVER03_4th_July_2017). In this case, we will have the downtime for 10-15 min when we will be doing a stop-start only. But the maintenance window needs 1 hour to complete.###Hi SpendHQ Team,As we have now successfully test installed the latest version of ixgbevf package which is 4.2.1. Please provide us a maintenance window again to perform the changes on the instance: i-0590f342fdc9965bb (PROD-SPHQ-WEB-SERVER03_4th_July_2017).In this case, we will have the downtime for 10-15 min when we will be doing a stop-start only. But the maintenance window needs 1 hour to complete.###For Internal Team:We need to delete these resources later:Instance:  i-0c685f4ac31134037 (Test-Enhanched-Networking)The security group attachedThe AMI used for this instance too.###Hi Team,We have launched a test Instance:  i-0c685f4ac31134037 (Test-Enhanched-Networking) and performed the ixgbevf driver update. Please find the details as below:1. We have launched a new instance from the AMI(ami-05684c7e) of the Secure server in a different VPC. Closed all outbound and checked no additional services running in the instances then system related services.2. We have installed the DKMS package and also the ixgbevf-2.16.4 package, But still getting errors when building the package using dkms. error below:[ Error! Bad return status for module build on kernel: 2.6.32-696.3.1.el6.x86_64 (x86_64) ]3. We have then tried to install the latest version available on Sourceforge.net, which is ixgbevf-4.2.1 version. The module is now built and installed successfully using DKMS.Finally, We have now stop-start the instances and it is coming up fine. We can verify the ixgbevf driver version is in use and is the latest stable version and is 4.2.1 by running the below commands:# modinfo ixgbevf# ethtool -i eth0Please let us know if you have any questions. Thanks###In the maintenance window we performed the below actions:1. We took an image of the PROD-SPHQ-WEB-SERVER03_4th_July_2017 instance2. Created access keys for an IAM user namedRean-MS and checked the Enhanced networking feature it was already enabled on the image and instance, but the driver version is less than recommended by AWS3. Current running ixgbevf driver version check by command modinfo ixgbevf is: 2.12.1-k4. Tried to install the version ixgbevf-2.16.4 recommended by AWS Support, but it is failing with errors related to kernel-devel packages. Current kernel version is 2.6.32-696.3.1.el6.x86_645. We tried to troubleshoot the issue and installed the new kernel version but still no luck with the issue.Finally, as we were reaching the end of the maintenance window timing, We confirmed with Matthew and rolled backed all the changes.Next Action Item:We have taken permission to test this driver update on a test instance launched by the AMI of the secure server. We are working on the testing and will provide you the update soon.###Deployment plan Link - https://docs.google.com/spreadsheets/d/1h1OxfAv5UivLdV9yqYY_iKgLibpDGYNRNv-9izadeWc/edit#gid=873897898Need to get it reviewed by CE3 or CC and perform the deployment.###Hello Matthew,Thank you for your update.We will perform the restart on the server at 2330 Hours EST today (9:00 AM 1/8/2017). Our estimated downtime will be approximately 1 hour. We will provide you the deployment plan shortly.###Matthew Watts9:12 PM (37 minutes ago)￼￼￼to Rean, spendhq-support￼Rean, After discussing with the team, can we restart the server at 2330 Hours EST today. What is your estimated downtime for this.###I will discuss internally and get back with an answer tomorrow Matthew.###Hello Team,We can hold off the network driver upgrade until mid august. But the issue may happen again and it will affect the availability of your application. If your team is fine with the downtime, we will schedule the network driver upgrade around mid of august.Please let us know your thoughts regarding this.###Matthew Watts7:09 PM (23 minutes ago)￼￼￼to Rean, spendhq-support￼Thank you. I will await the response###Hello Matthew,We received instance status check failure for the instance PROD-SPHQ-WEB-SERVER03_4th_July_2017,  5 times in past 24 hours. Please see the graph attached. Out of the 6 events, we faced an outage once for  https://secure.spendhq.com/login.We will check with our internal team whether we can hold off the upgrading of network driver and will revert back to you.###Matthew WattsCan we hold off on this until mid august? How many times have we have outages from this issue and when?###Hello SpendHQ Team,We are repeatedly receiving instance status check failure for the instance PROD-SPHQ-WEB-SERVER03_4th_July_2017.As already informed the network driver on the instance is running with an older version. Please let us know if we have your approval to proceed with this change as it requires instance reboot, we will start preparing the deployment plan for the same post approval.###Next Action: Evening shift: Send a reminder to the customer in the case of no response.###This is regarding the production down time that we had for the URL https://secure.spendhq.com/login.As we have already conveyed, this was due to the instance status check failure for the instance PROD-SPHQ-WEB-SERVER03_4th_July_2017. We had a call with AWS support team to investigate this further from the underlying host level. The team confirmed that there was no network related issues on the underlying host but they updated the network driver on the instance is running with an older version and that will lead to the network issues.Driver Details:ixgbevf: Intel(R) 10 Gigabit PCI Express Virtual Function Network Driver - version 2.12.1-kCurrent version: version 2.12.1-kRecommended Version: 2.14.2Please review this details and let us know if we have your approval to proceed with this change so we will start preparing the deployment plan for the same. Please note that this change will require a production down time as the driver version upgrade needs an instance reboot.Please feel free to reach out to us if you have any queries.Thank You,Safuvan KM###I has a chat with AWS support again and will post a comment to the customer.###Hello,Thank you for contacting AWS Support. To recap our conversation, you saw that instance i-0590f342fdc9965bb had failed status checks. You mentioned that this had happened before and you had checked /var/log/messages but were unable to determine the cause of the issue. I checked the underlying hardware that the instance is running on and I didn't see any network-related or other problems. We also don't currently have any open events in the us-east-1 region concerning network connectivity problems. I can see from the Console log that the instance is running the version 2.12.1-k of the ixgbevf driver, which is used for Enhanced Networking on C4 and other instance types:ixgbevf: Intel(R) 10 Gigabit PCI Express Virtual Function Network Driver - version 2.12.1-kWe recommend that version 2.16.4 or a higher version of the driver is used as older versions of the driver can cause network instability. I see that the instance was launched from an AMI that was built on ami-57cd8732, which is a CentOS 6 AMI from the Community provided AMI section. This is why the instance is using an older version of the driver as Community provided AMIs are maintained by their providers (in this case, centos.org) and do not always have the latest drivers. I believe that the older version of the driver is the root cause of the network connectivity problems.Our documentation on how to upgrade the driver is at the following link:Enabling Enhanced Networking with the Intel 82599 VF Interface on Other Linux Distributionshttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sriov-networking.html#enhanced-networking-linuxMy recommendation is to upgrade the driver, test and let me know if you still experience problems.Best regards,Bill B.Amazon Web Services###Hello,Upon further investigation I do seemsome network packet loss on the underlying hardware that the instance is running on. You will have to stop/start the instance in order to upgrade the ixgbevf driver and when the instance is started again it will come up on new underlying hardware.Best regards,Bill B.Amazon Web ServicesCheck out the AWS Support Knowledge Center, a knowledge base of articles and videos that answer customer questions about AWS services: https://aws.amazon.com/premiumsupport/knowledge-center/?icmpid=support_email_category###Hello Matthew,Thanks for the update.While analyzing the logs, we were able to figure out some network related issues. For further clarification, we are raising a Support Ticket with AWS Team regarding this network issues.Will keep your team posted regarding the findings. Kindly revert back in case of any further queries.Regards,Sumod.K.Bose###Functionality has been verified. No issues appear to be present. Matthew Watts###Hi Team,We are further investigating the issue while investigating we found that after the down time there was an increasing number of request resulting 4xx.Could you please verify the functionality of the website and let us know the update.Kindly refer the attachment section for more details.###Hello SpendHQ-Team,On further analysis, we were able to figure out that an instance status check failure has happened on the server 10.59.100.79(PROD-SPHQ-WEB-SERVER03_4th_July_2017). This is the real web server of Secure_prod_web_virtual Virtual Server.Due to this instance status check failure, we received the site down alert for the URL https://secure.spendhq.com/login. We are currently analyzing the instance metrics and will be providing a detailed report regarding this outage. Validate these details and revert back in case of any further queries.Regards,Sumod.K.Bose###Hello Matthew,Thanks for your confirmation.We are investigating further on this outage and will get back to you with more updates shortly.Regards,Sumod.K.Bose###Our team has not been performing any changes Regards,Matthew Watts###Hello SpendHQ-Team,This is to inform you that we received an alert regarding site down for the URL https://secure.spendhq.com/login. The overall downtime was about 6 minutes & 1 second. Currently, the URL is up and serving well. We are performing further investigation regarding this outage and will get back to you with further updates.Meanwhile, please let us know if your team has performed any kind of activity which lead to this outage. Revert back in case of any further queries.Regards,Sumod.K.Bose","Fri, 28 Jul 2017 10:51:30 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30005 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, Dallas-B US, Frankfurt DE, London UK-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,28-07-2017 20:21,148,0,SpendHQ,"Hi SpendHQ Team,Please find the below response from AWS Internal service team where they confirms the degraded hardware was causing the status check failures on the instance:",,,,,,,,,,,,,,,,,,,,,,,,,,,"Hello,Sorry for the delay in providing you with an update. So I was able to get a feedback from our internal service team who took a deep dive in finding the health status of the underlying hardware and after a thorough analysis, its confirmed that underlying hardware had issues for which they have now marked it in degraded state so then no new instances will be launched using the same. Which means there is no possibility of having your instances to go on the same faulty hardware as its already marked degraded now. I truly hope that I was able to assist you and in future if you happen to experience similar issues, please feel free to open a case for us and we will be happy to assist you in best possible way.Best regards,Ankit j.Amazon Web Services",,,,,,,,,,,,,,,,,,,,,,,,,,,"I hope this answer our queries on why the issue did not happen on the other servers running on the same network driver version. As per the AWS recommendation, REAN MGS Team will submit a plan to update the network driver versions on the all SpendHQ instances.","Hi Team,As discussed in our last biweekly call, we will further work on the network driver update activity across all nodes as a result of this incident.Attaching the incident RCA for your review. let us know if you have any questions. Thank you!","As discussed in the ops call we can close this since AWS already mentioned there is hardware issue. So we are not sharing the RCA.  As a next step based on the SpenHQ biweekly MOM there is an action item to update network driver as shown below: Network Driver Updatea.      Get Inventory of all the resources and their network driver version(Instance Name, Instance ID, IP Address, Driver Version)b.      Andrew/Matthew will provide comments which one needs update because they are planning to terminate few resourcesJira tickets will be created to follow up on the tasks. So we are closing the ticket from here and will be following the action in JIRA ticket.","In the morning call, this was discussed and Yogesh will take care of this.He will follow up with AWS support, make the changes to the RCA and will keep the customer updated with the status every day.","Reply from AWS team.Hello,Thanks for reaching out to AWS Premium Support today.I am sorry for the delay in responding over the email. This is because we experienced a high volume of customer contacts within the period. Just wanted to summarize about our discussed that we had today over chat. You wanted to know what caused your instances to hook them off from the network on 28th of July. From the couple of correspondence happened on this case, the speculation was over the network drivers and could be because of the underlying hardware. For the same, I asked you to start your instance so I can go through the latest console logs in real time. After analyzing those logs I confirmed that the instance was able to pass the health checks after the network was loaded fine by kernel. There wasnt any error reported on the network device so I further looked over to the underlying hardware. From the health stats of your instance I did see the failure on health check happened during the below timings27th July 23:40 - 00:1128th July 14:26 - 15:1128th on 20:41 - 21:11Further, I checked at the underlying hardware that was hosting your instance on that particular date/time, I found there were issues seen at the hardware level. For the same I opened a ticket for my internal service team to investigate further. At this moment, I can not gurantee the expected time around when they will revert but as soon as I get a response from them, I will immediately provide you with the information.Since you already confirmed that at present you are not using that instance as you have launched a new instance that came online on another underlying hardware, you not seeing any issues at the moment. I also informed you about using the recommended and stable version of the network driver as advertised on our public documentation :",Last Worked: SumodLast Action: Support ticket reopened and asked the queries. The network driver instability in the other nodes is not making issues now. AWS conveyed the network driver version may not make issues in every case but it may cause network instability sometimes.Next Action: Convey the same info to the customer champion and wait for the response from AWS support.,"+++Internal Comment+++We had a detailed discussion with the AWS Support Team regarding this issue. We have raised two main points related to this issues and they are,1, To check and confirm if there was any kind of underlying hardware issues on this during the time of these outages.AWS Support engineer initially mentioned that everything was fine at the time of these issues and after taking a deeper look, he was able to see that there were uplink issues with the underlying host and he has opened an internal ticket to get that issue fixed locally and will update us once they have any inputs on this case.2, If the issue is with the Network Enhancing Driver, why the clones created from these servers are not having any health check issues? AWS Team replied that, if we are not getting any issues on the other instances then its good but its always advisable to go with the recommendations as the versions are tested well with the kernel versions and tagged as stable. From their conversation, it was clear that they don't have a clear point of clarification.Next Action: Check for further updates from AWS Support Team regarding this case and also share all these updates with the CC. Can refer the chat details on the case for more details.Regards,Sumod.K.Bose",#NAME?,The RCA has completed.The URL: https://docs.google.com/a/reansolutionsinc.com/document/d/1xXhYVm1dgPUpplwKo1ktq55cfv-ByTOopGQhn_K4x5c/edit?usp=sharingI have assigned this to Yogesh for review.Next Action: Evening shift: Sync up with Yogesh and get the RCA reviewed. Please send the RCA to the customer once it is reviewed.,Started working on the RCA document. The document is in progresshttps://docs.google.com/a/reansolutionsinc.com/document/d/1xXhYVm1dgPUpplwKo1ktq55cfv-ByTOopGQhn_K4x5c/edit?usp=sharing,"Hello SpendHQ Team,We successfully installed the latest version of ixgbevf package which is 4.2.1 to the new node  created from the 10.59.100.79 (AMI ID: ami-a9c6e1d2) and enabled new virtual server configuration in sophos. Since Daniel performed the smoke test for the application and verified everything is working as expected, at this time, we're marking this case as Resolved. However, if you have any further queries on this please revert back to us.","Daniel Mackay7:39 AM (26 minutes ago)to Matthew, Rean, spendhq-support Rean, I am available if / when you need me. Feel free to reach out to me via email or phone – (404) 988-3100. Or I can call in if you provide a number.  Best regards, Dan Mackay | Spend Solutions DBA | SpendHQO: 770-741-0157 | dmackay@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group",Matthew has updated to perform this change on 2/8/2017 9 AM IST (11:30 PM EST) on another ticket.  (I-01071188).Need to call Yogesh and get the deployment plan updated with the steps required.,"Hello Matthew,Thanks for the update.We will schedule the change on 10 PM EST hours on Friday and also will share with you the updated deployment plan.",Let us set this to 2200 Hours EST on Friday.Matthew,"Hello SpendHQ-Team,We haven't heard back from you.As we have now successfully test installed the latest version of ixgbevf package which is 4.2.1. Please provide us a maintenance window again to perform the changes on the instance: i-0590f342fdc9965bb (PROD-SPHQ-WEB-SERVER03_4th_July_2017). In this case, we will have the downtime for 10-15 min when we will be doing a stop-start only. But the maintenance window needs 1 hour to complete.","Hi SpendHQ Team,As we have now successfully test installed the latest version of ixgbevf package which is 4.2.1. Please provide us a maintenance window again to perform the changes on the instance: i-0590f342fdc9965bb (PROD-SPHQ-WEB-SERVER03_4th_July_2017).In this case, we will have the downtime for 10-15 min when we will be doing a stop-start only. But the maintenance window needs 1 hour to complete.",For Internal Team:We need to delete these resources later:Instance:  i-0c685f4ac31134037 (Test-Enhanched-Networking)The security group attachedThe AMI used for this instance too.,"Hi Team,We have launched a test Instance:  i-0c685f4ac31134037 (Test-Enhanched-Networking) and performed the ixgbevf driver update. Please find the details as below:1. We have launched a new instance from the AMI(ami-05684c7e) of the Secure server in a different VPC. Closed all outbound and checked no additional services running in the instances then system related services.2. We have installed the DKMS package and also the ixgbevf-2.16.4 package, But still getting errors when building the package using dkms. error below:[ Error! Bad return status for module build on kernel: 2.6.32-696.3.1.el6.x86_64 (x86_64) ]3. We have then tried to install the latest version available on Sourceforge.net, which is ixgbevf-4.2.1 version. The module is now built and installed successfully using DKMS.Finally, We have now stop-start the instances and it is coming up fine. We can verify the ixgbevf driver version is in use and is the latest stable version and is 4.2.1 by running the below commands:# modinfo ixgbevf# ethtool -i eth0Please let us know if you have any questions. Thanks","In the maintenance window we performed the below actions:1. We took an image of the PROD-SPHQ-WEB-SERVER03_4th_July_2017 instance2. Created access keys for an IAM user namedRean-MS and checked the Enhanced networking feature it was already enabled on the image and instance, but the driver version is less than recommended by AWS3. Current running ixgbevf driver version check by command modinfo ixgbevf is: 2.12.1-k4. Tried to install the version ixgbevf-2.16.4 recommended by AWS Support, but it is failing with errors related to kernel-devel packages. Current kernel version is 2.6.32-696.3.1.el6.x86_645. We tried to troubleshoot the issue and installed the new kernel version but still no luck with the issue.Finally, as we were reaching the end of the maintenance window timing, We confirmed with Matthew and rolled backed all the changes.Next Action Item:We have taken permission to test this driver update on a test instance launched by the AMI of the secure server. We are working on the testing and will provide you the update soon.",Deployment plan Link - https://docs.google.com/spreadsheets/d/1h1OxfAv5UivLdV9yqYY_iKgLibpDGYNRNv-9izadeWc/edit#gid=873897898Need to get it reviewed by CE3 or CC and perform the deployment.,"Hello Matthew,Thank you for your update.We will perform the restart on the server at 2330 Hours EST today (9:00 AM 1/8/2017). Our estimated downtime will be approximately 1 hour. We will provide you the deployment plan shortly.","Matthew Watts9:12 PM (37 minutes ago)￼￼￼to Rean, spendhq-support￼Rean, After discussing with the team, can we restart the server at 2330 Hours EST today. What is your estimated downtime for this.",I will discuss internally and get back with an answer tomorrow Matthew.,"Hello Team,We can hold off the network driver upgrade until mid august. But the issue may happen again and it will affect the availability of your application. If your team is fine with the downtime, we will schedule the network driver upgrade around mid of august.Please let us know your thoughts regarding this.","Matthew Watts7:09 PM (23 minutes ago)￼￼￼to Rean, spendhq-support￼Thank you. I will await the response","Hello Matthew,We received instance status check failure for the instance PROD-SPHQ-WEB-SERVER03_4th_July_2017,  5 times in past 24 hours. Please see the graph attached. Out of the 6 events, we faced an outage once for  https://secure.spendhq.com/login.We will check with our internal team whether we can hold off the upgrading of network driver and will revert back to you.",Matthew WattsCan we hold off on this until mid august? How many times have we have outages from this issue and when?,"Hello SpendHQ Team,We are repeatedly receiving instance status check failure for the instance PROD-SPHQ-WEB-SERVER03_4th_July_2017.As already informed the network driver on the instance is running with an older version. Please let us know if we have your approval to proceed with this change as it requires instance reboot, we will start preparing the deployment plan for the same post approval.",Next Action: Evening shift: Send a reminder to the customer in the case of no response.,"This is regarding the production down time that we had for the URL https://secure.spendhq.com/login.As we have already conveyed, this was due to the instance status check failure for the instance PROD-SPHQ-WEB-SERVER03_4th_July_2017. We had a call with AWS support team to investigate this further from the underlying host level. The team confirmed that there was no network related issues on the underlying host but they updated the network driver on the instance is running with an older version and that will lead to the network issues.Driver Details:ixgbevf: Intel(R) 10 Gigabit PCI Express Virtual Function Network Driver - version 2.12.1-kCurrent version: version 2.12.1-kRecommended Version: 2.14.2Please review this details and let us know if we have your approval to proceed with this change so we will start preparing the deployment plan for the same. Please note that this change will require a production down time as the driver version upgrade needs an instance reboot.Please feel free to reach out to us if you have any queries.Thank You,Safuvan KM",I has a chat with AWS support again and will post a comment to the customer.,"Hello,Thank you for contacting AWS Support. To recap our conversation, you saw that instance i-0590f342fdc9965bb had failed status checks. You mentioned that this had happened before and you had checked /var/log/messages but were unable to determine the cause of the issue. I checked the underlying hardware that the instance is running on and I didn't see any network-related or other problems. We also don't currently have any open events in the us-east-1 region concerning network connectivity problems. I can see from the Console log that the instance is running the version 2.12.1-k of the ixgbevf driver, which is used for Enhanced Networking on C4 and other instance types:ixgbevf: Intel(R) 10 Gigabit PCI Express Virtual Function Network Driver - version 2.12.1-kWe recommend that version 2.16.4 or a higher version of the driver is used as older versions of the driver can cause network instability. I see that the instance was launched from an AMI that was built on ami-57cd8732, which is a CentOS 6 AMI from the Community provided AMI section. This is why the instance is using an older version of the driver as Community provided AMIs are maintained by their providers (in this case, centos.org) and do not always have the latest drivers. I believe that the older version of the driver is the root cause of the network connectivity problems.Our documentation on how to upgrade the driver is at the following link:Enabling Enhanced Networking with the Intel 82599 VF Interface on Other Linux Distributionshttp://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sriov-networking.html#enhanced-networking-linuxMy recommendation is to upgrade the driver, test and let me know if you still experience problems.Best regards,Bill B.Amazon Web Services","Hello,Upon further investigation I do seemsome network packet loss on the underlying hardware that the instance is running on. You will have to stop/start the instance in order to upgrade the ixgbevf driver and when the instance is started again it will come up on new underlying hardware.Best regards,Bill B.Amazon Web ServicesCheck out the AWS Support Knowledge Center, a knowledge base of articles and videos that answer customer questions about AWS services: https://aws.amazon.com/premiumsupport/knowledge-center/?icmpid=support_email_category","Hello Matthew,Thanks for the update.While analyzing the logs, we were able to figure out some network related issues. For further clarification, we are raising a Support Ticket with AWS Team regarding this network issues.Will keep your team posted regarding the findings. Kindly revert back in case of any further queries.Regards,Sumod.K.Bose",Functionality has been verified. No issues appear to be present. Matthew Watts,"Hi Team,We are further investigating the issue while investigating we found that after the down time there was an increasing number of request resulting 4xx.Could you please verify the functionality of the website and let us know the update.Kindly refer the attachment section for more details.","Hello SpendHQ-Team,On further analysis, we were able to figure out that an instance status check failure has happened on the server 10.59.100.79(PROD-SPHQ-WEB-SERVER03_4th_July_2017). This is the real web server of Secure_prod_web_virtual Virtual Server.Due to this instance status check failure, we received the site down alert for the URL https://secure.spendhq.com/login. We are currently analyzing the instance metrics and will be providing a detailed report regarding this outage. Validate these details and revert back in case of any further queries.Regards,Sumod.K.Bose","Hello Matthew,Thanks for your confirmation.We are investigating further on this outage and will get back to you with more updates shortly.Regards,Sumod.K.Bose","Our team has not been performing any changes Regards,Matthew Watts","Hello SpendHQ-Team,This is to inform you that we received an alert regarding site down for the URL https://secure.spendhq.com/login. The overall downtime was about 6 minutes & 1 second. Currently, the URL is up and serving well. We are performing further investigation regarding this outage and will get back to you with further updates.Meanwhile, please let us know if your team has performed any kind of activity which lead to this outage. Revert back in case of any further queries.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DBhwb,Cloud Engineer Level 1,Closed,1062290,Incident,13-06-2017 01:32,,"Hello Matthew,We have checked and verified the disk usages and It has returns to a normal state with the value of 24%.root@ip-10-59-100-94 etl_uploads]# df -hFilesystem            Size  Used Avail Use% Mounted on/dev/xvda1             50G   11G   36G  24% /tmpfs                 7.3G     0  7.3G   0% /dev/shm10.59.100.125:/exports_newer/files.spendhq.com                      2.0T  1.4T  498G  75% /var/www/vhosts/files.spendhq.com As of know, we are marking this case resolved. Please let us know if you have any other queries.###Hello Matthew,We are looking into this issue and will get back to you with the updates.","Rean can you find out what is eating space on 10.59.100.94 asap as we are unable to save anything to the file system.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Space Issues,,13-06-2017 00:43,1,0,SpendHQ,"Hello Matthew,We have checked and verified the disk usages and It has returns to a normal state with the value of 24%.root@ip-10-59-100-94 etl_uploads]# df -hFilesystem            Size  Used Avail Use% Mounted on/dev/xvda1             50G   11G   36G  24% /tmpfs                 7.3G     0  7.3G   0% /dev/shm10.59.100.125:/exports_newer/files.spendhq.com                      2.0T  1.4T  498G  75% /var/www/vhosts/files.spendhq.com As of know, we are marking this case resolved. Please let us know if you have any other queries.","Hello Matthew,We are looking into this issue and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Lwzx0,Cloud Engineer Level 1,Closed,1087383,Incident,27-12-2017 01:14,,"Dusty Fowler12:58 AM (14 minutes ago)to me, Technology, REAN, Alsa This has appeared to correct the issue.  Thanks.###Manideep Gunda <manideep.gunda@reancloud.com>11:11 PM (19 minutes ago)to Dusty, Technology, REAN, Alsa Hello Dusty,We have analyzed the issue, this is due to the port 7443 is not whitelisted at the security group level. We have whitelisted now please check from your end now and let us know if you still facing the issue.###Hello Dusty,We will check on this and will let you know the updates.Regards,Alsa T Alias","Hello,We are experiencing problems trying to connect to the VPN.  This is company wide for all SHQ employees who typically have access.  We are able to login to the SOPHOS UserPortal, but the VPN client does not connect for any of us.Thanks for any help!Dusty Fowler | Developer | SpendHQ(r)O: 770.628.0026 | dfowler@spendhq.com<mailto:dfowler@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://www.reancloud.com/news/rean-cloud-named-partner-newly-launched-aws-alexa-business/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",VPN Access Issues,,26-12-2017 21:44,4,0,SpendHQ,"Dusty Fowler12:58 AM (14 minutes ago)to me, Technology, REAN, Alsa This has appeared to correct the issue.  Thanks.","Manideep Gunda <manideep.gunda@reancloud.com>11:11 PM (19 minutes ago)to Dusty, Technology, REAN, Alsa Hello Dusty,We have analyzed the issue, this is due to the port 7443 is not whitelisted at the security group level. We have whitelisted now please check from your end now and let us know if you still facing the issue.","Hello Dusty,We will check on this and will let you know the updates.Regards,Alsa T Alias",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001blEVR,Cloud Engineer Level 1,Closed,1104849,Incident,19-09-2018 16:55,,We have applied temporary license for now.###rohit.puri [7:57 AM]We are working on it.###manideep.gunda [8:50 AM]Thanks for the update @rohit.puri###manideep.gunda [7:09 AM]@rohit.puri We received a notification regarding the [SpendHQ] [10.59.1.192] [INFO-020] License expiry: a feature will expire. When we checked from web admin portal we could see the license will expire by 20th of this month,"---------- Forwarded message ---------From: <ms@reancloud.com>Date: Tue, Sep 18, 2018 at 6:51 AMSubject: [SpendHQ] [10.59.1.192] [INFO-020] License expiry: a feature willexpireTo: <ms@reancloud.com>Your WirelessSecurity license subscription will expire in 1 days.If you do not take steps to renew your license before expiry,all features which depend on this subscription will be deactivated!Contact your Sophos Partner or Sophos (http://www.sophos.com)to renew your license.Account Name - SpendHQAccount DL - ms@reancloud.comUTM Hostname - spendhq-utmPrivate IP - 10.59.1.192Public IP - 52.0.17.10Device URL - https://52.0.17.10:4444-- System Uptime      : 114 days 20 hours 16 minutesSystem Load        : 0.07System Version     : Sophos UTM 9.509-3Please refer to the manual for detailed instructions.The send limit for this notification has been reached. No furthernotifications of this type will be sent during this period.-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [SpendHQ] [10.59.1.192] [INFO-020] License expiry: a feature will expire,,18-09-2018 07:10,48,0,SpendHQ,We have applied temporary license for now.,rohit.puri [7:57 AM]We are working on it.,manideep.gunda [8:50 AM]Thanks for the update @rohit.puri,manideep.gunda [7:09 AM]@rohit.puri We received a notification regarding the [SpendHQ] [10.59.1.192] [INFO-020] License expiry: a feature will expire. When we checked from web admin portal we could see the license will expire by 20th of this month,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TBie6,Cloud Engineer Level 1,Closed,1094209,Incident,30-03-2018 22:10,,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello Matthew,This is a gentle reminder.Please review our previous comment and let us know your thoughts regarding this case.###Hello Matthew, We haven't heard back from you.We recommend you to use m4.2xlarge instance. Please check below-mentioned instance type details. Memory: 32gb CPU: 8vcpu Network performance: High Instance usage: EBS Cost: $0.53 per Hour Please let us know if you have any further queries.###Hello Matthew,We recommend you to use m4.2xlarge instance.Please check below-mentioned instance type details.Memory: 32gbCPU: 8vcpuNetwork performance: HighInstance usage: EBSCost: $0.53 per Hour Please let us know if you have any further queries.###Please suggest the m4.2xlarge instance type to the customer with all the details.###Hello Team,As per the analysis from past two weeks graphs We could see that the instance is consuming the Highest value of 63% CPU and average memory 5.07G.As customer asked they need High memory optimized instance I would like to recommend m4.2xlarge.The m4.2xlarge instance provides 32 Gb and 8 CPU  where C4.2xlarge provides 15 GB of total memory and 8 core CPU. And comparing to cost details c4.2xlarge is $0.528 per Hour and m4.2xlarge costs $0.53 per HourPlease review this details with CC before sharing with the customer.###Hello Matthew,We will check on this and will get back to you with the updates.###Matthew Watts11:59 PM (6 minutes ago)to Rean, spendhq-support Can you advise if that server can be resized to offer more memory?###Hello Team, This is to inform you that we received alerts regarding the high memory utilization for instance prd-ww2_6. The memory utilization has exceeded the threshold value of 85% to a value of 92.53%. We could see that httpd process was consuming more memory. Also, the alerts were getting resolved within 4 minutes. Please let us know whether you are having any concerns regarding this. As currently the alert is resolved state we are closing this case. Refer the below resource details, Instance ID: i-01ac95c23ac66a40e Instance type: c4.2xlarge Availability zone: us-east-1c Private IP: 10.59.101.6 VPC ID: vpc-76df7212 Subnet ID: subnet-29b09361","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Fri, Mar 23, 2018 at 9:36 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Memory UtilizationAlert on host - prd-ww2_6 - 10.59.101.6 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 -10.59.101.6 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1521821207000&group=host%3Ai-01ac95c23ac66a40e&from_ts=1521820907000>avg(last_5m):( avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 85The monitor was last triggered at Fri Mar 23 2018 16:06:57 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-01ac95c23ac66a40e>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-01ac95c23ac66a40e<https://app.datadoghq.com/infrastructure?hostname=i-01ac95c23ac66a40e>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1521821217000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1521820317000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4321112122515060821>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 - 10.59.101.6 - web,,23-03-2018 23:20,167,0,SpendHQ,"Hello Matthew,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello Matthew,This is a gentle reminder.Please review our previous comment and let us know your thoughts regarding this case.","Hello Matthew, We haven't heard back from you.We recommend you to use m4.2xlarge instance. Please check below-mentioned instance type details. Memory: 32gb CPU: 8vcpu Network performance: High Instance usage: EBS Cost: $0.53 per Hour Please let us know if you have any further queries.","Hello Matthew,We recommend you to use m4.2xlarge instance.Please check below-mentioned instance type details.Memory: 32gbCPU: 8vcpuNetwork performance: HighInstance usage: EBSCost: $0.53 per Hour Please let us know if you have any further queries.",Please suggest the m4.2xlarge instance type to the customer with all the details.,"Hello Team,As per the analysis from past two weeks graphs We could see that the instance is consuming the Highest value of 63% CPU and average memory 5.07G.As customer asked they need High memory optimized instance I would like to recommend m4.2xlarge.The m4.2xlarge instance provides 32 Gb and 8 CPU  where C4.2xlarge provides 15 GB of total memory and 8 core CPU. And comparing to cost details c4.2xlarge is $0.528 per Hour and m4.2xlarge costs $0.53 per HourPlease review this details with CC before sharing with the customer.","Hello Matthew,We will check on this and will get back to you with the updates.","Matthew Watts11:59 PM (6 minutes ago)to Rean, spendhq-support Can you advise if that server can be resized to offer more memory?","Hello Team, This is to inform you that we received alerts regarding the high memory utilization for instance prd-ww2_6. The memory utilization has exceeded the threshold value of 85% to a value of 92.53%. We could see that httpd process was consuming more memory. Also, the alerts were getting resolved within 4 minutes. Please let us know whether you are having any concerns regarding this. As currently the alert is resolved state we are closing this case. Refer the below resource details, Instance ID: i-01ac95c23ac66a40e Instance type: c4.2xlarge Availability zone: us-east-1c Private IP: 10.59.101.6 VPC ID: vpc-76df7212 Subnet ID: subnet-29b09361",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001dedbq,Cloud Engineer Level 1,Closed,1106813,Incident,27-10-2018 02:32,,"Hello Kristen,Thanks for the confirmation.At this point we are marking this case as resolved hence closing it.Please feel free to reach us for continued support.Thanks & Regards.###Kristen Stretch11:50 PM (10 minutes ago)to meAlright, it worked! Thanks for your help.-Kristen###I went on a troubleshooting call with customer regarding this issue and was able to solve it. We are currently waiting for response from customer.###Hi Kristen,Please join below bridge to help troubleshoot the issuehttps://reancloud.zoom.us/j/6709937998Thanks.###Kristen Stretch10:27 PM (0 minutes ago)to meSure-Thu Oct 25 21:19:01 2018 MANAGEMENT: >STATE:1540516741,RECONNECTING,auth-failure,,,,,Thu Oct 25 21:19:01 2018 Restart pause, 5 second(s)Fri Oct 26 11:00:18 2018 MANAGEMENT: Client disconnectedFri Oct 26 11:00:18 2018 MANAGEMENT: Client connected from [AF_INET]127.0.0.1:25340Fri Oct 26 11:00:18 2018 MANAGEMENT: Client disconnectedFri Oct 26 11:00:56 2018 MANAGEMENT: Client connected from [AF_INET]127.0.0.1:25340Fri Oct 26 11:02:51 2018 MANAGEMENT: Client disconnectedFri Oct 26 12:07:25 2018 MANAGEMENT: Client connected from [AF_INET]127.0.0.1:25340 I assume it has something to do with my home network? I have even tried completely closing the vpn client. I do not get the login window either, like I do when I connect from the office. -Kristen###Hello Kristen,We have checked from our side and we can see that it is open to all.Can you share a screenshot or logs with us for solving this issue?Thank you Rafi Ramesh Pune India###Hello Kristen,We will look into this request and will let you know the update shortly.Thanks,","Hi,I have recently had my VPN set up but it seems I am now no longer able to access network from home. It gets stuck in a constant state of trying to connect or disconnect. When in the office this is not a problem and I can connect fine. Please advise.-Kristen StretchKristen Stretch | Senior Quality Assurance Automation Engineer | SpendHQ(r)kstretch@spendhq.com<mailto:kstretch@spendhq.com>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Unable to access VPN outside network,,26-10-2018 20:36,6,0,SpendHQ,"Hello Kristen,Thanks for the confirmation.At this point we are marking this case as resolved hence closing it.Please feel free to reach us for continued support.Thanks & Regards.","Kristen Stretch11:50 PM (10 minutes ago)to meAlright, it worked! Thanks for your help.-Kristen",I went on a troubleshooting call with customer regarding this issue and was able to solve it. We are currently waiting for response from customer.,"Hi Kristen,Please join below bridge to help troubleshoot the issuehttps://reancloud.zoom.us/j/6709937998Thanks.","Kristen Stretch10:27 PM (0 minutes ago)to meSure-Thu Oct 25 21:19:01 2018 MANAGEMENT: >STATE:1540516741,RECONNECTING,auth-failure,,,,,Thu Oct 25 21:19:01 2018 Restart pause, 5 second(s)Fri Oct 26 11:00:18 2018 MANAGEMENT: Client disconnectedFri Oct 26 11:00:18 2018 MANAGEMENT: Client connected from [AF_INET]127.0.0.1:25340Fri Oct 26 11:00:18 2018 MANAGEMENT: Client disconnectedFri Oct 26 11:00:56 2018 MANAGEMENT: Client connected from [AF_INET]127.0.0.1:25340Fri Oct 26 11:02:51 2018 MANAGEMENT: Client disconnectedFri Oct 26 12:07:25 2018 MANAGEMENT: Client connected from [AF_INET]127.0.0.1:25340 I assume it has something to do with my home network? I have even tried completely closing the vpn client. I do not get the login window either, like I do when I connect from the office. -Kristen","Hello Kristen,We have checked from our side and we can see that it is open to all.Can you share a screenshot or logs with us for solving this issue?Thank you Rafi Ramesh Pune India","Hello Kristen,We will look into this request and will let you know the update shortly.Thanks,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001i6Y2s,Cloud Engineer Level 1,Closed,1110743,Incident,15-01-2019 17:34,,"Hello Matthew,Thanks for the confirmation.Since the site is up and running we are marking the case as closed.Also, we have another ticket open for tracking the issue. Case Id: I-01110533Let us know if you have any queries.###Matthew Watts <mwatts@spendhq.com>Today, 5:16 PMRean Support <support@reancloud.com>;spendhq-support@reancloud.comYes it was due to my resolution of the matter at hand.###Hello Matthew,The site has gone down multiple times with the same error mentioned in the below comment.It is well accessible now. Please confirm this was due to the fix that you have applied for the DB issue.###Hello Matthew,This is to notify you that the site https://secure.spendhq.com/login is down now.Below is the error we are getting.[Tue Jan 15 10:54:41 2019] [error] [client 10.59.101.139] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 10:54:42 2019] [error] [client 10.59.101.139] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 10:54:42 2019] [error] [client 10.59.101.139] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popupPlease check the error on your end and let us know if you need any assistance from our end.###The site was not up the team has muted this URL from the Wormly. Please do follow up with the customer on this.###Hello Team,This is to inform you that we are receiving very frequent site down alert for the same URLs. Upon checking site was up and alert also getting recovered with 2-3 minutes.We further analyzed this issue and also capture the ELB logs for the NewPreviewELB.From the logs, we could that the backend processing time for the following URLs was too high.POST https://secure.spendhq.com:443/super_admin/whos_online HTTP/1.1 - 187.403799GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1547494137288 HTTP/1.1 - 50.871508GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1547509747409 HTTP/1.1 - 7.338132GET https://secure.spendhq.com:443/spend-visibility HTTP/1.1 - 3.717409GET https://secure.spendhq.com:443/login HTTP/1.1 - 2.490638HEAD https://secure.spendhq.com:443/login HTTP/1.1 - 0.299171Please find the complete logs and reference screenshots in the attachment section and let us know if you have any queries.Also, update us regarding your availability to get on a call with us to discuss this issue further.Thanks###Hello Matthew,Thanks for the update.###Matthew Watts <mwatts@spendhq.com>Tue 15-01-2019 06:27 AMRean Support <support@reancloud.com>;spendhq-support@reancloud.comWe will review the attachment an get back to you.###Hello Team,This is to inform you that at the time when we received site down alert, the site was loading fine from our end. We analyzed the issue and found the following on the NewPreview ELB :1. Spike in latency graph with a maximum value of 89367.60 ms 2. We can see a sudden spike in Request Count and value has been reached to 4873. We also found a sudden spike in active connection count and value was 453On Secure-SpendHQ-ELB also we noticed the same patterns of graphs, here are the details :1. Sudden Spike in latency during the same time of site down alert 2. Spike in request count with a value of 483 requestsWe have also checked the system logs on both the backend instance attached to NewPreview ELB as well as the UTM instance attached to Secure-SpendHQ-ELB load balancer but didn't find any error.On DB server 10.59.10.210 (SPHQ-DB4-20180830) also we verified but didn't find any suspicious activity for the time when we received site down alert.We have also verified the CPU, Network IN/OUT metrics for the time around but all looks normal.Based on this analysis, it seems like the same issue we are discussing which is causing due to latency. The site actually not goes down but due to high latency, our monitor tool timed out the ping and it triggers the site down alert. Please find the Cloudwatch Metrics graph in the attachment section for the reference and please provide your availability to get on a call with us to discuss this intermittent issue further.###Hello Spendhq-Team,This is to inform you that we received a site down alert for the URL: https://secure.spendhq.com/login. It got recovered within 3 minutes. During the time of site down, we could see the site is loading with high latency. We will analyze more on this case and let you know the update.","Mon, 14 Jan 2019 18:08:57 -0500Detected Error on SpendHQ SecureEstimated Downtime: 1 minute 59 secondshttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 60000 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): London UK, California US, Frankfurt DE, Frankfurt-B DE-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,15-01-2019 04:41,13,0,SpendHQ,"Hello Matthew,Thanks for the confirmation.Since the site is up and running we are marking the case as closed.Also, we have another ticket open for tracking the issue. Case Id: I-01110533Let us know if you have any queries.","Matthew Watts <mwatts@spendhq.com>Today, 5:16 PMRean Support <support@reancloud.com>;spendhq-support@reancloud.comYes it was due to my resolution of the matter at hand.","Hello Matthew,The site has gone down multiple times with the same error mentioned in the below comment.It is well accessible now. Please confirm this was due to the fix that you have applied for the DB issue.","Hello Matthew,This is to notify you that the site https://secure.spendhq.com/login is down now.Below is the error we are getting.[Tue Jan 15 10:54:41 2019] [error] [client 10.59.101.139] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 10:54:42 2019] [error] [client 10.59.101.139] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popup[Tue Jan 15 10:54:42 2019] [error] [client 10.59.101.139] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4760, referer: https://secure.spendhq.com/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/layout:popupPlease check the error on your end and let us know if you need any assistance from our end.",The site was not up the team has muted this URL from the Wormly. Please do follow up with the customer on this.,"Hello Team,This is to inform you that we are receiving very frequent site down alert for the same URLs. Upon checking site was up and alert also getting recovered with 2-3 minutes.We further analyzed this issue and also capture the ELB logs for the NewPreviewELB.From the logs, we could that the backend processing time for the following URLs was too high.POST https://secure.spendhq.com:443/super_admin/whos_online HTTP/1.1 - 187.403799GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1547494137288 HTTP/1.1 - 50.871508GET https://secure.spendhq.com:443/reports/view/U3BlbmQgVmlzaWJpbGl0eQ/?_=1547509747409 HTTP/1.1 - 7.338132GET https://secure.spendhq.com:443/spend-visibility HTTP/1.1 - 3.717409GET https://secure.spendhq.com:443/login HTTP/1.1 - 2.490638HEAD https://secure.spendhq.com:443/login HTTP/1.1 - 0.299171Please find the complete logs and reference screenshots in the attachment section and let us know if you have any queries.Also, update us regarding your availability to get on a call with us to discuss this issue further.Thanks","Hello Matthew,Thanks for the update.",Matthew Watts <mwatts@spendhq.com>Tue 15-01-2019 06:27 AMRean Support <support@reancloud.com>;spendhq-support@reancloud.comWe will review the attachment an get back to you.,"Hello Team,This is to inform you that at the time when we received site down alert, the site was loading fine from our end. We analyzed the issue and found the following on the NewPreview ELB :1. Spike in latency graph with a maximum value of 89367.60 ms 2. We can see a sudden spike in Request Count and value has been reached to 4873. We also found a sudden spike in active connection count and value was 453On Secure-SpendHQ-ELB also we noticed the same patterns of graphs, here are the details :1. Sudden Spike in latency during the same time of site down alert 2. Spike in request count with a value of 483 requestsWe have also checked the system logs on both the backend instance attached to NewPreview ELB as well as the UTM instance attached to Secure-SpendHQ-ELB load balancer but didn't find any error.On DB server 10.59.10.210 (SPHQ-DB4-20180830) also we verified but didn't find any suspicious activity for the time when we received site down alert.We have also verified the CPU, Network IN/OUT metrics for the time around but all looks normal.Based on this analysis, it seems like the same issue we are discussing which is causing due to latency. The site actually not goes down but due to high latency, our monitor tool timed out the ping and it triggers the site down alert. Please find the Cloudwatch Metrics graph in the attachment section for the reference and please provide your availability to get on a call with us to discuss this intermittent issue further.","Hello Spendhq-Team,This is to inform you that we received a site down alert for the URL: https://secure.spendhq.com/login. It got recovered within 3 minutes. During the time of site down, we could see the site is loading with high latency. We will analyze more on this case and let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014LovH,Cloud Engineer Level 1,Closed,1033814,Incident,,,,"Thu, 24 Nov 2016 14:08:35 -0500SpendHQ has RecoveredEstimated Downtime: 7 minutes https://www.wormly.com/edithost/hostid/50743----------HTTP is UP----------Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: ----------HTTP is UP----------Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SpendHQ has Recovered,,25-11-2016 00:38,0,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001DlpCj,Cloud Engineer Level 1,Closed,1064270,Incident,22-06-2017 19:36,,"Hello Team,This is to notify you that the alert regarding high volume usage on PROD-SPHQ-DB-SERVER05 got resolved and has returned to normal with a value of 62%. The violation lasted for 35 Minutes.###Hello Team,Please see the usage details below.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G  578M  99% /Usage under /47G     total19G     tmp15G     usr12G     var523M    home285M    lib282M    optUsage under /tmp19G     total7.8G    liger_view_d4f46cf1b5902128917c80caefc9d4f8.csv7.8G    liger_view_31582abbf49d038a89fe56c4a3cafcfd.csv927M    liger_view_caa16490a6f4c23258e135e31655eacd.csv446M    liger_view_c188b7a0208ceb11e189557a0517adc3.csv446M    liger_view_67ef06400e5e807ad729972f094ad1d6.csv221M    spark-2.1.0-bin-hadoop2.7201M    liger_view_492a6be898c881b1868f4b3e459dd3ea.csvPlease remove/zip unused data to reduce the current usage.###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 97.8%. From our initial analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. We will analyze the volume usage details and will update with you.","Thanks & Regards,Anjali G NairHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>anjali.gopinadhan@reancloud.com <kriti@reancloud.com> | +91-7702500499 |www.reancloud.com <http://www.reancloudsolutions.com/>---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Thu, Jun 22, 2017 at 6:59 PMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjbEOgjAURb-GbpLXVwq8oQMSiYmzgy6m0gokQLG0g39vSe5wcpNzr1GS3pZNCoFXUCJygYRVzqEoC5m3srgQNdiixKajc1aACWbIe8dGhVIA1URC2Frqt8BSgiXNK1NaJBBsVmMI256JJsMuRW9bbnTQxg3jN20sR9f3Lq4h0ebdZ5ptoniCJ7Sv2-9x59fIvFr2dOytXvvZRXOYLKjFrVNw_g_FDzk->[image: Metric Graph]<http://email.dtdg.co/c/eJxNj9FuwyAMRb-GPCJsMJ0feMjS5jcmAmkSqSkZodU-fyTawyRLtq_lo3ujIx7GZnGo4KIsImhkvEhQxhqSHZkbc4sdErY9fwqjYomTDKmZXQwWDAykhxBoMMzeArCCu_bWWuObh5tL2XahW4F9Lb9tMvriY5rm78pYq7am51JS3gVqVKjZstB9SV-lvl3B8AfoWqyUEminnF5b1eP4XsIokA4yYV_3s_-8o4dj6ua0l_MOShLXOBI0VcI9p_U_2_LJbrJb9xouj_4ZHukVD3dNcX_ufgH3s1Kz>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Thu Jun 22 2017 13:29:00 UTC (*26 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtjsGOgzAMRL8mHKPYiQM-5MCyy39kcQRIpWEhrfr5DdVKluwZS_NGAvFvataABlrjEcEiY6vBOO9ID-R-mHsckLAf-Us5I0VmPeVmCc5FIADPDj10EjvhyaaWU0fRtNY1t7CUsp_K9grHOnHftcQSJc_LX83Yqrfl-1rycSq0aNCyZ2XH-ciPXdlvSc91SgrpSiAcq_7s11MiXNew5LN8_mA0ca2twVJzhO2sVY8U79MtP-RiNSX8s950y0V_>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjcsOgyAURL8GluRyeeUuWFhT_wN5qIkWq_T_S5MmszqZM5O8oTnzzSNIBxZRKiR0QoK22ojR6CfRgCMaHCZ6MA2ppUXEylff-64YPesZdCjBAegoyULJJZZiM9_92tp5MzUwnHrCeYoUWkh1Wd994-jsqK-t1etmqBBQkaUOc9oav_xx978rh1fc6yf9BN78X_gCN-02ww>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVjksOgzAQQ09DllEyYYBZZEFpuUeaDyAVQsNw_6aSF5alZztYpHcUmwWle9UBaAMEvdSq7VqUE7YvohEmQBhnejStChwW6bNY7RBVJbpIaggApJJG7M3gg0lAmFB87Mp8Xo0ZG5ir3HnK4NiFvKzf2rHXbDtScReX2_NdYmPmNV98uL3ap1YSqV6R2qAodr_qfInu8J98hz8v2O752DiXHzvSOuk>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jUtuhDAQRE-Dl6jdH-xeeMF8uIeDHUAaMAOenD9kE6mkkp5Ur1IQ_cpmCQjWQYdoCRVda4E7lvYu_FTt8Y6C_aC3hiHVNLVjMXNwHMF3bNV7jVm-ETSPFkSJY-LszSvMte5nQ32Dw5W4722KNaYyze_LsV4s_-St_jcNS2roQYrkXMfkFYRYVMAcYT2v-yPHbXyVT_rbmxrWsi21HL_buTkB>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjUsOhCAQRE8jSwMtDWHBwjHjPbDBT6LAIN5_MKlF5aXyyls0S2CHBS40VwBiAAO6F1wqif2E8mvMCBMgjLP5dJL76reeEtut4uiQjAna0IoAqEkIx5UKCOuiFDvtXmu-u2HsYG5xOffeVefTtv-a43oZUXpibS2XsIYSIoWbFXvd7asEF-lMj3_HrNorxaOm8gdg5zZz>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,22-06-2017 19:01,1,0,SpendHQ,"Hello Team,This is to notify you that the alert regarding high volume usage on PROD-SPHQ-DB-SERVER05 got resolved and has returned to normal with a value of 62%. The violation lasted for 35 Minutes.","Hello Team,Please see the usage details below.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G  578M  99% /Usage under /47G     total19G     tmp15G     usr12G     var523M    home285M    lib282M    optUsage under /tmp19G     total7.8G    liger_view_d4f46cf1b5902128917c80caefc9d4f8.csv7.8G    liger_view_31582abbf49d038a89fe56c4a3cafcfd.csv927M    liger_view_caa16490a6f4c23258e135e31655eacd.csv446M    liger_view_c188b7a0208ceb11e189557a0517adc3.csv446M    liger_view_67ef06400e5e807ad729972f094ad1d6.csv221M    spark-2.1.0-bin-hadoop2.7201M    liger_view_492a6be898c881b1868f4b3e459dd3ea.csvPlease remove/zip unused data to reduce the current usage.","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 97.8%. From our initial analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. We will analyze the volume usage details and will update with you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Vrw8k,Cloud Engineer Level 2,Closed,1098352,Incident,23-05-2018 00:43,,"Hello Team, The activity has completed, At this time we are marking this case as closed.###As mentioned by Rohit on the Ops call, We have sent email to Andromeda team.###@Rohit: This is for 1 GBPS connection which is the secondary DC. Please confirm whether we need to reach out to Chris and update to verify the switch over connections.###@Team: Please drop a mail to Andromeda Team informing them about this as If they are planning to do testing for switch over connections. Note: Please CC Andromeda Team whenever we get Direct Connect Maintenance is scheduled from AWS.###Hello Andrew,Thanks for the update.###Received. Please be on standby to resolve any disconnects that happen.###Hello Team,We haven't heard back from you. Please review the previous comment and let us know about the same.###Hello SpendHQ-Team, This is to inform you that we received notification from AWS stating planned maintenance has been scheduled on an AWS Direct Connect router in Equinix Equinix DC2/DC11 Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 1Gbps may become unavailable. Connection name: SpendHQ Connection ID: dxcon-fg50qjyw Your Peer IP: 169.254.255.46/30 Amazon Peer IP: 169.254.255.45/30 AWS Scheduled Maintenance Window:- Start time: May 22, 2018 at 8:31:00 AM UTC+5:30 End time: May 22, 2018 at 1:31:00 PM UTC+5:30 AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same.###Hello SpendHQ-Team,This is to inform you that we received notification from AWS stating planned maintenance has been scheduled on an AWS Direct Connect router in Equinix  Equinix DC2/DC11 Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 1Gbps may become unavailable. Connection name: SpendHQ Connection ID: dxcon-fg50qjyw Your Peer IP: 169.254.255.46/30 Amazon Peer IP: 169.254.255.45/30 AWS Scheduled Maintenance Window:-Start time: May 22, 2018 at 8:31:00 AM UTC+5:30End time: May 22, 2018 at 1:31:00 PM UTC+5:30AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same.","---------- Forwarded message ----------From: SPHQAWS <no-reply@sns.amazonaws.com>Date: Wed, May 9, 2018 at 7:42 AMSubject: AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULEDTo: support@reancloud.comPlanned maintenance has been scheduled on an AWS Direct Connect router inEquinix DC2/DC11, Ashburn, VA. During this maintenance window, your AWSDirect Connect services associated with this event may become unavailable.This maintenance is scheduled to avoid disrupting redundant connections atthe same time.If you encounter any problems with your connection after the end of thismaintenance window, please contact us at https://aws.amazon.com/support Formore details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support--  <http://go.reancloud.com/gartner-magic-quadrant>-- Regards,Jamelunissa MohammedHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081jamelunissa.mohammed@reancloud.com  | www.reancloud.com--  <http://go.reancloud.com/gartner-magic-quadrant>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED,,09-05-2018 14:29,322,0,SpendHQ,"Hello Team, The activity has completed, At this time we are marking this case as closed.","As mentioned by Rohit on the Ops call, We have sent email to Andromeda team.",@Rohit: This is for 1 GBPS connection which is the secondary DC. Please confirm whether we need to reach out to Chris and update to verify the switch over connections.,@Team: Please drop a mail to Andromeda Team informing them about this as If they are planning to do testing for switch over connections. Note: Please CC Andromeda Team whenever we get Direct Connect Maintenance is scheduled from AWS.,"Hello Andrew,Thanks for the update.",Received. Please be on standby to resolve any disconnects that happen.,"Hello Team,We haven't heard back from you. Please review the previous comment and let us know about the same.","Hello SpendHQ-Team, This is to inform you that we received notification from AWS stating planned maintenance has been scheduled on an AWS Direct Connect router in Equinix Equinix DC2/DC11 Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 1Gbps may become unavailable. Connection name: SpendHQ Connection ID: dxcon-fg50qjyw Your Peer IP: 169.254.255.46/30 Amazon Peer IP: 169.254.255.45/30 AWS Scheduled Maintenance Window:- Start time: May 22, 2018 at 8:31:00 AM UTC+5:30 End time: May 22, 2018 at 1:31:00 PM UTC+5:30 AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same.","Hello SpendHQ-Team,This is to inform you that we received notification from AWS stating planned maintenance has been scheduled on an AWS Direct Connect router in Equinix  Equinix DC2/DC11 Ashburn, VA. During this maintenance window, the AWS Direct Connect services associated with SpendHQ with port speed 1Gbps may become unavailable. Connection name: SpendHQ Connection ID: dxcon-fg50qjyw Your Peer IP: 169.254.255.46/30 Amazon Peer IP: 169.254.255.45/30 AWS Scheduled Maintenance Window:-Start time: May 22, 2018 at 8:31:00 AM UTC+5:30End time: May 22, 2018 at 1:31:00 PM UTC+5:30AWS has scheduled this maintenance to avoid disrupting redundant connections at the same time. Kindly validate this information and let us know your thoughts regarding the same.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Zhmkm,Cloud Engineer Level 1,Closed,1102204,Incident,06-08-2018 14:43,,"As per Rohit update on morning call, we are closing this case.###Waiting for response from spendHQ Team###shared on emailHi Praveen,Thanks for reviewing this. Andrew/Mathew:I have deleted the account for:cveillette@Andromeda3.comdemsas.abraha@neoit.iodfowler.ses-smtp-user.20151214InternalDB01-ses-smtp-user.20160930-034009secure.spednhq.com.ses-smtp-userses-mwatts.20160329Please review the rest of the users details shared above and let us know your thoughts on this. Thanks !Regards,Rohit Puri###shared on emailHello Rohit,This is a big security risk where users Keys and Passwords are enabled and not in use. Go ahead and do it ASAP. We can always re-create on need basis.Regards,-Praveen###Hi Andrew/Mathew,We were looking to the Inactive IAM Users in your AWS Console. We found the below users which has not been active from long time or never used the credentials:Usename	Groups	Access Key Age	Password Age	Last Activity	Actioncveillette@Andromeda3.com	PowerUserGroup	None	180 days	None	REAN Team will delete this on Friday Eveningdemsas.abraha@neoit.io	None	None	None	None	REAN Team will delete this on Friday Eveningdfowler.ses-smtp-user.20151214	None	961 days	None	None	REAN Team will delete this on Friday Eveningdfowler.ses-smtp-user.20151215	None	960 days	None	518 Days	SpendHQ Team review thisInternalDB01-ses-smtp-user.20160930-034009	None	671 days	None	None	REAN Team will delete this on Friday Eveningsecure.spednhq.com.ses-smtp-user	None	993 days	None	None	REAN Team will delete this on Friday Eveningses-mwatts.20160329	None	855 days	None	None	REAN Team will delete this on Friday Eveningses-smtp-user.20151029-110924	None	1007 days	None	995 Days	SpendHQ Team review thisses-smtp-user.20170602-090630	None	426 days	None	425 Days	SpendHQ Team review thislogi.ses-smtp-user.20170616	None	411 days	None	401 Days	SpendHQ Team review thisREAN Team going to delete the users which are never been used(as mentioned in the Action Column) on Friday Evening. Please review the other users which has not been used from long time. Let us know if you have any concern regarding deleting the users. Thanks !Regards,Rohit Puri###Rohit is working on this case. Please reach out to him for further updates.###Most of the users are SES related - @rohit.puri - Please create a ticket and fix them.- Praveen","--------- Forwarded message ----------From: <ms@reancloud.com>Date: Wed, Aug 1, 2018 at 3:53 PMSubject: [Managed Cloud: spendhq] Inactive IAM Users AlertTo: spendhq-support@reancloud.comREAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environmentby REAN Managed Cloud.The following *AWS::IAM::User* resources were affected:------------------------------   - *Violation:* The user account is not enabled and Inactive since last   90 days.   - *Recommendation:* To prevent your account from getting Deleted, please   LogIn to your account or user your API Keys.   - *Action taken:* None   - *Resource details:*   Resource ID User Name Password Last Used Access Keys Last Used   AIDAIPVYL7ROUTOFUIG66 dfowler.ses-smtp-user.20151214 Never Never   AIDAJZTKTUXZP2QLXJV5U dfowler.ses-smtp-user.20151215 Never 2017-03-01   AIDAJ7CJRTJPPVMZQL7JK InternalDB01-ses-smtp-user.20160930-034009 Never   Never   AIDAJMDIEWQN7LVPAREHE logi.ses-smtp-user.20170616 Never 2017-06-26   AIDAIKLCMBUKEZMWJATWY secure.spednhq.com.ses-smtp-user Never Never   AIDAJXNJ3XPHJ33IGHTTC ses-mwatts.20160329 Never Never   AIDAIC5MT4RWQKK7364A2 ses-smtp-user.20151029-110924 Never 2015-11-10   AIDAJKRUWPUIAITHCZZRQ ses-smtp-user.20170602-090630 Never 2017-06-02------------------------------   - *Violation:* The user has reached maximum number of Inactive days   allowed 90   - *Recommendation:* Please LogIn to your account in every 10 days, to   prevent your account from getting deleted in future   - *Action taken:* None   - *Resource details:*   Resource ID User Name Password Last Used Access Keys Last Used Delete On   AIDAJFEWK4NVMEPJD2DJ2 cveillette@Andromeda3.com Never Never 2018-08-02------------------------------Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Managed Cloud: spendhq] Inactive IAM Users Alert,,01-08-2018 16:13,119,0,SpendHQ,"As per Rohit update on morning call, we are closing this case.",Waiting for response from spendHQ Team,"shared on emailHi Praveen,Thanks for reviewing this. Andrew/Mathew:I have deleted the account for:cveillette@Andromeda3.comdemsas.abraha@neoit.iodfowler.ses-smtp-user.20151214InternalDB01-ses-smtp-user.20160930-034009secure.spednhq.com.ses-smtp-userses-mwatts.20160329Please review the rest of the users details shared above and let us know your thoughts on this. Thanks !Regards,Rohit Puri","shared on emailHello Rohit,This is a big security risk where users Keys and Passwords are enabled and not in use. Go ahead and do it ASAP. We can always re-create on need basis.Regards,-Praveen","Hi Andrew/Mathew,We were looking to the Inactive IAM Users in your AWS Console. We found the below users which has not been active from long time or never used the credentials:Usename	Groups	Access Key Age	Password Age	Last Activity	Actioncveillette@Andromeda3.com	PowerUserGroup	None	180 days	None	REAN Team will delete this on Friday Eveningdemsas.abraha@neoit.io	None	None	None	None	REAN Team will delete this on Friday Eveningdfowler.ses-smtp-user.20151214	None	961 days	None	None	REAN Team will delete this on Friday Eveningdfowler.ses-smtp-user.20151215	None	960 days	None	518 Days	SpendHQ Team review thisInternalDB01-ses-smtp-user.20160930-034009	None	671 days	None	None	REAN Team will delete this on Friday Eveningsecure.spednhq.com.ses-smtp-user	None	993 days	None	None	REAN Team will delete this on Friday Eveningses-mwatts.20160329	None	855 days	None	None	REAN Team will delete this on Friday Eveningses-smtp-user.20151029-110924	None	1007 days	None	995 Days	SpendHQ Team review thisses-smtp-user.20170602-090630	None	426 days	None	425 Days	SpendHQ Team review thislogi.ses-smtp-user.20170616	None	411 days	None	401 Days	SpendHQ Team review thisREAN Team going to delete the users which are never been used(as mentioned in the Action Column) on Friday Evening. Please review the other users which has not been used from long time. Let us know if you have any concern regarding deleting the users. Thanks !Regards,Rohit Puri",Rohit is working on this case. Please reach out to him for further updates.,Most of the users are SES related - @rohit.puri - Please create a ticket and fix them.- Praveen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hSYko,Cloud Engineer Level 1,Closed,1110435,Incident,09-01-2019 18:50,,"Hello Team,We reducing the priority to P2 and closing the case as we have provided the detailed analysis and recommendations on another P1 case: 01110144.  Please review the case: 01110144  from your end and let us know your thoughts for the same. As this time we are marking this case as closed. Please revert back to us if you have any concerns.###Hello Team,On further analyzing the logs from the instance level we could see that there was no error reported during the time of the alert. But we noticed that there is no access log reported during the time of the alert. We went ahead and checked the httpd service uptime and it was running from 2018 there is no manual restart happened.[root@ip-10-59-100-122 httpd]# service httpd statushttpd (pid  1941) is running...[root@ip-10-59-100-122 httpd]# ps -aux | grep 1941Warning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.8/FAQroot      1941  0.0  0.0 367436  7800 ?        Ss    2018   1:10 /usr/sbin/httpdBased on this we can confirm that there was no issue from the AWS or instance. Please let us know if there any dependency issue from the application side.###Hello Team,We have checked on this alert and we could notice below points.1. From the instance lever logs, there is nothing that could have led to the alert.2. During the time of the alert, we could see a sudden spike on average latency both the Secure-SpendHQ-ELB and NewPreview-ELB during the time of the alert which reached to a high of 61574 milliseconds.3. Before the time of the alert we could see the there was a spike on the HTTP 4XX errors and the errors were from the internal IP 10.59.1.192 for PROD-SPHQ-SOPHOS-UTM-VPN014. We also noticed a spike in CPU for the backend instance PRD-WW1_122 which reached a high of  86.27%.Below are the URLs which had the highest backend processing time.POST https://secure.spendhq.com:443/spend-visibility/check_for_po_data HTTP/1.1 total > 1.35646GET https://secure.spendhq.com:443/spend-visibility/my_dashboard HTTP/1.1	total > 2.152753GET https://secure.spendhq.com:443/spend-visibility/spend_detail HTTP/1.1	total > 3.745909POST https://secure.spendhq.com:443/errors/report/js HTTP/1.1	total > 8.319953GET https://secure.spendhq.com:443/spend-visibility HTTP/1.1	total > 6.365857We have also attached the relevant logs and screenshot of the same.###Team,We checked on the instance level metrics and we could not find anything during the time of the alert.###On analyzing the issue we found the following issue:1) There were latency during the time of alert2) Request count was having spikes in graph3) There were 4XX around the time of alert as we found from the logs4) The CPU Utilization was high with the value of 86.29% on the instance5) Network In was high at that time but after the site came up we can see that Network Out was also high.We have also attached all the relevant graphs and 4XX logs for the reference###Mail Sent to leads.###Hello Team,We have received an alert regarding site down for URL: https://secure.spendhq.com/login  and got recovered within 1min. We are analyzing the issue and will back to you with the update meanwhile please let us know if you are doing any activity.","Tue, 08 Jan 2019 10:18:23 -0500Detected Error on SpendHQ SecureEstimated Downtime: 2 minuteshttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 60001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, Frankfurt DE, London UK, Frankfurt-B DE-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,08-01-2019 20:51,22,0,SpendHQ,"Hello Team,We reducing the priority to P2 and closing the case as we have provided the detailed analysis and recommendations on another P1 case: 01110144.  Please review the case: 01110144  from your end and let us know your thoughts for the same. As this time we are marking this case as closed. Please revert back to us if you have any concerns.","Hello Team,On further analyzing the logs from the instance level we could see that there was no error reported during the time of the alert. But we noticed that there is no access log reported during the time of the alert. We went ahead and checked the httpd service uptime and it was running from 2018 there is no manual restart happened.[root@ip-10-59-100-122 httpd]# service httpd statushttpd (pid  1941) is running...[root@ip-10-59-100-122 httpd]# ps -aux | grep 1941Warning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.8/FAQroot      1941  0.0  0.0 367436  7800 ?        Ss    2018   1:10 /usr/sbin/httpdBased on this we can confirm that there was no issue from the AWS or instance. Please let us know if there any dependency issue from the application side.","Hello Team,We have checked on this alert and we could notice below points.1. From the instance lever logs, there is nothing that could have led to the alert.2. During the time of the alert, we could see a sudden spike on average latency both the Secure-SpendHQ-ELB and NewPreview-ELB during the time of the alert which reached to a high of 61574 milliseconds.3. Before the time of the alert we could see the there was a spike on the HTTP 4XX errors and the errors were from the internal IP 10.59.1.192 for PROD-SPHQ-SOPHOS-UTM-VPN014. We also noticed a spike in CPU for the backend instance PRD-WW1_122 which reached a high of  86.27%.Below are the URLs which had the highest backend processing time.POST https://secure.spendhq.com:443/spend-visibility/check_for_po_data HTTP/1.1 total > 1.35646GET https://secure.spendhq.com:443/spend-visibility/my_dashboard HTTP/1.1	total > 2.152753GET https://secure.spendhq.com:443/spend-visibility/spend_detail HTTP/1.1	total > 3.745909POST https://secure.spendhq.com:443/errors/report/js HTTP/1.1	total > 8.319953GET https://secure.spendhq.com:443/spend-visibility HTTP/1.1	total > 6.365857We have also attached the relevant logs and screenshot of the same.","Team,We checked on the instance level metrics and we could not find anything during the time of the alert.",On analyzing the issue we found the following issue:1) There were latency during the time of alert2) Request count was having spikes in graph3) There were 4XX around the time of alert as we found from the logs4) The CPU Utilization was high with the value of 86.29% on the instance5) Network In was high at that time but after the site came up we can see that Network Out was also high.We have also attached all the relevant graphs and 4XX logs for the reference,Mail Sent to leads.,"Hello Team,We have received an alert regarding site down for URL: https://secure.spendhq.com/login  and got recovered within 1min. We are analyzing the issue and will back to you with the update meanwhile please let us know if you are doing any activity.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TkNVN,Cloud Engineer Level 1,Closed,1094311,Incident,04-04-2018 01:12,,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello Matthew,This is a gentle reminderPlease let us know if you are still facing the issue to connect VPN###Hello Matthew,We haven't heard back from you regarding the case for a while. For continued support regarding the same issue, you can contact us anytime. Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.###Hello Team,We haven't heard back from you.Please let us know if you have any issue regarding this case.###Hello Team,Please review our previous comment and let us know if you are facing any issue regarding this case.###Hello Matthew,Can you please confirm the username. From Sophos logs, we can find that shq-system had some issue in connecting to VPN.Please find the logs related to this user:2018:03:26-04:02:30 spendhq openvpn[7699]: shq_system/74.115.21.213:20814 Fatal TLS error (check_tls_errors_co), restarting2018:03:26-04:02:30 spendhq openvpn[7699]: shq_system/74.115.21.213:20814 SIGUSR1[soft,tls-error] received, client-instance restarting2018:03:26-04:02:30 spendhq openvpn[7699]: id=2202 severity=info sys=SecureNet sub=vpn event=Connection terminated username=shq_system variant=ssl srcip=74.115.21.213 virtual_ip=10.242.2.7 rx=5113728647 tx=1698534282018:03:26-04:02:30 spendhq openvpn[7699]: PLUGIN_CALL: POST /usr/lib/openvpn/plugins/openvpn-plugin-utm.so/PLUGIN_CLIENT_DISCONNECT status=0We are able to connect to VPN, please check it from your end once more, if you are still facing any issue, we can get on a call.###Hello Matthew,We will check on this issue and will let you know the updates.Regards,Jamelunissa.","Rean,Can you look into why I can’t connect;ar 26 09:49:27 2018 Restart pause, 5 second(s)Mon Mar 26 09:49:32 2018 WARNING: No server certificate verification method has been enabled.  See http://openvpn.net/howto.html#mitm for more info.Mon Mar 26 09:49:32 2018 TCP/UDP: Preserving recently used remote address: [AF_INET]52.0.17.10:7443Mon Mar 26 09:49:32 2018 Socket Buffers: R=[131072->131072] S=[131072->131072]Mon Mar 26 09:49:32 2018 Attempting to establish TCP connection with [AF_INET]52.0.17.10:7443 [nonblock]Mon Mar 26 09:49:32 2018 TCP: connect to [AF_INET]52.0.17.10:7443 failed: Can't assign requested addressMon Mar 26 09:49:32 2018 SIGUSR1[connection failed(soft),init_instance] received, process restartingMon Mar 26 09:49:32 2018 Restart pause, 5 second(s)Mon Mar 26 09:49:37 2018 WARNING: No server certificate verification method has been enabled.  See http://openvpn.net/howto.html#mitm for more info.Mon Mar 26 09:49:37 2018 TCP/UDP: Preserving recently used remote address: [AF_INET]52.0.17.10:7443Mon Mar 26 09:49:37 2018 Socket Buffers: R=[131072->131072] S=[131072->131072]Mon Mar 26 09:49:37 2018 Attempting to establish TCP connection with [AF_INET]52.0.17.10:7443 [nonblock]Mon Mar 26 09:49:37 2018 TCP: connect to [AF_INET]52.0.17.10:7443 failed: Can't assign requested addressMon Mar 26 09:49:37 2018 SIGUSR1[connection failed(soft),init_instance] received, process restartingMon Mar 26 09:49:37 2018 Restart pause, 5 second(s)Mon Mar 26 09:49:42 2018 WARNING: No server certificate verification method has been enabled.  See http://openvpn.net/howto.html#mitm for more info.Mon Mar 26 09:49:42 2018 TCP/UDP: Preserving recently used remote address: [AF_INET]52.0.17.10:7443Mon Mar 26 09:49:42 2018 Socket Buffers: R=[131072->131072] S=[131072->131072]Mon Mar 26 09:49:42 2018 Attempting to establish TCP connection with [AF_INET]52.0.17.10:7443 [nonblock]Mon Mar 26 09:49:42 2018 TCP: connect to [AF_INET]52.0.17.10:7443 failed: Can't assign requested addressMon Mar 26 09:49:42 2018 SIGUSR1[connection failed(soft),init_instance] received, process restartingMon Mar 26 09:49:42 2018 Restart pause, 10 second(s)-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Cannot connect to VPN,,26-03-2018 19:20,198,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello Matthew,This is a gentle reminderPlease let us know if you are still facing the issue to connect VPN","Hello Matthew,We haven't heard back from you regarding the case for a while. For continued support regarding the same issue, you can contact us anytime. Please note that no action is required on your part if you wish this case to be resolved. If we haven't heard back from you within the next 24 hours we will mark the case as Resolved, although you can re-open the case any time by sending an email back to us.","Hello Team,We haven't heard back from you.Please let us know if you have any issue regarding this case.","Hello Team,Please review our previous comment and let us know if you are facing any issue regarding this case.","Hello Matthew,Can you please confirm the username. From Sophos logs, we can find that shq-system had some issue in connecting to VPN.Please find the logs related to this user:2018:03:26-04:02:30 spendhq openvpn[7699]: shq_system/74.115.21.213:20814 Fatal TLS error (check_tls_errors_co), restarting2018:03:26-04:02:30 spendhq openvpn[7699]: shq_system/74.115.21.213:20814 SIGUSR1[soft,tls-error] received, client-instance restarting2018:03:26-04:02:30 spendhq openvpn[7699]: id=2202 severity=info sys=SecureNet sub=vpn event=Connection terminated username=shq_system variant=ssl srcip=74.115.21.213 virtual_ip=10.242.2.7 rx=5113728647 tx=1698534282018:03:26-04:02:30 spendhq openvpn[7699]: PLUGIN_CALL: POST /usr/lib/openvpn/plugins/openvpn-plugin-utm.so/PLUGIN_CLIENT_DISCONNECT status=0We are able to connect to VPN, please check it from your end once more, if you are still facing any issue, we can get on a call.","Hello Matthew,We will check on this issue and will let you know the updates.Regards,Jamelunissa.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VPQPZ,Cloud Engineer Level 3,Closed,1097686,Incident,04-05-2018 06:27,,"Praveen mentioned we don't need RCA, Just wait till tomorrow EOD and close the ticket.###Hello SpendHQ Team,The secure.spendhq.com alert down lasted for 4 mins because of the high latency. At Wormly, the URL Timeout was set to 100 seconds but during this outage time, your ELB latency was around 125-150 seconds. Hence wormly was throwing the URL down alert since the portal didn't respond in less than 100 seconds.The event has a correlation from External EB to the database where all the services were running on high utilization(CPU, Memory, and Network). REAN Suspect this might happened due to someone requests long time reports which have put the lot of pressure on the DB hence this latency was high.Let us know if you want to have any further discussions on this issue. Otherwise, we are good to close this issue.###I assigned this ticket to Praveen for final review.@Praveen Please review the RCA.###I have reviewed the RCA please share with Praveen for final review then we are good to share with Customer.###The RCA has been updated.@Rohit: Please review and suggest if any modification needed.https://docs.google.com/document/d/1XOEj21JltTNdguUZ0nQNyzlmdm9iXpI1_tSJoPjA2lU/edit?pli=1####Created RCA and need to add preventive actions on RCA: Link:https://docs.google.com/document/d/1XOEj21JltTNdguUZ0nQNyzlmdm9iXpI1_tSJoPjA2lU/edit?pli=1####Had a discussion with Rohit and he updated to create an RCA for this.###Hello Team,We haven't heard back from you.Please review the previous comments and let us know if you have any queries.###Hello Team,Please find the ELB latency logs in the attachment section.Kindly review this details and let us know the updates.###Working on ELB latency logs. will share with customer###Hello Team,On our primary analysis, We could see that the URL pointing https://secure.spendhq.com/login  to the ELB NewPreview-ELB. While checking the ELB shows the following spike at the time of the outage.1.  Average Latency (Value: 105793)2.  Requests count (Value: 258)3. The sudden spike in Surge Queue Length (Value: 13)4. ALB new connections (Value: 130)5. Estimated Processed bytes (Value: 59121314)And the NewPreview-ELB having backend instance PRD-WW2_6 and we could see the following spikes on this instance during the same time period.1. Network IN2. Network Out.Please find the screenshots for the above same in the attachment section.We will analyze from instance level and will get back to you with the updates. Kindly revert back to us in case of any queries.###Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login. The alert got resolved within 5 minutes and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.###Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login. The alert got resolved within 5 minutes and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.","Mon, 30 Apr 2018 08:51:38 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30005 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): California US, Sydney-C AU, Frankfurt DE, Dallas-B US--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,30-04-2018 18:21,102,0,SpendHQ,"Praveen mentioned we don't need RCA, Just wait till tomorrow EOD and close the ticket.","Hello SpendHQ Team,The secure.spendhq.com alert down lasted for 4 mins because of the high latency. At Wormly, the URL Timeout was set to 100 seconds but during this outage time, your ELB latency was around 125-150 seconds. Hence wormly was throwing the URL down alert since the portal didn't respond in less than 100 seconds.The event has a correlation from External EB to the database where all the services were running on high utilization(CPU, Memory, and Network). REAN Suspect this might happened due to someone requests long time reports which have put the lot of pressure on the DB hence this latency was high.Let us know if you want to have any further discussions on this issue. Otherwise, we are good to close this issue.",I assigned this ticket to Praveen for final review.@Praveen Please review the RCA.,I have reviewed the RCA please share with Praveen for final review then we are good to share with Customer.,The RCA has been updated.@Rohit: Please review and suggest if any modification needed.https://docs.google.com/document/d/1XOEj21JltTNdguUZ0nQNyzlmdm9iXpI1_tSJoPjA2lU/edit?pli=1,#Created RCA and need to add preventive actions on RCA: Link:https://docs.google.com/document/d/1XOEj21JltTNdguUZ0nQNyzlmdm9iXpI1_tSJoPjA2lU/edit?pli=1,#Had a discussion with Rohit and he updated to create an RCA for this.,"Hello Team,We haven't heard back from you.Please review the previous comments and let us know if you have any queries.","Hello Team,Please find the ELB latency logs in the attachment section.Kindly review this details and let us know the updates.",Working on ELB latency logs. will share with customer,"Hello Team,On our primary analysis, We could see that the URL pointing https://secure.spendhq.com/login  to the ELB NewPreview-ELB. While checking the ELB shows the following spike at the time of the outage.1.  Average Latency (Value: 105793)2.  Requests count (Value: 258)3. The sudden spike in Surge Queue Length (Value: 13)4. ALB new connections (Value: 130)5. Estimated Processed bytes (Value: 59121314)And the NewPreview-ELB having backend instance PRD-WW2_6 and we could see the following spikes on this instance during the same time period.1. Network IN2. Network Out.Please find the screenshots for the above same in the attachment section.We will analyze from instance level and will get back to you with the updates. Kindly revert back to us in case of any queries.","Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login. The alert got resolved within 5 minutes and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.","Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://secure.spendhq.com/login. The alert got resolved within 5 minutes and the website is now accessible. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001cISY3,Cloud Engineer Level 2,Closed,1105411,Incident,10-10-2018 11:54,,"@Team- We are doing a follow up through email for deletion unused ISCSI volumes. As per Rohit's Update, we are closing this case.###@Team-Rohit and Praveen are checking with SpendHQ for deleting unused ISCSI volumes.###Rohit Puri <rohit.puri@reancloud.com>4:44 PM (0 minutes ago)to Praveen, REANHi Praveen,For the duplicate iSCSI Initiatornames, most of them do not use the iSCSI volumes. We will check on this in next sprint if we do any conflict for this.For no iam-role instances, all the instances listed above are under REAN monitoring.Regards,Rohit Puri###Team,Check with Rohit on Praveen's comments and status of the email to customer###@teamDuring OPS call Praveen asked Rohit to raise the issue with customer again to ensure that unmounted or unused volumes are not showing on the machine.Rohit will be sending an email in the same respect.###Rohit updated he will work on this and will update the case.Afternoon team: Please check Rohit for further updates.###@team Please check with Rohit on this.###Hello rohit, What’s your plan to bring it down. Regards, -Praveen","Hello rohit,What’s your plan to bring it down.Regards,-PraveenFrom: ms@reancloud.com <ms@reancloud.com>Reply-To: ms@reancloud.com <ms@reancloud.com>Date: Monday, October 1, 2018 at 6:31 AMTo: ms@reancloud.com <ms@reancloud.com>Subject: ISCSI Device DetailsThe weekly report of ISCSI devices which are mounted and availableInstance_IDInstance_NameISCSI_NameMachine_Level_Disk_NameMount_DirectoryMount_Propertiesi-03ccfddd9f02cacb9PRD-DB1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-db-07-20-17-v777bb21358661922.00000026.2f1dab31-lun-0sdp/mnt/db_backup_07_20_2017rwi-03ccfddd9f02cacb9PRD-DB1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-170819-v777bb21358661922.00000028.2f1dab31-lun-0sdn/mnt/production_19082017rwi-03ccfddd9f02cacb9PRD-DB1ip-172.31.240.115:3260-iscsi-iqn.2011-04.com.zadarastorage:vsa-00000422:1-lun-0sdq/mnt/production_10-06-2017rwi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.112:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev3.ctr2-lun-3sdlNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.112:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev3.ctr2-lun-3-part1sdl1NANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.112:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev7.ctr2-lun-7sdcNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:capfiles:dev13.ctr2-lun-13sdeNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev3.ctr2-lun-3sdaNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev3.ctr2-lun-3-part1sda1NANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqdb01:dev14.ctr2-lun-14sddNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-0sdfNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-2sdgNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-2-part1sdg1NANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-3sdhNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-3-part1sdh1NANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-4sdiNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-4-part1sdi1NANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-5sdjNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-5-part1sdj1NANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev7.ctr2-lun-7sdbNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12sdmNANAi-03ccfddd9f02cacb9PRD-DB1ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0scsi-test:dev9.ctr2-lun-9sdkNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12sdb/mnt/mapd201803rwi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-mapd2:dev18.ctr1-lun-0sdo/mnt/backups/09032018rwi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.112:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev3.ctr2-lun-3sdhNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.112:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev3.ctr2-lun-3-part1sdh1NANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.112:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev7.ctr2-lun-7sdcNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:capfiles:dev13.ctr2-lun-13sdjNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev3.ctr2-lun-3sdgNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev3.ctr2-lun-3-part1sdg1NANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqdb01:dev14.ctr2-lun-14sdaNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-2sdeNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-2-part1sde1NANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-3sdfNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-3-part1sdf1NANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-4sdlNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-4-part1sdl1NANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-5sdmNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev0.ctr2-lun-5-part1sdm1NANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0-js-shqfiles01:dev7.ctr2-lun-7sddNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:map201803-180731:dev10.ctr2-lun-10sdnNANAi-04da5f97cbade5646PRD-CAT-MapD(13-03-2018)ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0scsi-test:dev9.ctr2-lun-9sdiNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server1-2018-04-01:dev10.ctr1-lun-0sdb/mnt/memsql_storagerwi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-0-part1sdc1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-1sdmNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-1-part1sdm1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-2sdpNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-2-part1sdp1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-3sdqNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-3-part1sdq1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-4sdsNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-4-part1sds1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-5sduNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-5-part1sdu1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend1:dev6.ctr1-lun-0sdaNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend2:dev7.ctr1-lun-0sdfNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server1-2018-04-01:dev10.ctr1-lun-0sdgNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server2-2018-04-01:dev11.ctr1-lun-0sdjNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server3-2018-04-01:dev12.ctr1-lun-0sdiNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-0sdeNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-0-part1sde1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-1sdnNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-1-part1sdn1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-2sdoNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-2-part1sdo1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-3sdrNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-3-part1sdr1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-4sdtNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-4-part1sdt1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-5sdvNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:dev0.ctr1-lun-5-part1sdv1NANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend1:dev6.ctr1-lun-0sddNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend2:dev7.ctr1-lun-0sdkNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server2-2018-04-01:dev11.ctr1-lun-0sdlNANAi-073579ff33c73d3cdSpendHQ-memsql-server1-2018-04-01ip-172.24.8.12:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:memsql-server3-2018-04-01:dev12.ctr1-lun-0sdhNANAi-1426f28bPRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0sda/var/www/vhosts/files.spendhq.comrwi-1426f28bPRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-170819-180402-v777bb21358661922.00000035.2f1dab31-lun-0sdeNANAi-1426f28bPRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-170819-clone-v777bb21358661922.00000044.2f1dab31-lun-0sddNANAi-1426f28bPRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-180410-v777bb21358661922.00000036.2f1dab31-lun-0sdbNANAi-1426f28bPRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-180604-clone2-v777bb21358661922.00000047.2f1dab31-lun-0sdcNANAi-1426f28bPRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-v777bb21358661922.00000029.2f1dab31-lun-0sdgNANAi-1426f28bPRD-FS1ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-db-backup-07-10-2017-v777bb21358661922.00000023.2f1dab31-lun-0sdfNANA--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: ISCSI Device Details,,01-10-2018 17:57,210,0,SpendHQ,"@Team- We are doing a follow up through email for deletion unused ISCSI volumes. As per Rohit's Update, we are closing this case.",@Team-Rohit and Praveen are checking with SpendHQ for deleting unused ISCSI volumes.,"Rohit Puri <rohit.puri@reancloud.com>4:44 PM (0 minutes ago)to Praveen, REANHi Praveen,For the duplicate iSCSI Initiatornames, most of them do not use the iSCSI volumes. We will check on this in next sprint if we do any conflict for this.For no iam-role instances, all the instances listed above are under REAN monitoring.Regards,Rohit Puri","Team,Check with Rohit on Praveen's comments and status of the email to customer",@teamDuring OPS call Praveen asked Rohit to raise the issue with customer again to ensure that unmounted or unused volumes are not showing on the machine.Rohit will be sending an email in the same respect.,Rohit updated he will work on this and will update the case.Afternoon team: Please check Rohit for further updates.,@team Please check with Rohit on this.,"Hello rohit, What’s your plan to bring it down. Regards, -Praveen",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eMTqP,Cloud Engineer Level 1,Closed,1107104,Incident,03-11-2018 00:18,,"Hello Matthew,We had further checked with these Volumes and could find that these volumes are not in use. So we have deleted them.As there is no pending action from our part we are marking this case as closed. Let us know if you have any queries.###Hello Matthew,Thanks for the approval. We will further check on this and will clean up the unused volumes and will update you.ThanksNishad Ali###Matthew Watts10:32 PM (1 hour ago)to ReanIf they are not used we can delete.###Hello SpendHQ Team,This is to bring to your attention below list of unused EBS volumes.Please provide approval to clean them up or give reason to retain them. Take note that unattached EBS volume are chargeable.1.Volume Name: Volume ID: vol-09942701b7515ed79Volume Size: 100 GiBState: AvailableDate Created: July 27, 2018 at 1:33:02 AM UTC+3AZ: us-east-1b2.Volume Name: SpendHQ-Server1-2018-06-15cloneVolume ID: vol-0e921824fccece88cVolume Size: 50 GiBState: AvailableDate Created: June 16, 2018 at 7:54:17 AM UTC+3AZ: us-east-1b3.Volume Name: Volume ID: vol-08525b5a8797e3935Volume Size: 500 GiBState: AvailableDate Created: May 10, 2018 at 3:23:44 AM UTC+3AZ: us-east-1bThanks.","Please clean it up ASAPFrom: ms@reancloud.com <ms@reancloud.com>Sent: November 2, 2018 10:04 AMTo: spendhq-support@reancloud.comSubject: [Managed Cloud: spendhq] Ununsed Ebs Volume checkREAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud.The following AWS::EC2::Volume resources were affected:________________________________  *   Violation: EBS volume is not attached any stopped or running EC2 instance.  *   Recommendation: Review the use of the unattached EBS volume. Unattached EBS volume are chargeable.  *   Action taken: None  *   Resource details:Resource IDVolume NameTypeOwnerRegionCreation DateSizeAgevol-08525b5a8797e3935A3-DX-Failover-Test-FixGeneral Purpose SSDus-east-12018-05-10500 GiB176 daysvol-060c6db8b26f5244fGeneral Purpose SSDspendhq-support@reancloud.com<mailto:spendhq-support@reancloud.com>us-east-12018-06-078 GiB148 daysvol-0e921824fccece88cSpendHQ-Server1-2018-06-15cloneGeneral Purpose SSDspendhq-support@reancloud.com<mailto:spendhq-support@reancloud.com>us-east-12018-06-1650 GiB139 daysvol-09942701b7515ed79General Purpose SSDus-east-12018-07-26100 GiB98 daysvol-78e4f4c5CloudEndure Volume u978vStandardus-west-12016-05-2510 GiB890 days________________________________Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Managed Cloud: spendhq] Ununsed Ebs Volume check,,02-11-2018 19:35,5,0,SpendHQ,"Hello Matthew,We had further checked with these Volumes and could find that these volumes are not in use. So we have deleted them.As there is no pending action from our part we are marking this case as closed. Let us know if you have any queries.","Hello Matthew,Thanks for the approval. We will further check on this and will clean up the unused volumes and will update you.ThanksNishad Ali",Matthew Watts10:32 PM (1 hour ago)to ReanIf they are not used we can delete.,"Hello SpendHQ Team,This is to bring to your attention below list of unused EBS volumes.Please provide approval to clean them up or give reason to retain them. Take note that unattached EBS volume are chargeable.1.Volume Name: Volume ID: vol-09942701b7515ed79Volume Size: 100 GiBState: AvailableDate Created: July 27, 2018 at 1:33:02 AM UTC+3AZ: us-east-1b2.Volume Name: SpendHQ-Server1-2018-06-15cloneVolume ID: vol-0e921824fccece88cVolume Size: 50 GiBState: AvailableDate Created: June 16, 2018 at 7:54:17 AM UTC+3AZ: us-east-1b3.Volume Name: Volume ID: vol-08525b5a8797e3935Volume Size: 500 GiBState: AvailableDate Created: May 10, 2018 at 3:23:44 AM UTC+3AZ: us-east-1bThanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DnLNC,Cloud Engineer Level 1,Closed,1065295,Incident,28-06-2017 06:47,,"Hello SpendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 81%. The violation lasted for 3 hours.We are closely monitoring the volume usage status and will inform your team if we again witness any spikes in the vi\\olume usage. Kindly validate these details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1       50G   47G   43M 100% /Files under root directory, 47G     total18G     usr17G     tmp12G     var523M    home285M    lib282M    optFiles under /tmp folder, 17G     total5.6G    liger_view_cff97cebc695fb18e222e5dedded2a23.csv2.2G    liger_view_210517be7a55f9b79ff655ff3699a076.csv1.8G    liger_view_943ef6f4f72be240b2622fcfa122d988.csv1.3G    liger_view_5c1018c05721ed23f37aee2b632b4e94.csv1.2G    liger_view_74d3df4c0435a74ba0a26f9a824556e2.csv1.2G    liger_view_458dbf01cd9766bc141964e1d6e193cf.csv652M    liger_view_3f2116c49ed5043f69412c128ade96ba.csv461M    liger_view_cbea22ef8a74d565eb9f8d4749332dc6.csv358M    liger_view_03f7fbf6b8f327efaae91a0d6458e80b.csv286M    liger_view_897aed78457b53cc02eeefbb5699955b.csv262M    liger_view_d7803b83619071bcf4ccea035ecdf216.csv221M    spark-2.1.0-bin-hadoop2.7216M    liger_view_304b3103c7b7b3a51526b509a772f5ca.csv183M    liger_view_2873bb4caea210ea05a294dadf218352.csv99M     liger_view_df807d4c59f568593f03ea2d1399c0f5.csv78M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm67M     liger_view_dcc8ecb85d0a773e151eb8c6e1811fdb.csv50M     liger_view_48340e06c2b974e3c47e47624827f112.csv49M     reportsFiles under /usr  folder, 18G     total16G     local882M    share813M    lib130M    lib6459M     binDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 90.685This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3931428556097196665 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,28-06-2017 01:41,5,0,SpendHQ,"Hello SpendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 81%. The violation lasted for 3 hours.We are closely monitoring the volume usage status and will inform your team if we again witness any spikes in the vi\\olume usage. Kindly validate these details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1       50G   47G   43M 100% /Files under root directory, 47G     total18G     usr17G     tmp12G     var523M    home285M    lib282M    optFiles under /tmp folder, 17G     total5.6G    liger_view_cff97cebc695fb18e222e5dedded2a23.csv2.2G    liger_view_210517be7a55f9b79ff655ff3699a076.csv1.8G    liger_view_943ef6f4f72be240b2622fcfa122d988.csv1.3G    liger_view_5c1018c05721ed23f37aee2b632b4e94.csv1.2G    liger_view_74d3df4c0435a74ba0a26f9a824556e2.csv1.2G    liger_view_458dbf01cd9766bc141964e1d6e193cf.csv652M    liger_view_3f2116c49ed5043f69412c128ade96ba.csv461M    liger_view_cbea22ef8a74d565eb9f8d4749332dc6.csv358M    liger_view_03f7fbf6b8f327efaae91a0d6458e80b.csv286M    liger_view_897aed78457b53cc02eeefbb5699955b.csv262M    liger_view_d7803b83619071bcf4ccea035ecdf216.csv221M    spark-2.1.0-bin-hadoop2.7216M    liger_view_304b3103c7b7b3a51526b509a772f5ca.csv183M    liger_view_2873bb4caea210ea05a294dadf218352.csv99M     liger_view_df807d4c59f568593f03ea2d1399c0f5.csv78M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm67M     liger_view_dcc8ecb85d0a773e151eb8c6e1811fdb.csv50M     liger_view_48340e06c2b974e3c47e47624827f112.csv49M     reportsFiles under /usr  folder, 18G     total16G     local882M    share813M    lib130M    lib6459M     binDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FbRiS,Cloud Engineer Level 1,Closed,1071704,Incident,04-08-2017 18:34,,"Hello Matthew, We are currently working on this case and will get back to you with the updates once it is done. We are following this under the ticket 01071363. Please let us know if you have any further queries.","What is the status of setting up the load balancer and server? -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Load Balancer,,04-08-2017 18:19,0,0,SpendHQ,"Hello Matthew, We are currently working on this case and will get back to you with the updates once it is done. We are following this under the ticket 01071363. Please let us know if you have any further queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001KnvB3,Cloud Engineer Level 2,Closed,1084843,Incident,21-11-2017 14:28,,"Team,Please put your initial RCA draft link on Problem ticket and close this one out.###Hi SpendHQ Team,As this is a known problem for SpendHQ and there is no permanent fix for this at this time. We want to track it separately to find a root cause with a permanent fix, We have created a problem ticket for this. Following is the problem ticket Id for this issue: Problem Ticket: 01084941. For now, we are closing this P1 ticket as the issue got resolved in the SpendHQ environment. We will provide our updates on the problem ticket created and will also provide an RCA with a possible permanent fix.We want to do a thorough analysis of this, hence this may take a few days to complete. Please let us know if you have any questions for us.###Did get much time to start on the RCA. Refer the below document and complete the RCA for this issue.https://docs.google.com/document/d/1WWH2h-54q0NPsd8HxHk1zWOEDiOGh-u6AGt_ogY1xI0/edit#####on 10.59.100.125commented all the non root fs mounts on the /etc/fstabrebooted the servermounted the iSCSI volume firstOn the NFS server created a new export folder /exports_productionmounted the /var/www/vhosts/files.spendhq.com to /exports_productionUpdated the /etc/fstab filesupdated the /etc/exports file with the new folder exports_productionthen changed the nfs mount details on all the secure, preview and supervisor servers by unmounting exoisting mounts a nd updating correct fstab entries.###Hello Team,Thank you for joining the call. As the issue got resolved, we will work on the RCA and will share with you.###Hello Dusty,Please join the below bridge to troubleshoot the issue.https://reancloud.zoom.us/j/986547156###Hello Dusty,Could you please provide some more details regarding the server and mount details.","Could somebody please take a look at our mount.  It appears to have gone into read only mode and everything is erroring our for us.  This needs to be corrected ASAP as we are under a Sev 1.Dusty Fowler | Developer | SpendHQ(r)O: 770.628.0026 | dfowler@spendhq.com<mailto:dfowler@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",files read only,,20-11-2017 20:56,18,0,SpendHQ,"Team,Please put your initial RCA draft link on Problem ticket and close this one out.","Hi SpendHQ Team,As this is a known problem for SpendHQ and there is no permanent fix for this at this time. We want to track it separately to find a root cause with a permanent fix, We have created a problem ticket for this. Following is the problem ticket Id for this issue: Problem Ticket: 01084941. For now, we are closing this P1 ticket as the issue got resolved in the SpendHQ environment. We will provide our updates on the problem ticket created and will also provide an RCA with a possible permanent fix.We want to do a thorough analysis of this, hence this may take a few days to complete. Please let us know if you have any questions for us.",Did get much time to start on the RCA. Refer the below document and complete the RCA for this issue.https://docs.google.com/document/d/1WWH2h-54q0NPsd8HxHk1zWOEDiOGh-u6AGt_ogY1xI0/edit,"##on 10.59.100.125commented all the non root fs mounts on the /etc/fstabrebooted the servermounted the iSCSI volume firstOn the NFS server created a new export folder /exports_productionmounted the /var/www/vhosts/files.spendhq.com to /exports_productionUpdated the /etc/fstab filesupdated the /etc/exports file with the new folder exports_productionthen changed the nfs mount details on all the secure, preview and supervisor servers by unmounting exoisting mounts a nd updating correct fstab entries.","Hello Team,Thank you for joining the call. As the issue got resolved, we will work on the RCA and will share with you.","Hello Dusty,Please join the below bridge to troubleshoot the issue.https://reancloud.zoom.us/j/986547156","Hello Dusty,Could you please provide some more details regarding the server and mount details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Uw6R5,Cloud Engineer Level 1,Closed,1101409,Incident,12-07-2018 11:41,,"Hello Team, This is to inform you that we have received an alert regarding clock in sync with NTP on the host. i-0627929bed380b8da The alert got resolved and the violation lasted for within One minutes. We have checked the NTP status which is synced on this host. As the alert in recovered state, We are marking this case as resolved and hence closing the case. Kindly revert back to us in case of any queries.###Hello Team,This is to inform you that we have received [Auto] Clock in sync with NTP on the following hosts:i-0627929bed380b8dai-093eff6fae479397c10.59.10.20For all the above the hosts the alert got resolved and the violation lasted for one minute.","[image: Datadog][Triggered on {host:i-0627929bed380b8da}] [Auto] Clock in sync with NTPTriggers if any host's clock goes out of sync with the time given by NTP.The offset threshold is configured in the Agent's ntp.yaml file.Please read the KB article<http://help.datadoghq.com/hc/en-us/articles/204282095-Network-Time-Protocol-NTP-Offset-Issues>on NTP Offset issues for more details on cause and resolution.@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>Offset 80 secs higher than offset threshold (60 secs)The monitor was last triggered at Wed Jul 11 2018 21:34:22 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#1953584?group=host%3Ai-0627929bed380b8da>]· [Edit Monitor <https://app.datadoghq.com/monitors#1953584/edit>] · [Viewi-0627929bed380b8da<https://app.datadoghq.com/infrastructure?filter=i-0627929bed380b8da>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CASC&to_ts=1531344862000&tags=host%3Ai-0627929bed380b8da&from_ts=1531343962000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4480892377808918105>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [Auto] Clock in sync with NTP on host:i-0627929bed380b8da,,12-07-2018 03:06,9,0,SpendHQ,"Hello Team, This is to inform you that we have received an alert regarding clock in sync with NTP on the host. i-0627929bed380b8da The alert got resolved and the violation lasted for within One minutes. We have checked the NTP status which is synced on this host. As the alert in recovered state, We are marking this case as resolved and hence closing the case. Kindly revert back to us in case of any queries.","Hello Team,This is to inform you that we have received [Auto] Clock in sync with NTP on the following hosts:i-0627929bed380b8dai-093eff6fae479397c10.59.10.20For all the above the hosts the alert got resolved and the violation lasted for one minute.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d48QY,Cloud Engineer Level 1,Closed,1106395,Incident,19-10-2018 16:40,,"as we created a new a new clone server requested by Matthew.closing this case.###Matthew WattsThu, Oct 18, 6:31 PM (22 hours ago)to Paul, Shubhankar, spendhq-support@reancloud.comConfirmed###Paul Mulonzia2:48 PM (0 minutes ago)to Shubhankar, Matthew, spendhq-supportHello Matthew,Kindly raise a separate  request ticket to clone this server.Thanks.###Shubhankar Raman <shubhankar.raman@reancloud.com>7:19 AM (0 minutes ago)to Matthew, spendhq-supportHello Matthew,We will work on it and will let you know the updates.###Matthew Watts7:11 AM (3 minutes ago)to Rean, spendhq-support@reancloud.comWe are not. Let’s create a clone of this server please.###[Via mail]Hello SpendHQ, We are receiving multiple alerts regarding High Memory Utilization on prd-ww2_6 - 10.59.101.6 - web from our analysis we could see that httpd is consuming most memory and CPU. We could also notice that during the time of the alert there was a drop in both networks in and out. The alert got recovered after 10 minutes. please let us know if you are performing any action on your end. PID PPID CMD %MEM %CPU 30335 23855 /usr/sbin/httpd 2.5 5.6###Hello SpendHQ, We are receiving multiple alerts regarding High Memory Utilization on prd-ww2_6 - 10.59.101.6 - web from our analysis we could see that httpd is consuming most memory 98% and CPU94.56%. We could also notice that during the time of the alert there was a drop in both networks in and out. The alert got recovered after 10 minutes. please let us know if you are performing any action on your end. Also attached is a screenshot of the process during the time of alert Resource DetailsInstance ID	i-01ac95c23ac66a40e	Instance Name or ID	PRD-WW2_6	Instance Type	m4.2xlarge	Availability Zone	us-east-1c	Region	us-east-1Private DNS Name	ip-10-59-101-6.ec2.internal	Private IP Address	10.59.101.6Subnet ID	subnet-29b09361	VPC	vpc-76df7212","[Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 -10.59.101.6 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1539805197000&group=host%3Ai-01ac95c23ac66a40e&from_ts=1539797997000>avg(last_30m):(avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by {host}- avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by{host} ) /avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9} by{host} * 100 > 95The monitor was last triggered at Wed Oct 17 2018 19:39:57 UTC (*1 min ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-01ac95c23ac66a40e>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-01ac95c23ac66a40e<https://app.datadoghq.com/infrastructure?filter=i-01ac95c23ac66a40e>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1539805317000&tags=host%3Ai-01ac95c23ac66a40e&from_ts=1539804297000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQ",[Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww2_6 - 10.59.101.6 - web,,18-10-2018 01:12,39,0,SpendHQ,as we created a new a new clone server requested by Matthew.closing this case.,"Matthew WattsThu, Oct 18, 6:31 PM (22 hours ago)to Paul, Shubhankar, spendhq-support@reancloud.comConfirmed","Paul Mulonzia2:48 PM (0 minutes ago)to Shubhankar, Matthew, spendhq-supportHello Matthew,Kindly raise a separate  request ticket to clone this server.Thanks.","Shubhankar Raman <shubhankar.raman@reancloud.com>7:19 AM (0 minutes ago)to Matthew, spendhq-supportHello Matthew,We will work on it and will let you know the updates.","Matthew Watts7:11 AM (3 minutes ago)to Rean, spendhq-support@reancloud.comWe are not. Let’s create a clone of this server please.","[Via mail]Hello SpendHQ, We are receiving multiple alerts regarding High Memory Utilization on prd-ww2_6 - 10.59.101.6 - web from our analysis we could see that httpd is consuming most memory and CPU. We could also notice that during the time of the alert there was a drop in both networks in and out. The alert got recovered after 10 minutes. please let us know if you are performing any action on your end. PID PPID CMD %MEM %CPU 30335 23855 /usr/sbin/httpd 2.5 5.6","Hello SpendHQ, We are receiving multiple alerts regarding High Memory Utilization on prd-ww2_6 - 10.59.101.6 - web from our analysis we could see that httpd is consuming most memory 98% and CPU94.56%. We could also notice that during the time of the alert there was a drop in both networks in and out. The alert got recovered after 10 minutes. please let us know if you are performing any action on your end. Also attached is a screenshot of the process during the time of alert Resource DetailsInstance ID	i-01ac95c23ac66a40e	Instance Name or ID	PRD-WW2_6	Instance Type	m4.2xlarge	Availability Zone	us-east-1c	Region	us-east-1Private DNS Name	ip-10-59-101-6.ec2.internal	Private IP Address	10.59.101.6Subnet ID	subnet-29b09361	VPC	vpc-76df7212",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKoJ,Cloud Engineer Level 1,Closed,1042232,Incident,,,,"Can we please just image the server and perform updates once done. Please advise when the image is complete and the upgrade.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]Sent: Friday, January 13, 2017 9:37 PMTo: Matthew Watts <mwatts@spendhq.com>Cc: REAN Support <support@reancloud.com>Subject: Re: MaintenanceHello Matthew,As mentioned earlier, Andromeda team is going to clone the volume before we proceed with the patching of the instance.Please let us know if that is done so that we can proceed with the security patching.On Sat, Jan 14, 2017 at 8:00 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Please update the 10.59.10.12 machine first and advise when complete.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com<mailto:mrigank.saxena@reancloud.com>]Sent: Friday, January 13, 2017 9:24 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,We are ready for the maintenance. Please let us know once you start making the changes.On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Rean Team are you ready to commence the updates as planned on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Maintenance,,14-01-2017 08:32,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EVUvV,Cloud Engineer Level 1,Closed,1068278,Incident,16-07-2017 19:36,,"Hello SpendHQ Team, This is to notify you that we have received an alert that the network inbound for prod-sphq-db-server05 is above the threshold of 2200000000.0.The alert got resolved within few minutes and returned to normal. Resource details: Instance Name - prod-sphq-db-server05 Instance ID - i-008d43ad00357e47a VPC ID - vpc-76df7212 Instance type - r3.8xlarge","[Triggered] [SpendHQ] - High Network IN  on host - prod-sphq-db-server05 - 10.59.10.135 - db Status  High Network IN on the instance. Please check the list open TCP Connections    @support@reancloud.comaws.ec2.network_in over host:10.59.10.135,monitoring:on was > 2200000000.0 at all times during the last 5m.Metric value: 3554276864.0This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024210?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2024210/edit · Event URL: https://app.datadoghq.com/event/event?id=3958549480618896960 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network IN on host - prod-sphq-db-server05 - 10.59.10.135 - db Status,,16-07-2017 18:43,1,0,SpendHQ,"Hello SpendHQ Team, This is to notify you that we have received an alert that the network inbound for prod-sphq-db-server05 is above the threshold of 2200000000.0.The alert got resolved within few minutes and returned to normal. Resource details: Instance Name - prod-sphq-db-server05 Instance ID - i-008d43ad00357e47a VPC ID - vpc-76df7212 Instance type - r3.8xlarge",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001XEulC,Cloud Engineer Level 1,Closed,1100076,Incident,14-06-2018 03:51,,"Hello Team, Please review or previously shared comments and do reach out to us in case you need any clarification.Since the alert was recovered we are as well marking this case as closed.Thank you.###Hello Team,After further analysis into the matter, we realized that there was a bit of Latency and Request count spike during the period of the error.From the CloudWatch Average Latency metrics, we could see a spike of 23868.404 milliseconds at around 5:24:00 PM UTC. At 5:25:00 PM UTC it hit it's highest at 26487.986 milliseconds. Request count was at 5:27:00 PM UTC with a value of 199 counts.Please find attached in the attachement section logs for the said period. Kindly validate them from your end and feel free to get in touch with us in case you need further clarification.Thank you.###Hello SpendHQ Team, This is to inform you that we've received a site down alert on URL: https://preview.spendhq.com/login. The downtime lasted for 2 minutes and eventually got recovered within 1 minute. We are analyzing this and will get back to you with further details on the issue. Thank you.","Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): California US, Sydney-C AU, New Jersey US, Dallas-B US-- Hosea B. Getusi,*Cloud Engineer,**REĀN Cloud. **Mobile*: +254713404220 | *Skype*: hoseagetusihosea.getusi@reancloud.com <yogesh.maloo@reancloud.com> | www.reancloud.co<http://www.reancloud.com/>m--",Detected Error on SpendHQ Preview,,12-06-2018 22:58,29,0,SpendHQ,"Hello Team, Please review or previously shared comments and do reach out to us in case you need any clarification.Since the alert was recovered we are as well marking this case as closed.Thank you.","Hello Team,After further analysis into the matter, we realized that there was a bit of Latency and Request count spike during the period of the error.From the CloudWatch Average Latency metrics, we could see a spike of 23868.404 milliseconds at around 5:24:00 PM UTC. At 5:25:00 PM UTC it hit it's highest at 26487.986 milliseconds. Request count was at 5:27:00 PM UTC with a value of 199 counts.Please find attached in the attachement section logs for the said period. Kindly validate them from your end and feel free to get in touch with us in case you need further clarification.Thank you.","Hello SpendHQ Team, This is to inform you that we've received a site down alert on URL: https://preview.spendhq.com/login. The downtime lasted for 2 minutes and eventually got recovered within 1 minute. We are analyzing this and will get back to you with further details on the issue. Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C4KUW,Cloud Engineer Level 1,Closed,1055786,Incident,27-05-2017 17:40,,"Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167 which belongs to the Preview ELB.On further analyzing the ELB logs at the time of the alert, We are able to figure out one IP 122.114.39.176  was trying to execute the SERVER-APACHE Apache Struts remote code. IP trace detailsIP: 122.114.39.176Country: ChinaOrganization: Zhengzhou GIANT Computer Network Technology Co., LtdPlease find the ELB logs details below, 2017-05-27T10:04:11.843175Z preview-spendhq-xelb 122.114.39.176:49575 10.59.1.192:80 0.00004 0.001952 0.000036 403 403 0 219 GET http://52.4.199.57:80/phpmyadmin HTTP/1.1 Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1) - -2017-05-27T10:04:12.141616Z preview-spendhq-xelb 122.114.39.176:49575 10.59.1.192:80 0.000043 0.001665 0.000024 403 403 0 219 GET http://52.4.199.57:80/phpmyadmin HTTP/1.1 Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1) - -###Hello Andrew,Thanks for the update. We will wait for June 10th Sophos Firmware update and see if these false positives are getting covered with that. We will keep monitoring the alerts and investigate the logs but will filter the false positives before informing you till the Firmware update in order to avoid this unwanted noise for you.We will keep the remaining updates in the ticket 01055736. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM###Andrew Kim2:35 AM (1 hour ago)to Rean, spendhq-support Hi Safuvan, My thought was to block the IP address at the NACL level, but based on a previous email, it sounds like there may be some false positives which may be resolved with the Sophos update scheduled for June 10th. Let’s keep the existing policy to drop requests for the remote code. In addition, if we can also stop proactive emails regarding Struts related alerts, this would also be appreciated. At this time, we are receiving too many emails, and I want to make sure we don’t miss any critical emails. Thank you, Andrew Kim###Hello Andrew,Please answer the below questions for my better understanding.1. Did you mean to drop the requests which are trying to run the remote code(it is already in place) or to block the IP addresses (at NACL level) which are trying to execute a Struts remote code on the server (even if it is getting dropped from Sophos level)?As of now, the requests which are trying to execute a Struts remote code are getting dropped from the Sophos level and SpendHQ environment does not use the Apache Strut till now, this requests will not have any impact.Please let us know your thoughts on this.Regards,Safuvan KM###Hello Andrew,We will check this internally and will get back to you with the updates.###Hello – thank you for the emails regarding the Apache Struts attacks. Based on the number of emails and non-use of Apache Struts, can we create a rule to automatically block IPs trying to execute a Struts remote code and not send email alerts? Thanks, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hello Team,On further analyzing the ELB logs at the time of the alert, We are able to figure out one IP 178.63.51.130 which belongs to the organization -Hetzner Online AG and country Germany was trying to execute the SERVER-APACHE Apache Struts remote code.Please find the ELB logs details below, 2017-05-24T05:58:36.281343Z Secure-SpendHQ-ELB 178.63.51.130:49008 10.59.1.192:443 0.000067 0.118337 0.000043 404 404 0 28279 GET https://secure.spendhq.com:443/n/j/Y HTTP/1.1 Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; .NET CLR 1.1.4307) AES128-SHA TLSv1Please let us know whether we need to block this IP in the NACL level and let us know if you have any queries.###Hello Team,This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.20  which belongs to the Secure ELB. Please find the Intrusion Prevention Logs:2017:05:24-04:26:14 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=19484 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are analyzing the ELB logs and will let you know the further updates.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-24 04:26:14Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.20Source port: 19484Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 192 days 20 hours 40 minutesSystem Load        : 0.16,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,24-05-2017 10:00,18,0,SpendHQ,"Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167 which belongs to the Preview ELB.On further analyzing the ELB logs at the time of the alert, We are able to figure out one IP 122.114.39.176  was trying to execute the SERVER-APACHE Apache Struts remote code. IP trace detailsIP: 122.114.39.176Country: ChinaOrganization: Zhengzhou GIANT Computer Network Technology Co., LtdPlease find the ELB logs details below, 2017-05-27T10:04:11.843175Z preview-spendhq-xelb 122.114.39.176:49575 10.59.1.192:80 0.00004 0.001952 0.000036 403 403 0 219 GET http://52.4.199.57:80/phpmyadmin HTTP/1.1 Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1) - -2017-05-27T10:04:12.141616Z preview-spendhq-xelb 122.114.39.176:49575 10.59.1.192:80 0.000043 0.001665 0.000024 403 403 0 219 GET http://52.4.199.57:80/phpmyadmin HTTP/1.1 Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1) - -","Hello Andrew,Thanks for the update. We will wait for June 10th Sophos Firmware update and see if these false positives are getting covered with that. We will keep monitoring the alerts and investigate the logs but will filter the false positives before informing you till the Firmware update in order to avoid this unwanted noise for you.We will keep the remaining updates in the ticket 01055736. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM","Andrew Kim2:35 AM (1 hour ago)to Rean, spendhq-support Hi Safuvan, My thought was to block the IP address at the NACL level, but based on a previous email, it sounds like there may be some false positives which may be resolved with the Sophos update scheduled for June 10th. Let’s keep the existing policy to drop requests for the remote code. In addition, if we can also stop proactive emails regarding Struts related alerts, this would also be appreciated. At this time, we are receiving too many emails, and I want to make sure we don’t miss any critical emails. Thank you, Andrew Kim","Hello Andrew,Please answer the below questions for my better understanding.1. Did you mean to drop the requests which are trying to run the remote code(it is already in place) or to block the IP addresses (at NACL level) which are trying to execute a Struts remote code on the server (even if it is getting dropped from Sophos level)?As of now, the requests which are trying to execute a Struts remote code are getting dropped from the Sophos level and SpendHQ environment does not use the Apache Strut till now, this requests will not have any impact.Please let us know your thoughts on this.Regards,Safuvan KM","Hello Andrew,We will check this internally and will get back to you with the updates.","Hello – thank you for the emails regarding the Apache Struts attacks. Based on the number of emails and non-use of Apache Struts, can we create a rule to automatically block IPs trying to execute a Struts remote code and not send email alerts? Thanks, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Hello Team,On further analyzing the ELB logs at the time of the alert, We are able to figure out one IP 178.63.51.130 which belongs to the organization -Hetzner Online AG and country Germany was trying to execute the SERVER-APACHE Apache Struts remote code.Please find the ELB logs details below, 2017-05-24T05:58:36.281343Z Secure-SpendHQ-ELB 178.63.51.130:49008 10.59.1.192:443 0.000067 0.118337 0.000043 404 404 0 28279 GET https://secure.spendhq.com:443/n/j/Y HTTP/1.1 Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; .NET CLR 1.1.4307) AES128-SHA TLSv1Please let us know whether we need to block this IP in the NACL level and let us know if you have any queries.","Hello Team,This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.20  which belongs to the Secure ELB. Please find the Intrusion Prevention Logs:2017:05:24-04:26:14 spendhq snort[12475]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.20 dstip=10.59.1.192 proto=6 srcport=19484 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are analyzing the ELB logs and will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013vud7,Cloud Engineer Level 1,Closed,1030976,Incident,,,,"New Firmware Up2Dates have been installed. The current firmware versionis now 9.407003.        -- System Uptime      : 168 days 2 hours 8 minutesSystem Load        : 0.93System Version     : Sophos UTM 9.407-3Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][INFO-302] New Firmware Up2Date installed,,12-11-2016 13:11,0,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DoiAr,Cloud Engineer Level 1,Closed,1066337,Incident,02-07-2017 18:12,,"Hello SpendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 68.9% . The violation lasted for an hour.We are monitoring on it and will keep your team updated. Kindly validate these details and let us know in case of any queries.Regards,Sumod.K.Bose###Hello SpendHQ-Team,We have analyzed the volume usage details on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). Refer the below given information,[root@ip-10-59-10-135 /]# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   46G  1.3G  98%        /Files present in root volume,19G     usr14G     tmp12G     var474M    homeHere we could see that tmp folder is consuming high volume usage. Refer the below details regarding the volume usage under /tmp folder [root@ip-10-59-10-135 tmp]# du -sch * | sort -hr14G     total14G     liger_view_1906b7ba4cda3ebf75b2479542ca0558.csv221M    spark-2.1.0-bin-hadoop2.778M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm49M     reports27M     spark-351c878d-7245-4f00-affa-34d5deff741412M     pgloader-3.3.212M     mysql-connector-java-5.1.41Kindly delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Regards, Sumod.K.Bose###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance.Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135 Delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Regards, Sumod.K.Bose","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 92.661This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3938022784224505082 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,02-07-2017 14:51,3,0,SpendHQ,"Hello SpendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 68.9% . The violation lasted for an hour.We are monitoring on it and will keep your team updated. Kindly validate these details and let us know in case of any queries.Regards,Sumod.K.Bose","Hello SpendHQ-Team,We have analyzed the volume usage details on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). Refer the below given information,[root@ip-10-59-10-135 /]# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   46G  1.3G  98%        /Files present in root volume,19G     usr14G     tmp12G     var474M    homeHere we could see that tmp folder is consuming high volume usage. Refer the below details regarding the volume usage under /tmp folder [root@ip-10-59-10-135 tmp]# du -sch * | sort -hr14G     total14G     liger_view_1906b7ba4cda3ebf75b2479542ca0558.csv221M    spark-2.1.0-bin-hadoop2.778M     infobright-iee_postgres-5.0.4-0-rhel_centos_6_64.rpm49M     reports27M     spark-351c878d-7245-4f00-affa-34d5deff741412M     pgloader-3.3.212M     mysql-connector-java-5.1.41Kindly delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Regards, Sumod.K.Bose","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance.Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135 Delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Regards, Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001OYuui,Cloud Engineer Level 1,Closed,1089041,Incident,19-01-2018 21:36,,"Yogesh Maloo9:28 PM (7 minutes ago)to Sanket, REAN Sure Sanket,We need to purchase more RI. I will initiate the discussion in next meeting.Regards,Yogesh MalooSenior Cloud Engineer, REĀN Cloud###Hello Andrew,We have stopped the instance 10.59.10.12.Feel free to reach out to us for any assistance.--Thanks & Regards,Safuvan KM###Andrew Kim <Akim@spendhq.com>9:04 PM (18 minutes ago)to Safuvan, Matthew, David, REAN Please put 10.59.10.12 into a STOP state in case we need to start the server again.Thank you,###Sanket Dangi9:06 PM (15 minutes ago)to Yogesh, REAN Yogesh,Make sure reservations are not affected.Thank You,Sanket Dangi###Safuvan Kotakuthmatayil <safuvan.kotakuthmatayil@reancloud.com>9:00 PM (21 minutes ago)to Andrew, Matthew, David, REAN ​Hello Matthew,Could you please approve this request?​","Rean,We have verified all servers are using the new elastic cache server and we need to decommission 10.59.10.12.  Please let me know when this has been completed.Thank YouDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/>--  <https://www.reancloud.com/aws-sko/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Decommission Server,,19-01-2018 20:50,1,0,SpendHQ,"Yogesh Maloo9:28 PM (7 minutes ago)to Sanket, REAN Sure Sanket,We need to purchase more RI. I will initiate the discussion in next meeting.Regards,Yogesh MalooSenior Cloud Engineer, REĀN Cloud","Hello Andrew,We have stopped the instance 10.59.10.12.Feel free to reach out to us for any assistance.--Thanks & Regards,Safuvan KM","Andrew Kim <Akim@spendhq.com>9:04 PM (18 minutes ago)to Safuvan, Matthew, David, REAN Please put 10.59.10.12 into a STOP state in case we need to start the server again.Thank you,","Sanket Dangi9:06 PM (15 minutes ago)to Yogesh, REAN Yogesh,Make sure reservations are not affected.Thank You,Sanket Dangi","Safuvan Kotakuthmatayil <safuvan.kotakuthmatayil@reancloud.com>9:00 PM (21 minutes ago)to Andrew, Matthew, David, REAN ​Hello Matthew,Could you please approve this request?​",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001Vs9yS,Cloud Engineer Level 1,Closed,1098398,Incident,10-05-2018 20:10,,"Hello Allen,Thanks for the update.Since the issue has been resolved we are marking the case as closed.###Hey Rean I got preview back online. The database it was connected to was offline. I’m assuming because of what happened on Tuesday. I tail’d  /var/www/vhosts/secure.spendhq.com/public/app/tmp/logs/* Saw this error2018-05-10 09:31:06 Warning: Warning (2): mysqli_query() expects parameter 1 to be mysqli, boolean given in [/var/www/vhosts/secure.spendhq.com/public/cake/libs/model/datasources/dbo/dbo_mysqli.php, line 111] Proceed to the database it was connected to at 10.59.10.135 Ran ps aux | grep mysql Saw nothing so I restarted the database. Don’t ever restart a database without asking beforehand, I just wanted to walk you through how I solved it.###Hello Team,This is to inform you that the alert regarding site down for the URL https://preview.spendhq.com/login is still in an open state and we are getting 500 response code while trying to access the URL. While checking the details at the instance level we could see there is php fatal error from the logs /var/www/vhosts/files.spendhq.com/w2/logs/web2-94-https-preview.spendhq.com-error.log.Sample logs are provided with this ticket. Please review the details with the application team and fix the issue. Let us know if you have any queries.[Thu May 10 10:54:36 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 10:54:36 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 10:54:40 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 10:54:41 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 10:54:42 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 10:54:42 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693###Hello Team,This is to notify you regarding the site down issue on url: https://preview.spendhq.com/login the site is still down please review the httpd error logs from the previous comment.http://www.php.net/manual/en/ini.core.php#ini.memory-limitmemory_limit = 4096M###Hello Team,We received the multiple alerts regarding the site down for failure and recoveries. The site still showing the Error: An Internal Error Has Occurred###On further analysis, we found that the issue now is related to the PHP fatal error. Please find the error logs below: tail -100 /var/log/httpd/error.log [[Wed May 09 21:42:59 2018] [error] [client 10.59.101.200] No Access, referer: https://secure.spendhq.com/spend-visibility[Wed May 09 21:43:18 2018] [error] [client 10.59.100.129] No Access, referer: https://secure.spendhq.com/spend-visibility[Wed May 09 21:43:56 2018] [error] [client 10.59.100.129] PHP Fatal error:  Allowed memory size of 4294967296 bytes exhausted (tried to allocate 64 bytes) in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 515, referer: https://secure.spendhq.com/spend-visibility/my_dashboard[Wed May 09 21:44:35 2018] [error] [client 10.59.100.129] PHP Fatal error:  Allowed memory size of 4294967296 bytes exhausted (tried to allocate 72 bytes) in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 515, referer: https://secure.spendhq.com/spend-visibility/my_dashboard[Wed May 09 21:53:31 2018] [error] [client 10.59.101.200] SHQ_Exception: [1]: Encryption Authentication Exception Thrown with message Could not access password provided for user 2660. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/components/auth.php on line 252 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/login[Wed May 09 21:53:50 2018] [error] [client 10.59.100.129] No Access, referer: https://secure.spendhq.com/spend-visibility[Wed May 09 21:54:10 2018] [error] [client 10.59.100.129] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:33955984[Wed May 09 21:55:44 2018] [error] [client 10.59.101.200] PHP Fatal error:  Allowed memory size of 4294967296 bytes exhausted (tried to allocate 72 bytes) in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 515, referer: https://secure.spendhq.com/spend-visibility/my_dashboardPlease let us know if you have any more queries regarding this issue.###Hello Team,We were able to witness an issue like Error: An Internal Error Has Occurred. Please let us know if your team was performing any activity from your end during the time.This was a nonproduction site. We are reducing the priority to P2###Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.","Wed, 09 May 2018 16:04:00 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 59 seconds https://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 500, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: Atlanta-B USConfirmed by node(s): London UK, California US, Dallas-B US, New Jersey US--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Preview,,10-05-2018 01:34,19,0,SpendHQ,"Hello Allen,Thanks for the update.Since the issue has been resolved we are marking the case as closed.","Hey Rean I got preview back online. The database it was connected to was offline. I’m assuming because of what happened on Tuesday. I tail’d  /var/www/vhosts/secure.spendhq.com/public/app/tmp/logs/* Saw this error2018-05-10 09:31:06 Warning: Warning (2): mysqli_query() expects parameter 1 to be mysqli, boolean given in [/var/www/vhosts/secure.spendhq.com/public/cake/libs/model/datasources/dbo/dbo_mysqli.php, line 111] Proceed to the database it was connected to at 10.59.10.135 Ran ps aux | grep mysql Saw nothing so I restarted the database. Don’t ever restart a database without asking beforehand, I just wanted to walk you through how I solved it.","Hello Team,This is to inform you that the alert regarding site down for the URL https://preview.spendhq.com/login is still in an open state and we are getting 500 response code while trying to access the URL. While checking the details at the instance level we could see there is php fatal error from the logs /var/www/vhosts/files.spendhq.com/w2/logs/web2-94-https-preview.spendhq.com-error.log.Sample logs are provided with this ticket. Please review the details with the application team and fix the issue. Let us know if you have any queries.[Thu May 10 10:54:36 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 10:54:36 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 10:54:40 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 10:54:41 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 10:54:42 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693[Thu May 10 10:54:42 2018] [error] [client 10.59.1.192] PHP Fatal error:  Call to a member function get_navigation() on null in /var/www/vhosts/secure.spendhq.com/public/app/app_controller.php on line 4693","Hello Team,This is to notify you regarding the site down issue on url: https://preview.spendhq.com/login the site is still down please review the httpd error logs from the previous comment.http://www.php.net/manual/en/ini.core.php#ini.memory-limitmemory_limit = 4096M","Hello Team,We received the multiple alerts regarding the site down for failure and recoveries. The site still showing the Error: An Internal Error Has Occurred","On further analysis, we found that the issue now is related to the PHP fatal error. Please find the error logs below: tail -100 /var/log/httpd/error.log [[Wed May 09 21:42:59 2018] [error] [client 10.59.101.200] No Access, referer: https://secure.spendhq.com/spend-visibility[Wed May 09 21:43:18 2018] [error] [client 10.59.100.129] No Access, referer: https://secure.spendhq.com/spend-visibility[Wed May 09 21:43:56 2018] [error] [client 10.59.100.129] PHP Fatal error:  Allowed memory size of 4294967296 bytes exhausted (tried to allocate 64 bytes) in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 515, referer: https://secure.spendhq.com/spend-visibility/my_dashboard[Wed May 09 21:44:35 2018] [error] [client 10.59.100.129] PHP Fatal error:  Allowed memory size of 4294967296 bytes exhausted (tried to allocate 72 bytes) in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 515, referer: https://secure.spendhq.com/spend-visibility/my_dashboard[Wed May 09 21:53:31 2018] [error] [client 10.59.101.200] SHQ_Exception: [1]: Encryption Authentication Exception Thrown with message Could not access password provided for user 2660. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/components/auth.php on line 252 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/login[Wed May 09 21:53:50 2018] [error] [client 10.59.100.129] No Access, referer: https://secure.spendhq.com/spend-visibility[Wed May 09 21:54:10 2018] [error] [client 10.59.100.129] No Access, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:33955984[Wed May 09 21:55:44 2018] [error] [client 10.59.101.200] PHP Fatal error:  Allowed memory size of 4294967296 bytes exhausted (tried to allocate 72 bytes) in /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 515, referer: https://secure.spendhq.com/spend-visibility/my_dashboardPlease let us know if you have any more queries regarding this issue.","Hello Team,We were able to witness an issue like Error: An Internal Error Has Occurred. Please let us know if your team was performing any activity from your end during the time.This was a nonproduction site. We are reducing the priority to P2","Hello SpendHQ-Team, This is to inform you that we have received an alert regarding site down for the URL https://preview.spendhq.com/login. We are further performing more analysis on this issue and will get back to you with the updates shortly. Meanwhile please let us know if you are performing any activities.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ZC79m,Cloud Engineer Level 2,Closed,1101928,Incident,31-07-2018 12:57,,"Hello Team,We are tracking this case on another ticket (01099898). Now we are closing this case.###Hi Andrew,We have mounted the volume in PRD-CAT-MapD(13-03-2018)-COPY machine at location /mnt/mapd201805/. For resolving this, we mounted the blank volume provided by Chris and copied the data from the machine it was cloned PRD-CAT-MapD(13-03-2018. Please verify the data and let us know if you find any issue.Chris:Thanks for providing the volume. Before that we were not able to mount this volume as error we were facing of read-only (shared screenshot in previous mail). To resolve this, we re-logged to the target and formatted this blank volume again. And this time we were able to mount this volume and copied the data. Please have a look to other pending item.Thanks again.Regards,Rohit Puri###@Team:Please close this as we are following up on other ticket https://reancloud.cloudforce.com/5000G00001XDGay###We had a call with Chris and the issue is not fixed for MapD server. and Chris updated that he will review and provide the update for other cases pending from his side.###Created calendar invite for a call with Chris on Monday at 7:30 PM IST (10:00 EST).###@Team,We have shared the details to Chris on a mail. For your information here are details which we shared with Chris.Here are details of action items pending at your end:1. CMP Ticket-01100212: Please create 2 clone of volume ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend3:dev8.ctr1-lun-0 and 2 clones of volume ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-180601-clone-v777bb21358661922.00000046.2f1dab31-lun-0 4TB each. And share the same with the machines 10.59.10.68 and 10.59.10.2272. CMP Ticket-01100517:Delete these iSCSI Volumes ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend2:dev7.ctr1-lun-0 (shared with 10.59.10.82), ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-180410-v777bb21358661922.00000036.2f1dab31-lun-0 (shared with  10.59.10.82) and ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-180411-v777bb21358661922.00000038.2f1dab31-lun-0 (shared with 10.59.10.180).3. CMP Ticket 01099898:You provided the clone of the volume ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12 and shared with the machine 10.59.10.116 namely map201803-180607. The server was flooded with the error of Kernel reported iSCSI connection 31:0 error. For resolving this, we reboot the server and restarted the iSCSI service. After that we were not able to mount this volume back as we were failing to login to the target portal where volume is present. We had a call with you and you re-shared the new cloned volume on call itself. With that volume we were facing the read-only error while mounting the volume. Your last update was on this that you will troubleshoot this issue. 4.Direct Connect Testing:We discussed on testing the switchover configuration for Direct Connect. We shared with you the testing environment details but did not hear back from you. 5. Read Only Access to the Nimble and Jetstor Volume console:We are waiting for the access to be shared with Andrew and Praveen for the Nimble and Jetstor Volume Console.###In evening ops call, Rohit mentioned that he will call Chris tomorrow as Chris is traveling today.###Rohit will check with Chris on evening hours###Hello Allen,We have escalated this issue and will have it resolved as soon as possible.We will work to keep you posted on any updates.Thanks.","---------- Forwarded message ----------From: Matthew Watts <mwatts@spendhq.com>Date: Tue, Jul 24, 2018 at 8:13 PMSubject: Re: Data Volume still missing - its been a monthTo: Allen Herrera <aherrera@spendhq.com>, spendhq-support@reancloud.com <spendhq-support@reancloud.com>, Matt Kiefer <mkiefer@spendhq.com>REAN,Can we escalate please.*Matthew Watts* | Manager, Application Development | *Spend**HQ®*O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting<http://calendly.com/matthewwatts>*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com*From: *Allen Herrera <aherrera@spendhq.com>*Date: *Tuesday, July 24, 2018 at 2:32 PM*To: *spendhq-support@reancloud.com <spendhq-support@reancloud.com>, MattKiefer <mkiefer@spendhq.com>*Subject: *Data Volume still missing - its been a monthHey Rean,Why is the data volume still missing on 10-59-10-116.  I have stake holderswanting this server back up for a long time !It’s been a month. Can we prioritize this to get it done today!?!?!?!?*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- You received this message because you are subscribed to the Google GroupsSpendhq Support group.To unsubscribe from this group and stop receiving emails from it, send anemail to spendhq-support+unsubscribe@reancloud.com.-- *Mr. Stephen Oduor Otieno**Junior Cloud Engineer**REĀN Cloud. **stephen.oduor@reancloud.com <stephen.oduor@reancloud.com> |www.reancloud.com <http://www.reancloud.com>**AWS SysOps-Admin Associate Certified*-- Raleigh Convention Center25th July, 2018 <http://go.reancloud.com/raleigh-email-sign>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>",Fwd: Data Volume still missing - its been a month,,24-07-2018 22:55,158,0,SpendHQ,"Hello Team,We are tracking this case on another ticket (01099898). Now we are closing this case.","Hi Andrew,We have mounted the volume in PRD-CAT-MapD(13-03-2018)-COPY machine at location /mnt/mapd201805/. For resolving this, we mounted the blank volume provided by Chris and copied the data from the machine it was cloned PRD-CAT-MapD(13-03-2018. Please verify the data and let us know if you find any issue.Chris:Thanks for providing the volume. Before that we were not able to mount this volume as error we were facing of read-only (shared screenshot in previous mail). To resolve this, we re-logged to the target and formatted this blank volume again. And this time we were able to mount this volume and copied the data. Please have a look to other pending item.Thanks again.Regards,Rohit Puri",@Team:Please close this as we are following up on other ticket https://reancloud.cloudforce.com/5000G00001XDGay,We had a call with Chris and the issue is not fixed for MapD server. and Chris updated that he will review and provide the update for other cases pending from his side.,Created calendar invite for a call with Chris on Monday at 7:30 PM IST (10:00 EST).,"@Team,We have shared the details to Chris on a mail. For your information here are details which we shared with Chris.Here are details of action items pending at your end:1. CMP Ticket-01100212: Please create 2 clone of volume ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend3:dev8.ctr1-lun-0 and 2 clones of volume ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-180601-clone-v777bb21358661922.00000046.2f1dab31-lun-0 4TB each. And share the same with the machines 10.59.10.68 and 10.59.10.2272. CMP Ticket-01100517:Delete these iSCSI Volumes ip-172.24.8.11:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40b58:js2-spend2:dev7.ctr1-lun-0 (shared with 10.59.10.82), ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-180410-v777bb21358661922.00000036.2f1dab31-lun-0 (shared with  10.59.10.82) and ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-180411-v777bb21358661922.00000038.2f1dab31-lun-0 (shared with 10.59.10.180).3. CMP Ticket 01099898:You provided the clone of the volume ip-172.24.5.3:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:mapd201803:dev12.ctr2-lun-12 and shared with the machine 10.59.10.116 namely map201803-180607. The server was flooded with the error of Kernel reported iSCSI connection 31:0 error. For resolving this, we reboot the server and restarted the iSCSI service. After that we were not able to mount this volume back as we were failing to login to the target portal where volume is present. We had a call with you and you re-shared the new cloned volume on call itself. With that volume we were facing the read-only error while mounting the volume. Your last update was on this that you will troubleshoot this issue. 4.Direct Connect Testing:We discussed on testing the switchover configuration for Direct Connect. We shared with you the testing environment details but did not hear back from you. 5. Read Only Access to the Nimble and Jetstor Volume console:We are waiting for the access to be shared with Andrew and Praveen for the Nimble and Jetstor Volume Console.","In evening ops call, Rohit mentioned that he will call Chris tomorrow as Chris is traveling today.",Rohit will check with Chris on evening hours,"Hello Allen,We have escalated this issue and will have it resolved as soon as possible.We will work to keep you posted on any updates.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001azWR6,Cloud Engineer Level 1,Closed,1103349,Incident,29-08-2018 19:43,,"Hello TeamAWS has resolved the issue from their end, we are therefore marking this case as resolve and hence closinf the case. However, if you have any queries regarding this please get back to us.###Hello TeamWe have receioved a notification that elevated rate of 500s for deleting buckets, deleting bucket tags, retrieving bucket tags and adding bucket tags. All other S3 APIs are operating normally. 8:35 PM PDT Between 6:10 PM and 8:32 PM PDT, S3 experienced elevated errors for bucket tagging and deleting. During this time, requests to delete buckets, add bucket tags, read bucket tags, and delete bucket tags were affected. Please let us know if you performed the action","7:17 PM PDT We are investigating elevated errors and latency for some customers deleting and managing Amazon S3 bucket configuration. Operations to add, delete, tag and retrieve objects from S3 are operating normally.   7:49 PM PDT  We are investigating an elevated rate of 500s for deleting buckets, deleting bucket tags, retrieving bucket tags and adding bucket tags. All other S3 APIs are operating normally.  8:35 PM PDT Between 6:10 PM and 8:32 PM PDT, S3 experienced elevated errors for bucket tagging and deleting. During this time, requests to delete buckets, add bucket tags, read bucket tags, and delete bucket tags were affected. Other API requests to S3 objects or S3 buckets were unaffected. The issue has been resolved and the service is operating normally. For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <https://hubs.ly/H0d8gJ20>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_S3_OPERATIONAL_ISSUE,,29-08-2018 18:11,2,0,SpendHQ,"Hello TeamAWS has resolved the issue from their end, we are therefore marking this case as resolve and hence closinf the case. However, if you have any queries regarding this please get back to us.","Hello TeamWe have receioved a notification that elevated rate of 500s for deleting buckets, deleting bucket tags, retrieving bucket tags and adding bucket tags. All other S3 APIs are operating normally. 8:35 PM PDT Between 6:10 PM and 8:32 PM PDT, S3 experienced elevated errors for bucket tagging and deleting. During this time, requests to delete buckets, add bucket tags, read bucket tags, and delete bucket tags were affected. Please let us know if you performed the action",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BYett,Cloud Engineer Level 1,Closed,1051425,Incident,03-05-2017 02:15,,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM###Hello Matthew,I can understand that you are able to connect to the VPN but unable to SSH into any of the instances. I need to few more information to investigate this.Please provide me the error messages you are witnessing while trying to connect to the instances using below command.ssh -i <keypair> <username>@<private_ip_address> -vvvRegards,Safuvan KM###Hi  Matthew,We will look into this issue and will let you know the updates.","I am trying to authenticate to the VPN from my MAC however I don’t seem to be having much luck. Here is a screenshot of the successful login, however I have no access to any of the servers. Please advise. Screenshot attached.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",MAC Login,,03-05-2017 00:01,2,0,SpendHQ,"Hello Matthew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM","Hello Matthew,I can understand that you are able to connect to the VPN but unable to SSH into any of the instances. I need to few more information to investigate this.Please provide me the error messages you are witnessing while trying to connect to the instances using below command.ssh -i <keypair> <username>@<private_ip_address> -vvvRegards,Safuvan KM","Hi  Matthew,We will look into this issue and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001GILvS,Cloud Engineer Level 1,Closed,1074543,Incident,24-08-2017 04:37,,"Hello SpendHQ-team,On further analysis, we could see some PHP Fatal errors. So we had a call with Matthew.As per the discussion with Matthew, we have started the instance i-a594d794 (PRD-RD) – IP 10.59.10.12, that was stopped just before the alert as per the request from Andrew. This resolved the site down issue. The site is up and running now.At this time we are marking this case as resolved. Please let us know if you have any queries.###Hello SpendHQ-Team,This is to notify you that we have received a site down alert for the url: https://preview.spendhq.com/login. The site is not accessible now.We are currently analyzing from our end and let us know if you are performing any activity from your end.","Wed, 23 Aug 2017 17:34:53 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30014 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): London UK, Frankfurt DE, California US, Dallas-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,24-08-2017 03:04,2,0,SpendHQ,"Hello SpendHQ-team,On further analysis, we could see some PHP Fatal errors. So we had a call with Matthew.As per the discussion with Matthew, we have started the instance i-a594d794 (PRD-RD) – IP 10.59.10.12, that was stopped just before the alert as per the request from Andrew. This resolved the site down issue. The site is up and running now.At this time we are marking this case as resolved. Please let us know if you have any queries.","Hello SpendHQ-Team,This is to notify you that we have received a site down alert for the url: https://preview.spendhq.com/login. The site is not accessible now.We are currently analyzing from our end and let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Koh1p,Cloud Engineer Level 2,Closed,1085107,Incident,09-01-2018 12:54,,"Hi SpendHQ team,As we have manually resolved the alert, We are closing this case from here.Please let us know once you complete the cleanup to free up some space on this volume. Thanks###Check with Yogesh whether we can close this case###Hello Team,We resolved the disk usage alert PRD-DB1(i-03ccfddd9f02cacb9) instance from datadog. Please let us know if you have any concerns.###Please resolve it from Datadog dashboard after informing the customer about it.Keep the threshold as it is.###Yogesh will be updating us regarding the steps to manually resolve the alert###I sent an email to Sarat & Jeff requesting to reach out to Chris from Amdromeda to provide update on this ticket. Waiting for a response.Regards/Chirodeep###Informed Chirodeep to reach out to Sarath or Jeff.###Hello Chris,We haven't heard back from you. Please let us know the update on this case.###I have tried to call to David and Chris but they didn't pick up the call###Yesterday OPS call Chirodeep updated that he will send a mail to Chris and David to get an update on this case.###Hello Chris,This is quick follow up.Please let us know the update on this case.###Yogesh updated via slack Send an email to David and Chris asking an update today.###Tried to call David twice but he was also not picking up the call. Need to discuss this case during Monday OPS Call for the next action items as we are not receiving any updates through continuous follow-ups.###Need to call David from Andromeda since Chris is not providing an update.###Hello Chris,We have tried to reach out to you over the phone but you are unavailable.Please provide us with an update on this case.###Hello Chris,We haven't heard back from you. Let us know whether you got a chance to check with Nimble Team. Please provide us with an update on this case.###Hello Chris,We have tried to reach out you by phone multiple times since we haven't received any response from you.Could you please let us know the update on this issue.###Todays Ops call, Chirodeep asked us to inform night shift team to get on a call with Chris as a high priority if he haven't provided any response by 10.30 PM IST###Hi Team,I have sent Chris Veillette a direct email for an update on this in case he is not receiving emails from REAN CMP. On the system, we can still see the PRD DB size is showing 91.7%. Waiting for an update from Chris Veillette on the next steps.###Hello Chris,We haven't heard back from you.Let us know whether you got a chance to check with Nimble Team. Please provide us with an update on this case.###Hello Chris,Let us know whether you got a chance to check with Nimble Team. Please provide us an update on this case.###Hello Chris, We haven't heard back from you. Please let us know if you have any updates from Nimble Team regarding this case.###Hello Chris, We haven't heard back from you.Please let us know if you have any updates from Nimble Team regarding this case.###Hello Chris,Please let us know if you have any updates from Nimble Team regarding this case.###Hello Chris,Let us know if you have any further updates regarding this case.Regards,Sumod.K.Bose###Followup with the customer during morning EST hours.###Hello Chris,Please let us know if you received any updates from the Nimble team for this case.###Sumod Kurian Bose11:50 PM (11 minutes ago)to Chris, REAN Hello Chris,Thanks for the information. Let us know once you have any further updates regarding this case.###Hi -I think this number is showing the uncompressed usage - whereas the actual usage is about 2.756 TB I will check with Nimble to verify...but there is plenty of space for the production DB..Thanks!Chris Veillette###update -correction - it appears the the production DB  is PRD-DB-170819  - still doesn't add up to 3.5TB though...Chris Veillette###Hello Chris,Yes, it's correct that the ISCSI volume on the production DB is PRD-DB-170819. Refer the below screenshots which clearly specifies that the volume has been used up to 92%.Let us know if you need any more details from our end regarding this case###Hi -I did a space calculation on the Storage and we are only at about 2.6 TB of 4.0 TB on the production DB - which is PRD-DB-171120 -which we did yesterday.I see the mount point listed as /mnt/production_19082017 - can you tell me what volumes are mounted to this?Could it be we are looking at two different volumes from different sources?Thanks!!Chris Veillette###Hello Chris,Please refer the below screenshot of the Disk Utilization details on PRD-DB1(i-03ccfddd9f02cacb9) instance. As of now, the volume used on the drive /dev/sdc is at 93%.Let us know if you need any more details on our end regarding this issue.","Hello REAN,Per our discussion on the call with SpendHQ,  I am not seeing the Production DB size at 91%.  Could you send me a screenshot where you are seeing this to me? 😊Thanks!Chris VeilletteCIO[1450833261212_7186d8e7bdbb48853119db07d964f770.jpg]www.Andromeda3.com<http://www.Andromeda3.com>cveillette@andromeda3.comMobile: 703.447.4124Office:   571.781.0428--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Production DB size,,22-11-2017 22:35,1142,0,SpendHQ,"Hi SpendHQ team,As we have manually resolved the alert, We are closing this case from here.Please let us know once you complete the cleanup to free up some space on this volume. Thanks",Check with Yogesh whether we can close this case,"Hello Team,We resolved the disk usage alert PRD-DB1(i-03ccfddd9f02cacb9) instance from datadog. Please let us know if you have any concerns.",Please resolve it from Datadog dashboard after informing the customer about it.Keep the threshold as it is.,Yogesh will be updating us regarding the steps to manually resolve the alert,I sent an email to Sarat & Jeff requesting to reach out to Chris from Amdromeda to provide update on this ticket. Waiting for a response.Regards/Chirodeep,Informed Chirodeep to reach out to Sarath or Jeff.,"Hello Chris,We haven't heard back from you. Please let us know the update on this case.",I have tried to call to David and Chris but they didn't pick up the call,Yesterday OPS call Chirodeep updated that he will send a mail to Chris and David to get an update on this case.,"Hello Chris,This is quick follow up.Please let us know the update on this case.",Yogesh updated via slack Send an email to David and Chris asking an update today.,Tried to call David twice but he was also not picking up the call. Need to discuss this case during Monday OPS Call for the next action items as we are not receiving any updates through continuous follow-ups.,Need to call David from Andromeda since Chris is not providing an update.,"Hello Chris,We have tried to reach out to you over the phone but you are unavailable.Please provide us with an update on this case.","Hello Chris,We haven't heard back from you. Let us know whether you got a chance to check with Nimble Team. Please provide us with an update on this case.","Hello Chris,We have tried to reach out you by phone multiple times since we haven't received any response from you.Could you please let us know the update on this issue.","Todays Ops call, Chirodeep asked us to inform night shift team to get on a call with Chris as a high priority if he haven't provided any response by 10.30 PM IST","Hi Team,I have sent Chris Veillette a direct email for an update on this in case he is not receiving emails from REAN CMP. On the system, we can still see the PRD DB size is showing 91.7%. Waiting for an update from Chris Veillette on the next steps.","Hello Chris,We haven't heard back from you.Let us know whether you got a chance to check with Nimble Team. Please provide us with an update on this case.","Hello Chris,Let us know whether you got a chance to check with Nimble Team. Please provide us an update on this case.","Hello Chris, We haven't heard back from you. Please let us know if you have any updates from Nimble Team regarding this case.","Hello Chris, We haven't heard back from you.Please let us know if you have any updates from Nimble Team regarding this case.","Hello Chris,Please let us know if you have any updates from Nimble Team regarding this case.","Hello Chris,Let us know if you have any further updates regarding this case.Regards,Sumod.K.Bose",Followup with the customer during morning EST hours.,"Hello Chris,Please let us know if you received any updates from the Nimble team for this case.","Sumod Kurian Bose11:50 PM (11 minutes ago)to Chris, REAN Hello Chris,Thanks for the information. Let us know once you have any further updates regarding this case.",Hi -I think this number is showing the uncompressed usage - whereas the actual usage is about 2.756 TB I will check with Nimble to verify...but there is plenty of space for the production DB..Thanks!Chris Veillette,update -correction - it appears the the production DB  is PRD-DB-170819  - still doesn't add up to 3.5TB though...Chris Veillette,"Hello Chris,Yes, it's correct that the ISCSI volume on the production DB is PRD-DB-170819. Refer the below screenshots which clearly specifies that the volume has been used up to 92%.Let us know if you need any more details from our end regarding this case",Hi -I did a space calculation on the Storage and we are only at about 2.6 TB of 4.0 TB on the production DB - which is PRD-DB-171120 -which we did yesterday.I see the mount point listed as /mnt/production_19082017 - can you tell me what volumes are mounted to this?Could it be we are looking at two different volumes from different sources?Thanks!!Chris Veillette,"Hello Chris,Please refer the below screenshot of the Disk Utilization details on PRD-DB1(i-03ccfddd9f02cacb9) instance. As of now, the volume used on the drive /dev/sdc is at 93%.Let us know if you need any more details on our end regarding this issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001RTjUk,Cloud Engineer Level 1,Closed,1092242,Incident,02-03-2018 06:50,,"Hello Team,The alert regarding  CPU utilisation, DB connection, as well as the decrease in freeable memory of RDS instance got resolved to a value of 6%, 8 and 5086 MB respectively. At this time we are marking this case as resolved and will notify you if we find any abnormal activity.###Steven Ng5:10 AM (1 hour ago)to Rean Thank you for alerting this to us. We have cleared out the long running queries and have returned to normal. We’ll keep monitoring a little bit more at the moment. Steven Ng | Full Stack LAMP Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.com###We went on a call with Andrew as mentioned by him they are running some queries.As discussed with him please keep an eye on RDS machine and send out an update to the customer in every shift.###Hello Team,As discussed on the call with Andrew the increase in CPU, DB connection, as well as decrease in freeable memory of RDS instance, were due to long query running in the database. As mentioned we will be closely monitoring the RDS status and will keep you posted regarding the updates.Please find the current RDS metrics value.Also, let us know if you have any concerns.CPU Utilization: 100%DB Connections: 500Freeable Memory: 4386.89 MB###Hello Team, This is to inform you that we got an alert of High RDS CPU Utilization for spendhqdb. The present utilization is above the threshold of 80% with a value of 99%. Resource Details. EndPoint: spendhqdb.cnq3fody8qqu.us-east-1.rds.amazonaws.com Name:spendhqdb Instance Class: db.r4.largeOn checking, we observed following details1) DB connections reached to a value of 100. 2) There is spike in Query count per second for the RDS.3) The network throughput is also showing an increase.Please check the snapshot in attachment section for details. From the above details, we suspect there is any activity going on from your end. Let us know whether this is expected.","[Triggered] [SpendHQ][PROD] High RDS CPU Utilization for  - spendhqdb - us-east-1  RDS CPU Utilization is above threshold  - spendhqdb    @support@reancloud.comaws.rds.cpuutilization over dbname:spendhqdb,host:db-QQCSORNBURRYJMGDFXN7MIV2IM was > 85.0 on average during the last 5m.Metric value: 99.67This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#3218209?group=host%3Adb-QQCSORNBURRYJMGDFXN7MIV2IM · Edit Monitor: https://app.datadoghq.com/monitors#3218209/edit · Event URL: https://app.datadoghq.com/event/event?id=4289419158766712308 · View db-QQCSORNBURRYJMGDFXN7MIV2IM: https://app.datadoghq.com/infrastructure?hostname=db-QQCSORNBURRYJMGDFXN7MIV2IM · Show Processes: https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=None&tags=host%3Adb-QQCSORNBURRYJMGDFXN7MIV2IM&from_ts=None&live=false&showSummaryGraphs=true-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ][PROD] High RDS CPU Utilization for  - spendhqdb - us-east-1,,02-03-2018 00:53,6,0,SpendHQ,"Hello Team,The alert regarding  CPU utilisation, DB connection, as well as the decrease in freeable memory of RDS instance got resolved to a value of 6%, 8 and 5086 MB respectively. At this time we are marking this case as resolved and will notify you if we find any abnormal activity.",Steven Ng5:10 AM (1 hour ago)to Rean Thank you for alerting this to us. We have cleared out the long running queries and have returned to normal. We’ll keep monitoring a little bit more at the moment. Steven Ng | Full Stack LAMP Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.com,We went on a call with Andrew as mentioned by him they are running some queries.As discussed with him please keep an eye on RDS machine and send out an update to the customer in every shift.,"Hello Team,As discussed on the call with Andrew the increase in CPU, DB connection, as well as decrease in freeable memory of RDS instance, were due to long query running in the database. As mentioned we will be closely monitoring the RDS status and will keep you posted regarding the updates.Please find the current RDS metrics value.Also, let us know if you have any concerns.CPU Utilization: 100%DB Connections: 500Freeable Memory: 4386.89 MB","Hello Team, This is to inform you that we got an alert of High RDS CPU Utilization for spendhqdb. The present utilization is above the threshold of 80% with a value of 99%. Resource Details. EndPoint: spendhqdb.cnq3fody8qqu.us-east-1.rds.amazonaws.com Name:spendhqdb Instance Class: db.r4.largeOn checking, we observed following details1) DB connections reached to a value of 100. 2) There is spike in Query count per second for the RDS.3) The network throughput is also showing an increase.Please check the snapshot in attachment section for details. From the above details, we suspect there is any activity going on from your end. Let us know whether this is expected.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001J6sfi,Cloud Engineer Level 1,Closed,1083893,Incident,06-11-2017 20:05,,"Hello Allen,Thank You for joining the call.As discussed over the call, the issue regarding Sophos configuration for api.spendhq.com has been resolved and you have confirmed the same on the call. Hence we are marking this case as resolved.Kindly validate these details and revert back in case of any further queries.Regards,Sumod.K.Bose###Hello Allen,We have verified the Sophos configurations for api.spendhq.com and has confirmed that everything is working fine as expected.api.spendhq.com (DNS) -> Pointed to api-spendhq-com ELB DNS Name(internet-facing) -> Sophos WAF -> Pointed to api-spendhq-com-ielb (internal ELB) -> Backend instances: preview-api.spendhq.com-1B-20171101 and preview-api.spendhq.com-1C-20171101We have checked and confirmed that everything is working fine as expected from AWS as well as Sophos level. Kindly validate these details and let us know if your team still face any issues or not. If any issue still persists, we can have a quick call to sort it out.As discussed, we have already scheduled a call for today at 9 AM EST hours to discuss further regarding the Sophos configuration issues with api.spendhq.com. Meeting invite has already been shared regarding the same.Validate these details from your end and let us know your thoughts regarding this case.Regards,Sumod.K.Bose###We have checked the Sophos configuration and everything seems fine. Since customer asked for a call. Praveen mentioned scheduling a troubleshooting call on Monday at 7:30PM IST.Created the calendar invite and shared with the customer.###Hello Allen,We are looking into this issue and will get back to you with details shortly.","We are having an issue with how api.spendhq.com is resolving. Currently it resolves to 10.59.100.170. We need it to resolve to one of the new api.spendhq.com boxes 10.59.101.78 and 10.59.100.78Api.spendhq.com (DNS)  --> api_spendhq.com(ELB) internet facing  --> Sophos -> internal-api-spendhq-com-ielb145 --> preview-api-spendhq-com-1c or preview-api-spendhq-com-1bWe think the issue with the Sophos configuration and would like you guys to review this.https://internal-api-spendhq-com-ielb-1453678816.us-east-1.elb.amazonaws.com/ resolves correctly, so believe the internal elb is good.Allen Herrera | Developer | SpendHQ(r)M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Sophos configuration with api.spendhq.com,,04-11-2017 01:05,67,0,SpendHQ,"Hello Allen,Thank You for joining the call.As discussed over the call, the issue regarding Sophos configuration for api.spendhq.com has been resolved and you have confirmed the same on the call. Hence we are marking this case as resolved.Kindly validate these details and revert back in case of any further queries.Regards,Sumod.K.Bose","Hello Allen,We have verified the Sophos configurations for api.spendhq.com and has confirmed that everything is working fine as expected.api.spendhq.com (DNS) -> Pointed to api-spendhq-com ELB DNS Name(internet-facing) -> Sophos WAF -> Pointed to api-spendhq-com-ielb (internal ELB) -> Backend instances: preview-api.spendhq.com-1B-20171101 and preview-api.spendhq.com-1C-20171101We have checked and confirmed that everything is working fine as expected from AWS as well as Sophos level. Kindly validate these details and let us know if your team still face any issues or not. If any issue still persists, we can have a quick call to sort it out.As discussed, we have already scheduled a call for today at 9 AM EST hours to discuss further regarding the Sophos configuration issues with api.spendhq.com. Meeting invite has already been shared regarding the same.Validate these details from your end and let us know your thoughts regarding this case.Regards,Sumod.K.Bose",We have checked the Sophos configuration and everything seems fine. Since customer asked for a call. Praveen mentioned scheduling a troubleshooting call on Monday at 7:30PM IST.Created the calendar invite and shared with the customer.,"Hello Allen,We are looking into this issue and will get back to you with details shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001TlVhp,Cloud Engineer Level 1,Closed,1094468,Incident,03-04-2018 23:52,,"Hello Andrew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###No questions. This ticket can be closed. Thank you###Hello Andrew,This is a gentle reminder.Please review the previous comment and let us know if you have any queries.###Hello Andrew,We have analyzed the alert and below are the details.On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 74.115.21.213 which belongs to the organization - Faction was trying to execute the Oracle WebLogic Server Remote Code Execution. This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. ELB Log2018-03-28T12:14:15.404736Z preview-spendhq-xelb 74.115.21.213:20015 10.59.1.192:80 0.000039 0.005556 0.000022 301 301 0 195 GET http://preview.spendhq.com:80/ HTTP/1.1 Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36 - -Please review the details and let us know if you have any queries.###Hello Andrew,We will do furthermore analysis on this alert and will let you know the update.###Andrew Kim8:26 PM (11 minutes ago)to Rean, spendhq-support Odd – I don’t recognize that IP address. Do we have more information on what type of activity was dropped?###Hello Team, This is to inform you that we have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.192  which belongs to the Preview-api-spendhq-comPlease find the Intrusion Prevention Logs: 2018:03:28-11:57:21 spendhq ulogd[2352]: id=2001 severity=info sys=SecureNet sub=packetfilter name=Packet dropped action=drop fwrule=60003 outitf=eth0 srcmac=12:c3:4f:d8:4c:1e srcip=10.59.1.192 dstip=10.59.0.77 proto=6 length=491 tos=0x00 prec=0x00 ttl=64 srcport=80 dstport=34894 tcpflags=ACK PSH FIN Please ELB logs details in the attachment section. On analyzing the ELB logs at the time of the alert, we are able to figure out the IP  52.6.219.227 was from amazon.com.Please review these details.","---------- Forwarded message ----------From: Firewall Notification System <manage-spendhq@reancloud.com>Date: Wed, Mar 28, 2018 at 5:24 PMSubject: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped)To: event-5domgd23@dtdg.co, spendhq-support@reancloud.com, ms@reancloud.comIntrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-ORACLE Oracle WebLogic Server remote commandexecution attemptDetails........: https://www.snort.org/search?query=45304Time...........: 2018-03-28 11:54:28Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.0.77Source port: 34894Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 93 days 4 hours 51 minutesSystem Load        : 0.17System Version     : Sophos UTM 9.506-2Please refer to the manual for detailed instructions.-- Regards,Jamelunissa MohammedHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081jamelunissa.mohammed@reancloud.com  | www.reancloud.com-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,28-03-2018 18:25,149,0,SpendHQ,"Hello Andrew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.",No questions. This ticket can be closed. Thank you,"Hello Andrew,This is a gentle reminder.Please review the previous comment and let us know if you have any queries.","Hello Andrew,We have analyzed the alert and below are the details.On further analyzing the ELB logs at the time of the alert, we are able to figure out one IP 74.115.21.213 which belongs to the organization - Faction was trying to execute the Oracle WebLogic Server Remote Code Execution. This vulnerability allows remote attackers to execute arbitrary commands via a crafted serialized Java object in T3 protocol traffic to TCP port 7001. ELB Log2018-03-28T12:14:15.404736Z preview-spendhq-xelb 74.115.21.213:20015 10.59.1.192:80 0.000039 0.005556 0.000022 301 301 0 195 GET http://preview.spendhq.com:80/ HTTP/1.1 Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36 - -Please review the details and let us know if you have any queries.","Hello Andrew,We will do furthermore analysis on this alert and will let you know the update.","Andrew Kim8:26 PM (11 minutes ago)to Rean, spendhq-support Odd – I don’t recognize that IP address. Do we have more information on what type of activity was dropped?","Hello Team, This is to inform you that we have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.192  which belongs to the Preview-api-spendhq-comPlease find the Intrusion Prevention Logs: 2018:03:28-11:57:21 spendhq ulogd[2352]: id=2001 severity=info sys=SecureNet sub=packetfilter name=Packet dropped action=drop fwrule=60003 outitf=eth0 srcmac=12:c3:4f:d8:4c:1e srcip=10.59.1.192 dstip=10.59.0.77 proto=6 length=491 tos=0x00 prec=0x00 ttl=64 srcport=80 dstport=34894 tcpflags=ACK PSH FIN Please ELB logs details in the attachment section. On analyzing the ELB logs at the time of the alert, we are able to figure out the IP  52.6.219.227 was from amazon.com.Please review these details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hQdVb,Cloud Engineer Level 1,Closed,1110150,Incident,03-01-2019 02:11,,"Hello Kristen,Thanks for joining the call.As you are able to connect the machine successfully, we are marking the case as resolved.ANJALI NAIR###[Shared on Email]Hi, any time before 4 will be fine.###Hi Team,I have requested for Kristen's availability to jump on a call so that we can be able to identify the exact error/issue being faced.I have checked from instance level and there no failed log in attempts from the user kstretch[root@ip-10-59-10-19 .ssh]# cat /var/log/secure | grep kstretchJan  2 16:45:46 ip-10-59-10-19 su: pam_unix(su-l:session): session opened for user kstretch by ec2-user(uid=0)Jan  2 16:45:58 ip-10-59-10-19 su: pam_unix(su-l:session): session closed for user kstretchJan  2 16:51:31 ip-10-59-10-19 su: pam_unix(su-l:session): session opened for user kstretch by ec2-user(uid=0)Jan  2 16:53:55 ip-10-59-10-19 su: pam_unix(su-l:session): session closed for user kstretchThe above logs were logged due to me switching user from ec2-user to kstretch so that I can check which groups the user belongs to.  Apart from that there are no logs indicating log in attempts for the user kstretch.I also checked for the last successful log in for the user and saw that it was on Dec 5:[root@ip-10-59-10-19 ec2-user]# lastec2-user pts/0        10.59.1.192      Wed Jan  2 16:38   still logged in   kstretch pts/0        10.59.1.192      Wed Dec  5 01:46 - 01:57  (00:10)    kstretch pts/0        10.59.1.192      Wed Dec  5 01:38 - 01:46  (00:07)    kstretch pts/0        10.59.1.192      Tue Dec  4 19:18 - 00:31  (05:12)    kstretch pts/0        10.59.1.192      Wed Nov 21 03:23 - 03:26  (00:02)    kstretch pts/0        10.59.1.192      Wed Nov 21 03:23 - 03:23  (00:00)    The user is already part of the group wheel, so they should have enough privileges.Once you get the response, check how the user is trying to log in and the exact error that they are getting.Thanks.###Hi Kristen,Kindly let us know your suitable time to get on call and look into this issue.Thanks###Hello Team,We are looking into this issue and will be updating you on our findings.Thanks.","Hi,I am still unable to log into matt_t2.xlarge. Can you please help resolve this?Thanks,-Kristen Stretch-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",unable to log in to box,,02-01-2019 22:02,4,0,SpendHQ,"Hello Kristen,Thanks for joining the call.As you are able to connect the machine successfully, we are marking the case as resolved.ANJALI NAIR","[Shared on Email]Hi, any time before 4 will be fine.","Hi Team,I have requested for Kristen's availability to jump on a call so that we can be able to identify the exact error/issue being faced.I have checked from instance level and there no failed log in attempts from the user kstretch[root@ip-10-59-10-19 .ssh]# cat /var/log/secure | grep kstretchJan  2 16:45:46 ip-10-59-10-19 su: pam_unix(su-l:session): session opened for user kstretch by ec2-user(uid=0)Jan  2 16:45:58 ip-10-59-10-19 su: pam_unix(su-l:session): session closed for user kstretchJan  2 16:51:31 ip-10-59-10-19 su: pam_unix(su-l:session): session opened for user kstretch by ec2-user(uid=0)Jan  2 16:53:55 ip-10-59-10-19 su: pam_unix(su-l:session): session closed for user kstretchThe above logs were logged due to me switching user from ec2-user to kstretch so that I can check which groups the user belongs to.  Apart from that there are no logs indicating log in attempts for the user kstretch.I also checked for the last successful log in for the user and saw that it was on Dec 5:[root@ip-10-59-10-19 ec2-user]# lastec2-user pts/0        10.59.1.192      Wed Jan  2 16:38   still logged in   kstretch pts/0        10.59.1.192      Wed Dec  5 01:46 - 01:57  (00:10)    kstretch pts/0        10.59.1.192      Wed Dec  5 01:38 - 01:46  (00:07)    kstretch pts/0        10.59.1.192      Tue Dec  4 19:18 - 00:31  (05:12)    kstretch pts/0        10.59.1.192      Wed Nov 21 03:23 - 03:26  (00:02)    kstretch pts/0        10.59.1.192      Wed Nov 21 03:23 - 03:23  (00:00)    The user is already part of the group wheel, so they should have enough privileges.Once you get the response, check how the user is trying to log in and the exact error that they are getting.Thanks.","Hi Kristen,Kindly let us know your suitable time to get on call and look into this issue.Thanks","Hello Team,We are looking into this issue and will be updating you on our findings.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EVV9S,Cloud Engineer Level 1,Closed,1068283,Incident,,,,"[Triggered] [SpendHQ] - High Network IN  on host - prod-sphq-db-server05 - 10.59.10.135 - db Status  High Network IN on the instance. Please check the list open TCP Connections    @support@reancloud.comaws.ec2.network_in over host:10.59.10.135,monitoring:on was > 2200000000.0 at all times during the last 5m.Metric value: 2559534080.0This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024210?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2024210/edit · Event URL: https://app.datadoghq.com/event/event?id=3958589881681748261 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network IN on host - prod-sphq-db-server05 - 10.59.10.135 - db Status,,16-07-2017 19:23,0,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EuFey,Cloud Engineer Level 1,Closed,1070867,Incident,31-07-2017 20:43,,"Hello Matthew,Thanks for the update.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Matthew Watts8:22 PM (14 minutes ago)???to Rean, spendhq-support?Verified###Hello Matthew,We have now allowed the internet access to the instance 10.59.100.122. Please check and verify from your end.","Rean,The machine 10.59.100.122 does not have access to the internet. Can we resolve this please.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",10.59.100.122,,31-07-2017 20:01,1,0,SpendHQ,"Hello Matthew,Thanks for the update.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Matthew Watts8:22 PM (14 minutes ago)???to Rean, spendhq-support?Verified","Hello Matthew,We have now allowed the internet access to the instance 10.59.100.122. Please check and verify from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014KP56,Cloud Engineer Level 1,Closed,1032954,Incident,21-11-2016 22:32,,Thank you for the information.,"Thank you for the update. This issue has been resolved on our end.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: noreply@salesforce.com [mailto:noreply@salesforce.com] On Behalf Of Rean SupportSent: Monday, November 21, 2016 11:50 AMTo: Matthew Watts <mwatts@spendhq.com>; akim@spenhq.comSubject: Priority Low - P4 | Update on Case # SI-01032562 Spend HQ - High Memory UtilizationHello Andrew,Below comment added in reference to the case : SI-01032562.Hi Team,This is to notify you that alert regarding high Memory usage on the instance PROD-SPHQ-DB-SERVER03 is still in the open state. The memory usage is currently at 86%. The process memsql process is consuming high memory usage.Let us know if you are performing any activity from your end.Case link: https://reancloud.force.com/customers/5000G000014JQepYou can click on the above link to add your comments or to review the progress. Thank you for your support and patience.Please do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at your respective REAN distribution email address.REAN Cloud-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Priority Low - P4 | Update on Case # SI-01032562 Spend HQ - High Memory Utilization,,21-11-2016 22:28,0,0,SpendHQ,Thank you for the information.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001QkOep,Cloud Engineer Level 2,Closed,1091258,Incident,23-02-2018 13:48,,"Hello SpendHQ Team,I can see we are not using SQS for SpendHQ AWS Account. Hence we are closing this case.Please let us know if you have any questions for us. For more information about this AWS update, please visit this blog post: https://aws.amazon.com/blogs/security/how-to-prepare-for-aws-move-to-its-own-certificate-authority/###Next Action: We have informed Yogesh to sent out email regarding this SQS Notification to the customers on Internal slack.###Praveen mentioned to sent out an email regarding this SQS Notification to all the customers. Need to reach out to Specific CC for sharing the details with teh customers.###Evening Ops call Praveen updated that he will review and will update.###Hello Team, We have received an SQS Operational Notification about updating the certificate authority (CA) for the certificates between March 5, 2018 to March 30, 2018.The SSL/TLS certificates used by Amazon SQS will be issued by Amazon Trust Services (ATS). If we are accessing AWS SQS endpoints via HTTPS whether through browsers or programmatically, will need to update the trusted CA list on the client machines if we do not already support any of the following CA's 1.Amazon Root CA 2.Starfield Services Root Certificate Authority 3.G2 - Starfield Class If we already trust at least one of the above three CAs then no action is required. However, if we do not already trust any of the above CAs and do not add them to the trusted CA list by 05 March 2018, HTTPS connections to the Amazon SQS APIs will not be established. For more information about this AWS update, please visit this blog post: https://aws.amazon.com/blogs/security/how-to-prepare-for-aws-move-to-its-own-certificate-authority/ I have created the sheet regarding SQS service status for all the customers, Please find the sheet in below :- https://docs.google.com/spreadsheets/d/1pBthPEDp2CwRUwiNYqKyXxEpwTvWiqv12D0yzFqLW3g/edit#gid=0###Need to check.","We will be updating the certificate authority (CA) for the certificates used by Amazon Simple Queue Service domain(s), between March 5, 2018 to March 30, 2018. After completing the updates, the SSL/TLS certificates used by Amazon SQS will be issued by Amazon Trust Services (ATS), the same certificate authority (CA) used by AWS Certificate Manager. The update means that customers accessing AWS SQS endpoints via HTTPS whether through browsers or programmatically, will need to update the trusted CA list on their client machines if they do not already support any of the following CAs: -	Amazon Root CA 1 -	Starfield Services Root Certificate Authority - G2 -	Starfield Class 2 Certification Authority      This upgrade notice covers the following endpoints: -	sqs.us-east-1.amazonaws.com [queue.amazonaws.com] -	sqs.us-east-2.amazonaws.com -	sqs.us-west-1.amazonaws.com -	sqs.us-west-2.amazonaws.com -	sqs.ap-south-1.amazonaws.com -	sqs.ap-northeast-2.amazonaws.com -	sqs.ap-southeast-1.amazonaws.com -	sqs.ap-southeast-2.amazonaws.com -	sqs.ap-northeast-1.amazonaws.com -	sqs.ca-central-1.amazonaws.com -	sqs.eu-central-1.amazonaws.com -	sqs.eu-west-1.amazonaws.com -	sqs.eu-west-2.amazonaws.com -	sqs.sa-east-1.amazonaws.com  If your clients already trust at least one of the above three CAs then they will trust our certificates and no action is required. However, if you do not already trust any of the above CAs and do not add them to your trusted CA list by 05 March 2018, HTTPS connections to the Amazon SQS APIs will not be established. For more information about this AWS update, please visit this blog post: https://aws.amazon.com/blogs/security/how-to-prepare-for-aws-move-to-its-own-certificate-authority/      For information on the Amazon root CA see: https://www.amazontrust.com/repository/      * Operating Systems With ATS Support -	Microsoft Windows versions that have January 2005 or later updates installed, Windows Vista, Windows 7, Windows Server 2008, and newer versions -	Mac OS X 10.4 with Java for Mac OS X 10.4 Release 5, Mac OS X 10.5 and newer versions -	Red Hat Enterprise Linux 5 (March 2007), Linux 6, and Linux 7 and CentOS 5, CentOS 6, and CentOS 7 -	Ubuntu 8.10 -	Debian 5.0 -	Amazon Linux (all versions) -	Java 1.4.2_12, Java 5 update 2, and all newer versions, including Java 6, Java 7, and Java 8   * Updating your Client Browser You can update the certificate bundle in your browser simply by updating your browser. Instructions for the most common browsers can be found on the browsers websites: -	Chrome: https://support.google.com/chrome/answer/95414?hl=en -	FireFox: https://support.mozilla.org/en-US/kb/update-firefox-latest-version -	Safari: https://support.apple.com/en-us/HT204416 -	Microsoft Internet Explorer: http://windows.microsoft.com/en-us/internet-explorer/which-version-am-i-using#ie=other - Certificate bundles for Internet Explorer are managed by the Windows OS, so ensure that you update the OS as well.      * Testing Your Programmatic Access To SQS If you access Amazon SQS programmatically, you will need to write a test that performs an HTTPS GET to https://aws.amazon.com and validate that the TLS handshake succeeds.      Most AWS SDKs and CLIs are not impacted by the transition to the Amazon Trust Services CA. If you are using a version of the Python AWS SDK or CLI released before October 29, 2013, you must upgrade. The .NET, Java, PHP, Go, JavaScript, and C++ SDKs and CLIs do not bundle any certificates, so their certificates come from the underlying operating system. The Ruby SDK has included at least one of the required CAs since June 10, 2015. Before that date, the Ruby V2 SDK did not bundle certificates.  You can test your changes against the SQS Paris region (https://sqs.eu-west-3.amazonaws.com) which used Amazon Trust Services (ATS) since it was launched on December 18, 2017.      * Manually Updating Your Certificate Bundle If you cannot access https://aws.amazon.com and you need to update your certificate bundle, then you can do so by importing at least one of the required CAs. They can be found here https://www.amazontrust.com/repository/ . Instructions for importing a root CA certificate into your certificate bundle will vary so please consult the documentation that came with your software.      Thanks for using Amazon Simple Queue Service (SQS), and please contact AWS Support if you have any questions:https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <https://www.reancloud.com/news/rean-cloud-awarded-cloud-contract-department-defense-worth-950-million/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_SQS_OPERATIONAL_NOTIFICATION,,20-02-2018 06:38,79,0,SpendHQ,"Hello SpendHQ Team,I can see we are not using SQS for SpendHQ AWS Account. Hence we are closing this case.Please let us know if you have any questions for us. For more information about this AWS update, please visit this blog post: https://aws.amazon.com/blogs/security/how-to-prepare-for-aws-move-to-its-own-certificate-authority/",Next Action: We have informed Yogesh to sent out email regarding this SQS Notification to the customers on Internal slack.,Praveen mentioned to sent out an email regarding this SQS Notification to all the customers. Need to reach out to Specific CC for sharing the details with teh customers.,Evening Ops call Praveen updated that he will review and will update.,"Hello Team, We have received an SQS Operational Notification about updating the certificate authority (CA) for the certificates between March 5, 2018 to March 30, 2018.The SSL/TLS certificates used by Amazon SQS will be issued by Amazon Trust Services (ATS). If we are accessing AWS SQS endpoints via HTTPS whether through browsers or programmatically, will need to update the trusted CA list on the client machines if we do not already support any of the following CA's 1.Amazon Root CA 2.Starfield Services Root Certificate Authority 3.G2 - Starfield Class If we already trust at least one of the above three CAs then no action is required. However, if we do not already trust any of the above CAs and do not add them to the trusted CA list by 05 March 2018, HTTPS connections to the Amazon SQS APIs will not be established. For more information about this AWS update, please visit this blog post: https://aws.amazon.com/blogs/security/how-to-prepare-for-aws-move-to-its-own-certificate-authority/ I have created the sheet regarding SQS service status for all the customers, Please find the sheet in below :- https://docs.google.com/spreadsheets/d/1pBthPEDp2CwRUwiNYqKyXxEpwTvWiqv12D0yzFqLW3g/edit#gid=0",Need to check.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hTCZB,Cloud Engineer Level 1,Closed,1110510,Incident,15-01-2019 23:43,,"Hi David,Thanks for the update.As of now, we are marking this case as resolved and closing it.Please reach out to us if you have any questions or concerns.Thank you,###[Via Email]David MillerThis has been completed, thank you!###[Sent Via Mail]Hello David, This is a quick followup in relation to the Password Reset request you raised a while a go. This request was completed and credentials shared with you separately.In case you might have missed the update, here it is again:We have reset your password from the instance PRD-API-WW2, IP:10.59.100.78 shared the new password with you via email. Please validate your access and please let us know if you are facing any issues while login. And please confirm whether we are good to close this case.Thanks.Stephen Oduor###Hello David,This is a quick followup.Please let us know if new password working fine for you.###Hello David,Please let us know whether the password that we have shared for the user in  instance PRD-API-WW2, IP:10.59.100.78 works. Thank you.###Hello David,This is a quick follow up. Please validate your new password for the instance  PRD-API-WW2, IP:10.59.100.78 and kindly let us know if you are facing issues while login.###Hello David,We have reset your password from the instance PRD-API-WW2, IP:10.59.100.78 shared the new password with you via email. Please validate your access and please let us know if you are facing any issues while login. And please confirm whether we are good to close this case.###Hello David,Thanks for reaching us. We will change your password and let you know the updates soon.","Rean,Please reset my password on 10.59.100.78 (user: dmiller) and let me know when complete with my new password.  Thank youDavidDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Password Reset,,10-01-2019 02:13,141,0,SpendHQ,"Hi David,Thanks for the update.As of now, we are marking this case as resolved and closing it.Please reach out to us if you have any questions or concerns.Thank you,","[Via Email]David MillerThis has been completed, thank you!","[Sent Via Mail]Hello David, This is a quick followup in relation to the Password Reset request you raised a while a go. This request was completed and credentials shared with you separately.In case you might have missed the update, here it is again:We have reset your password from the instance PRD-API-WW2, IP:10.59.100.78 shared the new password with you via email. Please validate your access and please let us know if you are facing any issues while login. And please confirm whether we are good to close this case.Thanks.Stephen Oduor","Hello David,This is a quick followup.Please let us know if new password working fine for you.","Hello David,Please let us know whether the password that we have shared for the user in  instance PRD-API-WW2, IP:10.59.100.78 works. Thank you.","Hello David,This is a quick follow up. Please validate your new password for the instance  PRD-API-WW2, IP:10.59.100.78 and kindly let us know if you are facing issues while login.","Hello David,We have reset your password from the instance PRD-API-WW2, IP:10.59.100.78 shared the new password with you via email. Please validate your access and please let us know if you are facing any issues while login. And please confirm whether we are good to close this case.","Hello David,Thanks for reaching us. We will change your password and let you know the updates soon.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001S5GS7,Cloud Engineer Level 1,Closed,1092686,Incident,08-03-2018 01:19,,"Hello SpendHQ-Team, This is to inform you that we have received an alert regarding high memory Utilization on prd-ww1_122 (10.59.100.122) has exceeded the threshold value of 85 to 90.52%. The alert got resolved and returned to normal with a value of 67%. The violation lasted for 8 minutes. Please find the resources details below. Resource Details:- Instance ID: i-0ace70ce06368e4a7 Instance Name: prd-ww1_122 Private IP: 10.59.100.122 As the alert is in the resolved state, we are marking this case as resolved. Kindly validate these details and revert back in case of any further queries.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Thu, Mar 8, 2018 at 12:59 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Memory UtilizationAlert on host - prd-ww1_122 - 10.59.100.122 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww1_122- 10.59.100.122 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1520450927000&group=host%3Ai-0ace70ce06368e4a7&from_ts=1520450627000>avg(last_5m):( avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 85The monitor was last triggered at Wed Mar 07 2018 19:28:57 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-0ace70ce06368e4a7>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?hostname=i-0ace70ce06368e4a7>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1520450937000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1520450037000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4298122638553478028>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww1_122 - 10.59.100.122 - web,,08-03-2018 01:04,0,0,SpendHQ,"Hello SpendHQ-Team, This is to inform you that we have received an alert regarding high memory Utilization on prd-ww1_122 (10.59.100.122) has exceeded the threshold value of 85 to 90.52%. The alert got resolved and returned to normal with a value of 67%. The violation lasted for 8 minutes. Please find the resources details below. Resource Details:- Instance ID: i-0ace70ce06368e4a7 Instance Name: prd-ww1_122 Private IP: 10.59.100.122 As the alert is in the resolved state, we are marking this case as resolved. Kindly validate these details and revert back in case of any further queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Zl68R,Cloud Engineer Level 1,Closed,1102652,Incident,12-08-2018 09:04,,Installed the  install NTP service on  host:i-058e1b217f4540213,"[image: Datadog][Triggered on {host:i-058e1b217f4540213}] [Auto] Clock in sync with NTPTriggers if any host's clock goes out of sync with the time given by NTP.The offset threshold is configured in the Agent's ntp.yaml file.Please read the KB article<http://help.datadoghq.com/hc/en-us/articles/204282095-Network-Time-Protocol-NTP-Offset-Issues>on NTP Offset issues for more details on cause and resolution.@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>Offset 86 secs higher than offset threshold (60 secs)The monitor was last triggered at Sun Aug 12 2018 03:23:02 UTC (*10 secsago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#1953584?group=host%3Ai-058e1b217f4540213>]· [Edit Monitor <https://app.datadoghq.com/monitors#1953584/edit>] · [Viewi-058e1b217f4540213<https://app.datadoghq.com/infrastructure?filter=i-058e1b217f4540213>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CASC&to_ts=1534044302000&tags=host%3Ai-058e1b217f4540213&from_ts=1534043282000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4526179582359878273>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [Auto] Clock in sync with NTP on host:i-058e1b217f4540213,,12-08-2018 09:01,0,0,SpendHQ,Installed the  install NTP service on  host:i-058e1b217f4540213,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001aQf7V,Cloud Engineer Level 1,Closed,1103146,Incident,25-08-2018 08:15,,"Hello Team, We have checked on the AWS console and the issue has been resolved and the service is operating normally, hence we are marking this case as resolved and closing it.Thanks,###Hello Team, This is to inform you that we received a notification from AWS stating that they are investigating increased packet loss between some AWS Direct Connect end points and the US-EAST-1 Region. We will keep you in the loop on any updates we receive from AWS.","We are investigating increased packet loss between some AWS Direct Connect end points and the US-EAST-1 Region. For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <https://hubs.ly/H0d8gJ20>PA Convention Center - Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>Hynes Convention Center - Boston, MA28th Aug, 2018 <http://go.reancloud.com/boston-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_OPERATIONAL_ISSUE,,24-08-2018 17:05,15,0,SpendHQ,"Hello Team, We have checked on the AWS console and the issue has been resolved and the service is operating normally, hence we are marking this case as resolved and closing it.Thanks,","Hello Team, This is to inform you that we received a notification from AWS stating that they are investigating increased packet loss between some AWS Direct Connect end points and the US-EAST-1 Region. We will keep you in the loop on any updates we receive from AWS.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bjrcC,Cloud Engineer Level 1,Closed,1104461,Incident,13-09-2018 18:04,,"Hello Team,This is to notify you that the alert regarding EC2 required tags has been fixed and thus we are marking this case as resolved and closing it.###The alert regarding EC2 required tags has been fixed.","I fixed all the Tagging related items. Please close this ticket with comments. From: ms@reancloud.com <ms@reancloud.com> Sent: September 13, 2018 5:05 AMTo: spendhq-support@reancloud.comSubject: [Managed Cloud: spendhq] EC2 Required tag REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud. The following AWS::EC2::Instance resources were affected:   _____  *	Violation: The instance does not adhere the tagging standards set for your organization.*	Recommendation: It is recommended to adhere the tagging standards set for your organization. Kindly refer internal policy documents.*	Action taken: None*	Resource details: Resource IDInstance NameInstance TypeRegionMissing tagsi-04a73921f177ee5b7SpendHQ-test-Instancec4.2xlargeus-east-1Owner,Monitoringi-0d785502662707a82	t2.microus-east-1Name,Owner,Monitoringi-048d057832851caa6TestInstancet2.microus-east-1Owner,Monitoringi-0bb0d389a7cdeb196Zadara Proxyt2.nanous-west-2Owner,Monitoring  _____  Best Regards, REAN Cloud Team IMPORTANT: Please do not reply to this message or email address. --  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: [Managed Cloud: spendhq] EC2 Required tag,,13-09-2018 16:06,2,0,SpendHQ,"Hello Team,This is to notify you that the alert regarding EC2 required tags has been fixed and thus we are marking this case as resolved and closing it.",The alert regarding EC2 required tags has been fixed.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000013vucn,Cloud Engineer Level 1,Closed,1030974,Incident,,,,"New Firmware Up2Dates have been installed. The current firmware versionis now 9.405005.        -- System Uptime      : 168 days 2 hours 6 minutesSystem Load        : 0.86System Version     : Sophos UTM 9.405-5Please refer to the manual for detailed instructions.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[spendhq][INFO-302] New Firmware Up2Date installed,,12-11-2016 13:09,0,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKbK,Cloud Engineer Level 1,Closed,1042227,Incident,,,,"Hello Matthew,We are ready for the maintenance. Please let us know once you start makingthe changes.On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com> wrote:> Rean Team are you ready to commence the updates as planned on the> 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.>>>> *Matthew Watts* | Manager, Data Intelligence Systems | *Spend**HQ®*>> O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com>> *A SaaS Spend Visibility solution from Insight Sourcing Group*>> *www.spendhq.com <http://www.spendhq.com/>* | *www.insightsourcing.com> <http://www.insightsourcing.com/>*>>>-- Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Maintenance,,14-01-2017 07:53,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001UufOn,Cloud Engineer Level 1,Closed,1101161,Incident,10-07-2018 07:28,,"Hello Team, We haven't heard back from you.Please review the previous comments and let us know if you have any further queries.At this time, we're marking this as Resolved hence closing the case. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queriesBest Regards,###Hello Team,We haven't heard back from you,Please review the previous comments and let us know if you have any further queries.###Hello, Actual httpd and java process count:[root@ip-10-59-101-6 httpd]# ps -AL | grep -c httpd243[root@ip-10-59-101-6 httpd]# ps -AL | grep -c java57httpd log messages:[root@ip-10-59-101-6 conf]# cat /var/log/httpd/error_log | grep -i Fri Jul 06 20*[Fri Jul 06 20:06:27 2018] [error] server reached MaxClients setting, consider raising the MaxClients setting[Fri Jul 06 20:09:34 2018] [notice] child pid 20317 exit signal Segmentation fault (11)###During our in-depth analysis of this, we could see spikes in the ELB Average Latency monitor. The highest hit a peak of 31292.57 milliseconds on average at around 8:08:00 PM UTC. We also noticed a high Requests Count on the ELB monitor, a spike occuring at 8:08:00 PM UTC with a value of 698.Concurrently we had a high number of process count showing on our Datadog High Number of Process Count monitor (on prd-ww2_6 - 10.59.101.6 - web). The reading on this monitor was at 87 processes at the time when the alert got triggered. This was above the set threshold of 40 procs.All this in turn led to a spike in HTTP 4XXXs count with a reading of 128 at the time of this alert.From the latency logs fetched, we could see 403 errors from this IP: 10.59.1.192 which from our investigation realized happened to be attached to your PROD-SPHQ-SOPHOS-UTM-VPN01 (i-02d1a63672fb172f4) instance. This were thrown as a result of forbidden access for one reason or the other.Please find attached within in the attachment section ELB Latency Logs for the period of this alert and screenshots of the aforementioned monitors. Kindly review them and do get in touch with us if you may need further clarification on this.Resource Details:Name: NewPreview-ELBType: ClassicDNS name: internal-NewPreview-ELB-1657548324.us-east-1.elb.amazonaws.com (A Record)VPC: vpc-76df7212Availability Zones: subnet-0d093d27 - us-east-1b                    subnet-29b09361 - us-east-1cThank you.###Hello Spendhq-Team, This is to notify you that we have received a site down alert on the URL:https://secure.spendhq.com/login. Later the alert got resolved and the site is accessible. Total violation 4 min We are analyzing this issue meanwhile please let us know if you are performing any changes on your end.","Fri, 06 Jul 2018 16:05:06 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): London UK, Frankfurt DE, California US, Sydney-C AU-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Secure,,07-07-2018 01:36,78,0,SpendHQ,"Hello Team, We haven't heard back from you.Please review the previous comments and let us know if you have any further queries.At this time, we're marking this as Resolved hence closing the case. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queriesBest Regards,","Hello Team,We haven't heard back from you,Please review the previous comments and let us know if you have any further queries.","Hello, Actual httpd and java process count:[root@ip-10-59-101-6 httpd]# ps -AL | grep -c httpd243[root@ip-10-59-101-6 httpd]# ps -AL | grep -c java57httpd log messages:[root@ip-10-59-101-6 conf]# cat /var/log/httpd/error_log | grep -i Fri Jul 06 20*[Fri Jul 06 20:06:27 2018] [error] server reached MaxClients setting, consider raising the MaxClients setting[Fri Jul 06 20:09:34 2018] [notice] child pid 20317 exit signal Segmentation fault (11)","During our in-depth analysis of this, we could see spikes in the ELB Average Latency monitor. The highest hit a peak of 31292.57 milliseconds on average at around 8:08:00 PM UTC. We also noticed a high Requests Count on the ELB monitor, a spike occuring at 8:08:00 PM UTC with a value of 698.Concurrently we had a high number of process count showing on our Datadog High Number of Process Count monitor (on prd-ww2_6 - 10.59.101.6 - web). The reading on this monitor was at 87 processes at the time when the alert got triggered. This was above the set threshold of 40 procs.All this in turn led to a spike in HTTP 4XXXs count with a reading of 128 at the time of this alert.From the latency logs fetched, we could see 403 errors from this IP: 10.59.1.192 which from our investigation realized happened to be attached to your PROD-SPHQ-SOPHOS-UTM-VPN01 (i-02d1a63672fb172f4) instance. This were thrown as a result of forbidden access for one reason or the other.Please find attached within in the attachment section ELB Latency Logs for the period of this alert and screenshots of the aforementioned monitors. Kindly review them and do get in touch with us if you may need further clarification on this.Resource Details:Name: NewPreview-ELBType: ClassicDNS name: internal-NewPreview-ELB-1657548324.us-east-1.elb.amazonaws.com (A Record)VPC: vpc-76df7212Availability Zones: subnet-0d093d27 - us-east-1b                    subnet-29b09361 - us-east-1cThank you.","Hello Spendhq-Team, This is to notify you that we have received a site down alert on the URL:https://secure.spendhq.com/login. Later the alert got resolved and the site is accessible. Total violation 4 min We are analyzing this issue meanwhile please let us know if you are performing any changes on your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DlTs3,Cloud Engineer Level 1,Closed,1064040,Incident,21-06-2017 20:22,,"Hello SpendHQ-Team, This volume usage alert on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) has been resolved and returned to a normal state with a value of 70%.The violation lasted for around 2 hours. We are monitoring on it and will keep your team updated. Let us know if your team have any further queries regarding this case. Regards, Sumod.K.Bose###Hello SpendHQ-Team, This is to remind you that the volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) is still in the open state. The volume usage has reached a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. Kindly delete/zip unwanted files or folders to reduce the current volume usage state on this since and let us know if your team need any further assistance from our end to resolve this issue at the earliest. Regards, Sumod.K.Bose###Hello SpendHQ-Team, This is to remind you that the volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) is still in the open state. The volume usage has reached a value of 100%. /tmp folder is consuming high volume usage on this instance. Kindly delete/zip unwanted files or folders to reduce the current volume usage state on this since and let us know if your team need any further assistance from our end to resolve this issue at the earliest. Regards, Sumod.K.Bose###Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1     ext4    50G   47G  55M  100% / Files under root directory, 20G     tmp15G     usr12G     var510M    home285M    lib282M    optFiles under /tmp folder, 1.3G    liger_view_9d07583a5d0ea91da649eb74de8925a0.csv768M    liger_view_48caddc5813d312db6eb6b36728d6d26.csv756M    liger_view_c0f088626aec54f9e717c38584057213.csv743M    liger_view_3ebfa4cd2bf7473040f224bbb67828a6.csv742M    liger_view_443aeba090c5e40888b6efe6044bc8e7.csv709M    liger_view_6087642a31564b858891c5ba13257a05.csv678M    liger_view_76f3fb462c7a42b14f3455add672f19d.csv661M    liger_view_aaa39c0daa998987610541f31e1f7312.csv639M    liger_view_b31af0e125cd4e8238db5db06912d6a2.csv632M    liger_view_148f690359debd2a1d869d93587239e9.csv617M    liger_view_96927baae1ace5dd41b0b0852f95080b.csv446M    liger_view_d0e49e45cf34c76c39bcb470d4f61b47.csv446M    liger_view_bd27273b9084d1504594ce3bd67bcad7.csv367M    liger_view_2d32b3c178972699268d8997969dc77b.csv360M    liger_view_5adfd020971cff855eba0fb0d95f6144.csv358M    liger_view_ba39f6bf1c5dfef4cd40b0c4c8c3c15b.csv354M    liger_view_0af8fe956b018d28f33aa6816a07bcba.csv345M    liger_view_3df8275ad124186c691b9fc2ecb62aa8.csv338M    liger_view_d06a176f5934a8b2ee4dfd7daf36c0bd.csv309M    liger_view_9cdb10db4533d226b95872ed6efa6db5.csv307M    liger_view_3fd75f90af0f3dbe9c50a03cd0a257ec.csv299M    liger_view_be028ac8e61292b6adaf5d5034d4f212.csv298M    liger_view_e3e4e41265c3a1bcaf1a3f500e807b80.csv295M    liger_view_b7cc699c1dfc0eae513d96b25c938f32.csv295M    liger_view_0be054146936e5f5b5c827e0c98a01aa.csv294M    liger_view_c4b00b23b5b2805a5055befd01c6a64f.csv290M    liger_view_a6f05997b617fa7cf84ae8fd04c55d5b.csv288M    liger_view_6f7293f0812941fe3157e418a32e91d8.csv288M    liger_view_582072ecf147b375fba4dfdda1135bd4.csv282M    liger_view_cc5773f18621fda2f754315b98bdb406.csv277M    liger_view_42d69d76efdb1123b415c7d1f56bc446.csv273M    liger_view_0d07fed255e084876f736234244f3774.csv271M    liger_view_91b2532c33bdb93d7cdc92aa2d914cb6.csv270M    liger_view_3232dd25bff838dc7f3afeebf2dc744a.csv269M    liger_view_abd67e4d26a85a9f53bfd0b87629e01f.csv268M    liger_view_607ba8bdcaac6693a20f3168961e4165.csv264M    liger_view_d28d5654c58a7e622b40208df2657e9d.csv264M    liger_view_a0ab81e2052528c03b8286a68dc21bc6.csv264M    liger_view_5d73c062221e9413e8b7f5bb49e32b25.csv264M    liger_view_45c50c01d6ec58953a4f0ec2f09ad8c4.csv264M    liger_view_3b85b1b297ac44ecc3e54d1991515ec8.csv262M    liger_view_782c2e55a7b5c9b000ba473cd4dda0a2.csv260M    liger_view_a1e0e9fe6fa5f273e793b66550c6084d.csv259M    liger_view_76002bf9f1e8aeb8d38186c9d776aedf.csv258M    liger_view_a4329a5ea14ceab1eaa83ae271622f19.csv241M    liger_view_ed0db6460737ac6b2d3b8dce082293d0.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135 Regards, Sumod.K.Bose","[Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135 High Disk Usage detected on the device /dev/xvda1   @ms@reancloud.comMetric Graphavg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90The monitor was last triggered at Wed Jun 21 2017 12:11:00 UTC (37 secs ago).[Monitor Status] · [Edit Monitor] · [View 10.59.10.135]This alert was raised by account SpendHQ",Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,21-06-2017 17:46,11,0,SpendHQ,"Hello SpendHQ-Team, This volume usage alert on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) has been resolved and returned to a normal state with a value of 70%.The violation lasted for around 2 hours. We are monitoring on it and will keep your team updated. Let us know if your team have any further queries regarding this case. Regards, Sumod.K.Bose","Hello SpendHQ-Team, This is to remind you that the volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) is still in the open state. The volume usage has reached a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. Kindly delete/zip unwanted files or folders to reduce the current volume usage state on this since and let us know if your team need any further assistance from our end to resolve this issue at the earliest. Regards, Sumod.K.Bose","Hello SpendHQ-Team, This is to remind you that the volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) is still in the open state. The volume usage has reached a value of 100%. /tmp folder is consuming high volume usage on this instance. Kindly delete/zip unwanted files or folders to reduce the current volume usage state on this since and let us know if your team need any further assistance from our end to resolve this issue at the earliest. Regards, Sumod.K.Bose","Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume is consuming high volume usage on this instance. [root@ip-10-59-10-135 ~]# df -Th Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1     ext4    50G   47G  55M  100% / Files under root directory, 20G     tmp15G     usr12G     var510M    home285M    lib282M    optFiles under /tmp folder, 1.3G    liger_view_9d07583a5d0ea91da649eb74de8925a0.csv768M    liger_view_48caddc5813d312db6eb6b36728d6d26.csv756M    liger_view_c0f088626aec54f9e717c38584057213.csv743M    liger_view_3ebfa4cd2bf7473040f224bbb67828a6.csv742M    liger_view_443aeba090c5e40888b6efe6044bc8e7.csv709M    liger_view_6087642a31564b858891c5ba13257a05.csv678M    liger_view_76f3fb462c7a42b14f3455add672f19d.csv661M    liger_view_aaa39c0daa998987610541f31e1f7312.csv639M    liger_view_b31af0e125cd4e8238db5db06912d6a2.csv632M    liger_view_148f690359debd2a1d869d93587239e9.csv617M    liger_view_96927baae1ace5dd41b0b0852f95080b.csv446M    liger_view_d0e49e45cf34c76c39bcb470d4f61b47.csv446M    liger_view_bd27273b9084d1504594ce3bd67bcad7.csv367M    liger_view_2d32b3c178972699268d8997969dc77b.csv360M    liger_view_5adfd020971cff855eba0fb0d95f6144.csv358M    liger_view_ba39f6bf1c5dfef4cd40b0c4c8c3c15b.csv354M    liger_view_0af8fe956b018d28f33aa6816a07bcba.csv345M    liger_view_3df8275ad124186c691b9fc2ecb62aa8.csv338M    liger_view_d06a176f5934a8b2ee4dfd7daf36c0bd.csv309M    liger_view_9cdb10db4533d226b95872ed6efa6db5.csv307M    liger_view_3fd75f90af0f3dbe9c50a03cd0a257ec.csv299M    liger_view_be028ac8e61292b6adaf5d5034d4f212.csv298M    liger_view_e3e4e41265c3a1bcaf1a3f500e807b80.csv295M    liger_view_b7cc699c1dfc0eae513d96b25c938f32.csv295M    liger_view_0be054146936e5f5b5c827e0c98a01aa.csv294M    liger_view_c4b00b23b5b2805a5055befd01c6a64f.csv290M    liger_view_a6f05997b617fa7cf84ae8fd04c55d5b.csv288M    liger_view_6f7293f0812941fe3157e418a32e91d8.csv288M    liger_view_582072ecf147b375fba4dfdda1135bd4.csv282M    liger_view_cc5773f18621fda2f754315b98bdb406.csv277M    liger_view_42d69d76efdb1123b415c7d1f56bc446.csv273M    liger_view_0d07fed255e084876f736234244f3774.csv271M    liger_view_91b2532c33bdb93d7cdc92aa2d914cb6.csv270M    liger_view_3232dd25bff838dc7f3afeebf2dc744a.csv269M    liger_view_abd67e4d26a85a9f53bfd0b87629e01f.csv268M    liger_view_607ba8bdcaac6693a20f3168961e4165.csv264M    liger_view_d28d5654c58a7e622b40208df2657e9d.csv264M    liger_view_a0ab81e2052528c03b8286a68dc21bc6.csv264M    liger_view_5d73c062221e9413e8b7f5bb49e32b25.csv264M    liger_view_45c50c01d6ec58953a4f0ec2f09ad8c4.csv264M    liger_view_3b85b1b297ac44ecc3e54d1991515ec8.csv262M    liger_view_782c2e55a7b5c9b000ba473cd4dda0a2.csv260M    liger_view_a1e0e9fe6fa5f273e793b66550c6084d.csv259M    liger_view_76002bf9f1e8aeb8d38186c9d776aedf.csv258M    liger_view_a4329a5ea14ceab1eaa83ae271622f19.csv241M    liger_view_ed0db6460737ac6b2d3b8dce082293d0.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135 Regards, Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Fenel,Cloud Engineer Level 1,Closed,1073599,Incident,17-08-2017 01:19,,"Allen Herrera11:55 PM (1 hour ago)to me, Matthew, Dusty, REAN Great thank you !###Hello Allen,We have modified the Idle timeout value to 600s in ELB level. Please verify this from your end and let us know if you are still facing any issues.###Hello SpendHQ-Team,We will work on this request and will get back to you with updates.","We are getting 504 timeout errors on preview.spendhq.com after around 60 seconds. Can you please investigate and increase the timeout to 10 minutes (600 seconds)Can we get this done today?You can test at https://preview.spendhq.com/timer.php?timer=60[cid:image001.jpg@01D31694.B7B771E0]Allen Herrera | Developer | SpendHQ(r)M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Preview.spendhq.com timeout increase from 60 to 600 seconds,,16-08-2017 23:07,2,0,SpendHQ,"Allen Herrera11:55 PM (1 hour ago)to me, Matthew, Dusty, REAN Great thank you !","Hello Allen,We have modified the Idle timeout value to 600s in ELB level. Please verify this from your end and let us know if you are still facing any issues.","Hello SpendHQ-Team,We will work on this request and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001WXmyV,Cloud Engineer Level 1,Closed,1099418,Incident,29-05-2018 23:16,,"Hello Team, This is to inform that the alert regarding EBS High Disk Usage for the /dev/xvda1  - prd-sv1 - 10.59.100.193 instance got resolved and returned to normal state. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.###Hello Spendhq-Team,We haven't heard back from you regarding high EBS disk usage on /dev/xvda1 on the instance PRD-SV1 has reached 90%.Please find the instance details below: Instance name: PRD-SV1 Instance ID: i-048e66836110e8d7b Private IP: 10.59.100.193 Please find the disk usage details below:Filesystem           Type   Size  Used Avail Use% Mounted on/dev/xvda1           ext4    50G   43G  4.6G  91% /tmpfs                tmpfs  7.3G     0  7.3G   0% /dev/shm818G    total813G    var2.8G    opt1.5G    usr514M    lib225M    home87M     boot31M     etc24M     tmp19M     lib64Please clean up unwanted files and let us know if you have queries.###The current usage is 89.7% and the alert is still in open state.###Hello SpendHQ Team, The current EBS disk usage on /dev/xvda1 on the instance PRD-SV1 is at 89.7%. Instance details:Instance name: PRD-SV1 Instance ID: i-048e66836110e8d7b Private IP: 10.59.100.193 Volume ID: vol-03f51ff2808aa9ba1Please clean up any unwanted files and let us know if you have any queries.Thank you.###The current disk usages are 89.7%.@NightShift - Please send a reminder for this case.###Hello SpendHQ-Team, This is to notify you that we received an alert regarding high EBS disk usage on /dev/xvda1 on the instance PRD-SV1 which has crossed threshold value of 80% and reached 81%. Please find the instance details below: Instance name: PRD-SV1 Instance ID: i-048e66836110e8d7b Private IP: 10.59.100.193 Please find the breakdown details below: Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 ext4 50G 38G 9.2G 81% / Disk usage as per directories in / : 771G total 766G var 2.8G opt 1.5G usr 514M lib 225M home 87M boot 31M etc 24M tmp 19M lib64 Disk usage as per Directories in /var 31G www 656M log 503M lib 349M tmp 144M cache 25M db 15M spool 116K run 12K lock 8.0K empty Please clean up unwanted files and let us know if you have any queries.###Hello SpendHQ-Team,This is to notify you that we received an alert regarding high EBS disk usage on /dev/xvda1 on the instance PRD-SV1 which has crossed threshold value of 80% and reached 81%. Please find the instance details below:Instance name: PRD-SV1Instance ID: i-048e66836110e8d7bPrivate IP: 10.59.100.193Please find the breakdown details below:Filesystem           Type   Size  Used Avail Use% Mounted on/dev/xvda1           ext4    50G   38G  9.2G  81% /Disk  usage as per directories in  / :771G    total766G    var2.8G    opt1.5G    usr514M    lib225M    home87M     boot31M     etc24M     tmp19M     lib64Disk usage as per Directories in /var31G     www656M    log503M    lib349M    tmp144M    cache25M     db15M     spool116K    run12K     lock8.0K    emptyPlease clean up unwanted files and let us know if you have any queries.","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Thu, May 24, 2018 at 2:00 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prd-sv1 - 10.59.100.193To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-sv1 -10.59.100.193High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1527107439000&group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-048e66836110e8d7b&from_ts=1527103839000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 80The monitor was last triggered at Wed May 23 2018 20:30:49 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3Ai-048e66836110e8d7b>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [Viewi-048e66836110e8d7b<https://app.datadoghq.com/infrastructure?hostname=i-048e66836110e8d7b>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1527107449000&tags=host%3Ai-048e66836110e8d7b&from_ts=1527106549000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4409800391202559726>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Regards,Jamelunissa MohammedHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081jamelunissa.mohammed@reancloud.com  | www.reancloud.com--  <http://go.reancloud.com/secure-your-cloud>--  <http://go.reancloud.com/secure-your-cloud>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prd-sv1 - 10.59.100.193,,24-05-2018 02:09,141,0,SpendHQ,"Hello Team, This is to inform that the alert regarding EBS High Disk Usage for the /dev/xvda1  - prd-sv1 - 10.59.100.193 instance got resolved and returned to normal state. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.","Hello Spendhq-Team,We haven't heard back from you regarding high EBS disk usage on /dev/xvda1 on the instance PRD-SV1 has reached 90%.Please find the instance details below: Instance name: PRD-SV1 Instance ID: i-048e66836110e8d7b Private IP: 10.59.100.193 Please find the disk usage details below:Filesystem           Type   Size  Used Avail Use% Mounted on/dev/xvda1           ext4    50G   43G  4.6G  91% /tmpfs                tmpfs  7.3G     0  7.3G   0% /dev/shm818G    total813G    var2.8G    opt1.5G    usr514M    lib225M    home87M     boot31M     etc24M     tmp19M     lib64Please clean up unwanted files and let us know if you have queries.",The current usage is 89.7% and the alert is still in open state.,"Hello SpendHQ Team, The current EBS disk usage on /dev/xvda1 on the instance PRD-SV1 is at 89.7%. Instance details:Instance name: PRD-SV1 Instance ID: i-048e66836110e8d7b Private IP: 10.59.100.193 Volume ID: vol-03f51ff2808aa9ba1Please clean up any unwanted files and let us know if you have any queries.Thank you.",The current disk usages are 89.7%.@NightShift - Please send a reminder for this case.,"Hello SpendHQ-Team, This is to notify you that we received an alert regarding high EBS disk usage on /dev/xvda1 on the instance PRD-SV1 which has crossed threshold value of 80% and reached 81%. Please find the instance details below: Instance name: PRD-SV1 Instance ID: i-048e66836110e8d7b Private IP: 10.59.100.193 Please find the breakdown details below: Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 ext4 50G 38G 9.2G 81% / Disk usage as per directories in / : 771G total 766G var 2.8G opt 1.5G usr 514M lib 225M home 87M boot 31M etc 24M tmp 19M lib64 Disk usage as per Directories in /var 31G www 656M log 503M lib 349M tmp 144M cache 25M db 15M spool 116K run 12K lock 8.0K empty Please clean up unwanted files and let us know if you have any queries.","Hello SpendHQ-Team,This is to notify you that we received an alert regarding high EBS disk usage on /dev/xvda1 on the instance PRD-SV1 which has crossed threshold value of 80% and reached 81%. Please find the instance details below:Instance name: PRD-SV1Instance ID: i-048e66836110e8d7bPrivate IP: 10.59.100.193Please find the breakdown details below:Filesystem           Type   Size  Used Avail Use% Mounted on/dev/xvda1           ext4    50G   38G  9.2G  81% /Disk  usage as per directories in  / :771G    total766G    var2.8G    opt1.5G    usr514M    lib225M    home87M     boot31M     etc24M     tmp19M     lib64Disk usage as per Directories in /var31G     www656M    log503M    lib349M    tmp144M    cache25M     db15M     spool116K    run12K     lock8.0K    emptyPlease clean up unwanted files and let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001dcrtQ,Cloud Engineer Level 1,Closed,1106532,Incident,23-10-2018 23:54,,"Hello Team,This is to inform you that this instance was launched by Rean Team for testing purpose.We have terminated the instance. As we don't have any further action item on this ticket, therefore, we are closing this case.Kindly update us if you have any queries.###Hello Team,While checking i could see that the instance i-0dcf6aa57af97ffdb is in stopped state. And the monitoring tag is not added to the instance. But still we are getting the alert. Please have a look on this.###Hello Team,This is to inform you that we have received an alert regarding one of the instance exposed SSH port to open world. Please find the resource details below.Resource ID Instance Name Region Exposed IP Exposed Port i-0dcf6aa57af97ffdb tagtesting us-east-1 0.0.0.0/0 22 This instance is not under monitoring. Please review the details and let us know if you are performing any deployments from your end. As of now, we are blocking this port to subnet range.","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Sat, Oct 20, 2018 at 8:35 PMSubject: [Managed Cloud: spendhq] EC2 Exposed Instance AlertTo: <spendhq-support@reancloud.com>REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environmentby REAN Managed Cloud.The following *AWS::EC2::Instance* resources were affected:------------------------------   - *Violation:* A forbidden port is exposed to the internet.   - *Recommendation:* Please ensure you have followed the correct   procedure to open this rule.   - *Action taken:* None   - *Resource details:*   Resource ID Instance Name Region Exposed IP Exposed Port   i-0dcf6aa57af97ffdb tagtesting us-east-1 0.0.0.0/0 22------------------------------Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Managed Cloud: spendhq] EC2 Exposed Instance Alert,,20-10-2018 21:17,75,0,SpendHQ,"Hello Team,This is to inform you that this instance was launched by Rean Team for testing purpose.We have terminated the instance. As we don't have any further action item on this ticket, therefore, we are closing this case.Kindly update us if you have any queries.","Hello Team,While checking i could see that the instance i-0dcf6aa57af97ffdb is in stopped state. And the monitoring tag is not added to the instance. But still we are getting the alert. Please have a look on this.","Hello Team,This is to inform you that we have received an alert regarding one of the instance exposed SSH port to open world. Please find the resource details below.Resource ID Instance Name Region Exposed IP Exposed Port i-0dcf6aa57af97ffdb tagtesting us-east-1 0.0.0.0/0 22 This instance is not under monitoring. Please review the details and let us know if you are performing any deployments from your end. As of now, we are blocking this port to subnet range.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gclBY,Cloud Engineer Level 1,Closed,1109631,Incident,19-12-2018 04:14,,"Hello Team,This is to inform you that the alert regarding High CPU Utilization on the host sphq-db1-20180830(10.59.10.26) got recovered and the violation lasted for 10 minutes.As the alert in the recovered state, we are marking this case as resolved and hence closing this case. Kindly revert back to us in case of any queries.###Hello Team,This is to inform you that we have received an alert regarding High CPU Utilization on the host sphq-db1-20180830(10.59.10.26).We are checking further details and will get back to you with an update.","---------- Forwarded message ---------From: Datadog Alerting <alert@dtdg.co>Date: Wed, Dec 19, 2018 at 2:09 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on thehost sphq-db1-20180830 - 10.59.10.26 -To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High CPU Utilization on the host sphq-db1-20180830- 10.59.10.26 -High CPU Utilization on the host. Log in to the machine and verify whichprocess is consuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024189?to_ts=1545165559000&group=host%3Ai-009c4b64628c39954&from_ts=1545158359000>avg(last_30m):avg:system.cpu.stolen{datadog_monitor:on} by {host} +avg:system.cpu.user{datadog_monitor:on} by {host} +avg:system.cpu.system{datadog_monitor:on} by {host} > 85The monitor was last triggered at Tue Dec 18 2018 20:39:29 UTC (*5 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024189?group=host%3Ai-009c4b64628c39954>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024189/edit>] · [Viewi-009c4b64628c39954<https://app.datadoghq.com/infrastructure?filter=i-009c4b64628c39954>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1545165689000&tags=host%3Ai-009c4b64628c39954&from_ts=1545164669000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4712765412188252722>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on the host sphq-db1-20180830 - 10.59.10.26 -,,19-12-2018 02:12,2,0,SpendHQ,"Hello Team,This is to inform you that the alert regarding High CPU Utilization on the host sphq-db1-20180830(10.59.10.26) got recovered and the violation lasted for 10 minutes.As the alert in the recovered state, we are marking this case as resolved and hence closing this case. Kindly revert back to us in case of any queries.","Hello Team,This is to inform you that we have received an alert regarding High CPU Utilization on the host sphq-db1-20180830(10.59.10.26).We are checking further details and will get back to you with an update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ETqZa,Cloud Engineer Level 1,Closed,1067470,Incident,12-07-2017 04:34,,"Hello Team,This is to notify you that the alert regarding volume usage for  prod-sphq-db-server05 - 10.59.10.135 got resolved and has returned to normal with a value of 24%. The violation lasted for 6 hours.###Hello Team,Please see the usage details below. Please note that out of 50G only 294M is available for use.# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G  294M 100% /Usage under /47G     total40G     usr5.0G    var790M    tmpUsage under /usr40G     total38G     local882M    shareUsage under /usr/local/infobright-products/iee/postgres/5.0.438G     total38G     ib_data196M    binUsage under /var5.0G    total2.2G    www2.1G    libPlease remove/zip unwanted files to reduce the current usage.###Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 90.212This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3951589295560106787 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,11-07-2017 23:29,5,0,SpendHQ,"Hello Team,This is to notify you that the alert regarding volume usage for  prod-sphq-db-server05 - 10.59.10.135 got resolved and has returned to normal with a value of 24%. The violation lasted for 6 hours.","Hello Team,Please see the usage details below. Please note that out of 50G only 294M is available for use.# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G  294M 100% /Usage under /47G     total40G     usr5.0G    var790M    tmpUsage under /usr40G     total38G     local882M    shareUsage under /usr/local/infobright-products/iee/postgres/5.0.438G     total38G     ib_data196M    binUsage under /var5.0G    total2.2G    www2.1G    libPlease remove/zip unwanted files to reduce the current usage.","Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EUCpS,Cloud Engineer Level 1,Closed,1067618,Incident,15-07-2017 00:43,,"We are closing this case and creating a change ticket.###Next action: Get the deployment plan review by CE2/CC and share with customer###I have made changes to the deployment plan as per Yogesh suggestion. Need to Reviewed by CE2/cc and share it with customerYogesh updated to add 1.  Add steps to take screenshot/notes of the below:     df -Th    mount    cat /etc/fstab    lsblk      netstat -ntlp2  and then after the deployment verify with this notes/screens that everything is finePlease upadate the deployment plan and reviewed by CE2/CC share it with customer###I have created the deployment plan. Morning shift team: Please get it reviewed by Yogesh.https://docs.google.com/spreadsheets/d/12stY9rjyAHLWEiAUedBPrXs0MX7I91NOL3NvGdbvdbM/edit#gid=0###Next action: Night Shift: Please work on the deployment plan and share it to Client after reviewing with Yogesh###Hello Allen/Dusty,Thanks for joining the call.As discussed on the call, we will schedule the volume increase of xvda1 volume from 50G to 500G for 10.59.10.135 on 15th July at 1 AM EST (10.30 AM IST). The expected downtime will be 1 hour.We will get back to you with a deployment plan.###Could we please schedule the volume increase of xvda1 to 500gb for 10.59.10.135 to happen this Saturday (July 15th) at 1am EST.  From the phone call we just had the expected downtime should only be around 1 hour.  Let us know if that changes. Thanks! Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com###Hello Matthew, Please join the below bridge. https://reancloud.zoom.us/my/mgse1+1 646 558 8656Meeting ID: 670 993 7998###Hello Matthew, We will be available on the mentioned time. Please use the below bridge to join the call at 10:00 AM EST (7.30 PM IST) https://reancloud.zoom.us/my/mgse2 +1 646 558 8656 Meeting ID: 211 276 6542###Matthew updated that,Can we schedule for 1000 EST Hours this morning.###Hello Matthew,We will assist you on this. Please let us know your availability to get on a screen share session.","We are trying to change the data directory on Postgres on 10.59.10.135 but continue to have issues with this. Can you assist? -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Postgres,,12-07-2017 17:33,55,0,SpendHQ,We are closing this case and creating a change ticket.,Next action: Get the deployment plan review by CE2/CC and share with customer,I have made changes to the deployment plan as per Yogesh suggestion. Need to Reviewed by CE2/cc and share it with customerYogesh updated to add 1.  Add steps to take screenshot/notes of the below:     df -Th    mount    cat /etc/fstab    lsblk      netstat -ntlp2  and then after the deployment verify with this notes/screens that everything is finePlease upadate the deployment plan and reviewed by CE2/CC share it with customer,I have created the deployment plan. Morning shift team: Please get it reviewed by Yogesh.https://docs.google.com/spreadsheets/d/12stY9rjyAHLWEiAUedBPrXs0MX7I91NOL3NvGdbvdbM/edit#gid=0,Next action: Night Shift: Please work on the deployment plan and share it to Client after reviewing with Yogesh,"Hello Allen/Dusty,Thanks for joining the call.As discussed on the call, we will schedule the volume increase of xvda1 volume from 50G to 500G for 10.59.10.135 on 15th July at 1 AM EST (10.30 AM IST). The expected downtime will be 1 hour.We will get back to you with a deployment plan.",Could we please schedule the volume increase of xvda1 to 500gb for 10.59.10.135 to happen this Saturday (July 15th) at 1am EST.  From the phone call we just had the expected downtime should only be around 1 hour.  Let us know if that changes. Thanks! Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com,"Hello Matthew, Please join the below bridge. https://reancloud.zoom.us/my/mgse1+1 646 558 8656Meeting ID: 670 993 7998","Hello Matthew, We will be available on the mentioned time. Please use the below bridge to join the call at 10:00 AM EST (7.30 PM IST) https://reancloud.zoom.us/my/mgse2 +1 646 558 8656 Meeting ID: 211 276 6542","Matthew updated that,Can we schedule for 1000 EST Hours this morning.","Hello Matthew,We will assist you on this. Please let us know your availability to get on a screen share session.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Uw3tu,Cloud Engineer Level 3,Closed,1101404,Incident,16-07-2018 18:34,,"From Allen HerreraI have reviewed the RCAThank you and keep us in the loop on Preventive Action items 1 & 2###Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if you have any other concerns###Hello Team, We haven't heard back from you. Please review the RCA shared with you and let us know if you have any further questions.###Hello Team,We haven't heard back from you.Please review the RCA shared with you and let us know if you have any further questions.###Hello Team,Please find the attached RCA for the production outage on 12th July 2018.  Kindly review the RCA and let us know if you have any further queries.###Praveen updated the RCA with the Preventive Actions.@ziv.catriel - Look at them.Then we are good to ship it to the customer.------------------------------------------------------------------ziv.catriel [2:36 AM]Reviewed, Updated and good to be sent @praveen.muppala###Hi Praveen,Please review the RCA, I haven't added any Preventive steps to the same as the issue was at Nimble side. Please give your thoughts on the same. Thanks !Here is the link for the same:https://docs.google.com/document/d/1JWd-kHC0FsEuBWS2Qg9WPZE2_8UzjvglgXla1CvT_sc/edit####Please find the RCAhttps://docs.google.com/document/d/1JWd-kHC0FsEuBWS2Qg9WPZE2_8UzjvglgXla1CvT_sc/edit#Need to be completed root cause, preventive and corrective action.###The customer informed  prd-db-19082017 mounted to /mnt/production_19082017 went to read-only mode on 10.59.10.100. We have shared the bridge and unmount the volume and tried to remount again. After some time, we could see the instance status check got failed for the instance, so we performed a stop and start on the instance and all the mount got unmounted. After the status check passed, we have tried to list the volume but not getting any nibble volumesDavid  from Andromeda joined the call and he mentioned they are run out of storage issue for the nibble volumes and they are fixing it and will provide all volume back onlineLater we get the volume back online and mount the volumes in 10.59.10.100. customer restarted the services and confirmed prod was working fine2. The second issue was with NFS server (10-59-100-78), which also went to ready only mount. we tried the unmount options performed the restart on the NFS server and its depended services, but it won't work so we have performed stop and start on the server. later it came back on normal.3. they faced read-only mount issue on all volumes in 10.59.10.135 server. Here also we have unmounted and mount the volumes and they have restarted the service and got confirmation4. The NFS  shared volume on  10-59-100-78 server was showing empty and they are unable to find the shared files on the serverSo we went ahead and perform NFS  and depended services restart on the NFS server (10-59-100-78) that resolved the issues.  Alos, we have checked all the NFS client server server and verified the all are having write permission customer restarted all the services again and got the confirmation###Hi All,The mount has been re-mounted back on all the read-only mode folder. As confirmed by you on the call, everything is working fine now. Please let us know if you find any issue. Meanwhile we will prepare RCA for the same and share with you. Thanks !Regards,Rohit Puri###David McLaughlin2:32 AM (2 hours ago)to me, Allen, spendhq-support Yes.  Just a moment.  I am getting some people online to fix the issue.  Nimble has called me as well about the issue.###Hello David,Yes, this the volume. Could you please join the bridge and help us on this.###Hello Allen,Please, join the bridge below:https://reancloud.zoom.us/my/mgse1Dail: +1 646 558 8656 (US Toll) or +1 408 638 0968 (US Toll)       000 800 001 4002 (India Toll Free)       000 800 040 1201 (India Toll Free)Meeting ID: 670 993 7998###So the volume is prd-db-19082017 REAN can you confirm please?###Hey Rean/Andromeda Can we setup a web conference? Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###/dev/sdh        4.0T  1.8T  2.0T  48% /mnt/production_19082017   Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com###David McLaughlin2:04 AM (3 hours ago)to Allen, spendhq-support Alan/REANWhat volume is mounted as the production db volume?###From Allen HerreraThis is a sev1###Hello Team,We acknowledge your request we working on it will get back to you with updates.","Stephen KimaniJunior Cloud EngineerReanCloudreancloud.com---------- Forwarded message ----------From: Allen Herrera <aherrera@spendhq.com>Date: Wed, Jul 11, 2018 at 11:27 PMSubject: PROD DATABASE MOUNTS IN READ ONLY!To: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Rean we need this fixed now.OUR APP IS DOWN*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html?sign1>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely?sign2>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: PROD DATABASE MOUNTS IN READ ONLY!,,12-07-2018 01:58,100,0,SpendHQ,From Allen HerreraI have reviewed the RCAThank you and keep us in the loop on Preventive Action items 1 & 2,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if you have any other concerns","Hello Team, We haven't heard back from you. Please review the RCA shared with you and let us know if you have any further questions.","Hello Team,We haven't heard back from you.Please review the RCA shared with you and let us know if you have any further questions.","Hello Team,Please find the attached RCA for the production outage on 12th July 2018.  Kindly review the RCA and let us know if you have any further queries.","Praveen updated the RCA with the Preventive Actions.@ziv.catriel - Look at them.Then we are good to ship it to the customer.------------------------------------------------------------------ziv.catriel [2:36 AM]Reviewed, Updated and good to be sent @praveen.muppala","Hi Praveen,Please review the RCA, I haven't added any Preventive steps to the same as the issue was at Nimble side. Please give your thoughts on the same. Thanks !Here is the link for the same:https://docs.google.com/document/d/1JWd-kHC0FsEuBWS2Qg9WPZE2_8UzjvglgXla1CvT_sc/edit","#Please find the RCAhttps://docs.google.com/document/d/1JWd-kHC0FsEuBWS2Qg9WPZE2_8UzjvglgXla1CvT_sc/edit#Need to be completed root cause, preventive and corrective action.","The customer informed  prd-db-19082017 mounted to /mnt/production_19082017 went to read-only mode on 10.59.10.100. We have shared the bridge and unmount the volume and tried to remount again. After some time, we could see the instance status check got failed for the instance, so we performed a stop and start on the instance and all the mount got unmounted. After the status check passed, we have tried to list the volume but not getting any nibble volumesDavid  from Andromeda joined the call and he mentioned they are run out of storage issue for the nibble volumes and they are fixing it and will provide all volume back onlineLater we get the volume back online and mount the volumes in 10.59.10.100. customer restarted the services and confirmed prod was working fine2. The second issue was with NFS server (10-59-100-78), which also went to ready only mount. we tried the unmount options performed the restart on the NFS server and its depended services, but it won't work so we have performed stop and start on the server. later it came back on normal.3. they faced read-only mount issue on all volumes in 10.59.10.135 server. Here also we have unmounted and mount the volumes and they have restarted the service and got confirmation4. The NFS  shared volume on  10-59-100-78 server was showing empty and they are unable to find the shared files on the serverSo we went ahead and perform NFS  and depended services restart on the NFS server (10-59-100-78) that resolved the issues.  Alos, we have checked all the NFS client server server and verified the all are having write permission customer restarted all the services again and got the confirmation","Hi All,The mount has been re-mounted back on all the read-only mode folder. As confirmed by you on the call, everything is working fine now. Please let us know if you find any issue. Meanwhile we will prepare RCA for the same and share with you. Thanks !Regards,Rohit Puri","David McLaughlin2:32 AM (2 hours ago)to me, Allen, spendhq-support Yes.  Just a moment.  I am getting some people online to fix the issue.  Nimble has called me as well about the issue.","Hello David,Yes, this the volume. Could you please join the bridge and help us on this.","Hello Allen,Please, join the bridge below:https://reancloud.zoom.us/my/mgse1Dail: +1 646 558 8656 (US Toll) or +1 408 638 0968 (US Toll)       000 800 001 4002 (India Toll Free)       000 800 040 1201 (India Toll Free)Meeting ID: 670 993 7998",So the volume is prd-db-19082017 REAN can you confirm please?,Hey Rean/Andromeda Can we setup a web conference? Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com,/dev/sdh        4.0T  1.8T  2.0T  48% /mnt/production_19082017   Allen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com,"David McLaughlin2:04 AM (3 hours ago)to Allen, spendhq-support Alan/REANWhat volume is mounted as the production db volume?",From Allen HerreraThis is a sev1,"Hello Team,We acknowledge your request we working on it will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eOpsq,Cloud Engineer Level 1,Closed,1107374,Incident,09-11-2018 05:07,,"Hello Team,This is to notify you that we have received a high CPU Utilization alert on the host SpendHQ-memsql-server3-2018-04-01 in us-east-1 region.On checking, we identified the memsqld process to be consuming high CPU. Please refer to the screenshot attached below.The alert lasted for 8 minutes and the got recovered.Please let us know if you have any queries.Thanks.Resource Details:Instance ID:	i-093eff6fae479397c	Instance Name:	SpendHQ-memsql-server3-2018-04-01	Instance Type: 	i3.8xlarge	Availability Zone:	us-east-1b	Region:	us-east-1Subnet:	subnet-0d093d27	VPC:	vpc-76df7212Private IP Address: 	10.59.100.230","[image: Datadog][Recovered] [SpendHQ] - High CPU Utilization on the hostspendhq-memsql-server3-2018-04-01 - 10.59.100.230 -The alert is recovered now @ms@reancloud.com<https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024189?to_ts=1541719459000&group=host%3Ai-093eff6fae479397c&from_ts=1541712259000>avg(last_30m):avg:system.cpu.stolen{datadog_monitor:on} by {host} +avg:system.cpu.user{datadog_monitor:on} by {host} +avg:system.cpu.system{datadog_monitor:on} by {host} > 85The monitor was last triggered at Thu Nov 08 2018 23:15:29 UTC (*9 mins ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024189?group=host%3Ai-093eff6fae479397c>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024189/edit>] · [Viewi-093eff6fae479397c<https://app.datadoghq.com/infrastructure?filter=i-093eff6fae479397c>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1541719049000&tags=host%3Ai-093eff6fae479397c&from_ts=1541718029000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4654949428650129743>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Paul MulonziaREĀN Cloud | Reach, Engage, Āctivate, Nurtur--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Recovered: [SpendHQ] - High CPU Utilization on the host spendhq-memsql-server3-2018-04-01 - 10.59.100.230 -,,09-11-2018 05:02,1,0,SpendHQ,"Hello Team,This is to notify you that we have received a high CPU Utilization alert on the host SpendHQ-memsql-server3-2018-04-01 in us-east-1 region.On checking, we identified the memsqld process to be consuming high CPU. Please refer to the screenshot attached below.The alert lasted for 8 minutes and the got recovered.Please let us know if you have any queries.Thanks.Resource Details:Instance ID:	i-093eff6fae479397c	Instance Name:	SpendHQ-memsql-server3-2018-04-01	Instance Type: 	i3.8xlarge	Availability Zone:	us-east-1b	Region:	us-east-1Subnet:	subnet-0d093d27	VPC:	vpc-76df7212Private IP Address: 	10.59.100.230",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001C4L2n,Cloud Engineer Level 1,Closed,1055802,Incident,24-05-2017 12:50,,"Hello Team, On further analyzing the Preview ELB logs at the time of the alert, We are able to find the IP 139.162.79.87. The IP 139.162.79.87 belongs to Linode, LLC-Japan. These  IP was trying to execute the SERVER-APACHE Apache Struts remote code. As a fix, we have blocked the IP's at NACL level.Please find the ELB log:2017-05-24T06:34:02.394424Z preview-spendhq-xelb 139.162.79.87:54150 10.59.1.192:8080 0.000034 0.001935 0.00002 403 403 0 209 GET http://52.6.177.194:8080/ HTTP/1.1 Mozilla/5.0 - -Let us know if your team have any further queries regarding this case.###Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167 which belongs to the Preview ELB. Please find the Intrusion Prevention logs:1. 2017:05:24-06:21:38 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=36802 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02. 2017:05:24-06:21:38 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=36802 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=03. 2017:05:24-06:21:57 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=36834 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=04. 2017:05:24-06:21:57 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=36834 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are analyzing the ELB logs and will let you know the further updates.",1. Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41819Time...........: 2017-05-24 06:21:38Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 36802Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)System Uptime      : 192 days 22 hours 36 minutesSystem Load        : 0.152. Intrusion Prevention AlertMessage........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-24 06:21:38Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 36802Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)System Uptime      : 192 days 22 hours 36 minutesSystem Load        : 0.15System Version     : Sophos UTM 9.408-43. Intrusion Prevention AlertMessage........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-24 06:21:57Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 36834Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)System Uptime      : 192 days 22 hours 36 minutesSystem Load        : 0.144.Intrusion Prevention AlertMessage........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41819Time...........: 2017-05-24 06:21:57Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 36834Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)System Uptime      : 192 days 22 hours 36 minutesSystem Load        : 0.14System Version     : Sophos UTM 9.408-4Please refer to the manual for detailed instructions5.Intrusion Prevention AlertMessage........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-24 06:22:16Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 36847Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)System Uptime      : 192 days 22 hours 36 minutesSystem Load        : 0.136. Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-24 06:22:34Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 36857Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)--System Uptime      : 192 days 22 hours 37 minutesSystem Load        : 0.257. Intrusion Prevention AlertMessage........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41819Time...........: 2017-05-24 06:22:16Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 368478. Intrusion Prevention AlertMessage........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41819Time...........: 2017-05-24 06:22:34Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 36857Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http),[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,24-05-2017 12:06,1,0,SpendHQ,"Hello Team, On further analyzing the Preview ELB logs at the time of the alert, We are able to find the IP 139.162.79.87. The IP 139.162.79.87 belongs to Linode, LLC-Japan. These  IP was trying to execute the SERVER-APACHE Apache Struts remote code. As a fix, we have blocked the IP's at NACL level.Please find the ELB log:2017-05-24T06:34:02.394424Z preview-spendhq-xelb 139.162.79.87:54150 10.59.1.192:8080 0.000034 0.001935 0.00002 403 403 0 209 GET http://52.6.177.194:8080/ HTTP/1.1 Mozilla/5.0 - -Let us know if your team have any further queries regarding this case.","Hello Team, This is to inform you that we received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.167 which belongs to the Preview ELB. Please find the Intrusion Prevention logs:1. 2017:05:24-06:21:38 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=36802 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02. 2017:05:24-06:21:38 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=36802 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=03. 2017:05:24-06:21:57 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=36834 dstport=80 sid=41819 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=04. 2017:05:24-06:21:57 spendhq snort[12489]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.167 dstip=10.59.1.192 proto=6 srcport=36834 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are analyzing the ELB logs and will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DHUBp,Cloud Engineer Level 1,Closed,1063687,Incident,19-06-2017 22:58,,"Hello SPendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 75%. The alert lasted for more than an hour.We are continuously monitoring on it and will keep your team updated. Kindly revert back in case of any queries.Regards,Sumod.K.Bose###Hello SpendHQ-Team,The volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) is still above the threshold 90% with a value of 100%. Delete/zip unwanted files or folders which will help to reduce the current volume usage state in this instance./dev/xvda1 mounted on root is consuming high volume usage on this instance.Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 ext4 50G 47G 17M 100% / Let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello SpendHQ-Team,This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 is consuming high volume usage on this instance.[root@ip-10-59-10-135 ~]# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G   17M 100% /Files under root directory,21G     tmp 13G     usr12G     var 510M    home 285M    lib 282M    optFiles under /tmp folder,2.9G    liger_view_d450f01b90e9cfa5848596f1e6457c17.csv 2.2G    liger_view_82aa639f39ebbc1bb4a396eeef74ca6b.csv1.9G    liger_view_c31d7f0f61026de9b107a5ec3779cdbf.csv1.8G    liger_view_c36be998a45470480cc1b2cc171a7d66.csv1.8G    liger_view_a3288d8d56cb06e9c4ca2c3f7517948e.csv1.8G    liger_view_943ef6f4f72be240b2622fcfa122d988.csv 1.5G    liger_view_0bf5a78ca892c483084936e64708b179.csv 1.4G    liger_view_b812845e2c16c8b2299761b27bc92b79.csv Delete/zip unwanted files or folders to reduce the current volume usage state on this instance and let us know if your team have any further queries regarding this case.Resource Details:-Instance ID : i-008d43ad00357e47aInstance type : r3.8xlargeAvailability zone : us-east-1bPrivate IPs : 10.59.10.135Regards,Sumod.K.Bose","[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1497885659000&group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135&from_ts=1497884459000>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Mon Jun 19 2017 15:21:00 UTC (*48 secsago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [View10.59.10.135<https://app.datadoghq.com/infrastructure?hostname=10.59.10.135>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=3919540895317237726>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,19-06-2017 20:54,2,0,SpendHQ,"Hello SPendHQ-Team,The alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) got resolved and returned to a normal state with a value of 75%. The alert lasted for more than an hour.We are continuously monitoring on it and will keep your team updated. Kindly revert back in case of any queries.Regards,Sumod.K.Bose","Hello SpendHQ-Team,The volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135) is still above the threshold 90% with a value of 100%. Delete/zip unwanted files or folders which will help to reduce the current volume usage state in this instance./dev/xvda1 mounted on root is consuming high volume usage on this instance.Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1 ext4 50G 47G 17M 100% / Let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello SpendHQ-Team,This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance is above the threshold value of 90% with a value of 100%. On further analysis, we were able to figure out that the device /dev/xvda1 is consuming high volume usage on this instance.[root@ip-10-59-10-135 ~]# df -ThFilesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G   17M 100% /Files under root directory,21G     tmp 13G     usr12G     var 510M    home 285M    lib 282M    optFiles under /tmp folder,2.9G    liger_view_d450f01b90e9cfa5848596f1e6457c17.csv 2.2G    liger_view_82aa639f39ebbc1bb4a396eeef74ca6b.csv1.9G    liger_view_c31d7f0f61026de9b107a5ec3779cdbf.csv1.8G    liger_view_c36be998a45470480cc1b2cc171a7d66.csv1.8G    liger_view_a3288d8d56cb06e9c4ca2c3f7517948e.csv1.8G    liger_view_943ef6f4f72be240b2622fcfa122d988.csv 1.5G    liger_view_0bf5a78ca892c483084936e64708b179.csv 1.4G    liger_view_b812845e2c16c8b2299761b27bc92b79.csv Delete/zip unwanted files or folders to reduce the current volume usage state on this instance and let us know if your team have any further queries regarding this case.Resource Details:-Instance ID : i-008d43ad00357e47aInstance type : r3.8xlargeAvailability zone : us-east-1bPrivate IPs : 10.59.10.135Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gbR4b,Cloud Engineer Level 1,Closed,1109457,Incident,19-12-2018 21:44,,"Hello Team,We haven't heard back from you regarding the case for a while.At this time we are marking the case as closed. Please revert back to us in case of further queries.###Hello Matthew,We haven't heard back from you.We have attached the RCA herein for your reference.Please review it and let us know if you have any concerns.Thanks.###Hello Matthew,We have already prepared and shared the RCA with you.Please find it on the attachments section and let us know if you have any questions.Thanks###Hello Team,We have checked the ELB metrics during the time of the alert we could see everything was normal during the time of the alert.From the email notification, we could see that the site was not actually down. wormly tool didn't get the response from one of the locations. Please find the wormly uptime details HTTP Request	02:55:07	Operation timed out after 30002 milliseconds with 0 bytes received		New Jersey US###Hello Team,We have again received site down alert for URL: https://secure.spendhq.com/login we are checking on this and will get back to you with more details, In the meantime please let us know if you are performing any activity from your end.###Hi Team,We have checked on the AWS console and we could see that during the time of the alert there was a spike in average latency, request counts estimated ALB new connection count and we noticed multiple spikes on 4XX errors for the NewPreview-ELB.We also checked on the metrics for the backend instance and we could see that most of the metrics were normal except for a small spike in CPU utilization.Please check on the above details and let us know your thoughts on the same.###Hi Matthew,We will be providing details regarding the issue shortly, in the meantime please find attached RCA on the attachment section for the previous site down.Please have a look and let us know your thoughts on the same.Thanks,###Matthew Watts4:54 PM (2 minutes ago)to Rean, spendhq-support@reancloud.comNegative. Just excessive load. We are looking into this too.###Hi Team,As of the moment, the alert is resolved and the violation lasted for about 4 minutes 59 seconds.###Hello Team,This is to inform you that we have yet again received  site down alert for URL: https://secure.spendhq.com/login we are checking on this and will get back to you with more details,In the meantime please let us know if you are performing any activity from your end.Thanks,###@team:As I updated on Friday itself I have reviewed the RCA. Once let Praveen review the RCA we are good to share with customer. Thanks !###Matthew Watts <mwatts@spendhq.com>Today, 1:30 AMLet’s re-enable. We should be good now.###Sure MattewAs mentioned in the emailWe have tested it from our end. URL has passed sensor test. We have re-enabled monitoring.###Hello Matthew,Thank you for the update. We are enabling maintenance for now as we are receiving multiple alerts. Please let us know once you are done with your activity.###From Matthew,Please ignore this outage.###Hello Team, This is to notify that we have again received a site down alert on URL: https://secure.spendhq.com/login. It has recovered within 2 minutes. We looking into the issue and we will get back to you with more details.Meanwhile, please let us know if you are performing any activity.###Next Action: RCA needs to be reviewed by Praveen or Rohit.https://docs.google.com/document/d/1pP-ew0PiRnPb681f5O9lWo3JKmd_4ov3dAR3Cu3H7jA/edit####Matthew Watts3:41 AM (6 minutes ago)to Rean, spendhq-support@reancloud.comPerfect! Thank you.###Hello Team,We are actively working on the RCA and will share it with you soon.Thank you for your patience.###OPS call Praveen mentioned he will review the RCA and provide us with the feedback.###Created the RCA and got it reviewed by Rohit. @Praveen Please review and provide us approval to share the RCA with the customer. https://docs.google.com/document/d/1pP-ew0PiRnPb681f5O9lWo3JKmd_4ov3dAR3Cu3H7jA/edit####@Team:Here is the analysis on the site down:1. ELB(External): Secure-SpendHQ-ELBThere was spike in Latency, ELB 5XX and HTTP 5XX metrics at the time of alert.2. ELB(Internal): NewPreview-ELB There was slight hike in latency, request and HTTP 4XX metrics at the time of alert.3. When we checked the error logs at the time of alert at instance level. We found below errors:[Thu Dec 13 21:16:36 2018] [error] [client 10.59.100.52] No Access, referer: https://secure.spendhq.com/spend-visibility[Thu Dec 13 21:44:58 2018] [error] [client 10.59.100.52] SHQ_Exception: [2]: Unable to save Liger table mapper entry for user_id - 2428 email - dfullenkamp@insightsourcing.com in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 14784 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:45481383Please prepare the RCA on the basis of this and get it review by me. Thanks !###Hello Rohit,Please review the analysis.1. We could see high latency at 10:40 PM UTC which is 1 hour after the site down with the value os 1357534 milliseconds on the NewPreview-ELB. ELB 2. At the time of site down, there is a spike in Estimated ALB active connection count with the range of 628 connections and spike as well in estimated alb new connection count with the value of 169 on the NewPreview-ELB.3. We could see from var/log/message that httpd got killed. But the time differs from the site downtime. Logs were at 10:31 UTC.Dec 13 22:31:19 ip-10-59-101-6 kernel: Out of memory: Kill process 10879 (httpd) score 223 or sacrifice childDec 13 22:31:19 ip-10-59-101-6 kernel: Killed process 10879, UID 48, (httpd) total-vm:7720520kB, anon-rss:7345588kB, file-rss:1432kBDec 13 22:48:41 ip-10-59-101-6 dhclient[1066]: DHCPREQUEST on eth0 to 10.59.101.1 port 67 (xid=0x26f97567)Dec 13 22:48:41 ip-10-59-101-6 dhclient[1066]: DHCPACK from 10.59.101.1 (xid=0x26f97567)Dec 13 22:48:43 ip-10-59-101-6 dhclient[1066]: bound to 10.59.101.6 -- renewal in 1353 seconds.Dec 13 23:11:16 ip-10-59-101-6 dhclient[1066]: DHCPREQUEST on eth0 to 10.59.101.1 port 67 (xid=0x26f97567)Dec 13 23:11:16 ip-10-59-101-6 dhclient[1066]: DHCPACK from 10.59.101.1 (xid=0x26f97567)Dec 13 23:11:18 ip-10-59-101-6 dhclient[1066]: bound to 10.59.101.6 -- renewal in 1779 seconds.Dec 13 23:35:09 ip-10-59-101-6 newrelic-infra: time=2018-12-13T23:35:09Z level=error msg=metric sender can't process 0 times error=InventoryIngest: events were not accepted: 500 500 Internal Server Error Internal Server ErrorDec 13 23:40:57 ip-10-59-101-6 dhclient[1066]: DHCPREQUEST on eth0 to 10.59.101.1 port 67 (xid=0x26f97567)Dec 13 23:40:57 ip-10-59-101-6 dhclient[1066]: DHCPACK from 10.59.101.1 (xid=0x26f97567)Dec 13 23:40:59 ip-10-59-101-6 dhclient[1066]: bound to 10.59.101.6 -- renewal in 1768 seconds.Dec 13 23:47:39 ip-10-59-101-6 newrelic-infra: time=2018-12-13T23:47:39Z level=error msg=metric sender can't process 0 times error=InventoryIngest: events were not accepted: 500 500 Internal Server Error Internal Server Error4. From httpd logs, we can see multiple times httpd got killed since a long time.We haven't found anything suspicious at the time of the site down other than the above.###Matthew Watts <mwatts@spendhq.com>Fri 14-12-2018 03:18 AMAllen Herrera <aherrera@spendhq.com>;spendhq-support@reancloud.comREAN, We are back up but had 3 minutes of down time. Can we please get an RCA sent over asap.###Send email to leads###Team,We checked on the instance level metrics precisely on httpd error logs, /var/log/messages and couldn't see anything that could have caused the alert.Please check more on the instance level metrics.###Hello Team,We are still analyzing on this alert and so far this are the findings we have from the AWS console.1. For the backend instance (PRD-WW2_6) all the metrics were normal during the time of the alert.2. There was a small time gap for both average latency and the request count for the (NewPreview-ELB) associated with the instance also for the request count had a sudden drop on request that reached 1 around the time of the alert.3. From the backend RDS we noticed that around the time of the alert there was a drop in the network throughput.We are checking more on the instance level metrics to see if we can find anything that could have lead to the site down alert.Please find screenshots of the same on the attachment section.Thanks,###Hello Mathew,We are doing our analysis and we will provide a detailed RCA regarding the issue###Matthew Watts	12:49 AM (6 minutes ago)	to Rean, spendhq-support@reancloud.comThank you. Please provide an RCA.###Hello Team,This is to notify that we have a received an detected error alert on url: https://secure.spendhq.com/login  we looking into the issue we will get back to you with more details. It has recovered within 4 minutes.","Thu, 13 Dec 2018 16:42:00 -0500Detected Error on SpendHQ SecureEstimated Downtime: 59 secondshttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): London UK, Sydney-C AU, California US, Frankfurt DE-- \\-- \\-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,14-12-2018 03:13,139,0,SpendHQ,"Hello Team,We haven't heard back from you regarding the case for a while.At this time we are marking the case as closed. Please revert back to us in case of further queries.","Hello Matthew,We haven't heard back from you.We have attached the RCA herein for your reference.Please review it and let us know if you have any concerns.Thanks.","Hello Matthew,We have already prepared and shared the RCA with you.Please find it on the attachments section and let us know if you have any questions.Thanks","Hello Team,We have checked the ELB metrics during the time of the alert we could see everything was normal during the time of the alert.From the email notification, we could see that the site was not actually down. wormly tool didn't get the response from one of the locations. Please find the wormly uptime details HTTP Request	02:55:07	Operation timed out after 30002 milliseconds with 0 bytes received		New Jersey US","Hello Team,We have again received site down alert for URL: https://secure.spendhq.com/login we are checking on this and will get back to you with more details, In the meantime please let us know if you are performing any activity from your end.","Hi Team,We have checked on the AWS console and we could see that during the time of the alert there was a spike in average latency, request counts estimated ALB new connection count and we noticed multiple spikes on 4XX errors for the NewPreview-ELB.We also checked on the metrics for the backend instance and we could see that most of the metrics were normal except for a small spike in CPU utilization.Please check on the above details and let us know your thoughts on the same.","Hi Matthew,We will be providing details regarding the issue shortly, in the meantime please find attached RCA on the attachment section for the previous site down.Please have a look and let us know your thoughts on the same.Thanks,","Matthew Watts4:54 PM (2 minutes ago)to Rean, spendhq-support@reancloud.comNegative. Just excessive load. We are looking into this too.","Hi Team,As of the moment, the alert is resolved and the violation lasted for about 4 minutes 59 seconds.","Hello Team,This is to inform you that we have yet again received  site down alert for URL: https://secure.spendhq.com/login we are checking on this and will get back to you with more details,In the meantime please let us know if you are performing any activity from your end.Thanks,",@team:As I updated on Friday itself I have reviewed the RCA. Once let Praveen review the RCA we are good to share with customer. Thanks !,"Matthew Watts <mwatts@spendhq.com>Today, 1:30 AMLet’s re-enable. We should be good now.",Sure MattewAs mentioned in the emailWe have tested it from our end. URL has passed sensor test. We have re-enabled monitoring.,"Hello Matthew,Thank you for the update. We are enabling maintenance for now as we are receiving multiple alerts. Please let us know once you are done with your activity.","From Matthew,Please ignore this outage.","Hello Team, This is to notify that we have again received a site down alert on URL: https://secure.spendhq.com/login. It has recovered within 2 minutes. We looking into the issue and we will get back to you with more details.Meanwhile, please let us know if you are performing any activity.",Next Action: RCA needs to be reviewed by Praveen or Rohit.https://docs.google.com/document/d/1pP-ew0PiRnPb681f5O9lWo3JKmd_4ov3dAR3Cu3H7jA/edit,"#Matthew Watts3:41 AM (6 minutes ago)to Rean, spendhq-support@reancloud.comPerfect! Thank you.","Hello Team,We are actively working on the RCA and will share it with you soon.Thank you for your patience.",OPS call Praveen mentioned he will review the RCA and provide us with the feedback.,Created the RCA and got it reviewed by Rohit. @Praveen Please review and provide us approval to share the RCA with the customer. https://docs.google.com/document/d/1pP-ew0PiRnPb681f5O9lWo3JKmd_4ov3dAR3Cu3H7jA/edit,"#@Team:Here is the analysis on the site down:1. ELB(External): Secure-SpendHQ-ELBThere was spike in Latency, ELB 5XX and HTTP 5XX metrics at the time of alert.2. ELB(Internal): NewPreview-ELB There was slight hike in latency, request and HTTP 4XX metrics at the time of alert.3. When we checked the error logs at the time of alert at instance level. We found below errors:[Thu Dec 13 21:16:36 2018] [error] [client 10.59.100.52] No Access, referer: https://secure.spendhq.com/spend-visibility[Thu Dec 13 21:44:58 2018] [error] [client 10.59.100.52] SHQ_Exception: [2]: Unable to save Liger table mapper entry for user_id - 2428 email - dfullenkamp@insightsourcing.com in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/spend_visibility_controller.php on line 14784 fired on host secure.spendhq.com\\n, referer: https://secure.spendhq.com/spend-visibility/spend_detail/vendor_dashboard/vendor_id:45481383Please prepare the RCA on the basis of this and get it review by me. Thanks !","Hello Rohit,Please review the analysis.1. We could see high latency at 10:40 PM UTC which is 1 hour after the site down with the value os 1357534 milliseconds on the NewPreview-ELB. ELB 2. At the time of site down, there is a spike in Estimated ALB active connection count with the range of 628 connections and spike as well in estimated alb new connection count with the value of 169 on the NewPreview-ELB.3. We could see from var/log/message that httpd got killed. But the time differs from the site downtime. Logs were at 10:31 UTC.Dec 13 22:31:19 ip-10-59-101-6 kernel: Out of memory: Kill process 10879 (httpd) score 223 or sacrifice childDec 13 22:31:19 ip-10-59-101-6 kernel: Killed process 10879, UID 48, (httpd) total-vm:7720520kB, anon-rss:7345588kB, file-rss:1432kBDec 13 22:48:41 ip-10-59-101-6 dhclient[1066]: DHCPREQUEST on eth0 to 10.59.101.1 port 67 (xid=0x26f97567)Dec 13 22:48:41 ip-10-59-101-6 dhclient[1066]: DHCPACK from 10.59.101.1 (xid=0x26f97567)Dec 13 22:48:43 ip-10-59-101-6 dhclient[1066]: bound to 10.59.101.6 -- renewal in 1353 seconds.Dec 13 23:11:16 ip-10-59-101-6 dhclient[1066]: DHCPREQUEST on eth0 to 10.59.101.1 port 67 (xid=0x26f97567)Dec 13 23:11:16 ip-10-59-101-6 dhclient[1066]: DHCPACK from 10.59.101.1 (xid=0x26f97567)Dec 13 23:11:18 ip-10-59-101-6 dhclient[1066]: bound to 10.59.101.6 -- renewal in 1779 seconds.Dec 13 23:35:09 ip-10-59-101-6 newrelic-infra: time=2018-12-13T23:35:09Z level=error msg=metric sender can't process 0 times error=InventoryIngest: events were not accepted: 500 500 Internal Server Error Internal Server ErrorDec 13 23:40:57 ip-10-59-101-6 dhclient[1066]: DHCPREQUEST on eth0 to 10.59.101.1 port 67 (xid=0x26f97567)Dec 13 23:40:57 ip-10-59-101-6 dhclient[1066]: DHCPACK from 10.59.101.1 (xid=0x26f97567)Dec 13 23:40:59 ip-10-59-101-6 dhclient[1066]: bound to 10.59.101.6 -- renewal in 1768 seconds.Dec 13 23:47:39 ip-10-59-101-6 newrelic-infra: time=2018-12-13T23:47:39Z level=error msg=metric sender can't process 0 times error=InventoryIngest: events were not accepted: 500 500 Internal Server Error Internal Server Error4. From httpd logs, we can see multiple times httpd got killed since a long time.We haven't found anything suspicious at the time of the site down other than the above.","Matthew Watts <mwatts@spendhq.com>Fri 14-12-2018 03:18 AMAllen Herrera <aherrera@spendhq.com>;spendhq-support@reancloud.comREAN, We are back up but had 3 minutes of down time. Can we please get an RCA sent over asap.",Send email to leads,"Team,We checked on the instance level metrics precisely on httpd error logs, /var/log/messages and couldn't see anything that could have caused the alert.Please check more on the instance level metrics.","Hello Team,We are still analyzing on this alert and so far this are the findings we have from the AWS console.1. For the backend instance (PRD-WW2_6) all the metrics were normal during the time of the alert.2. There was a small time gap for both average latency and the request count for the (NewPreview-ELB) associated with the instance also for the request count had a sudden drop on request that reached 1 around the time of the alert.3. From the backend RDS we noticed that around the time of the alert there was a drop in the network throughput.We are checking more on the instance level metrics to see if we can find anything that could have lead to the site down alert.Please find screenshots of the same on the attachment section.Thanks,","Hello Mathew,We are doing our analysis and we will provide a detailed RCA regarding the issue","Matthew Watts	12:49 AM (6 minutes ago)	to Rean, spendhq-support@reancloud.comThank you. Please provide an RCA.","Hello Team,This is to notify that we have a received an detected error alert on url: https://secure.spendhq.com/login  we looking into the issue we will get back to you with more details. It has recovered within 4 minutes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKda,Cloud Engineer Level 1,Closed,1042228,Incident,,,,"Please update the 10.59.10.12 machine first and advise when complete.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]Sent: Friday, January 13, 2017 9:24 PMTo: Matthew Watts <mwatts@spendhq.com>Cc: REAN Support <support@reancloud.com>Subject: Re: MaintenanceHello Matthew,We are ready for the maintenance. Please let us know once you start making the changes.On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Rean Team are you ready to commence the updates as planned on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[http://reancloud.com/aws-ny-summit/top-1.jpg][https://www.reancloud.com/wp-content/uploads/2016/12/Financial-Services_Prem-Consulting-Partner_300x150_1.png]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Maintenance,,14-01-2017 08:00,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BYy5p,Cloud Engineer Level 1,Closed,1051591,Incident,04-05-2017 02:09,,"Hi Andrew,Thanks for your confirmation, we have enabled maintenance for this resource. Please let us know once you are done with the activity from your side. At this time we are marking this case as resolved.###Andrew Kim1:59 AM (5 minutes ago)to Rean, spendhq-support It appears the web server was not able to respond due to high load on the attached application database server. Our login page requires a connection to the database, and we were performing reports. Please put the preview site into maintenance mode until midnight (eastern) tonight as we are continuing to run reports. Thank you,###Hello Team, This is to notify you that we received an alert regarding site down for the URL https://preview.spendhq.com/login. The incident got resolved and we are able to access the website. The violation lasted for 3 minutes.Please let us know if you are performing any activity from your end.Regards,Safuvan KM###Steven Ng12:08 AM (8 minutes ago)to Rean We’ve solved the issue with preview.spendhq.com The files in the httpd folder had the wrong permissions. You can mark this closed.###Hello Steven,Thanks for the update and resolving the issue. We could see that the website is serving well and the incident has resolved. The violation lasted for 1 hour and 11 minutes. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Regards,SafuvanKM###Steven Ng11:24 PM (52 minutes ago)to Rean We’re not aware of any issues. One of the developers was in the system debugging but he stated that he did not perform any problematic actions. I can see HTTPD running.###Hello SpendHQ Team,The website is still not loading. We could see that the HTTPD service in stopped state in the PROD-SPHQ-DB-SERVER03 instance. Please let us know if you are performing any changes from your end. Meanwhile, we will look into the logs and related matrices to find out the root cause.Regards,Safuvan KM###Hello Team,This is to notify you that we got an alert regarding site down for url: https://preview.spendhq.com/login. The site is not accessible now.We are analyzing the issue and will let you know the update. Please let us know if you are performing any activity.","Wed, 03 May 2017 13:19:03 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): London UK, Sydney-C AU, Atlanta-B US, Dallas-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,03-05-2017 22:49,3,0,SpendHQ,"Hi Andrew,Thanks for your confirmation, we have enabled maintenance for this resource. Please let us know once you are done with the activity from your side. At this time we are marking this case as resolved.","Andrew Kim1:59 AM (5 minutes ago)to Rean, spendhq-support It appears the web server was not able to respond due to high load on the attached application database server. Our login page requires a connection to the database, and we were performing reports. Please put the preview site into maintenance mode until midnight (eastern) tonight as we are continuing to run reports. Thank you,","Hello Team, This is to notify you that we received an alert regarding site down for the URL https://preview.spendhq.com/login. The incident got resolved and we are able to access the website. The violation lasted for 3 minutes.Please let us know if you are performing any activity from your end.Regards,Safuvan KM",Steven Ng12:08 AM (8 minutes ago)to Rean We’ve solved the issue with preview.spendhq.com The files in the httpd folder had the wrong permissions. You can mark this closed.,"Hello Steven,Thanks for the update and resolving the issue. We could see that the website is serving well and the incident has resolved. The violation lasted for 1 hour and 11 minutes. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Regards,SafuvanKM",Steven Ng11:24 PM (52 minutes ago)to Rean We’re not aware of any issues. One of the developers was in the system debugging but he stated that he did not perform any problematic actions. I can see HTTPD running.,"Hello SpendHQ Team,The website is still not loading. We could see that the HTTPD service in stopped state in the PROD-SPHQ-DB-SERVER03 instance. Please let us know if you are performing any changes from your end. Meanwhile, we will look into the logs and related matrices to find out the root cause.Regards,Safuvan KM","Hello Team,This is to notify you that we got an alert regarding site down for url: https://preview.spendhq.com/login. The site is not accessible now.We are analyzing the issue and will let you know the update. Please let us know if you are performing any activity.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Xztp8,Cloud Engineer Level 1,Closed,1100755,Incident,27-06-2018 19:55,,"Hello Allen,Thanks for the update, hence we are marking this case as closed.###From AllenGreat my test shows the same now. Weird. Ill reach out again if I notice it happen again.###Hello Allen,We have completed this request also tested from our end we could see 0% packet loss. Please find the screenshot of output and let us know if you are still facing the issue.###Hello Allen,We will work on this case and will get back to you with updates.","Instance ID: i-0323db693c5312672 Private IP: 10.59.100.188Instance ID: i-03fe1454eb96251be   Private IP: 10.59.100.126Instance ID: i-000043e5d88d1d738   Private IP: 10.59.100.187These servers can’t communicate with each other.These machines need to be in the same AWS Security Group allowing all communication between each other on all portsI need this done asap!Example:[root@ip-10-59-100-188 aherrera]# ping 10.59.100.126PING 10.59.100.126 (10.59.100.126) 56(84) bytes of data.^C--- 10.59.100.126 ping statistics ---4 packets transmitted, 0 received, 100% packet loss, time 2999msAllen Herrera | Associate Engineer | SpendHQ®C: 360.888.3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- Applying NIST and SCCA Frameworks to Cloud28th June, 2018 <https://info.redlock.io/nist-scca-in-public-cloud-computing-webinar>Powerful cloud automation with Chef and REAN CloudJuly 11th, 2018 <https://pages.chef.io/automation-nation-rsvp.html>Moving to the cloud, securelyJuly 11th, 2018 <http://go.reancloud.com/moving-to-the-cloud-securely>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",3 new server communications - ! important !,,27-06-2018 19:20,1,0,SpendHQ,"Hello Allen,Thanks for the update, hence we are marking this case as closed.",From AllenGreat my test shows the same now. Weird. Ill reach out again if I notice it happen again.,"Hello Allen,We have completed this request also tested from our end we could see 0% packet loss. Please find the screenshot of output and let us know if you are still facing the issue.","Hello Allen,We will work on this case and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001deKRR,Cloud Engineer Level 1,Closed,1106769,Incident,31-10-2018 14:38,,"Hello SpendHQ Team,We have received an alert regarding Status Check failed Any on prd-ww1_122.Resource Details: ------------------------------------------------------------------------------------------- Instance Name: PRD-WW1_122 Instance ID: i-0ace70ce06368e4a7 Instance Type: r4.2xlarge Private IP: 10.59.100.122 VPC ID: vpc-76df7212 Subnet ID: subnet-0d093d27 Availability Zone: us-east-1b We have analyzed the CloudWatch metrics at the time of the alert and we could see normal CPU utilization metrics. However, there was a spike in Network In metrics reaching a maximum value of 24578921 Bytes at the time. Network Out metrics looked relatively low though. From the instance level, we could see several tty processes being killed by TERM signal. Please refer to the attachment section for full messages logs at the time of the alert. Oct 25 18:10:59 ip-10-59-100-122 clamd[1831]: SelfCheck: Database status OK. Oct 25 18:13:02 ip-10-59-100-122 init: serial (ttyS0) main process (2402) killed by TERM signal Oct 25 18:13:02 ip-10-59-100-122 init: tty (/dev/tty1) main process (2403) killed by TERM signal Oct 25 18:13:02 ip-10-59-100-122 init: newrelic-infra main process (799) killed by TERM signal Oct 25 18:13:02 ip-10-59-100-122 clamd[1831]: Pid file removed. Oct 25 18:13:02 ip-10-59-100-122 clamd[1831]: --- Stopped at Thu Oct 25 18:13:02 2018 Oct 25 18:13:02 ip-10-59-100-122 clamd[1831]: Socket file removed. Oct 25 18:13:03 ip-10-59-100-122 rpc.mountd[6081]: Caught signal 15, un-registering and exiting. Oct 25 18:13:03 ip-10-59-100-122 kernel: nfsd: last server has exited, flushing export cache Oct 25 18:13:04 ip-10-59-100-122 acpid: exiting Oct 25 18:13:04 ip-10-59-100-122 init: datadog-agent main process (11970) killed by TERM signal Oct 25 18:13:04 ip-10-59-100-122 ntpd[1742]: ntpd exiting on signal 15 Oct 25 18:13:05 ip-10-59-100-122 rpcbind: rpcbind terminating on signal. Restart with rpcbind -w Oct 25 18:13:05 ip-10-59-100-122 auditd[1121]: The audit daemon is exiting. Oct 25 18:13:05 ip-10-59-100-122 kernel: type=1305 audit(1540491185.572:1225363): audit_pid=0 old=1121 auid=4294967295 ses=4294967295 res=1 Oct 25 18:13:05 ip-10-59-100-122 kernel: type=1305 audit(1540491185.672:1225364): audit_enabled=0 old=1 auid=4294967295 ses=4294967295 res=1 Oct 25 18:13:05 ip-10-59-100-122 kernel: Kernel logging (proc) stopped. Oct 25 18:13:05 ip-10-59-100-122 rsyslogd: [origin software=rsyslogd swVersion=5.8.10 x-pid=1147 x-info=http://www.rsyslog.com] exiting on signal 15. Oct 25 18:14:24 ip-10-59-100-122 kernel: imklog 5.8.10, log source = /proc/kmsg started. Oct 25 18:14:24 ip-10-59-100-122 rsyslogd: [origin software=rsyslogd swVersion=5.8.10 x-pid=1166 x-info=http://www.rsyslog.com] start Oct 25 18:14:24 ip-10-59-100-122 kernel: Initializing cgroup subsys cpuset Oct 25 18:14:24 ip-10-59-100-122 kernel: Initializing cgroup subsys cpu Please validate our analysis and please let us know if you have any concerns regarding the case. As of now, we are marking this case as close.###Hi SpendHQ Team,This is a quick follow up. We have received status check failed on instance PRD-WW1_122 and we have analysed the issue in detail. Please find our analyse from our previous comment and please let us know if you have any queries regarding the same.###Hello Team, We haven't heard back from you regarding the alert of Status Check failed  on prd-ww1_122 - 10.59.100.122 - web,Kindly validate our previous email and please let us know if you have queries.Thank you.###Hello Team,We have analyzed the CloudWatch metrics at the time of the alert and we could see normal CPU utilization metrics. However there was a spike in Network In metrics reaching a maximum value of 24578921 Bytes at the time. Network Out metrics looked relatively low though.From the instance level we could see several tty processes being killed by TERM signal. Please refer to the attachment section for full messages logs at the time of the alert.Oct 25 18:10:59 ip-10-59-100-122 clamd[1831]: SelfCheck: Database status OK.Oct 25 18:13:02 ip-10-59-100-122 init: serial (ttyS0) main process (2402) killed by TERM signalOct 25 18:13:02 ip-10-59-100-122 init: tty (/dev/tty1) main process (2403) killed by TERM signalOct 25 18:13:02 ip-10-59-100-122 init: newrelic-infra main process (799) killed by TERM signalOct 25 18:13:02 ip-10-59-100-122 clamd[1831]: Pid file removed.Oct 25 18:13:02 ip-10-59-100-122 clamd[1831]: --- Stopped at Thu Oct 25 18:13:02 2018Oct 25 18:13:02 ip-10-59-100-122 clamd[1831]: Socket file removed.Oct 25 18:13:03 ip-10-59-100-122 rpc.mountd[6081]: Caught signal 15, un-registering and exiting.Oct 25 18:13:03 ip-10-59-100-122 kernel: nfsd: last server has exited, flushing export cacheOct 25 18:13:04 ip-10-59-100-122 acpid: exitingOct 25 18:13:04 ip-10-59-100-122 init: datadog-agent main process (11970) killed by TERM signalOct 25 18:13:04 ip-10-59-100-122 ntpd[1742]: ntpd exiting on signal 15Oct 25 18:13:05 ip-10-59-100-122 rpcbind: rpcbind terminating on signal. Restart with rpcbind -wOct 25 18:13:05 ip-10-59-100-122 auditd[1121]: The audit daemon is exiting.Oct 25 18:13:05 ip-10-59-100-122 kernel: type=1305 audit(1540491185.572:1225363): audit_pid=0 old=1121 auid=4294967295 ses=4294967295 res=1Oct 25 18:13:05 ip-10-59-100-122 kernel: type=1305 audit(1540491185.672:1225364): audit_enabled=0 old=1 auid=4294967295 ses=4294967295 res=1Oct 25 18:13:05 ip-10-59-100-122 kernel: Kernel logging (proc) stopped.Oct 25 18:13:05 ip-10-59-100-122 rsyslogd: [origin software=rsyslogd swVersion=5.8.10 x-pid=1147 x-info=http://www.rsyslog.com] exiting on signal 15.Oct 25 18:14:24 ip-10-59-100-122 kernel: imklog 5.8.10, log source = /proc/kmsg started.Oct 25 18:14:24 ip-10-59-100-122 rsyslogd: [origin software=rsyslogd swVersion=5.8.10 x-pid=1166 x-info=http://www.rsyslog.com] startOct 25 18:14:24 ip-10-59-100-122 kernel: Initializing cgroup subsys cpusetOct 25 18:14:24 ip-10-59-100-122 kernel: Initializing cgroup subsys cpuFrom the secure logs we could see two users aherrera and mwatts were logged in a few minutes before the alert.Oct 25 18:13:02 ip-10-59-100-122 su: pam_unix(su:session): session closed for user dd-agentOct 25 18:13:02 ip-10-59-100-122 su: pam_unix(su:session): session closed for user dd-agentOct 25 18:13:02 ip-10-59-100-122 su: pam_unix(su:session): session closed for user dd-agentOct 25 18:13:02 ip-10-59-100-122 sshd[28269]: Received signal 15; terminating.Oct 25 18:13:02 ip-10-59-100-122 sshd[16280]: pam_unix(sshd:session): session closed for user aherreraOct 25 18:13:02 ip-10-59-100-122 sshd[24549]: pam_unix(sshd:session): session closed for user mwattsOct 25 18:13:02 ip-10-59-100-122 sshd[19004]: pam_unix(sshd:session): session closed for user aherreraOct 25 18:13:02 ip-10-59-100-122 su: pam_unix(su:session): session closed for user rootOct 25 18:14:27 ip-10-59-100-122 sshd[1657]: Server listening on 0.0.0.0 port 22.Oct 25 18:14:27 ip-10-59-100-122 sshd[1657]: Server listening on :: port 22.Oct 25 18:14:35 ip-10-59-100-122 sshd[1746]: Accepted publickey for aherrera from 10.59.1.192 port 55790 ssh2Oct 25 18:14:35 ip-10-59-100-122 sshd[1746]: pam_unix(sshd:session): session opened for user aherrera by (uid=0)Please review these details and let us know if you performed any activity at the time.Thanks.###Hello Team,This is to notify you that we received an alert regarding Status Check failed Any on prd-ww1_122 - 10.59.100.122 - web.The server failed instance status check. The alert is now recovered and in OK state. The violation lasted 11 minutes.We are investigating this issue and will get back to you with the updates.Resource Details:-------------------------------------------------------------------------------------------Instance Name: PRD-WW1_122Instance ID: i-0ace70ce06368e4a7Instance Type: r4.2xlargePrivate IP: 10.59.100.122VPC ID: vpc-76df7212Subnet ID: subnet-0d093d27Availability Zone: us-east-1b--------------------------------------------------------------------------------------------Thanks.","[Triggered] [SpendHQ] - Status Check failed Any on prd-ww1_122 -10.59.100.122 - webStop and start the instance and raise a support ticket if System statuscheck is failing. Get approval from client and reboot the system ifInstance status check is failing@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2044546?to_ts=1540491456000&group=host%3Ai-0ace70ce06368e4a7&from_ts=1540487856000>*aws.ec2.status_check_failed* over*datadog_monitor:on,host:i-0ace70ce06368e4a7* was *> 0.0* on average duringthe *last 5m*.The monitor was last triggered at Thu Oct 25 2018 18:17:46 UTC (*3 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2044546?group=host%3Ai-0ace70ce06368e4a7>]· [Edit Monitor <https://app.datadoghq.com/monitors#2044546/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?filter=i-0ace70ce06368e4a7>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1540491586000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1540490566000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4634346945459572211>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Triggered: [SpendHQ] - Status Check failed Any on prd-ww1_122 - 10.59.100.122 - web,,25-10-2018 23:59,135,0,SpendHQ,"Hello SpendHQ Team,We have received an alert regarding Status Check failed Any on prd-ww1_122.Resource Details: ------------------------------------------------------------------------------------------- Instance Name: PRD-WW1_122 Instance ID: i-0ace70ce06368e4a7 Instance Type: r4.2xlarge Private IP: 10.59.100.122 VPC ID: vpc-76df7212 Subnet ID: subnet-0d093d27 Availability Zone: us-east-1b We have analyzed the CloudWatch metrics at the time of the alert and we could see normal CPU utilization metrics. However, there was a spike in Network In metrics reaching a maximum value of 24578921 Bytes at the time. Network Out metrics looked relatively low though. From the instance level, we could see several tty processes being killed by TERM signal. Please refer to the attachment section for full messages logs at the time of the alert. Oct 25 18:10:59 ip-10-59-100-122 clamd[1831]: SelfCheck: Database status OK. Oct 25 18:13:02 ip-10-59-100-122 init: serial (ttyS0) main process (2402) killed by TERM signal Oct 25 18:13:02 ip-10-59-100-122 init: tty (/dev/tty1) main process (2403) killed by TERM signal Oct 25 18:13:02 ip-10-59-100-122 init: newrelic-infra main process (799) killed by TERM signal Oct 25 18:13:02 ip-10-59-100-122 clamd[1831]: Pid file removed. Oct 25 18:13:02 ip-10-59-100-122 clamd[1831]: --- Stopped at Thu Oct 25 18:13:02 2018 Oct 25 18:13:02 ip-10-59-100-122 clamd[1831]: Socket file removed. Oct 25 18:13:03 ip-10-59-100-122 rpc.mountd[6081]: Caught signal 15, un-registering and exiting. Oct 25 18:13:03 ip-10-59-100-122 kernel: nfsd: last server has exited, flushing export cache Oct 25 18:13:04 ip-10-59-100-122 acpid: exiting Oct 25 18:13:04 ip-10-59-100-122 init: datadog-agent main process (11970) killed by TERM signal Oct 25 18:13:04 ip-10-59-100-122 ntpd[1742]: ntpd exiting on signal 15 Oct 25 18:13:05 ip-10-59-100-122 rpcbind: rpcbind terminating on signal. Restart with rpcbind -w Oct 25 18:13:05 ip-10-59-100-122 auditd[1121]: The audit daemon is exiting. Oct 25 18:13:05 ip-10-59-100-122 kernel: type=1305 audit(1540491185.572:1225363): audit_pid=0 old=1121 auid=4294967295 ses=4294967295 res=1 Oct 25 18:13:05 ip-10-59-100-122 kernel: type=1305 audit(1540491185.672:1225364): audit_enabled=0 old=1 auid=4294967295 ses=4294967295 res=1 Oct 25 18:13:05 ip-10-59-100-122 kernel: Kernel logging (proc) stopped. Oct 25 18:13:05 ip-10-59-100-122 rsyslogd: [origin software=rsyslogd swVersion=5.8.10 x-pid=1147 x-info=http://www.rsyslog.com] exiting on signal 15. Oct 25 18:14:24 ip-10-59-100-122 kernel: imklog 5.8.10, log source = /proc/kmsg started. Oct 25 18:14:24 ip-10-59-100-122 rsyslogd: [origin software=rsyslogd swVersion=5.8.10 x-pid=1166 x-info=http://www.rsyslog.com] start Oct 25 18:14:24 ip-10-59-100-122 kernel: Initializing cgroup subsys cpuset Oct 25 18:14:24 ip-10-59-100-122 kernel: Initializing cgroup subsys cpu Please validate our analysis and please let us know if you have any concerns regarding the case. As of now, we are marking this case as close.","Hi SpendHQ Team,This is a quick follow up. We have received status check failed on instance PRD-WW1_122 and we have analysed the issue in detail. Please find our analyse from our previous comment and please let us know if you have any queries regarding the same.","Hello Team, We haven't heard back from you regarding the alert of Status Check failed  on prd-ww1_122 - 10.59.100.122 - web,Kindly validate our previous email and please let us know if you have queries.Thank you.","Hello Team,We have analyzed the CloudWatch metrics at the time of the alert and we could see normal CPU utilization metrics. However there was a spike in Network In metrics reaching a maximum value of 24578921 Bytes at the time. Network Out metrics looked relatively low though.From the instance level we could see several tty processes being killed by TERM signal. Please refer to the attachment section for full messages logs at the time of the alert.Oct 25 18:10:59 ip-10-59-100-122 clamd[1831]: SelfCheck: Database status OK.Oct 25 18:13:02 ip-10-59-100-122 init: serial (ttyS0) main process (2402) killed by TERM signalOct 25 18:13:02 ip-10-59-100-122 init: tty (/dev/tty1) main process (2403) killed by TERM signalOct 25 18:13:02 ip-10-59-100-122 init: newrelic-infra main process (799) killed by TERM signalOct 25 18:13:02 ip-10-59-100-122 clamd[1831]: Pid file removed.Oct 25 18:13:02 ip-10-59-100-122 clamd[1831]: --- Stopped at Thu Oct 25 18:13:02 2018Oct 25 18:13:02 ip-10-59-100-122 clamd[1831]: Socket file removed.Oct 25 18:13:03 ip-10-59-100-122 rpc.mountd[6081]: Caught signal 15, un-registering and exiting.Oct 25 18:13:03 ip-10-59-100-122 kernel: nfsd: last server has exited, flushing export cacheOct 25 18:13:04 ip-10-59-100-122 acpid: exitingOct 25 18:13:04 ip-10-59-100-122 init: datadog-agent main process (11970) killed by TERM signalOct 25 18:13:04 ip-10-59-100-122 ntpd[1742]: ntpd exiting on signal 15Oct 25 18:13:05 ip-10-59-100-122 rpcbind: rpcbind terminating on signal. Restart with rpcbind -wOct 25 18:13:05 ip-10-59-100-122 auditd[1121]: The audit daemon is exiting.Oct 25 18:13:05 ip-10-59-100-122 kernel: type=1305 audit(1540491185.572:1225363): audit_pid=0 old=1121 auid=4294967295 ses=4294967295 res=1Oct 25 18:13:05 ip-10-59-100-122 kernel: type=1305 audit(1540491185.672:1225364): audit_enabled=0 old=1 auid=4294967295 ses=4294967295 res=1Oct 25 18:13:05 ip-10-59-100-122 kernel: Kernel logging (proc) stopped.Oct 25 18:13:05 ip-10-59-100-122 rsyslogd: [origin software=rsyslogd swVersion=5.8.10 x-pid=1147 x-info=http://www.rsyslog.com] exiting on signal 15.Oct 25 18:14:24 ip-10-59-100-122 kernel: imklog 5.8.10, log source = /proc/kmsg started.Oct 25 18:14:24 ip-10-59-100-122 rsyslogd: [origin software=rsyslogd swVersion=5.8.10 x-pid=1166 x-info=http://www.rsyslog.com] startOct 25 18:14:24 ip-10-59-100-122 kernel: Initializing cgroup subsys cpusetOct 25 18:14:24 ip-10-59-100-122 kernel: Initializing cgroup subsys cpuFrom the secure logs we could see two users aherrera and mwatts were logged in a few minutes before the alert.Oct 25 18:13:02 ip-10-59-100-122 su: pam_unix(su:session): session closed for user dd-agentOct 25 18:13:02 ip-10-59-100-122 su: pam_unix(su:session): session closed for user dd-agentOct 25 18:13:02 ip-10-59-100-122 su: pam_unix(su:session): session closed for user dd-agentOct 25 18:13:02 ip-10-59-100-122 sshd[28269]: Received signal 15; terminating.Oct 25 18:13:02 ip-10-59-100-122 sshd[16280]: pam_unix(sshd:session): session closed for user aherreraOct 25 18:13:02 ip-10-59-100-122 sshd[24549]: pam_unix(sshd:session): session closed for user mwattsOct 25 18:13:02 ip-10-59-100-122 sshd[19004]: pam_unix(sshd:session): session closed for user aherreraOct 25 18:13:02 ip-10-59-100-122 su: pam_unix(su:session): session closed for user rootOct 25 18:14:27 ip-10-59-100-122 sshd[1657]: Server listening on 0.0.0.0 port 22.Oct 25 18:14:27 ip-10-59-100-122 sshd[1657]: Server listening on :: port 22.Oct 25 18:14:35 ip-10-59-100-122 sshd[1746]: Accepted publickey for aherrera from 10.59.1.192 port 55790 ssh2Oct 25 18:14:35 ip-10-59-100-122 sshd[1746]: pam_unix(sshd:session): session opened for user aherrera by (uid=0)Please review these details and let us know if you performed any activity at the time.Thanks.","Hello Team,This is to notify you that we received an alert regarding Status Check failed Any on prd-ww1_122 - 10.59.100.122 - web.The server failed instance status check. The alert is now recovered and in OK state. The violation lasted 11 minutes.We are investigating this issue and will get back to you with the updates.Resource Details:-------------------------------------------------------------------------------------------Instance Name: PRD-WW1_122Instance ID: i-0ace70ce06368e4a7Instance Type: r4.2xlargePrivate IP: 10.59.100.122VPC ID: vpc-76df7212Subnet ID: subnet-0d093d27Availability Zone: us-east-1b--------------------------------------------------------------------------------------------Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eMZRE,Cloud Engineer Level 1,Closed,1107112,Incident,05-11-2018 04:27,,"Matthew Watts4:23 AM (2 minutes ago)to me, REAN, spendhq-support@reancloud.comThank you.###Nishad Ali <nishad.ali@reancloud.com>================================Hello Matthew,At the time the issue, we have tried to Login to the instance using the ssh but not able to do that. On further checking, we could see that instance has failed with Instance level status check. To fix this issue we had performed a stop and start on the instance.From the logs, we could see that Kernel panic - not syncing: Fatal exception in interrupt . Normally this error triggers when the system got stucks due to one or more causes that mentioned Below.Causes of Kernel PanicThere are several causes, but most common are listed below:Defective or Incompatible RAM is the most common and frequent cause of Kernel Panic.Obsolete, Incompatible or Corrupted Kernel ExtensionsObsolete, Incompatible or Corrupted Kernel Drivers.Hard disk corruption or issues such as bad sectors or directory corruption can also lead to kernel panic.Insufficient RAM or Hard disk spaceDefective hardware, badly written programs or hardware failures can also lead to kernel Panic.When the system encountered with the Kernal panic error, it will result in the booting failure of the instance and will stop writing any log files.  So we have to go ahead with a forced restart to fix this issue.So the root cause of the issue that you faced in reaching to the instance is exactly due to the Status check failure. The schedule tags are actually working fine and from the Metrics, we could see that the instance has started at the 11:00 AM UTC as scheduled and then encountered with the errors around at 11:07 AM UTC and resulted in Instance status check failure. Please check the attached screenshot for more details.Let us know if you have any queries###Matthew Watts3:34 AM (1 hour ago)to Rean, spendhq-support@reancloud.comWhat was the root cause here?###Shared on Email:----------------------------------------------Hello Chris,Thank you for the confirmation.We have checked further and were able to see that there was a kernel panic.We could see the following error from system logs:Kernel panic - not syncing: Fatal exception in interruptTherefore, as mentioned, the instance has now passed both Status Checks.As the issue is resolved, we proceeding to close the case.Regards,Isaac###Nishad Ali===============Hello ChrisIn order to fix the issue, we have performed stop and start on the instance. At present, the instance is passing both the System and Instance level status checks and running fine. We will be checking more on the cause of the status check failure and will update you.ThanksNishad Ali###Nishad Ali <nishad.ali@reancloud.com>=============================Hello ChrisWe had checked with the issue and could see that the Instance Status check is failed and this caused the issue. We will be checking more on this and update you with the details.Thanks Nishad Ali","Date: Fri, Nov 2, 2018 at 10:35 PMSubject: 10.59.100.61 did not wake up this morningTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Cc: Matthew Watts <mwatts@spendhq.com>, Leonel Atencio <latencio@number8.com>Hi REAN,It seems that *10.59.100.61* did not wake up as scheduled this morning.Could you take a look?Thanks,*Chris Min* | Senior Data Engineer | *Spend**HQ®*O: 470.204.0862 | C: 770.688.5695 | cmin@spendhq.com <cmin@spenhq.com>*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com--",10.59.100.61 did not wake up this morning,,02-11-2018 22:43,3,0,SpendHQ,"Matthew Watts4:23 AM (2 minutes ago)to me, REAN, spendhq-support@reancloud.comThank you.","Nishad Ali <nishad.ali@reancloud.com>================================Hello Matthew,At the time the issue, we have tried to Login to the instance using the ssh but not able to do that. On further checking, we could see that instance has failed with Instance level status check. To fix this issue we had performed a stop and start on the instance.From the logs, we could see that Kernel panic - not syncing: Fatal exception in interrupt . Normally this error triggers when the system got stucks due to one or more causes that mentioned Below.Causes of Kernel PanicThere are several causes, but most common are listed below:Defective or Incompatible RAM is the most common and frequent cause of Kernel Panic.Obsolete, Incompatible or Corrupted Kernel ExtensionsObsolete, Incompatible or Corrupted Kernel Drivers.Hard disk corruption or issues such as bad sectors or directory corruption can also lead to kernel panic.Insufficient RAM or Hard disk spaceDefective hardware, badly written programs or hardware failures can also lead to kernel Panic.When the system encountered with the Kernal panic error, it will result in the booting failure of the instance and will stop writing any log files.  So we have to go ahead with a forced restart to fix this issue.So the root cause of the issue that you faced in reaching to the instance is exactly due to the Status check failure. The schedule tags are actually working fine and from the Metrics, we could see that the instance has started at the 11:00 AM UTC as scheduled and then encountered with the errors around at 11:07 AM UTC and resulted in Instance status check failure. Please check the attached screenshot for more details.Let us know if you have any queries","Matthew Watts3:34 AM (1 hour ago)to Rean, spendhq-support@reancloud.comWhat was the root cause here?","Shared on Email:----------------------------------------------Hello Chris,Thank you for the confirmation.We have checked further and were able to see that there was a kernel panic.We could see the following error from system logs:Kernel panic - not syncing: Fatal exception in interruptTherefore, as mentioned, the instance has now passed both Status Checks.As the issue is resolved, we proceeding to close the case.Regards,Isaac","Nishad Ali===============Hello ChrisIn order to fix the issue, we have performed stop and start on the instance. At present, the instance is passing both the System and Instance level status checks and running fine. We will be checking more on the cause of the status check failure and will update you.ThanksNishad Ali",Nishad Ali <nishad.ali@reancloud.com>=============================Hello ChrisWe had checked with the issue and could see that the Instance Status check is failed and this caused the issue. We will be checking more on this and update you with the details.Thanks Nishad Ali,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001lSKlc,Cloud Engineer Level 1,Closed,1113187,Incident,14-03-2019 00:16,,"Hello Balam,Since we don't have any action item pending from our end as of now we are marking this case as closed.###Hello Balam,As you have already mentioned, since this issue is resolved, please let us know if you need any help from us. Thank you.###This box runs between 5pm EST and 12AM EST I believe. So not sure if that would be why you saw a discrepancy. It should currently be on as to whether or not it’s reachable from the pentest box, I cannot answer that.  Best Regards, Dan Mackay###You’re welcome. Also note – this server is a replica of the Supervisor server (but has more resources) and its sole purpose is to run the ETL job for production uploads. The only Supervisor job that typically runs on it would be etl_initiator.  Best Regards, Dan Mackay###I understand. The team can reach it now. Since it was labeled with the SpendHQ-office-hours policy we asked. I'll let the team know of the availability of the instance. Thank you for the clarification. Balam MendozaCISO OfficeSpendHQ","Hi,The instance named ETL_Server with IP 10.59.100.214 is off or unreachable from the pentest box, although in the inventory is marked as running.Can you confirm it is on and reachable from the pentest box?Thanks,Balam MendozaCISO OfficeSpendHQ",ETL_Server - Pentest Efforts,,13-03-2019 03:45,21,0,SpendHQ,"Hello Balam,Since we don't have any action item pending from our end as of now we are marking this case as closed.","Hello Balam,As you have already mentioned, since this issue is resolved, please let us know if you need any help from us. Thank you.","This box runs between 5pm EST and 12AM EST I believe. So not sure if that would be why you saw a discrepancy. It should currently be on as to whether or not it’s reachable from the pentest box, I cannot answer that.  Best Regards, Dan Mackay","You’re welcome. Also note – this server is a replica of the Supervisor server (but has more resources) and its sole purpose is to run the ETL job for production uploads. The only Supervisor job that typically runs on it would be etl_initiator.  Best Regards, Dan Mackay",I understand. The team can reach it now. Since it was labeled with the SpendHQ-office-hours policy we asked. I'll let the team know of the availability of the instance. Thank you for the clarification. Balam MendozaCISO OfficeSpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKq5,Cloud Engineer Level 1,Closed,1042234,Incident,,,,"HI Matt -Sorry - didn't know which vol to image - and if you want to clone it ...Can you let me know - I am standing byChris VeilletteCTO[1450833261212_7186d8e7bdbb48853119db07d964f770.jpg]www.Andromeda3.com<http://www.Andromeda3.com>cveillette@andromeda3.comMobile: 703.447.4124Office:   571.781.0428________________________________From: Matthew Watts <mwatts@spendhq.com>Sent: Friday, January 13, 2017 9:52 PMTo: Mrigank Saxena; Chris VeilletteCc: REAN SupportSubject: RE: MaintenanceChris,Did you manage to image the machine?Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]Sent: Friday, January 13, 2017 9:37 PMTo: Matthew Watts <mwatts@spendhq.com>Cc: REAN Support <support@reancloud.com>Subject: Re: MaintenanceHello Matthew,As mentioned earlier, Andromeda team is going to clone the volume before we proceed with the patching of the instance.Please let us know if that is done so that we can proceed with the security patching.On Sat, Jan 14, 2017 at 8:00 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Please update the 10.59.10.12 machine first and advise when complete.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com<mailto:mrigank.saxena@reancloud.com>]Sent: Friday, January 13, 2017 9:24 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,We are ready for the maintenance. Please let us know once you start making the changes.On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Rean Team are you ready to commence the updates as planned on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--Mrigank SaxenaREAN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>--Mrigank SaxenaREAN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Maintenance,,14-01-2017 08:36,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000017QEMF,Cloud Engineer Level 1,Closed,1042776,Incident,03-02-2017 00:59,,"Hello Matthew,Yes. As we witness the status check failure, we have performed a stop and start action that will change the underlying hardware for the instance.t this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM###Matthew replied that,Thank you for that information. Just to be crystal clear, REAN has migrated the database 10.59.10.12 to new hardware to mitigate any future issues?###Hi Matthew,The issue encountered by the underlying hardware for PROD-SPHQ-DB-SERVER02 as a result this caused the system level check to failThe AWS Team replied that the underlying hardware hosting your instances developed some issues resulting in your instances being impaired. You performed a stop/start operation and your instances were migrated to underlying hardware that is operating as expected.Amazon EC2 performs automated checks on every running EC2 instance to identify hardware and software issues. There are 2 types of status check --1. System Status Checks : This means, if there was a failure with the underlying hardware where the instance is running i.e on AWS side.2. Instance Status Checks: This means, if there is a problem with the instance i.e. within the operating systemAll of these issues can only be resolved and fixed by AWS as they are issues relating to the underlying hardware that the instances reside on which we (users of AWS) have no access to. For resolving this we have performed stop and start to migrate the instance to a new underlying hardware which has resolved the issue.Let us know if you need any further clarification.###Hello SpendHQ-Team,We went ahead a call with AWS Support team and they have confirmed that there was an issue with the underlying hardware of the instance PROD-SPHQ-DB-SERVER02 which lead to this outage. Currently, we are analyzing the mount points and will check whether they were impacted during this outage and will get back to you with further updates on it.Please let us know if you have any queries regarding this case.###Hello SpendHQ-Team,This is to inform you that we received an alert regarding site down for the URL's https://preview.spendhq.com/login and https://secure.spendhq.com/login. On further analysis, we were able to figure out that the instance and system status check has failed for the instance PROD-SPHQ-DB-SERVER02.We have performed a stop and start an activity on this instance which resolved this case.Now, both the sites are up and running well.We have raised a ticket with AWS regarding this case and will get back to you with further updates as soon as possible.","Thu, 02 Feb 2017 02:17:42 -0500Detected Error on SpendHQEstimated Downtime: 2 minutes https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: --------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Atlanta-B US, California US, Sydney-C AU, London UK-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,02-02-2017 12:47,12,0,SpendHQ,"Hello Matthew,Yes. As we witness the status check failure, we have performed a stop and start action that will change the underlying hardware for the instance.t this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM","Matthew replied that,Thank you for that information. Just to be crystal clear, REAN has migrated the database 10.59.10.12 to new hardware to mitigate any future issues?","Hi Matthew,The issue encountered by the underlying hardware for PROD-SPHQ-DB-SERVER02 as a result this caused the system level check to failThe AWS Team replied that the underlying hardware hosting your instances developed some issues resulting in your instances being impaired. You performed a stop/start operation and your instances were migrated to underlying hardware that is operating as expected.Amazon EC2 performs automated checks on every running EC2 instance to identify hardware and software issues. There are 2 types of status check --1. System Status Checks : This means, if there was a failure with the underlying hardware where the instance is running i.e on AWS side.2. Instance Status Checks: This means, if there is a problem with the instance i.e. within the operating systemAll of these issues can only be resolved and fixed by AWS as they are issues relating to the underlying hardware that the instances reside on which we (users of AWS) have no access to. For resolving this we have performed stop and start to migrate the instance to a new underlying hardware which has resolved the issue.Let us know if you need any further clarification.","Hello SpendHQ-Team,We went ahead a call with AWS Support team and they have confirmed that there was an issue with the underlying hardware of the instance PROD-SPHQ-DB-SERVER02 which lead to this outage. Currently, we are analyzing the mount points and will check whether they were impacted during this outage and will get back to you with further updates on it.Please let us know if you have any queries regarding this case.","Hello SpendHQ-Team,This is to inform you that we received an alert regarding site down for the URL's https://preview.spendhq.com/login and https://secure.spendhq.com/login. On further analysis, we were able to figure out that the instance and system status check has failed for the instance PROD-SPHQ-DB-SERVER02.We have performed a stop and start an activity on this instance which resolved this case.Now, both the sites are up and running well.We have raised a ticket with AWS regarding this case and will get back to you with further updates as soon as possible.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001EsmBT,Cloud Engineer Level 1,Closed,1069749,Incident,25-07-2017 12:26,,"Hello SpendHQ Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0 on average with the value of 3.032 after that the alert got resolved automatically and return to a normal state with the value of 2.973.","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.032This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3971201902638048947 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,25-07-2017 12:12,0,0,SpendHQ,"Hello SpendHQ Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0 on average with the value of 3.032 after that the alert got resolved automatically and return to a normal state with the value of 2.973.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001jkQ2D,Cloud Engineer Level 1,Closed,1112149,Incident,15-02-2019 03:32,,"Hello Team,We have turned on the server 10.59.100.214. Hence we are marking this case as closed.###I approve. Please mitigate as quickly as possible.Matthew Watts <mwatts@spendhq.com>###Hello Team,Thanks for reaching us. As per your request, we have turned on the server 10.59.100.214.ThanksRevathy Kurup","I approve. Please mitigate as quickly as possible.Get Outlook for iOS<https://aka.ms/o0ukef>________________________________From: Daniel Mackay <dmackay@spendhq.com>Sent: Thursday, February 14, 2019 12:36 pmTo: Rean SupportCc: Matthew Watts; Allen HerreraSubject: Turn on 10.59.100.214REAN,Can you please turn on 10.59.100.214 ASAP. It can turn off tonight as per the usual schedule, we just want to turn it on early today.Best Regards,Dan Mackay | Spend Solutions DBA | SpendHQO: 770-741-0157 | dmackay@spendhq.com<mailto:dmackay@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Turn on 10.59.100.214,,14-02-2019 23:06,8,0,SpendHQ,"Hello Team,We have turned on the server 10.59.100.214. Hence we are marking this case as closed.",I approve. Please mitigate as quickly as possible.Matthew Watts <mwatts@spendhq.com>,"Hello Team,Thanks for reaching us. As per your request, we have turned on the server 10.59.100.214.ThanksRevathy Kurup",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001dclZj,Cloud Engineer Level 1,Closed,1106516,Incident,29-10-2018 06:01,,"Hello <CustomerName/ClientName-Team>,We haven't heard back from you regarding this case.At this time, we're marking this case as closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue. Regards,Rafi RameshPune India###Hello Matthew,This is the gentle reminder.We have created the IAM user creation  kstretch  and automation_service_user with the permissions. We have shared the login credentials in a separate email. Please validate the credentials and please enable MFA from your endPlease let us know if you have any queries related to it.###Hello Matthew, This is a quick follow up. We have done with the IAM user creation  kstretch  and automation_service_user with the permissions that you have mentioned in your request. We have shared the login credentials in a separate email. Please validate the credentials and please enable MFA from your end. And please let us know if we are good to close this case.###Hello Matthew, We haven't got any response from your end regarding AWS user creation.As per your request we have created IAM users  kstretch  and  automation_service_user with the permissions that you have mentioned in your request. We have also shared the login credentials with in a separate email with you. While checking we could see that the last activity is none, which means you haven't used these accounts yet. Please login to your account as soon as possible and enable MFA from your end. kindly let us know once you are done with the same. In case of any difficulties, please don't hesitate to contact back to us.We await your reply.###Hello Matthew, This is a gentle reminder. We have already done with the request and shared the credentials with you in a separate email. Please validate the same kindly confirm that whether we are good to close this case. And please let us know if you have any queries regarding the same.###Matthew WattsMon, Oct 22, 12:12 PM (23 hours ago)to ReanWe are working on validation and will advise once this is complete.###Hello Mathew,This is a quick followup regarding your request to create two new users. We have already done with the request and shared the credentials with you in a separate email.Kindly check it from your end and revert back to us if you are facing any issues.###Hello Matthew,We have created the two users and provided the required access as you have requested. Also, shared the credentials and the keys with you in a separate email.email subj: Credentials for AWS permissions email draft emailPlease find the permission details of the two users in the screenshot as an attachment.Kindly check it from your end and revert back to us if you are facing any issues.Thanks & Regards,Thenmozhy D###Hello Matthew,We acknowledge your request, we will work on this and once done will let you know the update.Thanks,","Could we please create these users on AWS. If anything is unclear, let’s setup a call. This needs to locked to outside the PROD VPC so that it does not cause any downtime.Once this is configured please only send me the credentials.Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com> | Schedule a Meeting<http://calendly.com/matthewwatts>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>On 10/19/18, 12:01 PM, Kristen Stretch <kstretch@spendhq.com<mailto:kstretch@spendhq.com>> wrote:The following users and permission sets are needed to complete the setup of the test automation platform in lambda:  1.  Create user ‘kstretch’ with both programmatic and console access. This user needs the following permissions:[cid:image001.png@01D4679F.8F77EF90]The IAM:putRole, Lambda:GetAccountSettings, and cloudformationLimited permissions must be created as new custom policies and attached to the user. The cloudFormationLimited custom policy contains multiple permissions (GetAccountSettings and PutRole are only single permissions of the same name) and is expanded below:CloudFormationLimited policy:[cid:image002.jpg@01D467A3.6FC5EF40]  1.  Create user ‘automation_service_user’ with programmatic access. This user needs the same permission set as the user kstretch, but with an additional custom policy: iam:CreateRole.  *   Once the automation_service_user is generated I will need the access key ID and secret access key.  1.  A role for lambda debugging purposes. You can name this role ‘lambda-selenium’. It will need the following:[cid:image003.jpg@01D467A3.6FC5EF40]Please let me know if you have any questions.-Kristen--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS permissions email draft,,20-10-2018 03:12,219,0,SpendHQ,"Hello <CustomerName/ClientName-Team>,We haven't heard back from you regarding this case.At this time, we're marking this case as closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue. Regards,Rafi RameshPune India","Hello Matthew,This is the gentle reminder.We have created the IAM user creation  kstretch  and automation_service_user with the permissions. We have shared the login credentials in a separate email. Please validate the credentials and please enable MFA from your endPlease let us know if you have any queries related to it.","Hello Matthew, This is a quick follow up. We have done with the IAM user creation  kstretch  and automation_service_user with the permissions that you have mentioned in your request. We have shared the login credentials in a separate email. Please validate the credentials and please enable MFA from your end. And please let us know if we are good to close this case.","Hello Matthew, We haven't got any response from your end regarding AWS user creation.As per your request we have created IAM users  kstretch  and  automation_service_user with the permissions that you have mentioned in your request. We have also shared the login credentials with in a separate email with you. While checking we could see that the last activity is none, which means you haven't used these accounts yet. Please login to your account as soon as possible and enable MFA from your end. kindly let us know once you are done with the same. In case of any difficulties, please don't hesitate to contact back to us.We await your reply.","Hello Matthew, This is a gentle reminder. We have already done with the request and shared the credentials with you in a separate email. Please validate the same kindly confirm that whether we are good to close this case. And please let us know if you have any queries regarding the same.","Matthew WattsMon, Oct 22, 12:12 PM (23 hours ago)to ReanWe are working on validation and will advise once this is complete.","Hello Mathew,This is a quick followup regarding your request to create two new users. We have already done with the request and shared the credentials with you in a separate email.Kindly check it from your end and revert back to us if you are facing any issues.","Hello Matthew,We have created the two users and provided the required access as you have requested. Also, shared the credentials and the keys with you in a separate email.email subj: Credentials for AWS permissions email draft emailPlease find the permission details of the two users in the screenshot as an attachment.Kindly check it from your end and revert back to us if you are facing any issues.Thanks & Regards,Thenmozhy D","Hello Matthew,We acknowledge your request, we will work on this and once done will let you know the update.Thanks,",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EVVNK,Cloud Engineer Level 1,Closed,1068295,Incident,,,,"[Triggered] [SpendHQ] - High Network IN  on host - prod-sphq-db-server05 - 10.59.10.135 - db Status  High Network IN on the instance. Please check the list open TCP Connections    @support@reancloud.comaws.ec2.network_in over host:10.59.10.135,monitoring:on was > 2200000000.0 at all times during the last 5m.Metric value: 2964569600.0This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024210?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2024210/edit · Event URL: https://app.datadoghq.com/event/event?id=3958630057409815659 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network IN on host - prod-sphq-db-server05 - 10.59.10.135 - db Status,,16-07-2017 20:03,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001SVdY1,Cloud Engineer Level 1,Closed,1093338,Incident,14-03-2018 21:44,,"Hello Team,We have stopped the instance. Please check and let us know if you have any concerns.###Hello Team,We will check on this and will let you know the updates.","On Wed, Mar 14, 2018 at 9:16 PM, Andrew Kim <Akim@spendhq.com> wrote:> Please stop the following EC2 instances. Do NOT terminate them at this> time.>>>> Name: PRD-MEMSQL1>> Instance: i-962a78a7>> IP: 10.59.10.148>>>> Name: PRD-MEMSQL1-05-01-2018>> Instance:  i-04cd9730251cc5b7a>> IP: 10.59.10.67>>>> Name: PRD-MEMSQL2>> Instance: i-0dad9606fbf9c84e8>> IP: IP: 10.59.10.140>>>> Name: PRD-MEMSQL3>> Instance: i-0060cd63480895922>> IP: 10.59.10.17>>>> Name: Prod-Capfiles-WebServer>> Instance: i-0479906010b6e3585>> IP: 10.59.101.135>>>> Thank you,>>>> *Andrew Kim* | Director of Information Technology & Security | *Spend*> *HQ®*>> O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com>> *A SaaS Spend Visibility solution from Insight Sourcing Group*>> www.spendhq.com | www.insightsourcing.com>>>-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Stop following EC2 instances,,14-03-2018 21:21,1,0,SpendHQ,"Hello Team,We have stopped the instance. Please check and let us know if you have any concerns.","Hello Team,We will check on this and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Xwe49,Cloud Engineer Level 1,Closed,1100307,Incident,21-06-2018 18:38,,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.###Hello Team, This gentle reminder, Please review the previous comment and let us know if you have any further queries.###Hello Team,This gentle reminder,Please review the previous comment and let us know if you have any further queries.###Hello Team,Could you please review the below analysis we cloud to see the new instances PRD-API-WW1 (i-06733a709434b8c7d ) was registered under Preview-ELB Load Balancer and old instances were de-registered from this ELB by user MWatts around 2018-06-19, 12:36:16 AM IST. Due to this change, the load balancer was unable to route the traffic and result in site down. Later we confirmed that the old instances again register to same ELB by MWatt around 2018-06-19, 01:07:19 AM IST. This resolves the issue and site back to normal. Please find the attached cloud trial for details and let us know if you have any further queries.###Hello SpendHQ-Team,The is to inform you that the site down alert for the URL: https://secure.spendhq.com/login got resolved. The total violation lasted for 20 minutes 59 seconds.On further analyzing, we cloud to see the new instances PRD-API-WW1 (i-06733a709434b8c7d ) was registered under Preview-ELB Load Balancer and old instances were de-registered from this ELB by user MWatts around 2018-06-19, 12:36:16 AM IST.  Due to this change, the load balancer was unable to route the traffic and result in site down. Later we confirmed that the old instances again register to same ELB by MWatt around 2018-06-19, 01:07:19 AM IST. This resolves the issue and site back to normal. Please find the attached cloud trial for details and let us know if you have any further queries.###Latest from Matthew:All is working for me now.###From Matthew Watts:We are having a SEV ONE with the load balancer. Directly the IP’s resolve however secure.spendhq.com is not serving traffic.###Hello Team, This is to inform you that we received a site down alert for URL: https://secure.spendhq.com/loginWe are analyzing this issue and will keep you posted. Kindly let us know if you are performing any activity on your end. Thank you.","Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 404, expected 200Wanted string: All Rights Reserved not found in response.Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Frankfurt DE, California US, London UK, Atlanta-B US-- Hosea B. Getusi,*Cloud Engineer,**REĀN Cloud. *",Detected Error on SpendHQ Secure,,19-06-2018 00:39,66,0,SpendHQ,"Hello Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.","Hello Team, This gentle reminder, Please review the previous comment and let us know if you have any further queries.","Hello Team,This gentle reminder,Please review the previous comment and let us know if you have any further queries.","Hello Team,Could you please review the below analysis we cloud to see the new instances PRD-API-WW1 (i-06733a709434b8c7d ) was registered under Preview-ELB Load Balancer and old instances were de-registered from this ELB by user MWatts around 2018-06-19, 12:36:16 AM IST. Due to this change, the load balancer was unable to route the traffic and result in site down. Later we confirmed that the old instances again register to same ELB by MWatt around 2018-06-19, 01:07:19 AM IST. This resolves the issue and site back to normal. Please find the attached cloud trial for details and let us know if you have any further queries.","Hello SpendHQ-Team,The is to inform you that the site down alert for the URL: https://secure.spendhq.com/login got resolved. The total violation lasted for 20 minutes 59 seconds.On further analyzing, we cloud to see the new instances PRD-API-WW1 (i-06733a709434b8c7d ) was registered under Preview-ELB Load Balancer and old instances were de-registered from this ELB by user MWatts around 2018-06-19, 12:36:16 AM IST.  Due to this change, the load balancer was unable to route the traffic and result in site down. Later we confirmed that the old instances again register to same ELB by MWatt around 2018-06-19, 01:07:19 AM IST. This resolves the issue and site back to normal. Please find the attached cloud trial for details and let us know if you have any further queries.",Latest from Matthew:All is working for me now.,From Matthew Watts:We are having a SEV ONE with the load balancer. Directly the IP’s resolve however secure.spendhq.com is not serving traffic.,"Hello Team, This is to inform you that we received a site down alert for URL: https://secure.spendhq.com/loginWe are analyzing this issue and will keep you posted. Kindly let us know if you are performing any activity on your end. Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001CdmGl,Cloud Engineer Level 1,Closed,1058320,Incident,31-05-2017 22:07,,"Hello Andrew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries###Yes, this server appears to be working now. This ticket can be closed.###Hello Andrew,We have remounted the iscsi devices back on this and verified that it was working fine.Please verify it from your end and let us know if you have any queries.###Hello Andrew,We acknowledge the delivery your mail.We are investigating on this issue and will get back to you with updates.","DB02 (10.59.10.12) has gone into read-only mode, and changes to the database are not being written. [akim@ip-10-59-10-12 data]$ pwd/var/infobright/data[akim@ip-10-59-10-12 data]$ sudo touch aktest.20150531touch: cannot touch `aktest.20150531': Read-only file system[akim@ip-10-59-10-12 data]$",DB02 - Read Only,,31-05-2017 18:36,4,0,SpendHQ,"Hello Andrew,Thanks for your confirmation.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries","Yes, this server appears to be working now. This ticket can be closed.","Hello Andrew,We have remounted the iscsi devices back on this and verified that it was working fine.Please verify it from your end and let us know if you have any queries.","Hello Andrew,We acknowledge the delivery your mail.We are investigating on this issue and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DmJQI,Cloud Engineer Level 1,Closed,1064566,Incident,24-06-2017 02:20,,"Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance was above the threshold value of 90% with a value of 100%. Later the alert got resolved and returned to normal with a value of  89%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume was consuming high volume usage on this instance. Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1     ext4    50G   42G  5.3G  89% /Files under root directory, 12G tmp 15G usr 12G var 510M home 285M lib 282M opt Files under /tmp folder, 12G     total1.8G    liger_view_9e59678f3d319473f4a7ba053b242600.csv1.6G    liger_view_9afa90d9543aaf946ea3ff768a3b88cd.csv590M    liger_view_f562be549d5c02cff02cfaaddf785981.csv513M    liger_view_f47058d94522e5ab35555eb90fdea140.csv513M    liger_view_6a622ed1ed6dc734c9e7a22684cb6664.csv513M    liger_view_467282af40dbe9dbef2d619d1141ae7d.csv449M    liger_view_fca31c82ac2f94e1a93a38746b82c36e.csv449M    liger_view_f57149c9c33e8266e1b1f59b939a5827.csv449M    liger_view_9529ca526803fd4cf952152781f289be.csv449M    liger_view_5962b3cce6ee9f7f40a2e401d09496c0.csv449M    liger_view_54b8fa674525c1f696db9a309fa28272.csv446M    liger_view_a905ecaca51638a5e89e5ccfb9ddd3da.csv394M    liger_view_09edb01c859c06ddecb1cc659a6702ea.csv385M    liger_view_54451efdd16ebf36c7f3494814da20cf.csv360M    liger_view_c0f088626aec54f9e717c38584057213.csv283M    liger_view_f1f0eae3a73193f88af4c2a7f436b44c.csv283M    liger_view_4851e9a2a49e54a3adc2dcbacd64fffc.csv280M    liger_view_302a2cc49e068896aad47ed75dbc7dde.csv262M    liger_view_d7803b83619071bcf4ccea035ecdf216.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 91.486This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3925617757822917991 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,24-06-2017 01:28,5,0,SpendHQ,"Hello SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PROD-SPHQ-DB-SERVER05(10.59.10.135). The volume usage on this instance was above the threshold value of 90% with a value of 100%. Later the alert got resolved and returned to normal with a value of  89%. On further analysis, we were able to figure out that the device /dev/xvda1 mounted on root volume was consuming high volume usage on this instance. Filesystem Type Size Used Avail Use% Mounted on /dev/xvda1     ext4    50G   42G  5.3G  89% /Files under root directory, 12G tmp 15G usr 12G var 510M home 285M lib 282M opt Files under /tmp folder, 12G     total1.8G    liger_view_9e59678f3d319473f4a7ba053b242600.csv1.6G    liger_view_9afa90d9543aaf946ea3ff768a3b88cd.csv590M    liger_view_f562be549d5c02cff02cfaaddf785981.csv513M    liger_view_f47058d94522e5ab35555eb90fdea140.csv513M    liger_view_6a622ed1ed6dc734c9e7a22684cb6664.csv513M    liger_view_467282af40dbe9dbef2d619d1141ae7d.csv449M    liger_view_fca31c82ac2f94e1a93a38746b82c36e.csv449M    liger_view_f57149c9c33e8266e1b1f59b939a5827.csv449M    liger_view_9529ca526803fd4cf952152781f289be.csv449M    liger_view_5962b3cce6ee9f7f40a2e401d09496c0.csv449M    liger_view_54b8fa674525c1f696db9a309fa28272.csv446M    liger_view_a905ecaca51638a5e89e5ccfb9ddd3da.csv394M    liger_view_09edb01c859c06ddecb1cc659a6702ea.csv385M    liger_view_54451efdd16ebf36c7f3494814da20cf.csv360M    liger_view_c0f088626aec54f9e717c38584057213.csv283M    liger_view_f1f0eae3a73193f88af4c2a7f436b44c.csv283M    liger_view_4851e9a2a49e54a3adc2dcbacd64fffc.csv280M    liger_view_302a2cc49e068896aad47ed75dbc7dde.csv262M    liger_view_d7803b83619071bcf4ccea035ecdf216.csvDelete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case. Resource Details:- Instance ID : i-008d43ad00357e47a Instance type : r3.8xlarge Availability zone : us-east-1b Private IPs : 10.59.10.135",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ESUNc,Cloud Engineer Level 1,Closed,1066957,Incident,06-07-2017 21:47,,"Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0. The alert got resolved automatically and return to a normal state with the value of 2.994.###Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 3.041.","[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.041This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3944211135508032599 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,06-07-2017 21:19,0,0,SpendHQ,"Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.0. The alert got resolved automatically and return to a normal state with the value of 2.994.","Hello Team, This is to notify you that we have received an alert that CPU Load for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 3.o on average with the value of 3.041.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Fdf02,Cloud Engineer Level 1,Closed,1073014,Incident,12-08-2017 12:34,,Following up on parent case.,"[Triggered] [SpendHQ] -  High Number of Process Count prod-sphq-web-server03_2nd_august_2017 - 10.59.100.170 - web  This is to inform you that there are a high number of processes running in the instances. Execute ps aux and find out if there are any unwanted processes running in the instance    @support@reancloud.comsystem.processes.number over host:i-0f36027c388e7a563,monitoring:on was > 30.0 on average during the last 5m.Metric value: 34.622This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2024191?group=host%3Ai-0f36027c388e7a563 · Edit Monitor: https://app.datadoghq.com/monitors#2024191/edit · Event URL: https://app.datadoghq.com/event/event?id=3997069314193138333 · View i-0f36027c388e7a563: https://app.datadoghq.com/infrastructure?hostname=i-0f36027c388e7a563-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Number of Process Count prod-sphq-web-server03_2nd_august_2017 - 10.59.100.170 - web,,12-08-2017 08:29,4,0,SpendHQ,Following up on parent case.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VsDIu,Cloud Engineer Level 1,Closed,1098419,Incident,10-05-2018 21:31,,"Hello Andrew,Thanks for the confirmation.At this time we are marking the case as closed.###Andrew Kim9:29 PM (0 minutes ago)to Rean, spendhq-support Please keep the volume vol-07c3f61c50450cb7b for now. Thank you. Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hello Andrew,We have deleted the following volumes which are secondary volumes.vol-0f173184db2c346f2 In use i-0060cd63480895922 Stopped vol-03579327a6271f651 In use i-01efda76a4651350c Stopped vol-04a713af496b5bc40 In use i-0f1acc6b6bcbea409 Stopped vol-d541e646 In use i-adc348a3 Stopped The volume vol-07c3f61c50450cb7b associated with the instance  i-0b54f8b6bce5c3fa8 is the root volume and if we removed it the instance will also be gone. Let us know if you want us to delete this volume or you want to keep it as it is.###Andrew Kim6:27 PM (2 hours ago)to Rean, spendhq-support Please do NOT terminate the EC2 instanced. Approved to delete the EBS volumes.###Hello Team,Please review the following available EBS volumes which are attached to the instances which are in the stopped state.vol-07c3f61c50450cb7b In use i-0b54f8b6bce5c3fa8 Stopped vol-0f173184db2c346f2 In use i-0060cd63480895922 Stopped vol-03579327a6271f651 In use i-01efda76a4651350c Stopped vol-04a713af496b5bc40 In use i-0f1acc6b6bcbea409 Stopped vol-d541e646 In use i-adc348a3 Stopped kindly review this information and let us know if we are good to delete the volumes and please provide an approval to terminate the instances which mentioned above.###Delete the available volumes :vol-05201d2f10c584e33 Available vol-045ec5612a15f3947 Available vol-0a59937b188cf5ceb Available For the volumes attached to the instances, send a mail to customer that do you want us to simply delete the atached volumes or you want us to terminate these stopped instances too. Take the approval and do the action.###We have checked all the volumes to confirm their status and we have found out that three are in the available state while the other five are associated with stopped instances.Volume ID                            Status        Instance ID                     Instance Statevol-05201d2f10c584e33     Availablevol-045ec5612a15f3947     Availablevol-0a59937b188cf5ceb      Availablevol-07c3f61c50450cb7b       In use          i-0b54f8b6bce5c3fa8      Stoppedvol-0f173184db2c346f2       In use          i-0060cd63480895922    Stoppedvol-03579327a6271f651      In use          i-01efda76a4651350c     Stoppedvol-04a713af496b5bc40      In use          i-0f1acc6b6bcbea409      Stoppedvol-d541e646                       In use          i-adc348a3                       StoppedNext action:- To be reviewed by Rohit","Thanks & Regards,Gourav PokhraREĀN Cloud Solutions | Reach, Engage, Activate, Nurture4th Floor, 26, Tulsi Complex,100 Feet Road, New BhupalpuraUdaipur, Rajasthan 313001Gourav.pokhra@reancloud.com |+918696096500| www.reancloud.com<http://www.reancloudsolutions.com/>Toll-Free Number: +12015828406---------- Forwarded message ----------From: Andrew Kim <Akim@spendhq.com>Date: Thu, May 10, 2018 at 3:42 AMSubject: Please delete following EBS volumesTo: spendhq-support@reancloud.com <spendhq-support@reancloud.com>Cc: Matthew Watts <mwatts@spendhq.com>Hello – we’ve reviewed our current EBS volumes and would like the followingvolumes to be deleted.EBS Volume IDSizeEC2 ServerEC2 StatusEC2 IPvol-03579327a6271f6512048 GBPRD-DB-Clone-2018-03-16Stopped10.59.10.89vol-04a713af496b5bc402048 GBPROD-SPHQ-DB-SERVER05-Clone-19th_July_2017Stopped10.59.10.106vol-d541e6462048 GBPROD-SPHQ-DB-SERVER04Stopped10.59.10.91vol-845016511000 GBPROD-SPHQ-DB-SERVER01Stopped10.59.10.137vol-045ec5612a15f3947500 GBNonevol-07c3f61c50450cb7b500 GBClone of PRD-DB_v20171207Stopped10.59.10.86vol-0a59937b188cf5ceb500 GBNonevol-05201d2f10c584e33130 GBNonevol-0f173184db2c346f2500 GBPRD-MEMSQL3Stopped10.59.10.17Thanks,*Andrew Kim* | Director of Information Technology & Security | *Spend**HQ®*O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com--  <http://go.reancloud.com/gartner-magic-quadrant>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Please delete following EBS volumes,,10-05-2018 03:47,18,0,SpendHQ,"Hello Andrew,Thanks for the confirmation.At this time we are marking the case as closed.","Andrew Kim9:29 PM (0 minutes ago)to Rean, spendhq-support Please keep the volume vol-07c3f61c50450cb7b for now. Thank you. Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Hello Andrew,We have deleted the following volumes which are secondary volumes.vol-0f173184db2c346f2 In use i-0060cd63480895922 Stopped vol-03579327a6271f651 In use i-01efda76a4651350c Stopped vol-04a713af496b5bc40 In use i-0f1acc6b6bcbea409 Stopped vol-d541e646 In use i-adc348a3 Stopped The volume vol-07c3f61c50450cb7b associated with the instance  i-0b54f8b6bce5c3fa8 is the root volume and if we removed it the instance will also be gone. Let us know if you want us to delete this volume or you want to keep it as it is.","Andrew Kim6:27 PM (2 hours ago)to Rean, spendhq-support Please do NOT terminate the EC2 instanced. Approved to delete the EBS volumes.","Hello Team,Please review the following available EBS volumes which are attached to the instances which are in the stopped state.vol-07c3f61c50450cb7b In use i-0b54f8b6bce5c3fa8 Stopped vol-0f173184db2c346f2 In use i-0060cd63480895922 Stopped vol-03579327a6271f651 In use i-01efda76a4651350c Stopped vol-04a713af496b5bc40 In use i-0f1acc6b6bcbea409 Stopped vol-d541e646 In use i-adc348a3 Stopped kindly review this information and let us know if we are good to delete the volumes and please provide an approval to terminate the instances which mentioned above.","Delete the available volumes :vol-05201d2f10c584e33 Available vol-045ec5612a15f3947 Available vol-0a59937b188cf5ceb Available For the volumes attached to the instances, send a mail to customer that do you want us to simply delete the atached volumes or you want us to terminate these stopped instances too. Take the approval and do the action.",We have checked all the volumes to confirm their status and we have found out that three are in the available state while the other five are associated with stopped instances.Volume ID                            Status        Instance ID                     Instance Statevol-05201d2f10c584e33     Availablevol-045ec5612a15f3947     Availablevol-0a59937b188cf5ceb      Availablevol-07c3f61c50450cb7b       In use          i-0b54f8b6bce5c3fa8      Stoppedvol-0f173184db2c346f2       In use          i-0060cd63480895922    Stoppedvol-03579327a6271f651      In use          i-01efda76a4651350c     Stoppedvol-04a713af496b5bc40      In use          i-0f1acc6b6bcbea409      Stoppedvol-d541e646                       In use          i-adc348a3                       StoppedNext action:- To be reviewed by Rohit,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VtJUO,Cloud Engineer Level 1,Closed,1098805,Incident,16-05-2018 08:05,,"Hello Allen,Thanks for the update.At this time we are marking this case closed.###Allen Herrera8:00 AM (3 minutes ago)to Rean, spendhq-support Yes its great! Thank you again. You can close this issue###Hello Allen, We haven't heard back from you,We have remounted the volume on the mount /mnt/mapd201803. Please verify it from your end and let us know if you are facing the issue.###Hello Allen,We have remounted the volume on the mount /mnt/mapd201803. Please verify it from your end and let us know if you are facing the issue.###Hi Allen,Please join the call herehttps://reancloud.zoom.us/my/mgse2","---------- Forwarded message ----------From: Allen Herrera <aherrera@spendhq.com>Date: Mon, May 14, 2018 at 9:58 PMSubject: Re: Mount is in read only on a prod machineTo: Rohit Puri <rohit.puri@reancloud.com>Cc: spendhq-support@reancloud.com <spendhq-support@reancloud.com>10.59.10.50 is the server*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com*From: *Allen Herrera <aherrera@spendhq.com>*Date: *Monday, May 14, 2018 at 12:26 PM*To: *Rohit Puri <rohit.puri@reancloud.com>*Cc: *spendhq-support@reancloud.com <spendhq-support@reancloud.com>*Subject: *Re: Mount is in read only on a prod machineThis is a sev-1 we need this fixed in the next 30 minutes. ASAP*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com*From: *Rohit Puri <rohit.puri@reancloud.com>*Date: *Monday, May 14, 2018 at 12:25 PM*To: *Allen Herrera <aherrera@spendhq.com>*Cc: *spendhq-support@reancloud.com <spendhq-support@reancloud.com>*Subject: *Re: Mount is in read only on a prod machineHi Aallen,We will work on this and update.Regards,Rohit PuriOn Mon, May 14, 2018 at 9:52 PM, Allen Herrera <aherrera@spendhq.com> wrote:Andrew & MatthewThe mapd prod server mount at /mnt//mnt/mapd201803 is in read only mode forsome reason.We need rean or someone to reattach the mount ASAPPreferably without restarting the server*Allen Herrera* | Associate Engineer | *Spend**HQ®*C: 360.888.3938 | aherrera@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- -- REĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*rohit.puri*@reancloud.com <sivasankar.nagireddy@reancloud.com> |900-195-2605 | www.reancloud.com <http://www.reancloudsolutions.com/>[image: Image removed by sender.]<https://www.reancloud.com/news/47lining-achieves-aws-machine-learning-competency-status/>-- You received this message because you are subscribed to the Google GroupsSpendhq Support group.To unsubscribe from this group and stop receiving emails from it, send anemail to spendhq-support+unsubscribe@reancloud.com.-- Regards,Jamelunissa MohammedHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081jamelunissa.mohammed@reancloud.com  | www.reancloud.com--  <https://www.reancloud.com/news/47lining-achieves-aws-machine-learning-competency-status/>--  <https://www.reancloud.com/news/47lining-achieves-aws-machine-learning-competency-status/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Mount is in read only on a prod machine,,14-05-2018 22:03,34,0,SpendHQ,"Hello Allen,Thanks for the update.At this time we are marking this case closed.","Allen Herrera8:00 AM (3 minutes ago)to Rean, spendhq-support Yes its great! Thank you again. You can close this issue","Hello Allen, We haven't heard back from you,We have remounted the volume on the mount /mnt/mapd201803. Please verify it from your end and let us know if you are facing the issue.","Hello Allen,We have remounted the volume on the mount /mnt/mapd201803. Please verify it from your end and let us know if you are facing the issue.","Hi Allen,Please join the call herehttps://reancloud.zoom.us/my/mgse2",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001m1cct,Cloud Engineer Level 1,Closed,1113812,Incident,19-03-2019 15:04,,"Hello Team,We have deleted spendhqdb-mysqlaurora-db as per your request and there is no pending action from our end.At this time, we are closing this case.. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Regards###Send a closure mail and close it.###Hello David,As per your request, we have deleted spendhqdb-mysqlaurora-db.Please let us know if you have any issue related to it.Thanks.###Approved Matthew Watts###Hello Davis,Thanks For reaching us. We will work accordingly and let you know the updates son.Thanks and regardsRevathy Kurup###Hello Matthew,Could you provide approval for removing the server spendhqdb-mysqlaurora-db  as requested by David. Thanks and regardsRevathy Kurup","Rean,Please remove/delete the following instance as it is no longer needed and was replaced by another instanceName: spendhqdb-mysqlaurora-dbVPC: SpendHQ-VPC (vpc-76df7212)Availability zone: us-east-1bEngine version:5.6.10aEngine: Mysql 5.6Instance class: db.t3.mediumMaster username: spendhqdbadminRDS End Point: spendhqdb-mysqlaurora-db.cnq3fody8qqu.us-east-1.rds.amazonaws.comMatthew: we replaced this with maraidb late last week.Thank YouDavidDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/> | Schedule a Meeting<https://calendly.com/dmillershq>-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Instance Deletion,,18-03-2019 19:06,20,0,SpendHQ,"Hello Team,We have deleted spendhqdb-mysqlaurora-db as per your request and there is no pending action from our end.At this time, we are closing this case.. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Regards",Send a closure mail and close it.,"Hello David,As per your request, we have deleted spendhqdb-mysqlaurora-db.Please let us know if you have any issue related to it.Thanks.",Approved Matthew Watts,"Hello Davis,Thanks For reaching us. We will work accordingly and let you know the updates son.Thanks and regardsRevathy Kurup","Hello Matthew,Could you provide approval for removing the server spendhqdb-mysqlaurora-db  as requested by David. Thanks and regardsRevathy Kurup",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKgA,Cloud Engineer Level 1,Closed,1042230,Incident,,,,"Chris, can you let us know when this has been completed?Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]Sent: Friday, January 13, 2017 9:37 PMTo: Matthew Watts <mwatts@spendhq.com>Cc: REAN Support <support@reancloud.com>Subject: Re: MaintenanceHello Matthew,As mentioned earlier, Andromeda team is going to clone the volume before we proceed with the patching of the instance.Please let us know if that is done so that we can proceed with the security patching.On Sat, Jan 14, 2017 at 8:00 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Please update the 10.59.10.12 machine first and advise when complete.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com<mailto:mrigank.saxena@reancloud.com>]Sent: Friday, January 13, 2017 9:24 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,We are ready for the maintenance. Please let us know once you start making the changes.On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Rean Team are you ready to commence the updates as planned on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[http://reancloud.com/aws-ny-summit/top-1.jpg][https://www.reancloud.com/wp-content/uploads/2016/12/Financial-Services_Prem-Consulting-Partner_300x150_1.png]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[http://reancloud.com/aws-ny-summit/top-1.jpg][https://www.reancloud.com/wp-content/uploads/2016/12/Financial-Services_Prem-Consulting-Partner_300x150_1.png]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Maintenance,,14-01-2017 08:07,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ZhPWw,Cloud Engineer Level 1,Closed,1102168,Incident,01-08-2018 00:23,,"Rohit updated we should close the ticket after increasing the limit.###Sent via email:Hello Andrew,We have requested for a service limit increase for SES daily sending quota from AWS. Thanks.###From Andrew,We are currently using us-west-2 for dev testing and this is not critical. In the meantime, can we increase the threshold?Thank you,###Sent email to client.subj. AWS RESOURCE LIMIT USAGE SERVICE###Hello Team,This is to inform you that we have received an AWS limit checker ALERT for SES us-west-2 region. The Daily sending quota limit exceeded the threshold value of 200 to the 372. Please find details and attached the screenshot for reference. Sending Quota: send 200 emails per 24 hour period Quota Used:	100% as of 2018-07-31 15:22 UTC+5:30 Max Send Rate: 1 email/second Last updated:	2018-07-31 15:22 UTC+5:30 Please let us know where actually this SES being used and let us know if you want us to increase the limit###@Team:We are not sure where SpendHQ Team is using the SES service in Oregon region. For this I have enabled SNS for forwarding any bouce or complaint details to my email id for now. In meanwhile, please drop a mail to customer asking for if they want us to increase the limit and where they are using the SES Service as this is been configured in us-west -2 region.###Hello Team,This is to inform you that we have received an AWS limit checker ALERT for SES  us-west-2  region.  The Daily sending quota limit exceeded the threshold value of 200 to the 372. Please find details and attached the screenshot for reference. Sending Quota:  send 200 emails per 24 hour periodQuota Used:	   100% as of 2018-07-31 15:22 UTC+5:30Max Send Rate:  1 email/secondLast updated:	     2018-07-31 15:22 UTC+5:30Kindly validate the details and let us know if you want us to increase the limit","Subject: REAN CLOUD AWS limit checker ALERT for spendhq - WARNINGTo: ms@reancloud.comBelow are resource details that cross limitsREGION       RESOURCE   LIMIT          USAGE          SERVICEus-west-2       SES               200             372             Dailysending quota--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-west-2.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-west-2:210278571640:AWS-Limit:1217fddf-d8e0-4042-af10-1de467aaca07&Endpoint=ms@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",REAN CLOUD AWS limit checker ALERT for spendhq - WARNING,,31-07-2018 15:07,9,0,SpendHQ,Rohit updated we should close the ticket after increasing the limit.,"Sent via email:Hello Andrew,We have requested for a service limit increase for SES daily sending quota from AWS. Thanks.","From Andrew,We are currently using us-west-2 for dev testing and this is not critical. In the meantime, can we increase the threshold?Thank you,",Sent email to client.subj. AWS RESOURCE LIMIT USAGE SERVICE,"Hello Team,This is to inform you that we have received an AWS limit checker ALERT for SES us-west-2 region. The Daily sending quota limit exceeded the threshold value of 200 to the 372. Please find details and attached the screenshot for reference. Sending Quota: send 200 emails per 24 hour period Quota Used:	100% as of 2018-07-31 15:22 UTC+5:30 Max Send Rate: 1 email/second Last updated:	2018-07-31 15:22 UTC+5:30 Please let us know where actually this SES being used and let us know if you want us to increase the limit","@Team:We are not sure where SpendHQ Team is using the SES service in Oregon region. For this I have enabled SNS for forwarding any bouce or complaint details to my email id for now. In meanwhile, please drop a mail to customer asking for if they want us to increase the limit and where they are using the SES Service as this is been configured in us-west -2 region.","Hello Team,This is to inform you that we have received an AWS limit checker ALERT for SES  us-west-2  region.  The Daily sending quota limit exceeded the threshold value of 200 to the 372. Please find details and attached the screenshot for reference. Sending Quota:  send 200 emails per 24 hour periodQuota Used:	   100% as of 2018-07-31 15:22 UTC+5:30Max Send Rate:  1 email/secondLast updated:	     2018-07-31 15:22 UTC+5:30Kindly validate the details and let us know if you want us to increase the limit",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016A0yb,Cloud Engineer Level 1,Closed,1041864,Incident,17-01-2017 05:44,,"Hello SpendHQ-Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Sumod.K.Bose###Hello Team,This is a gentle reminder since we haven't heard back from you regarding this case.We have already changed the ISCSI initiator name for PROD-SPHQ-DB-SERVER03 and TEST-SPHQ-WEB-SERVER01.We are attaching a document which shows the ISCSI initiator name for all the SpendHQ servers.Please note that now all the instance have different ISCSI initiator name.Please let us know if you have any more queries regarding this.###Hello Andrew, We have changed the iscsi initiator name for PROD-SPHQ-DB-SERVER03 and TEST-SPHQ-WEB-SERVER01. We have restarted the iscsi service on this server after changing the initiator name. We have also verified from /var/log/messages that there are no more error messages now. Please let us know if you have any more queries regarding this###Hello Andrew,We are proceeding with changing the iscsi initiator name for PROD-SPHQ-DB-SERVER03 and TEST-SPHQ-WEB-SERVER01. We will update the progress shortly.###Andrew has confirmed to perform the changes for all the remaining servers.###Andrew replied that  Hi Safuvan, Can we schedule for tonight at 9pm eastern? Thank you,###Hi Andrew,Thanks for the confirmation.We can schedule the maintenance tonight at 9PM eastern and let you know once it is done.###Hi Steven,Thanks for your confirmation.We can close this for now. For March update, we can create a new change case later. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! Please feel free to ask in case of any queries. Thanks,Safuvan KM###I am not comfortable in modifying the last 2 servers just yet. Lets hold of on this until the next maintenance period (early March).Would you prefer to close this issue but open a new case for the March update? Or we can leave this pending?###Hi Steven,We have changed the IQN name for PROD-SPHQ-WEB-SERVER03. Please confirm the same and let us know if we can proceed with remaining two servers. If needed, please provide a maintenance window for the same so that we could close this case. We are waiting for your response.Thanks,Safuvan KM###Hello Steve, We have changed the iscsi initiator name of the server PROD-SPHQ-WEB-SERVER03(10.59.100.94) to InitiatorName=iqn.1994-05.com.redhat:201701110094. We have verified from /var/log/messages that no error logs are present as of now.Also, we have restarted the iscsi service on this server after changing the initiator name. Please check and confirm from your end whether your team has any further queries regarding this issue.###Hello Steven, Thanks for the update.We will change the initiator name for PROD-SPHQ-WEB-SERVER03 at 1 AM EST tomorrow and we will notify you before performing the change. Please let us know if you have any queries regarding this.###Please make the change to PROD-SPHQ-WEB-SERVER03The last 2 servers we'll correct at a later, planned maintenance date.###Hello Steven,We have changed the ISCSI initiator name of the server PROD-SPHQ-WEB-SERVER04(10.59.100.104)  and also verified from  /var/log/messages that no error logs are present as of now. Please verify it from your end and also let us know if your team has any further queries regarding this.Also, please let us know whether we can move forward to perform the changes on PROD-SPHQ-WEB-SERVER02, PROD-SPHQ-WEB-SERVER03 and TEST-SPHQ-WEB-SERVER01.###Hello Steve,We have changed the iscsi initiator name of the server PROD-SPHQ-WEB-SERVER04(10.59.100.104) to  InitiatorName=iqn.1994-05.com.redhat:201701100104.We have verified from /var/log/messages that no error logs are present as of now.Also, we have restarted the iscsi service on this server after changing the initiator name.Please check and confirm from your end whether your team has any further queries regarding this issue.###Hello Steven,As per your request, we are going to change in iscsi initiator name of the server PROD-SPHQ-WEB-SERVER04(10.59.100.104).Current iscsi initiator name on this server is InitiatorName=iqn.1994-05.com.redhat:a7565668c72a. We are going to change the iscsi initiator name based on our new naming procedure which was described in the document.The new iscsi initator will be InitiatorName=iqn.1994-05.com.redhat:201701100104.###Hello Steven,We will perform the change at 1 AM EST tomorrow and we will notify you before performing the change.Please let us know if you have any queries regarding this.###Hi Steven,Thanks for the update.As mentioned we will perform the change for PROD-SPHQ-WEB-SERVER04 and will do it in non-core business hours.We will notify you before performing the action.###I have reviewed the document and would like to proceed on with this additional process going forward in the future.As for the current machines, I would like to correct the initiator name first for PROD-SPHQ-WEB-SERVER04	10.59.100.104Do so during non-core business hours to minimize downtime risks. Make sure this does not affectPROD-SPHQ-WEB-SERVER02	10.59.100.118PROD-SPHQ-DB-SERVER02	        10.59.10.12###Steven updated that he will check this on Monday.###Hello Steven,Thanks for the update. Please let us know once you have validated the document.###Hello Steven, This is a gentle reminder since we haven't heard back from you regarding this issue. Kindly validate the document and let us know if your team have any further queries. Also, please let us know whether we can move forward and change the existing identical iscsi initiator names.###Hello Steven, This is a gentle reminder since we haven't heard back from you regarding this issue. Kindly validate the document and let us know if your team have any further queries. Also, let us know whether we can move forward and change the existing identical iscsi initiator names.###Hello Steven,We have created a document which contains the details of this incident and have come up with a new naming procedure that can be followed while creating new initiators.Please refer the below attached document for more details, also we have updated our knowledgebase based on the attached document and will follow the mentioned naming procedure from now onwards for new instances.Kindly validate the document and let us know if your team have any further queries. Also, let us know whether we can move forward and change the existing identical iscsi initiator names.###Hi Steven,Yes, this happens as they are launched from same AMIs. We will document the naming procedure that can be followed while creating new initiators.###This occurred because they are replicas of the same machine? If so please document this incident so that whenever a new clone is spooled up we change the initiator to a uid for each instance.I will talk with my team about this tomorrow to see if it is safe to rename each instance so that they have an uid.###Hello Steven,On further analysis, we found that PROD-SPHQ-WEB-SERVER02, PROD-SPHQ-WEB-SERVER03, PROD-SPHQ-WEB-SERVER04, TEST-SPHQ-WEB-SERVER01 servers having the same initiator name 'InitiatorName=iqn.1994-05.com.redhat:a7565668c72a'.To resolve this we need to modify the iSCSI initiator names so that each host has a unique initiator namesPlease review the attached sheet and let us know if you have any queries.###Hello Steven,We have analyzed the /var/log/messages on 10.59.100.118 which was showing the below error log files,Jan  5 15:32:41 ip-10-59-10-91 iscsid: Kernel reported iSCSI connection 2:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3).We suspect that these errors occur because multiple hosts are using the same iSCSI initiator names.Currently, we are analyzing the iscsi initiator name's on the servers and will get back to you with our findings.###Hello Steven,We acknowledge the delivery of your email.We will look on this issue and will get back with the updates.","REAN team, can someone look into the reason why in /var/log/messages on the 10.59.10.118 (SHQ WEB 02) there is a constant message of TCP connection being closed then recovered. See attached image. Thanks.",iSCSI connection constant recovery,,05-01-2017 20:44,273,0,SpendHQ,"Hello SpendHQ-Team,We haven't heard back from you regarding this case.At this time, we're marking this case as Resolved. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Best Regards,Sumod.K.Bose","Hello Team,This is a gentle reminder since we haven't heard back from you regarding this case.We have already changed the ISCSI initiator name for PROD-SPHQ-DB-SERVER03 and TEST-SPHQ-WEB-SERVER01.We are attaching a document which shows the ISCSI initiator name for all the SpendHQ servers.Please note that now all the instance have different ISCSI initiator name.Please let us know if you have any more queries regarding this.","Hello Andrew, We have changed the iscsi initiator name for PROD-SPHQ-DB-SERVER03 and TEST-SPHQ-WEB-SERVER01. We have restarted the iscsi service on this server after changing the initiator name. We have also verified from /var/log/messages that there are no more error messages now. Please let us know if you have any more queries regarding this","Hello Andrew,We are proceeding with changing the iscsi initiator name for PROD-SPHQ-DB-SERVER03 and TEST-SPHQ-WEB-SERVER01. We will update the progress shortly.",Andrew has confirmed to perform the changes for all the remaining servers.,"Andrew replied that  Hi Safuvan, Can we schedule for tonight at 9pm eastern? Thank you,","Hi Andrew,Thanks for the confirmation.We can schedule the maintenance tonight at 9PM eastern and let you know once it is done.","Hi Steven,Thanks for your confirmation.We can close this for now. For March update, we can create a new change case later. At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! Please feel free to ask in case of any queries. Thanks,Safuvan KM",I am not comfortable in modifying the last 2 servers just yet. Lets hold of on this until the next maintenance period (early March).Would you prefer to close this issue but open a new case for the March update? Or we can leave this pending?,"Hi Steven,We have changed the IQN name for PROD-SPHQ-WEB-SERVER03. Please confirm the same and let us know if we can proceed with remaining two servers. If needed, please provide a maintenance window for the same so that we could close this case. We are waiting for your response.Thanks,Safuvan KM","Hello Steve, We have changed the iscsi initiator name of the server PROD-SPHQ-WEB-SERVER03(10.59.100.94) to InitiatorName=iqn.1994-05.com.redhat:201701110094. We have verified from /var/log/messages that no error logs are present as of now.Also, we have restarted the iscsi service on this server after changing the initiator name. Please check and confirm from your end whether your team has any further queries regarding this issue.","Hello Steven, Thanks for the update.We will change the initiator name for PROD-SPHQ-WEB-SERVER03 at 1 AM EST tomorrow and we will notify you before performing the change. Please let us know if you have any queries regarding this.","Please make the change to PROD-SPHQ-WEB-SERVER03The last 2 servers we'll correct at a later, planned maintenance date.","Hello Steven,We have changed the ISCSI initiator name of the server PROD-SPHQ-WEB-SERVER04(10.59.100.104)  and also verified from  /var/log/messages that no error logs are present as of now. Please verify it from your end and also let us know if your team has any further queries regarding this.Also, please let us know whether we can move forward to perform the changes on PROD-SPHQ-WEB-SERVER02, PROD-SPHQ-WEB-SERVER03 and TEST-SPHQ-WEB-SERVER01.","Hello Steve,We have changed the iscsi initiator name of the server PROD-SPHQ-WEB-SERVER04(10.59.100.104) to  InitiatorName=iqn.1994-05.com.redhat:201701100104.We have verified from /var/log/messages that no error logs are present as of now.Also, we have restarted the iscsi service on this server after changing the initiator name.Please check and confirm from your end whether your team has any further queries regarding this issue.","Hello Steven,As per your request, we are going to change in iscsi initiator name of the server PROD-SPHQ-WEB-SERVER04(10.59.100.104).Current iscsi initiator name on this server is InitiatorName=iqn.1994-05.com.redhat:a7565668c72a. We are going to change the iscsi initiator name based on our new naming procedure which was described in the document.The new iscsi initator will be InitiatorName=iqn.1994-05.com.redhat:201701100104.","Hello Steven,We will perform the change at 1 AM EST tomorrow and we will notify you before performing the change.Please let us know if you have any queries regarding this.","Hi Steven,Thanks for the update.As mentioned we will perform the change for PROD-SPHQ-WEB-SERVER04 and will do it in non-core business hours.We will notify you before performing the action.","I have reviewed the document and would like to proceed on with this additional process going forward in the future.As for the current machines, I would like to correct the initiator name first for PROD-SPHQ-WEB-SERVER04	10.59.100.104Do so during non-core business hours to minimize downtime risks. Make sure this does not affectPROD-SPHQ-WEB-SERVER02	10.59.100.118PROD-SPHQ-DB-SERVER02	        10.59.10.12",Steven updated that he will check this on Monday.,"Hello Steven,Thanks for the update. Please let us know once you have validated the document.","Hello Steven, This is a gentle reminder since we haven't heard back from you regarding this issue. Kindly validate the document and let us know if your team have any further queries. Also, please let us know whether we can move forward and change the existing identical iscsi initiator names.","Hello Steven, This is a gentle reminder since we haven't heard back from you regarding this issue. Kindly validate the document and let us know if your team have any further queries. Also, let us know whether we can move forward and change the existing identical iscsi initiator names.","Hello Steven,We have created a document which contains the details of this incident and have come up with a new naming procedure that can be followed while creating new initiators.Please refer the below attached document for more details, also we have updated our knowledgebase based on the attached document and will follow the mentioned naming procedure from now onwards for new instances.Kindly validate the document and let us know if your team have any further queries. Also, let us know whether we can move forward and change the existing identical iscsi initiator names.","Hi Steven,Yes, this happens as they are launched from same AMIs. We will document the naming procedure that can be followed while creating new initiators.",This occurred because they are replicas of the same machine? If so please document this incident so that whenever a new clone is spooled up we change the initiator to a uid for each instance.I will talk with my team about this tomorrow to see if it is safe to rename each instance so that they have an uid.,"Hello Steven,On further analysis, we found that PROD-SPHQ-WEB-SERVER02, PROD-SPHQ-WEB-SERVER03, PROD-SPHQ-WEB-SERVER04, TEST-SPHQ-WEB-SERVER01 servers having the same initiator name 'InitiatorName=iqn.1994-05.com.redhat:a7565668c72a'.To resolve this we need to modify the iSCSI initiator names so that each host has a unique initiator namesPlease review the attached sheet and let us know if you have any queries.","Hello Steven,We have analyzed the /var/log/messages on 10.59.100.118 which was showing the below error log files,Jan  5 15:32:41 ip-10-59-10-91 iscsid: Kernel reported iSCSI connection 2:0 error (1020 - ISCSI_ERR_TCP_CONN_CLOSE: TCP connection closed) state (3).We suspect that these errors occur because multiple hosts are using the same iSCSI initiator names.Currently, we are analyzing the iscsi initiator name's on the servers and will get back to you with our findings.","Hello Steven,We acknowledge the delivery of your email.We will look on this issue and will get back with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000016oKtn,Cloud Engineer Level 1,Closed,1042238,Incident,,,,"Perfect. Thanks.There is no need to create a clone at this time.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Friday, January 13, 2017 10:12 PMTo: Matthew Watts <mwatts@spendhq.com>; Mrigank Saxena <mrigank.saxena@reancloud.com>Cc: REAN Support <support@reancloud.com>Subject: Re: Maintenanceok, done -      volume Spend4 has had a snapshot takenDo you want to turn it into  a clone?Chris VeilletteCTO[1450833261212_7186d8e7bdbb48853119db07d964f770.jpg]www.Andromeda3.com<http://www.Andromeda3.com>cveillette@andromeda3.com<mailto:cveillette@andromeda3.com>Mobile: 703.447.4124Office:   571.781.0428________________________________From: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Sent: Friday, January 13, 2017 10:08 PMTo: Chris Veillette; Mrigank SaxenaCc: REAN SupportSubject: RE: MaintenanceCan you image the Production Machine – Spend4. We just want to create a clone.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Chris Veillette [mailto:cveillette@Andromeda3.com]Sent: Friday, January 13, 2017 10:06 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>; Mrigank Saxena <mrigank.saxena@reancloud.com<mailto:mrigank.saxena@reancloud.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHI Matt -Sorry - didn't know which vol to image - and if you want to clone it ...Can you let me know - I am standing byChris VeilletteCTO[1450833261212_7186d8e7bdbb48853119db07d964f770.jpg]www.Andromeda3.com<http://www.Andromeda3.com>cveillette@andromeda3.com<mailto:cveillette@andromeda3.com>Mobile: 703.447.4124Office:   571.781.0428________________________________From: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Sent: Friday, January 13, 2017 9:52 PMTo: Mrigank Saxena; Chris VeilletteCc: REAN SupportSubject: RE: MaintenanceChris,Did you manage to image the machine?Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com]Sent: Friday, January 13, 2017 9:37 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,As mentioned earlier, Andromeda team is going to clone the volume before we proceed with the patching of the instance.Please let us know if that is done so that we can proceed with the security patching.On Sat, Jan 14, 2017 at 8:00 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Please update the 10.59.10.12 machine first and advise when complete.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Mrigank Saxena [mailto:mrigank.saxena@reancloud.com<mailto:mrigank.saxena@reancloud.com>]Sent: Friday, January 13, 2017 9:24 PMTo: Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>>Cc: REAN Support <support@reancloud.com<mailto:support@reancloud.com>>Subject: Re: MaintenanceHello Matthew,We are ready for the maintenance. Please let us know once you start making the changes.On Sat, Jan 14, 2017 at 7:46 AM, Matthew Watts <mwatts@spendhq.com<mailto:mwatts@spendhq.com>> wrote:Rean Team are you ready to commence the updates as planned on the 10.59.10.12 machine and the SSL certificate on .118 and the ELB/Sophos.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>--Mrigank SaxenaREĀN Cloud Solutions | Reach, Engage, Activate, Nurture2201 Cooperative Way #250, Herndon, VA 20171Cloud Consulting | Secure Managed Services | AWS VAR[Image removed by sender.][Image removed by sender.]<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud Achieves AWS Financial Services Competency<https://www.reancloud.com/news/rean-cloud-among-first-achieve-aws-financial-services-competency-status-amazon-web-services/>  *   REAN Cloud is Premier Consulting Partner 2017<https://www.reancloud.com/news/rean-cloud-retains-premier-designation-aws-partner-network-apn-2017/>  *   REAN Cloud receives 8 AWS Service Designations<https://www.reancloud.com/news/rean-cloud-achieves-aws-service-delivery-partner-status-8-aws-services/>  *   Accelerate the Application Life Cycle with REAN DevOpsNow<https://www.reancloud.com/devopsnow/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: Maintenance,,14-01-2017 08:45,1,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BZxhd,Cloud Engineer Level 1,Closed,1052079,Incident,09-05-2017 18:29,,"Hello SpendHQ Team,While analyzing the recent incidents, we were able to see multiple intrusion prevention incidents and the analysis report seems like someone is trying to expose the APACHE STRUT vulnerability that reported recently.I verified from the instance level that we are not using the JAVA module Struts in our application and this incident will not affect our application but, as a prevention step, we have blocked the IPs 155.133.82.12, 67.160.232.236 and 174.47.83.157 in the NACL level as the behaviour of the requests seems like someone is trying to check the possibility of making an impact in the application by checking the strut module status.This can also happen if you are running any vulnerability test from your end. Please revert back to us if you are performing any vulnerability test causing this.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM###Hello Team,This is to notify you that we have received multiple alerts regarding Intrusion Prevention Alert. The source IP is 10.59.1.167 and which is belongs to Preview ELB.On further analyzing the ELB logs at the time of alert we could see the IP 155.133.82.12 having 504 response code.IP trace details:IP: 155.133.82.12Location: PolandOrganization: ORG-FSAG1-RIPEPlease let us know if this IP is valid or whether you want to block this.###Hello Team,This is to notify you that we got an alert regarding intrusion prevention alert. The source IP is 10.59.1.101 and which is belongs to the secure ELB.On further analyzing the ELB logs at the time of the alert we could see the IP's 67.160.232.236 and 174.47.83.157 having 403 response code.The IP 67.160.232.236 is from Unites states and organization is Comcast Cable Communications LLC. The IP 174.47.83.157 is from United states and TW Telecom Holdings Inc.Let us know if this IP's are valid and whether you want us to block this.###Hello SpendHQ-Team,This is to inform you that we have again received an intrusion prevention alert. The source IP is 10.59.5.94 and which is belongs to the secure ELB. On further analyzing the ELB logs at the time of the alert 2017-05-08 22:35:42 UTC, We are able to find the IP 163.172.68.183  which belongs to an ONLINE SAS located in France is trying to execute Apache Struts remote code. As per https://www.abuseipdb.com, this IP address has been reported a total of 107 times for web app attack and port scan. We have blocked the IP address at NACL level.Please let us know if you have any queries regarding this.###Hi Team,This is to inform you that we got Intrusion Prevention Alert again regarding malware detected. We have analyzed the logs and found the below IP details.The request came from 2 IP's one is 91.236.75.4 which is from Poland and Organization is Przedsiebiorstwo Uslug Specjalistycznych ELAN mgr inz. Andrzej Niechcial. The other IP is 91.196.50.33 from Poland and Organization is Euronet S.C. Jacek Majak Aleksandra Kuc. Both the request were having 403 response code.Please let us know if this IP's are valid and whether you want us to block in NACL.###Hi Team,On further analysis of the alert, we found the below details.From the alert description, we could see that it is related to SERVER-APACHE Apache Struts remote code execution attempt. On checking, we found that there is a vulnerability CVE-2017-5638which allows a remote attacker to inject operating system commands into a web application through the “Content-Type” header. As a recommendation If you are using Apache struct 2 frameworks, we suggest to upgrade your Apache Struts version as soon as possible.The vulnerable versions of Apache Struts are:Struts 2.3.5 - Struts 2.3.31Struts 2.5 - Struts 2.5.10Upgrading to the following versions resolves the vulnerability:Struts 2.3.32Struts 2.5.10.1Please let us know if you have any further queries.###Hi SpendHQ Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address 10.59.1.167 belongs to the prievew ELB. On further analysis of the ELB logs we found that IP 87.118.90.90 with 504 response. The requested client IP address 87.118.90.90  is from Germany and organization is Keyweb AG.We have blocked the IP in NACL. Please verify the IP and let us know if it is a valid one.Let us know if you have any queries.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41819Time...........: 2017-05-07 04:58:01Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.167Source port: 31233,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,07-05-2017 10:51,56,0,SpendHQ,"Hello SpendHQ Team,While analyzing the recent incidents, we were able to see multiple intrusion prevention incidents and the analysis report seems like someone is trying to expose the APACHE STRUT vulnerability that reported recently.I verified from the instance level that we are not using the JAVA module Struts in our application and this incident will not affect our application but, as a prevention step, we have blocked the IPs 155.133.82.12, 67.160.232.236 and 174.47.83.157 in the NACL level as the behaviour of the requests seems like someone is trying to check the possibility of making an impact in the application by checking the strut module status.This can also happen if you are running any vulnerability test from your end. Please revert back to us if you are performing any vulnerability test causing this.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Safuvan KM","Hello Team,This is to notify you that we have received multiple alerts regarding Intrusion Prevention Alert. The source IP is 10.59.1.167 and which is belongs to Preview ELB.On further analyzing the ELB logs at the time of alert we could see the IP 155.133.82.12 having 504 response code.IP trace details:IP: 155.133.82.12Location: PolandOrganization: ORG-FSAG1-RIPEPlease let us know if this IP is valid or whether you want to block this.","Hello Team,This is to notify you that we got an alert regarding intrusion prevention alert. The source IP is 10.59.1.101 and which is belongs to the secure ELB.On further analyzing the ELB logs at the time of the alert we could see the IP's 67.160.232.236 and 174.47.83.157 having 403 response code.The IP 67.160.232.236 is from Unites states and organization is Comcast Cable Communications LLC. The IP 174.47.83.157 is from United states and TW Telecom Holdings Inc.Let us know if this IP's are valid and whether you want us to block this.","Hello SpendHQ-Team,This is to inform you that we have again received an intrusion prevention alert. The source IP is 10.59.5.94 and which is belongs to the secure ELB. On further analyzing the ELB logs at the time of the alert 2017-05-08 22:35:42 UTC, We are able to find the IP 163.172.68.183  which belongs to an ONLINE SAS located in France is trying to execute Apache Struts remote code. As per https://www.abuseipdb.com, this IP address has been reported a total of 107 times for web app attack and port scan. We have blocked the IP address at NACL level.Please let us know if you have any queries regarding this.","Hi Team,This is to inform you that we got Intrusion Prevention Alert again regarding malware detected. We have analyzed the logs and found the below IP details.The request came from 2 IP's one is 91.236.75.4 which is from Poland and Organization is Przedsiebiorstwo Uslug Specjalistycznych ELAN mgr inz. Andrzej Niechcial. The other IP is 91.196.50.33 from Poland and Organization is Euronet S.C. Jacek Majak Aleksandra Kuc. Both the request were having 403 response code.Please let us know if this IP's are valid and whether you want us to block in NACL.","Hi Team,On further analysis of the alert, we found the below details.From the alert description, we could see that it is related to SERVER-APACHE Apache Struts remote code execution attempt. On checking, we found that there is a vulnerability CVE-2017-5638which allows a remote attacker to inject operating system commands into a web application through the “Content-Type” header. As a recommendation If you are using Apache struct 2 frameworks, we suggest to upgrade your Apache Struts version as soon as possible.The vulnerable versions of Apache Struts are:Struts 2.3.5 - Struts 2.3.31Struts 2.5 - Struts 2.5.10Upgrading to the following versions resolves the vulnerability:Struts 2.3.32Struts 2.5.10.1Please let us know if you have any further queries.","Hi SpendHQ Team, We have received an Intrusion Prevention Alert from Sophos and the source IP address 10.59.1.167 belongs to the prievew ELB. On further analysis of the ELB logs we found that IP 87.118.90.90 with 504 response. The requested client IP address 87.118.90.90  is from Germany and organization is Keyweb AG.We have blocked the IP in NACL. Please verify the IP and let us know if it is a valid one.Let us know if you have any queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Cf4cB,Cloud Engineer Level 1,Closed,1059289,Incident,06-06-2017 05:11,,"We had a call with spendhq and Andromeda team. During the call, we have deleted some of the volumes. Andromeda team will provide new volumes and we need to mount it on servers.###Hi Andrew,I spent time today looking at the Nimble utilization; for earlier today, we received a request for an additional (2) 2TB volumes.Right now unfortunately  we only have 2.24TB usable that is available.   We have a couple options:Short term: we need to delete some of the volumes on the Nimble.  Please see the attachments I sent out this AM. This really needs to be done regardless.  We have so many volumes it has become hard to track for REAN and A3 what each volume is...permissions, mount points, IP addresses, iSCSI initiator groups, et cetera.Long term:  we could start using the JetStor.  This might take a week or so as we continue testing/configuring to  make ensure it will perform without issues.  Given my testing so far,  I am not anticipating any issues.    Another clear advantage to this approach is,  by starting fresh, REAN and A3 can better track the characteristics of each volume as it is created. Let me know how to proceed.  😊Have a great weekend!ChrisChris VeilletteCTO###Hello Chris/David, Do you have any update on the below request. Regards,-Praveen From: Akhil Baby <akhil.baby@reancloud.com>Reply-To: <akhil.baby@reancloud.com>Date: Friday, June 2, 2017 at 1:03 PMTo: Chris Veillette <cveillette@andromeda3.com>, David McLaughlin <dmclaughlin@andromeda3.com>Cc: Praveen Kumar Muppala <praveen.muppala@reancloud.com>, Fazlu <fazlu.rahman@reancloud.com>, Andrew Kim <Akim@spendhq.com>, Matthew Watts <mwatts@spendhq.com>, REAN Managed Services <ms@reancloud.com>, <rlittle@insightsourcing.com>Subject: Re: iSCSI Disks Review and Cleanup Hi Andromeda Team, We need to create two new empty volumes for the machines 10.59.10.140 and 10.59.10.148. Refer the details below,New 2TB empty volume and associate it to 10.59.10.140New 2TB empty volume and associate it to 10.59.10.148Let us know once the volumes are available so that we can mount these volumes on these machines. Also, share the IQN names of the new volumes. Revert back in case of any queries.Regards,Akhil BREĀN Cloud Solutions | Reach, Engage, Āctivate, Nurture2201 Cooperative Way #250, Herndon, Va 20171akhil.baby@reancloud.com | www.reancloud.com###Working on it.  Email to follow...David McLaughlinAndromeda3703.439.4413###Hello Robert,We have checked it from the existing mount points. We will mount the unmounted ones and will try to figure out from there. Will get back to you with the details once it's done.###Hello Robert,We have cross verified the file Client287*.sql.gz in all machines and below are the findings,PROD-SPHQ-DB-SERVER05 (10.59.10.135) /var/tmp/Client287SpendData_Reporting.sql.gzPROD-SPHQ-DB-SERVER04 (10.59.10.91) /var/tmp/Client287SpendData_Reporting.sql.gzPROD-SPHQ-DB-SERVER03 (10.59.10.148) /var/tmp/Client287SpendData_Reporting.sql.gzPROD-SPHQ-DB-SERVER03 (10.59.10.148) /tmp/Client287SpendData_mv2DB3MemSQL.sql.gzWe have tried to mount the unmounted volumes and searched for the files starting with file Client283*.sql.gz but was not able to figure out any files related to it.###Hey Fazlu, When you say all the machines are you referencing just the ones that are already mounted? Have you mounted the others that were unmounted and searched for it? Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###Thanks for the update. Just for clarity the file I am most concerned with finding is Client283SpendData_fullbackup6012017.sql.gz. Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###Hello Robert,We have checked for the file Client287*.sql.gz in all machines which are mounted already and found the below detailsPROD-SPHQ-DB-SERVER04 (10.59.10.91) /var/tmp/Client287SpendData_Reporting.sql.gzPROD-SPHQ-DB-SERVER03 (10.59.10.148) /var/tmp/Client287SpendData_Reporting.sql.gzPROD-SPHQ-DB-SERVER03 (10.59.10.148) /tmp/Client287SpendData_mv2DB3MemSQL.sql.gzFrom the above details we could see that Client287 is in the DB03 in the /var/tmp location itself. We are now further checking the file Client287*.sql.gz from the unmounted volumes and will get back to you with our findings.###Hello Robert,We have checked for that particular file also in all the machines, but we didn't find any related entries.###Thanks Chris. However, can you please provide the connection details. Regards,-Praveen###Hi Praveen - the connections are a little misleading-  when a snapshot is taken/made, the snapshot takes all the attributes of the master volume- including connections - which is needed  - remember the new clone is really empty - changes are written to the new cline but all the former data is still there ...Chris Veillette###Hey Praveen, For both 1 and 2 mounted directories please mount to /mnt. For number 3, once you identify the Client287*.sql.gz data copying it to 148 would be perfect. If it helps I know there is one file named Client283SpendData_fullbackup6012017.sql.gz. Thanks, Robert Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.com###Hi Andromeda Team,We need to create two new empty volumes for the machines 10.59.10.140 and 10.59.10.148. Refer the details below,New 2TB empty volume and associate it to 10.59.10.140New 2TB empty volume and associate it to 10.59.10.148Let us know once the volumes are available so that we can mount these volumes on these machines. Also, share the IQN names of the new volumes. Revert back in case of any queries.Regards,Akhil BREĀN Cloud Solutions | Reach, Engage, Āctivate, Nurture2201 Cooperative Way #250, Herndon, Va 20171 akhil.baby@reancloud.com | www.reancloud.com###Unfortunately I can not see any data or structure- a great security feature - but no help for you.  All I see is volume names. 😞Chris Veillette###Hello Rob, Let me digest this request well. New 2TB empty volume and associate it to 10.59.10.140. Let us know on what directory you want to mount it?New 2TB empty volume and associate it to 10.59.10.148. Let us know on what directory you want to mount it?Identify the Client287*.sql.gz in any of the existing mounts, if we find it you want us to copy it to 148 machine? Based on your response, I will ask my team to work on these requests. Regards,-Praveen###Hello Chris, The report looks good. Is there anyway, we can identify the connections details as per the first screenshot. The connection is from which IP address. I am curious why certain disks has 2 connections. Ideally each disk should only have one 1 connection. Regards,-Praveen###REAN, Sorry too keep pestering you guys. It turns out I need another volume mounted as well. To summarize we need 1 2tb drive mounted on 10.59.10.140, 1 2tb drive mounted on 10.59.10.148. And do identify which mount had the files named something like Client287<something>.sql.gz that would be in /dev/shm.  Thanks, Robert Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###REAN, Have you been creating a mapping database for all these volumes as this would greatly help. Regards,Matthew Watts###I am not sure which one based on those names. I can say that the one I need has a bunch of backups in it that we need named something like Client287<something>.sql.gz that would be in /dev/shm/.  Can you see the contents of the volumes at all? In the meantime, I am trying to set up a memsql cluster and to keep things moving can we get a 2 tb drive mounted on that box? Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###Hello Chris/David, Can you please help us to associate the unused/unmounted scsi disks to 10.59.10.148 machine. So that, we will mount each one and try it out.Regards,-Praveen###Hey Team, Would it be possible for you to mount all drives somewhere so I can take a look and see if I can identify the correct one?  Thanks, Robert Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.com###Hi -I have enclosed three screen shots - two show the volumes that are on the Nimble - - there are so many I had to create two screenshots - and another that shows the current iSCSI connections and which IQN they are pointed to or associated with.I can't help associate the volumes since all I have is the Nimble volume name to present - I don't know what they are called once they are mapped.Chris VeilletteCTO###Hello Andrew,We will work on creating the excel sheet with details and let you know the updates.###Can we get a list of all of the iSCSI disks and which servers they’re attached to? Preferably in excel format. Thanks, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hi All - I agree with Praveen - we need to tidy-up the Nimble. 😊Chris VeilletteCTO","Hello Andrew/Matthew, We have umpteen number of iSCSI disks, can we please review and identify the required ones and perform the cleanup. Please see the below association report. Let us know your thoughts on it. Based on that, I will schedule a call sometime early next week. 10.59.100.125 lrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-shqsshot-12-14-16-v777bb21358661922.00000008.2f1dab31.s777bb21358661922.00000008.00004bf2-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shqfiles01a-v777bb21358661922.00000013.2f1dab31-lun-0 -> ../../sdelrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shqsshot-12-14-16-v777bb21358661922.00000019.2f1dab31-lun-0 -> ../../sdalrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 -> ../../sdb /dev/sdb        2.0T  1.3T  630G  68% /var/www/vhosts/files.spendhq.com 10.59.10.135 lrwxrwxrwx 1 root root  9 May 31 18:45 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db-backup-02-02-17-v777bb21358661922.00000018.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 May 31 18:45 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db-backup-12-16-16.clone-v777bb21358661922.00000014.2f1dab31-lun-0 -> ../../sdalrwxrwxrwx 1 root root  9 May 31 18:45 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-copy-04-24-17-v777bb21358661922.0000001b.2f1dab31-lun-0 -> ../../sdb/dev/xvdf       2.0T  100G  1.8T   6% /mnt/drtest2016/dev/sdb        4.0T  2.3T  1.5T  61% /var/infobright/dev/sdc        4.0T  2.1T  1.8T  55% /mnt/db_backup-12-16-16/dev/sdb        4.0T  2.3T  1.5T  61% /mnt/db_backup_04_24_17/dev/sda        4.0T  1.6T  2.2T  43% /mnt/db_backup_02_02_2017 10.59.10.91 lrwxrwxrwx 1 root root  9 Jan  3 19:18 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000015.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 Jan  3 19:28 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000016.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root  9 Jan 10 16:17 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prod-backup-1-10-17-v777bb21358661922.00000017.2f1dab31-lun-0 -> ../../sdelrwxrwxrwx 1 root root  9 Nov  4  2016 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend5-v777bb21358661922.0000000d.2f1dab31-lun-0 -> ../../sdalrwxrwxrwx 1 root root  9 Nov  7  2016 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq-db4-v777bb21358661922.00000010.2f1dab31-lun-0 -> ../../sdb/dev/sdb        1.5T   91G  1.4T   7% /var/infobright/dev/xvdf       2.0T  100G  1.8T   6% /mnt/drtest2016/dev/sdd        4.0T  1.6T  2.2T  43% /mnt/db5-backup/dev/sde        4.0T  1.6T  2.2T  43% /mnt/prod-backup-1-10-17 10.59.10.148 None  10.59.10.12 lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:centos-vol-v777bb21358661922.00000003.2f1dab31-lun-0 -> ../../sdhlrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:centos-vol-v777bb21358661922.00000003.2f1dab31-lun-0-part1 -> ../../sdh1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-copy-04-26-17-v777bb21358661922.0000001c.2f1dab31-lun-0 -> ../../sdblrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-v777bb21358661922.00000009.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq011-11-16.data22.clone-v777bb21358661922.00000012.2f1dab31-lun-0 -> ../../sdilrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq011-11-16.data22.clone-v777bb21358661922.00000012.2f1dab31-lun-0-part1 -> ../../sdi1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq-11-11-16.data.clone-v777bb21358661922.00000011.2f1dab31-lun-0 -> ../../sdflrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq-11-11-16.data.clone-v777bb21358661922.00000011.2f1dab31-lun-0-part1 -> ../../sdf1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-10-15-16-testspq-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.0000406d-lun-0 -> ../../sdglrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-10-15-16-testspq-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.0000406d-lun-0-part1 -> ../../sdg1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-clone092016-sphqec2var-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003baf-lun-0 -> ../../sdelrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-clone092016-sphqec2var-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003baf-lun-0-part1 -> ../../sde1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-snap1-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003ba8-lun-0 -> ../../sdalrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-snap1-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003ba8-lun-0-part1 -> ../../sda1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-v777bb21358661922.00000002.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-v777bb21358661922.00000002.2f1dab31-lun-0-part1 -> ../../sdd1 /dev/sdc        4.0T  2.5T  1.3T  67% /var/infobright Regards,-Praveen",iSCSI Disks Review and Cleanup,,03-06-2017 06:35,90,0,SpendHQ,"We had a call with spendhq and Andromeda team. During the call, we have deleted some of the volumes. Andromeda team will provide new volumes and we need to mount it on servers.","Hi Andrew,I spent time today looking at the Nimble utilization; for earlier today, we received a request for an additional (2) 2TB volumes.Right now unfortunately  we only have 2.24TB usable that is available.   We have a couple options:Short term: we need to delete some of the volumes on the Nimble.  Please see the attachments I sent out this AM. This really needs to be done regardless.  We have so many volumes it has become hard to track for REAN and A3 what each volume is...permissions, mount points, IP addresses, iSCSI initiator groups, et cetera.Long term:  we could start using the JetStor.  This might take a week or so as we continue testing/configuring to  make ensure it will perform without issues.  Given my testing so far,  I am not anticipating any issues.    Another clear advantage to this approach is,  by starting fresh, REAN and A3 can better track the characteristics of each volume as it is created. Let me know how to proceed.  😊Have a great weekend!ChrisChris VeilletteCTO","Hello Chris/David, Do you have any update on the below request. Regards,-Praveen From: Akhil Baby <akhil.baby@reancloud.com>Reply-To: <akhil.baby@reancloud.com>Date: Friday, June 2, 2017 at 1:03 PMTo: Chris Veillette <cveillette@andromeda3.com>, David McLaughlin <dmclaughlin@andromeda3.com>Cc: Praveen Kumar Muppala <praveen.muppala@reancloud.com>, Fazlu <fazlu.rahman@reancloud.com>, Andrew Kim <Akim@spendhq.com>, Matthew Watts <mwatts@spendhq.com>, REAN Managed Services <ms@reancloud.com>, <rlittle@insightsourcing.com>Subject: Re: iSCSI Disks Review and Cleanup Hi Andromeda Team, We need to create two new empty volumes for the machines 10.59.10.140 and 10.59.10.148. Refer the details below,New 2TB empty volume and associate it to 10.59.10.140New 2TB empty volume and associate it to 10.59.10.148Let us know once the volumes are available so that we can mount these volumes on these machines. Also, share the IQN names of the new volumes. Revert back in case of any queries.Regards,Akhil BREĀN Cloud Solutions | Reach, Engage, Āctivate, Nurture2201 Cooperative Way #250, Herndon, Va 20171akhil.baby@reancloud.com | www.reancloud.com",Working on it.  Email to follow...David McLaughlinAndromeda3703.439.4413,"Hello Robert,We have checked it from the existing mount points. We will mount the unmounted ones and will try to figure out from there. Will get back to you with the details once it's done.","Hello Robert,We have cross verified the file Client287*.sql.gz in all machines and below are the findings,PROD-SPHQ-DB-SERVER05 (10.59.10.135) /var/tmp/Client287SpendData_Reporting.sql.gzPROD-SPHQ-DB-SERVER04 (10.59.10.91) /var/tmp/Client287SpendData_Reporting.sql.gzPROD-SPHQ-DB-SERVER03 (10.59.10.148) /var/tmp/Client287SpendData_Reporting.sql.gzPROD-SPHQ-DB-SERVER03 (10.59.10.148) /tmp/Client287SpendData_mv2DB3MemSQL.sql.gzWe have tried to mount the unmounted volumes and searched for the files starting with file Client283*.sql.gz but was not able to figure out any files related to it.","Hey Fazlu, When you say all the machines are you referencing just the ones that are already mounted? Have you mounted the others that were unmounted and searched for it? Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com",Thanks for the update. Just for clarity the file I am most concerned with finding is Client283SpendData_fullbackup6012017.sql.gz. Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com,"Hello Robert,We have checked for the file Client287*.sql.gz in all machines which are mounted already and found the below detailsPROD-SPHQ-DB-SERVER04 (10.59.10.91) /var/tmp/Client287SpendData_Reporting.sql.gzPROD-SPHQ-DB-SERVER03 (10.59.10.148) /var/tmp/Client287SpendData_Reporting.sql.gzPROD-SPHQ-DB-SERVER03 (10.59.10.148) /tmp/Client287SpendData_mv2DB3MemSQL.sql.gzFrom the above details we could see that Client287 is in the DB03 in the /var/tmp location itself. We are now further checking the file Client287*.sql.gz from the unmounted volumes and will get back to you with our findings.","Hello Robert,We have checked for that particular file also in all the machines, but we didn't find any related entries.","Thanks Chris. However, can you please provide the connection details. Regards,-Praveen","Hi Praveen - the connections are a little misleading-  when a snapshot is taken/made, the snapshot takes all the attributes of the master volume- including connections - which is needed  - remember the new clone is really empty - changes are written to the new cline but all the former data is still there ...Chris Veillette","Hey Praveen, For both 1 and 2 mounted directories please mount to /mnt. For number 3, once you identify the Client287*.sql.gz data copying it to 148 would be perfect. If it helps I know there is one file named Client283SpendData_fullbackup6012017.sql.gz. Thanks, Robert Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.com","Hi Andromeda Team,We need to create two new empty volumes for the machines 10.59.10.140 and 10.59.10.148. Refer the details below,New 2TB empty volume and associate it to 10.59.10.140New 2TB empty volume and associate it to 10.59.10.148Let us know once the volumes are available so that we can mount these volumes on these machines. Also, share the IQN names of the new volumes. Revert back in case of any queries.Regards,Akhil BREĀN Cloud Solutions | Reach, Engage, Āctivate, Nurture2201 Cooperative Way #250, Herndon, Va 20171 akhil.baby@reancloud.com | www.reancloud.com",Unfortunately I can not see any data or structure- a great security feature - but no help for you.  All I see is volume names. 😞Chris Veillette,"Hello Rob, Let me digest this request well. New 2TB empty volume and associate it to 10.59.10.140. Let us know on what directory you want to mount it?New 2TB empty volume and associate it to 10.59.10.148. Let us know on what directory you want to mount it?Identify the Client287*.sql.gz in any of the existing mounts, if we find it you want us to copy it to 148 machine? Based on your response, I will ask my team to work on these requests. Regards,-Praveen","Hello Chris, The report looks good. Is there anyway, we can identify the connections details as per the first screenshot. The connection is from which IP address. I am curious why certain disks has 2 connections. Ideally each disk should only have one 1 connection. Regards,-Praveen","REAN, Sorry too keep pestering you guys. It turns out I need another volume mounted as well. To summarize we need 1 2tb drive mounted on 10.59.10.140, 1 2tb drive mounted on 10.59.10.148. And do identify which mount had the files named something like Client287<something>.sql.gz that would be in /dev/shm.  Thanks, Robert Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com","REAN, Have you been creating a mapping database for all these volumes as this would greatly help. Regards,Matthew Watts","I am not sure which one based on those names. I can say that the one I need has a bunch of backups in it that we need named something like Client287<something>.sql.gz that would be in /dev/shm/.  Can you see the contents of the volumes at all? In the meantime, I am trying to set up a memsql cluster and to keep things moving can we get a 2 tb drive mounted on that box? Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com","Hello Chris/David, Can you please help us to associate the unused/unmounted scsi disks to 10.59.10.148 machine. So that, we will mount each one and try it out.Regards,-Praveen","Hey Team, Would it be possible for you to mount all drives somewhere so I can take a look and see if I can identify the correct one?  Thanks, Robert Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.com",Hi -I have enclosed three screen shots - two show the volumes that are on the Nimble - - there are so many I had to create two screenshots - and another that shows the current iSCSI connections and which IQN they are pointed to or associated with.I can't help associate the volumes since all I have is the Nimble volume name to present - I don't know what they are called once they are mapped.Chris VeilletteCTO,"Hello Andrew,We will work on creating the excel sheet with details and let you know the updates.","Can we get a list of all of the iSCSI disks and which servers they’re attached to? Preferably in excel format. Thanks, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com",Hi All - I agree with Praveen - we need to tidy-up the Nimble. 😊Chris VeilletteCTO,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001dcqAP,Cloud Engineer Level 1,Closed,1106530,Incident,25-10-2018 18:09,,"Hello TeamWe haven't heard back from you regarding the alert unused ENI - eni-de76d3fe.We got this alert as this Network interface is not attached to any of the Instances.kindly check with the same and update us back if you have any queries. As of now, we are marking this case as closed.you can update on the same case to reopen this if you have any queries.###Hi Team,This is a quick follow up.Please find the below details regarding the alert unused ENI - eni-de76d3fe. Please review the same and let us know whether we can remove the ENI Resource Details: Network interface ID: eni-de76d3fe Subnet ID: subnet-0fdde924 VPC ID: vpc-76df7212 Availability Zone: us-east-1b Status: available###Hello Team,This is a gentle reminder. Please find the below details regarding the alert unused ENI - eni-de76d3fe. Please review the same and let us know whether we can remove the ENIResource Details: Network interface ID: eni-de76d3fe Subnet ID: subnet-0fdde924 VPC ID: vpc-76df7212 Availability Zone: us-east-1b Status: available###Hello Team,This is to inform you that we have received an alert regarding  unused ENI - eni-de76d3fe. While checking we could see that this ENI is not associated with any of the instances. So we suggest you to review the same from your end and let us know whether we can remove this ENI. For your information,  Resource Details: Network interface ID: eni-de76d3fe Subnet ID: subnet-0fdde924 VPC ID: vpc-76df7212 Availability Zone: us-east-1b Status: availableWe are awaiting your response. Thank you.###Hello Team,This resource marked as unused from past 20 days or more and we sent multiple follow-ups to the customer to get an approval from customer to clean up this unused eni but we didn't receive any response from them. Please check with CC on Monday morning to proceed further on this case.###Hello Team, We received an alert regarding an unused ENI - eni-de76d3fe. Currently, it isn't associated with any instance and as such would like to advise you to do so or risk having it deleted in the near future. Resource Details: Network interface ID: eni-de76d3fe Subnet ID: subnet-0fdde924 VPC ID: vpc-76df7212 Availability Zone: us-east-1b Status: available","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Sat, Oct 20, 2018 at 5:34 PMSubject: [Managed Cloud: spendhq] Unused ENIs CheckTo: <spendhq-support@reancloud.com>REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environmentby REAN Managed Cloud.The following *AWS::EC2::NetworkInterface* resources were affected:------------------------------   - *Violation:* This Network Interface is not being used by any instance   - *Recommendation:* Since the Network interface is not being used by any   Instance, associate it with any Instance or it will get Deleted..   - *Action taken:* None   - *Resource details:*   Resource ID Region   eni-de76d3fe us-east-1------------------------------Best Regards,REAN Cloud TeamIMPORTANT: Please do not reply to this message or email address.-- Regards,G.ManideepHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>*manideep.gunda@reancloud.com <manideep.gunda@reancloud.com>* | 733-7263-007 | www.reancloud.com <http://www.reancloudsolutions.com/><https://www.reancloud.com/workshop-securely-implement-bigdata-on-aws/>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>--  <https://hubs.ly/H0d8gJ20>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Managed Cloud: spendhq] Unused ENIs Check,,20-10-2018 17:36,121,0,SpendHQ,"Hello TeamWe haven't heard back from you regarding the alert unused ENI - eni-de76d3fe.We got this alert as this Network interface is not attached to any of the Instances.kindly check with the same and update us back if you have any queries. As of now, we are marking this case as closed.you can update on the same case to reopen this if you have any queries.","Hi Team,This is a quick follow up.Please find the below details regarding the alert unused ENI - eni-de76d3fe. Please review the same and let us know whether we can remove the ENI Resource Details: Network interface ID: eni-de76d3fe Subnet ID: subnet-0fdde924 VPC ID: vpc-76df7212 Availability Zone: us-east-1b Status: available","Hello Team,This is a gentle reminder. Please find the below details regarding the alert unused ENI - eni-de76d3fe. Please review the same and let us know whether we can remove the ENIResource Details: Network interface ID: eni-de76d3fe Subnet ID: subnet-0fdde924 VPC ID: vpc-76df7212 Availability Zone: us-east-1b Status: available","Hello Team,This is to inform you that we have received an alert regarding  unused ENI - eni-de76d3fe. While checking we could see that this ENI is not associated with any of the instances. So we suggest you to review the same from your end and let us know whether we can remove this ENI. For your information,  Resource Details: Network interface ID: eni-de76d3fe Subnet ID: subnet-0fdde924 VPC ID: vpc-76df7212 Availability Zone: us-east-1b Status: availableWe are awaiting your response. Thank you.","Hello Team,This resource marked as unused from past 20 days or more and we sent multiple follow-ups to the customer to get an approval from customer to clean up this unused eni but we didn't receive any response from them. Please check with CC on Monday morning to proceed further on this case.","Hello Team, We received an alert regarding an unused ENI - eni-de76d3fe. Currently, it isn't associated with any instance and as such would like to advise you to do so or risk having it deleted in the near future. Resource Details: Network interface ID: eni-de76d3fe Subnet ID: subnet-0fdde924 VPC ID: vpc-76df7212 Availability Zone: us-east-1b Status: available",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DBffI,Cloud Engineer Level 1,Closed,1062271,Incident,13-06-2017 15:53,,"Hello Team,We are closing this ticket and will follow it in ticket number  01062384. Please let us know if you have any concerns.###Hello Team,From our analysis, we found that /tmp and /var/tmp are taking most of the disk.please find the details of disk usage below:du --max-depth=1 -h /13M     /sbin0       /proc16K     /lost+found285M    /lib4.0K    /cgroup4.0K    /media510M    /home168K    /root44M     /boot30M     /etc8.0K    /run19M     /lib64282M    /opt7.0G    /usr184K    /dev4.0K    /srv25G     /tmp0       /sys4.0K    /selinux6.5M    /bin7.4T    /du --max-depth=1 -h /var/129M    /var/cache2.1G    /var/lib8.0K    /var/empty4.0K    /var/preserve4.0K    /var/nis4.0K    /var/crash188K    /var/db12K     /var/lock124K    /var/run212M    /var/log4.0K    /var/opt2.2G    /var/www4.0K    /var/games4.0K    /var/yp9.9G    /var/tmp4.0K    /var/local116K    /var/spoolPlease delete or zip the unwanted files in order to resolve this issue.Please let us know if you have any more queries regarding this.###Hello Team,We are looking into this issue and will get back to you with the updates.","Hi,Would you be able to tell me what is consuming the space on the following server and drive?Server: 10.59.10.135Drive: /dev/xvda1It says it's at 100% use so I can't even create a mytop config file. I'd like to try and clear up some space so I can at least save a mytop config file.Best Regards,Dan Mackay | Spend Solutions DBA | SpendHQO: 770-741-0157 | dmackay@spendhq.com<mailto:dmackay@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",No space on drive,,12-06-2017 23:28,16,0,SpendHQ,"Hello Team,We are closing this ticket and will follow it in ticket number  01062384. Please let us know if you have any concerns.","Hello Team,From our analysis, we found that /tmp and /var/tmp are taking most of the disk.please find the details of disk usage below:du --max-depth=1 -h /13M     /sbin0       /proc16K     /lost+found285M    /lib4.0K    /cgroup4.0K    /media510M    /home168K    /root44M     /boot30M     /etc8.0K    /run19M     /lib64282M    /opt7.0G    /usr184K    /dev4.0K    /srv25G     /tmp0       /sys4.0K    /selinux6.5M    /bin7.4T    /du --max-depth=1 -h /var/129M    /var/cache2.1G    /var/lib8.0K    /var/empty4.0K    /var/preserve4.0K    /var/nis4.0K    /var/crash188K    /var/db12K     /var/lock124K    /var/run212M    /var/log4.0K    /var/opt2.2G    /var/www4.0K    /var/games4.0K    /var/yp9.9G    /var/tmp4.0K    /var/local116K    /var/spoolPlease delete or zip the unwanted files in order to resolve this issue.Please let us know if you have any more queries regarding this.","Hello Team,We are looking into this issue and will get back to you with the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001eNmR9,Cloud Engineer Level 1,Closed,1107254,Incident,08-11-2018 18:12,,"Hello Team, Your ticket #01107254 is auto closed. We are closing the ticket as no action was performed from your end. If the ticket is closed erroneously, feel free to reopen the ticket. For any escalation, please send an email to reansupportescalation@reancloud.com . We look forward to serve you. Feel free to reach out to us at support@reancloud.com for any additional queries. Rean Cloud Solutions support@reancloud.com###Hello Team,This is a follow up regarding the URL: https://preview.spendhq.com/login  caused high latency. kindly review our previous mail and let us know if you have any queries.Thank you###Hello Team,We haven't heard back from you regarding this case.The analysis we shared indicates that the issue arose due to latency.Please find time to review and let us know if you have any questions.###Hello Team,This is to inform you that we have again received the site down alert and later got recovered automatically and the site is up and accessible the violation lasted for 17 minutes.The latency was gradually increased for the load balancer preview-spendhq-xelb and it reached the max value of 600000ms. While checking the Preview DB server has 100% CPU utilization when the site was down. As the instance is not under Rean monitoring, we haven't received any alert for this.Apart from that, we couldn't find any suspicious activity for the Preview DB and the Preview Web server from the EC2 metrics.While analysing the logs from the Preview Web instance, we could able to see the SHQ_Exception error. Please find the screenshot in the attachment section for the same and kindly review the logs and the network conncetions and revert back to us in case of any queries.Error Logs:----------------[Tue Nov 06 16:19:39 2018] [error] [client 10.59.1.192] SHQ_Exception: [11]: A back up table, isg_att.spend_visibility3_v61_bak20181106111938, has been created for the mv2infobright process. You should clean things up every now and then. in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 3639 fired on host preview.spendhq.com\\n, referer: https://preview.spendhq.com/spend-visibility/administration/vendor_recategorization[Tue Nov 06 16:19:39 2018] [error] [client 10.59.1.192] SHQ_Exception: [1]: Line count between isg_att.spend_visibility3_v61_temp1541520939 & isg_att.spend_visibility is not equal. Check if there is another upload in progress as that can cause the line count between MyISAM and Infobright to mismatch. If there isn't you should go to super admin and under the Technical section rebuild some Infobright tables that has a failed status. in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 3659 fired on host preview.spendhq.com\\n, referer: https://preview.spendhq.com/spend-visibility/administration/vendor_recategorization[Tue Nov 06 21:48:52 2018] [error] [client 10.59.1.192] SHQ_Exception: [1]: Encryption Authentication Exception Thrown with message Could not access password provided for user 4499. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/components/auth.php on line 265 fired on host preview.spendhq.com\\n, referer: https://preview.spendhq.com/login###Hello Team,This is to inform you that we have received a site down alert for the URL: https://preview.spendhq.com/login .We will check on this and will get back to you.","Tue, 06 Nov 2018 17:28:23 -0500Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30003 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): London UK, California US, Dallas-B US, Frankfurt DE--  <http://htchivantara.is/2RAornF>",Detected Error on SpendHQ Preview,,07-11-2018 03:59,38,0,SpendHQ,"Hello Team, Your ticket #01107254 is auto closed. We are closing the ticket as no action was performed from your end. If the ticket is closed erroneously, feel free to reopen the ticket. For any escalation, please send an email to reansupportescalation@reancloud.com . We look forward to serve you. Feel free to reach out to us at support@reancloud.com for any additional queries. Rean Cloud Solutions support@reancloud.com","Hello Team,This is a follow up regarding the URL: https://preview.spendhq.com/login  caused high latency. kindly review our previous mail and let us know if you have any queries.Thank you","Hello Team,We haven't heard back from you regarding this case.The analysis we shared indicates that the issue arose due to latency.Please find time to review and let us know if you have any questions.","Hello Team,This is to inform you that we have again received the site down alert and later got recovered automatically and the site is up and accessible the violation lasted for 17 minutes.The latency was gradually increased for the load balancer preview-spendhq-xelb and it reached the max value of 600000ms. While checking the Preview DB server has 100% CPU utilization when the site was down. As the instance is not under Rean monitoring, we haven't received any alert for this.Apart from that, we couldn't find any suspicious activity for the Preview DB and the Preview Web server from the EC2 metrics.While analysing the logs from the Preview Web instance, we could able to see the SHQ_Exception error. Please find the screenshot in the attachment section for the same and kindly review the logs and the network conncetions and revert back to us in case of any queries.Error Logs:----------------[Tue Nov 06 16:19:39 2018] [error] [client 10.59.1.192] SHQ_Exception: [11]: A back up table, isg_att.spend_visibility3_v61_bak20181106111938, has been created for the mv2infobright process. You should clean things up every now and then. in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 3639 fired on host preview.spendhq.com\\n, referer: https://preview.spendhq.com/spend-visibility/administration/vendor_recategorization[Tue Nov 06 16:19:39 2018] [error] [client 10.59.1.192] SHQ_Exception: [1]: Line count between isg_att.spend_visibility3_v61_temp1541520939 & isg_att.spend_visibility is not equal. Check if there is another upload in progress as that can cause the line count between MyISAM and Infobright to mismatch. If there isn't you should go to super admin and under the Technical section rebuild some Infobright tables that has a failed status. in file /var/www/vhosts/secure.spendhq.com/public/app/app_model.php on line 3659 fired on host preview.spendhq.com\\n, referer: https://preview.spendhq.com/spend-visibility/administration/vendor_recategorization[Tue Nov 06 21:48:52 2018] [error] [client 10.59.1.192] SHQ_Exception: [1]: Encryption Authentication Exception Thrown with message Could not access password provided for user 4499. in file /var/www/vhosts/secure.spendhq.com/public/app/controllers/components/auth.php on line 265 fired on host preview.spendhq.com\\n, referer: https://preview.spendhq.com/login","Hello Team,This is to inform you that we have received a site down alert for the URL: https://preview.spendhq.com/login .We will check on this and will get back to you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015Ynrr,Cloud Engineer Level 1,Closed,1040945,Incident,,,,"Yes, that is correct. We reported the issue at 10:15 this morning, however it commenced late yesterday afternoon thus placing those errors in the right time frame.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>From: Praveen Muppala - Rean [mailto:praveen.muppala@reancloud.com]Sent: Friday, December 23, 2016 3:01 PMTo: Matthew Watts <mwatts@spendhq.com>; spendhq-support@reancloud.com; 'REAN Support' <support@reancloud.com>; 'Chris Veillette' <cveillette@Andromeda3.com>Subject: RE: SEV One: ReviewHello Matthew,We noticed this error. But this error is on Dec 22nd. By any time zone the issue you reported time was 23rd. So our team is looking further to understand the issue further. We will get back to you ASAP as soon as we finishes our analysis.Thank you for your findings.Regards,-PraveenFrom: Matthew Watts [mailto:mwatts@spendhq.com]Sent: Friday, December 23, 2016 2:56 PMTo: spendhq-support@reancloud.com<mailto:spendhq-support@reancloud.com>; REAN Support <support@reancloud.com<mailto:support@reancloud.com>>; Chris Veillette <cveillette@Andromeda3.com<mailto:cveillette@Andromeda3.com>>Subject: SEV One: ReviewI have just reviewed the log files on .125 (File Server) and it appears that we had some issues early on in the afternoon, which ultimately got worse. It seems that with the Journal Commit Error's that the drive got enough errors that the Operating System took it to read-only mode. Especially considering we have multiple entries for I/O Errors on specific blocks that retried and ultimately resulted in the read only mount.Can you advise if you think this is a storage issue error or other?Dec 22 23:06:31 ip-10-59-100-125 kernel: connection3:0: ping timeout of 10 secs expired, recv timeout 5, last rx 4705624002, last ping 4705629002, now 4705639002Dec 22 23:06:32 ip-10-59-100-125 iscsid: Kernel reported iSCSI connection 3:0 error (1011 - ISCSI_ERR_CONN_FAILED: iSCSI connection failed) state (3)Dec 22 23:06:36 ip-10-59-100-125 iscsid: connect to 172.23.104.77:3260 failed (Network is unreachable)Dec 22 23:06:41 ip-10-59-100-125 kernel: sd 4:0:0:0: rejecting I/O to offline deviceDec 22 23:06:41 ip-10-59-100-125 kernel: sd 4:0:0:0: [sda] killing requestDec 22 23:06:41 ip-10-59-100-125 kernel: JBD2: Detected IO errors while flushing file data on sda-8Dec 22 23:06:41 ip-10-59-100-125 kernel: JBD2: I/O error detected when updating journal superblock for sda-8.Dec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs error (device sda) in ext4_dirty_inode: Journal has abortedDec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs error (device sda): ext4_journal_start_sb: Detected aborted journalDec 22 23:06:41 ip-10-59-100-125 kernel: EXT4-fs (sda): Remounting filesystem read-onlyDec 22 23:06:45 ip-10-59-100-125 kernel: journal commit I/O errorMatthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",RE: SEV One: Review,,24-12-2016 01:35,4,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Dnyfg,Cloud Engineer Level 1,Closed,1065750,Incident,30-06-2017 01:16,,We are following this on 01065712,"Thu, 29 Jun 2017 13:20:29 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: Reported by node: New Jersey USConfirmed by node(s): Sydney-C AU, London UK, California US, Atlanta-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,29-06-2017 22:50,2,0,SpendHQ,We are following this on 01065712,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ESMqN,Cloud Engineer Level 1,Closed,1066919,Incident,06-07-2017 17:51,,"Hi Team,This is to notify you that the alert regarding volume usage for PROD-SPHQ-DB-SERVER05 instance got resolved and the usage has returned to normal with a value of 57.9%. The violation has lasted for 2 hours.###Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 91.8%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 90.669This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3943877365881938514 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,06-07-2017 15:48,8,0,SpendHQ,"Hi Team,This is to notify you that the alert regarding volume usage for PROD-SPHQ-DB-SERVER05 instance got resolved and the usage has returned to normal with a value of 57.9%. The violation has lasted for 2 hours.","Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 91.8%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001K2K2S,Cloud Engineer Level 1,Closed,1084484,Incident,08-12-2017 00:17,,"Hi SpendHQ Team,I am closing this case as we are following on an another case with Chris Veillette. The case number is I-01085107.###We have another case form Chris for the Production DB size issue: Case ID: 01085107###Hello SPendHQ-Team,The alert regarding high disk usage on the instance PRD-DB1 is still in the open state. The current volume usage state in this instance is at 91.6%. We have already shared the volume usage breakdown details regarding this case. Kindly validate it from your end and delete/zip unwanted files or folders to reduce the current volume usage on this instance and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello SpendHQ-Team,This is to notify you that the alert regarding volume usage for PRD-DB1 instance /dev/sdc volume is still in open state and the current usage is 92%. Out of 3.5TB, only 339GB is left. Please find the volume usage details below and remove or zip unused files to resolve this issue./mnt/production_19082017/3.4T	data41G	watts12G	dmackay4.1G	postgres_old2.7G	postgres501M	rlittledata/3.0T	isg50G	isg_metronic49G	ip-10-59-10-190.log33G	isg_thlee20131G	isg_ares227G	isg_att16G	isg_att_01_07_201714G	isg_cgi12G	isg_lowes12G	isg_cushmanwisg/66G	sv_ap_att_201508_201612s.MYD65G	Client217SpendData_base_allfields.MYD59G	spend_visibility_old_backup.MYI52G	sv_ap_ATT_201501_201609s.MYD51G	spend_visibility_old20161001.MYD42G	spend_visibility_old20161001.MYI38G	spend_visibility.MYD32G	spend_visibility.MYI28G	spend_visibility_unmanaged3.bht27G	sv_ap_medtronic_201404_201701s.MYD###Hi Team,We want to follow up on this alert.This holds a high priority as the production database (10.59.10.190 - PRD-DB1) mount is 92% filled now.Please find the mount details for this volume below:##lrwxrwxrwx 1 root root 9 Aug 19 22:12 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-170819-v777bb21358661922.00000028.2f1dab31-lun-0 -> ../../sdc## /dev/sdc       ext4      4.0T  3.5T  345G  92% /mnt/production_19082017We recommend cleanup of unused files or increase iSCSI disk size to prevent any outage.###Hello SpendHQ Team,The alert regarding the volume usage for PRD-DB1 instance for /dev/sdc volume is still in open state for past 2 days, please delete or zip unwanted files and let us know if you are having any queries.###Hello SpendHQ-Team,This is to notify you that we have received an alert that volume usage for PRD-DB1 instance /dev/sdc volume has exceeded a threshold value of 90 to 90.1%. Please find the volume usage details below and remove or zip unused files to resolve this issue.3.4T	data41G	watts12G	dmackay4.1G	postgres_old2.7G	postgres501M	rlittle164K	tmp16K	lost+found16K	cachedata/2.9T	isg50G	isg_metronic49G	ip-10-59-10-190.log33G	isg_thlee20131G	isg_ares227G	isg_att16G	isg_att_01_07_201714G	isg_cgi12G	isg_lowes12G	isg_cushmanwisg/66G	sv_ap_att_201508_201612s.MYD65G	Client217SpendData_base_allfields.MYD59G	spend_visibility_old_backup.MYI52G	sv_ap_ATT_201501_201609s.MYD51G	spend_visibility_old20161001.MYD42G	spend_visibility_old20161001.MYI38G	spend_visibility.MYD32G	spend_visibility.MYI27G	sv_ap_medtronic_201404_201701s.MYD25G	sv_ap_medtronic_201404_201610s.MYDResource Details:Instance Name: PRD-DB1Instance ID:  i-03ccfddd9f02cacb9Instance type: r4.8xlargePrivate IP: 10.59.10.190","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sdc ) - prd-db1 - 10.59.10.190  High Disk Usage detected on the device /dev/sdc     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{datadog_monitor:on} by {host,device} * 100 > 90`Metric value: 90.002This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fsdc%2Chost%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=4134071539941137707 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9--  <https://signup.paloaltonetworks.com/ehome/291273>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sdc ) - prd-db1 - 10.59.10.190,,14-11-2017 20:54,556,0,SpendHQ,"Hi SpendHQ Team,I am closing this case as we are following on an another case with Chris Veillette. The case number is I-01085107.",We have another case form Chris for the Production DB size issue: Case ID: 01085107,"Hello SPendHQ-Team,The alert regarding high disk usage on the instance PRD-DB1 is still in the open state. The current volume usage state in this instance is at 91.6%. We have already shared the volume usage breakdown details regarding this case. Kindly validate it from your end and delete/zip unwanted files or folders to reduce the current volume usage on this instance and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello SpendHQ-Team,This is to notify you that the alert regarding volume usage for PRD-DB1 instance /dev/sdc volume is still in open state and the current usage is 92%. Out of 3.5TB, only 339GB is left. Please find the volume usage details below and remove or zip unused files to resolve this issue./mnt/production_19082017/3.4T	data41G	watts12G	dmackay4.1G	postgres_old2.7G	postgres501M	rlittledata/3.0T	isg50G	isg_metronic49G	ip-10-59-10-190.log33G	isg_thlee20131G	isg_ares227G	isg_att16G	isg_att_01_07_201714G	isg_cgi12G	isg_lowes12G	isg_cushmanwisg/66G	sv_ap_att_201508_201612s.MYD65G	Client217SpendData_base_allfields.MYD59G	spend_visibility_old_backup.MYI52G	sv_ap_ATT_201501_201609s.MYD51G	spend_visibility_old20161001.MYD42G	spend_visibility_old20161001.MYI38G	spend_visibility.MYD32G	spend_visibility.MYI28G	spend_visibility_unmanaged3.bht27G	sv_ap_medtronic_201404_201701s.MYD","Hi Team,We want to follow up on this alert.This holds a high priority as the production database (10.59.10.190 - PRD-DB1) mount is 92% filled now.Please find the mount details for this volume below:##lrwxrwxrwx 1 root root 9 Aug 19 22:12 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-170819-v777bb21358661922.00000028.2f1dab31-lun-0 -> ../../sdc## /dev/sdc       ext4      4.0T  3.5T  345G  92% /mnt/production_19082017We recommend cleanup of unused files or increase iSCSI disk size to prevent any outage.","Hello SpendHQ Team,The alert regarding the volume usage for PRD-DB1 instance for /dev/sdc volume is still in open state for past 2 days, please delete or zip unwanted files and let us know if you are having any queries.","Hello SpendHQ-Team,This is to notify you that we have received an alert that volume usage for PRD-DB1 instance /dev/sdc volume has exceeded a threshold value of 90 to 90.1%. Please find the volume usage details below and remove or zip unused files to resolve this issue.3.4T	data41G	watts12G	dmackay4.1G	postgres_old2.7G	postgres501M	rlittle164K	tmp16K	lost+found16K	cachedata/2.9T	isg50G	isg_metronic49G	ip-10-59-10-190.log33G	isg_thlee20131G	isg_ares227G	isg_att16G	isg_att_01_07_201714G	isg_cgi12G	isg_lowes12G	isg_cushmanwisg/66G	sv_ap_att_201508_201612s.MYD65G	Client217SpendData_base_allfields.MYD59G	spend_visibility_old_backup.MYI52G	sv_ap_ATT_201501_201609s.MYD51G	spend_visibility_old20161001.MYD42G	spend_visibility_old20161001.MYI38G	spend_visibility.MYD32G	spend_visibility.MYI27G	sv_ap_medtronic_201404_201701s.MYD25G	sv_ap_medtronic_201404_201610s.MYDResource Details:Instance Name: PRD-DB1Instance ID:  i-03ccfddd9f02cacb9Instance type: r4.8xlargePrivate IP: 10.59.10.190",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BYp5x,Cloud Engineer Level 1,Closed,1051522,Incident,05-05-2017 21:43,,"Hello SpendHQ Team,The scheduled maintenance is only going to affect one DX connection dxcon-fg50qjyw which is 1GBps connection. We are not using the 1GBps connection and we are only using the 10GBps one.However we will be monitoring the environment around this maintenance window time. Please let us know if you have any queries regarding this.###Check with Sanket and update the customer.The scheduled maintenance is only going to affect one DX connection dxcon-fg50qjyw which is 1GBps connection.We already have another 10GB Direct Connect tunnel in place. We have raised a support ticket and AWS support team recommended to manually bring down the BGP peering connection on a router during that maintenance window so that it won't affect the routing of traffic during that period.Can we share this information with client###AWS team updated thatHi,I had a look at the correspondence that was sent to you for the scheduled maintenance and it's only going to affect one DX connection which is dxcon-fg50qjyw. It seems the two DX connection provide redundancy to your VPC, I would recommend that you manually  bring down the  BGP peering for that connection on your router during that maintenance window so that it won't affect the routing of traffic during that period.Please let me know should you have any queries and we will be happy to assist.Best regards,Finley C.Amazon Web Services###@Akhil B @Fazlu: Please check with Sanket/Praveen with the recommendations provided by AWS team and based on their comment please move forward.###Hello SpendHQ-Team,We have raised a support ticket with AWS team and they have confirmed the scheduled maintenance is only going to affect one DX connection which is dxcon-fg50qjyw.DC details:-Connection Name : SpendHQ Connection ID : dxcon-fg50qjywLocation : Equinix DC1 - DC6, DC10, Ashburn, VAAWS Device : EqDC2-51oh37hzf1gxPort Speed : 1GbpsWe will check further on this and will let you know the updates.###Hello SpendHQ-Team,This is to notify you that we have received a notification from AWS that there will be a planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6, DC10, Ashburn, VA. Start time : May 17, 2017 at 1:30:00 PM UTC+5:30/ 4:00 AM ESTEnd time  : May 17, 2017 at 5:30:00 PM UTC+5:30/ 8:00 AM ESTWe will raise a support ticket with AWS team to confirm this and will let you know the updates.","Planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6, DC10, Ashburn, VA. During this maintenance window, your AWS Direct Connect services associated with this event may become unavailable.This maintenance is scheduled to avoid disrupting redundant connections at the same time.If you encounter any problems with your connection after the end of this maintenance window, please contact us at https://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_MAINTENANCE_SCHEDULED,,03-05-2017 13:43,134,0,SpendHQ,"Hello SpendHQ Team,The scheduled maintenance is only going to affect one DX connection dxcon-fg50qjyw which is 1GBps connection. We are not using the 1GBps connection and we are only using the 10GBps one.However we will be monitoring the environment around this maintenance window time. Please let us know if you have any queries regarding this.",Check with Sanket and update the customer.The scheduled maintenance is only going to affect one DX connection dxcon-fg50qjyw which is 1GBps connection.We already have another 10GB Direct Connect tunnel in place. We have raised a support ticket and AWS support team recommended to manually bring down the BGP peering connection on a router during that maintenance window so that it won't affect the routing of traffic during that period.Can we share this information with client,"AWS team updated thatHi,I had a look at the correspondence that was sent to you for the scheduled maintenance and it's only going to affect one DX connection which is dxcon-fg50qjyw. It seems the two DX connection provide redundancy to your VPC, I would recommend that you manually  bring down the  BGP peering for that connection on your router during that maintenance window so that it won't affect the routing of traffic during that period.Please let me know should you have any queries and we will be happy to assist.Best regards,Finley C.Amazon Web Services",@Akhil B @Fazlu: Please check with Sanket/Praveen with the recommendations provided by AWS team and based on their comment please move forward.,"Hello SpendHQ-Team,We have raised a support ticket with AWS team and they have confirmed the scheduled maintenance is only going to affect one DX connection which is dxcon-fg50qjyw.DC details:-Connection Name : SpendHQ Connection ID : dxcon-fg50qjywLocation : Equinix DC1 - DC6, DC10, Ashburn, VAAWS Device : EqDC2-51oh37hzf1gxPort Speed : 1GbpsWe will check further on this and will let you know the updates.","Hello SpendHQ-Team,This is to notify you that we have received a notification from AWS that there will be a planned maintenance has been scheduled on an AWS Direct Connect router in Equinix DC1 - DC6, DC10, Ashburn, VA. Start time : May 17, 2017 at 1:30:00 PM UTC+5:30/ 4:00 AM ESTEnd time  : May 17, 2017 at 5:30:00 PM UTC+5:30/ 8:00 AM ESTWe will raise a support ticket with AWS team to confirm this and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Fe5Dy,Cloud Engineer Level 1,Closed,1073224,Incident,14-08-2017 21:48,,"Hello Allen,We have on-boarded the instance and whitelisted the instance in Sophos. We have verified it from our end, please check and let us know if you are still facing any issue###Hello Allen,We will work on this and will let you know the updates.","I just ran a test withcurl -l 'http://www.google.com'curl: (7) Failed to connect to 2607:f8b0:400d:c08::68: Network is unreachableLeading me to believe there is not internet on this box. Can you confirm and fix? If this box isn't being monitored, please do.I originally discovered this problem trying to git fetch for our code basesudo -Hu apache git fetchssh: connect to host bitbucket.org port 22: Network is unreachablefatal: The remote end hung up unexpectedlyAllen Herrera | Developer | SpendHQ(r)M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Does 10.59.101.6 have internet?,,14-08-2017 20:10,13,0,SpendHQ,"Hello Allen,We have on-boarded the instance and whitelisted the instance in Sophos. We have verified it from our end, please check and let us know if you are still facing any issue","Hello Allen,We will work on this and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001UKKcm,Cloud Engineer Level 2,Closed,1095645,Incident,17-04-2018 16:54,,"Hello Team,As we have discussed yesterday on monthly call with Andrew, we have disable the notification to the SpendHQ Team for now. If we find anything critical we will update you. For now we are closing this case. Thanks !###Hello Team,This alert is related to Remote Command Execution Tempt against Oracle Weblogic App Server. It might be a sub-rule in Operating System Attacks or Attack Against Servers. I am sure either we need to live with the alerts or disable the notifications for all drop alerts. IPS is doing its job.For now, this case can be closed and wait for Sophos UTM Alerts management DevOps program roll out. So that, we can add this feature of not to alert via our automation.###Rohit updated that he and Yogesh try to resolve this but didn't find the Group Name in the Intrusion Prevention which needs to be muted for alerting.We are not sure under which Group Names the SERVER-ORACLE Oracle WebLogic Server remote command comes.I updated same to Praveen and he updated that he will check in this case.###We have informed Rohit on this and he is woking on this###Need to check with Rohit to suppress the SERVER-ORACLE Oracle WebLogic Server remote command execution attempt alerts.###Hello Andrew,Thanks for the update,We won't block the IP and regarding your concern to suppress the SERVER-ORACLE alerts will check internally and let you the update.###Please do not block this IP address.Is there a way to suppress the SERVER-ORACLE Oracle WebLogic Server remote command execution attempt alert?Thank you.###Hello Team, This is to inform you that we have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.192 which belongs to the Preview-api-spendhq-com Please find the Intrusion Prevention Logs: 2018:04:09-11:29:53 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.218 dstip=10.59.1.192 proto=6 srcport=20416 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0Please ELB logs details in the attachment section. On analyzing the ELB logs at the time of the alert, we are able to figure out the IP 18.195.163.71 which belongs to the organization Amazon Technologies Inc. Please review these details###Working on it.","Thanks & Regards,Anjali G NairHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081<https://www.reancloud.com/contact-us/>anjali.gopinadhan@reancloud.com <kriti@reancloud.com> | www.reancloud.com<http://www.reancloudsolutions.com/>---------- Forwarded message ----------From: <ms@reancloud.com>Date: Mon, Apr 9, 2018 at 5:00 PMSubject: [SpendHQ] [10.59.1.192] [CRIT-852] Intrusion Prevention Alert(Packet dropped)To: spendhq-support@reancloud.comIntrusion Count: 3Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-ORACLE Oracle WebLogic Server remote commandexecution attemptDetails........: https://www.snort.org/search?query=45304Time...........: 2018-04-09 11:29:53Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.0.218Source port: 20416Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)Account Name - SpendHQAccount DL - spendhq-support@reancloud.comUTM Hostname - spendhq-utmPrivate IP - 10.59.1.192Public IP - 52.0.17.10Device URL - https://52.0.17.10:4444--System Uptime      : 105 days 4 hours 27 minutesSystem Load        : 0.06System Version     : Sophos UTM 9.506-2Please refer to the manual for detailed instructions.--  <https://signup.paloaltonetworks.com/ehome/321670>--  <https://signup.paloaltonetworks.com/ehome/321670>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [SpendHQ] [10.59.1.192] [CRIT-852] Intrusion Prevention Alert (Packet dropped),,09-04-2018 17:01,198,0,SpendHQ,"Hello Team,As we have discussed yesterday on monthly call with Andrew, we have disable the notification to the SpendHQ Team for now. If we find anything critical we will update you. For now we are closing this case. Thanks !","Hello Team,This alert is related to Remote Command Execution Tempt against Oracle Weblogic App Server. It might be a sub-rule in Operating System Attacks or Attack Against Servers. I am sure either we need to live with the alerts or disable the notifications for all drop alerts. IPS is doing its job.For now, this case can be closed and wait for Sophos UTM Alerts management DevOps program roll out. So that, we can add this feature of not to alert via our automation.",Rohit updated that he and Yogesh try to resolve this but didn't find the Group Name in the Intrusion Prevention which needs to be muted for alerting.We are not sure under which Group Names the SERVER-ORACLE Oracle WebLogic Server remote command comes.I updated same to Praveen and he updated that he will check in this case.,We have informed Rohit on this and he is woking on this,Need to check with Rohit to suppress the SERVER-ORACLE Oracle WebLogic Server remote command execution attempt alerts.,"Hello Andrew,Thanks for the update,We won't block the IP and regarding your concern to suppress the SERVER-ORACLE alerts will check internally and let you the update.",Please do not block this IP address.Is there a way to suppress the SERVER-ORACLE Oracle WebLogic Server remote command execution attempt alert?Thank you.,"Hello Team, This is to inform you that we have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.192 which belongs to the Preview-api-spendhq-com Please find the Intrusion Prevention Logs: 2018:04:09-11:29:53 spendhq snort[23835]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-ORACLE Oracle WebLogic Server remote command execution attempt group=500 srcip=10.59.0.218 dstip=10.59.1.192 proto=6 srcport=20416 dstport=80 sid=45304 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0Please ELB logs details in the attachment section. On analyzing the ELB logs at the time of the alert, we are able to figure out the IP 18.195.163.71 which belongs to the organization Amazon Technologies Inc. Please review these details",Working on it.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gcfoQ,Cloud Engineer Level 1,Closed,1109622,Incident,20-12-2018 19:58,,"Hello Team,This is to inform you that we are closing this ticket from our end since the high CPU alert got recovered and we haven't received any further alerts regarding the high CPU utilization. If you feel this is still in trouble, please don't hesitate to contact back. Thank you.###Hello Team,This is a follow up regarding received an alert regarding high CPU utilization on the SPHQ-DB3-20180830 instance. Please review our analysis from the previous ticket and please let us know if you have any queries regarding the same.###Hello Team,This is to inform you that we've received an alert regarding high CPU utilization on the SPHQ-DB3-20180830 instance.From checking we can see that the PrimProc and semodule -l processes are consuming majority of the CPU. Current reading on the monitor is 91.84% above the set threshold of 85%.Below is a breakdown of the CPU utilization on the instance at our time of checking:Load Average of the System18.47, 19.80, 24.40################################################   Processes with highest CPU usage################################################ USER       PID  PPID CMD                         %CPUroot     29686  1851 [PrimProc]                  89.9root      1928   692 semodule -l                 63.0root      1955 29695 /usr/local/mariadb/columnst 17.0root      1965 24588 /usr/bin/ssm-document-worke  1.0root       692     1 /usr/bin/newrelic-infra      0.8root     29654  1851 /usr/local/mariadb/columnst  0.2root     29695  1851 [WriteEngineServ]            0.2root       104     2 [kswapd0]                    0.1dd-agent 28626     1 /opt/datadog-agent/bin/agen  0.1root         1     0 /usr/lib/systemd/systemd --  0.0Below are TIME_WAIT connection summary ################################################ tcp        0      0 10.59.10.235:40598      10.59.10.26:8620        TIME_WAIT   -                   tcp        0      0 10.59.10.235:8620       10.59.10.45:40678       TIME_WAIT   -                   tcp        0      0 10.59.10.235:53644      10.59.10.45:8620        TIME_WAIT   -                   tcp        0      0 10.59.10.235:53550      10.59.10.235:8620       TIME_WAIT   -                   tcp        0      0 10.59.10.235:8620       10.59.10.26:33606       TIME_WAIT   -                   tcp        0      0 10.59.10.235:48042      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:48050      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:47314      10.59.10.26:8606        TIME_WAIT   -                   tcp        0      0 10.59.10.235:8630       10.59.10.210:58952      TIME_WAIT   -                   tcp        0      0 10.59.10.235:53470      10.59.10.235:8620       TIME_WAIT   -                   tcp        0      0 10.59.10.235:54608      10.59.10.26:8616        TIME_WAIT   -                   tcp        0      0 10.59.10.235:8620       10.59.10.235:53576      TIME_WAIT   -                   tcp        0      0 10.59.10.235:54690      10.59.10.26:8616        TIME_WAIT   -                   tcp        0      0 10.59.10.235:8620       10.59.10.45:40800       TIME_WAIT   -                   tcp        0      0 10.59.10.235:8620       10.59.10.26:60334       TIME_WAIT   -   1 established)     34 ESTABLISHED      1 Foreign     14 LISTEN     50 TIME_WAITPlease find the full analysis in the attachment sectionfor your perusal. Resource Details:-----------------------Name: SPHQ-DB3-20180830Instance ID:  i-0e76e98abf08a1b70Pricate IP: 10.59.10.235AZ: us-east-1bVPC ID: vpc-76df7212------------------------Thanks","[image: Datadog][Triggered] [SpendHQ] - High CPU Utilization on the host sphq-db3-20180830- 10.59.10.235 -High CPU Utilization on the host. Log in to the machine and verify whichprocess is consuming high CPU resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024189?to_ts=1545154459000&group=host%3Ai-0e76e98abf08a1b70&from_ts=1545147259000>avg(last_30m):avg:system.cpu.stolen{datadog_monitor:on} by {host} +avg:system.cpu.user{datadog_monitor:on} by {host} +avg:system.cpu.system{datadog_monitor:on} by {host} > 85The monitor was last triggered at Tue Dec 18 2018 17:34:29 UTC (*4 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024189?group=host%3Ai-0e76e98abf08a1b70>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024189/edit>] · [Viewi-0e76e98abf08a1b70<https://app.datadoghq.com/infrastructure?filter=i-0e76e98abf08a1b70>] · [ShowProcesses<https://app.datadoghq.com/process?sort=cpu%2CDESC&to_ts=1545154589000&tags=host%3Ai-0e76e98abf08a1b70&from_ts=1545153569000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4712579166702139246>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Utilization on the host sphq-db3-20180830 - 10.59.10.235 -,,18-12-2018 23:25,45,0,SpendHQ,"Hello Team,This is to inform you that we are closing this ticket from our end since the high CPU alert got recovered and we haven't received any further alerts regarding the high CPU utilization. If you feel this is still in trouble, please don't hesitate to contact back. Thank you.","Hello Team,This is a follow up regarding received an alert regarding high CPU utilization on the SPHQ-DB3-20180830 instance. Please review our analysis from the previous ticket and please let us know if you have any queries regarding the same.","Hello Team,This is to inform you that we've received an alert regarding high CPU utilization on the SPHQ-DB3-20180830 instance.From checking we can see that the PrimProc and semodule -l processes are consuming majority of the CPU. Current reading on the monitor is 91.84% above the set threshold of 85%.Below is a breakdown of the CPU utilization on the instance at our time of checking:Load Average of the System18.47, 19.80, 24.40",,,,,,,,,,,,,,,,Processes with highest CPU usage,,,,,,,,,,,,,,,,USER       PID  PPID CMD                         %CPUroot     29686  1851 [PrimProc]                  89.9root      1928   692 semodule -l                 63.0root      1955 29695 /usr/local/mariadb/columnst 17.0root      1965 24588 /usr/bin/ssm-document-worke  1.0root       692     1 /usr/bin/newrelic-infra      0.8root     29654  1851 /usr/local/mariadb/columnst  0.2root     29695  1851 [WriteEngineServ]            0.2root       104     2 [kswapd0]                    0.1dd-agent 28626     1 /opt/datadog-agent/bin/agen  0.1root         1     0 /usr/lib/systemd/systemd --  0.0Below are TIME_WAIT connection summary,,,,,,,,,,,,,,,,tcp        0      0 10.59.10.235:40598      10.59.10.26:8620        TIME_WAIT   -                   tcp        0      0 10.59.10.235:8620       10.59.10.45:40678       TIME_WAIT   -                   tcp        0      0 10.59.10.235:53644      10.59.10.45:8620        TIME_WAIT   -                   tcp        0      0 10.59.10.235:53550      10.59.10.235:8620       TIME_WAIT   -                   tcp        0      0 10.59.10.235:8620       10.59.10.26:33606       TIME_WAIT   -                   tcp        0      0 10.59.10.235:48042      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:48050      10.59.10.26:8603        TIME_WAIT   -                   tcp        0      0 10.59.10.235:47314      10.59.10.26:8606        TIME_WAIT   -                   tcp        0      0 10.59.10.235:8630       10.59.10.210:58952      TIME_WAIT   -                   tcp        0      0 10.59.10.235:53470      10.59.10.235:8620       TIME_WAIT   -                   tcp        0      0 10.59.10.235:54608      10.59.10.26:8616        TIME_WAIT   -                   tcp        0      0 10.59.10.235:8620       10.59.10.235:53576      TIME_WAIT   -                   tcp        0      0 10.59.10.235:54690      10.59.10.26:8616        TIME_WAIT   -                   tcp        0      0 10.59.10.235:8620       10.59.10.45:40800       TIME_WAIT   -                   tcp        0      0 10.59.10.235:8620       10.59.10.26:60334       TIME_WAIT   -   1 established)     34 ESTABLISHED      1 Foreign     14 LISTEN     50 TIME_WAITPlease find the full analysis in the attachment sectionfor your perusal. Resource Details:-----------------------Name: SPHQ-DB3-20180830Instance ID:  i-0e76e98abf08a1b70Pricate IP: 10.59.10.235AZ: us-east-1bVPC ID: vpc-76df7212------------------------Thanks,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001i9Mdj,Cloud Engineer Level 1,Closed,1111118,Incident,06-02-2019 22:46,,"Hello Mathew,As the alert is still in open state for a while and the disk has a capacity of 8TB and only 6.2 TB is in use, we have just changed the Alert threshold to 90% to resolve the alert.The current Disk utilization is 87%. Kindly check with that from your side.As of now, we don't have any action item pending on this case We are marking this case as closed. Let us know if you have any queries.Thanks###Hello Team This is a quick followup, The alert regarding EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26 still in open state.Please review the details and delete or zip the unused files to resolve this alert.###Hello Team This is a quick followup, The alert regarding EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26 still in open state.Please review the details and delete or zip the unused files to resolve this alert.###Hello Team The alert is triggered by the ISCSI volumes and is still open state. Kindly look into this on priority and delete and/or zip files to free up space. Let us know if you have any queries.###Hello TeamThis is a quick followup,The alert is still in open state with the value of 82.6% of Disk usage.kindly check with the detailed analysis shared with you on the previous comment and delete or zip the unused files to resolve this alert.Let us know if you have any queries.Thanks###Hello Team The alert is triggered by the ISCSI volumes and is still open state. Kindly look into this on priority and delete and/or zip files to free up space. Let us know if you have any queries. Thanks###@Team: Its iSCSI Volume and taken care by SpendHQ team only. Ask them to take care of this.###Hello Team, This is a gentle reminder that the alert is still in open state with the value of 86.4%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage. Thanks###Hello Team, This is a gentle reminder that the alert is still in open state with the value of 85.3%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage. Thanks###Hello Team, This is a gentle reminder that the alert is still in open state with the value of 83.1%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage. Thanks###Hello Team,This is a quick follow up. The alerts regarding EBS High Disk usage for /usr/local/mariadb is still open state with a value 82.9%.Please let us know if you have an update.Regards###Hello Team, This is to inform you that we received an alert for EBS High Disk Usage for the host in production. On checking the details we can see that /usr/local/MariaDB Consuming the high usage. below are the details 6.2T	total1.4T	/usr/local/mariadb/columnstore/data1/000.dir/009.dir1.3T	/usr/local/mariadb/columnstore/data1/000.dir/006.dir1.2T	/usr/local/mariadb/columnstore/data1/000.dir/010.dir1.2T	/usr/local/mariadb/columnstore/data1/000.dir/007.dir929G	/usr/local/mariadb/columnstore/data1/000.dir/008.dir320G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir64G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/035.dir27G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/034.dir25G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/032.dir14G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/059.dir14G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/213.dir13G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/050.dir13G	/usr/local/mariadb/columnstore/data1/000.dir/007.dir/090.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/066.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/057.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/228.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/209.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/161.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/138.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/104.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/055.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/046.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/040.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/038.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/036.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/245.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/188.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/187.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/175.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/173.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/168.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/148.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/146.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/109.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/104.dirPlease check these details and let us know your update. Resources DetailsInstance ID: i-009c4b64628c39954Name: SPHQ-DB1-20180830Ip: 10.59.10.26","[image: Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sda ) -sphq-db1-20180830 - 10.59.10.26High Disk Usage detected on the device /dev/sda@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023969?to_ts=1548339879000&group=device%3A%2Fdev%2Fsda%2Chost%3Ai-009c4b64628c39954&from_ts=1548336279000>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc}by {host,device} * 100 > 80The monitor was last triggered at Thu Jan 24 2019 14:24:49 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fsda%2Chost%3Ai-009c4b64628c39954>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023969/edit>] · [Viewi-009c4b64628c39954<https://app.datadoghq.com/infrastructure?filter=i-009c4b64628c39954>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1548340009000&tags=host%3Ai-009c4b64628c39954&from_ts=1548338989000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4766021623074518858>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26,,24-01-2019 20:45,314,0,SpendHQ,"Hello Mathew,As the alert is still in open state for a while and the disk has a capacity of 8TB and only 6.2 TB is in use, we have just changed the Alert threshold to 90% to resolve the alert.The current Disk utilization is 87%. Kindly check with that from your side.As of now, we don't have any action item pending on this case We are marking this case as closed. Let us know if you have any queries.Thanks","Hello Team This is a quick followup, The alert regarding EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26 still in open state.Please review the details and delete or zip the unused files to resolve this alert.","Hello Team This is a quick followup, The alert regarding EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26 still in open state.Please review the details and delete or zip the unused files to resolve this alert.",Hello Team The alert is triggered by the ISCSI volumes and is still open state. Kindly look into this on priority and delete and/or zip files to free up space. Let us know if you have any queries.,"Hello TeamThis is a quick followup,The alert is still in open state with the value of 82.6% of Disk usage.kindly check with the detailed analysis shared with you on the previous comment and delete or zip the unused files to resolve this alert.Let us know if you have any queries.Thanks",Hello Team The alert is triggered by the ISCSI volumes and is still open state. Kindly look into this on priority and delete and/or zip files to free up space. Let us know if you have any queries. Thanks,@Team: Its iSCSI Volume and taken care by SpendHQ team only. Ask them to take care of this.,"Hello Team, This is a gentle reminder that the alert is still in open state with the value of 86.4%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage. Thanks","Hello Team, This is a gentle reminder that the alert is still in open state with the value of 85.3%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage. Thanks","Hello Team, This is a gentle reminder that the alert is still in open state with the value of 83.1%. Please perform zip/delete for unnecessary files or directories in order to reduce the disk usage. Thanks","Hello Team,This is a quick follow up. The alerts regarding EBS High Disk usage for /usr/local/mariadb is still open state with a value 82.9%.Please let us know if you have an update.Regards","Hello Team, This is to inform you that we received an alert for EBS High Disk Usage for the host in production. On checking the details we can see that /usr/local/MariaDB Consuming the high usage. below are the details 6.2T	total1.4T	/usr/local/mariadb/columnstore/data1/000.dir/009.dir1.3T	/usr/local/mariadb/columnstore/data1/000.dir/006.dir1.2T	/usr/local/mariadb/columnstore/data1/000.dir/010.dir1.2T	/usr/local/mariadb/columnstore/data1/000.dir/007.dir929G	/usr/local/mariadb/columnstore/data1/000.dir/008.dir320G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir64G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/035.dir27G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/034.dir25G	/usr/local/mariadb/columnstore/data1/000.dir/006.dir/032.dir14G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/059.dir14G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/213.dir13G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/050.dir13G	/usr/local/mariadb/columnstore/data1/000.dir/007.dir/090.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/066.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/011.dir/057.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/228.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/209.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/161.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/138.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/104.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/055.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/046.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/040.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/038.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/010.dir/036.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/245.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/188.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/187.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/175.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/173.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/168.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/148.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/146.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/109.dir12G	/usr/local/mariadb/columnstore/data1/000.dir/009.dir/104.dirPlease check these details and let us know your update. Resources DetailsInstance ID: i-009c4b64628c39954Name: SPHQ-DB1-20180830Ip: 10.59.10.26",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Qjdhv,Cloud Engineer Level 1,Closed,1091069,Incident,02-03-2018 07:24,,"Hello Team,We haven't heard back from you,At this time we are marking this case as resolved and closing this case.Please get back to us if you have any further queries.###Hello Dusty,Since we haven't heard back from you.Please review the previous comment.Please let us know whether are we good to close this ticket and let us know if you have any queries.###Hello Dusty,We haven't heard back from you.Please let us know whether are we good to close this ticket and let us know if you have any queries.###Hello Dusty,Thanks for the update.@Justin: As we discussed over the call which was held on 21st Feb, it was confirmed that you were able to access the server 10.59.10.157. Kindly check and let us know in case of any further issues.Regards,Sumod.K.Bose###Thank you,So would you be able to work with Justin to ensure he has connectivity to this machine (the initial email chain)? Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com###Hello All,The public instance i-0aff73c4cca32df0d was launched and the instance details have been shared through the case 01088837, the public comment email notification was sent to spendhq-support@reancloud.com. Later on the same day, we realized some configuration issues with the instance and terminated the instance to launch a new one i-01ced4cc61378d959. The case comment has been modified on the case 01088837 after this change. The comment modification won't send any notification to the email DL so we have to check it from the CMP case itself. This was the reason for the confusion here.Please find the resource details one more time for the clarity.Deleted Instance :~~~~~~~~~~~~~Instance Name: cloneof(Clone of PRD-LG1) Instance ID: i-0aff73c4cca32df0d Private IP: 10.59.1.132 Public IP: 34.227.21.175Existing Instance:~~~~~~~~~~~~~~Instance Name: Cloneof-i-0ed30e530bfccff3b-20180118 Instance ID: i-01ced4cc61378d959 Private IP: 10.59.10.157Please let us know if you have any further queries.--Thanks & Regards,Safuvan KM###Is there a way to audit who shut down the server? The only similar email I have is a request and confirmation to stop the instance 10.59.10.12 (case #I-01089041). I do not believe this instance is running, so I believe the ticket was performed correctly. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hello Matthew,Could you please review this case and help us to identify a solution on this issue?Regards,Sumod.K.Bose###[Dusty updated the case via Email]That is the instance.  I have no clue why it was terminated. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com###Hello Dusty,We could see that this instance(i-01ced4cc61378d959) has been terminated after 24 hours once it was launched. Can you help us to understand which is the exact instance you are searching for? Regards,SUmod.K.Bose###[Dusty updated the case via Email]Here is the details from email sent to us from REAN on 1/17/2018 Hello SpendHQ, Below comment added in reference to the case : I-01088837. Hello Team, We have created a clone the Clone of PRD-LG1 server. Please find the new server details below. Instance Name: cloneof(Clone of PRD-LG1) Instance ID: i-0aff73c4cca32df0d Private IP: 10.59.1.132 Public IP: 34.227.21.175 Kindly validate the server details and let us know if you have any further queries. Case link: https://reancloud.force.com/customers/5000G00001OYIUz You can click on the above link to add your comments or to review the progress. Thank you for your support and patience. REAN Cloud ref:_00DF08Ezf._5000G1OYIUz:ref  Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###Hello Team,This is a gentle reminder, Please review the details mentioned in the previous comment.please let us know if you have any further queries.###Hello SpendHQ-Team,The IP mentioned by Justin (34.227.21.175) belongs to Amazon but we were unable to figure out any resources from SpendHQ AWS Console allocated to this IP address. Could you please check and validate this IP from your end and let us know if this is the correct one which Justin is seeking for. Also, revert back in case of any queries.Regards,sumod.K.Bose###Hello Justin,Thanks for Joining the call.As you have confirmed that you are successfully able to connect VPN and login to the instance 10.59.10.157. Since we couldn't find the IP  (34.227.21.175) from the AWS console, please reach out to Dusty and cross check that IP. Kindly let us know if you need any further assistance from our end.###Hello Justin,Thank you for the update. We have scheduled the call on 20th Feb 2018 at 4 PM EST. Meeting invite has been shared regarding the same. Kindly validate these details and let us know in case of any further queries.Regards,Sumod.K.Bose###Hello Dusty,We acknowledge the delivery of this email. Will work along with Justin to sort this issue at the earliest.@Justin: Could you please let us know your available timings to schedule a call for further discussion on this case.Regards,Sumod.K.Bose","Hello,We have a 3rd party vendor that is having issue connecting to one of our servers.  Would you be able to work with them to troubleshoot the issue?  The machine in question is located at 10.59.10.157.  I have copied the user onto this email.Thanks!Dusty Fowler | Developer | SpendHQ(r)O: 770.628.0026 | dfowler@spendhq.com<mailto:dfowler@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>--  <https://www.reancloud.com/news/rean-cloud-awarded-cloud-contract-department-defense-worth-950-million/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Access to server,,17-02-2018 01:02,318,0,SpendHQ,"Hello Team,We haven't heard back from you,At this time we are marking this case as resolved and closing this case.Please get back to us if you have any further queries.","Hello Dusty,Since we haven't heard back from you.Please review the previous comment.Please let us know whether are we good to close this ticket and let us know if you have any queries.","Hello Dusty,We haven't heard back from you.Please let us know whether are we good to close this ticket and let us know if you have any queries.","Hello Dusty,Thanks for the update.@Justin: As we discussed over the call which was held on 21st Feb, it was confirmed that you were able to access the server 10.59.10.157. Kindly check and let us know in case of any further issues.Regards,Sumod.K.Bose","Thank you,So would you be able to work with Justin to ensure he has connectivity to this machine (the initial email chain)? Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com","Hello All,The public instance i-0aff73c4cca32df0d was launched and the instance details have been shared through the case 01088837, the public comment email notification was sent to spendhq-support@reancloud.com. Later on the same day, we realized some configuration issues with the instance and terminated the instance to launch a new one i-01ced4cc61378d959. The case comment has been modified on the case 01088837 after this change. The comment modification won't send any notification to the email DL so we have to check it from the CMP case itself. This was the reason for the confusion here.Please find the resource details one more time for the clarity.Deleted Instance :~~~~~~~~~~~~~Instance Name: cloneof(Clone of PRD-LG1) Instance ID: i-0aff73c4cca32df0d Private IP: 10.59.1.132 Public IP: 34.227.21.175Existing Instance:~~~~~~~~~~~~~~Instance Name: Cloneof-i-0ed30e530bfccff3b-20180118 Instance ID: i-01ced4cc61378d959 Private IP: 10.59.10.157Please let us know if you have any further queries.--Thanks & Regards,Safuvan KM","Is there a way to audit who shut down the server? The only similar email I have is a request and confirmation to stop the instance 10.59.10.12 (case #I-01089041). I do not believe this instance is running, so I believe the ticket was performed correctly. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Hello Matthew,Could you please review this case and help us to identify a solution on this issue?Regards,Sumod.K.Bose",[Dusty updated the case via Email]That is the instance.  I have no clue why it was terminated. Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com,"Hello Dusty,We could see that this instance(i-01ced4cc61378d959) has been terminated after 24 hours once it was launched. Can you help us to understand which is the exact instance you are searching for? Regards,SUmod.K.Bose","[Dusty updated the case via Email]Here is the details from email sent to us from REAN on 1/17/2018 Hello SpendHQ, Below comment added in reference to the case : I-01088837. Hello Team, We have created a clone the Clone of PRD-LG1 server. Please find the new server details below. Instance Name: cloneof(Clone of PRD-LG1) Instance ID: i-0aff73c4cca32df0d Private IP: 10.59.1.132 Public IP: 34.227.21.175 Kindly validate the server details and let us know if you have any further queries. Case link: https://reancloud.force.com/customers/5000G00001OYIUz You can click on the above link to add your comments or to review the progress. Thank you for your support and patience. REAN Cloud ref:_00DF08Ezf._5000G1OYIUz:ref  Dusty Fowler | Developer | SpendHQ®O: 770.628.0026 | dfowler@spendhq.com A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com","Hello Team,This is a gentle reminder, Please review the details mentioned in the previous comment.please let us know if you have any further queries.","Hello SpendHQ-Team,The IP mentioned by Justin (34.227.21.175) belongs to Amazon but we were unable to figure out any resources from SpendHQ AWS Console allocated to this IP address. Could you please check and validate this IP from your end and let us know if this is the correct one which Justin is seeking for. Also, revert back in case of any queries.Regards,sumod.K.Bose","Hello Justin,Thanks for Joining the call.As you have confirmed that you are successfully able to connect VPN and login to the instance 10.59.10.157. Since we couldn't find the IP  (34.227.21.175) from the AWS console, please reach out to Dusty and cross check that IP. Kindly let us know if you need any further assistance from our end.","Hello Justin,Thank you for the update. We have scheduled the call on 20th Feb 2018 at 4 PM EST. Meeting invite has been shared regarding the same. Kindly validate these details and let us know in case of any further queries.Regards,Sumod.K.Bose","Hello Dusty,We acknowledge the delivery of this email. Will work along with Justin to sort this issue at the earliest.@Justin: Could you please let us know your available timings to schedule a call for further discussion on this case.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hPrtQ,Cloud Engineer Level 1,Closed,1110024,Incident,31-12-2018 00:32,,"Revathy Kurup*********************************************************Hello Matthew,Thanks for the update. We are marking this case as closed.###Matthew Wattsto Rean, spendhq-support@reancloud.com*********************************************************8We can close this case###Hello Team,This is a quick follow up. Please review our analysis on the alert high network out alerts on the host SPHQ-DB4-20180830.Please let us know if you have any queries regarding the same.###Hello Team,This is a gentle reminder regarding high network out alerts on the host SPHQ-DB4-20180830.Please review our analysis and please us know your thought regarding the ticket.###Hello Team,We would like to inform you that we have received multiple high network out alerts on the host SPHQ-DB4-20180830Currently the alert has crossed the set threshold of 1.1Gb/min and is currently at a value of 1.61Gb/min.Please find attached the current number of open tcp connections.Resource Details:Instance ID:	i-082d412700b276f44	Instance Name: 	SPHQ-DB4-20180830	Instance Type: 	r4.8xlarge	Account:  	SpendHQ	Availability Zone:	us-east-1b	Region:	us-east-1Subnet:	subnet-0fdde924	VPC: 	vpc-76df7212Private IP Address: 	10.59.10.210","[image: Datadog][Triggered] [SpendHQ] - High Network OUT on host - sphq-db4-20180830 -10.59.10.210 -High Network OUT on the instance. Please check the list open TCPConnections@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2024199?to_ts=1546034429000&group=host%3Ai-082d412700b276f44&from_ts=1546027229000>*aws.ec2.network_out* over *datadog_monitor:on,host:i-082d412700b276f44*was *> 1100000000.0* at all times during the *last 30m*.The monitor was last triggered at Fri Dec 28 2018 22:00:39 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2024199?group=host%3Ai-082d412700b276f44>]· [Edit Monitor <https://app.datadoghq.com/monitors#2024199/edit>] · [Viewi-082d412700b276f44<https://app.datadoghq.com/infrastructure?filter=i-082d412700b276f44>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1546034559000&tags=host%3Ai-082d412700b276f44&from_ts=1546033539000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4727342577612750633>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.---- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High Network OUT on host - sphq-db4-20180830 - 10.59.10.210 -,,29-12-2018 04:01,45,0,SpendHQ,"Revathy Kurup*********************************************************Hello Matthew,Thanks for the update. We are marking this case as closed.","Matthew Wattsto Rean, spendhq-support@reancloud.com*********************************************************8We can close this case","Hello Team,This is a quick follow up. Please review our analysis on the alert high network out alerts on the host SPHQ-DB4-20180830.Please let us know if you have any queries regarding the same.","Hello Team,This is a gentle reminder regarding high network out alerts on the host SPHQ-DB4-20180830.Please review our analysis and please us know your thought regarding the ticket.","Hello Team,We would like to inform you that we have received multiple high network out alerts on the host SPHQ-DB4-20180830Currently the alert has crossed the set threshold of 1.1Gb/min and is currently at a value of 1.61Gb/min.Please find attached the current number of open tcp connections.Resource Details:Instance ID:	i-082d412700b276f44	Instance Name: 	SPHQ-DB4-20180830	Instance Type: 	r4.8xlarge	Account:  	SpendHQ	Availability Zone:	us-east-1b	Region:	us-east-1Subnet:	subnet-0fdde924	VPC: 	vpc-76df7212Private IP Address: 	10.59.10.210",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014olHi,Cloud Engineer Level 1,Closed,1035938,Incident,03-12-2016 06:45,,We are closing this ticket as we are following in change ticket.,"What is the status and ETA's of the snaphots?Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Snapshot Status,,03-12-2016 06:18,0,0,SpendHQ,We are closing this ticket as we are following in change ticket.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ddfDZ,Cloud Engineer Level 3,Closed,1106652,Incident,26-10-2018 22:12,,"Hello Team,We haven't heard back from you regarding the case  Detected Error on SpendHQ Preview for a while. For continued support regarding the same issue, you can contact us any time.At this time, we're marking this case as closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,Rafi RameshPune India###Please sent a final follow up on Tmorrow.###Hello Team, We haven't heard back from you on the analysis we shared.Please find time to go through and let us know if you have any queries/concerns. Thanks.###Hello Team,This is the gentle reminder.Could you please let us know if you have any queries related to it.###Hello Team,We haven't heard back from you, please look into our previously shared analysis to this alert and let us know if you have any queries/concerns.Thanks.###Hello Team,From our analysis we could see that there were spikes in the ELB Requst count and average latency metrics during the time of the alert.We also identified spikes in Network in Metrics on the backend instance during the time of the alert.Checking from instance level we could also see that the httpd process was terminated due to out of memory. Below are the system event logs:Oct 23 18:20:35 ip-10-59-101-6 kernel: Out of memory: Kill process 27467 (httpd) score 124 or sacrifice childOct 23 18:20:35 ip-10-59-101-6 kernel: Killed process 27467, UID 48, (httpd) total-vm:4447616kB, anon-rss:4073228kB, file-rss:1016kBOct 23 19:07:55 ip-10-59-101-6 kernel: httpd invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0Oct 23 19:07:55 ip-10-59-101-6 kernel: httpd cpuset=/ mems_allowed=0Oct 23 19:07:55 ip-10-59-101-6 kernel: Out of memory: Kill process 27451 (httpd) score 160 or sacrifice childOct 23 19:07:55 ip-10-59-101-6 kernel: Killed process 27451, UID 48, (httpd) total-vm:5648820kB, anon-rss:5276072kB, file-rss:92Oct 23 19:08:02 ip-10-59-101-6 kernel: Out of memory: Kill process 26753 (httpd) score 249 or sacrifice childOct 23 19:08:02 ip-10-59-101-6 kernel: Killed process 26753, UID 48, (httpd) total-vm:8545576kB, anon-rss:8170972kB, file-rss:960kBWe have attached the screenshots to the Cloudwatch Metrics mentioned above from console level.Please check and validate these details and also feel free to reach out to us if you have any concerns.Thanks.###Hello Team, This is to notify you that we have received an alert regarding Detected Error on SpendHQ Preview URL: https://preview.spendhq.com/login.As of the moment, the alert has recovered and the violation lasted for about 2 min. We are checking more on this and will let you know the update.","Tue, 23 Oct 2018 14:53:53 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30009 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): California US, London UK, Dallas-B US, Sydney-C AU",Detected Error on SpendHQ Preview,,24-10-2018 00:28,70,0,SpendHQ,"Hello Team,We haven't heard back from you regarding the case  Detected Error on SpendHQ Preview for a while. For continued support regarding the same issue, you can contact us any time.At this time, we're marking this case as closed. However, if you're still experiencing issues, we want to hear from you! Please re-open this case for continued support. Please let us know if we resolved your issue.Regards,Rafi RameshPune India",Please sent a final follow up on Tmorrow.,"Hello Team, We haven't heard back from you on the analysis we shared.Please find time to go through and let us know if you have any queries/concerns. Thanks.","Hello Team,This is the gentle reminder.Could you please let us know if you have any queries related to it.","Hello Team,We haven't heard back from you, please look into our previously shared analysis to this alert and let us know if you have any queries/concerns.Thanks.","Hello Team,From our analysis we could see that there were spikes in the ELB Requst count and average latency metrics during the time of the alert.We also identified spikes in Network in Metrics on the backend instance during the time of the alert.Checking from instance level we could also see that the httpd process was terminated due to out of memory. Below are the system event logs:Oct 23 18:20:35 ip-10-59-101-6 kernel: Out of memory: Kill process 27467 (httpd) score 124 or sacrifice childOct 23 18:20:35 ip-10-59-101-6 kernel: Killed process 27467, UID 48, (httpd) total-vm:4447616kB, anon-rss:4073228kB, file-rss:1016kBOct 23 19:07:55 ip-10-59-101-6 kernel: httpd invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0Oct 23 19:07:55 ip-10-59-101-6 kernel: httpd cpuset=/ mems_allowed=0Oct 23 19:07:55 ip-10-59-101-6 kernel: Out of memory: Kill process 27451 (httpd) score 160 or sacrifice childOct 23 19:07:55 ip-10-59-101-6 kernel: Killed process 27451, UID 48, (httpd) total-vm:5648820kB, anon-rss:5276072kB, file-rss:92Oct 23 19:08:02 ip-10-59-101-6 kernel: Out of memory: Kill process 26753 (httpd) score 249 or sacrifice childOct 23 19:08:02 ip-10-59-101-6 kernel: Killed process 26753, UID 48, (httpd) total-vm:8545576kB, anon-rss:8170972kB, file-rss:960kBWe have attached the screenshots to the Cloudwatch Metrics mentioned above from console level.Please check and validate these details and also feel free to reach out to us if you have any concerns.Thanks.","Hello Team, This is to notify you that we have received an alert regarding Detected Error on SpendHQ Preview URL: https://preview.spendhq.com/login.As of the moment, the alert has recovered and the violation lasted for about 2 min. We are checking more on this and will let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ETIPm,Cloud Engineer Level 1,Closed,1067281,Incident,,,,"[Triggered] [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db  Detected High CPU load. Log in to the machine and verify which process is consuming high CPU resources    @support@reancloud.comsystem.load.15 over host:10.59.10.135,monitoring:on was > 3.0 on average during the last 5m.Metric value: 3.081This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023975?group=host%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023975/edit · Event URL: https://app.datadoghq.com/event/event?id=3949415429958051285 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - High CPU Load prod-sphq-db-server05 - 10.59.10.135 - db,,10-07-2017 11:29,0,0,SpendHQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ErcnS,Cloud Engineer Level 1,Closed,1068985,Incident,21-07-2017 21:56,,"Hello Team,Thanks for the confirmation. At this time we are marking  this case as resolved.###Hello, We have reviewed the S3 buckets, and all 3 buckets should be permitted for public read only access. This case may be closed. Thank you, Andrew Kim###Hello Team,Just a quick follow up.We were able to list down 3 buckets in your account which are permitted to be accessed by any public users. Please find the list of buckets below. > spendhq-assets > secure.spendhq.com > preview.spendhq.com On checking the bucket contents we could see bucket :spendhq-assets contains mp4, image files. The bucket secure.spendhq.com is having css files, html and image files.The preview.spendhq.com is also having the similar site related contents.Please note that there have been public disclosures by third parties of S3 bucket contents that were inadvertently configured to allow world read access but were not intended to be publicly available.Please review the bucket permissions as they are configured to allow world read access. Consider this as high priority and let us know whether we can go ahead remove the public availability.###Hello Team,This is a quick follow up. Please review your S3 buckets mentioned and their contents as they are configured to allow world read access. Consider this as high priority and let us know whether we can go ahead remove the public availability.###Next Action: Morning Shift Team: Check if we receive any updates from the customer else send a reminder email during evening shift hours.###Hello Team, This is to notify you that we have received an alert from AWS stating that one or more of the Amazon S3 bucket access control lists (ACLs) in Spendhq account are currently configured to allow access from any user on the Internet. On analysis, We were able to list down 3 buckets in your account which are permitted to be accessed by any public users. Please find the list of buckets below.> spendhq-assets > secure.spendhq.com > preview.spendhq.comPlease note that there have been public disclosures by third parties of S3 bucket contents that were inadvertently configured to allow world read access but were not intended to be publicly available. We encourage you to promptly review your S3 buckets and their contents to ensure that you are not inadvertently making objects available to users that you don’t intend. Please let us know if you have any more queries.","Thank You,Sanket DangiOn Thu, Jul 20, 2017 at 2:49 AM, Amazon Web Services, Inc. <no-reply-aws@amazon.com> wrote:> Hello,>> We're writing to remind you that one or more of your Amazon S3 bucket> access control lists (ACLs) are currently configured to allow read access> from any user on the Internet. The list of buckets with this configuration> is below.>> By default, S3 bucket ACLs allow only the account owner to list the bucket> or write/delete objects; however, these ACLs can be configured to permit> public read access. While there are reasons to configure buckets with> public read access, including public websites or publicly downloadable> content, recently there have been public disclosures by third parties of S3> bucket contents that were inadvertently configured to allow public read> access but were not intended to be publicly available.>> We encourage you to promptly review your S3 buckets and their contents to> ensure that you are not inadvertently making objects visible to users that> you don't intend. Bucket ACLs can be reviewed in the AWS Management Console> (http://console.aws.amazon.com ), or using the AWS CLI tools. ACLs> permitting All Users grant public read access to the related content.>> For more information on configuring your bucket ACLs, please visit:> https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html>> For additional assistance reviewing your bucket ACLs, please visit> http://aws.amazon.com/support to create a case with AWS Developer Support.>> Your list of buckets configured to allow read access from anyone on the> Internet are:>> spendhq-assets> secure.spendhq.com> preview.spendhq.com>> Sincerely,> Amazon Web Services>> Amazon Web Services, Inc. is a subsidiary of Amazon.com, Inc. Amazon.com> is a registered trademark of Amazon.com, Inc. This message was produced and> distributed by Amazon Web Services Inc., 410 Terry Ave. North, Seattle, WA> 98109-5210-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Re: Securing Amazon S3 Buckets,,20-07-2017 13:02,33,0,SpendHQ,"Hello Team,Thanks for the confirmation. At this time we are marking  this case as resolved.","Hello, We have reviewed the S3 buckets, and all 3 buckets should be permitted for public read only access. This case may be closed. Thank you, Andrew Kim","Hello Team,Just a quick follow up.We were able to list down 3 buckets in your account which are permitted to be accessed by any public users. Please find the list of buckets below. > spendhq-assets > secure.spendhq.com > preview.spendhq.com On checking the bucket contents we could see bucket :spendhq-assets contains mp4, image files. The bucket secure.spendhq.com is having css files, html and image files.The preview.spendhq.com is also having the similar site related contents.Please note that there have been public disclosures by third parties of S3 bucket contents that were inadvertently configured to allow world read access but were not intended to be publicly available.Please review the bucket permissions as they are configured to allow world read access. Consider this as high priority and let us know whether we can go ahead remove the public availability.","Hello Team,This is a quick follow up. Please review your S3 buckets mentioned and their contents as they are configured to allow world read access. Consider this as high priority and let us know whether we can go ahead remove the public availability.",Next Action: Morning Shift Team: Check if we receive any updates from the customer else send a reminder email during evening shift hours.,"Hello Team, This is to notify you that we have received an alert from AWS stating that one or more of the Amazon S3 bucket access control lists (ACLs) in Spendhq account are currently configured to allow access from any user on the Internet. On analysis, We were able to list down 3 buckets in your account which are permitted to be accessed by any public users. Please find the list of buckets below.> spendhq-assets > secure.spendhq.com > preview.spendhq.comPlease note that there have been public disclosures by third parties of S3 bucket contents that were inadvertently configured to allow world read access but were not intended to be publicly available. We encourage you to promptly review your S3 buckets and their contents to ensure that you are not inadvertently making objects available to users that you don’t intend. Please let us know if you have any more queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FcGn8,Cloud Engineer Level 1,Closed,1072167,Incident,09-08-2017 19:43,,"Hello Matthew,We haven't heard back from you.At this time we are marking this case as closed. However, if you have any further queries regarding this we want to hear back from you. You can re-open the case any time by sending an email back to us. Thank You.###Hello Matthew,We haven't heard back from you.Please review the comments and let us know if you have any further queries regarding this.###Hi Matthew,We launched the newly cloned server(10.59.101.6) in 10.59.101.0/24 subnet to make sure both instances are in different availability zones.As they are behind an ELB and traffic is equally distributed, Keeping both instances in different availability zone will help us achieve High Availability. In the HA scenario if one complete AZs goes down ELB will still route the traffic to the instance in another Availability Zone.Please let us know if you have additional questions. Thanks###This case is a follow up for 01071363.Since we have closed 01071363, the below comments are communicated over email.Next action: Need to check with Yogesh for identifying the reason why we launched the instance in 101 subnet.###Hi Matthew,I will check this with our internal team and will get back to you with details.###Hello Matthew, As per the request, we have also cloned the 10.59.100.122 server and have attached it under the new internal ELB. Refer the new server resource details below, Resource Details:- Instance Name: 10.59.100.122 - Clone-3rdAug2017 Instance ID: i-01ac95c23ac66a40e Instance type: c4.2xlarge Availability zone: us-east-1c Private IPs: 10.59.101.6###Why is the IP on the 101 subnet?",What is the IP of the newly cloned server of 10.59.100.122 that is behind the load balancer?,Load Balancer,,08-08-2017 04:06,40,0,SpendHQ,"Hello Matthew,We haven't heard back from you.At this time we are marking this case as closed. However, if you have any further queries regarding this we want to hear back from you. You can re-open the case any time by sending an email back to us. Thank You.","Hello Matthew,We haven't heard back from you.Please review the comments and let us know if you have any further queries regarding this.","Hi Matthew,We launched the newly cloned server(10.59.101.6) in 10.59.101.0/24 subnet to make sure both instances are in different availability zones.As they are behind an ELB and traffic is equally distributed, Keeping both instances in different availability zone will help us achieve High Availability. In the HA scenario if one complete AZs goes down ELB will still route the traffic to the instance in another Availability Zone.Please let us know if you have additional questions. Thanks","This case is a follow up for 01071363.Since we have closed 01071363, the below comments are communicated over email.Next action: Need to check with Yogesh for identifying the reason why we launched the instance in 101 subnet.","Hi Matthew,I will check this with our internal team and will get back to you with details.","Hello Matthew, As per the request, we have also cloned the 10.59.100.122 server and have attached it under the new internal ELB. Refer the new server resource details below, Resource Details:- Instance Name: 10.59.100.122 - Clone-3rdAug2017 Instance ID: i-01ac95c23ac66a40e Instance type: c4.2xlarge Availability zone: us-east-1c Private IPs: 10.59.101.6",Why is the IP on the 101 subnet?,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001SeaWZ,Cloud Engineer Level 1,Closed,1092996,Incident,13-03-2018 02:53,,"Thank you. This case can be closed.###Hello Andrew,We have disabled the user account sng from AWS.Please let us know if you have any queires.###Hello Andrew,We have disabled the user account sng from the Sophos. Please let us know if you have any concerns.###Hello Andrew,We will work on this request and will get back to you.Regards,Safuvan KM","Please Disable Steven Ng’s (sng) account. This should include his SohposVPN account.Thank you,*Andrew Kim* | Director of Information Technology & Security | *Spend**HQ®*O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Please Disable Steven Ng's account,,12-03-2018 19:40,13,0,SpendHQ,Thank you. This case can be closed.,"Hello Andrew,We have disabled the user account sng from AWS.Please let us know if you have any queires.","Hello Andrew,We have disabled the user account sng from the Sophos. Please let us know if you have any concerns.","Hello Andrew,We will work on this request and will get back to you.Regards,Safuvan KM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001cHdG1,Cloud Engineer Level 1,Closed,1105277,Incident,02-10-2018 07:03,,"Hello Team, We are closing the ticket as no action was performed from your end.However, if the ticket is closed erroneously, feel free to reopen the ticket. You can always to reach out to us at support@reancloud.com for any additional queries.###Hello Team, This is a gentle reminder. Please have a look at our analysis shared with you. kindly check the configuration files and update us back if you had made any changes to the certificate files.###Hello Team,This is a gentle reminder.Please have a look at our analysis shared with you. kindly check the configuration files and update us back if you had made any changes to the certificate files.###Hello Team, On further analysis, We could see, At the time of alert the Apache process got SIGTERM in the logs show it was trying to restart Apache but Apache shut down.--------------------------------------------------------------------------[root@ip-10-59-100-170 httpd]# cat error_log[Sun Sep 23 03:49:07 2018] [notice] Digest: generating secret for digest authentication ...[Sun Sep 23 03:49:07 2018] [notice] Digest: done[Sun Sep 23 03:49:07 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Sun Sep 23 03:49:07 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations[Thu Sep 27 15:10:46 2018] [notice] caught SIGTERM, shutting down(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs[Thu Sep 27 15:21:12 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Thu Sep 27 15:21:12 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Thu Sep 27 15:21:12 2018] [notice] Digest: generating secret for digest authentication ...[Thu Sep 27 15:21:12 2018] [notice] Digest: done[Thu Sep 27 15:21:12 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Thu Sep 27 15:21:12 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations----------------------------------------------------------------------------We could Also find that there is some certificate relate errors from the logs. kindly check the configuration files and update us back if you had made any changes to the certificate files.---------------------------------------------- [Thu Sep 27 15:21:12 2018] [warn] RSA server certificate CommonName (CN) `secure.spendhq.com' does NOT match server name!? [Thu Sep 27 15:21:12 2018] [warn] RSA server certificate CommonName (CN) `secure.spendhq.com' does NOT match server name!?------------------------------------------###@Team:SIGTERM in the logs show it was trying to restart Apache but Apache shut down.The entries in the logs resembles to some changes made to the certificate. As this is a preview.spendhq.com and when we checked the vhosts logs it is giving the certificate does not match the server name.Please share the logs with customer to check further in the configuration if they have made any changes recently.###Morning ops call Rohit mentioned he will review the analysis and will update.###Hello Team,We are actively working on this issue and will provide an update ASAP###@TeamI went ahead and checked the /var/www/vhosts/files.spendhq.com/w2/logs directory and under this file  web2-https-secure.spendhq.com-error.log found this error:[Thu Sep 27 15:21:12 2018] [warn] RSA server certificate CommonName (CN) `secure.spendhq.com' does NOT match server name!?[Thu Sep 27 15:21:12 2018] [warn] RSA server certificate CommonName (CN) `secure.spendhq.com' does NOT match server name!?Besides this and what @Isaac had shared previously, there wasn't much to report on.###Team,I have checked and noticed that there was a SIGTERM signal and httpd was shutdown:[Thu Sep 27 15:10:46 2018] [notice] caught SIGTERM, shutting down(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs[Thu Sep 27 15:21:12 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Thu Sep 27 15:21:12 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Thu Sep 27 15:21:12 2018] [notice] Digest: generating secret for digest authentication ...[Thu Sep 27 15:21:12 2018] [notice] Digest: done[Thu Sep 27 15:21:12 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Thu Sep 27 15:21:12 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operationsPlease check further###Critical P1 - Detected Error on SpendHQ - RecoveredRafi Ramesh <rafi.ramesh@reancloud.com>9:02 PM (0 minutes ago)to MGSHi, Leads,We have encountered a P1 issue. Below are the details of the issueCustomer Name: SpendHQOpen date/time: 8:24PM ISTIssue Summary/Details: Detected Error on SpendHQ - RecoveredOwner: Rafi RameshStatus: RecoveredAction/s Taken: We are analyzing on this.###Hello Team,This is to inform you that we go site down alert for the URL: https://preview.spendhq.com/loginwe analyzing the issue and get back to you with an update.meanwhile please let us know if you are performing any activity from your end.Thank you.","---------- Forwarded message ---------From: <ms@reancloud.com>Date: Thu, Sep 27, 2018 at 8:42 PMSubject: Detected Error on SpendHQ PreviewTo: <ms@reancloud.com>Thu, 27 Sep 2018 11:11:59 -0400Detected Error on SpendHQ PreviewEstimated Downtime: 59 secondshttps://www.wormly.com/edithost/hostid/59890--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 200Wanted string: SpendHQ not found in response.Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring:Reported by node: Atlanta-B USConfirmed by node(s): Sydney-C AU, Dallas-B US, New Jersey US, London UK-- *Thank You,**        Rafi R*--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Preview,,27-09-2018 20:44,106,0,SpendHQ,"Hello Team, We are closing the ticket as no action was performed from your end.However, if the ticket is closed erroneously, feel free to reopen the ticket. You can always to reach out to us at support@reancloud.com for any additional queries.","Hello Team, This is a gentle reminder. Please have a look at our analysis shared with you. kindly check the configuration files and update us back if you had made any changes to the certificate files.","Hello Team,This is a gentle reminder.Please have a look at our analysis shared with you. kindly check the configuration files and update us back if you had made any changes to the certificate files.","Hello Team, On further analysis, We could see, At the time of alert the Apache process got SIGTERM in the logs show it was trying to restart Apache but Apache shut down.--------------------------------------------------------------------------[root@ip-10-59-100-170 httpd]# cat error_log[Sun Sep 23 03:49:07 2018] [notice] Digest: generating secret for digest authentication ...[Sun Sep 23 03:49:07 2018] [notice] Digest: done[Sun Sep 23 03:49:07 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Sun Sep 23 03:49:07 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations[Thu Sep 27 15:10:46 2018] [notice] caught SIGTERM, shutting down(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs[Thu Sep 27 15:21:12 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Thu Sep 27 15:21:12 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Thu Sep 27 15:21:12 2018] [notice] Digest: generating secret for digest authentication ...[Thu Sep 27 15:21:12 2018] [notice] Digest: done[Thu Sep 27 15:21:12 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Thu Sep 27 15:21:12 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operations----------------------------------------------------------------------------We could Also find that there is some certificate relate errors from the logs. kindly check the configuration files and update us back if you had made any changes to the certificate files.---------------------------------------------- [Thu Sep 27 15:21:12 2018] [warn] RSA server certificate CommonName (CN) `secure.spendhq.com' does NOT match server name!? [Thu Sep 27 15:21:12 2018] [warn] RSA server certificate CommonName (CN) `secure.spendhq.com' does NOT match server name!?------------------------------------------",@Team:SIGTERM in the logs show it was trying to restart Apache but Apache shut down.The entries in the logs resembles to some changes made to the certificate. As this is a preview.spendhq.com and when we checked the vhosts logs it is giving the certificate does not match the server name.Please share the logs with customer to check further in the configuration if they have made any changes recently.,Morning ops call Rohit mentioned he will review the analysis and will update.,"Hello Team,We are actively working on this issue and will provide an update ASAP","@TeamI went ahead and checked the /var/www/vhosts/files.spendhq.com/w2/logs directory and under this file  web2-https-secure.spendhq.com-error.log found this error:[Thu Sep 27 15:21:12 2018] [warn] RSA server certificate CommonName (CN) `secure.spendhq.com' does NOT match server name!?[Thu Sep 27 15:21:12 2018] [warn] RSA server certificate CommonName (CN) `secure.spendhq.com' does NOT match server name!?Besides this and what @Isaac had shared previously, there wasn't much to report on.","Team,I have checked and noticed that there was a SIGTERM signal and httpd was shutdown:[Thu Sep 27 15:10:46 2018] [notice] caught SIGTERM, shutting down(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs(2)No such file or directory: httpd: could not open error log file /var/www/vhosts/files.spendhq.com/w2/logs/web2-https-secure.spendhq.com-error.log.Unable to open logs[Thu Sep 27 15:21:12 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Thu Sep 27 15:21:12 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Thu Sep 27 15:21:12 2018] [notice] Digest: generating secret for digest authentication ...[Thu Sep 27 15:21:12 2018] [notice] Digest: done[Thu Sep 27 15:21:12 2018] [warn] Init: Name-based SSL virtual hosts only work for clients with TLS server name indication support (RFC 4366)[Thu Sep 27 15:21:12 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operationsPlease check further","Critical P1 - Detected Error on SpendHQ - RecoveredRafi Ramesh <rafi.ramesh@reancloud.com>9:02 PM (0 minutes ago)to MGSHi, Leads,We have encountered a P1 issue. Below are the details of the issueCustomer Name: SpendHQOpen date/time: 8:24PM ISTIssue Summary/Details: Detected Error on SpendHQ - RecoveredOwner: Rafi RameshStatus: RecoveredAction/s Taken: We are analyzing on this.","Hello Team,This is to inform you that we go site down alert for the URL: https://preview.spendhq.com/loginwe analyzing the issue and get back to you with an update.meanwhile please let us know if you are performing any activity from your end.Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5000G00001bmg4r,Cloud Engineer Level 1,Closed,1105045,Incident,21-09-2018 22:57,,Following this case on : 01105047hence closing this case,"Starting at 7:23 AM PDT we began to experience elevated network latency, impacting AWS Direct Connect connectivity to the US-EAST-1 Region. We are investigating the issue. For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_DIRECTCONNECT_CONNECTIVITY_ISSUE,,21-09-2018 21:24,2,0,SpendHQ,Following this case on : 01105047hence closing this case,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001lQNVH,Cloud Engineer Level 1,Closed,1112968,Incident,11-03-2019 08:36,,"Hello Team,This is to inform you that EBS high Disk usage alert for /dev/sda disk on sphq-db1-20180830 server (10.59.10.26) got recovered.Current utilization is 80.2%As of now, we are marking this case resolved. Feel free to reopen if you have any related queries.###Current value: 91.7###Hello David, This is a quick follow up! Please review the previous comment because the alert is in a still open state with current EBS disk usage is 91.7%. Thanks.###Hello TeamThe alert is still in open state with the value of 92%--------[root@ip-10-59-10-26 data1]# df -Th | grep /dev/sda/dev/sda       ext4      8.0T  7.0T  693G  92% /usr/local/mariadb[root@ip-10-59-10-26 data1]# ---------We have further analyzed this alert and could see that the files under the directory /usr/local/mariadb/columnstore/data contains the largest files. Below are the details of the top 20 largest size files under this directory.--------------[root@ip-10-59-10-26 data1]# sudo du -ah . | sort -n -r | head -n 20991M	./000.dir/007.dir/068.dir956M	./000.dir/007.dir/049.dir929M	./000.dir/009.dir/188.dir921M	./000.dir/008.dir/125.dir907M	./000.dir/006.dir/035.dir/051.dir891M	./000.dir/006.dir/241.dir878M	./000.dir/010.dir/027.dir867M	./000.dir/006.dir/035.dir/072.dir864M	./000.dir/010.dir/193.dir861M	./000.dir/009.dir/083.dir858M	./000.dir/006.dir/032.dir/138.dir856M	./000.dir/008.dir/162.dir844K	./000.dir/012.dir/182.dir/029.dir/002.dir844K	./000.dir/012.dir/182.dir/029.dir/001.dir844K	./000.dir/012.dir/182.dir/029.dir/000.dir844K	./000.dir/012.dir/138.dir/052.dir/002.dir844K	./000.dir/012.dir/138.dir/052.dir/001.dir844K	./000.dir/012.dir/138.dir/052.dir/000.dir844K	./000.dir/011.dir/048.dir/036.dir/002.dir844K	./000.dir/011.dir/048.dir/036.dir/001.dir==============Kindly check with the analysis and delete and/or zip unwanted files to resolve this alert.Let us know if you have any queries.Thanks###Hello Team This is to notify you that we have received an EBS high Disk usage alert for the sphq-db1-20180830 - 10.59.10.26The current disk utilization is 90.23%. We will fetch the disk usage details and will get back to you. Regards","________________________________From: Datadog Alerting <alert@dtdg.co>Sent: 07 March 2019 22:01To: REAN Managed ServicesSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26***** EXTERNAL EMAIL *****[Datadog][Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26High Disk Usage detected on the device /dev/sda   @rean_ms@hitachivantara.com[Metric Graph]<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUojdS6ryQNaqk7yrL9FyLrV3alqsDcsezjbdHwWGX2Une9-2B5txHiAzsOxOiS2r-2F6Qu4q4S5BaFVYTP61lrxMn5g2wHSEnZpCCLPAgaI9Qkzi-2BEyRA4wfgFswB9kmGM5yc27I3NIlwObNcWiPT9rcIuEA-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33c30XidHKL-2BRfUBxvq9-2FW1QiF-2FPYfNre3FspB2EKZOwFhZYZH05w1QPOb-2Bq9KmM9RlFiDdLuM-2FvQ08qjkW-2Fpo4Q8ocDUH9rvZhTEk1FA38AvAAtFCbRmHHj00JUDJ2cVdkECDZK8ClXIbfkppeivi6-2FLNdtxoBQF-2F7OQZedoLgJ9l9g7g87JeJCxeI9B-2FyYbdqNHXnYKBu829Tj6sjrD50&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cb99dcb16ddc94a6d445e08d6a31a68a8%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=Z8Jr7HnqdU7sRo5a9jHL5Seokf6FNqQAq8P1X6edsNk%3D&reserved=0>avg(last_5m):avg:system.disk.in_use{datadog_monitor:on,!host:i-03ccfddd9f02cacb9,!device:/dev/sdc} by {host,device} * 100 > 90The monitor was last triggered at Thu Mar 07 2019 16:31:49 UTC (2 secs ago).________________________________[Monitor Status<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUoKvcGnAzkyStJKdzb6NVcA5t2M-2BrFxoMN2TmHLeZCbSa8AYoFnJPzhQsfotJyWIEOwpdY6qar2OvVL9gKeG85Rw-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33c30XidHKL-2BRfUBxvq9-2FW1QiF-2FPYfNre3FspB2EKZOwNwTxvgNoajV89AZTrJP78k-2FfeUmd-2BjxBAVICD32SZCd3TVDtJpkuTJizVo-2FbbXGXpmP0f5MGwzsRURdu0ewKjKRrvYUa18addPMdXYCpG1-2Fvbkzvsre-2F3PhBoVm8Yk-2BOPc-2BXqqEe8KNA-2Fp9fMBq29bZoF4GwldOVt3L4505JxkK&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cb99dcb16ddc94a6d445e08d6a31a68a8%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=dTtnHcgrHWOMzVaglcV1jCQmrgi0GMpjjY7w2ULcitM%3D&reserved=0>] · [Edit Monitor<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAA-2F9Hmpx-2FSw-2FPFn-2FGnEHUo3IM-2FbEP-2FJM89epazZbNBUA-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33c30XidHKL-2BRfUBxvq9-2FW1QiF-2FPYfNre3FspB2EKZOwD8mnfUPQyPrW7DIGykoX5JEQV-2FvWBRxrcdhL-2FWhDzYiO8dIn8Yh2yAIJHHwAFcGURVGQrFGLqZdUwRBzLN4tAlqbp2rwNY7pLfAOT2rJ91a9aqejFZd6WgZvnUAl5RNH4oTbHS2n3DPQPBHkOnthlfdUFL4HWXik-2FqiVbdt0zzJ&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cb99dcb16ddc94a6d445e08d6a31a68a8%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=YL7g4ahmqMq1qaKxmvCpfS0oiFUNV1KnGPVf0Xae6IU%3D&reserved=0>] · [View i-009c4b64628c39954<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEDKT1NZt0tnkwEaAxSQZgju0vyJXQkH1ijIgP0bgTjT4nZOqaAoOXNpNmNd2gLu9R8-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33c30XidHKL-2BRfUBxvq9-2FW1QiF-2FPYfNre3FspB2EKZOwIsnMQ1L2Q8tmVvOBr93aEHRUSIVuW2-2FWENP4yPuEbYNnhz0yts9MEEYzAgaVl4WHKk7G2HFr1VJTz5io886CAqGZkJJeqJ4Z8jeqT8hE-2BIP8ZBNKzwcTEgO1GivU36a1yIjmcVvvn95JgmpXzGMCCRDEi8MLJouS6cJWqKuzO-2FW&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cb99dcb16ddc94a6d445e08d6a31a68a8%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=8qk3SWbll%2BE9ouUVn3oRzOiViPmSMU3NPgqQwxniHP4%3D&reserved=0>] · [Show Processes<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQED-2FFPDBbKPsalSo1i1ufo6S-2FX4pKstbDP3BrKs5ghv715-2BYzccpMFhkg9ta9cXq6EHwp-2Bt4SYVJWNLZfm6OfCOazCiaPp9ZfjXhy9DpD9iHerGBxn2fKNEHycysoCGPL5aO9jNZD-2BHzyTljxkoyGTFRW5S4qy91rLj2dA4WlaNSo6N0LtF2ObsGEzm4tPCO-2BO4-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33c30XidHKL-2BRfUBxvq9-2FW1QiF-2FPYfNre3FspB2EKZOwBR-2FFoJ-2FgGUaJuLhOp1Y2zwJUYsqgkjJb2ua1fQ-2BW965hD1eHE5Gy9WKYU7JNWeUljdw-2BQhybEUIYThqg-2BFDUGMpQ4uk2gQkOjp8w6Q12ups7lv5VETjEBJUWyubt2Qi-2Fd7ixhDBDaejosVKlDRLMva6U1F25wTWGyHuNsT9QXxv&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cb99dcb16ddc94a6d445e08d6a31a68a8%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=PEkgpdPBFaO8hrTXCP%2FvN8T2IUcSEdRjUWHSVLq1GCM%3D&reserved=0>]This alert was raised by account SpendHQComment in Datadog<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQEAYJwPp8omKJuncXDFvQtomkanZ-2FyDzi-2FY-2BmGqex7xGdMuzSwEVpcq7BSsL-2B-2FlDrp8-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33c30XidHKL-2BRfUBxvq9-2FW1QiF-2FPYfNre3FspB2EKZOwLdWFA373eMr24EJbXv-2F2eITSCY2f58-2BfO4KkgGDzCiQqFokVYUpqG6-2BSIpJauRO-2BElRaom9ytNuk7-2FIdvM65DEDqbuYfRpCUMevZqwsMikcvNZAMTDUvjT5JE44seAusgbkiv2vC8EqDuJtHzncD5BJsDH4ABREOF4-2BSOWDRLFu&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cb99dcb16ddc94a6d445e08d6a31a68a8%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=zfFBEa98mARzJJvE41cq%2BBtIKSaB0vSl73jDZn5tXFg%3D&reserved=0>To manage your Datadog subscriptions, click here<https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Foutbound.dtdg.co%2Fwf%2Fclick%3Fupn%3D-2F4mdpADWUAWk9uvqkeGKKktae7H6XCvCCJh7u98yQECkg7AnUPKGn51plZlHct1NB9fwJzgmRoiq4UZtJ-2F9d6Q-3D-3D_P-2FLJgepdm1ikc27d18MWlnCKGw3Yfqi1YkMG4Ymij33c30XidHKL-2BRfUBxvq9-2FW1QiF-2FPYfNre3FspB2EKZOwNzpWM5aFRHvsKFwH6IUmT8-2Bg1lXsC1idjeJBjY1ZlDgmiua9Y9Afw1T6CEqsghNcsCtKQzZz12DhSIeZBmAFGTSDlYtJdY9jndZB-2BRYr1UrqmGrd7t5NuWamZ3MNPxv3brBkX-2BMxa061mK6jetmVdkdA5IDeTkEl7EwWBDfiXwP&data=01%7C01%7Cathira.pk%40hitachivantara.com%7Cb99dcb16ddc94a6d445e08d6a31a68a8%7C18791e1761594f52a8d4de814ca8284a%7C0&sdata=%2BPVvpN9u8vsmXTBwbOZbkZfZ2SE8S9aBlb38QnTFnNc%3D&reserved=0>.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sda ) - sphq-db1-20180830 - 10.59.10.26,,07-03-2019 22:03,83,0,SpendHQ,"Hello Team,This is to inform you that EBS high Disk usage alert for /dev/sda disk on sphq-db1-20180830 server (10.59.10.26) got recovered.Current utilization is 80.2%As of now, we are marking this case resolved. Feel free to reopen if you have any related queries.",Current value: 91.7,"Hello David, This is a quick follow up! Please review the previous comment because the alert is in a still open state with current EBS disk usage is 91.7%. Thanks.","Hello TeamThe alert is still in open state with the value of 92%--------[root@ip-10-59-10-26 data1]# df -Th | grep /dev/sda/dev/sda       ext4      8.0T  7.0T  693G  92% /usr/local/mariadb[root@ip-10-59-10-26 data1]# ---------We have further analyzed this alert and could see that the files under the directory /usr/local/mariadb/columnstore/data contains the largest files. Below are the details of the top 20 largest size files under this directory.--------------[root@ip-10-59-10-26 data1]# sudo du -ah . | sort -n -r | head -n 20991M	./000.dir/007.dir/068.dir956M	./000.dir/007.dir/049.dir929M	./000.dir/009.dir/188.dir921M	./000.dir/008.dir/125.dir907M	./000.dir/006.dir/035.dir/051.dir891M	./000.dir/006.dir/241.dir878M	./000.dir/010.dir/027.dir867M	./000.dir/006.dir/035.dir/072.dir864M	./000.dir/010.dir/193.dir861M	./000.dir/009.dir/083.dir858M	./000.dir/006.dir/032.dir/138.dir856M	./000.dir/008.dir/162.dir844K	./000.dir/012.dir/182.dir/029.dir/002.dir844K	./000.dir/012.dir/182.dir/029.dir/001.dir844K	./000.dir/012.dir/182.dir/029.dir/000.dir844K	./000.dir/012.dir/138.dir/052.dir/002.dir844K	./000.dir/012.dir/138.dir/052.dir/001.dir844K	./000.dir/012.dir/138.dir/052.dir/000.dir844K	./000.dir/011.dir/048.dir/036.dir/002.dir844K	./000.dir/011.dir/048.dir/036.dir/001.dir==============Kindly check with the analysis and delete and/or zip unwanted files to resolve this alert.Let us know if you have any queries.Thanks",Hello Team This is to notify you that we have received an EBS high Disk usage alert for the sphq-db1-20180830 - 10.59.10.26The current disk utilization is 90.23%. We will fetch the disk usage details and will get back to you. Regards,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Fc5cP,Cloud Engineer Level 1,Closed,1072057,Incident,10-08-2017 17:45,,"Hello SpendHQ-Team,Did you get a chance to review the RCA shared for the outage happened for the URL https://secure.spendhq.com/login. Kindly validate the RCA and let us know if your team have any further queries regarding this case. As of now, we are marking this case as resolved.Regards,Sumod.K.Bose###Next Action: Evening Shift: Send a reminder to the customer in case of no response.###Hello SpendHQ-Team,We have prepared the RCA regarding the outage happened for the URL https://secure.spendhq.com/login which caused on 7th August 2017. Refer the attachment section for more details.Validate the RCA and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###We updated the RCA and asked Yogesh to review it.Link - https://docs.google.com/document/d/11R-IQQEvnZVZIFxA0sMnkTFmRxI5zZV-9sLcro0a8nw/edit####We have started preparing the RCA document and need to complete it.https://docs.google.com/document/d/11R-IQQEvnZVZIFxA0sMnkTFmRxI5zZV-9sLcro0a8nw/edit####Hello Team,Matthew updated that the details are being reviewed internally.Let us know once you are done with review and reach out to us if you have any queries.###Matthew updated that they will review and let us know.###Hello SpendHQ-Team,Did you get a chance to look into the analysis we have done? Please review the findings and let us know if you have any queries regarding this.###I found the initial observation good so far. There are segmentation fault errors which can be caused by different circumstances a mentioned below:# In most of the cases this can be caused by uneven memory allocations# This can be due to a buggy script. Can be fixed by correcting the code.# Can be due to the bug in the software, which can be corrected by applying a patch.# Sometimes hardware or faulty memory or driver can also create the problem.In this case, it seems to be caused by the uneven memory distribution. where memory_limit per script is set to 2048M.I will do more analysis on this and will provide an update on how to trace the reason segmentation fault. We may need help from developer team on this.###The ticket is assigned to Yogesh.###Hello SpendHQ Team,In our analysis, we found the following entry in Apache error logs:[Mon Aug 07 15:54:24 2017] [notice] child pid 24663 exit signal Segmentation fault (11)The segmentation fault can be created as a result of any one of the below-mentioned condition:1.An endless loop of the function in PHP code.2.It can happen when a program does something that's not allowed, like trying to access memory that isn't valid.We have checked and verified that the memory_limit variable in php.ini file and found that it is currently set to 2048M.The memory_limit Variable sets the maximum amount of memory in bytes that a script is allowed to allocate.Now the default value of /proc/sys/vm/overcommit_ratio is 50 on the system, so the kernel will not allow applications to allocate more than 50% of ram+swap. Since in AWS instances we have no swap by default, The kernel will not allow applications to allocate more than 50% of the RAM, leaving the other 50% free for the cache.Hence, to prevent this issue from happening again, We would recommend to lower down the value of memory_limit which will prevent a child process from trying to access a memory which isn't available in the system as it is already in use by other child processes.Kindly review our findings and let us know if you have any more queries.###Hello Team,This is to inform you that we received a site down alert for the URL https://secure.spendhq.com/login. The alert got recovered within 2 minutes and the site is well accessible now. We will analyze the issue from our end and meanwhile please let us know if your team has performed any activity from your end.","Mon, 07 Aug 2017 11:50:20 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): California US, Sydney-C AU, Dallas-B US, Atlanta-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,07-08-2017 21:20,68,0,SpendHQ,"Hello SpendHQ-Team,Did you get a chance to review the RCA shared for the outage happened for the URL https://secure.spendhq.com/login. Kindly validate the RCA and let us know if your team have any further queries regarding this case. As of now, we are marking this case as resolved.Regards,Sumod.K.Bose",Next Action: Evening Shift: Send a reminder to the customer in case of no response.,"Hello SpendHQ-Team,We have prepared the RCA regarding the outage happened for the URL https://secure.spendhq.com/login which caused on 7th August 2017. Refer the attachment section for more details.Validate the RCA and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose",We updated the RCA and asked Yogesh to review it.Link - https://docs.google.com/document/d/11R-IQQEvnZVZIFxA0sMnkTFmRxI5zZV-9sLcro0a8nw/edit,#We have started preparing the RCA document and need to complete it.https://docs.google.com/document/d/11R-IQQEvnZVZIFxA0sMnkTFmRxI5zZV-9sLcro0a8nw/edit,"#Hello Team,Matthew updated that the details are being reviewed internally.Let us know once you are done with review and reach out to us if you have any queries.",Matthew updated that they will review and let us know.,"Hello SpendHQ-Team,Did you get a chance to look into the analysis we have done? Please review the findings and let us know if you have any queries regarding this.","I found the initial observation good so far. There are segmentation fault errors which can be caused by different circumstances a mentioned below:# In most of the cases this can be caused by uneven memory allocations# This can be due to a buggy script. Can be fixed by correcting the code.# Can be due to the bug in the software, which can be corrected by applying a patch.# Sometimes hardware or faulty memory or driver can also create the problem.In this case, it seems to be caused by the uneven memory distribution. where memory_limit per script is set to 2048M.I will do more analysis on this and will provide an update on how to trace the reason segmentation fault. We may need help from developer team on this.",The ticket is assigned to Yogesh.,"Hello SpendHQ Team,In our analysis, we found the following entry in Apache error logs:[Mon Aug 07 15:54:24 2017] [notice] child pid 24663 exit signal Segmentation fault (11)The segmentation fault can be created as a result of any one of the below-mentioned condition:1.An endless loop of the function in PHP code.2.It can happen when a program does something that's not allowed, like trying to access memory that isn't valid.We have checked and verified that the memory_limit variable in php.ini file and found that it is currently set to 2048M.The memory_limit Variable sets the maximum amount of memory in bytes that a script is allowed to allocate.Now the default value of /proc/sys/vm/overcommit_ratio is 50 on the system, so the kernel will not allow applications to allocate more than 50% of ram+swap. Since in AWS instances we have no swap by default, The kernel will not allow applications to allocate more than 50% of the RAM, leaving the other 50% free for the cache.Hence, to prevent this issue from happening again, We would recommend to lower down the value of memory_limit which will prevent a child process from trying to access a memory which isn't available in the system as it is already in use by other child processes.Kindly review our findings and let us know if you have any more queries.","Hello Team,This is to inform you that we received a site down alert for the URL https://secure.spendhq.com/login. The alert got recovered within 2 minutes and the site is well accessible now. We will analyze the issue from our end and meanwhile please let us know if your team has performed any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001FeWOp,Cloud Engineer Level 1,Closed,1073449,Incident,16-08-2017 02:29,,"Hello Matthew,While checking, We could see that the two instance behind the NewPreview-ELB went out of service. We have checked the Health Check configuration on ELB level and found that it was set to HTTP:80/index.html. Please find the screenshot below.​We have checked and verified that the index.html page was not present that causes the ELB health check failure. Because of this the instances behind the ELB went out of service and  ELB stops serving the request. So we have modified the health check configuration to TCP:80 that resolved this issue. Please let us know if you have made any changes in the instance level.###This is follow up on another case : 01073446###Matthew Watts1:14 AM (1 hour ago)to me, Allen, Rean, Dusty This has been resolved. What was the issue.###Hello Allen,We are analyzing the issue and will get back to you with details.","When I hit the IP 10.59.100.122 and 10.59.101.6 our webapp works, but when  I access our webapp but from preview.spendhq.com I'm getting a 503 error.    Preview.spendhq.com is our ELB for the 2 servers mentioned before.Allen Herrera | Developer | SpendHQ(r)M: 360-888-3938 | aherrera@spendhq.com<mailto:aherrera@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",CRITICAL: preview.spendhq.com ELB????,,16-08-2017 00:28,2,0,SpendHQ,"Hello Matthew,While checking, We could see that the two instance behind the NewPreview-ELB went out of service. We have checked the Health Check configuration on ELB level and found that it was set to HTTP:80/index.html. Please find the screenshot below.​We have checked and verified that the index.html page was not present that causes the ELB health check failure. Because of this the instances behind the ELB went out of service and  ELB stops serving the request. So we have modified the health check configuration to TCP:80 that resolved this issue. Please let us know if you have made any changes in the instance level.",This is follow up on another case : 01073446,"Matthew Watts1:14 AM (1 hour ago)to me, Allen, Rean, Dusty This has been resolved. What was the issue.","Hello Allen,We are analyzing the issue and will get back to you with details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Fei2S,Cloud Engineer Level 1,Closed,1073555,Incident,16-08-2017 20:42,,"Refer case 01073556 for the details.###Hello SpendHQ,This is to inform you that we received an alert that the MySQL Process is down in the production DB server prd-db - 10.59.10.135. Around the same time, we witnessed a high volume used also, for the volume /dev/sdb that is the Infobright volume mounted using iSCSI. We are analyzing this issue further meanwhile, please let us know if you are performing any activity in this server.Thank You,Safuvan KM","[Triggered on {host:10.59.10.135,process:mysql}] [SpendHQ] MySQL Process is down - prd-db  - 10.59.10.135 - db  MySQL Process is down @support@reancloud.com     @support@reancloud.comPROCS CRITICAL: 0 processes found for mysqlThis alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2014430?group=host%3A10.59.10.135%2Cprocess%3Amysql · Edit Monitor: https://app.datadoghq.com/monitors#2014430/edit · Event URL: https://app.datadoghq.com/event/event?id=4003547106780850148 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","[Monitor Alert] Triggered: [SpendHQ] MySQL Process is down - prd-db - 10.59.10.135 - db on process:mysql,host:10.59.10.135",,16-08-2017 19:44,1,0,SpendHQ,Refer case 01073556 for the details.,"Hello SpendHQ,This is to inform you that we received an alert that the MySQL Process is down in the production DB server prd-db - 10.59.10.135. Around the same time, we witnessed a high volume used also, for the volume /dev/sdb that is the Infobright volume mounted using iSCSI. We are analyzing this issue further meanwhile, please let us know if you are performing any activity in this server.Thank You,Safuvan KM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001LtVbY,Cloud Engineer Level 3,Closed,1086220,Incident,15-01-2018 13:41,,"Hello Chris,We haven't heard back from you regarding this case for a while.At this time, we are marking this case as resolved. Kindly validate the details from your end and revert back in case of any further queries.Regards,Sumod.K.Bose###Send a final closure and close this###Hello Chris, We haven't heard back from you, Could you please let us do we have any updates on this case.###Hello Chris, We haven't heard back from you, Could you please let us do we have any updates on this case.###Hello Chris,We haven't heard back from you,Could you please let us do we have any updates on this case.###HI Praveen,Thanks for the email.  Per our discussion on yesterdays' call, I need to make some changes to the network on our end to make this happen. I want to be very careful when makes any network changes :-) Our network guy has been out on PTO and training - but I believe he made changes last night.  I will follow up with him and update everyone once completed and tested.Thanks!Chris Veillette###Praveen Muppala5:55 PM (30 minutes ago)to Chris, David, Akim, spendhq-support Hello Chris/David, Our team is trying to reach both of you to get an assistance on this issue via the REAN CMP Ticket ID: 01086220. Can we please quickly get on a call to resolve the issue ASAP. It’s been pending since last 4 weeks. I understand your poor response because of the holiday season. Let’s make sure this issue is resolved earliest by end of this week. Regards,-Praveen###I sent an email to Sarat & Jeff requesting to reach out to Chris from Amdromeda to provide update on this ticket. Waiting for a response. Regards/Chirodeep###Informed Chirodeep to reach out to Sarath or Jeff.###Chirodeep updated on the OPS call that as Chris is not responding, we need to reach out to Sarath or Jeff. Yogesh will take care of this.###Hi Andrew,As discussed on Bi-Weekly call you were going to work on this with Chris.This ticket is now open for a long time, Please let us know if this was completed. Thank you###Yesterday OPS call Chirodeep updated that he will send a mail to Chris and David to get an update on this case.###Hello Chris, We haven't heard back from you. Please let us know the update on this case.###Hello Chris,We haven't heard back from you.Please let us know the update on this case.###Yogesh updated Need to Send an email to David and Chris asking an update today.###Tried to call David twice but he was also not picking up the call. Need to discuss this case during Monday OPS Call for the next action items as we are not receiving any updates through continuous follow-ups.###Need to call David from Andromeda since Chris is not providing an update.###Hello Chris, We have tried to reach out to you over the phone but you are unavailable. Please provide us with an update on this case.###Hello Chris,We have tried to reachout to you over phone but were not available. Please let us know if there are any updates from Nimble team.###We have tried to reach out Chris but he was unreachable.Next action: evening shift: Reach out to Chris Via Phone in the night shift in order mount the volume.###We have tried to reach out to Chris via Phone but he didn't pick up the call. Next action: Reach out to Chris Via Phone in the night shift in order mount the volume.###Call customer in evening shift###in the evening ops call, chirodeep asked Yogesh to work with Chris n this ticket.###I pinged Praveen via slack he mentioned he will look into the response from Chris.Next Action: Check with Praveen.###Chris Veillette7:08 PM (4 minutes ago)to Praveen, spendhq-support, David Hi Praveen,Yes, we are helping Spend move from Nimble to JetStor - a few problems have risen and we (A3) are  activity addressing them.    Can we chat later today ? - I want to talk to Nimble first - I will keep everyone apprised of the status.Thanks,Chris Veillette###Hello Chris/David, Please see the below issue and need your help to fix the issue. Let us know, what time works for a quick 30 min call to sync up. Regards,-Praveen###By getting an error while trying to restore the superblocks from the backups, I think this issue has something to do with the disk hardware like a faulty hardware can be the culprit here.Please refer these details and have a look at the disk configuration from the data center and post more information here so that we will have a closer look at the issue again.Thank You,Safuvan KM###Hi Andrew,I looked into this issue and here is the outcome:Ran a file system check against the disk /dev/sdac [root@ip-10-59-10-135 ~]# fsck.ext4 -y /dev/sdace2fsck 1.41.12 (17-May-2010)/dev/sdac: recovering journalSuperblock needs_recovery flag is clear, but journal has data.Run journal anyway? yesfsck.ext4: unable to set superblock flags on /dev/sdacThe file system check fails. In order to make sure of the file format:[root@ip-10-59-10-135 ~]# parted -lModel: Nimble Server (scsi)Disk /dev/sdac: 2199GBSector size (logical/physical): 512B/512BPartition Table: loopNumber  Start  End     Size    File system  Flags 1      0.00B  2199GB  2199GB  ext4[root@ip-10-59-10-135 ~]# mount -t ext4 /dev/sdac /mnt/ni_files01mount: wrong fs type, bad option, bad superblock on /dev/sdac,       missing codepage or helper program, or other error       In some cases useful info is found in syslog - try       dmesg | tail  or so[root@ip-10-59-10-135 ~]# tail /var/log/messagesDec 11 01:22:15 ip-10-59-10-135 kernel: sd 131:0:0:0: timing out command, waited 180sDec 11 01:22:15 ip-10-59-10-135 kernel: sd 131:0:0:0: timing out command, waited 180sDec 11 01:22:15 ip-10-59-10-135 kernel: sd 131:0:0:0: timing out command, waited 180sDec 11 01:22:15 ip-10-59-10-135 kernel: sd 131:0:0:0: timing out command, waited 180sDec 11 01:22:15 ip-10-59-10-135 kernel: sd 131:0:0:0: timing out command, waited 180sDec 11 01:22:15 ip-10-59-10-135 kernel: JBD: recovery failedDec 11 01:22:15 ip-10-59-10-135 kernel: EXT4-fs (sdac): error loading journalDec 11 01:23:55 ip-10-59-10-135 dhclient[1665]: DHCPREQUEST on eth0 to 10.59.10.1 port 67 (xid=0x7f270530)Dec 11 01:23:55 ip-10-59-10-135 dhclient[1665]: DHCPACK from 10.59.10.1 (xid=0x7f270530)Dec 11 01:23:57 ip-10-59-10-135 dhclient[1665]: bound to 10.59.10.135 -- renewal in 1457 seconds.[root@ip-10-59-10-135 ~]# dmesg | tailsd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180sJBD: recovery failedEXT4-fs (sdac): error loading journalAssuming the superblock is corrupt, trying to find where the superblock backups are kept.[root@ip-10-59-10-135 ~]# mke2fs -n /dev/sdacmke2fs 1.41.12 (17-May-2010)/dev/sdac is entire device, not just one partition!Proceed anyway? (y,n) yFilesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks134217728 inodes, 536870912 blocks26843545 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=429496729616384 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks:        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,        4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968,        102400000, 214990848, 512000000Trying to restore from the first backup block.[root@ip-10-59-10-135 ~]# e2fsck -b 32768 /dev/sdace2fsck 1.41.12 (17-May-2010)Superblock needs_recovery flag is clear, but journal has data.Recovery flag not set in backup superblock, so running journal anyway./dev/sdac: recovering journalSuperblock needs_recovery flag is clear, but journal has data.Recovery flag not set in backup superblock, so running journal anyway.Superblock needs_recovery flag is clear, but journal has data.Recovery flag not set in backup superblock, so running journal anyway.e2fsck: unable to set superblock flags on /dev/sdac***To be continued***###[root@ip-10-59-10-135 ~]# iscsiadm --mode discovery --type sendtargets --portal 172.24.4.3:3260172.24.4.3:3260,2460 iqn.2007-11.com.nimblestorage:shqfiles01-v0a99b078cb77210e.00000001.c1ee9176172.24.4.3:3260,2460 iqn.2007-11.com.nimblestorage:shqfile01-12-09-17-v0a99b078cb77210e.00000003.c1ee9176172.24.4.3:3260,2460 iqn.2007-11.com.nimblestorage:spend4-new-test-07-25-17-v0a99b078cb77210e.00000002.c1ee9176172.24.4.3:3260,2460 iqn.2007-11.com.nimblestorage:shqfiles01-shqfile01-12-09-17-v0a99b078cb77210e.00000001.c1ee9176.s0a99b078cb77210e.00000007.00000caa###root@ip-10-59-10-135 ~]# ls -l /dev/disk/by-pathtotal 0lrwxrwxrwx 1 root root  9 Nov 20 19:47 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-v777bb21358661922.00000029.2f1dab31-lun-0 -> ../../sdnlrwxrwxrwx 1 root root  9 Aug 16 14:29 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-06-10-17-v777bb21358661922.00000022.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root  9 Aug 16 14:29 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-copy-04-24-17-v777bb21358661922.0000001b.2f1dab31-lun-0 -> ../../sdelrwxrwxrwx 1 root root  9 Dec  9 20:16 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-prod-backup-1-10-17-v777bb21358661922.00000009.2f1dab31.s777bb21358661922.00000009.00005121-lun-0 -> ../../sdglrwxrwxrwx 1 root root  9 Aug 16 14:29 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-v777bb21358661922.00000009.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root 10 Dec  9 23:11 ip-172.24.4.3:3260-iscsi-iqn.2007-11.com.nimblestorage:shqfile01-12-09-17-v0a99b078cb77210e.00000003.c1ee9176-lun-0 -> ../../sdaclrwxrwxrwx 1 root root 10 Dec  9 20:21 ip-172.24.4.3:3260-iscsi-iqn.2007-11.com.nimblestorage:shqfiles01-shqfile01-12-09-17-v0a99b078cb77210e.00000001.c1ee9176.s0a99b078cb77210e.00000007.00000caa-lun-0 -> ../../sdablrwxrwxrwx 1 root root  9 Nov 27 16:46 ip-172.24.4.3:3260-iscsi-iqn.2007-11.com.nimblestorage:shqfiles01-v0a99b078cb77210e.00000001.c1ee9176-lun-0 -> ../../sdrlrwxrwxrwx 1 root root  9 Nov 27 16:46 ip-172.24.4.3:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-new-test-07-25-17-v0a99b078cb77210e.00000002.c1ee9176-lun-0 -> ../../sdklrwxrwxrwx 1 root root  9 Dec  9 19:45 ip-172.24.5.2:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev0.ctr1-lun-2 -> ../../sdl###Hello Andrew,We are looking into this issue and will let you know the updates.","We are trying to mount a volume on 10.59.10.135, but are receiving an errormessage. Please assist.[akim@ip-10-59-10-135 mnt]$ sudo mount -t ext4 /dev/sdac /mnt/ni_files01mount: wrong fs type, bad option, bad superblock on /dev/sdac,       missing codepage or helper program, or other error       In some cases useful info is found in syslog - try       dmesg | tail  or so[akim@ip-10-59-10-135 mnt]$We are trying to copy data from the Nimble SAN to the JetStor SAN over theAWS instance. /mnt/ni_files01 should be the mount point for the Nimble, and/mnt/js_shqfiles01 is the mount point for the JetStor (working).Please advise. Thank you,*Andrew Kim* | Director of Information Technology & Security | *Spend**HQ®*O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com*A SaaS Spend Visibility solution from Insight Sourcing Group*www.spendhq.com | www.insightsourcing.com-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Assistance mounting volume,,10-12-2017 05:25,872,0,SpendHQ,"Hello Chris,We haven't heard back from you regarding this case for a while.At this time, we are marking this case as resolved. Kindly validate the details from your end and revert back in case of any further queries.Regards,Sumod.K.Bose",Send a final closure and close this,"Hello Chris, We haven't heard back from you, Could you please let us do we have any updates on this case.","Hello Chris, We haven't heard back from you, Could you please let us do we have any updates on this case.","Hello Chris,We haven't heard back from you,Could you please let us do we have any updates on this case.","HI Praveen,Thanks for the email.  Per our discussion on yesterdays' call, I need to make some changes to the network on our end to make this happen. I want to be very careful when makes any network changes :-) Our network guy has been out on PTO and training - but I believe he made changes last night.  I will follow up with him and update everyone once completed and tested.Thanks!Chris Veillette","Praveen Muppala5:55 PM (30 minutes ago)to Chris, David, Akim, spendhq-support Hello Chris/David, Our team is trying to reach both of you to get an assistance on this issue via the REAN CMP Ticket ID: 01086220. Can we please quickly get on a call to resolve the issue ASAP. It’s been pending since last 4 weeks. I understand your poor response because of the holiday season. Let’s make sure this issue is resolved earliest by end of this week. Regards,-Praveen",I sent an email to Sarat & Jeff requesting to reach out to Chris from Amdromeda to provide update on this ticket. Waiting for a response. Regards/Chirodeep,Informed Chirodeep to reach out to Sarath or Jeff.,"Chirodeep updated on the OPS call that as Chris is not responding, we need to reach out to Sarath or Jeff. Yogesh will take care of this.","Hi Andrew,As discussed on Bi-Weekly call you were going to work on this with Chris.This ticket is now open for a long time, Please let us know if this was completed. Thank you",Yesterday OPS call Chirodeep updated that he will send a mail to Chris and David to get an update on this case.,"Hello Chris, We haven't heard back from you. Please let us know the update on this case.","Hello Chris,We haven't heard back from you.Please let us know the update on this case.",Yogesh updated Need to Send an email to David and Chris asking an update today.,Tried to call David twice but he was also not picking up the call. Need to discuss this case during Monday OPS Call for the next action items as we are not receiving any updates through continuous follow-ups.,Need to call David from Andromeda since Chris is not providing an update.,"Hello Chris, We have tried to reach out to you over the phone but you are unavailable. Please provide us with an update on this case.","Hello Chris,We have tried to reachout to you over phone but were not available. Please let us know if there are any updates from Nimble team.",We have tried to reach out Chris but he was unreachable.Next action: evening shift: Reach out to Chris Via Phone in the night shift in order mount the volume.,We have tried to reach out to Chris via Phone but he didn't pick up the call. Next action: Reach out to Chris Via Phone in the night shift in order mount the volume.,Call customer in evening shift,"in the evening ops call, chirodeep asked Yogesh to work with Chris n this ticket.",I pinged Praveen via slack he mentioned he will look into the response from Chris.Next Action: Check with Praveen.,"Chris Veillette7:08 PM (4 minutes ago)to Praveen, spendhq-support, David Hi Praveen,Yes, we are helping Spend move from Nimble to JetStor - a few problems have risen and we (A3) are  activity addressing them.    Can we chat later today ? - I want to talk to Nimble first - I will keep everyone apprised of the status.Thanks,Chris Veillette","Hello Chris/David, Please see the below issue and need your help to fix the issue. Let us know, what time works for a quick 30 min call to sync up. Regards,-Praveen","By getting an error while trying to restore the superblocks from the backups, I think this issue has something to do with the disk hardware like a faulty hardware can be the culprit here.Please refer these details and have a look at the disk configuration from the data center and post more information here so that we will have a closer look at the issue again.Thank You,Safuvan KM","Hi Andrew,I looked into this issue and here is the outcome:Ran a file system check against the disk /dev/sdac [root@ip-10-59-10-135 ~]# fsck.ext4 -y /dev/sdace2fsck 1.41.12 (17-May-2010)/dev/sdac: recovering journalSuperblock needs_recovery flag is clear, but journal has data.Run journal anyway? yesfsck.ext4: unable to set superblock flags on /dev/sdacThe file system check fails. In order to make sure of the file format:[root@ip-10-59-10-135 ~]# parted -lModel: Nimble Server (scsi)Disk /dev/sdac: 2199GBSector size (logical/physical): 512B/512BPartition Table: loopNumber  Start  End     Size    File system  Flags 1      0.00B  2199GB  2199GB  ext4[root@ip-10-59-10-135 ~]# mount -t ext4 /dev/sdac /mnt/ni_files01mount: wrong fs type, bad option, bad superblock on /dev/sdac,       missing codepage or helper program, or other error       In some cases useful info is found in syslog - try       dmesg | tail  or so[root@ip-10-59-10-135 ~]# tail /var/log/messagesDec 11 01:22:15 ip-10-59-10-135 kernel: sd 131:0:0:0: timing out command, waited 180sDec 11 01:22:15 ip-10-59-10-135 kernel: sd 131:0:0:0: timing out command, waited 180sDec 11 01:22:15 ip-10-59-10-135 kernel: sd 131:0:0:0: timing out command, waited 180sDec 11 01:22:15 ip-10-59-10-135 kernel: sd 131:0:0:0: timing out command, waited 180sDec 11 01:22:15 ip-10-59-10-135 kernel: sd 131:0:0:0: timing out command, waited 180sDec 11 01:22:15 ip-10-59-10-135 kernel: JBD: recovery failedDec 11 01:22:15 ip-10-59-10-135 kernel: EXT4-fs (sdac): error loading journalDec 11 01:23:55 ip-10-59-10-135 dhclient[1665]: DHCPREQUEST on eth0 to 10.59.10.1 port 67 (xid=0x7f270530)Dec 11 01:23:55 ip-10-59-10-135 dhclient[1665]: DHCPACK from 10.59.10.1 (xid=0x7f270530)Dec 11 01:23:57 ip-10-59-10-135 dhclient[1665]: bound to 10.59.10.135 -- renewal in 1457 seconds.[root@ip-10-59-10-135 ~]# dmesg | tailsd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180ssd 131:0:0:0: timing out command, waited 180sJBD: recovery failedEXT4-fs (sdac): error loading journalAssuming the superblock is corrupt, trying to find where the superblock backups are kept.[root@ip-10-59-10-135 ~]# mke2fs -n /dev/sdacmke2fs 1.41.12 (17-May-2010)/dev/sdac is entire device, not just one partition!Proceed anyway? (y,n) yFilesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks134217728 inodes, 536870912 blocks26843545 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=429496729616384 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks:        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,        4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968,        102400000, 214990848, 512000000Trying to restore from the first backup block.[root@ip-10-59-10-135 ~]# e2fsck -b 32768 /dev/sdace2fsck 1.41.12 (17-May-2010)Superblock needs_recovery flag is clear, but journal has data.Recovery flag not set in backup superblock, so running journal anyway./dev/sdac: recovering journalSuperblock needs_recovery flag is clear, but journal has data.Recovery flag not set in backup superblock, so running journal anyway.Superblock needs_recovery flag is clear, but journal has data.Recovery flag not set in backup superblock, so running journal anyway.e2fsck: unable to set superblock flags on /dev/sdac***To be continued***","[root@ip-10-59-10-135 ~]# iscsiadm --mode discovery --type sendtargets --portal 172.24.4.3:3260172.24.4.3:3260,2460 iqn.2007-11.com.nimblestorage:shqfiles01-v0a99b078cb77210e.00000001.c1ee9176172.24.4.3:3260,2460 iqn.2007-11.com.nimblestorage:shqfile01-12-09-17-v0a99b078cb77210e.00000003.c1ee9176172.24.4.3:3260,2460 iqn.2007-11.com.nimblestorage:spend4-new-test-07-25-17-v0a99b078cb77210e.00000002.c1ee9176172.24.4.3:3260,2460 iqn.2007-11.com.nimblestorage:shqfiles01-shqfile01-12-09-17-v0a99b078cb77210e.00000001.c1ee9176.s0a99b078cb77210e.00000007.00000caa",root@ip-10-59-10-135 ~]# ls -l /dev/disk/by-pathtotal 0lrwxrwxrwx 1 root root  9 Nov 20 19:47 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prd-db-171120-v777bb21358661922.00000029.2f1dab31-lun-0 -> ../../sdnlrwxrwxrwx 1 root root  9 Aug 16 14:29 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-06-10-17-v777bb21358661922.00000022.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root  9 Aug 16 14:29 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-copy-04-24-17-v777bb21358661922.0000001b.2f1dab31-lun-0 -> ../../sdelrwxrwxrwx 1 root root  9 Dec  9 20:16 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-prod-backup-1-10-17-v777bb21358661922.00000009.2f1dab31.s777bb21358661922.00000009.00005121-lun-0 -> ../../sdglrwxrwxrwx 1 root root  9 Aug 16 14:29 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-v777bb21358661922.00000009.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root 10 Dec  9 23:11 ip-172.24.4.3:3260-iscsi-iqn.2007-11.com.nimblestorage:shqfile01-12-09-17-v0a99b078cb77210e.00000003.c1ee9176-lun-0 -> ../../sdaclrwxrwxrwx 1 root root 10 Dec  9 20:21 ip-172.24.4.3:3260-iscsi-iqn.2007-11.com.nimblestorage:shqfiles01-shqfile01-12-09-17-v0a99b078cb77210e.00000001.c1ee9176.s0a99b078cb77210e.00000007.00000caa-lun-0 -> ../../sdablrwxrwxrwx 1 root root  9 Nov 27 16:46 ip-172.24.4.3:3260-iscsi-iqn.2007-11.com.nimblestorage:shqfiles01-v0a99b078cb77210e.00000001.c1ee9176-lun-0 -> ../../sdrlrwxrwxrwx 1 root root  9 Nov 27 16:46 ip-172.24.4.3:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-new-test-07-25-17-v0a99b078cb77210e.00000002.c1ee9176-lun-0 -> ../../sdklrwxrwxrwx 1 root root  9 Dec  9 19:45 ip-172.24.5.2:3260-iscsi-iqn.2004-08.com.acnc:jetstorsas816ixd-000d40fc0:dev0.ctr1-lun-2 -> ../../sdl,"Hello Andrew,We are looking into this issue and will let you know the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000014LoqM,Cloud Engineer Level 1,Closed,1033812,Incident,25-11-2016 02:57,,"Hi Matthew,Thanks for the update. We have also verified that the sites https://secure.spendhq.com/login & https://preview.spendhq.com/login is loading and serving fine.From our analysis for Secure&Preview ELB access logs, we found many requests had 5XX, 4XX response code and high latency. All access logs details for both the ELBs are attached with the case.We have analysed all resource usage metrixes during the time of alert and all were fine.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please feel free to reach out to us.Best Regards,Safuvan KM###Hi Matthew, We can see that the https://secure.spendhq.com/login is loading and serving well now but the https://preview.spendhq.com/login is loading but showing the same data base error message we shared. Please find the screen show attached with the case.###Hi Matthew,Thanks for the quick response. For just a clarification, as you are working on this, please let us know if you need any assistance from our side.###Matthew Watts commented via e-mail that Thank you for the notification. I will advise when resolved.###Hi SpendHQ Team,This is to inform you that we received a site down alert for https://preview.spendhq.com/login. When we try to access the site, it was serving well but we witness database errors that displayed on the login page. The alert got resolved within 5 minutes but the error message still persists. The error message is as below. SQL Error: 145: Table './isg/cake_sessions' is marked as crashed and should be repaired [CORE/cake/libs/model/datasources/dbo_source.php, line 685]string(195) Query: SELECT `Session`.`id`, `Session`.`data`, `Session`.`expires` FROM `cake_sessions` AS `Session`   WHERE `id` = 'p6h2diglco4u1g2opn8c78q8c4'    LIMIT 1 We are investigating further on this and will get back to you ASAP, Meanwhile please let us know if you are performing any activity from your end.","Thu, 24 Nov 2016 14:03:14 -0500Detected Error on SpendHQEstimated Downtime: 2 minutes https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30000 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: --------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Atlanta-B US, Dallas-B US, Frankfurt DE, California US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,25-11-2016 00:33,2,0,SpendHQ,"Hi Matthew,Thanks for the update. We have also verified that the sites https://secure.spendhq.com/login & https://preview.spendhq.com/login is loading and serving fine.From our analysis for Secure&Preview ELB access logs, we found many requests had 5XX, 4XX response code and high latency. All access logs details for both the ELBs are attached with the case.We have analysed all resource usage metrixes during the time of alert and all were fine.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please feel free to reach out to us.Best Regards,Safuvan KM","Hi Matthew, We can see that the https://secure.spendhq.com/login is loading and serving well now but the https://preview.spendhq.com/login is loading but showing the same data base error message we shared. Please find the screen show attached with the case.","Hi Matthew,Thanks for the quick response. For just a clarification, as you are working on this, please let us know if you need any assistance from our side.",Matthew Watts commented via e-mail that Thank you for the notification. I will advise when resolved.,"Hi SpendHQ Team,This is to inform you that we received a site down alert for https://preview.spendhq.com/login. When we try to access the site, it was serving well but we witness database errors that displayed on the login page. The alert got resolved within 5 minutes but the error message still persists. The error message is as below. SQL Error: 145: Table './isg/cake_sessions' is marked as crashed and should be repaired [CORE/cake/libs/model/datasources/dbo_source.php, line 685]string(195) Query: SELECT `Session`.`id`, `Session`.`data`, `Session`.`expires` FROM `cake_sessions` AS `Session`   WHERE `id` = 'p6h2diglco4u1g2opn8c78q8c4'    LIMIT 1 We are investigating further on this and will get back to you ASAP, Meanwhile please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BZUwr,Cloud Engineer Level 1,Closed,1051819,Incident,06-05-2017 00:15,,"Hi Steven,Thanks for the updated, We have blocked the IP at NACL level. Please let us know if you need any further details.###Steven Ng12:00 AM (9 minutes ago)to Rean Please block that IP.###Hello SpendHQ-Team, On further analysing the ELB logs at the time of the alert, We are able to find the IP 42.106.52.68 which belongs to located in Gujrat region in India is trying to execute the SERVER-APACHE Apache Struts remote code.Please find the logs details below2017-05-05T14:06:22.010933Z preview-spendhq-xelb 42.106.52.68:36601 10.59.1.192:8080 0.000043 0.020534 0.000058 200 200 0 2058 GET http://preview.spendhq.com:8080/ HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36 - -2017-05-05T14:06:23.471480Z preview-spendhq-xelb 42.106.52.68:36601 10.59.1.192:8080 0.000049 0.017495 0.000087 200 200 0 7290 GET http://preview.spendhq.com:8080/favicon.ico HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36 - -Please let us know if this IP belongs to your Dev teams so that we can add an exception for this IP in Sophos level.Else we will block it.###Hello SpendHQ Team,This is to inform you that we have again received an Intrusion Prevention Alert from Sophos for preview.spendhq.com on port 8080.We are investigating the alert and will get back to you with updates.###Hello Steven,We have already blocked that IP on the NACL level .But as a recommendation, We would like to ask you to to do a version update for Apache Struts 2 as the current version has some vulnerabilities which can be exploited to attack the Website.Please refer the following pages for reference. https://www.imperva.com/blog/2017/03/cve-2017-5638-new-remote-code-execution-rce-vulnerability-in-apache-struts-2/ https://nvd.nist.gov/vuln/detail/CVE-2017-5638#vulnDescriptionTitle Do let us know if you have any more queries or if you need any support from our side regarding this issue.###Steven Ng5:39 PM (31 minutes ago)￼￼￼to Rean￼Yes please do block that IP. I am not aware of apache struts 2 but will look into it this morning. Are there any additional action we need to take in order to prevent any malicious actions against this security flaw?Thank you REAN.###Hello SpendHQ-Team,By investigating further regarding this issue, we found on March 6th, a new remote code execution (RCE) vulnerability in Apache Struts 2 was made public. This recent vulnerability, CVE-2017-5638, allows a remote attacker to inject operating system commands into a web application through the “Content-Type” header.Please refer the following pages for reference.https://www.imperva.com/blog/2017/03/cve-2017-5638-new-remote-code-execution-rce-vulnerability-in-apache-struts-2/https://nvd.nist.gov/vuln/detail/CVE-2017-5638#vulnDescriptionTitleIf you are using Apache struct 2 frameworks, we would like to recommend a version update.As of now, we have blocked the IP in NACL level. Please let us know if you have any further queries regarding this.###Hello SpendHQ-Team,On further analysing the ELB logs at the time of the alert 2017-05-05 05:50:17 UTC, We are able to find the IP 118.190.65.44 which belongs to an Aliyun Computing Co., LTD located in China is trying to execute the SERVER-APACHE Apache Struts remote code. As per https://www.abuseipdb.com, this IP address has been reported a total of 3 times for web app attack.Please let us know if you want to block the IP at NACL level. Also, let us know if you have any further queries regarding this.###Hello Team,We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.227 which belongs to the secure ELB. Please find the IPS logs below. 2017:05:05-05:49:39 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.227 dstip=10.59.1.192 proto=6 srcport=28207 dstport=80 sid=41922 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:05-05:49:56 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.227 dstip=10.59.1.192 proto=6 srcport=28277 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are analyzing the ELB logs and will let you know the further updates.",Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41922Time...........: 2017-05-05 05:49:39Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.227Source port: 28207Destination IP address: 10.59.1.192 (spendhq)Destination port: 80 (http)2. Intrusion Prevention AlertAn intrusion has been detected. The packet has been dropped automatically.You can toggle this rule between drop and alert only in WebAdmin.Details about the intrusion alert:Message........: SERVER-APACHE Apache Struts remote code execution attemptDetails........: https://www.snort.org/search?query=41818Time...........: 2017-05-05 05:49:56Packet dropped.: yesPriority.......: highClassification.: Attempted Administrator Privilege GainIP protocol....: 6 (TCP)Source IP address: 10.59.1.227Source port: 28277,[spendhq][CRIT-852] Intrusion Prevention Alert (Packet dropped),,05-05-2017 11:27,34,0,SpendHQ,"Hi Steven,Thanks for the updated, We have blocked the IP at NACL level. Please let us know if you need any further details.",Steven Ng12:00 AM (9 minutes ago)to Rean Please block that IP.,"Hello SpendHQ-Team, On further analysing the ELB logs at the time of the alert, We are able to find the IP 42.106.52.68 which belongs to located in Gujrat region in India is trying to execute the SERVER-APACHE Apache Struts remote code.Please find the logs details below2017-05-05T14:06:22.010933Z preview-spendhq-xelb 42.106.52.68:36601 10.59.1.192:8080 0.000043 0.020534 0.000058 200 200 0 2058 GET http://preview.spendhq.com:8080/ HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36 - -2017-05-05T14:06:23.471480Z preview-spendhq-xelb 42.106.52.68:36601 10.59.1.192:8080 0.000049 0.017495 0.000087 200 200 0 7290 GET http://preview.spendhq.com:8080/favicon.ico HTTP/1.1 Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36 - -Please let us know if this IP belongs to your Dev teams so that we can add an exception for this IP in Sophos level.Else we will block it.","Hello SpendHQ Team,This is to inform you that we have again received an Intrusion Prevention Alert from Sophos for preview.spendhq.com on port 8080.We are investigating the alert and will get back to you with updates.","Hello Steven,We have already blocked that IP on the NACL level .But as a recommendation, We would like to ask you to to do a version update for Apache Struts 2 as the current version has some vulnerabilities which can be exploited to attack the Website.Please refer the following pages for reference. https://www.imperva.com/blog/2017/03/cve-2017-5638-new-remote-code-execution-rce-vulnerability-in-apache-struts-2/ https://nvd.nist.gov/vuln/detail/CVE-2017-5638#vulnDescriptionTitle Do let us know if you have any more queries or if you need any support from our side regarding this issue.",Steven Ng5:39 PM (31 minutes ago)￼￼￼to Rean￼Yes please do block that IP. I am not aware of apache struts 2 but will look into it this morning. Are there any additional action we need to take in order to prevent any malicious actions against this security flaw?Thank you REAN.,"Hello SpendHQ-Team,By investigating further regarding this issue, we found on March 6th, a new remote code execution (RCE) vulnerability in Apache Struts 2 was made public. This recent vulnerability, CVE-2017-5638, allows a remote attacker to inject operating system commands into a web application through the “Content-Type” header.Please refer the following pages for reference.https://www.imperva.com/blog/2017/03/cve-2017-5638-new-remote-code-execution-rce-vulnerability-in-apache-struts-2/https://nvd.nist.gov/vuln/detail/CVE-2017-5638#vulnDescriptionTitleIf you are using Apache struct 2 frameworks, we would like to recommend a version update.As of now, we have blocked the IP in NACL level. Please let us know if you have any further queries regarding this.","Hello SpendHQ-Team,On further analysing the ELB logs at the time of the alert 2017-05-05 05:50:17 UTC, We are able to find the IP 118.190.65.44 which belongs to an Aliyun Computing Co., LTD located in China is trying to execute the SERVER-APACHE Apache Struts remote code. As per https://www.abuseipdb.com, this IP address has been reported a total of 3 times for web app attack.Please let us know if you want to block the IP at NACL level. Also, let us know if you have any further queries regarding this.","Hello Team,We have received an Intrusion Prevention Alert from Sophos and the source IP address is 10.59.1.227 which belongs to the secure ELB. Please find the IPS logs below. 2017:05:05-05:49:39 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.227 dstip=10.59.1.192 proto=6 srcport=28207 dstport=80 sid=41922 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=02017:05:05-05:49:56 spendhq snort[12479]: id=2101 severity=warn sys=SecureNet sub=ips name=Intrusion protection alert action=drop reason=SERVER-APACHE Apache Struts remote code execution attempt group=212 srcip=10.59.1.227 dstip=10.59.1.192 proto=6 srcport=28277 dstport=80 sid=41818 class=Attempted Administrator Privilege Gain priority=1 generator=1 msgid=0We are analyzing the ELB logs and will let you know the further updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bmDo6,Cloud Engineer Level 1,Closed,1104986,Incident,20-09-2018 17:53,,"Hello,This is Fadwa from AWS Accounts and Billing.I received your limit increase for the Elastic Load Balancers. I am happy to let you know that the limit increase has been approved and processed. The new limit is as follows:Region: US East (Northern Virginia)Limit name: Application and Classic Load BalancersNew limit value: 35Please allow 10 - 15 minutes for this to update in the account.Best regards,FadwaAmazon Web Services###We've raised a Limit increase request for 10 ELBs. Case ID: 5376592261###@team We got a confirmation from rohit increase the limit to raise it by 10 load balancer more.","---------- Forwarded message ---------From: AWS-Limit <no-reply@sns.amazonaws.com>Date: Thu, Sep 20, 2018 at 3:00 PMSubject: REAN CLOUD AWS limit checker ALERT for spendhq - WARNINGTo: <ms@reancloud.com>Below are resource details that cross limitsREGION       RESOURCE   LIMIT          USAGE          SERVICEus-east-1       ELB               25              20              Activeload balancers--If you wish to stop receiving notifications from this topic, please clickor visit the link below to unsubscribe:https://sns.us-west-2.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-west-2:210278571640:AWS-Limit:1217fddf-d8e0-4042-af10-1de467aaca07&Endpoint=ms@reancloud.comPlease do not reply directly to this email. If you have any questions orcomments regarding this email, please contact us athttps://aws.amazon.com/support-- *Thank You,**        Rafi R*--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>--  <https://hubs.ly/H0d8gJ20>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: REAN CLOUD AWS limit checker ALERT for spendhq - WARNING,,20-09-2018 15:27,2,0,SpendHQ,"Hello,This is Fadwa from AWS Accounts and Billing.I received your limit increase for the Elastic Load Balancers. I am happy to let you know that the limit increase has been approved and processed. The new limit is as follows:Region: US East (Northern Virginia)Limit name: Application and Classic Load BalancersNew limit value: 35Please allow 10 - 15 minutes for this to update in the account.Best regards,FadwaAmazon Web Services",We've raised a Limit increase request for 10 ELBs. Case ID: 5376592261,@team We got a confirmation from rohit increase the limit to raise it by 10 load balancer more.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000015XG4m,Cloud Engineer Level 1,Closed,1039936,Incident,20-12-2016 05:13,,"Closing this ticket got confirmation from Matthew.###Hi Matthew,We have successfully mounted the newly cloned volume under the mount point /mnt/db_backup-12-16-16.Please let us know if you want to change the mount point or have any further queries on this.###We have mounted the cloned volume to DB5 and got confirmation from client.###[Email Communication]Hi Mathew,We acknowledge the delivery of this email, We will mount the volume to DB5 once the clone is created from the PROD database backup.Chris: As per Matthew mentioned could you please take a snapshot of the backup volume made from PRD Database on Friday and let us know once it's done.","A backup was made of our PRD Database last Friday night. Can we please make a copy of this backup and then mount the copy to the DB5 (*.135) machine that was setup. We will need to ensure that we can roll-back to this backup without having to stop the database to create another image.Please advise when this is completed.Matthew Watts | Manager, Data Intelligence Systems | SpendHQ(r)O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com<mailto:mwatts@spendhq.com>A SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com<http://www.spendhq.com/> | www.insightsourcing.com<http://www.insightsourcing.com/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Database Volume Mount,,19-12-2016 21:14,8,0,SpendHQ,Closing this ticket got confirmation from Matthew.,"Hi Matthew,We have successfully mounted the newly cloned volume under the mount point /mnt/db_backup-12-16-16.Please let us know if you want to change the mount point or have any further queries on this.",We have mounted the cloned volume to DB5 and got confirmation from client.,"[Email Communication]Hi Mathew,We acknowledge the delivery of this email, We will mount the volume to DB5 once the clone is created from the PROD database backup.Chris: As per Matthew mentioned could you please take a snapshot of the backup volume made from PRD Database on Friday and let us know once it's done.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001Fd1uP,Cloud Engineer Level 1,Closed,1072696,Incident,10-08-2017 20:41,,"Hello SpendHQ-Team, This is to inform you that we have received an alert regarding MySQL Process is down for the instance prod-sphq-db-server05(10.59.10.135). The number of processes was found less than 5 for prod-sphq-db-server05. Later the alert got resolved and returned to normal and violation lasted for 1 minutes. Refer the resource details below,Resource Details: name:prod-sphq-db-server05 Instance ID : i-008d43ad00357e47a Private IP:10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924 Kindly validate these details and let us know if your team have any further queries regarding this case. As the alert is in the resolved state, we are marking this case as resolved.Regards,Sumod.K.Bose","[Triggered on {host:10.59.10.135,process:mysql}] [SpendHQ] MySQL Process is down - prod-sphq-db-server05  - 10.59.10.135 - db  MySQL Process is down @support@reancloud.com     @support@reancloud.comPROCS CRITICAL: 0 processes found for mysqlThis alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2014430?group=host%3A10.59.10.135%2Cprocess%3Amysql · Edit Monitor: https://app.datadoghq.com/monitors#2014430/edit · Event URL: https://app.datadoghq.com/event/event?id=3994809694937398643 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","[Monitor Alert] Triggered: [SpendHQ] MySQL Process is down - prod-sphq-db-server05 - 10.59.10.135 - db on process:mysql,host:10.59.10.135",,10-08-2017 19:04,2,0,SpendHQ,"Hello SpendHQ-Team, This is to inform you that we have received an alert regarding MySQL Process is down for the instance prod-sphq-db-server05(10.59.10.135). The number of processes was found less than 5 for prod-sphq-db-server05. Later the alert got resolved and returned to normal and violation lasted for 1 minutes. Refer the resource details below,Resource Details: name:prod-sphq-db-server05 Instance ID : i-008d43ad00357e47a Private IP:10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924 Kindly validate these details and let us know if your team have any further queries regarding this case. As the alert is in the resolved state, we are marking this case as resolved.Regards,Sumod.K.Bose",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001ULKaS,Cloud Engineer Level 3,Closed,1095807,Incident,26-04-2018 07:45,,"Hello Team,We are tracking this case on another ticket. Case id:01097357.Hence, we are closing this case.###Please check with Praveen as the customer mentioned this as a high priority###Matthew Watts8:25 PM (26 minutes ago)to David, Kapil, Manideep, REAN Can we please expedite this request REAN###Hello Matthew/David,We are actively working on this request and we will get back to you with the updates shortly.###David Miller <dmiller@spendhq.com>8:10 PM (4 minutes ago)to Kapil, Manideep, Matthew, REAN Guys,It’s been over a week, we will need some solution to this issue to later than this Friday.  Please advise.David###Last night we asked Praveen regarding multiple tickets but he was busy with some other priority tasks.Next Action: Please check with Praveen to have a look at this issue.###Morning Ops call Rohit Updated that We need to check With Praveen to proceed further on this case###Hello David,We are currently looking into the case and will get back to you soon.###David Miller <dmiller@spendhq.com>1:01 AM (0 minutes ago)to Manideep, Matthew, REAN Is there any update on this issue?###I asked Praveen to assist us in this case.Next Action: Please check with Praveen to proceed further on this case.###David Miller7:39 PM (21 minutes ago)to me, Matthew, REAN I was able to repeat this issue using chrome as well.###Manideep Gunda <manideep.gunda@reancloud.com>7:54 PM (6 minutes ago)to David, Matthew, REAN Hello Devid,We will check on this and will get back to you with details.###Hello Mattew,As we went on a call David and tried to replicate the issue but we didn't find any issue at our end.  It might be the issue with Mozilla browser David is using. In case it is just because of the browser we want to get clear on this aspect as we did not find anything unusual in the logs.###This issue is now just localized to me, this issue was first reported by our QA engineer.  I will try and replicate on chrome to see if that fails as well.###Hello David,As the issue still exists we suspect re-installing the browser will resolve the issue.###In this case, nothing is pending from our end. As we tried to replicate the issue when we were on call with David. But we dint get any issue in uploading files of around 32KB size each 40 files at time. We were successful to do so. We made changes to Proxy Timeout of Apache and enabled the stickness. We rollback these changes.  We asked David to re-install the Browser as this was issue with him only. None from our team faced the issue while uploading the files.@Team: Please get back to David asking him if he re-install the browser and tried again to upload the files in morning time EST.###Hello Team,I Have joined the call with the customer I modified the stickness values at ELB level with port 80 and 443 and 8443 but still customer facing the same issue. I have added proxy Timeout value 1000 still customer facing the issue I conveyed this to Rohit.Next Action: Need to check with Rohit in this case.###Hi David,Please let us know when are you available to setup a call today. Thanks !Regards,Rohit Puri###Rohit updated that he will schedule a call with the customer today.###Rohit updated that he is working on this case###Rohit updated in eve. ops call that he will look into this.Next Action: Check with Rohit for further updates.###Hello David,We are currently working on this and will get back to you with an update.###David Miller <dmiller@spendhq.com>11:44 PM (48 minutes ago)to praveen.muppala, Rohit, spendhq-support Whats the status on this?###praveen.muppala@reancloud.com8:18 PM (5 minutes ago)to Rohit, David, spendhq-support Thank you David. Including spendhq-support@reancloud.comOur team will get back to you with a fix for this.Regards,-Praveen###From: David Miller <dmiller@spendhq.com> Sent: April 12, 2018 9:42 AMTo: praveen.muppala@reancloud.comSubject: Re: Server Support IssueYes small batches work, but we need to be able to handle large uploads like 40 (we accept 40 max), these files are also only 2kb each.  This needs to be fixed on both preview and production, but go ahead and fix preview first and let us know what the solution is FIRST before touching production.Thank YouDavid###praveen.muppala@reancloud.com4:03 PM (7 minutes ago)to spendhq-support, parvesh.pothur., David Hello David, This kind of Proxy Errors causes because of the timeout issue either in Apache or Tomcat when they communicate to upstream server. In our case, we have many proxy servers where the data upstream to the serves. ELB – Sophos – Apache – Tomcat – Database == This is how data traverse from your browser to the application. Timeout in any of these cases will result into the below issue. Can you pleas try small count of files upload instead of 40 at a time, may be batch of 10. And also, can you confirm this issue is happening for secure.spendhq.com so that, our team will get the timeout details of these services. Regards,-Praveen###Hello David,Could you please let us know your availability to get on a call in your morning hours to further discuss this issue. We need more information regarding this case.###Afternoon shift team please setup a call with customer in their morning hours. We need more information on this case.###Rohit is checking in this case.Next action: Need to check with Rohit for the further updates.###In morning call, Rohit updated that he will check in this case.###Hello David,We will look into this issue and will get back to you shortly.","Rean,I am currently on 10.59.100.170 and uploading 40 files but received a proxy error.Proxy ErrorThe proxy server received an invalid response from an upstream server.The proxy server could not handle the request POST /files/upload_document<chrome://devtools/files/upload_document>.Reason: Error reading from remote serverDirectory: /var/www/vhosts/secure.spendhq.com/publicurl: https://preview.spendhq.com/filesDirections: Upload 40 small files, use firebug console to see the ajax request and response with the above.Not sure how to fix this, please advise.  Please feel free to each out and ask more questions if need be.DavidDavid Miller | Developer | SpendHQdmiller@spendhq.comwww.spendhq.com<http://www.spendhq.com/>--  <http://go.reancloud.com/gartner-magic-quadrant>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Server Support Issue,,11-04-2018 02:16,366,0,SpendHQ,"Hello Team,We are tracking this case on another ticket. Case id:01097357.Hence, we are closing this case.",Please check with Praveen as the customer mentioned this as a high priority,"Matthew Watts8:25 PM (26 minutes ago)to David, Kapil, Manideep, REAN Can we please expedite this request REAN","Hello Matthew/David,We are actively working on this request and we will get back to you with the updates shortly.","David Miller <dmiller@spendhq.com>8:10 PM (4 minutes ago)to Kapil, Manideep, Matthew, REAN Guys,It’s been over a week, we will need some solution to this issue to later than this Friday.  Please advise.David",Last night we asked Praveen regarding multiple tickets but he was busy with some other priority tasks.Next Action: Please check with Praveen to have a look at this issue.,Morning Ops call Rohit Updated that We need to check With Praveen to proceed further on this case,"Hello David,We are currently looking into the case and will get back to you soon.","David Miller <dmiller@spendhq.com>1:01 AM (0 minutes ago)to Manideep, Matthew, REAN Is there any update on this issue?",I asked Praveen to assist us in this case.Next Action: Please check with Praveen to proceed further on this case.,"David Miller7:39 PM (21 minutes ago)to me, Matthew, REAN I was able to repeat this issue using chrome as well.","Manideep Gunda <manideep.gunda@reancloud.com>7:54 PM (6 minutes ago)to David, Matthew, REAN Hello Devid,We will check on this and will get back to you with details.","Hello Mattew,As we went on a call David and tried to replicate the issue but we didn't find any issue at our end.  It might be the issue with Mozilla browser David is using. In case it is just because of the browser we want to get clear on this aspect as we did not find anything unusual in the logs.","This issue is now just localized to me, this issue was first reported by our QA engineer.  I will try and replicate on chrome to see if that fails as well.","Hello David,As the issue still exists we suspect re-installing the browser will resolve the issue.","In this case, nothing is pending from our end. As we tried to replicate the issue when we were on call with David. But we dint get any issue in uploading files of around 32KB size each 40 files at time. We were successful to do so. We made changes to Proxy Timeout of Apache and enabled the stickness. We rollback these changes.  We asked David to re-install the Browser as this was issue with him only. None from our team faced the issue while uploading the files.@Team: Please get back to David asking him if he re-install the browser and tried again to upload the files in morning time EST.","Hello Team,I Have joined the call with the customer I modified the stickness values at ELB level with port 80 and 443 and 8443 but still customer facing the same issue. I have added proxy Timeout value 1000 still customer facing the issue I conveyed this to Rohit.Next Action: Need to check with Rohit in this case.","Hi David,Please let us know when are you available to setup a call today. Thanks !Regards,Rohit Puri",Rohit updated that he will schedule a call with the customer today.,Rohit updated that he is working on this case,Rohit updated in eve. ops call that he will look into this.Next Action: Check with Rohit for further updates.,"Hello David,We are currently working on this and will get back to you with an update.","David Miller <dmiller@spendhq.com>11:44 PM (48 minutes ago)to praveen.muppala, Rohit, spendhq-support Whats the status on this?","praveen.muppala@reancloud.com8:18 PM (5 minutes ago)to Rohit, David, spendhq-support Thank you David. Including spendhq-support@reancloud.comOur team will get back to you with a fix for this.Regards,-Praveen","From: David Miller <dmiller@spendhq.com> Sent: April 12, 2018 9:42 AMTo: praveen.muppala@reancloud.comSubject: Re: Server Support IssueYes small batches work, but we need to be able to handle large uploads like 40 (we accept 40 max), these files are also only 2kb each.  This needs to be fixed on both preview and production, but go ahead and fix preview first and let us know what the solution is FIRST before touching production.Thank YouDavid","praveen.muppala@reancloud.com4:03 PM (7 minutes ago)to spendhq-support, parvesh.pothur., David Hello David, This kind of Proxy Errors causes because of the timeout issue either in Apache or Tomcat when they communicate to upstream server. In our case, we have many proxy servers where the data upstream to the serves. ELB – Sophos – Apache – Tomcat – Database == This is how data traverse from your browser to the application. Timeout in any of these cases will result into the below issue. Can you pleas try small count of files upload instead of 40 at a time, may be batch of 10. And also, can you confirm this issue is happening for secure.spendhq.com so that, our team will get the timeout details of these services. Regards,-Praveen","Hello David,Could you please let us know your availability to get on a call in your morning hours to further discuss this issue. We need more information regarding this case.",Afternoon shift team please setup a call with customer in their morning hours. We need more information on this case.,Rohit is checking in this case.Next action: Need to check with Rohit for the further updates.,"In morning call, Rohit updated that he will check in this case.","Hello David,We will look into this issue and will get back to you shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001VMaF0,Cloud Engineer Level 3,Closed,1097357,Incident,28-06-2018 19:07,,"Hello David,Thanks for the confirmation.We are marking this as closed. Please feel free to reach us if you have any issues.###David Miller6:56 PM (9 minutes ago)to Rohit, Matthew, Chirodeep, REAN, Praveen Seems to be working, please go ahead and close the ticket, thank you!###Hello Team,This is the gentle reminder.Please review the details mentioned in the previous comment and let us know if you have any queries.###Hello All, The files upload 502 bad gateway issue is resolved. Here is the background of the issue. For secure.spendhq.com, we have 3 levels of web proxies before the request reaches to the Server : 1. External ELB, 2. Sophos WAF, 3. Internal ELB. All the 3 Proxies should have the same KeepAlive timeout Value that is greater than 15 mins because most of the time the files are taking anytime between 9 mins to 16 mins depending on size when David was doing his uploads. Solution : So we have updated the Timeout session to 3600 seconds across all the 3 Proxy layers as per David recommendation. External ELB – IdleTimeout SessionSophos WAF , Real Web Servers, Advanced, KeepAlive TimeoutInternal ELB – IdleTImeout Session. Additional Information : We are not making this KeepAliveTimeout changes at real EC2 Apache Service because the request is doing the files upload process and it is actively handled by Apache and it is not in idle state. But where as the proxy layers passed the request and waiting for an response from Apache hence they need KeepAliveTimeout. Let us know if you need any additional details on it. Regards,-Praveen###@Praveen:Yesterday we have made changes in the Internal ELB, External ELB and Sophos Virtual Webserver Configuration and increased the timeout to 3600. As asked by you, I have checked the Instance Level Virtual Host configuration for secure.spendhq.com in both the instances  PRD-WW2_6 and PRD-WW1_122. We did not found any entry for timeout.Do we include the TimeOut 3600 entry in both the instances and ask them for reload/restart permission of apache?Let me know your feedback on this. Thanks !###I have talked with Rohit regarding this case and he updated that he will update case.###Hi Rohit,It was nice working with you today.I have created new case that is linked to the previous case that I will close. However, your new case number is #8075166 , All the troubleshooting done with previous case is linked to this new case. Please update me if issue gets resolved with the timeout value on HTTP and ELB timeout. Regards, Harsh Patel Sophos Technical Support###The call is scheduled for today. Please check with Rohit for the update###Hello David, Thank you for reiterating. On Monday call, we will nail down the root cause of the issue with the 3 possible scenarios while Sophos is also on the call with us. Directly accessing the portal over Private IP address of the Web Server by making an host entry.Directly accessing the portal over public IP ELB bypassing the Sophos WAFAccess the portal using regular method via Sophos WAF. Our team will help you to simulate all the scenarios and capture the results while Sophos engineer is with us for further analysis. Regards,-Praveen###Another dev has experienced the “proxy error” on another page.  We are highly concerned that this issue is of highest priority and needs to be fixed asap.  Please research and provide us a plan to fix this issue because we can’t keep dealing with this every day. ThanksDavid###David Miller12:17 AM (4 minutes ago)to Rohit, Chirodeep, REAN Let’s schedule a meeting for Monday June 25th around 10:30 EST###David Miller9:20 PM (18 hours ago)to Rohit, Chirodeep, REAN Thank You Rohit, I’ve been out of the office and haven’t had time, let me retest this and get back to you on scheduling a time to screenshare with you. ThanksDavid###Rohit Puri3:09 PM (26 minutes ago)to David, Chirodeep, REAN Hi David,Thanks for the response. Let us know once you are done with the testing again. Regards,Rohit Puri###Hello David, We haven't heard back from you. Could you please provide your availability to schedule a screen share call with Sophos Team to troubleshoot the issue. Let us know if you have any concerns.###Please reach out to David for the call###Hello Team,Rohit discussed the same on call with Mathew. He said david will be available on Monday.Next Action: Need to reach out to david today for the call.###Rohit will check with Matthew on Sync up call.###Rohit will speak with Matthew to get David contact details to complete this request.###Hello David, We haven't heard back from you.Could you please provide your availability to schedule a screen share call with Sophos Team to troubleshoot the issue. Let us know if you have any concerns.###Rohit updated that we need to setup a call with David and then call Sophos team to troubleshoot this issue.###Next steps:if David respond with the time frame, then call Sophos to be available and share the ticket number with Sophos for reference###Hello David,Could you please provide your availability to schedule a screen share call with  Sophos Team to troubleshoot the issue.  Let us know if you have any concerns.###Hello Team,After extensively reviewing the ticket I found that issue is isolated with UTM. Let's working towards resolving this issue. Help me setting up a call between David, Sophos Support and I will make sure I will be available for the call.Here is our approach.1. Test the site via the Public ELB(without Sophos), we will create a public ELB, get the ELB IP and add hosts entry and test it2. Test the site via the Internal IP add hosts entry and test it3. Test the site via the Sophos(regular approach) while doing it perform the tcpdump and share it with UTM to analyze it further.Regards,-Praveen###Praveen mentioned that he is working on this case and will update.###I have pinged to Praveen for the update but he was not available.###OPS call Praveen mentioned that he will review and provide an update to Rohit on this case###Chirodeep updated that he will check with Rohit to get further update on this case.###I have pinged to Praveen for this case but there is no response from him.###Please reach out to Praveen for his help to troubleshoot the issue###Hello Matthew,We  will check on the issues  in Sophos and will let you know the updates###n this case this is an issue with Sophos. Can you raise this with Sophos as we have no control over that implementation as REAN manage it. Please aim to have it resolved by the End of Business today. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting###Hello Matthew,We have tested scenario by uploading files on the site with and without connecting to Sophos and confirmed that files are uploaded successfully from our end.@David, Please let us know how frequently you are facing the issue, is it every time when you are trying to upload the files. Kindly try to upload files from other local machines too and let us know whether you are able to replicate the issue over there. Revert back to us if you have any further concerns.###While you wait for @David Miller to respond, can you please try this without connecting to Sophos and advise if you still get the same issue. This has to be resolved asap as it’s been ongoing for over a month. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting###Thenmozhy D <thenmozhy.d@reancloud.com>2:20 PM (5 minutes ago)to David, Rohit, REAN, Matthew Hello David,Please let us know your availability time so that we can set up a call with you to troubleshoot this issue.Kindly revert back to us in case of any queries.###Setup a call with David in EST Time and troubleshoot the issue as steps provided by SOPHOS Team###Hello Team,We are actively working along with Sophos team and get back to you with updates shortly.###Rohit updated in eve Ops call that he will do a detailed discussion with Praveen for this case.Next Action: Please check with Rohit.###In morning ops call, Rohit updated he will check with Praveen regarding this case and let us know how to proceed further in this case.###Hello Manideep,It was a pleasure speaking with you today.As discussed on the phone, this issue seems unusual as if there was an issue with the UTM everyone should be having an issue not just the client from where he's uploading the files from. Please use wireshark on the server while the client is trying to upload a few files and review the output. Also collect the tpcdump pcap files from the UTM and open it up in wireshark to also review. To capture the traffic on the firewall you could use this command. log into the UTM as root and run the following commands in 2 putty sessions at the same time (tcpdump -veni eth1 host 10.59.100.113 -w /home/tmp/tcpdata.pcap) and (tcpdump -veni eth1 host 10.59.100.6 -w /home/tmp/tcpdata.pcap), this will store the capture in cd /home/tmp directory. You can then connect using winscp to log into the utm using username loginuser and copy those packet cap. If you need to upload the pcaps to our ftp, you can using the steps below. Please keep me updated on your progress.FTP Directory:	/cases/8075166FTP Username:	8075166FTP Password:	E57bc34942FTP Instructions:	Configuring your FTP Client to connect to Sophos' FTP###Hello Team,Thank you for the email,We will set up a meeting at 1:30 PM EST (11 PM IST). Whenever you are available to please call +917337263007 Name: Manideep. We will set up a meeting bridge and share the details with you to join the call.###Please check with chirodeep, regarding the update from Sophos team.###Hello Manideep, I will be arranging for a call back Tuesday May 29th around 12 PM IST.Which number is best to reach you?###Hello Team,You can directly send an email to ms@reancloud.com dl with call details. And you can also use +91 9001952605 Name: Rohit###Hello Team,We will be available 12:00 PM IST. Please reach out to available engineers and schedule a call. And please don't forget to CC ms@reancloud.com dl while sending the emails.###Please provide me with your availability for tomorrow.For any call backs, we ask the session to be scheduled at least a day before.Once we have your availability (with time zone) I can reach out to available engineers at that time.Also, you always have an option contact us directly with the case number at any time.###Hello Team,We have some queries regarding this previous email. If it is possible please provide your availability to set up a call to discuss more on this issue. Whenever you are available please call me +917337263007. I will set up a meeting bridge and share the details with you to join the call.###Please get a call with Sophos and ask below-mentioned query:1: Which internal elb is fulfilling the request for preview.spendhq.com?2: How did you find and which log you can say the request is handling by this internal elb.###I have forwarded Sophos mail to Rohit.###@Team: Please provide me the mail sent to us by Sophos for the whole analysis the done. As how they are sure about the request is going to this internal ELB from SOPHOS.###Rohit is working on this case. Please check with him for the further update on this case.###@Rohit Please look into this case.Please check with Rohit in Morning hours.###Rohit is not available today and we have tried to reach out Yogesh he is not reachable.###I reached out to Rohit but there is he was not available.@afternoon Team: please check with Rohit.###Hello David,As per the Sophos team update, the request was passing to an internal ELB internal-newpreview-elb-1657548324.us-east-1.elb.amazonaws.com. When we tried to access this ELB we are redirecting to another site instead of secure.spendhq.com. We are reviewing the details provided by Sophos team with our internal team and will get back to you with an update.###David Miller1:05 AM (3 hours ago)to me, Rohit, REAN, Matthew Can you provide the IP address I can use for the upload?###Hello Dave,Thanks for joining the call.Here is the summary that Sophos team provided with us.During our session, we were able to isolate the issue regarding HTTP post request returning with status code 502.The client makes HTTP post request to https://secure.spendhq.com/files but the return we get is Error reading from remote server returned by /files/upload_document, referer: https://secure.spendhq.com/filesWe are unsure as to why the REAL web server that is hosting the page is returning an error code 502.It may be that the path /files/upload_document is somehow not valid in the real server (maybe the path does not actually exists?)It is clear at this time that the UTM is not explicitly blocking this traffic (no security error).Overall, this is an issue that has to be resolved from the real web server itself.UTM in reverse proxy deployment simply forwards requests, it does not host any real resources.As per the suggestion by Sophos team, can you please perform an upload of files from internal ELB to the REAL web server and see if any proxy error is showing up.  So that we can conclude the above points provided by the Sophos team.###We have informed Sophos team regarding this. Once received update from Sophos team, we  can share the bridge with customer###Hello David,Thanks for the update.We will check with Sophos team and will share the bridge link at 1.30 PM EST###David Miller9:24 PM (12 minutes ago)to Rohit, REAN, Matthew I am available around 1:30 / 2ish, can you send the bridge link when your ready###@AfterNoon Team:Please set up a call with Sophos once we heard back from the customer.###Hi David,We shared the logs and other details with SOPHOS. But they need us to upload the files live. Please let us know when you are available today for the call with SOPHOS so that we go ahead and set up a call with them as per your availability. Thanks !Regards,Rohit Puri###David Miller2:46 AM (3 hours ago)to me, REAN, Matthew Just received the proxy error IP: 159.100.161.41Time: 5:10 – 5:15 pm We also had someone say when they tried to download a file they also received a proxy error, but it may have been from a long running query###Sophos Support <support@sophos.com>Attachments4:43 AM (1 hour ago)to rohit.puri, kapil.bokdia, ms Hello Rohit,Based on the logs provided, there are some modsecurity rules being hit during the provided time. We may need to create exception for those rules but we need to capture live traffic to make sure we are doing exception to the correct one. Please advise when you can arrange an upload test and while doing it, we capture logs in real time.###Jamelunissa Mohammed <jamelunissa.mohammed@reancloud.com>2:26 AM (3 hours ago)to David, REAN, Matthew Hello David,Could please let us know whether the issue still persists when trying to upload files from your machine on secure.spendhq.com even after changes done by SOPHOS team by increasing timeout.###Hi David, We haven't heard back from you. Please try to upload files from your machine on secure.spendhq.com as few changes been made by SOPHOS team to increase the timeout. Let us know if you still face the same issue.###Hi David, We haven't heard back from you.Please try to upload files from your machine on secure.spendhq.com as few changes been made by SOPHOS team to increase the timeout. Let us know if you still face the same issue.###Hi David,Please try to upload files from your machine on secure.spendhq.com as few changes been made by SOPHOS team to increase the timeout. Let us know if you still face the same issue. Thanks!Regards,Rohit Puri###Hello David,This was the IP you have provided earlier. Could you please provide some more information regarding the issue you are facing now.###David Miller3:27 AM (1 minute ago)to Rean, spendhq-support The ip address doesn’t seem to be working###Hello David, we haven't heard back from you, Please try once again to upload the file from IP: 74.115.21.213 and let us know if you are still facing the same issue.###Hello David, we haven't heard back from you,Please try once again to upload the file from IP: 74.115.21.213 and let us know if you are still facing the same issue.###Hello David,Please try once again to upload the file from IP: 74.115.21.213 and let us know if you are still facing the same issue.###Kapil Bokdia <kapil.bokdia@reancloud.com>4:56 AM (1 hour ago)to anthonythomas.., support, REAN Hi Anthony,As discussed on the call, Please find the bridge details.https://reancloud.zoom.us/my/mgse1###Sophos Support5:57 AM (1 minute ago)to me, ms Hello Kapil,As per last troubleshooting, we have modified the following: /var/storage/chroot-reverseproxy/usr/apache/conf/httpd.conf Timeout 1800 MaxKeepAliveRequests 1000 KeepAliveTimeout 60 Then we restarted the reverseproxy: /var/mdw/scripts/reverseproxy restartPlease check and confirm with clients if all is good. Regards, Tony Bueta###Hi Gourav,I have tried to reach out to the other team and it seems they will be able to give you a call after 6 pm EST. However, you can call us in when you have test user that can reproduce this issue. Please note that our technical support teams are available 24/7 and can be contacted on your local Technical Support number listed on our website: https://www.sophos.com/en-us/support/contact-support.aspx###Sophos Support2:09 AM (24 minutes ago)to me, ms, rohit.puri Hi Gourav,It was nice speaking with you today.We started our session at 3.30 pm EST as I was on another inbound call and was not able to give you a call at 3 pm.During our session we wanted to reproduced the issue and collect the logs as the logs you have provided earlier did not have any logs for the IP address 74.115.21.213.we tried to replicate the issue but there was no response from your client. It is my end of the shift so as agreed on the call I am handing over this case to the next region.###Hello David,Can you upload the file with this Ip: 74.115.21.213###Gourav Pokhra <gourav.pokhra@reancloud.com>10:51 PM (33 minutes ago)to support, REAN, Rohit Hello Team,Thank you for the email,I will set up a meeting at 3 PM EST (12:30 AM IST). Whenever you are available please call me +918696096500. I will set up a meeting bridge and share the details with you to join the call.Thanks & Regards,Gourav Pokhra###We will setup a call to analyse the logs with SOPHOS and try to close it on call today itself.###We have shared the reverse-proxy logs with Sophos and waiting an response from Sophos team to provide an analysis on this Mail thread: RE: [#8075166] Error reading from remote server - WAF HTTP Proxy -- Priority: High -- Level: Premium###I have checked the WAF logs for yesterday, not able find any logs related to the ip:74.115.21.213 provide by David###I have informed to Rohit in this case and he will look and will udpate.###Hello David,We will analyze the logs and will let you know the updates.###David Miller11:33 PM (0 minutes ago)to Rohit, REAN, Praveen, Matthew I replicated the issue right around 2pm Eastern time today. IP: 74.115.21.213Domain: secure.spendhq.com/files###Hello David,We haven't heard back from you.Thanks for updating us on the issue. Will you please tell us the IP of the machine from where you try to upload the files and you face this issue? As this will help us to analyze the logs.###Hi David,Thanks for updating us about the issue. Will you please tell us the IP of the machine from where you try to upload the files and you faces this issue? As this will help us to analysis the logs. Thanks !Regards,Rohit Puri###I have checked the WAF logs during the time mentioned by the customer. I can found 403 and 408 response code error at that time. Please verify the WAF logs again and check whether we can fount any error during them###Please check the WAF logs around the time mentioned by the customer. Check with Rohit and respond back to Sophos for the regarding the issue.###I  have checked the instance level PRD-WW2_6 and PRD-DB1 server logs, we can a network spike in 4 am utc. And also I have seen a  memory issue on the web server around 11:52 am est other than this I could find any issues.May  4 11:52:58 ip-10-59-101-6 kernel: python invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0May  4 11:52:58 ip-10-59-101-6 kernel: python cpuset=/ mems_allowed=0May  4 11:52:58 ip-10-59-101-6 kernel: Pid: 2366, comm: python Not tainted 2.6.32-696.3.1.el6.x86_64 #1May  4 11:52:58 ip-10-59-101-6 kernel: Call Trace:May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff81131680>] ? dump_header+0x90/0x1b0May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff8123c30c>] ? security_real_capable_noaudit+0x3c/0x70May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff81131b02>] ? oom_kill_process+0x82/0x2a0May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff81131a41>] ? select_bad_process+0xe1/0x120May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff81131f40>] ? out_of_memory+0x220/0x3c0May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff8113e91c>] ? __alloc_pages_nodemask+0x93c/0x950May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffffa008b4a0>] ? ext4_get_block+0x0/0x120 [ext4]May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff81177b6a>] ? alloc_pages_current+0xaa/0x110May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff8112ea77>] ? __page_cache_alloc+0x87/0x90May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff8112e45e>] ? find_get_page+0x1e/0xa0May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff8112fa17>] ? filemap_fault+0x1a7/0x500May  4 11:53:06 ip-10-59-101-6 kernel: Out of memory: Kill process 16483 (httpd) score 263 or sacrifice childMay  4 11:53:06 ip-10-59-101-6 kernel: Killed process 16483, UID 48, (httpd) total-vm:9004396kB, anon-rss:8631136kB, file-rss:916kB###Hello Rohit, Lets carefully look at the response times, Network In/Out metrics and DB response. @David Miller or @Matthew Watts – Are these files will be stored in DB or NFS file system. So that, it will be easy for us to nail down further. praveen.muppala@reancloud.com###David Millerto praveen.muppala, Rohit, Matthew, REAN They are stored on a mounted volume on the web server, there are references to them in the database as well.###I have tried to call Rohit but he was not available.Next action: Check with Rohit for the further action.###Hello David,We are checking on this and will let you know the updates.###David Miller8:10 PM (2 minutes ago)to Rohit, REAN, Praveen, Matthew So I am no longer able to reproduce the error on our preview.spendhq.com.  I was however able to reproduce it on secure.spendhq.com between 10:10am and 10:15am if that helps###Follow up the customer on Monday afternoon shift and confirm the issue has been resolved or not.###Hi David,As discussed on the call, this issue seems to be not there while uploading the files. Now you are able to upload the files successfully. We are moving this ticket from Sev1 to Sev4. We will keep this ticket open for 3-4 days so that if you face the issue again. Please share the timestamp and source IP of the machine when you face the issue again. So that we will go ahead and analysis the logs. Thanks for keeping patience with us and giving your time to join the meeting. Have a great day ! Regards,Rohit Puri###David Miller10:58 PM (4 minutes ago)to Rohit, REAN, Praveen, Matthew Yes I can do 2Get Outlook for Android###Thanks David. Please join the same bridge.Rohit Puri###Hi David,We have already re-scheduled the call with SOPHOS for 2PM EST today. Will you be able to join? Regards,Rohit Puri###Anytine today after 2:30 or Friday before 11:30 or after 1Get Outlook for AndroidDavid Miller###David Miller10:52 PM (3 minutes ago)to Rohit, REAN, Praveen, Matthew Anytine today after 2:30 or Friday before 11:30 or after 1###Hi David,We have already re-scheduled the call with SOPHOS for 2PM EST today. Will you be able to join? Regards,Rohit Puri###Hi David,We have re-schedule the call to 2PM EST today. Please join the call at the same bridge. Thanks !Regards,Rohit Puri###Hello David,Can you please provide your availability so we can reschedule the call tomorrow and will send the meeting invite. Thanks & Regards,Gourav Pokhra###David Miller7:49 PM (2 hours ago)to Rohit, REAN, Praveen, Matthew I have a meeting at 1, can we push to 2?###Hi David,Yesterday Sophos Team was not available to setup a call to resolve this issue. We have scheduled a call for today at 1:00 PM EST.Please find the bridge details for today’s call.Join from PC, Mac, Linux, iOS or Android: https://reancloud.zoom.us/j/6709937998Or iPhone one-tap :    US: +16465588656,,6709937998#  or +16699006833,,6709937998# Or Telephone:    Dial(for higher quality, dial a number based on your current location):        US: +1 646 558 8656  or +1 669 900 6833  or +1 855 880 1246 (Toll Free) or +1 877 369 0926 (Toll Free)     Meeting ID: 670 993 7998     International numbers available: https://zoom.us/u/ZDxaXRegards,Rohit Puri###Hello Rohit/Joydip,Thanks for your call today and we deeply apologize for missing the scheduled call yesterday. As agreed on call, we will arrange the callback today at 1-2 PM EST today.Please send us the Zoom meeting bridge by replying to this email, and the assigned engineer will join the bridge accordingly.Regards, Ashish Das Sophos Technical Support###Hello David,Once the Sophos team is available we will send the meeting invite to you.###David Miller8:25 PM (18 minutes ago)to Rohit, REAN, Praveen, Matthew Please send the meeting link when it’s available, thank you###Hi David,Thanks for testing it out. We have setup a call with SOPHOS Team today 11:00 AM EST. Once they will be available, I will share with you the Meeting Details. Please be available to join the call as they want to analysis the live logs. Thanks !Regards,Rohit Puri###Hi David,Thanks for testing it out. We have setup a call with SOPHOS Team today 11:00 AM EST. Once they will be available, I will share with you the Meeting Details. Please be available to join the call as they want to analysis the live logs. Thanks !Regards,Rohit Puri###We have informed Rohit, He mentioned that he is replying to them.###David Miller6:19 PM (13 minutes ago)to Rohit, REAN, Praveen, Matthew I am working from home today (similar to our clients) and still receiving the proxy error.  Could this be a load balancer issue by change?  I was not on the Sophos vpn while testing this time around either###David Miller6:19 PM (2 minutes ago)to Rohit, REAN, Praveen, Matthew I am working from home today (similar to our clients) and still receiving the proxy error.  Could this be a load balancer issue by change?  I was not on the Sophos vpn while testing this time around either###Hi David,We have made changes in the SOPHOS WAF Configuration. Please try to upload the files on https://preview.spendhq.com/files and let us know if you still have any issue for the same. If issue still persist, then we will schedule a call today with the SOPHOS Team and we will invite to the call. Thanks !Regards,Rohit Puri###@Team: I had a call with the SOPHOS Team and discuss the issue again with them that we have confirmed the issue is not at instance level. They were not able to help much now. They asked us to setup a call with the SpendHQ Team so that they can see the live logs at the same time to help us resolve the issue. So we have asked the SOPHOS Team to be available at 11 AM EST so that I will schedule a call with David Miller so he can replicate the issue.###Hello David,We will check on this and will get back to you shortly.###Rohit I tried the following: I Uploaded files to http://10.59.100.170/files with success.I uploaded the same files to https://preview.spendhq.com/files after changing my hosts and I received a proxy error. I also had an outside source upload the same files and received a proxy error as well.  They were not in the office and more of a realistic client setup. This is still a sev1 as out clients are having this issue outside the office/vpn settings.ThanksDavid###Hi David,We have reached out to SOPHOS on this issue but they have told us this issue is at the instance level only. We have seen that the apache configuration there is no changes needs to be made. But for getting more sure on this that the issue is not at instance level we need you to make one more test. Testing Steps:1. Please make changes in the /etc/hosts file of your local machine and make the entry for 10.59.100.170	https://preview.spendhq.com/files and save it. 2. Now Connect to SOPHOS SSL VPN.3. Try to upload the files again on URL: http://10.59.100.170/files and https://preview.spendhq.com/filesPlease let us know if you are successful to upload the files or not. On the basis of that we will work with SOPHOS team to get it resolve. Thanks !Regards,Rohit Puri###We have checked with Praveen and he mentioned that he will provide steps to further look into this issue.###Please ask Praveen to look into the suggestion provided by the Sophos Team as we cannot go ahead and disable the WAF this might affect the Customer environment.###SOPHOS team told us that there is no issue with WAF at SOPHOS end. The issue is at instance level only. They asked us to disable the proxy and use DNAT to confirm the issue is at instance level only. Need to confirm with the Praveen if we disable the WAF on preview URL and check the issue if this at instance level or SOPHOS side.###We got a response from Sophos Team.Sub: RE: [#8075166] Error reading from remote server - WAF HTTP ProxyI already inform Rohit regarding this.Please check with for further updates.###Rohit and Team, please work with Sophos Support team on Monday morning and get ready for the updates by Monday Ops call.Regards,-Praveen###Hello Matthew,We are actively working on this case to resolve this issue. Will let you know the updates shortly.###Still getting the error. <!DOCTYPE HTML PUBLIC -//IETF//DTD HTML 2.0//EN><html><head><title>502 Proxy Error</title></head><body><h1>Proxy Error</h1><p>The proxy server received an invalidresponse from an upstream server.<br />The proxy server could not handle the request <em><a href=/files/upload_document>POST&nbsp;/files/upload_document</a></em>.<p>Reason: <strong>Error reading from remote server</strong></p></p></body></html>###Matthew Watts9:23 PM (19 minutes ago)to Rohit, David, REAN, me, Praveen Looking into it now.###Hi Mathew/David,Will you please try to upload the files? We do have made some changes in the apache configuration.Let us know if you still facing the issue while uploading. Thanks !Regards,Rohit Puri###Hello Matthew,Please join the below bridge.https://zoom.us/j/988612347###Matthew Watts5:32 PM (12 minutes ago)to Jamelunissa, David, Rohit, REAN Please, can we have this meeting at 11 as I already have a meeting.###Hello Matthew,Thanks for the update.We will schedule the call at 11 AM EST and will share you the bridge details. Please revert back to us in case of any queries.###Hello David,We scheduled the call tomorrow at 9 AM EST and will share you the bridge details. Please let us know whether it is feasible time for you to join the call.###David Miller2:28 AM (56 minutes ago)to praveen.muppala, Matthew, Rohit, spendhq-support There is no reason to touch tomcat.  Please schedule a call with Matthew and I to sort this out.  Thank You###No David.We generally don’t manage the tomcat. It will be Matt or your dev team. Hence the changes are not made. In the below email also, I asked your team to make the changes.Regards,-Praveen###Hello Team,As you have discussed with Praveen please test and let us know if the issue is resolved or not.###Praveen updated that he has made some changes in the apache and informed David and Matthew to test it form their end.###Hello David,We are working on this issue and will let you know the updates.","Rean,We have to promote this issue to a Sev 1 as our clients can now not uploaddocuments due to the proxy error issue.Please advise and provide feedbackDavid",Fwd: Sev1,,25-04-2018 23:40,1531,0,SpendHQ,"Hello David,Thanks for the confirmation.We are marking this as closed. Please feel free to reach us if you have any issues.","David Miller6:56 PM (9 minutes ago)to Rohit, Matthew, Chirodeep, REAN, Praveen Seems to be working, please go ahead and close the ticket, thank you!","Hello Team,This is the gentle reminder.Please review the details mentioned in the previous comment and let us know if you have any queries.","Hello All, The files upload 502 bad gateway issue is resolved. Here is the background of the issue. For secure.spendhq.com, we have 3 levels of web proxies before the request reaches to the Server : 1. External ELB, 2. Sophos WAF, 3. Internal ELB. All the 3 Proxies should have the same KeepAlive timeout Value that is greater than 15 mins because most of the time the files are taking anytime between 9 mins to 16 mins depending on size when David was doing his uploads. Solution : So we have updated the Timeout session to 3600 seconds across all the 3 Proxy layers as per David recommendation. External ELB – IdleTimeout SessionSophos WAF , Real Web Servers, Advanced, KeepAlive TimeoutInternal ELB – IdleTImeout Session. Additional Information : We are not making this KeepAliveTimeout changes at real EC2 Apache Service because the request is doing the files upload process and it is actively handled by Apache and it is not in idle state. But where as the proxy layers passed the request and waiting for an response from Apache hence they need KeepAliveTimeout. Let us know if you need any additional details on it. Regards,-Praveen","@Praveen:Yesterday we have made changes in the Internal ELB, External ELB and Sophos Virtual Webserver Configuration and increased the timeout to 3600. As asked by you, I have checked the Instance Level Virtual Host configuration for secure.spendhq.com in both the instances  PRD-WW2_6 and PRD-WW1_122. We did not found any entry for timeout.Do we include the TimeOut 3600 entry in both the instances and ask them for reload/restart permission of apache?Let me know your feedback on this. Thanks !",I have talked with Rohit regarding this case and he updated that he will update case.,"Hi Rohit,It was nice working with you today.I have created new case that is linked to the previous case that I will close. However, your new case number is #8075166 , All the troubleshooting done with previous case is linked to this new case. Please update me if issue gets resolved with the timeout value on HTTP and ELB timeout. Regards, Harsh Patel Sophos Technical Support",The call is scheduled for today. Please check with Rohit for the update,"Hello David, Thank you for reiterating. On Monday call, we will nail down the root cause of the issue with the 3 possible scenarios while Sophos is also on the call with us. Directly accessing the portal over Private IP address of the Web Server by making an host entry.Directly accessing the portal over public IP ELB bypassing the Sophos WAFAccess the portal using regular method via Sophos WAF. Our team will help you to simulate all the scenarios and capture the results while Sophos engineer is with us for further analysis. Regards,-Praveen",Another dev has experienced the “proxy error” on another page.  We are highly concerned that this issue is of highest priority and needs to be fixed asap.  Please research and provide us a plan to fix this issue because we can’t keep dealing with this every day. ThanksDavid,"David Miller12:17 AM (4 minutes ago)to Rohit, Chirodeep, REAN Let’s schedule a meeting for Monday June 25th around 10:30 EST","David Miller9:20 PM (18 hours ago)to Rohit, Chirodeep, REAN Thank You Rohit, I’ve been out of the office and haven’t had time, let me retest this and get back to you on scheduling a time to screenshare with you. ThanksDavid","Rohit Puri3:09 PM (26 minutes ago)to David, Chirodeep, REAN Hi David,Thanks for the response. Let us know once you are done with the testing again. Regards,Rohit Puri","Hello David, We haven't heard back from you. Could you please provide your availability to schedule a screen share call with Sophos Team to troubleshoot the issue. Let us know if you have any concerns.",Please reach out to David for the call,"Hello Team,Rohit discussed the same on call with Mathew. He said david will be available on Monday.Next Action: Need to reach out to david today for the call.",Rohit will check with Matthew on Sync up call.,Rohit will speak with Matthew to get David contact details to complete this request.,"Hello David, We haven't heard back from you.Could you please provide your availability to schedule a screen share call with Sophos Team to troubleshoot the issue. Let us know if you have any concerns.",Rohit updated that we need to setup a call with David and then call Sophos team to troubleshoot this issue.,"Next steps:if David respond with the time frame, then call Sophos to be available and share the ticket number with Sophos for reference","Hello David,Could you please provide your availability to schedule a screen share call with  Sophos Team to troubleshoot the issue.  Let us know if you have any concerns.","Hello Team,After extensively reviewing the ticket I found that issue is isolated with UTM. Let's working towards resolving this issue. Help me setting up a call between David, Sophos Support and I will make sure I will be available for the call.Here is our approach.1. Test the site via the Public ELB(without Sophos), we will create a public ELB, get the ELB IP and add hosts entry and test it2. Test the site via the Internal IP add hosts entry and test it3. Test the site via the Sophos(regular approach) while doing it perform the tcpdump and share it with UTM to analyze it further.Regards,-Praveen",Praveen mentioned that he is working on this case and will update.,I have pinged to Praveen for the update but he was not available.,OPS call Praveen mentioned that he will review and provide an update to Rohit on this case,Chirodeep updated that he will check with Rohit to get further update on this case.,I have pinged to Praveen for this case but there is no response from him.,Please reach out to Praveen for his help to troubleshoot the issue,"Hello Matthew,We  will check on the issues  in Sophos and will let you know the updates","n this case this is an issue with Sophos. Can you raise this with Sophos as we have no control over that implementation as REAN manage it. Please aim to have it resolved by the End of Business today. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting","Hello Matthew,We have tested scenario by uploading files on the site with and without connecting to Sophos and confirmed that files are uploaded successfully from our end.@David, Please let us know how frequently you are facing the issue, is it every time when you are trying to upload the files. Kindly try to upload files from other local machines too and let us know whether you are able to replicate the issue over there. Revert back to us if you have any further concerns.","While you wait for @David Miller to respond, can you please try this without connecting to Sophos and advise if you still get the same issue. This has to be resolved asap as it’s been ongoing for over a month. Matthew Watts | Manager, Application Development | SpendHQ®O: 770.629.3158 | C: 904.868.8848 | mwatts@spendhq.com | Schedule a Meeting","Thenmozhy D <thenmozhy.d@reancloud.com>2:20 PM (5 minutes ago)to David, Rohit, REAN, Matthew Hello David,Please let us know your availability time so that we can set up a call with you to troubleshoot this issue.Kindly revert back to us in case of any queries.",Setup a call with David in EST Time and troubleshoot the issue as steps provided by SOPHOS Team,"Hello Team,We are actively working along with Sophos team and get back to you with updates shortly.",Rohit updated in eve Ops call that he will do a detailed discussion with Praveen for this case.Next Action: Please check with Rohit.,"In morning ops call, Rohit updated he will check with Praveen regarding this case and let us know how to proceed further in this case.","Hello Manideep,It was a pleasure speaking with you today.As discussed on the phone, this issue seems unusual as if there was an issue with the UTM everyone should be having an issue not just the client from where he's uploading the files from. Please use wireshark on the server while the client is trying to upload a few files and review the output. Also collect the tpcdump pcap files from the UTM and open it up in wireshark to also review. To capture the traffic on the firewall you could use this command. log into the UTM as root and run the following commands in 2 putty sessions at the same time (tcpdump -veni eth1 host 10.59.100.113 -w /home/tmp/tcpdata.pcap) and (tcpdump -veni eth1 host 10.59.100.6 -w /home/tmp/tcpdata.pcap), this will store the capture in cd /home/tmp directory. You can then connect using winscp to log into the utm using username loginuser and copy those packet cap. If you need to upload the pcaps to our ftp, you can using the steps below. Please keep me updated on your progress.FTP Directory:	/cases/8075166FTP Username:	8075166FTP Password:	E57bc34942FTP Instructions:	Configuring your FTP Client to connect to Sophos' FTP","Hello Team,Thank you for the email,We will set up a meeting at 1:30 PM EST (11 PM IST). Whenever you are available to please call +917337263007 Name: Manideep. We will set up a meeting bridge and share the details with you to join the call.","Please check with chirodeep, regarding the update from Sophos team.","Hello Manideep, I will be arranging for a call back Tuesday May 29th around 12 PM IST.Which number is best to reach you?","Hello Team,You can directly send an email to ms@reancloud.com dl with call details. And you can also use +91 9001952605 Name: Rohit","Hello Team,We will be available 12:00 PM IST. Please reach out to available engineers and schedule a call. And please don't forget to CC ms@reancloud.com dl while sending the emails.","Please provide me with your availability for tomorrow.For any call backs, we ask the session to be scheduled at least a day before.Once we have your availability (with time zone) I can reach out to available engineers at that time.Also, you always have an option contact us directly with the case number at any time.","Hello Team,We have some queries regarding this previous email. If it is possible please provide your availability to set up a call to discuss more on this issue. Whenever you are available please call me +917337263007. I will set up a meeting bridge and share the details with you to join the call.",Please get a call with Sophos and ask below-mentioned query:1: Which internal elb is fulfilling the request for preview.spendhq.com?2: How did you find and which log you can say the request is handling by this internal elb.,I have forwarded Sophos mail to Rohit.,@Team: Please provide me the mail sent to us by Sophos for the whole analysis the done. As how they are sure about the request is going to this internal ELB from SOPHOS.,Rohit is working on this case. Please check with him for the further update on this case.,@Rohit Please look into this case.Please check with Rohit in Morning hours.,Rohit is not available today and we have tried to reach out Yogesh he is not reachable.,I reached out to Rohit but there is he was not available.@afternoon Team: please check with Rohit.,"Hello David,As per the Sophos team update, the request was passing to an internal ELB internal-newpreview-elb-1657548324.us-east-1.elb.amazonaws.com. When we tried to access this ELB we are redirecting to another site instead of secure.spendhq.com. We are reviewing the details provided by Sophos team with our internal team and will get back to you with an update.","David Miller1:05 AM (3 hours ago)to me, Rohit, REAN, Matthew Can you provide the IP address I can use for the upload?","Hello Dave,Thanks for joining the call.Here is the summary that Sophos team provided with us.During our session, we were able to isolate the issue regarding HTTP post request returning with status code 502.The client makes HTTP post request to https://secure.spendhq.com/files but the return we get is Error reading from remote server returned by /files/upload_document, referer: https://secure.spendhq.com/filesWe are unsure as to why the REAL web server that is hosting the page is returning an error code 502.It may be that the path /files/upload_document is somehow not valid in the real server (maybe the path does not actually exists?)It is clear at this time that the UTM is not explicitly blocking this traffic (no security error).Overall, this is an issue that has to be resolved from the real web server itself.UTM in reverse proxy deployment simply forwards requests, it does not host any real resources.As per the suggestion by Sophos team, can you please perform an upload of files from internal ELB to the REAL web server and see if any proxy error is showing up.  So that we can conclude the above points provided by the Sophos team.","We have informed Sophos team regarding this. Once received update from Sophos team, we  can share the bridge with customer","Hello David,Thanks for the update.We will check with Sophos team and will share the bridge link at 1.30 PM EST","David Miller9:24 PM (12 minutes ago)to Rohit, REAN, Matthew I am available around 1:30 / 2ish, can you send the bridge link when your ready",@AfterNoon Team:Please set up a call with Sophos once we heard back from the customer.,"Hi David,We shared the logs and other details with SOPHOS. But they need us to upload the files live. Please let us know when you are available today for the call with SOPHOS so that we go ahead and set up a call with them as per your availability. Thanks !Regards,Rohit Puri","David Miller2:46 AM (3 hours ago)to me, REAN, Matthew Just received the proxy error IP: 159.100.161.41Time: 5:10 – 5:15 pm We also had someone say when they tried to download a file they also received a proxy error, but it may have been from a long running query","Sophos Support <support@sophos.com>Attachments4:43 AM (1 hour ago)to rohit.puri, kapil.bokdia, ms Hello Rohit,Based on the logs provided, there are some modsecurity rules being hit during the provided time. We may need to create exception for those rules but we need to capture live traffic to make sure we are doing exception to the correct one. Please advise when you can arrange an upload test and while doing it, we capture logs in real time.","Jamelunissa Mohammed <jamelunissa.mohammed@reancloud.com>2:26 AM (3 hours ago)to David, REAN, Matthew Hello David,Could please let us know whether the issue still persists when trying to upload files from your machine on secure.spendhq.com even after changes done by SOPHOS team by increasing timeout.","Hi David, We haven't heard back from you. Please try to upload files from your machine on secure.spendhq.com as few changes been made by SOPHOS team to increase the timeout. Let us know if you still face the same issue.","Hi David, We haven't heard back from you.Please try to upload files from your machine on secure.spendhq.com as few changes been made by SOPHOS team to increase the timeout. Let us know if you still face the same issue.","Hi David,Please try to upload files from your machine on secure.spendhq.com as few changes been made by SOPHOS team to increase the timeout. Let us know if you still face the same issue. Thanks!Regards,Rohit Puri","Hello David,This was the IP you have provided earlier. Could you please provide some more information regarding the issue you are facing now.","David Miller3:27 AM (1 minute ago)to Rean, spendhq-support The ip address doesn’t seem to be working","Hello David, we haven't heard back from you, Please try once again to upload the file from IP: 74.115.21.213 and let us know if you are still facing the same issue.","Hello David, we haven't heard back from you,Please try once again to upload the file from IP: 74.115.21.213 and let us know if you are still facing the same issue.","Hello David,Please try once again to upload the file from IP: 74.115.21.213 and let us know if you are still facing the same issue.","Kapil Bokdia <kapil.bokdia@reancloud.com>4:56 AM (1 hour ago)to anthonythomas.., support, REAN Hi Anthony,As discussed on the call, Please find the bridge details.https://reancloud.zoom.us/my/mgse1","Sophos Support5:57 AM (1 minute ago)to me, ms Hello Kapil,As per last troubleshooting, we have modified the following: /var/storage/chroot-reverseproxy/usr/apache/conf/httpd.conf Timeout 1800 MaxKeepAliveRequests 1000 KeepAliveTimeout 60 Then we restarted the reverseproxy: /var/mdw/scripts/reverseproxy restartPlease check and confirm with clients if all is good. Regards, Tony Bueta","Hi Gourav,I have tried to reach out to the other team and it seems they will be able to give you a call after 6 pm EST. However, you can call us in when you have test user that can reproduce this issue. Please note that our technical support teams are available 24/7 and can be contacted on your local Technical Support number listed on our website: https://www.sophos.com/en-us/support/contact-support.aspx","Sophos Support2:09 AM (24 minutes ago)to me, ms, rohit.puri Hi Gourav,It was nice speaking with you today.We started our session at 3.30 pm EST as I was on another inbound call and was not able to give you a call at 3 pm.During our session we wanted to reproduced the issue and collect the logs as the logs you have provided earlier did not have any logs for the IP address 74.115.21.213.we tried to replicate the issue but there was no response from your client. It is my end of the shift so as agreed on the call I am handing over this case to the next region.","Hello David,Can you upload the file with this Ip: 74.115.21.213","Gourav Pokhra <gourav.pokhra@reancloud.com>10:51 PM (33 minutes ago)to support, REAN, Rohit Hello Team,Thank you for the email,I will set up a meeting at 3 PM EST (12:30 AM IST). Whenever you are available please call me +918696096500. I will set up a meeting bridge and share the details with you to join the call.Thanks & Regards,Gourav Pokhra",We will setup a call to analyse the logs with SOPHOS and try to close it on call today itself.,We have shared the reverse-proxy logs with Sophos and waiting an response from Sophos team to provide an analysis on this Mail thread: RE: [#8075166] Error reading from remote server - WAF HTTP Proxy -- Priority: High -- Level: Premium,"I have checked the WAF logs for yesterday, not able find any logs related to the ip:74.115.21.213 provide by David",I have informed to Rohit in this case and he will look and will udpate.,"Hello David,We will analyze the logs and will let you know the updates.","David Miller11:33 PM (0 minutes ago)to Rohit, REAN, Praveen, Matthew I replicated the issue right around 2pm Eastern time today. IP: 74.115.21.213Domain: secure.spendhq.com/files","Hello David,We haven't heard back from you.Thanks for updating us on the issue. Will you please tell us the IP of the machine from where you try to upload the files and you face this issue? As this will help us to analyze the logs.","Hi David,Thanks for updating us about the issue. Will you please tell us the IP of the machine from where you try to upload the files and you faces this issue? As this will help us to analysis the logs. Thanks !Regards,Rohit Puri",I have checked the WAF logs during the time mentioned by the customer. I can found 403 and 408 response code error at that time. Please verify the WAF logs again and check whether we can fount any error during them,Please check the WAF logs around the time mentioned by the customer. Check with Rohit and respond back to Sophos for the regarding the issue.,"I  have checked the instance level PRD-WW2_6 and PRD-DB1 server logs, we can a network spike in 4 am utc. And also I have seen a  memory issue on the web server around 11:52 am est other than this I could find any issues.May  4 11:52:58 ip-10-59-101-6 kernel: python invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0May  4 11:52:58 ip-10-59-101-6 kernel: python cpuset=/ mems_allowed=0May  4 11:52:58 ip-10-59-101-6 kernel: Pid: 2366, comm: python Not tainted 2.6.32-696.3.1.el6.x86_64 #1May  4 11:52:58 ip-10-59-101-6 kernel: Call Trace:May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff81131680>] ? dump_header+0x90/0x1b0May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff8123c30c>] ? security_real_capable_noaudit+0x3c/0x70May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff81131b02>] ? oom_kill_process+0x82/0x2a0May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff81131a41>] ? select_bad_process+0xe1/0x120May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff81131f40>] ? out_of_memory+0x220/0x3c0May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff8113e91c>] ? __alloc_pages_nodemask+0x93c/0x950May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffffa008b4a0>] ? ext4_get_block+0x0/0x120 [ext4]May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff81177b6a>] ? alloc_pages_current+0xaa/0x110May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff8112ea77>] ? __page_cache_alloc+0x87/0x90May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff8112e45e>] ? find_get_page+0x1e/0xa0May  4 11:52:58 ip-10-59-101-6 kernel: [<ffffffff8112fa17>] ? filemap_fault+0x1a7/0x500May  4 11:53:06 ip-10-59-101-6 kernel: Out of memory: Kill process 16483 (httpd) score 263 or sacrifice childMay  4 11:53:06 ip-10-59-101-6 kernel: Killed process 16483, UID 48, (httpd) total-vm:9004396kB, anon-rss:8631136kB, file-rss:916kB","Hello Rohit, Lets carefully look at the response times, Network In/Out metrics and DB response. @David Miller or @Matthew Watts – Are these files will be stored in DB or NFS file system. So that, it will be easy for us to nail down further. praveen.muppala@reancloud.com","David Millerto praveen.muppala, Rohit, Matthew, REAN They are stored on a mounted volume on the web server, there are references to them in the database as well.",I have tried to call Rohit but he was not available.Next action: Check with Rohit for the further action.,"Hello David,We are checking on this and will let you know the updates.","David Miller8:10 PM (2 minutes ago)to Rohit, REAN, Praveen, Matthew So I am no longer able to reproduce the error on our preview.spendhq.com.  I was however able to reproduce it on secure.spendhq.com between 10:10am and 10:15am if that helps",Follow up the customer on Monday afternoon shift and confirm the issue has been resolved or not.,"Hi David,As discussed on the call, this issue seems to be not there while uploading the files. Now you are able to upload the files successfully. We are moving this ticket from Sev1 to Sev4. We will keep this ticket open for 3-4 days so that if you face the issue again. Please share the timestamp and source IP of the machine when you face the issue again. So that we will go ahead and analysis the logs. Thanks for keeping patience with us and giving your time to join the meeting. Have a great day ! Regards,Rohit Puri","David Miller10:58 PM (4 minutes ago)to Rohit, REAN, Praveen, Matthew Yes I can do 2Get Outlook for Android",Thanks David. Please join the same bridge.Rohit Puri,"Hi David,We have already re-scheduled the call with SOPHOS for 2PM EST today. Will you be able to join? Regards,Rohit Puri",Anytine today after 2:30 or Friday before 11:30 or after 1Get Outlook for AndroidDavid Miller,"David Miller10:52 PM (3 minutes ago)to Rohit, REAN, Praveen, Matthew Anytine today after 2:30 or Friday before 11:30 or after 1","Hi David,We have already re-scheduled the call with SOPHOS for 2PM EST today. Will you be able to join? Regards,Rohit Puri","Hi David,We have re-schedule the call to 2PM EST today. Please join the call at the same bridge. Thanks !Regards,Rohit Puri","Hello David,Can you please provide your availability so we can reschedule the call tomorrow and will send the meeting invite. Thanks & Regards,Gourav Pokhra","David Miller7:49 PM (2 hours ago)to Rohit, REAN, Praveen, Matthew I have a meeting at 1, can we push to 2?","Hi David,Yesterday Sophos Team was not available to setup a call to resolve this issue. We have scheduled a call for today at 1:00 PM EST.Please find the bridge details for today’s call.Join from PC, Mac, Linux, iOS or Android: https://reancloud.zoom.us/j/6709937998Or iPhone one-tap :    US: +16465588656,,6709937998#  or +16699006833,,6709937998# Or Telephone:    Dial(for higher quality, dial a number based on your current location):        US: +1 646 558 8656  or +1 669 900 6833  or +1 855 880 1246 (Toll Free) or +1 877 369 0926 (Toll Free)     Meeting ID: 670 993 7998     International numbers available: https://zoom.us/u/ZDxaXRegards,Rohit Puri","Hello Rohit/Joydip,Thanks for your call today and we deeply apologize for missing the scheduled call yesterday. As agreed on call, we will arrange the callback today at 1-2 PM EST today.Please send us the Zoom meeting bridge by replying to this email, and the assigned engineer will join the bridge accordingly.Regards, Ashish Das Sophos Technical Support","Hello David,Once the Sophos team is available we will send the meeting invite to you.","David Miller8:25 PM (18 minutes ago)to Rohit, REAN, Praveen, Matthew Please send the meeting link when it’s available, thank you","Hi David,Thanks for testing it out. We have setup a call with SOPHOS Team today 11:00 AM EST. Once they will be available, I will share with you the Meeting Details. Please be available to join the call as they want to analysis the live logs. Thanks !Regards,Rohit Puri","Hi David,Thanks for testing it out. We have setup a call with SOPHOS Team today 11:00 AM EST. Once they will be available, I will share with you the Meeting Details. Please be available to join the call as they want to analysis the live logs. Thanks !Regards,Rohit Puri","We have informed Rohit, He mentioned that he is replying to them.","David Miller6:19 PM (13 minutes ago)to Rohit, REAN, Praveen, Matthew I am working from home today (similar to our clients) and still receiving the proxy error.  Could this be a load balancer issue by change?  I was not on the Sophos vpn while testing this time around either","David Miller6:19 PM (2 minutes ago)to Rohit, REAN, Praveen, Matthew I am working from home today (similar to our clients) and still receiving the proxy error.  Could this be a load balancer issue by change?  I was not on the Sophos vpn while testing this time around either","Hi David,We have made changes in the SOPHOS WAF Configuration. Please try to upload the files on https://preview.spendhq.com/files and let us know if you still have any issue for the same. If issue still persist, then we will schedule a call today with the SOPHOS Team and we will invite to the call. Thanks !Regards,Rohit Puri",@Team: I had a call with the SOPHOS Team and discuss the issue again with them that we have confirmed the issue is not at instance level. They were not able to help much now. They asked us to setup a call with the SpendHQ Team so that they can see the live logs at the same time to help us resolve the issue. So we have asked the SOPHOS Team to be available at 11 AM EST so that I will schedule a call with David Miller so he can replicate the issue.,"Hello David,We will check on this and will get back to you shortly.",Rohit I tried the following: I Uploaded files to http://10.59.100.170/files with success.I uploaded the same files to https://preview.spendhq.com/files after changing my hosts and I received a proxy error. I also had an outside source upload the same files and received a proxy error as well.  They were not in the office and more of a realistic client setup. This is still a sev1 as out clients are having this issue outside the office/vpn settings.ThanksDavid,"Hi David,We have reached out to SOPHOS on this issue but they have told us this issue is at the instance level only. We have seen that the apache configuration there is no changes needs to be made. But for getting more sure on this that the issue is not at instance level we need you to make one more test. Testing Steps:1. Please make changes in the /etc/hosts file of your local machine and make the entry for 10.59.100.170	https://preview.spendhq.com/files and save it. 2. Now Connect to SOPHOS SSL VPN.3. Try to upload the files again on URL: http://10.59.100.170/files and https://preview.spendhq.com/filesPlease let us know if you are successful to upload the files or not. On the basis of that we will work with SOPHOS team to get it resolve. Thanks !Regards,Rohit Puri",We have checked with Praveen and he mentioned that he will provide steps to further look into this issue.,Please ask Praveen to look into the suggestion provided by the Sophos Team as we cannot go ahead and disable the WAF this might affect the Customer environment.,SOPHOS team told us that there is no issue with WAF at SOPHOS end. The issue is at instance level only. They asked us to disable the proxy and use DNAT to confirm the issue is at instance level only. Need to confirm with the Praveen if we disable the WAF on preview URL and check the issue if this at instance level or SOPHOS side.,We got a response from Sophos Team.Sub: RE: [#8075166] Error reading from remote server - WAF HTTP ProxyI already inform Rohit regarding this.Please check with for further updates.,"Rohit and Team, please work with Sophos Support team on Monday morning and get ready for the updates by Monday Ops call.Regards,-Praveen","Hello Matthew,We are actively working on this case to resolve this issue. Will let you know the updates shortly.",Still getting the error. <!DOCTYPE HTML PUBLIC -//IETF//DTD HTML 2.0//EN><html><head><title>502 Proxy Error</title></head><body><h1>Proxy Error</h1><p>The proxy server received an invalidresponse from an upstream server.<br />The proxy server could not handle the request <em><a href=/files/upload_document>POST&nbsp;/files/upload_document</a></em>.<p>Reason: <strong>Error reading from remote server</strong></p></p></body></html>,"Matthew Watts9:23 PM (19 minutes ago)to Rohit, David, REAN, me, Praveen Looking into it now.","Hi Mathew/David,Will you please try to upload the files? We do have made some changes in the apache configuration.Let us know if you still facing the issue while uploading. Thanks !Regards,Rohit Puri","Hello Matthew,Please join the below bridge.https://zoom.us/j/988612347","Matthew Watts5:32 PM (12 minutes ago)to Jamelunissa, David, Rohit, REAN Please, can we have this meeting at 11 as I already have a meeting.","Hello Matthew,Thanks for the update.We will schedule the call at 11 AM EST and will share you the bridge details. Please revert back to us in case of any queries.","Hello David,We scheduled the call tomorrow at 9 AM EST and will share you the bridge details. Please let us know whether it is feasible time for you to join the call.","David Miller2:28 AM (56 minutes ago)to praveen.muppala, Matthew, Rohit, spendhq-support There is no reason to touch tomcat.  Please schedule a call with Matthew and I to sort this out.  Thank You","No David.We generally don’t manage the tomcat. It will be Matt or your dev team. Hence the changes are not made. In the below email also, I asked your team to make the changes.Regards,-Praveen","Hello Team,As you have discussed with Praveen please test and let us know if the issue is resolved or not.",Praveen updated that he has made some changes in the apache and informed David and Matthew to test it form their end.,"Hello David,We are working on this issue and will let you know the updates.",0
5000G00001K02bM,Cloud Engineer Level 1,Closed,1083993,Incident,13-11-2017 04:43,,"Hello Team,This is to notify you that teh alert regarding volume usage for /dev/sdc on the instance PRD-DB1(10.59.10.190) got resolved and returned to normal with a value of 88%.###Hello Team, We haven't heard back from you This is to inform you that the alert regarding the high volume usage for /dev/sdc on the instance PRD-DB1(10.59.10.190) is still open state and current usage at 90.7%. Please delete or zip unwanted files and let us know if you have any queries.###Hello Team,This is to notify you that the alert regarding EBS volume usage for  /dev/sdc on the instance PRD-DB1(10.59.10.190) is still open state and current usage at 91%. On further analysis, we could see that /dev/sdc mounted on /mnt/production_19082017 has reached the threshold value of 90% to a value of 91%. Filesystem Type Size Used Avail Use% Mounted on /dev/sdc ext4 4.0T 3.4T 379G 91% /mnt/production_19082017 Please find the breakdown details of the volume. 3.4T total 3.4T data 41G watts 12G dmackay 4.1G postgres_old 2.7G postgres 501M rlittle 164K tmp data directory 3.4T total 2.9T isg 50G isg_metronic 48G ip-10-59-10-12.log 33G isg_metronic_bk 32G isg_thlee201 31G isg_ares2 26G isg_att 24G isg_medtronic_bk 16G isg_att_01_07_2017 14G isg_cgi 12G isg_lowes 12G isg_cushmanw 9.8G isg_jll 9.4G isg_petsmart 9.1G isg_stryker 7.6G isg_apollogl 6.5G isg_mit 6.5G isg_harvardu 6.1G isg_raytheon 6.0G isg_att_doug_backup 5.9G isg_lifescie 5.8G isg_prgx 5.0G isg_cgi_copy 4.4G isg_tufts 4.4G isg_iheartm 4.1G isg_aaronrents 3.8G isg_petco 3.2G isg_serta_simmons 3.2G isg_otpp 3.2G isg_gpc_two 2.9G isg_tpg_port 2.9G isg_qi 2.4G isg_hearst 2.1G isg_incrsrch 2.1G BH_RSI_Repository 2.0G isg_aip4 1.6G isg_quintile 1.6G isg_invesco 1.6G isg_fossil 1.5G isg_lgp 1.3G isg_anixter 1.2G isg_synovus 1.2G isg_southern_wine 1.1G isg_hub 971M isg_owensand Please Delete or zip unwanted files to reduce the current usage. Let us know if you have any queries regarding this.Regards,Anjali G Nair###Hello Team, We haven't heard back from youThis is to inform you that the alert regarding the high volume usage for /dev/sdc on the instance PRD-DB1(10.59.10.190) is still open state and current usage at 90.5%. Please delete or zip unwanted files and let us know if you have any queries.###Hello Team,This is to inform you that the alert regarding the high volume usage for   /dev/sdc on the instance PRD-DB1(10.59.10.190)  is still open state and current usage at 90.4%.Please delete or zip unwanted files and let us know if you have any queries.###Alert is still at 90.3%###Hello Team,On further analysis, we could see that /dev/sdc mounted on /mnt/production_19082017 has reached the threshold value of 90% to a value of 91%. Filesystem     Type    Size   Used    Avail    Use%      Mounted on/dev/sdc       ext4      4.0T   3.4T     379G      91%      /mnt/production_19082017Please find the breakdown details of the volume.3.4T    total3.4T    data41G     watts12G     dmackay4.1G    postgres_old2.7G    postgres501M    rlittle164K    tmpdata directory3.4T    total2.9T    isg50G     isg_metronic48G     ip-10-59-10-12.log33G     isg_metronic_bk32G     isg_thlee20131G     isg_ares226G     isg_att24G     isg_medtronic_bk16G     isg_att_01_07_201714G     isg_cgi12G     isg_lowes12G     isg_cushmanw9.8G    isg_jll9.4G    isg_petsmart9.1G    isg_stryker7.6G    isg_apollogl6.5G    isg_mit6.5G    isg_harvardu6.1G    isg_raytheon6.0G    isg_att_doug_backup5.9G    isg_lifescie5.8G    isg_prgx5.0G    isg_cgi_copy4.4G    isg_tufts4.4G    isg_iheartm4.1G    isg_aaronrents3.8G    isg_petco3.2G    isg_serta_simmons3.2G    isg_otpp3.2G    isg_gpc_two2.9G    isg_tpg_port2.9G    isg_qi2.4G    isg_hearst2.1G    isg_incrsrch2.1G    BH_RSI_Repository2.0G    isg_aip41.6G    isg_quintile1.6G    isg_invesco1.6G    isg_fossil1.5G    isg_lgp1.3G    isg_anixter1.2G    isg_synovus1.2G    isg_southern_wine1.1G    isg_hub971M    isg_owensandDelete or zip unwanted files and let us know if you have any queries.###Hi SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PRD-DB1(10.59.10.190). The volume usage on this instance is above the threshold value of 90% with a value90.006%. We are investigating the alert and we will keep you posted on the progress. Resource Details:- Instance ID : i-03ccfddd9f02cacb9 Instance type :r4.8xlargeAvailability zone : us-east-1b Private IPs : 10.59.10.190","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/sdc ) - prd-db1 - 10.59.10.190  High Disk Usage detected on the device /dev/sdc     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{datadog_monitor:on} by {host,device} * 100 > 90`Metric value: 90.006This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fsdc%2Chost%3Ai-03ccfddd9f02cacb9 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=4122942207374147718 · View i-03ccfddd9f02cacb9: https://app.datadoghq.com/infrastructure?hostname=i-03ccfddd9f02cacb9--  <https://www.reancloud.com/aws-reinvent/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/sdc ) - prd-db1 - 10.59.10.190,,07-11-2017 04:32,144,0,SpendHQ,"Hello Team,This is to notify you that teh alert regarding volume usage for /dev/sdc on the instance PRD-DB1(10.59.10.190) got resolved and returned to normal with a value of 88%.","Hello Team, We haven't heard back from you This is to inform you that the alert regarding the high volume usage for /dev/sdc on the instance PRD-DB1(10.59.10.190) is still open state and current usage at 90.7%. Please delete or zip unwanted files and let us know if you have any queries.","Hello Team,This is to notify you that the alert regarding EBS volume usage for  /dev/sdc on the instance PRD-DB1(10.59.10.190) is still open state and current usage at 91%. On further analysis, we could see that /dev/sdc mounted on /mnt/production_19082017 has reached the threshold value of 90% to a value of 91%. Filesystem Type Size Used Avail Use% Mounted on /dev/sdc ext4 4.0T 3.4T 379G 91% /mnt/production_19082017 Please find the breakdown details of the volume. 3.4T total 3.4T data 41G watts 12G dmackay 4.1G postgres_old 2.7G postgres 501M rlittle 164K tmp data directory 3.4T total 2.9T isg 50G isg_metronic 48G ip-10-59-10-12.log 33G isg_metronic_bk 32G isg_thlee201 31G isg_ares2 26G isg_att 24G isg_medtronic_bk 16G isg_att_01_07_2017 14G isg_cgi 12G isg_lowes 12G isg_cushmanw 9.8G isg_jll 9.4G isg_petsmart 9.1G isg_stryker 7.6G isg_apollogl 6.5G isg_mit 6.5G isg_harvardu 6.1G isg_raytheon 6.0G isg_att_doug_backup 5.9G isg_lifescie 5.8G isg_prgx 5.0G isg_cgi_copy 4.4G isg_tufts 4.4G isg_iheartm 4.1G isg_aaronrents 3.8G isg_petco 3.2G isg_serta_simmons 3.2G isg_otpp 3.2G isg_gpc_two 2.9G isg_tpg_port 2.9G isg_qi 2.4G isg_hearst 2.1G isg_incrsrch 2.1G BH_RSI_Repository 2.0G isg_aip4 1.6G isg_quintile 1.6G isg_invesco 1.6G isg_fossil 1.5G isg_lgp 1.3G isg_anixter 1.2G isg_synovus 1.2G isg_southern_wine 1.1G isg_hub 971M isg_owensand Please Delete or zip unwanted files to reduce the current usage. Let us know if you have any queries regarding this.Regards,Anjali G Nair","Hello Team, We haven't heard back from youThis is to inform you that the alert regarding the high volume usage for /dev/sdc on the instance PRD-DB1(10.59.10.190) is still open state and current usage at 90.5%. Please delete or zip unwanted files and let us know if you have any queries.","Hello Team,This is to inform you that the alert regarding the high volume usage for   /dev/sdc on the instance PRD-DB1(10.59.10.190)  is still open state and current usage at 90.4%.Please delete or zip unwanted files and let us know if you have any queries.",Alert is still at 90.3%,"Hello Team,On further analysis, we could see that /dev/sdc mounted on /mnt/production_19082017 has reached the threshold value of 90% to a value of 91%. Filesystem     Type    Size   Used    Avail    Use%      Mounted on/dev/sdc       ext4      4.0T   3.4T     379G      91%      /mnt/production_19082017Please find the breakdown details of the volume.3.4T    total3.4T    data41G     watts12G     dmackay4.1G    postgres_old2.7G    postgres501M    rlittle164K    tmpdata directory3.4T    total2.9T    isg50G     isg_metronic48G     ip-10-59-10-12.log33G     isg_metronic_bk32G     isg_thlee20131G     isg_ares226G     isg_att24G     isg_medtronic_bk16G     isg_att_01_07_201714G     isg_cgi12G     isg_lowes12G     isg_cushmanw9.8G    isg_jll9.4G    isg_petsmart9.1G    isg_stryker7.6G    isg_apollogl6.5G    isg_mit6.5G    isg_harvardu6.1G    isg_raytheon6.0G    isg_att_doug_backup5.9G    isg_lifescie5.8G    isg_prgx5.0G    isg_cgi_copy4.4G    isg_tufts4.4G    isg_iheartm4.1G    isg_aaronrents3.8G    isg_petco3.2G    isg_serta_simmons3.2G    isg_otpp3.2G    isg_gpc_two2.9G    isg_tpg_port2.9G    isg_qi2.4G    isg_hearst2.1G    isg_incrsrch2.1G    BH_RSI_Repository2.0G    isg_aip41.6G    isg_quintile1.6G    isg_invesco1.6G    isg_fossil1.5G    isg_lgp1.3G    isg_anixter1.2G    isg_synovus1.2G    isg_southern_wine1.1G    isg_hub971M    isg_owensandDelete or zip unwanted files and let us know if you have any queries.","Hi SpendHQ-Team, This is to inform you that we received an alert regarding high volume usage on the instance PRD-DB1(10.59.10.190). The volume usage on this instance is above the threshold value of 90% with a value90.006%. We are investigating the alert and we will keep you posted on the progress. Resource Details:- Instance ID : i-03ccfddd9f02cacb9 Instance type :r4.8xlargeAvailability zone : us-east-1b Private IPs : 10.59.10.190",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001EVVC7,Cloud Engineer Level 1,Closed,1068284,Incident,16-07-2017 19:48,,Following on 01068276,"Sun, 16 Jul 2017 10:03:55 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: --------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, California US, London UK, Atlanta-B US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,16-07-2017 19:33,0,0,SpendHQ,Following on 01068276,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001QjXS1,Cloud Engineer Level 1,Closed,1091046,Incident,16-02-2018 23:04,,"Hello Mattew,We have reset your password and the credentials are shared through secure email. Please check and confirm from your end and let us know if you have any queries.###Hello Matthew,We acknowledge the delivery of your request. We will work on this request and will let you know the update.","Rean,Can you reset my password for the PRD rean account.--  <https://www.reancloud.com/news/rean-cloud-awarded-cloud-contract-department-defense-worth-950-million/>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS,,16-02-2018 21:51,8,0,SpendHQ,"Hello Mattew,We have reset your password and the credentials are shared through secure email. Please check and confirm from your end and let us know if you have any queries.","Hello Matthew,We acknowledge the delivery of your request. We will work on this request and will let you know the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001d18u0,Cloud Engineer Level 1,Closed,1106058,Incident,10-10-2018 11:59,,"@Team- as per Rohit's update we are marking this case as closed###Matthew:FYI we restored the process.###Hello Spendhq-Team,This is to inform you we received an alert for httpd process down on the instance  prd-ww1_122 (Instance ID:  i-0ace70ce06368e4a7). Later,  restoration of the process is done from your end. Then it got recovered within 6 minutes. From the primary analysis, we could see below logs from https logs: [Tue Oct 09 17:13:20 2018] [notice] caught SIGTERM, shutting down[Tue Oct 09 17:19:31 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Tue Oct 09 17:19:31 2018] [notice] Digest: generating secret for digest authentication ...[Tue Oct 09 17:19:31 2018] [notice] Digest: donePHP Deprecated:  Comments starting with '#' are deprecated in /etc/php.ini on line 1670 in Unknown on line 0[Tue Oct 09 17:19:31 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operationsPlease let us know if it is part of any activity performed from your end which has caused the process down.","---------- Forwarded message ---------From: Datadog Alerting <alert@dtdg.co>Date: Tue, Oct 9, 2018 at 10:45 PMSubject: [Monitor Alert] Triggered: [SpendHQ] Httpd Process is down -prd-ww1_122 - 10.59.100.122 - web on host:i-0ace70ce06368e4a7,process:httpdTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {host:i-0ace70ce06368e4a7,process:httpd}] [SpendHQ] HttpdProcess is down - prd-ww1_122 - 10.59.100.122 - webHttpd Process is down @ms@reancloud.com<https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>PROCS CRITICAL: 0 processes found for httpdThe monitor was last triggered at Tue Oct 09 2018 17:15:14 UTC (*2 secs ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2014428?group=host%3Ai-0ace70ce06368e4a7%2Cprocess%3Ahttpd>]· [Edit Monitor <https://app.datadoghq.com/monitors#2014428/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?filter=i-0ace70ce06368e4a7>] · [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CASC&to_ts=1539105434000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1539104414000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4611091165071267860>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- Regards,Jamelunissa MohammedHyderabad, IndiaREĀN Cloud | Reach, Engage, Āctivate, Nurture3rd Floor, Melange Tower, Madhapur, Hyderabad 500081jamelunissa.mohammed@reancloud.com  | www.reancloud.com--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>--  <https://hubs.ly/H0d8gJ20>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","Fwd: [Monitor Alert] Triggered: [SpendHQ] Httpd Process is down - prd-ww1_122 - 10.59.100.122 - web on host:i-0ace70ce06368e4a7,process:httpd",,09-10-2018 22:49,13,0,SpendHQ,@Team- as per Rohit's update we are marking this case as closed,Matthew:FYI we restored the process.,"Hello Spendhq-Team,This is to inform you we received an alert for httpd process down on the instance  prd-ww1_122 (Instance ID:  i-0ace70ce06368e4a7). Later,  restoration of the process is done from your end. Then it got recovered within 6 minutes. From the primary analysis, we could see below logs from https logs: [Tue Oct 09 17:13:20 2018] [notice] caught SIGTERM, shutting down[Tue Oct 09 17:19:31 2018] [notice] suEXEC mechanism enabled (wrapper: /usr/sbin/suexec)[Tue Oct 09 17:19:31 2018] [notice] Digest: generating secret for digest authentication ...[Tue Oct 09 17:19:31 2018] [notice] Digest: donePHP Deprecated:  Comments starting with '#' are deprecated in /etc/php.ini on line 1670 in Unknown on line 0[Tue Oct 09 17:19:31 2018] [notice] Apache/2.2.15 (Unix) DAV/2 mod_ssl/2.2.15 OpenSSL/1.0.1e-fips configured -- resuming normal operationsPlease let us know if it is part of any activity performed from your end which has caused the process down.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gcbDQ,Cloud Engineer Level 1,Closed,1109616,Incident,20-12-2018 21:42,,"Hello Matthew,We hope that you are doing fine.We still haven't heard back from you regarding this case.On 18/12/2018 we received a site down alert for the URL https://secure.spendhq.com/login. REAN team proceeded and analysed the issue, then shared the findings with you.At this point, since the issue was resolved and the site is accessible, we will be closing this case. However, if you have any questions and/or concerns, please let us know.Thank you.###Hello Matthew, We didn't hear back from you.Please review the analysis shared by us and let us know if you have any queries related to it.###Hello Matthew,This is quick follow up.Please review the previous comment and let us know if you have any queries related to it.###No RCA needed. If no response from the customer by Thursday EoD, close this case.###@praveen.muppala please also have a look at this SpendHQ P1 and let us know whether RCA is needed: https://reancloud.cloudforce.com/5002I00001gcbDQ###Hi Matthew,We checked on the site down and here are the details on the same:1. We checked ELB logs at the time of alert we found 500 error code at the particular time of alert.2. Site went down for 2 times for a duration of a minute only.3. When we checked the instance[10.59.100.122] logs which is serving the request we did not find any apache error during the time of alert4. But we do find the out of memory issue at the time of alert which killed the httpd process. Please see the logs below:Dec 18 16:53:46 ip-10-59-100-122 kernel: Out of memory: Kill process 6560 (httpd) score 79 or sacrifice child Dec 18 16:53:46 ip-10-59-100-122 kernel: Killed process 6560, UID 48, (httpd) total-vm:5345488kB, anon-rss:4972120kB, file-rss:960kBPlease let us know if you have any queries on the same. Thanks.###@Praveen,We checked on this issue. The site went down for 2 times just for a minute.We checked the ELB logs we found that there 500 of count of 2 at the time of alert.We found that the customer has also changed the backend instance now the traffice to the website is been served by only one instance Instance:  i-0ace70ce06368e4a7 (PRD-WW1_122)We checked on instance level at the time of alert. We did not find any error logs for the particular time interval. When we checked the number of count of request around the 2 hours duration(at the time of alert) its only  38.This I dont think will create any issue as the r4.2xlarge instance type been used.We did more analysis on this and found the out of memory error at the time of alert:Dec 18 16:53:46 ip-10-59-100-122 kernel: Out of memory: Kill process 6560 (httpd) score 79 or sacrifice childDec 18 16:53:46 ip-10-59-100-122 kernel: Killed process 6560, UID 48, (httpd) total-vm:5345488kB, anon-rss:4972120kB, file-rss:960kBBy which we can see that httpd process was killed with the reason of out of memory. Please assist further on this do we need to share any RCA on this as we did not find much on this. THanks###Hello Team,We are actively working to prepare the RCA and will share with you ASAP.###Hello Team,Upon further checking, we found that yesterday this site went down 2 times.1. 3.32 PM UTC2. 4:56 PM UTCIf we look at the wormly alerts, we can see that the time of alert triggered and recovered is the same for both site failure.For both of these times site down alert, all the ELB and instance looks normal. We can see a small spike in CPU utilization and request count. I have also verified the /var/www/vhosts/files.spendhq.com/logs/production logs but there are no error logs file generated for tomorrow.I have verified the message logs as well and found the following: [root@ip-10-59-100-122 log]# cat messages | grep -i Dec 18 03Dec 18 03:37:47 ip-10-59-100-122 dhclient[1063]: DHCPREQUEST on eth0 to 10.59.100.1 port 67 (xid=0xfc63236)Dec 18 03:37:47 ip-10-59-100-122 dhclient[1063]: DHCPACK from 10.59.100.1 (xid=0xfc63236)Dec 18 03:37:49 ip-10-59-100-122 dhclient[1063]: bound to 10.59.100.122 -- renewal in 1609 seconds.Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: ClamAV update process started at Tue Dec 18 03:40:01 2018Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: Your ClamAV installation is OUTDATED!Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: Local version: 0.99.2 Recommended version: 0.101.0Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: DON'T PANIC! Read http://www.clamav.net/documents/upgrading-clamavDec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: main.cld is up to date (version: 58, sigs: 4566249, f-level: 60, builder: sigmgr)Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: Downloading daily-25215.cdiff [100%]Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: Downloading daily-25216.cdiff [100%]Dec 18 03:40:02 ip-10-59-100-122 freshclam[1999]: Downloading daily-25217.cdiff [100%]Dec 18 03:40:07 ip-10-59-100-122 freshclam[1999]: daily.cld updated (version: 25217, sigs: 2181543, f-level: 63, builder: neo)Dec 18 03:40:07 ip-10-59-100-122 freshclam[1999]: bytecode.cld is up to date (version: 327, sigs: 91, f-level: 63, builder: neo)Dec 18 03:40:09 ip-10-59-100-122 freshclam[1999]: Database updated (6747883 signatures) from db.local.clamav.net (IP: 104.16.187.138)Dec 18 03:42:58 ip-10-59-100-122 clamd[1749]: SelfCheck: Database modification detected. Forcing reload.Dec 18 03:42:58 ip-10-59-100-122 clamd[1749]: Reading databases from /var/lib/clamavDec 18 03:43:10 ip-10-59-100-122 clamd[1749]: Database correctly reloaded (6740655 signatures)Dec 18 03:53:10 ip-10-59-100-122 clamd[1749]: SelfCheck: Database status OK.[root@ip-10-59-100-122 clamav]# cat freshclam.logClamAV update process started at Tue Dec 18 03:40:01 2018WARNING: Your ClamAV installation is OUTDATED!WARNING: Local version: 0.99.2 Recommended version: 0.101.0DON'T PANIC! Read http://www.clamav.net/documents/upgrading-clamavmain.cld is up to date (version: 58, sigs: 4566249, f-level: 60, builder: sigmgr)Downloading daily-25215.cdiff [100%]Downloading daily-25216.cdiff [100%]Downloading daily-25217.cdiff [100%]daily.cld updated (version: 25217, sigs: 2181543, f-level: 63, builder: neo)bytecode.cld is up to date (version: 327, sigs: 91, f-level: 63, builder: neo)Database updated (6747883 signatures) from db.local.clamav.net (IP: 104.16.187.138)#cat clamd.logTue Dec 18 03:32:58 2018 -> SelfCheck: Database status OK.Tue Dec 18 03:42:58 2018 -> SelfCheck: Database modification detected. Forcing reload.Tue Dec 18 03:42:58 2018 -> Reading databases from /var/lib/clamavTue Dec 18 03:43:10 2018 -> Database correctly reloaded (6740655 signatures)These logs are repetitive but for around the same time when the site went down.Please do more analysis and prepare the RCA.###Please review case with Rohit and if needed, please work the RCA###As this is P1, Please work on the RCA and get it reviewed the by CC.###Hello Team,Please review the previously shared analysis and let us know if you have any queries.Thanks.###Hello Team,We have checked and noticed that there are spikes in requests count and latency from the load balancer metrics. This has been the case for sometime now. From instance and AWS console level, we can we that the instance has high cpu load, and this has been so for sometime now as we have been monitoring the status for about an hour.Our analysis indicates that httpd is consuming high CPU resources. Please see the summary of CPU details below. As you can see, CPU load on this server is high (You can find the full details from attached text document).The ESTABLISHED and connections in TIME_WAIT are also high, and this is causing the latency issue.Load Average of the System2.65, 3.21, 4.04################################################   Processes with highest CPU usage################################################ USER       PID  PPID CMD                         %CPUapache   14006 14005 /usr/bin/clamscan /var/www/ 92.6root     14031 14028 /usr/bin/php /var/www/vhost 36.6apache    6629  1941 /usr/sbin/httpd              4.1apache    6628  1941 /usr/sbin/httpd              3.3apache    4942  1941 /usr/sbin/httpd              2.5apache    6555  1941 /usr/sbin/httpd              2.5apache   28385  1941 /usr/sbin/httpd              2.1apache   20496  1941 /usr/sbin/httpd              1.5apache   27146  1941 /usr/sbin/httpd              1.5apache   27150  1941 /usr/sbin/httpd              1.5Below are connection summary ################################################      15 CLOSE_WAIT      1 established)    541 ESTABLISHED      1 Foreign     35 LISTEN   1367 TIME_WAITWe have also attached the ELB logs analysis which have also attached.Please review these details and let us know if you have any questions and/or if you are performing any activity.Thanks###Hello Team,This is to notify that we have received an alert regarding Detected Error on SpendHQ Secure for the URL https://secure.spendhq.com/login.The alert got recovered. Violation is 1 minute. The site is accessible now. Currently, we are analyzing the issue and keep you posted the updates.","Tue, 18 Dec 2018 10:32:24 -0500Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30002 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Dallas-B US, California US, Dallas-C US, Frankfurt-BDE-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,18-12-2018 21:03,49,0,SpendHQ,"Hello Matthew,We hope that you are doing fine.We still haven't heard back from you regarding this case.On 18/12/2018 we received a site down alert for the URL https://secure.spendhq.com/login. REAN team proceeded and analysed the issue, then shared the findings with you.At this point, since the issue was resolved and the site is accessible, we will be closing this case. However, if you have any questions and/or concerns, please let us know.Thank you.","Hello Matthew, We didn't hear back from you.Please review the analysis shared by us and let us know if you have any queries related to it.","Hello Matthew,This is quick follow up.Please review the previous comment and let us know if you have any queries related to it.","No RCA needed. If no response from the customer by Thursday EoD, close this case.",@praveen.muppala please also have a look at this SpendHQ P1 and let us know whether RCA is needed: https://reancloud.cloudforce.com/5002I00001gcbDQ,"Hi Matthew,We checked on the site down and here are the details on the same:1. We checked ELB logs at the time of alert we found 500 error code at the particular time of alert.2. Site went down for 2 times for a duration of a minute only.3. When we checked the instance[10.59.100.122] logs which is serving the request we did not find any apache error during the time of alert4. But we do find the out of memory issue at the time of alert which killed the httpd process. Please see the logs below:Dec 18 16:53:46 ip-10-59-100-122 kernel: Out of memory: Kill process 6560 (httpd) score 79 or sacrifice child Dec 18 16:53:46 ip-10-59-100-122 kernel: Killed process 6560, UID 48, (httpd) total-vm:5345488kB, anon-rss:4972120kB, file-rss:960kBPlease let us know if you have any queries on the same. Thanks.","@Praveen,We checked on this issue. The site went down for 2 times just for a minute.We checked the ELB logs we found that there 500 of count of 2 at the time of alert.We found that the customer has also changed the backend instance now the traffice to the website is been served by only one instance Instance:  i-0ace70ce06368e4a7 (PRD-WW1_122)We checked on instance level at the time of alert. We did not find any error logs for the particular time interval. When we checked the number of count of request around the 2 hours duration(at the time of alert) its only  38.This I dont think will create any issue as the r4.2xlarge instance type been used.We did more analysis on this and found the out of memory error at the time of alert:Dec 18 16:53:46 ip-10-59-100-122 kernel: Out of memory: Kill process 6560 (httpd) score 79 or sacrifice childDec 18 16:53:46 ip-10-59-100-122 kernel: Killed process 6560, UID 48, (httpd) total-vm:5345488kB, anon-rss:4972120kB, file-rss:960kBBy which we can see that httpd process was killed with the reason of out of memory. Please assist further on this do we need to share any RCA on this as we did not find much on this. THanks","Hello Team,We are actively working to prepare the RCA and will share with you ASAP.","Hello Team,Upon further checking, we found that yesterday this site went down 2 times.1. 3.32 PM UTC2. 4:56 PM UTCIf we look at the wormly alerts, we can see that the time of alert triggered and recovered is the same for both site failure.For both of these times site down alert, all the ELB and instance looks normal. We can see a small spike in CPU utilization and request count. I have also verified the /var/www/vhosts/files.spendhq.com/logs/production logs but there are no error logs file generated for tomorrow.I have verified the message logs as well and found the following: [root@ip-10-59-100-122 log]# cat messages | grep -i Dec 18 03Dec 18 03:37:47 ip-10-59-100-122 dhclient[1063]: DHCPREQUEST on eth0 to 10.59.100.1 port 67 (xid=0xfc63236)Dec 18 03:37:47 ip-10-59-100-122 dhclient[1063]: DHCPACK from 10.59.100.1 (xid=0xfc63236)Dec 18 03:37:49 ip-10-59-100-122 dhclient[1063]: bound to 10.59.100.122 -- renewal in 1609 seconds.Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: ClamAV update process started at Tue Dec 18 03:40:01 2018Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: Your ClamAV installation is OUTDATED!Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: Local version: 0.99.2 Recommended version: 0.101.0Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: DON'T PANIC! Read http://www.clamav.net/documents/upgrading-clamavDec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: main.cld is up to date (version: 58, sigs: 4566249, f-level: 60, builder: sigmgr)Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: Downloading daily-25215.cdiff [100%]Dec 18 03:40:01 ip-10-59-100-122 freshclam[1999]: Downloading daily-25216.cdiff [100%]Dec 18 03:40:02 ip-10-59-100-122 freshclam[1999]: Downloading daily-25217.cdiff [100%]Dec 18 03:40:07 ip-10-59-100-122 freshclam[1999]: daily.cld updated (version: 25217, sigs: 2181543, f-level: 63, builder: neo)Dec 18 03:40:07 ip-10-59-100-122 freshclam[1999]: bytecode.cld is up to date (version: 327, sigs: 91, f-level: 63, builder: neo)Dec 18 03:40:09 ip-10-59-100-122 freshclam[1999]: Database updated (6747883 signatures) from db.local.clamav.net (IP: 104.16.187.138)Dec 18 03:42:58 ip-10-59-100-122 clamd[1749]: SelfCheck: Database modification detected. Forcing reload.Dec 18 03:42:58 ip-10-59-100-122 clamd[1749]: Reading databases from /var/lib/clamavDec 18 03:43:10 ip-10-59-100-122 clamd[1749]: Database correctly reloaded (6740655 signatures)Dec 18 03:53:10 ip-10-59-100-122 clamd[1749]: SelfCheck: Database status OK.[root@ip-10-59-100-122 clamav]# cat freshclam.logClamAV update process started at Tue Dec 18 03:40:01 2018WARNING: Your ClamAV installation is OUTDATED!WARNING: Local version: 0.99.2 Recommended version: 0.101.0DON'T PANIC! Read http://www.clamav.net/documents/upgrading-clamavmain.cld is up to date (version: 58, sigs: 4566249, f-level: 60, builder: sigmgr)Downloading daily-25215.cdiff [100%]Downloading daily-25216.cdiff [100%]Downloading daily-25217.cdiff [100%]daily.cld updated (version: 25217, sigs: 2181543, f-level: 63, builder: neo)bytecode.cld is up to date (version: 327, sigs: 91, f-level: 63, builder: neo)Database updated (6747883 signatures) from db.local.clamav.net (IP: 104.16.187.138)#cat clamd.logTue Dec 18 03:32:58 2018 -> SelfCheck: Database status OK.Tue Dec 18 03:42:58 2018 -> SelfCheck: Database modification detected. Forcing reload.Tue Dec 18 03:42:58 2018 -> Reading databases from /var/lib/clamavTue Dec 18 03:43:10 2018 -> Database correctly reloaded (6740655 signatures)These logs are repetitive but for around the same time when the site went down.Please do more analysis and prepare the RCA.","Please review case with Rohit and if needed, please work the RCA","As this is P1, Please work on the RCA and get it reviewed the by CC.","Hello Team,Please review the previously shared analysis and let us know if you have any queries.Thanks.","Hello Team,We have checked and noticed that there are spikes in requests count and latency from the load balancer metrics. This has been the case for sometime now. From instance and AWS console level, we can we that the instance has high cpu load, and this has been so for sometime now as we have been monitoring the status for about an hour.Our analysis indicates that httpd is consuming high CPU resources. Please see the summary of CPU details below. As you can see, CPU load on this server is high (You can find the full details from attached text document).The ESTABLISHED and connections in TIME_WAIT are also high, and this is causing the latency issue.Load Average of the System2.65, 3.21, 4.04",,,,,,,,,,,,,,,,Processes with highest CPU usage,,,,,,,,,,,,,,,,USER       PID  PPID CMD                         %CPUapache   14006 14005 /usr/bin/clamscan /var/www/ 92.6root     14031 14028 /usr/bin/php /var/www/vhost 36.6apache    6629  1941 /usr/sbin/httpd              4.1apache    6628  1941 /usr/sbin/httpd              3.3apache    4942  1941 /usr/sbin/httpd              2.5apache    6555  1941 /usr/sbin/httpd              2.5apache   28385  1941 /usr/sbin/httpd              2.1apache   20496  1941 /usr/sbin/httpd              1.5apache   27146  1941 /usr/sbin/httpd              1.5apache   27150  1941 /usr/sbin/httpd              1.5Below are connection summary,,,,,,,,,,,,,,,,15 CLOSE_WAIT      1 established)    541 ESTABLISHED      1 Foreign     35 LISTEN   1367 TIME_WAITWe have also attached the ELB logs analysis which have also attached.Please review these details and let us know if you have any questions and/or if you are performing any activity.Thanks,"Hello Team,This is to notify that we have received an alert regarding Detected Error on SpendHQ Secure for the URL https://secure.spendhq.com/login.The alert got recovered. Violation is 1 minute. The site is accessible now. Currently, we are analyzing the issue and keep you posted the updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1
5002I00001jjGwX,Cloud Engineer Level 1,Closed,1111956,Incident,20-02-2019 16:09,,"Hello Team,We are marking this case closed for now.If the ticket is closed erroneously, feel free to reopen the ticket. We look forward to serve you. Feel free to reach out to us in case of queries on this case.###Hello Team,We haven't heard back from you.We will mark this ticket as closed after 24 hours if we won't hear back from your end. If the ticket is closed erroneously, feel free to reopen the ticket.We look forward to serve you. Feel free to reach out to us in case of queries on this case.###check with CC as we already did three followup###Hello TeamWe haven't heard back from you,Kindly review the analysis shared with you on previous comments and let us know if you have any queries.RegardsNishad Ali###Hello Team, This is a gentle reminder. Please review the details in the previous command and let us know if you have any queries. Thanks.###Hello Team,This is a gentle reminder.Please review the details in the previous command and let us know if you have any queries.Thanks.###[Via email]Hello Balam, On further analysis, we found that “93.174.93.73” IP is hitting our Sophos ELB to the various known endpoints which are exposed via Sophos and then these endpoints speaking internally with other endpoints within your VPC network. So in the alert, you see local IP’s for both the Source and Destination.The Advanced Threat Protection feature is enabled in an alert mode in SpendHQ Sophos environment. But Web Protection and IPS services are enabled in Drop mode.                                                                                           Coming to the alert, C2/Generic-A is the threat name associated with the command and control (C&C) servers used by malware. C2/Generic-A is not detection of a malware payload on an infected machine. This attack is specific to the Windows environment, and we don’t have any Windows ec2 instances in SpendHQ environment. However, we found this “93.174.93.73” IP Address as a blacklisted IP, and we blocked this IP address at the VPC NACL level. So, it cannot enter into our VPC perimeter.Let us know if you need any additional details on this.Thanks.Praveen Muppala###@Praveen,We have checked on this. Here are details:1. The source host ips belongs to spendhq-patch-server. 2. The attached instance i-0590f342fdc9965bb is been stopped long back on 12th Nov 20173. This ELB is not serving any traffic from that time.4. We checked the logs of ELB but couldn't find any as there were no logs for the time of alert.5. We checked the VPC flow logs subnet-0fdde924:2019-02-1116:32:15 2 261234435984 eni-701119e4 10.59.10.24 93.174.93.73 80 50108 6 6 264 1549902735 1549902794 ACCEPT OK16:32:15 2 261234435984 eni-701119e4 93.174.93.73 10.59.10.24 50108 80 6 1 40 1549902735 1549902794 ACCEPT OK18:26:25 2 261234435984 eni-701119e4 93.174.93.73 10.59.10.24 33765 53 17 1 56 1549909585 1549909637 REJECT OKWe could see the request was rejected for DNS protocol. I think we are good here.6. As this ELB and instance falls under same network of SOPHOS, we got this alert of Threat Protection.7. We checked the Threat Protection Logs for the given time. Here are they:2019:02:11-08:51:11 spendhq ulogd[27917]: id=2023 severity=info sys=SecureNet sub=packetfilter name=Packet logged (ATP) action=log fwrule=63001 initf=eth0 threatname=C2/Generic-A srcmac=12:63:81:fa:d5:a1 dstmac=12:c3:4f:d8:4c:1e srcip=10.59.10.184 dstip=93.174.93.73 proto=6 length=44 tos=0x00 prec=0x00 ttl=255 srcport=80 dstport=50108 tcpflags=ACK SYNResolution:1. Blocking the abusive destination IP 93.174.93.73 -- Team already did that.2. Decommission the ELB n Instance -- As this instance and ELB is not been used from long time. I will ask Matthew in today monthly call to approve to decommission this.Let me know anything else needs to be done. Thanks###Hello Praveen The request are coming from the source IPs 10.59.10.184 and 10.59.10.24 which belongs to spendhq-patch-server ELB. The instance behind the ELB is in stopped state and we don't have any ELB logs generated after 2017. So I am not able to fetch the client public IP. The team was blocked an abusive IP which is the destination IP.================2019:02:11-08:51:27 spendhq ulogd[27917]: id=2023 severity=info sys=SecureNet sub=packetfilter name=Packet logged (ATP) action=log fwrule=63001 initf=eth0 threatname=C2/Generic-A srcmac=12:63:81:fa:d5:a1 dstmac=12:c3:4f:d8:4c:1e srcip=10.59.10.184 dstip=93.174.93.73 proto=6 length=44 tos=0x00 prec=0x00 ttl=255 srcport=80 dstport=50108 tcpflags=ACK SYN2019:02:11-16:32:34 spendhq ulogd[27917]: id=2023 severity=info sys=SecureNet sub=packetfilter name=Packet logged (ATP) action=log fwrule=63001 initf=eth0 threatname=C2/Generic-A srcmac=12:63:81:fa:d5:a1 dstmac=12:c3:4f:d8:4c:1e srcip=10.59.10.24 dstip=93.174.93.73 proto=6 length=44 tos=0x00 prec=0x00 ttl=255 srcport=80 dstport=50108 tcpflags=ACK SYN================Since the logs are not their for ELB how will I find out the Public IP for the request.Threat Name: C2/Generic-ACharacteristics: Enables remote accessCould you please suggest.Rohit has already talked with the customer on the phone and updated the status.###Hello Rohit, Chirodeep,It's been more than 12 hours from this request.Can you provide an update?Best,Balam MendozaCISO OfficeSpendHQ###Hello Balam, I will ask team to expedite it. Praveen Muppala###Hello Ray,For Sophos logs, We saw that requests were going to the destination IP address: 93.174.93.73 which belongs to Netherlands and blacklisted in many RBLs with 100% abusive rate.We have blocked the IP in NACL level. Please let us know in case of any queries.###Hello Ray,While checking the logs, we found that the request was going to the destination IP address : 93.174.93.73 which belongs to Netherlands and black listed in many RBLs with 100% abusive rate. Hence we have blocked the IP address in the NACL level to avoid further issues. Please let us know whether it is a valid IP address. Thank you.###@Rohit,We have checked the Advanced Threat Protection logs in the sophos portal and below are the same. ================2019:02:11-08:51:27 spendhq ulogd[27917]: id=2023 severity=info sys=SecureNet sub=packetfilter name=Packet logged (ATP) action=log fwrule=63001 initf=eth0 threatname=C2/Generic-A srcmac=12:63:81:fa:d5:a1 dstmac=12:c3:4f:d8:4c:1e srcip=10.59.10.184 dstip=93.174.93.73 proto=6 length=44 tos=0x00 prec=0x00 ttl=255 srcport=80 dstport=50108 tcpflags=ACK SYN 2019:02:11-16:32:34 spendhq ulogd[27917]: id=2023 severity=info sys=SecureNet sub=packetfilter name=Packet logged (ATP) action=log fwrule=63001 initf=eth0 threatname=C2/Generic-A srcmac=12:63:81:fa:d5:a1 dstmac=12:c3:4f:d8:4c:1e srcip=10.59.10.24 dstip=93.174.93.73 proto=6 length=44 tos=0x00 prec=0x00 ttl=255 srcport=80 dstport=50108 tcpflags=ACK SYN================The private IP address belongs to the following ENIs10.59.10.184 - eni-9112bd0610.59.10.24 - eni-701119e4The request goes to the destination IP address : 93.174.93.73 which belongs to Netherlands and black listed in many RBLs with 100% abusive rate. As of now we have blocked this IP address in the NACL level.The following are the ELB details : Secure-Spendhq-ELB spendhq-patch-serverIn spendhq-patch-server ELB, there is only one instance - PROD-SPHQ-WEB-SERVER03_4th_July_2017 [10.59.100.79] which is in stopped state.###Hello Ray,We are checking on the source IP details from which the request came. We will be checking on the details and will let you know the same. Kindly await for further update from us. Thank you.###Hi Rohit & Support,Regarding this alert, please isolate this endpoint.  I'm unclear based on the wording of the alert if the host that triggered the alert is 10.51.1.192 or the host at IP 10.59.10.24 that's listed as the Source in the body of the alert.  The malware referenced in the alert is older and modern, up to date anti-virus should be able to detect and remove it.  I ask that once the host is confirmed and isolated that we understand the role of the system.  If the system is an employee endpoint it should be rebuilt so that any and all malware is destroyed by the rebuilding process.  If the systems is something other than an employee endpoint, let me know so the proper steps can be taken to minimize the impact to the business.   To get additional context for the event I would like to see anti-virus logs for this system to determine if other malware was detected before and around the time of the alert.  If there are additional details or information you have about the event or the host, feel free to pass that along to me as well.Thanks,-Ray###Hi SpendHQ Team, We want to inform you that we have received threat notification from Sophos in your environment. The source IP/host 10.59.10.24  was found to communicate with a potentially malicious site outside your company. We are looking into it and will update you with details shortly.",Advanced Threat ProtectionA threat has been detected in your networkThe source IP/host listed below was found to communicate with a potentially malicious site outside your company.Details about the alert:Threat name....: C2/Generic-ADetails........: https://nam04.safelinks.protection.outlook.com/?url=http:%2F%2Fwww.sophos.com%2Fen-us%2Fthreat-center%2Fthreat-analyses%2Fviruses-and-spyware%2FC2~Generic-A.aspx&amp;data=01%7C01%7Cjamelunissa.mohammed%40hitachivantara.com%7Cd329a598499e4563e24708d6903e8a6e%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=An68vqg6sFKDksAUo6GqZqyTA5MVAUaSf6bTbDrVc8Q%3D&amp;reserved=0Time...........: 2019-02-11 16:32:34Traffic blocked: noSource IP address or host: 10.59.10.24Account Name - SpendHQAccount DL - rean_spendhq_support@hitachivantara.comUTM Hostname - spendhq-utmPrivate IP - 10.59.1.192Public IP - 52.0.17.10Device URL - https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2F52.0.17.10%3A4444&amp;data=01%7C01%7Cjamelunissa.mohammed%40hitachivantara.com%7Cd329a598499e4563e24708d6903e8a6e%7C18791e1761594f52a8d4de814ca8284a%7C0&amp;sdata=%2FzncyE75tb2BrP7Zdsz12Hz6DdEFZ51xRzstbZiOpOw%3D&amp;reserved=0--System Uptime      : 261 days 11 hours 28 minutesSystem Load        : 0.09System Version     : Sophos UTM 9.509-3Please refer to the manual for detailed instructions.The send limit for this notification has been reached. No furthernotifications of this type will be sent during this period.,[spendhq][CRIT-861] Advanced Threat Protection Alert,,11-02-2019 23:03,209,0,SpendHQ,"Hello Team,We are marking this case closed for now.If the ticket is closed erroneously, feel free to reopen the ticket. We look forward to serve you. Feel free to reach out to us in case of queries on this case.","Hello Team,We haven't heard back from you.We will mark this ticket as closed after 24 hours if we won't hear back from your end. If the ticket is closed erroneously, feel free to reopen the ticket.We look forward to serve you. Feel free to reach out to us in case of queries on this case.",check with CC as we already did three followup,"Hello TeamWe haven't heard back from you,Kindly review the analysis shared with you on previous comments and let us know if you have any queries.RegardsNishad Ali","Hello Team, This is a gentle reminder. Please review the details in the previous command and let us know if you have any queries. Thanks.","Hello Team,This is a gentle reminder.Please review the details in the previous command and let us know if you have any queries.Thanks.","[Via email]Hello Balam, On further analysis, we found that “93.174.93.73” IP is hitting our Sophos ELB to the various known endpoints which are exposed via Sophos and then these endpoints speaking internally with other endpoints within your VPC network. So in the alert, you see local IP’s for both the Source and Destination.The Advanced Threat Protection feature is enabled in an alert mode in SpendHQ Sophos environment. But Web Protection and IPS services are enabled in Drop mode.                                                                                           Coming to the alert, C2/Generic-A is the threat name associated with the command and control (C&C) servers used by malware. C2/Generic-A is not detection of a malware payload on an infected machine. This attack is specific to the Windows environment, and we don’t have any Windows ec2 instances in SpendHQ environment. However, we found this “93.174.93.73” IP Address as a blacklisted IP, and we blocked this IP address at the VPC NACL level. So, it cannot enter into our VPC perimeter.Let us know if you need any additional details on this.Thanks.Praveen Muppala","@Praveen,We have checked on this. Here are details:1. The source host ips belongs to spendhq-patch-server. 2. The attached instance i-0590f342fdc9965bb is been stopped long back on 12th Nov 20173. This ELB is not serving any traffic from that time.4. We checked the logs of ELB but couldn't find any as there were no logs for the time of alert.5. We checked the VPC flow logs subnet-0fdde924:2019-02-1116:32:15 2 261234435984 eni-701119e4 10.59.10.24 93.174.93.73 80 50108 6 6 264 1549902735 1549902794 ACCEPT OK16:32:15 2 261234435984 eni-701119e4 93.174.93.73 10.59.10.24 50108 80 6 1 40 1549902735 1549902794 ACCEPT OK18:26:25 2 261234435984 eni-701119e4 93.174.93.73 10.59.10.24 33765 53 17 1 56 1549909585 1549909637 REJECT OKWe could see the request was rejected for DNS protocol. I think we are good here.6. As this ELB and instance falls under same network of SOPHOS, we got this alert of Threat Protection.7. We checked the Threat Protection Logs for the given time. Here are they:2019:02:11-08:51:11 spendhq ulogd[27917]: id=2023 severity=info sys=SecureNet sub=packetfilter name=Packet logged (ATP) action=log fwrule=63001 initf=eth0 threatname=C2/Generic-A srcmac=12:63:81:fa:d5:a1 dstmac=12:c3:4f:d8:4c:1e srcip=10.59.10.184 dstip=93.174.93.73 proto=6 length=44 tos=0x00 prec=0x00 ttl=255 srcport=80 dstport=50108 tcpflags=ACK SYNResolution:1. Blocking the abusive destination IP 93.174.93.73 -- Team already did that.2. Decommission the ELB n Instance -- As this instance and ELB is not been used from long time. I will ask Matthew in today monthly call to approve to decommission this.Let me know anything else needs to be done. Thanks",Hello Praveen The request are coming from the source IPs 10.59.10.184 and 10.59.10.24 which belongs to spendhq-patch-server ELB. The instance behind the ELB is in stopped state and we don't have any ELB logs generated after 2017. So I am not able to fetch the client public IP. The team was blocked an abusive IP which is the destination IP.================2019:02:11-08:51:27 spendhq ulogd[27917]: id=2023 severity=info sys=SecureNet sub=packetfilter name=Packet logged (ATP) action=log fwrule=63001 initf=eth0 threatname=C2/Generic-A srcmac=12:63:81:fa:d5:a1 dstmac=12:c3:4f:d8:4c:1e srcip=10.59.10.184 dstip=93.174.93.73 proto=6 length=44 tos=0x00 prec=0x00 ttl=255 srcport=80 dstport=50108 tcpflags=ACK SYN2019:02:11-16:32:34 spendhq ulogd[27917]: id=2023 severity=info sys=SecureNet sub=packetfilter name=Packet logged (ATP) action=log fwrule=63001 initf=eth0 threatname=C2/Generic-A srcmac=12:63:81:fa:d5:a1 dstmac=12:c3:4f:d8:4c:1e srcip=10.59.10.24 dstip=93.174.93.73 proto=6 length=44 tos=0x00 prec=0x00 ttl=255 srcport=80 dstport=50108 tcpflags=ACK SYN================Since the logs are not their for ELB how will I find out the Public IP for the request.Threat Name: C2/Generic-ACharacteristics: Enables remote accessCould you please suggest.Rohit has already talked with the customer on the phone and updated the status.,"Hello Rohit, Chirodeep,It's been more than 12 hours from this request.Can you provide an update?Best,Balam MendozaCISO OfficeSpendHQ","Hello Balam, I will ask team to expedite it. Praveen Muppala","Hello Ray,For Sophos logs, We saw that requests were going to the destination IP address: 93.174.93.73 which belongs to Netherlands and blacklisted in many RBLs with 100% abusive rate.We have blocked the IP in NACL level. Please let us know in case of any queries.","Hello Ray,While checking the logs, we found that the request was going to the destination IP address : 93.174.93.73 which belongs to Netherlands and black listed in many RBLs with 100% abusive rate. Hence we have blocked the IP address in the NACL level to avoid further issues. Please let us know whether it is a valid IP address. Thank you.","@Rohit,We have checked the Advanced Threat Protection logs in the sophos portal and below are the same. ================2019:02:11-08:51:27 spendhq ulogd[27917]: id=2023 severity=info sys=SecureNet sub=packetfilter name=Packet logged (ATP) action=log fwrule=63001 initf=eth0 threatname=C2/Generic-A srcmac=12:63:81:fa:d5:a1 dstmac=12:c3:4f:d8:4c:1e srcip=10.59.10.184 dstip=93.174.93.73 proto=6 length=44 tos=0x00 prec=0x00 ttl=255 srcport=80 dstport=50108 tcpflags=ACK SYN 2019:02:11-16:32:34 spendhq ulogd[27917]: id=2023 severity=info sys=SecureNet sub=packetfilter name=Packet logged (ATP) action=log fwrule=63001 initf=eth0 threatname=C2/Generic-A srcmac=12:63:81:fa:d5:a1 dstmac=12:c3:4f:d8:4c:1e srcip=10.59.10.24 dstip=93.174.93.73 proto=6 length=44 tos=0x00 prec=0x00 ttl=255 srcport=80 dstport=50108 tcpflags=ACK SYN================The private IP address belongs to the following ENIs10.59.10.184 - eni-9112bd0610.59.10.24 - eni-701119e4The request goes to the destination IP address : 93.174.93.73 which belongs to Netherlands and black listed in many RBLs with 100% abusive rate. As of now we have blocked this IP address in the NACL level.The following are the ELB details : Secure-Spendhq-ELB spendhq-patch-serverIn spendhq-patch-server ELB, there is only one instance - PROD-SPHQ-WEB-SERVER03_4th_July_2017 [10.59.100.79] which is in stopped state.","Hello Ray,We are checking on the source IP details from which the request came. We will be checking on the details and will let you know the same. Kindly await for further update from us. Thank you.","Hi Rohit & Support,Regarding this alert, please isolate this endpoint.  I'm unclear based on the wording of the alert if the host that triggered the alert is 10.51.1.192 or the host at IP 10.59.10.24 that's listed as the Source in the body of the alert.  The malware referenced in the alert is older and modern, up to date anti-virus should be able to detect and remove it.  I ask that once the host is confirmed and isolated that we understand the role of the system.  If the system is an employee endpoint it should be rebuilt so that any and all malware is destroyed by the rebuilding process.  If the systems is something other than an employee endpoint, let me know so the proper steps can be taken to minimize the impact to the business.   To get additional context for the event I would like to see anti-virus logs for this system to determine if other malware was detected before and around the time of the alert.  If there are additional details or information you have about the event or the host, feel free to pass that along to me as well.Thanks,-Ray","Hi SpendHQ Team, We want to inform you that we have received threat notification from Sophos in your environment. The source IP/host 10.59.10.24  was found to communicate with a potentially malicious site outside your company. We are looking into it and will update you with details shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001D9zGZ,Cloud Engineer Level 1,Closed,1061201,Incident,08-06-2017 07:47,,"Hello SpendHQ Team,This is to inform you that the alert regarding volume usage for PROD-SPHQ-DB-SERVER05 instance got resolved and the current volume usage is 57%. The violation has lasted for 4 hours and 30 minutes.###Hello SpendHQ Team,This is to inform you that the alert regarding volume usage for PROD-SPHQ-DB-SERVER05 instance is still in open state and the current usage has reached 100%. Please delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.###Hello Team,On further analysis, we could see /dev/xvda1 mounted on / is consuming high volume usage on this instance.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G   16M 100% /Please find the volume usage in /47G     total26G     /tmp15G     /var6.1G    /usr510M    /home285M    /lib282M    /opt44M     /bootPlease find the attachment section for the detailed volume usage in /tmp, /var, and /usr folder. Please delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.###Hi SpendHQ-Team,This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress.Resource DetailsInstance Name : PROD-SPHQ-DB-SERVER05Instance ID : i-008d43ad00357e47aInstance Private IP Address : 10.59.10.135Instance Availability Zone : us-east-1bInstance Type : r3.8xlargeVPC ID : vpc-76df7212Subnet ID : subnet-0fdde924","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Thu, Jun 8, 2017 at 1:45 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage (/dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135To: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered on {device:/dev/xvda1,host:10.59.10.135}] [SpendHQ] - EBS HighDisk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135High Disk Usage detected on the device /dev/xvda1@ms@reancloud.com<http://email.dtdg.co/c/eJwVjT0LwyAYhH9N3CqvJsY4OCQhpdC5Q7sUo-YDkmiNDv33tXDwHAd3ZyQTo0WrpEA41MAzGeWYZXDcCVY1DRn6vh26mkFRgYlmxtqhRdJKTcxyKNkoiKG1FUJoQfTUGFU2I0WbXGL0Z1G2Bb1mKe-xUVEZNy-fvLH_M61dOmJ2Prhp3Wx26QIv6N_37_NBbgkFuZ_5OFh16M0l82-iKHd3rNGFHw1HOfs>[image: Metric Graph]<http://email.dtdg.co/c/eJxNj91uwyAMhZ8GLpExGMIFF23WvMZEgSWRmpIltNrjj0S7mGT5-Ef-dJw8uXvms0eQFgzYpoRWUBMrro5018lb319uV0PANKSaRhELnzzIABJU1hpj1PeMVlsC00WbOsra8Iefal13pi4MhxZhXUUKNaQyTt-NsbTZUp5zLdvOUCGgcsYxNdTyWdvZh9TOdMZo5wCAoRm38lrbPOX3HDNDOsiEQ-tP_XmnII-qn8pez70EQU60LBU1wtdWlv9swpPNN7_s7bkth2d8lFc63PHq_9z9AmniUjI>avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 >90The monitor was last triggered at Wed Jun 07 2017 20:15:00 UTC (*26 secsago*).------------------------------[Monitor Status<http://email.dtdg.co/c/eJwtjkGOwyAMRU8DSwR2HGDBos009yA4TSI1JU1oNccfUo1k-X3b0v_mQH4Y5RJAG6tbbSsJrKIKq66eGufMresut2tLWjSaC08qZTkHkwaLTfSg0x0ie-3QDXAn46j1Azr5CHMp2yHwIqCvFbdNcSyR8zS_qsdad2t-LiXvhwAEDehbL7Cf9vzeBP7w-FnSKIBOB4K-zl_-fjiaU3VzPsr3brQir2o3SHIP61Ff3cf4TI_85jNLlvCf9QeC4kWi>]· [Edit Monitor<http://email.dtdg.co/c/eJwtjd0KhCAUhJ9GL-V01NQLL7Zo30M9_UFlW-77r8HCwAcD3wx57eLIV4_QGGjBVGo0QlcY0TmtrG2Gvn8NXauBKaBCs0iZL166CQ1BAqVjMjJMyoFT1liMEaVr-eaXUs6byRfDd004T0GhBMrz8qkbe-32fKwlXzdDifBYrpYjrYVffr_r3zWGI235S4_Ai_8LP7tqNag>]· [View 10.59.10.135<http://email.dtdg.co/c/eJwVTUsOhCAUO40sCR-fwIKFOnoPBPwkCg4-7z9M0rRNk7bBglkiOaxgXLGOqaogFIUqig4GWq35NI79NHTAmpYFDBv1mexWR6M632ql2NIaAaKT3ACT0axaCG_IaXfE-2lk34i5wt03DQ5dyNv-rRtXzY60FvdgeT2-JTZy3vODyV3VfjijYGhlLoEUez31vkSX_Jnf8O8TtFdOB-byA-wAOmE>]This alert was raised by account SpendHQComment in Datadog<http://email.dtdg.co/c/eJw9jcsKgzAURL_GLOXmevNaZKFW_yMxqQpqrKb9_qabwsCBgTMTrDA-stUicAUSVKFAVYsCVXdGkNZ86Pt26KSAiiDkMNdTYouVQOCf3qPyUXKNHiUpSQiOnJhUYJtdcj7vqmkrHEvcedbBZRfSvLzKxl66-IlH_rMZ11A1j8YAEnEtJBkBwJE0u-x-l_srumPa0jv8fJbtno41p-sL0T04-Q>To manage your Datadog subscriptions, click here<http://email.dtdg.co/c/eJwVjc0OhCAQg59GjgRZ-fHAQY37HiMzqIkKi_j-i0mTr2maFp3qF2K7k6I1QgtTqaThqsLwsVedte08TcM8aiWaTmDBlfvINqe8JUAtEf3HKuggCFhabReJknwI7HBbKeluPkMjv1WQEkcogHHdfnXjfDPv43OV6lKmQJkuTzfL7rzrVya4_BEffMusuDNee4n5D86gN6o>.-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,08-06-2017 02:37,5,0,SpendHQ,"Hello SpendHQ Team,This is to inform you that the alert regarding volume usage for PROD-SPHQ-DB-SERVER05 instance got resolved and the current volume usage is 57%. The violation has lasted for 4 hours and 30 minutes.","Hello SpendHQ Team,This is to inform you that the alert regarding volume usage for PROD-SPHQ-DB-SERVER05 instance is still in open state and the current usage has reached 100%. Please delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.","Hello Team,On further analysis, we could see /dev/xvda1 mounted on / is consuming high volume usage on this instance.Filesystem     Type   Size  Used Avail Use% Mounted on/dev/xvda1     ext4    50G   47G   16M 100% /Please find the volume usage in /47G     total26G     /tmp15G     /var6.1G    /usr510M    /home285M    /lib282M    /opt44M     /bootPlease find the attachment section for the detailed volume usage in /tmp, /var, and /usr folder. Please delete/zip unwanted files/folders to reduce the current volume usage state and let us know if your team have any further queries regarding this issue.","Hi SpendHQ-Team,This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 100%. We are investigating the alert and we will keep you posted on the progress.Resource DetailsInstance Name : PROD-SPHQ-DB-SERVER05Instance ID : i-008d43ad00357e47aInstance Private IP Address : 10.59.10.135Instance Availability Zone : us-east-1bInstance Type : r3.8xlargeVPC ID : vpc-76df7212Subnet ID : subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001PeA7k,Cloud Engineer Level 1,Closed,1090066,Incident,04-02-2018 03:54,,"Steven Ng3:53 AM (1 minute ago)to Rean The site is back up. You can mark this closed. Steven Ng | Full Stack Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.com###Hello SpendHQ Team,Let us know whether you got a chance to review the below details, the site http://l.spendhq.com.went down as the tomcat process got killed due to out of memory. Please validate the case and let us know whether we are good to close this case.###Hello SpendHQ Team,By further analysis, we could see that the tomcat process got killed due to out of memory. So we went ahead and restarted the service which brought back the service and currently the site came up and serving well.The site went down for 27 minutes. Please check and let us know if you are having any queries.###Hello SpendHQ-Team, This is to inform you that we have received a site down alert for the URL: http://l.spendhq.com. We are analyzing more on this issue and meanwhile let us know if you are performing any activity from your end.","Fri, 02 Feb 2018 14:49:54 -0500Detected Error on SpendHQ LEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/59891--------------------Sensor Failure: HTTP--------------------Sensor reported error:Got response code 503, expected 302Sensor parameters:url: http://l.spendhq.comexpect: 302wantedstring: unwantedstring: Reported by node: Frankfurt DEConfirmed by node(s): London UK, Dallas-B US, New Jersey US, California US--  <https://signup.paloaltonetworks.com/ehome/305324>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ L,,03-02-2018 01:19,27,0,SpendHQ,Steven Ng3:53 AM (1 minute ago)to Rean The site is back up. You can mark this closed. Steven Ng | Full Stack Developer | SpendHQ®O: 770.628.0692 | C: 404.993.0856 | sng@spendhq.com,"Hello SpendHQ Team,Let us know whether you got a chance to review the below details, the site http://l.spendhq.com.went down as the tomcat process got killed due to out of memory. Please validate the case and let us know whether we are good to close this case.","Hello SpendHQ Team,By further analysis, we could see that the tomcat process got killed due to out of memory. So we went ahead and restarted the service which brought back the service and currently the site came up and serving well.The site went down for 27 minutes. Please check and let us know if you are having any queries.","Hello SpendHQ-Team, This is to inform you that we have received a site down alert for the URL: http://l.spendhq.com. We are analyzing more on this issue and meanwhile let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001SVnDc,Cloud Engineer Level 1,Closed,1093357,Incident,15-03-2018 03:01,,"Hello Team,This is to notify that the alert High Memory utilization on PRD-WW1_122 got resolved.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Parvesh.###Hello Team,On further analysis, we could see the memory usage on PRD-WW1_122.USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDapache    4155  3.3 10.9 2032528 1667824 ?     S    19:43   0:48 /usr/sbin/httpdapache   27634  1.2  7.4 1512340 1147020 ?     S    17:58   1:36 /usr/sbin/httpdapache   28679  1.0  7.2 1476420 1110396 ?     S    18:10   1:16 /usr/sbin/httpdclam      1635  0.0  3.6 714300 552240 ?       Ssl  Mar06   1:13 clamdapache   18280  1.2  3.5 910732 544376 ?       S    16:04   3:08 /usr/sbin/httpdtomcat    1787  0.0  3.3 5916696 517464 ?      Sl   Mar06   7:28 /usr/java/default/bin/java -Djava.util.logging.config.file=/opt/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Dfile.encoding=UTF-8 -Dnet.sf.ehcache.skipUpdateCheck=true -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+UseParNewGC -XX:MaxPermSize=128m -Xms512m -Xmx512m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -classpath /opt/tomcat/bin/bootstrap.jar:/opt/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/opt/tomcat -Dcatalina.home=/opt/tomcat -Djava.io.tmpdir=/opt/tomcat/temp org.apache.catalina.startup.Bootstrap startapache   16330  1.3  2.6 772232 406796 ?       S    15:40   3:31 /usr/sbin/httpdapache   10454  1.0  1.1 540124 175104 ?       S    14:28   3:26 /usr/sbin/httpdapache    5182  0.8  0.9 515400 152356 ?       S    19:55   0:06 /usr/sbin/httpdapache   17397  1.0  0.8 495664 130600 ?       S    15:53   2:43 /usr/sbin/httpd###Hello Team,This is to notify that we have received an alert regarding the High Memory Utilization Alert on host PRD-WW1_122.Resource Details:-Instance name:- PRD-WW1_122Instance ID:-i-0ace70ce06368e4a7Instance type:-c4.2xlargePrivate IPs:-10.59.100.122VPC ID:-vpc-76df7212AMI ID:-PROD-SPHQ-WEB-SERVER03-10.59.100.79-Clone_19th_July_2017 (ami-a5cddab3)Subnet ID:-subnet-0d093d27.We are analyzing the issue and will get back to you with an update.Meanwhile Please let us know if there is any activity is performing on your end","---------- Forwarded message ----------From: Datadog Alerting <alert@datadoghq.com>Date: Thu, Mar 15, 2018 at 1:15 AMSubject: [Monitor Alert] Triggered: [SpendHQ] - High Memory UtilizationAlert on host - prd-ww1_122 - 10.59.100.122 - webTo: REANCloud Support <ms@reancloud.com>[image: Datadog][Triggered] [SpendHQ] - High Memory Utilization Alert on host - prd-ww1_122- 10.59.100.122 - webDetected High MEMORY utilization. Log in to the machine and verify whichprocess is consuming high MEMORY resources@ms@reancloud.com <https://app.datadoghq.com/account/profile/u-0Z0C_KyYU1Hu>[image: Metric Graph]<https://app.datadoghq.com/monitors#2023977?to_ts=1521056747000&group=host%3Ai-0ace70ce06368e4a7&from_ts=1521056447000>avg(last_5m):( avg:system.mem.used{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} - avg:system.mem.cached{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} ) / avg:system.mem.total{datadog_monitor:on,!host:i-03ccfddd9f02cacb9}by {host} * 100 > 85The monitor was last triggered at Wed Mar 14 2018 19:45:57 UTC (*1 sec ago*).------------------------------[Monitor Status<https://app.datadoghq.com/monitors#2023977?group=host%3Ai-0ace70ce06368e4a7>]· [Edit Monitor <https://app.datadoghq.com/monitors#2023977/edit>] · [Viewi-0ace70ce06368e4a7<https://app.datadoghq.com/infrastructure?hostname=i-0ace70ce06368e4a7>]· [ShowProcesses<https://app.datadoghq.com/process?sort=memory%2CDESC&to_ts=1521056757000&tags=host%3Ai-0ace70ce06368e4a7&from_ts=1521055857000&live=false&showSummaryGraphs=true>]This alert was raised by account SpendHQComment in Datadog<https://app.datadoghq.com/event/event?id=4308286607037526038>To manage your Datadog subscriptions, click here<https://app.datadoghq.com/account/preferences>.-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: [Monitor Alert] Triggered: [SpendHQ] - High Memory Utilization Alert on host - prd-ww1_122 - 10.59.100.122 - web,,15-03-2018 01:28,2,0,SpendHQ,"Hello Team,This is to notify that the alert High Memory utilization on PRD-WW1_122 got resolved.At this time, we're marking this case as Resolved. However, if you have any further queries on this, we want to hear from you! For continued support, please drop us an email with your queries.Best Regards,Parvesh.","Hello Team,On further analysis, we could see the memory usage on PRD-WW1_122.USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDapache    4155  3.3 10.9 2032528 1667824 ?     S    19:43   0:48 /usr/sbin/httpdapache   27634  1.2  7.4 1512340 1147020 ?     S    17:58   1:36 /usr/sbin/httpdapache   28679  1.0  7.2 1476420 1110396 ?     S    18:10   1:16 /usr/sbin/httpdclam      1635  0.0  3.6 714300 552240 ?       Ssl  Mar06   1:13 clamdapache   18280  1.2  3.5 910732 544376 ?       S    16:04   3:08 /usr/sbin/httpdtomcat    1787  0.0  3.3 5916696 517464 ?      Sl   Mar06   7:28 /usr/java/default/bin/java -Djava.util.logging.config.file=/opt/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Dfile.encoding=UTF-8 -Dnet.sf.ehcache.skipUpdateCheck=true -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+UseParNewGC -XX:MaxPermSize=128m -Xms512m -Xmx512m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -classpath /opt/tomcat/bin/bootstrap.jar:/opt/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/opt/tomcat -Dcatalina.home=/opt/tomcat -Djava.io.tmpdir=/opt/tomcat/temp org.apache.catalina.startup.Bootstrap startapache   16330  1.3  2.6 772232 406796 ?       S    15:40   3:31 /usr/sbin/httpdapache   10454  1.0  1.1 540124 175104 ?       S    14:28   3:26 /usr/sbin/httpdapache    5182  0.8  0.9 515400 152356 ?       S    19:55   0:06 /usr/sbin/httpdapache   17397  1.0  0.8 495664 130600 ?       S    15:53   2:43 /usr/sbin/httpd","Hello Team,This is to notify that we have received an alert regarding the High Memory Utilization Alert on host PRD-WW1_122.Resource Details:-Instance name:- PRD-WW1_122Instance ID:-i-0ace70ce06368e4a7Instance type:-c4.2xlargePrivate IPs:-10.59.100.122VPC ID:-vpc-76df7212AMI ID:-PROD-SPHQ-WEB-SERVER03-10.59.100.79-Clone_19th_July_2017 (ami-a5cddab3)Subnet ID:-subnet-0d093d27.We are analyzing the issue and will get back to you with an update.Meanwhile Please let us know if there is any activity is performing on your end",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001aN3tF,Cloud Engineer Level 1,Closed,1102698,Incident,13-08-2018 23:07,,"Hello Team, The site down alert for the URL:https://secure.spendhq.com/login got resolved and Estimated Downtime was 1 minute. As mentioned in the previous comment we checked all the metrics from AWS and instance level but there is no suspicious activity during the time of the alert. As this alert was triggered because of latency. As the alert is in the resolved state we are marking this case as resolved and closing this case. Please let us know if you have any further queries###Hello Team, The site down alert for the URL:https://secure.spendhq.com/login got resolved and Estimated Downtime was 1 minute. While checking the backend ELB, instance and DB servers, we found the below details. 1. From the NewPreview-ELB load balancer, we could see Latency was around 37273.70 NewPreview-ELB From the Backend Instance PRD-WW1_122 and PRD-WW2_6, we could see all the metrics are looking normal. Kindly validate these details and let us know if you have performed any activity from your end###Hello Spendhq-Team, This is to notify you that we received an alert site down on the URL: https://secure.spendhq.com/login .and recovered within a minute. we are analyzing more on this issue and will get back to you with updates. Please let us know if you are performing any activity from your end.","Thanks & Regards,Mon, 13 Aug 2018 10:10:02 -0400Detected Error on SpendHQ SecureEstimated Downtime: 1 minutehttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30007 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Sydney-C AU, Frankfurt DE, California US, Atlanta-B US--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>--  <https://hubs.ly/H0d8gJ20>Palais de Congres, Montreal 8th Aug, 2018 <http://go.reancloud.com/palais-email-sign>Amazon Smile7th-8th Aug, 2018 <http://go.reancloud.com/amazon-smile-email-sign>PA Convention Center, Philadelphia23rd Aug, 2018 <http://go.reancloud.com/philadelphia-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Fwd: Detected Error on SpendHQ Secure,,13-08-2018 19:40,3,0,SpendHQ,"Hello Team, The site down alert for the URL:https://secure.spendhq.com/login got resolved and Estimated Downtime was 1 minute. As mentioned in the previous comment we checked all the metrics from AWS and instance level but there is no suspicious activity during the time of the alert. As this alert was triggered because of latency. As the alert is in the resolved state we are marking this case as resolved and closing this case. Please let us know if you have any further queries","Hello Team, The site down alert for the URL:https://secure.spendhq.com/login got resolved and Estimated Downtime was 1 minute. While checking the backend ELB, instance and DB servers, we found the below details. 1. From the NewPreview-ELB load balancer, we could see Latency was around 37273.70 NewPreview-ELB From the Backend Instance PRD-WW1_122 and PRD-WW2_6, we could see all the metrics are looking normal. Kindly validate these details and let us know if you have performed any activity from your end","Hello Spendhq-Team, This is to notify you that we received an alert site down on the URL: https://secure.spendhq.com/login .and recovered within a minute. we are analyzing more on this issue and will get back to you with updates. Please let us know if you are performing any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001bkHPz,Cloud Engineer Level 1,Closed,1104661,Incident,15-09-2018 16:19,,"I have updated the missing tags. Now closing this case.###Hi Praveen,We will check and adjust the tags accordingly.Thanks.","Hello Team, Fix this tag issues.  From: ms@reancloud.com <ms@reancloud.com> Sent: September 14, 2018 10:05 AMTo: spendhq-support@reancloud.comSubject: [Managed Cloud: spendhq] ELB Required tag check REAN Managed Cloud NotificationThis is to notify you about the recent changes made to your AWS environment by REAN Managed Cloud. The following AWS::ElasticLoadBalancing::LoadBalancer resources were affected:   _____  *	Violation: The ELB does not have required tag.*	Recommendation: None*	Action taken: None*	Resource details: Resource IDTypeRegionCreation DateMissing tagswww1-sandbox-spendhq-comclassicus-east-12018-06-26Owner,Monitoringmapdtest2classicus-east-12018-08-07Name,Owner,Monitoringmapdclassicus-east-12018-08-07Name,Owner,Monitoring  _____  Best Regards, REAN Cloud Team IMPORTANT: Please do not reply to this message or email address. --  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>--  <https://hubs.ly/H0d8gJ20>Santa Clara Convention Center - Santa Clara, CA12th Sep, 2018 <http://go.reancloud.com/santa-clara-email-sign>Detroit Marriott at the Renaissance Center - Detroit, MI25th Sep, 2018 <http://go.reancloud.com/detroit-email-sign>Westin Seattle - WA9th Oct, 2018 <http://go.reancloud.com/seattle-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",FW: [Managed Cloud: spendhq] ELB Required tag check,,14-09-2018 20:06,20,0,SpendHQ,I have updated the missing tags. Now closing this case.,"Hi Praveen,We will check and adjust the tags accordingly.Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001gclnr,Cloud Engineer Level 2,Closed,1109633,Incident,20-12-2018 21:23,,"Hi Matthew,As discussed over the call today, you have made the changes at the storage side and you are able to optimize the write i/o.For now we are closing this case. Thanks !###Hi Matthew,Thanks for joining the call.As discussed on the call, you will be doing the test by attaching the secondary volume to the machine and check the performance. We will get on a call tomorrow to discuss further on this.###Matthew Watts4:48 PM (4 minutes ago)to ReanRean, We don’t need Chris on the call. It’s just to discuss resizing.###Matthew Watts4:38 PM (3 minutes ago)to cveillette@andromeda3.com, ReanPerfect. Thank you###Hello Chris,We request to join the bridge at 9:30 AM EST to discuss regarding the issue faced by Spendhq team while migrating the database over to MariaDB.Below are bridge details:https://reancloud.zoom.us/my/mgse2###@Team:Please add Chris from A3 Team to the meeting invite. As we need him over there. Thanks###Calendar invite is created.###Hello Matthew,We are scheduling a call with you to discuss the issue at 9:30 am EST.  We will be available on the bridge at that time.Below is the bridge link: https://reancloud.zoom.us/my/mgse2Kindly join the link in order to fix the issue.###@Team:Please setup a call for today 8:00 PM IST Today and share the invite with customer.###Sure Matthew,We will get back to you with the new timings.Thanks.###Matthew Watts4:13 AM (3 minutes ago)to ReanPlease advise of a time in advance and I will join.###Team,Please check with Rohit and share the new bridge and timings with customer.###Hello Matthew,We shared the bridge but did not have anyone joining.We will reschedule the call and share the new availability timings and bridge with you.Thanks.###Hello Matthew,Can you please join the below bridge to discuss increasing the instance type.https://reancloud.zoom.us/j/6709937998###Hello Matthew,We will check on this and we will share the bridge shortly.","Rean,We migrated our database over to MariaDB over the weekend at are getting constraints on the sdb volume. Is there any chance we can get on a call to discuss increasing the instance type to help with this. The database writes. Temp tables to this directory which is causing the issue.[cid:image001.png@01D496EB.2F343AA0][cid:image002.png@01D496EB.2F343AA0][cid:image003.png@01D496EB.2F343AA0]-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Write I/O,,19-12-2018 02:33,43,0,SpendHQ,"Hi Matthew,As discussed over the call today, you have made the changes at the storage side and you are able to optimize the write i/o.For now we are closing this case. Thanks !","Hi Matthew,Thanks for joining the call.As discussed on the call, you will be doing the test by attaching the secondary volume to the machine and check the performance. We will get on a call tomorrow to discuss further on this.","Matthew Watts4:48 PM (4 minutes ago)to ReanRean, We don’t need Chris on the call. It’s just to discuss resizing.","Matthew Watts4:38 PM (3 minutes ago)to cveillette@andromeda3.com, ReanPerfect. Thank you","Hello Chris,We request to join the bridge at 9:30 AM EST to discuss regarding the issue faced by Spendhq team while migrating the database over to MariaDB.Below are bridge details:https://reancloud.zoom.us/my/mgse2",@Team:Please add Chris from A3 Team to the meeting invite. As we need him over there. Thanks,Calendar invite is created.,"Hello Matthew,We are scheduling a call with you to discuss the issue at 9:30 am EST.  We will be available on the bridge at that time.Below is the bridge link: https://reancloud.zoom.us/my/mgse2Kindly join the link in order to fix the issue.",@Team:Please setup a call for today 8:00 PM IST Today and share the invite with customer.,"Sure Matthew,We will get back to you with the new timings.Thanks.",Matthew Watts4:13 AM (3 minutes ago)to ReanPlease advise of a time in advance and I will join.,"Team,Please check with Rohit and share the new bridge and timings with customer.","Hello Matthew,We shared the bridge but did not have anyone joining.We will reschedule the call and share the new availability timings and bridge with you.Thanks.","Hello Matthew,Can you please join the below bridge to discuss increasing the instance type.https://reancloud.zoom.us/j/6709937998","Hello Matthew,We will check on this and we will share the bridge shortly.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G000018I9G5,Cloud Engineer Level 1,Closed,1043230,Incident,16-02-2017 11:59,,We are following this on 1043214,"Thu, 16 Feb 2017 00:37:34 -0500SpendHQ has RecoveredEstimated Downtime: 2 minutes 59 seconds https://www.wormly.com/edithost/hostid/50743----------HTTP is UP----------Sensor parameters:url: https://preview.spendhq.com/loginexpect: 200wantedstring: SpendHQunwantedstring: ----------HTTP is UP----------Sensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey US-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",SpendHQ has Recovered,,16-02-2017 11:07,2,0,SpendHQ,We are following this on 1043214,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001eNdUL,Cloud Engineer Level 1,Closed,1107229,Incident,07-11-2018 00:45,,"Kristen Stretch10:09 PM (5 minutes ago)to meYes, thank you that worked. It must have happened when I had to kill the background process and I didn’t restart it correctly.###Kristen,Glad to hear that. As of now we are proceeding with marking this case (01107229) as closed. Regards,-Hosea###Hello Kristen,Thank you for reaching out. From the logs you've shared, the issue can easily be resolved by ensuring you run the OpenvpnGUI.exe as administrator. This is a security measure imposed by Microsoft not OpenVPN.To do this please follow this step:- You must select OpenvpnGUI.exe and <right-click>:Run As Administrator Try this out and let us know if you are able to connect, if not we can get on call.Regards,-Hosea","Hi,I was connected to VPN this morning with no issue. However, I was disconnected and upon successfully reconnecting can no longer access anything. VPN says I am connected. Verified others can connect to the same servers, etc I was working on earlier so I am assuming this a problem with my VPN specifically. Have tried to reconnect on both wifi and ethernet. I have added the logs below:Enter Management Password:Tue Nov 06 13:14:50 2018 MANAGEMENT: TCP Socket listening on [AF_INET]127.0.0.1:25340Tue Nov 06 13:14:50 2018 Need hold release from management interface, waiting...Tue Nov 06 13:14:50 2018 MANAGEMENT: Client connected from [AF_INET]127.0.0.1:25340Tue Nov 06 13:14:51 2018 MANAGEMENT: CMD 'state on'Tue Nov 06 13:14:51 2018 MANAGEMENT: CMD 'log all on'Tue Nov 06 13:14:51 2018 MANAGEMENT: CMD 'hold off'Tue Nov 06 13:14:51 2018 MANAGEMENT: CMD 'hold release'Tue Nov 06 13:15:08 2018 MANAGEMENT: CMD 'username Auth kristen'Tue Nov 06 13:15:08 2018 MANAGEMENT: CMD 'password [...]'Tue Nov 06 13:15:08 2018 Socket Buffers: R=[65536->65536] S=[65536->65536]Tue Nov 06 13:15:08 2018 Attempting to establish TCP connection with [AF_INET]52.0.17.10:7443 [nonblock]Tue Nov 06 13:15:08 2018 MANAGEMENT: >STATE:1541528108,TCP_CONNECT,,,,,,Tue Nov 06 13:15:12 2018 TCP connection established with [AF_INET]52.0.17.10:7443Tue Nov 06 13:15:12 2018 TCPv4_CLIENT link local: [undef]Tue Nov 06 13:15:12 2018 TCPv4_CLIENT link remote: [AF_INET]52.0.17.10:7443Tue Nov 06 13:15:12 2018 MANAGEMENT: >STATE:1541528112,WAIT,,,,,,Tue Nov 06 13:15:12 2018 MANAGEMENT: >STATE:1541528112,AUTH,,,,,,Tue Nov 06 13:15:12 2018 TLS: Initial packet from [AF_INET]52.0.17.10:7443, sid=8a02f73f f10ec3ccTue Nov 06 13:15:12 2018 WARNING: this configuration may cache passwords in memory -- use the auth-nocache option to prevent thisTue Nov 06 13:15:13 2018 VERIFY OK: depth=1, C=us, L=virginia, O=spendhq, CN=spendhq VPN CA, emailAddress=spendhq-support@reancloud.comTue Nov 06 13:15:13 2018 VERIFY X509NAME OK: C=us, L=virginia, O=spendhq, CN=spendhq, emailAddress=spendhq-support@reancloud.comTue Nov 06 13:15:13 2018 VERIFY OK: depth=0, C=us, L=virginia, O=spendhq, CN=spendhq, emailAddress=spendhq-support@reancloud.comTue Nov 06 13:15:13 2018 Data Channel Encrypt: Cipher 'AES-128-CBC' initialized with 128 bit keyTue Nov 06 13:15:13 2018 Data Channel Encrypt: Using 160 bit message hash 'SHA1' for HMAC authenticationTue Nov 06 13:15:13 2018 Data Channel Decrypt: Cipher 'AES-128-CBC' initialized with 128 bit keyTue Nov 06 13:15:13 2018 Data Channel Decrypt: Using 160 bit message hash 'SHA1' for HMAC authenticationTue Nov 06 13:15:13 2018 Control Channel: TLSv1.2, cipher TLSv1/SSLv3 DHE-RSA-AES256-GCM-SHA384, 2048 bit RSATue Nov 06 13:15:13 2018 [spendhq] Peer Connection Initiated with [AF_INET]52.0.17.10:7443Tue Nov 06 13:15:14 2018 MANAGEMENT: >STATE:1541528114,GET_CONFIG,,,,,,Tue Nov 06 13:15:16 2018 SENT CONTROL [spendhq]: 'PUSH_REQUEST' (status=1)Tue Nov 06 13:15:16 2018 PUSH: Received control message: 'PUSH_REPLY,route-gateway 10.242.2.1,route-gateway 10.242.2.1,topology subnet,ping 10,ping-restart 120,route 10.59.0.0 255.255.0.0,ifconfig 10.242.2.3 255.255.255.0'Tue Nov 06 13:15:16 2018 OPTIONS IMPORT: timers and/or timeouts modifiedTue Nov 06 13:15:16 2018 OPTIONS IMPORT: --ifconfig/up options modifiedTue Nov 06 13:15:16 2018 OPTIONS IMPORT: route options modifiedTue Nov 06 13:15:16 2018 OPTIONS IMPORT: route-related options modifiedTue Nov 06 13:15:16 2018 ROUTE_GATEWAY 192.168.35.1/255.255.254.0 I=21 HWADDR=38:de:ad:51:74:03Tue Nov 06 13:15:16 2018 open_tun, tt->ipv6=0Tue Nov 06 13:15:16 2018 TAP-WIN32 device [Ethernet 3] opened: \\.\\Global\\{9ECCD85C-8FAF-44CA-9986-6960239B6026}.tapTue Nov 06 13:15:16 2018 TAP-Windows Driver Version 9.21Tue Nov 06 13:15:16 2018 Set TAP-Windows TUN subnet mode network/local/netmask = 10.242.2.0/10.242.2.3/255.255.255.0 [SUCCEEDED]Tue Nov 06 13:15:16 2018 Notified TAP-Windows driver to set a DHCP IP/netmask of 10.242.2.3/255.255.255.0 on interface {9ECCD85C-8FAF-44CA-9986-6960239B6026} [DHCP-serv: 10.242.2.254, lease-time: 31536000]Tue Nov 06 13:15:16 2018 NOTE: FlushIpNetTable failed on interface [19] {9ECCD85C-8FAF-44CA-9986-6960239B6026} (status=5) : Access is denied.Tue Nov 06 13:15:16 2018 do_ifconfig, tt->ipv6=0, tt->did_ifconfig_ipv6_setup=0Tue Nov 06 13:15:16 2018 MANAGEMENT: >STATE:1541528116,ASSIGN_IP,,10.242.2.3,,,,Tue Nov 06 13:15:20 2018 TEST ROUTES: 2/2 succeeded len=2 ret=1 a=0 u/d=upTue Nov 06 13:15:20 2018 MANAGEMENT: >STATE:1541528120,ADD_ROUTES,,,,,,Tue Nov 06 13:15:20 2018 C:\\WINDOWS\\system32\\route.exe ADD 52.0.17.10 MASK 255.255.255.255 192.168.35.1Tue Nov 06 13:15:20 2018 ROUTE: route addition failed using CreateIpForwardEntry: Access is denied.   [status=5 if_index=21]Tue Nov 06 13:15:20 2018 Route addition via IPAPI failed [adaptive]Tue Nov 06 13:15:20 2018 Route addition fallback to route.exeTue Nov 06 13:15:20 2018 env_block: add PATH=C:\\Windows\\System32;C:\\WINDOWS;C:\\WINDOWS\\System32\\WbemTue Nov 06 13:15:20 2018 ERROR: Windows route add command failed [adaptive]: returned error code 1Tue Nov 06 13:15:20 2018 C:\\WINDOWS\\system32\\route.exe ADD 10.59.0.0 MASK 255.255.0.0 10.242.2.1Tue Nov 06 13:15:20 2018 ROUTE: route addition failed using CreateIpForwardEntry: Access is denied.   [status=5 if_index=19]Tue Nov 06 13:15:20 2018 Route addition via IPAPI failed [adaptive]Tue Nov 06 13:15:20 2018 Route addition fallback to route.exeTue Nov 06 13:15:20 2018 env_block: add PATH=C:\\Windows\\System32;C:\\WINDOWS;C:\\WINDOWS\\System32\\WbemTue Nov 06 13:15:20 2018 ERROR: Windows route add command failed [adaptive]: returned error code 1Tue Nov 06 13:15:20 2018 Initialization Sequence CompletedTue Nov 06 13:15:20 2018 MANAGEMENT: >STATE:1541528120,CONNECTED,SUCCESS,10.242.2.3,52.0.17.10,7443,192.168.35.130,58946-Kristen--  <http://htchivantara.is/2RAornF>Charlotte Convention Center - Charlotte, NC30th Oct, 2018 <http://go.reancloud.com/charlotte-email-sign>Westin Harbor Castle - Toronto, Canada1st Nov, 2018 <http://go.reancloud.com/toronto-email-sign>The Marquette Hotel, Curio Collection by Hilton - Minneapolis, MN5th Nov, 2018 <http://go.reancloud.com/minneapolis-email-sign>-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.","VPN suddenly not working, cant access servers",,06-11-2018 23:53,1,0,SpendHQ,"Kristen Stretch10:09 PM (5 minutes ago)to meYes, thank you that worked. It must have happened when I had to kill the background process and I didn’t restart it correctly.","Kristen,Glad to hear that. As of now we are proceeding with marking this case (01107229) as closed. Regards,-Hosea","Hello Kristen,Thank you for reaching out. From the logs you've shared, the issue can easily be resolved by ensuring you run the OpenvpnGUI.exe as administrator. This is a security measure imposed by Microsoft not OpenVPN.To do this please follow this step:- You must select OpenvpnGUI.exe and <right-click>:Run As Administrator Try this out and let us know if you are able to connect, if not we can get on call.Regards,-Hosea",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hTNol,Cloud Engineer Level 1,Closed,1110533,Incident,17-01-2019 11:52,,"Hello Matthew,We are following on this case 01110746.At this time we are marking this case closed and let us know if you have any queries related to it.###Hello Matthew, We didn't hear back from you regarding this case. Kindly review the analysis that was shared and let us know if you have questions or concerns. Thanks###Hello Matthew, This is a quick followup. We didn't hear back from you. Kindly review the analysis that was shared and let us know if you have questions or concerns. Thanks###Hello Matthew,This is a quick followup.  We didn't hear back from you.Kindly review the analysis that was shared and let us know if you have questions or concerns. Thanks###Hello Matthew,We have not heard back from you again.Kindly review the analysis that was shared and let us know if you have questions or concerns.Thanks###Hello Matthew,As promised, we have analyzed this issue in detail and have some new developments on it.Though all metrics on the web server seem normal, we observed with concern a few errors on the db server 10.59.10.210 (SPHQ-DB4-20180830) that could be related to the alert.At the time of the alert, on the server 10.59.10.210 a few errors were observed with newrelic-infra service failing it's checks at that exact time (13:12 PM UTC). Jan 10 13:12:09 ip-10-59-10-210 agent: 2019-01-10 13:12:09 UTC | INFO | (serializer.go:263 in SendJSONToV1Intake) | Sent processes metadata payload, size: 1403 bytes. Jan 10 13:12:34 ip-10-59-10-210 newrelic-infra: time=2019-01-10T13:12:34Z level=error msg=unable to get systemd service status error=exit status 1 Jan 10 13:12:37 ip-10-59-10-210 trace-agent: 2019-01-10 13:12:37 INFO (api.go:324) - no data received In addition to this, there seemed to be several login attempts on the server being rejected with a timeout error. Sessions are being stopped as soon as they are created with a connection timeout error. We suspect this is why you were unable to login earlier.Jan 10 13:09:45 ip-10-59-10-210 systemd: Stopping User Slice of root. Jan 10 13:10:07 ip-10-59-10-210 trace-agent: 2019-01-10 13:10:07 INFO (service_mapper.go:59) - total number of tracked services: 0 Jan 10 13:10:17 ip-10-59-10-210 trace-agent: 2019-01-10 13:10:17 INFO (api.go:324) - no data received Jan 10 13:10:17 ip-10-59-10-210 systemd-logind: Failed to start user slice user-0.slice, ignoring: Connection timed out ((null)) Jan 10 13:10:22 ip-10-59-10-210 agent: 2019-01-10 13:10:22 UTC | INFO | (transaction.go:198 in Process) | Successfully posted payload to https://6-8-0-app.agent.datadoghq.com/api/v1/check_run?api_key=*************************149e2 Jan 10 13:10:30 ip-10-59-10-210 newrelic-infra: time=2019-01-10T13:10:30Z level=error msg=unable to get systemd service status error=exit status 1 From the db logs we could see connections from the web server 10.59.100.193 being aborted 1 minute before the alert got triggered. cat mysql/mysqlmariadb-error.log | grep 2019-01-10 13:*:* 2019-01-10 13:10:38 140140534019840 [Warning] Aborted connection 1987998 to db: 'isg' user: 'shq_www' host: '10.59.100.193' (Got an error reading communication packets) 2019-01-10 13:10:38 140141631100672 [Warning] Aborted connection 1987999 to db: 'isg' user: 'shq_www' host: '10.59.100.193' (Got an error reading communication packets) 2019-01-10 13:16:53 140129078859520 [Warning] Sort aborted, host: 10.59.100.122, user: ww1_mdb, thread: 1989241, query: select `isg_cushmanw.Subcategory.category` `category`, `isg_cushmanw.Subcategory.subcategory` `subcategory`, `isg_cushmanw.Vendor.name` `name`, `isg_cushmanw.SpendVisibility.amount` `amount`, `isg_cushmanw.Location.country` `country`, `isg_cushmanw.Subdivision.division` `division`, `isg_cushmanw.SpendVisibilityCustomValue.custom1` `custom1`, `isg_cushmanw.SpendVisibilityCustomValue.custom4` `custom4`, `isg_cushmanw.SpendVisibilityCustomValue.custom5` `custom5`, `isg.Company.lft` `lft` from infinidb_vtable.$vtable_1989241 order by `isg_cushmanw.SpendVisibility.date_id`, `isg_cushmanw.SpendVisibility.amount` desc, `isg_cushmanw.SpendVisibility.id` limit 30000, 5000 From the above errors, we can conclude that the resulting latency issue is as a result of an error on the backend DB server which is serving the prod server. Since the prod server can't communicate with the database, connections are dropped leading to a spike in latency on the frontend prod server as requests can't be served. This issue seems to happen momentarily before resolving. We have attached the error logs from the 10.59.10.210 instance for your reference. Please review these analysis and consider our earlier request to get on call to find a permanent solution to this issue and let us know your thoughts.Thanks.###@Rohit,I got interested with the mention of server 10.59.10.210 (SPHQ-DB4-20180830) by Matthew and had to check it out to understand it's correlation with this alert. Below are my findings.At the time of the alert, on the server 10.59.10.210 a few errors were observed with newrelic-infra service failing it's checks at that exact time (13:12 PM UTC).Jan 10 13:12:09 ip-10-59-10-210 agent: 2019-01-10 13:12:09 UTC | INFO | (serializer.go:263 in SendJSONToV1Intake) | Sent processes metadata payload, size: 1403 bytes.Jan 10 13:12:34 ip-10-59-10-210 newrelic-infra: time=2019-01-10T13:12:34Z level=error msg=unable to get systemd service status error=exit status 1Jan 10 13:12:37 ip-10-59-10-210 trace-agent: 2019-01-10 13:12:37 INFO (api.go:324) - no data received In addition to this, there seemed to be several login attempts on the server being rejected with a timeout error. Sessions are being stopped as soon as they are created with a connection timeout error.Jan 10 13:09:45 ip-10-59-10-210 systemd: Stopping User Slice of root.Jan 10 13:10:07 ip-10-59-10-210 trace-agent: 2019-01-10 13:10:07 INFO (service_mapper.go:59) - total number of tracked services: 0Jan 10 13:10:17 ip-10-59-10-210 trace-agent: 2019-01-10 13:10:17 INFO (api.go:324) - no data receivedJan 10 13:10:17 ip-10-59-10-210 systemd-logind: Failed to start user slice user-0.slice, ignoring: Connection timed out ((null))Jan 10 13:10:22 ip-10-59-10-210 agent: 2019-01-10 13:10:22 UTC | INFO | (transaction.go:198 in Process) | Successfully posted payload to https://6-8-0-app.agent.datadoghq.com/api/v1/check_run?api_key=*************************149e2Jan 10 13:10:30 ip-10-59-10-210 newrelic-infra: time=2019-01-10T13:10:30Z level=error msg=unable to get systemd service status error=exit status 1From the db logs we could see connections from the web server 10.59.100.193 being aborted 1 minute before the alert got triggered.cat mysql/mysqlmariadb-error.log | grep 2019-01-10 13:*:*2019-01-10 13:10:38 140140534019840 [Warning] Aborted connection 1987998 to db: 'isg' user: 'shq_www' host: '10.59.100.193' (Got an error reading communication packets)2019-01-10 13:10:38 140141631100672 [Warning] Aborted connection 1987999 to db: 'isg' user: 'shq_www' host: '10.59.100.193' (Got an error reading communication packets)2019-01-10 13:16:53 140129078859520 [Warning] Sort aborted, host: 10.59.100.122, user: ww1_mdb, thread: 1989241, query: select `isg_cushmanw.Subcategory.category` `category`, `isg_cushmanw.Subcategory.subcategory` `subcategory`, `isg_cushmanw.Vendor.name` `name`, `isg_cushmanw.SpendVisibility.amount` `amount`, `isg_cushmanw.Location.country` `country`, `isg_cushmanw.Subdivision.division` `division`, `isg_cushmanw.SpendVisibilityCustomValue.custom1` `custom1`, `isg_cushmanw.SpendVisibilityCustomValue.custom4` `custom4`, `isg_cushmanw.SpendVisibilityCustomValue.custom5` `custom5`, `isg.Company.lft` `lft`  from infinidb_vtable.$vtable_1989241 order by `isg_cushmanw.SpendVisibility.date_id`,  `isg_cushmanw.SpendVisibility.amount` desc, `isg_cushmanw.SpendVisibility.id` limit 30000, 5000From the above errors, my conclusion is that the resulting latency issue is as a result of an error on the backend DB server serving the prod server. Since the prod server can't communicate with the database, connections are dropped leading to a spike in latency on the frontend prod server as requests can't be served. This issue seems to happen momentarily before resolving.Please review these details and let us know your thoughts.You can find the full logs here: https://docs.google.com/document/d/1amw3Jg3taN46pqROpB1Hs-i_866g7jxwQUhWYlQ4A_0/edit?usp=sharing###Hello Team, Just like it is with the previous incidents, we cant find any errors with the backend server. All metrics look normal from the CloudWatch level.However from the ELB level we can see a couple of spikes in latency, request count and Network In/Out.As we work on an amicable solution, we are dip diving on the issue to see if we can find any causes of this. In the meantime, please review this suggestions earlier provided and let us know your thoughts.1. Enable the Datadog Apache integration to review the Apache metrics. 2. Enable the Datadog DB Integration(if the database is PostgreSQL or MySQL compatible, we can enable a plugin) Thanks.###On analyzing the issue we found the following issue:1) There were latency during the time of alert2) Request count was having spikes in graph3) Network IN/OUT was high at the same time###Hi Matthew,Sorry for the delay in response.We are able to ssh from our side. We want to believe after another try it succeeded for you since we can see you are already logged in. If that's the case, please have a look into the issue at hand and get back to us.[centos@ip-10-59-10-210 ~]$ w 13:31:15 up 3 days,  1:34,  2 users,  load average: 1.25, 1.49, 2.94USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHATmwatts   pts/0    10.59.1.192      13:15   11:15   0.12s  0.12s /usr/local/mariadb/columnstore/mysql/bin/mysql --defaults-extra-file=/usr/local/mariadb/columnstore/mysql/my.cnf -u rootcentos   pts/2    10.59.1.192      13:31    3.00s  0.02s  0.02s wThanks. Regards.Stephen Oduor###Matthew Watts6:48 PM (11 minutes ago)to Rean, spendhq-support@reancloud.comLooked like the machines locked up. 10.59.10.210 was not letting me in via SSH.###Hello Team, We have received an alert regarding site down for url: https://secure.spendhq.com/login. We are analyzing the issue and will back to you with the update.","Thu, 10 Jan 2019 08:12:51 -0500Detected Error on SpendHQ SecureEstimated Downtime: 1 minute 59 secondshttps://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 60001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Atlanta-B US, London UK, Dallas-C US, Frankfurt-B DE-- -- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ Secure,,10-01-2019 18:44,161,0,SpendHQ,"Hello Matthew,We are following on this case 01110746.At this time we are marking this case closed and let us know if you have any queries related to it.","Hello Matthew, We didn't hear back from you regarding this case. Kindly review the analysis that was shared and let us know if you have questions or concerns. Thanks","Hello Matthew, This is a quick followup. We didn't hear back from you. Kindly review the analysis that was shared and let us know if you have questions or concerns. Thanks","Hello Matthew,This is a quick followup.  We didn't hear back from you.Kindly review the analysis that was shared and let us know if you have questions or concerns. Thanks","Hello Matthew,We have not heard back from you again.Kindly review the analysis that was shared and let us know if you have questions or concerns.Thanks","Hello Matthew,As promised, we have analyzed this issue in detail and have some new developments on it.Though all metrics on the web server seem normal, we observed with concern a few errors on the db server 10.59.10.210 (SPHQ-DB4-20180830) that could be related to the alert.At the time of the alert, on the server 10.59.10.210 a few errors were observed with newrelic-infra service failing it's checks at that exact time (13:12 PM UTC). Jan 10 13:12:09 ip-10-59-10-210 agent: 2019-01-10 13:12:09 UTC | INFO | (serializer.go:263 in SendJSONToV1Intake) | Sent processes metadata payload, size: 1403 bytes. Jan 10 13:12:34 ip-10-59-10-210 newrelic-infra: time=2019-01-10T13:12:34Z level=error msg=unable to get systemd service status error=exit status 1 Jan 10 13:12:37 ip-10-59-10-210 trace-agent: 2019-01-10 13:12:37 INFO (api.go:324) - no data received In addition to this, there seemed to be several login attempts on the server being rejected with a timeout error. Sessions are being stopped as soon as they are created with a connection timeout error. We suspect this is why you were unable to login earlier.Jan 10 13:09:45 ip-10-59-10-210 systemd: Stopping User Slice of root. Jan 10 13:10:07 ip-10-59-10-210 trace-agent: 2019-01-10 13:10:07 INFO (service_mapper.go:59) - total number of tracked services: 0 Jan 10 13:10:17 ip-10-59-10-210 trace-agent: 2019-01-10 13:10:17 INFO (api.go:324) - no data received Jan 10 13:10:17 ip-10-59-10-210 systemd-logind: Failed to start user slice user-0.slice, ignoring: Connection timed out ((null)) Jan 10 13:10:22 ip-10-59-10-210 agent: 2019-01-10 13:10:22 UTC | INFO | (transaction.go:198 in Process) | Successfully posted payload to https://6-8-0-app.agent.datadoghq.com/api/v1/check_run?api_key=*************************149e2 Jan 10 13:10:30 ip-10-59-10-210 newrelic-infra: time=2019-01-10T13:10:30Z level=error msg=unable to get systemd service status error=exit status 1 From the db logs we could see connections from the web server 10.59.100.193 being aborted 1 minute before the alert got triggered. cat mysql/mysqlmariadb-error.log | grep 2019-01-10 13:*:* 2019-01-10 13:10:38 140140534019840 [Warning] Aborted connection 1987998 to db: 'isg' user: 'shq_www' host: '10.59.100.193' (Got an error reading communication packets) 2019-01-10 13:10:38 140141631100672 [Warning] Aborted connection 1987999 to db: 'isg' user: 'shq_www' host: '10.59.100.193' (Got an error reading communication packets) 2019-01-10 13:16:53 140129078859520 [Warning] Sort aborted, host: 10.59.100.122, user: ww1_mdb, thread: 1989241, query: select `isg_cushmanw.Subcategory.category` `category`, `isg_cushmanw.Subcategory.subcategory` `subcategory`, `isg_cushmanw.Vendor.name` `name`, `isg_cushmanw.SpendVisibility.amount` `amount`, `isg_cushmanw.Location.country` `country`, `isg_cushmanw.Subdivision.division` `division`, `isg_cushmanw.SpendVisibilityCustomValue.custom1` `custom1`, `isg_cushmanw.SpendVisibilityCustomValue.custom4` `custom4`, `isg_cushmanw.SpendVisibilityCustomValue.custom5` `custom5`, `isg.Company.lft` `lft` from infinidb_vtable.$vtable_1989241 order by `isg_cushmanw.SpendVisibility.date_id`, `isg_cushmanw.SpendVisibility.amount` desc, `isg_cushmanw.SpendVisibility.id` limit 30000, 5000 From the above errors, we can conclude that the resulting latency issue is as a result of an error on the backend DB server which is serving the prod server. Since the prod server can't communicate with the database, connections are dropped leading to a spike in latency on the frontend prod server as requests can't be served. This issue seems to happen momentarily before resolving. We have attached the error logs from the 10.59.10.210 instance for your reference. Please review these analysis and consider our earlier request to get on call to find a permanent solution to this issue and let us know your thoughts.Thanks.","@Rohit,I got interested with the mention of server 10.59.10.210 (SPHQ-DB4-20180830) by Matthew and had to check it out to understand it's correlation with this alert. Below are my findings.At the time of the alert, on the server 10.59.10.210 a few errors were observed with newrelic-infra service failing it's checks at that exact time (13:12 PM UTC).Jan 10 13:12:09 ip-10-59-10-210 agent: 2019-01-10 13:12:09 UTC | INFO | (serializer.go:263 in SendJSONToV1Intake) | Sent processes metadata payload, size: 1403 bytes.Jan 10 13:12:34 ip-10-59-10-210 newrelic-infra: time=2019-01-10T13:12:34Z level=error msg=unable to get systemd service status error=exit status 1Jan 10 13:12:37 ip-10-59-10-210 trace-agent: 2019-01-10 13:12:37 INFO (api.go:324) - no data received In addition to this, there seemed to be several login attempts on the server being rejected with a timeout error. Sessions are being stopped as soon as they are created with a connection timeout error.Jan 10 13:09:45 ip-10-59-10-210 systemd: Stopping User Slice of root.Jan 10 13:10:07 ip-10-59-10-210 trace-agent: 2019-01-10 13:10:07 INFO (service_mapper.go:59) - total number of tracked services: 0Jan 10 13:10:17 ip-10-59-10-210 trace-agent: 2019-01-10 13:10:17 INFO (api.go:324) - no data receivedJan 10 13:10:17 ip-10-59-10-210 systemd-logind: Failed to start user slice user-0.slice, ignoring: Connection timed out ((null))Jan 10 13:10:22 ip-10-59-10-210 agent: 2019-01-10 13:10:22 UTC | INFO | (transaction.go:198 in Process) | Successfully posted payload to https://6-8-0-app.agent.datadoghq.com/api/v1/check_run?api_key=*************************149e2Jan 10 13:10:30 ip-10-59-10-210 newrelic-infra: time=2019-01-10T13:10:30Z level=error msg=unable to get systemd service status error=exit status 1From the db logs we could see connections from the web server 10.59.100.193 being aborted 1 minute before the alert got triggered.cat mysql/mysqlmariadb-error.log | grep 2019-01-10 13:*:*2019-01-10 13:10:38 140140534019840 [Warning] Aborted connection 1987998 to db: 'isg' user: 'shq_www' host: '10.59.100.193' (Got an error reading communication packets)2019-01-10 13:10:38 140141631100672 [Warning] Aborted connection 1987999 to db: 'isg' user: 'shq_www' host: '10.59.100.193' (Got an error reading communication packets)2019-01-10 13:16:53 140129078859520 [Warning] Sort aborted, host: 10.59.100.122, user: ww1_mdb, thread: 1989241, query: select `isg_cushmanw.Subcategory.category` `category`, `isg_cushmanw.Subcategory.subcategory` `subcategory`, `isg_cushmanw.Vendor.name` `name`, `isg_cushmanw.SpendVisibility.amount` `amount`, `isg_cushmanw.Location.country` `country`, `isg_cushmanw.Subdivision.division` `division`, `isg_cushmanw.SpendVisibilityCustomValue.custom1` `custom1`, `isg_cushmanw.SpendVisibilityCustomValue.custom4` `custom4`, `isg_cushmanw.SpendVisibilityCustomValue.custom5` `custom5`, `isg.Company.lft` `lft`  from infinidb_vtable.$vtable_1989241 order by `isg_cushmanw.SpendVisibility.date_id`,  `isg_cushmanw.SpendVisibility.amount` desc, `isg_cushmanw.SpendVisibility.id` limit 30000, 5000From the above errors, my conclusion is that the resulting latency issue is as a result of an error on the backend DB server serving the prod server. Since the prod server can't communicate with the database, connections are dropped leading to a spike in latency on the frontend prod server as requests can't be served. This issue seems to happen momentarily before resolving.Please review these details and let us know your thoughts.You can find the full logs here: https://docs.google.com/document/d/1amw3Jg3taN46pqROpB1Hs-i_866g7jxwQUhWYlQ4A_0/edit?usp=sharing","Hello Team, Just like it is with the previous incidents, we cant find any errors with the backend server. All metrics look normal from the CloudWatch level.However from the ELB level we can see a couple of spikes in latency, request count and Network In/Out.As we work on an amicable solution, we are dip diving on the issue to see if we can find any causes of this. In the meantime, please review this suggestions earlier provided and let us know your thoughts.1. Enable the Datadog Apache integration to review the Apache metrics. 2. Enable the Datadog DB Integration(if the database is PostgreSQL or MySQL compatible, we can enable a plugin) Thanks.",On analyzing the issue we found the following issue:1) There were latency during the time of alert2) Request count was having spikes in graph3) Network IN/OUT was high at the same time,"Hi Matthew,Sorry for the delay in response.We are able to ssh from our side. We want to believe after another try it succeeded for you since we can see you are already logged in. If that's the case, please have a look into the issue at hand and get back to us.[centos@ip-10-59-10-210 ~]$ w 13:31:15 up 3 days,  1:34,  2 users,  load average: 1.25, 1.49, 2.94USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHATmwatts   pts/0    10.59.1.192      13:15   11:15   0.12s  0.12s /usr/local/mariadb/columnstore/mysql/bin/mysql --defaults-extra-file=/usr/local/mariadb/columnstore/mysql/my.cnf -u rootcentos   pts/2    10.59.1.192      13:31    3.00s  0.02s  0.02s wThanks. Regards.Stephen Oduor","Matthew Watts6:48 PM (11 minutes ago)to Rean, spendhq-support@reancloud.comLooked like the machines locked up. 10.59.10.210 was not letting me in via SSH.","Hello Team, We have received an alert regarding site down for url: https://secure.spendhq.com/login. We are analyzing the issue and will back to you with the update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001CeFc1,Cloud Engineer Level 2,Closed,1058764,Incident,07-06-2017 13:52,,"Hello Team, As per our analysis we could see that at the point of incident the iscsi disk went offline and re discovered as /dev/sda, but  iscsi target was trying to remount as /dev/sdb.  May 31 10:30:12 ip-10-59-10-148 kernel: sd 13:0:0:0: rejecting I/O to offline device May 31 10:30:12 ip-10-59-10-148 kernel: Aborting journal on device sdb-8. May 31 10:30:12 ip-10-59-10-148 kernel: sd 13:0:0:0: rejecting I/O to offline device May 31 10:30:12 ip-10-59-10-148 kernel: JBD2: I/O error detected when updating journal superblock for sdb-8. May 31 10:30:22 ip-10-59-10-148 dd.collector[126719]: INFO (collector.py:530): Finished run #103070. Collection time: 4.07s. Emit time: 0.01s May 31 10:30:39 ip-10-59-10-148 dd.forwarder[126712]: INFO (transaction.py:177): Flushing 1 transaction during flush #689560 May 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs error (device sdb): ext4_journal_start_sb: Detected aborted journal May 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs (sdb): Remounting filesystem read-only May 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs (sdb): ext4_da_writepages: jbd2_start: 1024 pages, ino 132907033; err -30###++internal +++From the logs we can find out that the disk was offline May 31 10:30:12 ip-10-59-10-148 kernel: sd 13:0:0:0: rejecting I/O to offline deviceMay 31 10:30:12 ip-10-59-10-148 kernel: Aborting journal on device sdb-8.May 31 10:30:12 ip-10-59-10-148 kernel: sd 13:0:0:0: rejecting I/O to offline deviceMay 31 10:30:12 ip-10-59-10-148 kernel: JBD2: I/O error detected when updating journal superblock for sdb-8.May 31 10:30:22 ip-10-59-10-148 dd.collector[126719]: INFO (collector.py:530): Finished run #103070. Collection time: 4.07s. Emit time: 0.01sMay 31 10:30:39 ip-10-59-10-148 dd.forwarder[126712]: INFO (transaction.py:177): Flushing 1 transaction during flush #689560May 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs error (device sdb): ext4_journal_start_sb: Detected aborted journalMay 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs (sdb): Remounting filesystem read-onlyMay 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs (sdb): ext4_da_writepages: jbd2_start: 1024 pages, ino 132907033; err -30May 31 10:30:41 ip-10-59-10-148 kernel:###Errors detected in /var/log/messagesMay 31 10:30:12 ip-10-59-10-148 kernel: JBD2: I/O error detected when updating journal superblock for sdb-8.May 31 10:30:22 ip-10-59-10-148 dd.collector[126719]: INFO (collector.py:530): Finished run #103070. Collection time: 4.07s. Emit time: 0.01sMay 31 10:30:39 ip-10-59-10-148 dd.forwarder[126712]: INFO (transaction.py:177): Flushing 1 transaction during flush #689560May 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs error (device sdb): ext4_journal_start_sb: Detected aborted journalapart from this i couldn't find any errors in system logs.###Please find the document regarding iscsi volume details:https://docs.google.com/spreadsheets/d/171c0ZHcVEVbep-XqW2Ko8vsSVqVQrpSKHA0sTTJ8-rU/edit#gid=1821311068Also check messages log regarding directory  changed to read only mode###10.59.10.12 lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:centos-vol-v777bb21358661922.00000003.2f1dab31-lun-0 -> ../../sdhlrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:centos-vol-v777bb21358661922.00000003.2f1dab31-lun-0-part1 -> ../../sdh1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-copy-04-26-17-v777bb21358661922.0000001c.2f1dab31-lun-0 -> ../../sdblrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-v777bb21358661922.00000009.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq011-11-16.data22.clone-v777bb21358661922.00000012.2f1dab31-lun-0 -> ../../sdilrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq011-11-16.data22.clone-v777bb21358661922.00000012.2f1dab31-lun-0-part1 -> ../../sdi1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq-11-11-16.data.clone-v777bb21358661922.00000011.2f1dab31-lun-0 -> ../../sdflrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq-11-11-16.data.clone-v777bb21358661922.00000011.2f1dab31-lun-0-part1 -> ../../sdf1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-10-15-16-testspq-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.0000406d-lun-0 -> ../../sdglrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-10-15-16-testspq-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.0000406d-lun-0-part1 -> ../../sdg1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-clone092016-sphqec2var-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003baf-lun-0 -> ../../sdelrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-clone092016-sphqec2var-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003baf-lun-0-part1 -> ../../sde1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-snap1-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003ba8-lun-0 -> ../../sdalrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-snap1-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003ba8-lun-0-part1 -> ../../sda1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-v777bb21358661922.00000002.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-v777bb21358661922.00000002.2f1dab31-lun-0-part1 -> ../../sdd1 /dev/sdc        4.0T  2.5T  1.3T  67% /var/infobright Regards,-Praveen###10.59.10.135 lrwxrwxrwx 1 root root  9 May 31 18:45 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db-backup-02-02-17-v777bb21358661922.00000018.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 May 31 18:45 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db-backup-12-16-16.clone-v777bb21358661922.00000014.2f1dab31-lun-0 -> ../../sdalrwxrwxrwx 1 root root  9 May 31 18:45 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-copy-04-24-17-v777bb21358661922.0000001b.2f1dab31-lun-0 -> ../../sdb/dev/xvdf       2.0T  100G  1.8T   6% /mnt/drtest2016/dev/sdb        4.0T  2.3T  1.5T  61% /var/infobright/dev/sdc        4.0T  2.1T  1.8T  55% /mnt/db_backup-12-16-16/dev/sdb        4.0T  2.3T  1.5T  61% /mnt/db_backup_04_24_17/dev/sda        4.0T  1.6T  2.2T  43% /mnt/db_backup_02_02_2017 10.59.10.91 lrwxrwxrwx 1 root root  9 Jan  3 19:18 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000015.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 Jan  3 19:28 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000016.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root  9 Jan 10 16:17 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prod-backup-1-10-17-v777bb21358661922.00000017.2f1dab31-lun-0 -> ../../sdelrwxrwxrwx 1 root root  9 Nov  4  2016 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend5-v777bb21358661922.0000000d.2f1dab31-lun-0 -> ../../sdalrwxrwxrwx 1 root root  9 Nov  7  2016 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq-db4-v777bb21358661922.00000010.2f1dab31-lun-0 -> ../../sdb/dev/sdb        1.5T   91G  1.4T   7% /var/infobright/dev/xvdf       2.0T  100G  1.8T   6% /mnt/drtest2016/dev/sdd        4.0T  1.6T  2.2T  43% /mnt/db5-backup/dev/sde        4.0T  1.6T  2.2T  43% /mnt/prod-backup-1-10-17 10.59.10.148 NoneTBC....###Hello Rob, As far as knowledge, it would be difficult to get that info after the machine reboot. Here is the current iSCSI association details in each machine. @Matthew, please let us know if you know the device details by any chance and also let us know, if we can rebuild the database from any of the other DB iSCSI volumes or from backups. From our end, we will create an excel sheet to track each iSCSI volume lifecycle : create, associate, re-associate, mount not to arise such kind of issue in future.10.59.100.125 lrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-shqsshot-12-14-16-v777bb21358661922.00000008.2f1dab31.s777bb21358661922.00000008.00004bf2-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shqfiles01a-v777bb21358661922.00000013.2f1dab31-lun-0 -> ../../sdelrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shqsshot-12-14-16-v777bb21358661922.00000019.2f1dab31-lun-0 -> ../../sdalrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 -> ../../sdb /dev/sdb        2.0T  1.3T  630G  68% /var/www/vhosts/files.spendhq.comTBC...###Unfortunately, I have no clue. Based on the root users history I would say 172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend5-v777bb21358661922.0000000d.2f1dab31. Is there some kind of log of what was mounted previously?  Matthew, Do you have any idea which one was mounted before?    Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com###Hello Rob, Can you please help us which iSCSI device needs a mount to the 148 machine. 172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:db-backup-02-02-17-v777bb21358661922.00000018.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:db-backup-12-16-16.clone-v777bb21358661922.00000014.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000016.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend4-v777bb21358661922.00000009.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend4-copy-04-24-17-v777bb21358661922.0000001b.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend5-v777bb21358661922.0000000d.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spendhq-db4-v777bb21358661922.00000010.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:prod-backup-1-10-17-v777bb21358661922.00000017.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend4-copy-04-26-17-v777bb21358661922.0000001c.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend4-prod-backup-1-10-17-v777bb21358661922.00000009.2f1dab31.s777bb21358661922.00000009.00005121  Regards,-Praveen###This ticket has been escalated to on call CE2. I have tried to log in to all of the available ISCSI volumes on the DB Server 03 instance but was failed to do so. Chris from Andromeda team informed that this issue occurs when they are already login to other servers. Need to resolve this issue at the earliest.###Hi REAN -Here is the eerror message being generated on the storage end:SCSI login to volume iqn.2007-11.com.nimblestorage:spend4-copy-04-26-17-v777bb21358661922.0000001c.2f1dab31 rejected from iqn.1994-05.com.redhat:201701140148 - existing session from iqn.1994-05.com.redhat:573c3f4764bit appears that there is already login to this volume.  Does this information help you?Let me know!Standing by...Chris###Hello Andrew,As per the confirmation. We have restarted the server 10.59.10.148 and tried to mount the ISCSI volume on /var/Infobright but it does not get succeeded. We are getting an authorization error. Refer the below details,iscsiadm: Could not login to [iface: default, target: iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000016.2f1dab31, portal: 172.23.104.77,3260].iscsiadm: initiator reported error (24 - iSCSI login failed due to authorization failure)Here in this case, we are able to discover the available ISCSI volumes but not able mount it. Also, ISCSI service is not coming up properly.REAN Team is actively working on this case along with Andromeda Team to sort this issue at the earliest. Please validate these details and let us know if your team have any further queries.Regards,Sumod.K.Bose###Yes, can you try restart the network service to see if that will fix the problem? If not, yes please reboot the server. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com###Hello Team,We see that the device is busy when we try to remount as read/write.  We see the below process holding the directory.[root@10 centos]# ps -aux | grep /var/infobrightWarning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.8/FAQroot      18728  0.0  0.0 145016  1580 ?        S    Mar12   0:00 su mysql -s /bin/bash -c /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-148.ec2.internal.pid >/dev/null 2>&1mysql     18731  0.0  0.0 106072  1300 ?        Ss   Mar12   0:00 bash -c /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-148.ec2.internal.pid >/dev/null 2>&1mysql     18732  0.0  0.0 106076  1496 ?        S    Mar12   0:00 /bin/sh /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-148.ec2.internal.pidmysql     18864  0.0  0.0 335432 26424 ?        Sl   Mar12  28:37 /usr/local/infobright-4.9.0-x86_64/bin/mysqld --defaults-file=/etc/my-ib.cnf --basedir=/usr/local/infobright-4.9.0-x86_64 --datadir=/var/infobright/data --log-error=/var/infobright/data/iee-mysql.err --pid-file=/var/infobright/data/ip-10-59-10-148.ec2.internal.pid --socket=/tmp/mysql-ib.sock --port=5029Pleaze let us know whether we can kill the process or reboot the machine to fix the issue.###Hello Robert,We acknowledge the delivery of this mail.We are looking into this and we will get back to you with updates","Hello, On the server with the internal ip 10.59.10.148 the /var/infobright/memsql directory seems to have been changed to read only mode. Please correct this issue. Thanks,",Read Only Issue SpendHQ,,01-06-2017 22:04,136,0,SpendHQ,"Hello Team, As per our analysis we could see that at the point of incident the iscsi disk went offline and re discovered as /dev/sda, but  iscsi target was trying to remount as /dev/sdb.  May 31 10:30:12 ip-10-59-10-148 kernel: sd 13:0:0:0: rejecting I/O to offline device May 31 10:30:12 ip-10-59-10-148 kernel: Aborting journal on device sdb-8. May 31 10:30:12 ip-10-59-10-148 kernel: sd 13:0:0:0: rejecting I/O to offline device May 31 10:30:12 ip-10-59-10-148 kernel: JBD2: I/O error detected when updating journal superblock for sdb-8. May 31 10:30:22 ip-10-59-10-148 dd.collector[126719]: INFO (collector.py:530): Finished run #103070. Collection time: 4.07s. Emit time: 0.01s May 31 10:30:39 ip-10-59-10-148 dd.forwarder[126712]: INFO (transaction.py:177): Flushing 1 transaction during flush #689560 May 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs error (device sdb): ext4_journal_start_sb: Detected aborted journal May 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs (sdb): Remounting filesystem read-only May 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs (sdb): ext4_da_writepages: jbd2_start: 1024 pages, ino 132907033; err -30","++internal +++From the logs we can find out that the disk was offline May 31 10:30:12 ip-10-59-10-148 kernel: sd 13:0:0:0: rejecting I/O to offline deviceMay 31 10:30:12 ip-10-59-10-148 kernel: Aborting journal on device sdb-8.May 31 10:30:12 ip-10-59-10-148 kernel: sd 13:0:0:0: rejecting I/O to offline deviceMay 31 10:30:12 ip-10-59-10-148 kernel: JBD2: I/O error detected when updating journal superblock for sdb-8.May 31 10:30:22 ip-10-59-10-148 dd.collector[126719]: INFO (collector.py:530): Finished run #103070. Collection time: 4.07s. Emit time: 0.01sMay 31 10:30:39 ip-10-59-10-148 dd.forwarder[126712]: INFO (transaction.py:177): Flushing 1 transaction during flush #689560May 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs error (device sdb): ext4_journal_start_sb: Detected aborted journalMay 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs (sdb): Remounting filesystem read-onlyMay 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs (sdb): ext4_da_writepages: jbd2_start: 1024 pages, ino 132907033; err -30May 31 10:30:41 ip-10-59-10-148 kernel:",Errors detected in /var/log/messagesMay 31 10:30:12 ip-10-59-10-148 kernel: JBD2: I/O error detected when updating journal superblock for sdb-8.May 31 10:30:22 ip-10-59-10-148 dd.collector[126719]: INFO (collector.py:530): Finished run #103070. Collection time: 4.07s. Emit time: 0.01sMay 31 10:30:39 ip-10-59-10-148 dd.forwarder[126712]: INFO (transaction.py:177): Flushing 1 transaction during flush #689560May 31 10:30:41 ip-10-59-10-148 kernel: EXT4-fs error (device sdb): ext4_journal_start_sb: Detected aborted journalapart from this i couldn't find any errors in system logs.,Please find the document regarding iscsi volume details:https://docs.google.com/spreadsheets/d/171c0ZHcVEVbep-XqW2Ko8vsSVqVQrpSKHA0sTTJ8-rU/edit#gid=1821311068Also check messages log regarding directory  changed to read only mode,"10.59.10.12 lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:centos-vol-v777bb21358661922.00000003.2f1dab31-lun-0 -> ../../sdhlrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:centos-vol-v777bb21358661922.00000003.2f1dab31-lun-0-part1 -> ../../sdh1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-copy-04-26-17-v777bb21358661922.0000001c.2f1dab31-lun-0 -> ../../sdblrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-v777bb21358661922.00000009.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq011-11-16.data22.clone-v777bb21358661922.00000012.2f1dab31-lun-0 -> ../../sdilrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq011-11-16.data22.clone-v777bb21358661922.00000012.2f1dab31-lun-0-part1 -> ../../sdi1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq-11-11-16.data.clone-v777bb21358661922.00000011.2f1dab31-lun-0 -> ../../sdflrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq-11-11-16.data.clone-v777bb21358661922.00000011.2f1dab31-lun-0-part1 -> ../../sdf1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-10-15-16-testspq-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.0000406d-lun-0 -> ../../sdglrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-10-15-16-testspq-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.0000406d-lun-0-part1 -> ../../sdg1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-clone092016-sphqec2var-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003baf-lun-0 -> ../../sdelrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-clone092016-sphqec2var-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003baf-lun-0-part1 -> ../../sde1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-snap1-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003ba8-lun-0 -> ../../sdalrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-snap1-v777bb21358661922.00000002.2f1dab31.s777bb21358661922.00000002.00003ba8-lun-0-part1 -> ../../sda1lrwxrwxrwx 1 root root  9 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-v777bb21358661922.00000002.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root 10 May 31 15:38 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:sphqec2var-v777bb21358661922.00000002.2f1dab31-lun-0-part1 -> ../../sdd1 /dev/sdc        4.0T  2.5T  1.3T  67% /var/infobright Regards,-Praveen",10.59.10.135 lrwxrwxrwx 1 root root  9 May 31 18:45 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db-backup-02-02-17-v777bb21358661922.00000018.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 May 31 18:45 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db-backup-12-16-16.clone-v777bb21358661922.00000014.2f1dab31-lun-0 -> ../../sdalrwxrwxrwx 1 root root  9 May 31 18:45 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend4-copy-04-24-17-v777bb21358661922.0000001b.2f1dab31-lun-0 -> ../../sdb/dev/xvdf       2.0T  100G  1.8T   6% /mnt/drtest2016/dev/sdb        4.0T  2.3T  1.5T  61% /var/infobright/dev/sdc        4.0T  2.1T  1.8T  55% /mnt/db_backup-12-16-16/dev/sdb        4.0T  2.3T  1.5T  61% /mnt/db_backup_04_24_17/dev/sda        4.0T  1.6T  2.2T  43% /mnt/db_backup_02_02_2017 10.59.10.91 lrwxrwxrwx 1 root root  9 Jan  3 19:18 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000015.2f1dab31-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 Jan  3 19:28 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000016.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root  9 Jan 10 16:17 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:prod-backup-1-10-17-v777bb21358661922.00000017.2f1dab31-lun-0 -> ../../sdelrwxrwxrwx 1 root root  9 Nov  4  2016 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spend5-v777bb21358661922.0000000d.2f1dab31-lun-0 -> ../../sdalrwxrwxrwx 1 root root  9 Nov  7  2016 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:spendhq-db4-v777bb21358661922.00000010.2f1dab31-lun-0 -> ../../sdb/dev/sdb        1.5T   91G  1.4T   7% /var/infobright/dev/xvdf       2.0T  100G  1.8T   6% /mnt/drtest2016/dev/sdd        4.0T  1.6T  2.2T  43% /mnt/db5-backup/dev/sde        4.0T  1.6T  2.2T  43% /mnt/prod-backup-1-10-17 10.59.10.148 NoneTBC....,"Hello Rob, As far as knowledge, it would be difficult to get that info after the machine reboot. Here is the current iSCSI association details in each machine. @Matthew, please let us know if you know the device details by any chance and also let us know, if we can rebuild the database from any of the other DB iSCSI volumes or from backups. From our end, we will create an excel sheet to track each iSCSI volume lifecycle : create, associate, re-associate, mount not to arise such kind of issue in future.10.59.100.125 lrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-v777bb21358661922.00000008.2f1dab31-lun-0 -> ../../sddlrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shq1files01-shqsshot-12-14-16-v777bb21358661922.00000008.2f1dab31.s777bb21358661922.00000008.00004bf2-lun-0 -> ../../sdclrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shqfiles01a-v777bb21358661922.00000013.2f1dab31-lun-0 -> ../../sdelrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:shqsshot-12-14-16-v777bb21358661922.00000019.2f1dab31-lun-0 -> ../../sdalrwxrwxrwx 1 root root  9 May 31 15:25 ip-172.23.104.77:3260-iscsi-iqn.2007-11.com.nimblestorage:3-11-17-shqfiles01-v777bb21358661922.0000001a.2f1dab31-lun-0 -> ../../sdb /dev/sdb        2.0T  1.3T  630G  68% /var/www/vhosts/files.spendhq.comTBC...","Unfortunately, I have no clue. Based on the root users history I would say 172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend5-v777bb21358661922.0000000d.2f1dab31. Is there some kind of log of what was mounted previously?  Matthew, Do you have any idea which one was mounted before?    Robert Little | Spend Solutions DBA | SpendHQ®O: 770-628-0898 | rlittle@spendhq.comA SaaS Spend Visibility solution from Insight Sourcing Groupwww.spendhq.com | www.insightsourcing.com","Hello Rob, Can you please help us which iSCSI device needs a mount to the 148 machine. 172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:db-backup-02-02-17-v777bb21358661922.00000018.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:db-backup-12-16-16.clone-v777bb21358661922.00000014.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000016.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend4-v777bb21358661922.00000009.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend4-copy-04-24-17-v777bb21358661922.0000001b.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend5-v777bb21358661922.0000000d.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spendhq-db4-v777bb21358661922.00000010.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:prod-backup-1-10-17-v777bb21358661922.00000017.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend4-copy-04-26-17-v777bb21358661922.0000001c.2f1dab31172.23.104.77:3260,2460 iqn.2007-11.com.nimblestorage:spend4-prod-backup-1-10-17-v777bb21358661922.00000009.2f1dab31.s777bb21358661922.00000009.00005121  Regards,-Praveen",This ticket has been escalated to on call CE2. I have tried to log in to all of the available ISCSI volumes on the DB Server 03 instance but was failed to do so. Chris from Andromeda team informed that this issue occurs when they are already login to other servers. Need to resolve this issue at the earliest.,Hi REAN -Here is the eerror message being generated on the storage end:SCSI login to volume iqn.2007-11.com.nimblestorage:spend4-copy-04-26-17-v777bb21358661922.0000001c.2f1dab31 rejected from iqn.1994-05.com.redhat:201701140148 - existing session from iqn.1994-05.com.redhat:573c3f4764bit appears that there is already login to this volume.  Does this information help you?Let me know!Standing by...Chris,"Hello Andrew,As per the confirmation. We have restarted the server 10.59.10.148 and tried to mount the ISCSI volume on /var/Infobright but it does not get succeeded. We are getting an authorization error. Refer the below details,iscsiadm: Could not login to [iface: default, target: iqn.2007-11.com.nimblestorage:db5-backup-v777bb21358661922.00000016.2f1dab31, portal: 172.23.104.77,3260].iscsiadm: initiator reported error (24 - iSCSI login failed due to authorization failure)Here in this case, we are able to discover the available ISCSI volumes but not able mount it. Also, ISCSI service is not coming up properly.REAN Team is actively working on this case along with Andromeda Team to sort this issue at the earliest. Please validate these details and let us know if your team have any further queries.Regards,Sumod.K.Bose","Yes, can you try restart the network service to see if that will fix the problem? If not, yes please reboot the server. Thank you, Andrew Kim | Director of Information Technology & Security | SpendHQ®O: 770.481.3021 | C: 404.668.6738 | akim@spendhq.com","Hello Team,We see that the device is busy when we try to remount as read/write.  We see the below process holding the directory.[root@10 centos]# ps -aux | grep /var/infobrightWarning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.8/FAQroot      18728  0.0  0.0 145016  1580 ?        S    Mar12   0:00 su mysql -s /bin/bash -c /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-148.ec2.internal.pid >/dev/null 2>&1mysql     18731  0.0  0.0 106072  1300 ?        Ss   Mar12   0:00 bash -c /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-148.ec2.internal.pid >/dev/null 2>&1mysql     18732  0.0  0.0 106076  1496 ?        S    Mar12   0:00 /bin/sh /usr/local/infobright-4.9.0-x86_64/bin/mysqld_safe --defaults-file=/etc/my-ib.cnf --user=mysql --pid-file=/var/infobright/data/ip-10-59-10-148.ec2.internal.pidmysql     18864  0.0  0.0 335432 26424 ?        Sl   Mar12  28:37 /usr/local/infobright-4.9.0-x86_64/bin/mysqld --defaults-file=/etc/my-ib.cnf --basedir=/usr/local/infobright-4.9.0-x86_64 --datadir=/var/infobright/data --log-error=/var/infobright/data/iee-mysql.err --pid-file=/var/infobright/data/ip-10-59-10-148.ec2.internal.pid --socket=/tmp/mysql-ib.sock --port=5029Pleaze let us know whether we can kill the process or reboot the machine to fix the issue.","Hello Robert,We acknowledge the delivery of this mail.We are looking into this and we will get back to you with updates",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001DngR7,Cloud Engineer Level 1,Closed,1065547,Incident,29-06-2017 06:19,,"Hi Team, This is to inform you that volume usage alert for PROD-SPHQ-DB-SERVER05 instance got resolved and returned to a normal value of 67.6%. The violation has lasted for 1 hour and 50 minutes.###Hello SpendHQ-Team,This is to inform you that the volume usage for PROD-SPHQ-DB-SERVER05 instance is still in open state and has reached 98%. Please delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.###Hi Team, On further analysis, we were able to figure out that the device /dev/xvda1 volume mounted on root is consuming high volume usage on this instance. Please find the disk usage details. usage on /tmp : 12G	total1.8G 	liger_view_a065ddb249e79cfe77b8b7693bb00d53.csv1.7G 	liger_view_b2d9ac0912a0f5bc3b105ea07cf73eb3.csv1.2G	        liger_view_f4f5915af84661e569b9bc6a20702fcb.csv1.2G 	liger_view_b308fa5f5fda550b714cad4d72fca7de.csv1.2G 	liger_view_304b3103c7b7b3a51526b509a772f5ca.csv968M	liger_view_ff0c544362bd7fa2335d0ad79ed6ab0e.csv922M	liger_view_04e5451513d153c57e6cf6384d081253.csv511M	liger_view_b15d30d91bd8abb03bb275da2db8dbb2.csv412M	liger_view_943ef6f4f72be240b2622fcfa122d988.csvusage on /usr : 18G  	total16G	        local882M	share813M	lib130M	lib64Delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.###Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 93.7%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924","[Triggered] [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135  High Disk Usage detected on the device /dev/xvda1     @support@reancloud.com`avg(last_5m):avg:system.disk.in_use{monitoring:on} by {host,device} * 100 > 90`Metric value: 90.567This alert was raised by account SpendHQMonitor Status: https://app.datadoghq.com/monitors#2023969?group=device%3A%2Fdev%2Fxvda1%2Chost%3A10.59.10.135 · Edit Monitor: https://app.datadoghq.com/monitors#2023969/edit · Event URL: https://app.datadoghq.com/event/event?id=3932813012229954992 · View 10.59.10.135: https://app.datadoghq.com/infrastructure?hostname=10.59.10.135-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",[Monitor Alert] Triggered: [SpendHQ] - EBS High Disk Usage ( /dev/xvda1 ) - prod-sphq-db-server05 - 10.59.10.135,,29-06-2017 00:36,6,0,SpendHQ,"Hi Team, This is to inform you that volume usage alert for PROD-SPHQ-DB-SERVER05 instance got resolved and returned to a normal value of 67.6%. The violation has lasted for 1 hour and 50 minutes.","Hello SpendHQ-Team,This is to inform you that the volume usage for PROD-SPHQ-DB-SERVER05 instance is still in open state and has reached 98%. Please delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.","Hi Team, On further analysis, we were able to figure out that the device /dev/xvda1 volume mounted on root is consuming high volume usage on this instance. Please find the disk usage details. usage on /tmp : 12G	total1.8G 	liger_view_a065ddb249e79cfe77b8b7693bb00d53.csv1.7G 	liger_view_b2d9ac0912a0f5bc3b105ea07cf73eb3.csv1.2G	        liger_view_f4f5915af84661e569b9bc6a20702fcb.csv1.2G 	liger_view_b308fa5f5fda550b714cad4d72fca7de.csv1.2G 	liger_view_304b3103c7b7b3a51526b509a772f5ca.csv968M	liger_view_ff0c544362bd7fa2335d0ad79ed6ab0e.csv922M	liger_view_04e5451513d153c57e6cf6384d081253.csv511M	liger_view_b15d30d91bd8abb03bb275da2db8dbb2.csv412M	liger_view_943ef6f4f72be240b2622fcfa122d988.csvusage on /usr : 18G  	total16G	        local882M	share813M	lib130M	lib64Delete/zip unwanted files or folders to reduce the current volume usage state in this instance and let us know if your team have any further queries regarding this case.","Hi SpendHQ-Team, This is to notify you that we have received an alert that volume usage for PROD-SPHQ-DB-SERVER05 instance has exceeded a threshold value of 90% to 93.7%. We are investigating the alert and we will keep you posted on the progress. Resource Details Instance Name : PROD-SPHQ-DB-SERVER05 Instance ID : i-008d43ad00357e47a Instance Private IP Address : 10.59.10.135 Instance Availability Zone : us-east-1b Instance Type : r3.8xlarge VPC ID : vpc-76df7212 Subnet ID : subnet-0fdde924",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001BYvdE,Cloud Engineer Level 1,Closed,1051577,Incident,06-05-2017 13:38,,"Hello Allen,We haven't heard back from you.At this time we are marking this case as resolved. However, if you have any further queries regarding this we want to hear back from you. For continuous support please feel free to reach out to us anytime.###Hello Allen,We haven't heard back from you.Please let us know if you need any further information regarding this.###Hello Allen,We have verified today's logs and we couldn't find any mod sec rules which are blocking the requests. Please refer the attached logs below.After analysing the yesterday's logs we could see below log entry which the web application firewall has blocked access to https://preview.spendhq.com/spend-visibility2017:05:03-14:47:30 spendhq reverseproxy: [Wed May 03 14:47:30.272229 2017] [cookie:error] [pid 2351:tid 3953462128] [client 10.59.1.167:34534] No signature found, cookie: __utmc, referer: https://preview.spendhq.com/spend-visibilityPlease let us know whether we need to add this folder(spend-visibility) as an exception in firewall profile.###Allen Herrera <aherrera@insightsourcing.com>12:33 AM (4 hours ago)to Akhil, Steven, Darren, Dusty, Matthew, REAN 981200 should already be added to our skiplist ? Don’t we have an shq profile of custom mod sec rules skiplisted. I spent a week on this a couple months ago. Why do we have, and what is this Advanced protection profile ??? These were the rules included in that. Rule IDMessage981319SQL Injection Attack: SQL Operator Detected981173Restricted SQL Character Anomaly Detection Alert – Total # of special characters exceeded981176Inbound Anomaly Score Exceeded (18)981204Inbound Anomaly Score Exceeded(18)950109Multiple URL Encoding981203Inbound Anomaly Score (2)960015Request Missing an Accept Header970003SQL Information Leakage981200Outbound Anomaly Score Exceeded (4)981172Restricted SQL Character Anomaly Detection Alert – Total # of special characters exceeded981001Possibly malicious iframe tag in output950901SQL Injection Attack: SQL Tautology Detected.981245Detects basic SQL authentication bypass attempts 2/3981257Detects MySQL comment-/space-obfuscated injections and backtick termination981318SQL Injection Attack: Common Injection Testing Detected960024Meta-Character Anomaly Detection Alert – Repetative Non-Word Characters973347IE XSS Filters – Attack Detected   Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group###Hello Allen,There were two rules(981172 and 981200) missing in the skip-listed rules in the SpendHQ Protection firewall profile. We have added those now.The Advanced Protection profile was created a few months back while we enabled WAF for the Preview website and that has been reverted at that time itself and from then, this profile is not in use. Please let us know if you have further queries regarding this.###Allen Herrera <aherrera@insightsourcing.com>11:10 PM (5 hours ago)to Darren, Dusty, Matthew, Steven, Rean Any update? We can’t begin development on preview without this resolved. I need feedback on this asap to continue troubleshooting. Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group From: Steven Ng Sent: Wednesday, May 3, 2017 12:07 PMTo: 'Rean Support' <support@reancloud.com>Cc: Allen Herrera <aherrera@insightsourcing.com>Subject: WAF on preview.spendhq.com###Hello Allen,We have analyzed the logs this issue occurs due to the protection measures of WAF. Please see the below error and attached log file for more details.2017:05:03-15:58:44 spendhq reverseproxy: [Wed May 03 15:58:44.870874 2017] [security2:error] [pid 3658:tid 3936676720] [client 10.59.1.167] ModSecurity: Access denied with code 403 (phase 4). Pattern match (.*) at TX:970014-OWASP_CRS/LEAKAGE/SOURCE_CODE-RESPONSE_BODY. [file /usr/apache/conf/waf/modsecurity_crs_outbound_blocking.conf] [line 24] [id 981200] [msg Outbound Anomaly Score Exceeded (score 8): Last Matched Message: IIS Information Leakage] [data Last Matched Data: javax.servlet] [hostname preview-spendhq-xelb-520312558.us-east-1.elb.amazonaws.com] [uri /spend-visibility] [unique_id WQn@Lwo7AcAAAA5K2a4AAABJ]Advanced protection profile has rules, it will reject all the contents that can not be scanned. From the logs, we can see error related to Cookie Signing which gets rejected.Let us know if you want us to make exceptions to skip Filter Rules. Please let us know if you have any queries.###Hello Steven,WAF is enabled on preview.spendhq.com. We will analyse the logs and will get back to you with updates.","REAN,Can you advise us if the WAF is on for the domain at preview.spendhq.com?If it is on can you provide log information on why we are getting forbidden errors. See the attached screenshots[cid:image001.jpg@01D2C405.B457CFE0]Steven Ng | Full Stack Developer | SpendHQ(r)O: 770-628-0692 | sng@spendhq.com<mailto:sng@spendhq.com>www.spendhq.com<http://www.spendhq.com/> | A SaaS Spend Visibility solution from Insight Sourcing Group-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",WAF on preview.spendhq.com,,03-05-2017 21:36,64,0,SpendHQ,"Hello Allen,We haven't heard back from you.At this time we are marking this case as resolved. However, if you have any further queries regarding this we want to hear back from you. For continuous support please feel free to reach out to us anytime.","Hello Allen,We haven't heard back from you.Please let us know if you need any further information regarding this.","Hello Allen,We have verified today's logs and we couldn't find any mod sec rules which are blocking the requests. Please refer the attached logs below.After analysing the yesterday's logs we could see below log entry which the web application firewall has blocked access to https://preview.spendhq.com/spend-visibility2017:05:03-14:47:30 spendhq reverseproxy: [Wed May 03 14:47:30.272229 2017] [cookie:error] [pid 2351:tid 3953462128] [client 10.59.1.167:34534] No signature found, cookie: __utmc, referer: https://preview.spendhq.com/spend-visibilityPlease let us know whether we need to add this folder(spend-visibility) as an exception in firewall profile.","Allen Herrera <aherrera@insightsourcing.com>12:33 AM (4 hours ago)to Akhil, Steven, Darren, Dusty, Matthew, REAN 981200 should already be added to our skiplist ? Don’t we have an shq profile of custom mod sec rules skiplisted. I spent a week on this a couple months ago. Why do we have, and what is this Advanced protection profile ??? These were the rules included in that. Rule IDMessage981319SQL Injection Attack: SQL Operator Detected981173Restricted SQL Character Anomaly Detection Alert – Total # of special characters exceeded981176Inbound Anomaly Score Exceeded (18)981204Inbound Anomaly Score Exceeded(18)950109Multiple URL Encoding981203Inbound Anomaly Score (2)960015Request Missing an Accept Header970003SQL Information Leakage981200Outbound Anomaly Score Exceeded (4)981172Restricted SQL Character Anomaly Detection Alert – Total # of special characters exceeded981001Possibly malicious iframe tag in output950901SQL Injection Attack: SQL Tautology Detected.981245Detects basic SQL authentication bypass attempts 2/3981257Detects MySQL comment-/space-obfuscated injections and backtick termination981318SQL Injection Attack: Common Injection Testing Detected960024Meta-Character Anomaly Detection Alert – Repetative Non-Word Characters973347IE XSS Filters – Attack Detected   Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group","Hello Allen,There were two rules(981172 and 981200) missing in the skip-listed rules in the SpendHQ Protection firewall profile. We have added those now.The Advanced Protection profile was created a few months back while we enabled WAF for the Preview website and that has been reverted at that time itself and from then, this profile is not in use. Please let us know if you have further queries regarding this.","Allen Herrera <aherrera@insightsourcing.com>11:10 PM (5 hours ago)to Darren, Dusty, Matthew, Steven, Rean Any update? We can’t begin development on preview without this resolved. I need feedback on this asap to continue troubleshooting. Allen Herrera | Developer | SpendHQ®M: 360-888-3938 | aherrera@spendhq.comwww.spendhq.com | A SaaS Spend Visibility solution from Insight Sourcing Group From: Steven Ng Sent: Wednesday, May 3, 2017 12:07 PMTo: 'Rean Support' <support@reancloud.com>Cc: Allen Herrera <aherrera@insightsourcing.com>Subject: WAF on preview.spendhq.com","Hello Allen,We have analyzed the logs this issue occurs due to the protection measures of WAF. Please see the below error and attached log file for more details.2017:05:03-15:58:44 spendhq reverseproxy: [Wed May 03 15:58:44.870874 2017] [security2:error] [pid 3658:tid 3936676720] [client 10.59.1.167] ModSecurity: Access denied with code 403 (phase 4). Pattern match (.*) at TX:970014-OWASP_CRS/LEAKAGE/SOURCE_CODE-RESPONSE_BODY. [file /usr/apache/conf/waf/modsecurity_crs_outbound_blocking.conf] [line 24] [id 981200] [msg Outbound Anomaly Score Exceeded (score 8): Last Matched Message: IIS Information Leakage] [data Last Matched Data: javax.servlet] [hostname preview-spendhq-xelb-520312558.us-east-1.elb.amazonaws.com] [uri /spend-visibility] [unique_id WQn@Lwo7AcAAAA5K2a4AAABJ]Advanced protection profile has rules, it will reject all the contents that can not be scanned. From the logs, we can see error related to Cookie Signing which gets rejected.Let us know if you want us to make exceptions to skip Filter Rules. Please let us know if you have any queries.","Hello Steven,WAF is enabled on preview.spendhq.com. We will analyse the logs and will get back to you with updates.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5000G00001GHK4Q,Cloud Engineer Level 1,Closed,1073909,Incident,24-08-2017 09:24,,"Yogesh will be tracking the dashboard setup in Jira hence closing the case.###I have created a separate monitor for 10.59.10.135 with 90% alert threshold and 80% warning threshold with 1 minute period so we will get notified as soon as we witness high CPU spike on the node.Next Action: Morning Shift: Follow up with Yogesh for the status of the Dashboard suggested by Praveen.###Hello Matthew, We haven't heard back from you regarding the case for a while. Please review the shared RCA document and provide your feedback for the same. Please let us know if you have any queries regarding this. Thank You, Safuvan KM###Decrease the DD CPU threshold to 1 minute.Create a new dashboard with ELB, DB and Apache matrices.Praveen will review once these details are ready.###We have completed the RCA document for the SpendHQ outage and the document has attached with the ticket. Please review the RCA and let us know if you have any queries regarding this.Thank You,Safuvan KM###RCA is completed regarding the recommendation part need to be further discussed with client. Check with Yogesh regarding RCAhttps://docs.google.com/document/d/1jW-XNpTOGZxpRgWSfNJfFTp2p5v-M-y5t2fxksjR9hI/edit####We have completed the RCA. Need to review the RCA by CC/CE2 and share it with customerRCA:  https://docs.google.com/document/d/1jW-XNpTOGZxpRgWSfNJfFTp2p5v-M-y5t2fxksjR9hI/edit####we are already started preparing the RCA https://docs.google.com/document/d/1jW-XNpTOGZxpRgWSfNJfFTp2p5v-M-y5t2fxksjR9hI/edit#Will complete the RCA and will provide to Yogesh for review.we will complete the RCA shortly.###As discussed with Yogesh, we have started creating RCA.###When this same incident occurred last time, we had the similar root cause analysis so the recommendations. We didn't receive any confirmation from the customer for the RCA on that occation. Further more, SpendHQ has made the changes to point the prod application to the same backend resources for the dev application and the DB instance that witnessed the high load so lead to the outage is not in use after the change, we require a response from the customer about the last change and if that is a persisting change or not, before recommending the DB instance type upgrade recommendation again.Next Action: Morning Shift: Talk to the Customer Champion to talk to the customer about the change so to decide with the recommendation.###Hello SpendHQ-Team,Did you get a chance to review the analysis performed for the outage happened on the secure.spendhq.com URL on 19th August 2017?As informed, the outage has happened due to the high CPU load on the backend database server(10.59.10.135).The CPU usage has reached a value of 100%. The Network IN has gone above with a value of 6000MB/min. The Network Out has gone above the value of 8000MB/min. At the time of the alert, 140 connections were in the closed wait state,609 in Time wait for state and 316 were in Established state. TIME_WAIT state occurred due to connections are not getting properly closed.The database server was not able to serve all the webserver request which caused the site down issue. As a part of the Release that has been performed on 19th August 2017 at 18 EST, we have pointed Secure ELB to the DNS of NewPreview-ELB(Internal ELB) at the WAF layer in Sophos. Hence, all of the requests coming for secure and preview are getting served with the same load balancer. Here, we could see that i-0ace70ce06368e4a7(PRD-WW1) and i-01ac95c23ac66a40e(PRD-WW2) are the registered instances under the NewPreview-ELB. The backend database configured for both of this instances is i-03ccfddd9f02cacb9(PRD-DB1). Hence, the Secure environment has been entirely changed to a new one after the recent Release. Let us know if there are any new changes planning for the current secure configuration.Kindly validate these details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose###Hello Team,On further investigation, we were able to figure out the below details.We have analyzed the ELB logs at the time of the incident and found many requests with 502 response code specifying bad gateway error because the backend server became unreachable. This resulted in high backend response time for requests causing the latency. The monitoring tool Wormly also reported operation timed out. Please review the attached logs.From the web-server level, every metrics seemed to be normal and there abnormal activity. The backend database server experienced a spike in CPU, Network IN/OUT. The CPU usage has reached a value of 100%. The Network IN has gone above value of 6000MB/min. The Network Out has gone above the value of 8000MB/min. Please refer the attachment for metrics details.We have analyzed the direct connect metrics and we could see spike in ConnectionBpsEgress, ConnectionBpsIngress, ConnectionPpsEgress, and ConnectionPpsIngress metrics. At the time of the alert, 140 were in the closed wait state,609 in Time wait for state and 316 were in Established state.TIME_WAIT state occurred due to connections are not getting properly closed.The database server was not able to serve all the web-server request which caused the site down issue.Let us know if you have any further queries.###Need to analyze further and inform client###Hello Matthew,We are currently investigating further on this. We will get back to you with more details.###I have verified the app and all seems well. Can we investigate and provide further details. Sent from my iPhoneMatthew Watts###Hello Team,This is to inform you that we have again received a site down for the URL https://secure.spendhq.com/login. The alert got recovered within 2 minutes and the site is well accessible now. We analysing this from our end and will revert back to you with further updates.###We are not performing any activities on our end Sent from my iPhoneMatthew Watts###Hello Team,On further analysis from the instance 10.59.100.170, we could see that there were total 1170 active connections during the time of alert out of which 140 were in the closed wait state,609 in Time wait for state and 316 were in Established state. Please see the details below[root@ip-10-59-100-170 httpd]# netstat | wc -l1170[root@ip-10-59-100-170 httpd]# netstat | grep CLOSE_WAIT | wc -l140[root@ip-10-59-100-170 httpd]# netstat | grep TIME_WAIT | wc -l609[root@ip-10-59-100-170 httpd]# netstat | grep ESTABLISHED | wc -l316The ELB was experiencing high latency, 5xx response code for the request and also high CPU Load of the backend database instance( 10.59.10.135). The CPU usage on this backend instance was at 100% at the time of alerts and also we could a high spike in Network IN and OUT for the DB instance. Please see the attached screen shot for the details.Please let us know whether you are performing any activities from your end.###Hello Team, This is to notify you that we have received a site down alerts for URL: https://secure.spendhq.com/login. The alert got recovered within 4 minutes and the site is well accessible now. We will analyze the issue from our end and meanwhile please let us know if your team has performed any activity from your end.","Sat, 19 Aug 2017 09:11:39 -0400Detected Error on SpendHQEstimated Downtime: 1 minute https://www.wormly.com/edithost/hostid/50743--------------------Sensor Failure: HTTP--------------------Sensor reported error:Operation timed out after 30001 milliseconds with 0 bytes receivedSensor parameters:url: https://secure.spendhq.com/loginexpect: 200wantedstring: All Rights Reservedunwantedstring: ForbiddenReported by node: New Jersey USConfirmed by node(s): Atlanta-B US, London UK, California US, Sydney-C AU-- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",Detected Error on SpendHQ,,19-08-2017 18:41,111,0,SpendHQ,Yogesh will be tracking the dashboard setup in Jira hence closing the case.,I have created a separate monitor for 10.59.10.135 with 90% alert threshold and 80% warning threshold with 1 minute period so we will get notified as soon as we witness high CPU spike on the node.Next Action: Morning Shift: Follow up with Yogesh for the status of the Dashboard suggested by Praveen.,"Hello Matthew, We haven't heard back from you regarding the case for a while. Please review the shared RCA document and provide your feedback for the same. Please let us know if you have any queries regarding this. Thank You, Safuvan KM","Decrease the DD CPU threshold to 1 minute.Create a new dashboard with ELB, DB and Apache matrices.Praveen will review once these details are ready.","We have completed the RCA document for the SpendHQ outage and the document has attached with the ticket. Please review the RCA and let us know if you have any queries regarding this.Thank You,Safuvan KM",RCA is completed regarding the recommendation part need to be further discussed with client. Check with Yogesh regarding RCAhttps://docs.google.com/document/d/1jW-XNpTOGZxpRgWSfNJfFTp2p5v-M-y5t2fxksjR9hI/edit,#We have completed the RCA. Need to review the RCA by CC/CE2 and share it with customerRCA:  https://docs.google.com/document/d/1jW-XNpTOGZxpRgWSfNJfFTp2p5v-M-y5t2fxksjR9hI/edit,#we are already started preparing the RCA https://docs.google.com/document/d/1jW-XNpTOGZxpRgWSfNJfFTp2p5v-M-y5t2fxksjR9hI/edit#Will complete the RCA and will provide to Yogesh for review.we will complete the RCA shortly.,"As discussed with Yogesh, we have started creating RCA.","When this same incident occurred last time, we had the similar root cause analysis so the recommendations. We didn't receive any confirmation from the customer for the RCA on that occation. Further more, SpendHQ has made the changes to point the prod application to the same backend resources for the dev application and the DB instance that witnessed the high load so lead to the outage is not in use after the change, we require a response from the customer about the last change and if that is a persisting change or not, before recommending the DB instance type upgrade recommendation again.Next Action: Morning Shift: Talk to the Customer Champion to talk to the customer about the change so to decide with the recommendation.","Hello SpendHQ-Team,Did you get a chance to review the analysis performed for the outage happened on the secure.spendhq.com URL on 19th August 2017?As informed, the outage has happened due to the high CPU load on the backend database server(10.59.10.135).The CPU usage has reached a value of 100%. The Network IN has gone above with a value of 6000MB/min. The Network Out has gone above the value of 8000MB/min. At the time of the alert, 140 connections were in the closed wait state,609 in Time wait for state and 316 were in Established state. TIME_WAIT state occurred due to connections are not getting properly closed.The database server was not able to serve all the webserver request which caused the site down issue. As a part of the Release that has been performed on 19th August 2017 at 18 EST, we have pointed Secure ELB to the DNS of NewPreview-ELB(Internal ELB) at the WAF layer in Sophos. Hence, all of the requests coming for secure and preview are getting served with the same load balancer. Here, we could see that i-0ace70ce06368e4a7(PRD-WW1) and i-01ac95c23ac66a40e(PRD-WW2) are the registered instances under the NewPreview-ELB. The backend database configured for both of this instances is i-03ccfddd9f02cacb9(PRD-DB1). Hence, the Secure environment has been entirely changed to a new one after the recent Release. Let us know if there are any new changes planning for the current secure configuration.Kindly validate these details and let us know if your team have any further queries regarding this case.Regards,Sumod.K.Bose","Hello Team,On further investigation, we were able to figure out the below details.We have analyzed the ELB logs at the time of the incident and found many requests with 502 response code specifying bad gateway error because the backend server became unreachable. This resulted in high backend response time for requests causing the latency. The monitoring tool Wormly also reported operation timed out. Please review the attached logs.From the web-server level, every metrics seemed to be normal and there abnormal activity. The backend database server experienced a spike in CPU, Network IN/OUT. The CPU usage has reached a value of 100%. The Network IN has gone above value of 6000MB/min. The Network Out has gone above the value of 8000MB/min. Please refer the attachment for metrics details.We have analyzed the direct connect metrics and we could see spike in ConnectionBpsEgress, ConnectionBpsIngress, ConnectionPpsEgress, and ConnectionPpsIngress metrics. At the time of the alert, 140 were in the closed wait state,609 in Time wait for state and 316 were in Established state.TIME_WAIT state occurred due to connections are not getting properly closed.The database server was not able to serve all the web-server request which caused the site down issue.Let us know if you have any further queries.",Need to analyze further and inform client,"Hello Matthew,We are currently investigating further on this. We will get back to you with more details.",I have verified the app and all seems well. Can we investigate and provide further details. Sent from my iPhoneMatthew Watts,"Hello Team,This is to inform you that we have again received a site down for the URL https://secure.spendhq.com/login. The alert got recovered within 2 minutes and the site is well accessible now. We analysing this from our end and will revert back to you with further updates.",We are not performing any activities on our end Sent from my iPhoneMatthew Watts,"Hello Team,On further analysis from the instance 10.59.100.170, we could see that there were total 1170 active connections during the time of alert out of which 140 were in the closed wait state,609 in Time wait for state and 316 were in Established state. Please see the details below[root@ip-10-59-100-170 httpd]# netstat | wc -l1170[root@ip-10-59-100-170 httpd]# netstat | grep CLOSE_WAIT | wc -l140[root@ip-10-59-100-170 httpd]# netstat | grep TIME_WAIT | wc -l609[root@ip-10-59-100-170 httpd]# netstat | grep ESTABLISHED | wc -l316The ELB was experiencing high latency, 5xx response code for the request and also high CPU Load of the backend database instance( 10.59.10.135). The CPU usage on this backend instance was at 100% at the time of alerts and also we could a high spike in Network IN and OUT for the DB instance. Please see the attached screen shot for the details.Please let us know whether you are performing any activities from your end.","Hello Team, This is to notify you that we have received a site down alerts for URL: https://secure.spendhq.com/login. The alert got recovered within 4 minutes and the site is well accessible now. We will analyze the issue from our end and meanwhile please let us know if your team has performed any activity from your end.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hQUJv,Cloud Engineer Level 1,Closed,1110111,Incident,06-01-2019 08:43,,"Hi Matthew,We have created a change ticket #	01110322	 to perform this stop/start activity to complete instance retirement.Please verify the instance functionality from your end and update us on the same ticket.As of now, we are marking this incident ticket closed.###Hello Matthew,We have performed stop/start on matt_SHQ_m5.large_01 (i-01998ce82253d4012) and server is up now. Both 2/2 status check got passed.Please verify it from your end and confirm us. Feel free to reach us if you have any queries.###Hello Matthew,Thanks for the update.We are going to perform this action now to stop/start the server and will let you know once it has done.Thank you,###From Matthew:This can be done now.###Hello Matthew,Thank you for the update. Can you please confirm the time frame when we can perform stop and start on the server or let us know if we can perform now.###From MatthewYes please###Hello Team,This is a quick follow up  to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012 Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43Regards###Hello Team,This is a quick follow up, we recently received a notification from AWS stating that there is a degradation of the underlying hardware hosting one of your instances.The instance matt_SHQ_m5.large_01 is the instance in question and we recommend performing a stop and start on this machine to resolve the issue.Thanks.###Hello Team, We haven't heard back from you.This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012 Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43###Hello Team, This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43","EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped.\\n \\nYou can see more information on your instances that are scheduled for retirement in the AWS Management Console (https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Events)\\n \\n* How does this affect you?\\n \\nYour instance will be stopped after the specified retirement date, but you can start it again at any time. Note that if you have EC2 instance store volumes attached to the instance, any data on these volumes will be lost when the instance is stopped or terminated as these volumes are physically attached to the host computer\\n \\n* What do you need to do?\\n \\nYou can wait for the scheduled retirement date - when the instance is stopped - or stop the instance yourself any time before then. Once the instances has been stopped, you can start the instance again at any time. For more information about stopping and starting your instance, and what to expect when your instance is stopped, such as the effect on public, private and Elastic IP addresses associated with your instance, see Stop and Start Your Instance in the EC2 User Guide (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html).\\n \\n* Why retirement?\\n \\nAWS may schedule instances for retirement in cases where there is an unrecoverable issue with the underlying hardware. For more information about scheduled retirement events please see the EC2 user guide (http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-retirement.html).\\n \\nIf you have any questions or concerns, you can contact the AWS Support Team on the community forums and via AWS Premium Support at: http://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_EC2_PERSISTENT_INSTANCE_RETIREMENT_SCHEDULED,,02-01-2019 05:48,99,0,SpendHQ,"Hi Matthew,We have created a change ticket #	01110322	 to perform this stop/start activity to complete instance retirement.Please verify the instance functionality from your end and update us on the same ticket.As of now, we are marking this incident ticket closed.","Hello Matthew,We have performed stop/start on matt_SHQ_m5.large_01 (i-01998ce82253d4012) and server is up now. Both 2/2 status check got passed.Please verify it from your end and confirm us. Feel free to reach us if you have any queries.","Hello Matthew,Thanks for the update.We are going to perform this action now to stop/start the server and will let you know once it has done.Thank you,",From Matthew:This can be done now.,"Hello Matthew,Thank you for the update. Can you please confirm the time frame when we can perform stop and start on the server or let us know if we can perform now.",From MatthewYes please,"Hello Team,This is a quick follow up  to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012 Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43Regards","Hello Team,This is a quick follow up, we recently received a notification from AWS stating that there is a degradation of the underlying hardware hosting one of your instances.The instance matt_SHQ_m5.large_01 is the instance in question and we recommend performing a stop and start on this machine to resolve the issue.Thanks.","Hello Team, We haven't heard back from you.This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012 Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43","Hello Team, This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0
5002I00001hQUJv,Cloud Engineer Level 1,Closed,1110111,Incident,06-01-2019 08:43,,"Hi Matthew,We have created a change ticket #	01110322	 to perform this stop/start activity to complete instance retirement.Please verify the instance functionality from your end and update us on the same ticket.As of now, we are marking this incident ticket closed.###Hello Matthew,We have performed stop/start on matt_SHQ_m5.large_01 (i-01998ce82253d4012) and server is up now. Both 2/2 status check got passed.Please verify it from your end and confirm us. Feel free to reach us if you have any queries.###Hello Matthew,Thanks for the update.We are going to perform this action now to stop/start the server and will let you know once it has done.Thank you,###From Matthew:This can be done now.###Hello Matthew,Thank you for the update. Can you please confirm the time frame when we can perform stop and start on the server or let us know if we can perform now.###From MatthewYes please###Hello Team,This is a quick follow up  to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012 Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43Regards###Hello Team,This is a quick follow up, we recently received a notification from AWS stating that there is a degradation of the underlying hardware hosting one of your instances.The instance matt_SHQ_m5.large_01 is the instance in question and we recommend performing a stop and start on this machine to resolve the issue.Thanks.###Hello Team, We haven't heard back from you.This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012 Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43###Hello Team, This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43","EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped.\\n \\nYou can see more information on your instances that are scheduled for retirement in the AWS Management Console (https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Events)\\n \\n* How does this affect you?\\n \\nYour instance will be stopped after the specified retirement date, but you can start it again at any time. Note that if you have EC2 instance store volumes attached to the instance, any data on these volumes will be lost when the instance is stopped or terminated as these volumes are physically attached to the host computer\\n \\n* What do you need to do?\\n \\nYou can wait for the scheduled retirement date - when the instance is stopped - or stop the instance yourself any time before then. Once the instances has been stopped, you can start the instance again at any time. For more information about stopping and starting your instance, and what to expect when your instance is stopped, such as the effect on public, private and Elastic IP addresses associated with your instance, see Stop and Start Your Instance in the EC2 User Guide (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html).\\n \\n* Why retirement?\\n \\nAWS may schedule instances for retirement in cases where there is an unrecoverable issue with the underlying hardware. For more information about scheduled retirement events please see the EC2 user guide (http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-retirement.html).\\n \\nIf you have any questions or concerns, you can contact the AWS Support Team on the community forums and via AWS Premium Support at: http://aws.amazon.com/support For more details, please see https://phd.aws.amazon.com/phd/home?region=us-east-1#/dashboard/open-issues--If you wish to stop receiving notifications from this topic, please click or visit the link below to unsubscribe:https://sns.us-east-1.amazonaws.com/unsubscribe.html?SubscriptionArn=arn:aws:sns:us-east-1:261234435984:SpendHQAWSHealth:09fe47fc-f599-46ea-b1c2-8fc7ba31782b&Endpoint=support@reancloud.comPlease do not reply directly to this email. If you have any questions or comments regarding this email, please contact us at https://aws.amazon.com/support-- -- You received this message because you are subscribed to the Google Groups HelpDesk group.To unsubscribe from this group and stop receiving emails from it, send an email to help+unsubscribe@reancloud.com.",AWS_EC2_PERSISTENT_INSTANCE_RETIREMENT_SCHEDULED,,02-01-2019 05:48,99,0,SpendHQ,"Hi Matthew,We have created a change ticket #	01110322	 to perform this stop/start activity to complete instance retirement.Please verify the instance functionality from your end and update us on the same ticket.As of now, we are marking this incident ticket closed.","Hello Matthew,We have performed stop/start on matt_SHQ_m5.large_01 (i-01998ce82253d4012) and server is up now. Both 2/2 status check got passed.Please verify it from your end and confirm us. Feel free to reach us if you have any queries.","Hello Matthew,Thanks for the update.We are going to perform this action now to stop/start the server and will let you know once it has done.Thank you,",From Matthew:This can be done now.,"Hello Matthew,Thank you for the update. Can you please confirm the time frame when we can perform stop and start on the server or let us know if we can perform now.",From MatthewYes please,"Hello Team,This is a quick follow up  to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012 Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43Regards","Hello Team,This is a quick follow up, we recently received a notification from AWS stating that there is a degradation of the underlying hardware hosting one of your instances.The instance matt_SHQ_m5.large_01 is the instance in question and we recommend performing a stop and start on this machine to resolve the issue.Thanks.","Hello Team, We haven't heard back from you.This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012 Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43","Hello Team, This is to bring to your attention that EC2 has detected degradation of the underlying hardware hosting your Amazon EC2 instance associated with this event in the us-east-1 region. Due to this degradation, your instance could already be unreachable. After 2019-01-16 00:00 UTC your instance, which has an EBS volume as the root device, will be stopped. A stop and start of the server can resolve the issue. Kindly let us know if we can perform the action or you will do the same. Resource details Instance ID : i-01998ce82253d4012Instance Name : matt_SHQ_m5.large_01	Instance Type	: m5.large	Account	SpendHQ	Region	us-east-1	Private IP Address	10.59.100.43",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
